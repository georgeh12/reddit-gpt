{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# MLflow model\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# math functions\n",
    "import numpy as np\n",
    "\n",
    "# read CSV file\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# data frames\n",
    "import pandas as pd\n",
    "\n",
    "# regexes\n",
    "import re\n",
    "\n",
    "# Print pandas.describe() in PDF\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# converting created dates from reddit API into human readable format\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable automated output\n",
    "import warnings\n",
    "# Future deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "# Set logging level to suppress INFO messages\n",
    "logging.getLogger('mlflow').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/bitgrit-data-science-publication/sentiment-analysis-on-reddit-tech-news-with-python-cbaddb8e9bb6\n",
    "\n",
    "# Load NLTK Libraries\n",
    "\n",
    "# sentiment analysis\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer # tokenize words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Downloading NLTK's databases\n",
    "nltk.download('vader_lexicon', quiet=True); # get lexicons data\n",
    "nltk.download('punkt', quiet=True); # for tokenizer\n",
    "nltk.download('stopwords', quiet=True); # dictionary for tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8) # default plot size\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', palette='Dark2')\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Subreddit API analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit metadata structure\n",
    "subreddit_dict = {  \"name\":[],\n",
    "                    \"subscribers\":[] }\n",
    "\n",
    "# Import subreddit metadata\n",
    "metadata = pd.DataFrame()\n",
    "for fname in glob.iglob(os.path.abspath('./data/**/*.meta'), recursive=True):\n",
    "    _metadata = pd.read_csv(fname)\n",
    "    _metadata['display_name'] = _metadata['name']\n",
    "    _metadata['name'] = _metadata['name'].str.lower()\n",
    "    metadata = metadata.append(_metadata.copy(), ignore_index=True)\n",
    "    #print(fname)\n",
    "    #break #DEBUG\n",
    "\n",
    "# Drop duplicates from the 'name' column\n",
    "metadata.reset_index(inplace=True)  # Reset index\n",
    "metadata.drop_duplicates(subset='name', inplace=True)  # Drop duplicates based on the 'name' column\n",
    "metadata.sort_values(by='subscribers', ascending=False, inplace=True)\n",
    "\n",
    "# filter subreddits with less than 100,000 subscribers\n",
    "metadata = metadata[metadata['subscribers'] > 100000]\n",
    "# Calculate subscribers as a percentage of the total\n",
    "total_subscribers = metadata['subscribers'].sum()\n",
    "metadata['subscribers_pct'] = (metadata['subscribers'] / total_subscribers) * 100\n",
    "\n",
    "print('Subreddit Stats')\n",
    "# Create a PrettyTable object\n",
    "table = PrettyTable()\n",
    "# Add columns to the table\n",
    "table.field_names = metadata.columns\n",
    "# Add rows to the table\n",
    "for row in metadata.itertuples(index=False):\n",
    "    # Set the float format for all float columns\n",
    "    float_format = \"{:.2f}\"\n",
    "    # Format float values\n",
    "    row = [float_format.format(value) if isinstance(value, float) else value for value in row]\n",
    "    table.add_row(row)\n",
    "# Print the table\n",
    "print(table)\n",
    "\n",
    "# After printing, set name as the index\n",
    "metadata.set_index('name', inplace=True)  # Set the 'name' column as the index of the DataFrame\n",
    "metadata.to_csv('/'.join(['output', 'subreddits.meta']))\n",
    "\n",
    "# Plot pie chart of sentiment label distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(metadata)))\n",
    "metadata['subscribers_pct'].plot(kind='pie', autopct='%1.1f%%', colors=colors)\n",
    "# Add annotations for subscriber percentages\n",
    "plt.legend(loc='lower left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title('Subreddit Stats: Subscriber Distribution')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Total Subscribers: ' + \"{:,}\".format(total_subscribers))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Search API data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit data structure\n",
    "topics_dict_template = {\"subreddit\":[],\n",
    "                        \"query\":[],\n",
    "                        \"sort\":[],\n",
    "                        \"date\":[],\n",
    "                        \"title\":[],\n",
    "                        \"author\":[],\n",
    "                        \"stickied\":[],\n",
    "                        \"upvote_ratio\":[],\n",
    "                        \"score\":[],\n",
    "                        \"id\":[],\n",
    "                        \"url\":[],\n",
    "                        \"num_comments\": [],\n",
    "                        \"created\": [],\n",
    "                        \"body\":[]}\n",
    "\n",
    "# Import query data\n",
    "df = pd.DataFrame()\n",
    "running_total = 0\n",
    "for fname in glob.glob(os.path.abspath('./data/**/*.csv'), recursive=True):\n",
    "    _df=pd.read_csv(fname)\n",
    "    # Check for empty dataset\n",
    "    if _df.empty: continue\n",
    "    _df['subreddit'] = _df[_df['subreddit'].str.lower().isin(metadata.index)]['subreddit'].str.lower()\n",
    "\n",
    "    # Remove missing subreddit values\n",
    "    _df = _df[_df['subreddit'].notna()]\n",
    "    if _df.empty: continue\n",
    "\n",
    "    # Calculate weighted score by dividing the score by the percentage of the subreddit\n",
    "    _df['score_weighted'] = _df.apply(lambda row: row['score'] * 100 / (100 - metadata.loc[row['subreddit']]['subscribers_pct']), axis=1)\n",
    "    _df['num_comments_weighted'] = _df.apply(lambda row: row['num_comments'] * 100 / (100 - metadata.loc[row['subreddit']]['subscribers_pct']), axis=1)\n",
    "    _df['date'] = pd.to_datetime(_df['date']) # convert date column\n",
    "    df = df.append(_df.copy(), ignore_index=True)\n",
    "    running_total+=len(_df)\n",
    "    #print(fname)\n",
    "    #print(running_total)\n",
    "    #break #DEBUG\n",
    "\n",
    "# remove duplicate posts\n",
    "df.reset_index(inplace=True)  # Reset index\n",
    "df.drop_duplicates(subset='id', inplace=True)  # Drop duplicates based on the 'id' column\n",
    "df.set_index('id', inplace=True)  # Set the 'id' column as the index of the DataFrame\n",
    "\n",
    "print(f\"Total imported Reddit posts: {running_total}\")\n",
    "print(f\"Duplicate cross-subreddit posts: {running_total-len(df)}\")\n",
    "print(f\"De-duplicated reddit posts: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "\n",
    "#Create a function to clean the tweets\n",
    "def cleanTxt(text):\n",
    "    text = re.sub(r'@[A-Za-z0–9]+', '', text) #Remove @mentions replace with blank\n",
    "    text = re.sub(r'#', '', text) #Remove the ‘#’ symbol, replace with blank\n",
    "    text = re.sub(r'RT[\\s]+', '', text) #Removing RT, replace with blank\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text) #Remove the hyperlinks\n",
    "    text = re.sub(r':', '', text) # Remove :\n",
    "    return text\n",
    "\n",
    "#Next we have to remove emoji & Unicode from the Tweet data.\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
    "    u\"\\U00002500-\\U00002BEF\" # chinese char\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    "    u\"\\U0001f926-\\U0001f937\"\n",
    "    u\"\\U00010000-\\U0010ffff\"\n",
    "    u\"\\u2640-\\u2642\"\n",
    "    u\"\\u2600-\\u2B55\"\n",
    "    u\"\\u200d\"\n",
    "    u\"\\u23cf\"\n",
    "    u\"\\u23e9\"\n",
    "    u\"\\u231a\"\n",
    "    u\"\\ufe0f\" # dingbats\n",
    "    u\"\\u3030\"\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_sentiment(dataset):\n",
    "    # VADER sentiment analysis\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    dataset[['neg', 'neu', 'pos', 'compound']] = dataset['clean'].apply(lambda text: pd.Series(sid.polarity_scores(text)))\n",
    "\n",
    "    # Threshold conditions determine the value of the sentiment of the text\n",
    "    THRESHOLD = 0.2\n",
    "    conditions = [\n",
    "        (dataset['compound'] <= -THRESHOLD),\n",
    "        (dataset['compound'] > -THRESHOLD) & (dataset['compound'] < THRESHOLD),\n",
    "        (dataset['compound'] >= THRESHOLD),\n",
    "        ]\n",
    "    values = [\"neg\", \"neu\", \"pos\"]\n",
    "    dataset['label'] = np.select(conditions, values)\n",
    "\n",
    "    # Convert all sentiment columns to numeric type\n",
    "    dataset[['neg', 'neu', 'pos', 'compound']] = dataset[['neg', 'neu', 'pos', 'compound']].apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows without a comment body\n",
    "df.dropna(subset='body', how=\"any\", inplace=True)\n",
    "\n",
    "df['clean'] = df['body'].apply(lambda x: remove_emoji(cleanTxt(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the date range for GPT-3 hype analysis\n",
    "gpt3_start = datetime(2022, 11, 1)\n",
    "gpt3_launch = datetime(2022, 11, 30)\n",
    "gpt3_end = datetime(2023, 1, 31)\n",
    "\n",
    "# Define the date range for GPT-4 hype analysis\n",
    "gpt4_start = datetime(2023, 2, 15)\n",
    "gpt4_launch =  datetime(2023, 3, 14)\n",
    "gpt4_end = datetime(2023, 5, 15)\n",
    "\n",
    "# Filter GPT-3 dataset\n",
    "df_gpt3 = df[(gpt3_start <= df['date']) & (df['date'] < gpt3_end + timedelta(days=1))]\n",
    "# get the distance of the date to the GPT-3 launch date\n",
    "df_gpt3['launch_distance'] = abs(gpt3_launch - df_gpt3['date'])\n",
    "df_gpt3['launch_distance_f'] = df_gpt3['launch_distance'] / pd.to_timedelta(1, unit='D')\n",
    "\n",
    "\n",
    "# Filter GPT-4 dataset\n",
    "df_gpt4 = df[(gpt4_start <= df['date']) & (df['date'] < gpt4_end + timedelta(days=1))]\n",
    "# get the distance of the date to the GPT-4 launch date\n",
    "df_gpt4['launch_distance'] = abs(gpt4_launch - df_gpt4['date'])\n",
    "df_gpt4['launch_distance_f'] = df_gpt4['launch_distance'] / pd.to_timedelta(1, unit='D')\n",
    "\n",
    "# apply vader sentiment to matched datasets\n",
    "vader_sentiment(df_gpt3)\n",
    "vader_sentiment(df_gpt4)\n",
    "\n",
    "# Split at gpt3_launch date\n",
    "df_gpt3_before = df_gpt3[df_gpt3['date'] < gpt3_launch]\n",
    "df_gpt3_after = df_gpt3[gpt3_launch <= df_gpt3['date']]\n",
    "# Split at gpt4_launch date\n",
    "df_gpt4_before = df_gpt4[df_gpt4['date'] < gpt4_launch]\n",
    "df_gpt4_after = df_gpt4[gpt4_launch <= df_gpt4['date']]\n",
    "\n",
    "# Get counts of datasets before and after launch dates\n",
    "df_gpt_counts = {\n",
    "    'GPT-3 Before Launch': len(df_gpt3_before),\n",
    "    'GPT-3 After Launch': len(df_gpt3_after),\n",
    "    'GPT-4 Before Launch': len(df_gpt4_before),\n",
    "    'GPT-4 After Launch': len(df_gpt4_after)\n",
    "}\n",
    "# Plot pie chart of GPT search distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['#4e79a7', '#85c0f9', '#ff7f7f', '#ffcccb']  \n",
    "plt.pie(df_gpt_counts.values(), colors=colors, labels=df_gpt_counts.keys(), autopct=lambda pct: f\"{pct:.1f}% ({int(pct/100*sum(df_gpt_counts.values()))})\")\n",
    "# Add annotations for subscriber percentages\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 0.5))\n",
    "plt.title('Dataset: Posts Distribution')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Total Posts: ' + \"{:,}\".format(sum(df_gpt_counts.values())))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sentiment(dataset, name):\n",
    "    # Plot histogram of compound sentiment scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=dataset, x='compound', bins=20, kde=True, color='skyblue')\n",
    "    plt.title(name + ': Distribution of Compound Sentiment Scores')\n",
    "    plt.xlabel('Compound Sentiment')\n",
    "    plt.ylabel('Reddit Posts')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot pie chart of sentiment label distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    dataset['label'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['lightgreen', 'lightgray', 'lightcoral'])\n",
    "    plt.title(name + ': Sentiment Distribution')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "visualize_sentiment(dataset=df_gpt3_before, name='GPT-3 model before release')\n",
    "visualize_sentiment(dataset=df_gpt3_after, name='GPT-3 model after release')\n",
    "visualize_sentiment(dataset=df_gpt4_before, name='GPT-4 model before release')\n",
    "visualize_sentiment(dataset=df_gpt4_after, name='GPT-4 model after release')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing datasets, features, and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to measure with MLflow\n",
    "feature_names = ['launch_distance_f', 'num_comments_weighted', 'stickied', 'upvote_ratio', 'created', 'compound', 'pos', 'neg', 'neu']\n",
    "# Target MLflow value\n",
    "target_name = 'score_weighted'\n",
    "# these variables should be represented as log of the original values\n",
    "log_variables = ['score_weighted','num_comments', 'launch_distance_f', 'num_comments_weighted']\n",
    "\n",
    "def clean_dataset(dataset, csv_name, inplace=True):\n",
    "    global log_variables, feature_names, target_name\n",
    "    if inplace is True:\n",
    "        _dataset = dataset\n",
    "    else:\n",
    "        _dataset = dataset.copy()\n",
    "    for variable in log_variables:\n",
    "        # Rename the variables to log_[variable] in the datasets\n",
    "        log_variable = 'log_'+variable\n",
    "        if target_name == variable:\n",
    "            target_name = log_variable\n",
    "        elif variable in feature_names:\n",
    "            feature_names[feature_names.index(variable)] = log_variable\n",
    "        _dataset[log_variable] = _dataset[variable].apply(lambda value: np.log(value+1))\n",
    "    _dataset.dropna(subset=feature_names, how=\"any\", inplace=inplace)\n",
    "    _dataset.dropna(subset=target_name, how=\"any\", inplace=inplace)\n",
    "    _dataset = _dataset.sort_index()\n",
    "    \n",
    "    ## Output file to csv\n",
    "    _dataset.to_csv('/'.join(['output', csv_name + '.csv']))\n",
    "    return _dataset\n",
    "\n",
    "clean_dataset(df_gpt3_before, 'gpt3-before')\n",
    "clean_dataset(df_gpt3_after, 'gpt3-after')\n",
    "clean_dataset(df_gpt4_before, 'gpt4-before')\n",
    "clean_dataset(df_gpt4_after, 'gpt4-after')\n",
    "\n",
    "# These features are disabled. Stickied items throw off the counts.\n",
    "for feature in ['stickied', 'created']: feature_names.remove(feature)\n",
    "\n",
    "print(f\"feature_names={feature_names}\")\n",
    "print(f\"target_name={target_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_dataset(dataset, name):\n",
    "    print(name)\n",
    "    description_table = dataset.describe()\n",
    "\n",
    "    # Convert the 'created' column to datetime\n",
    "    description_table['created'] = pd.to_datetime(description_table['created'], unit='s')\n",
    "\n",
    "    description_table = description_table.transpose()\n",
    "    description_table.reset_index(inplace=True)\n",
    "\n",
    "    # Create a PrettyTable object for the first half of columns\n",
    "    table1 = PrettyTable()\n",
    "    table1.field_names = description_table.columns[:1+len(description_table.columns)//2]\n",
    "\n",
    "    # Create a PrettyTable object for the second half of columns, including the first column\n",
    "    table2 = PrettyTable()\n",
    "    table2.field_names = ['index'] + list(description_table.columns[1+len(description_table.columns)//2:])\n",
    "\n",
    "    # Set the float format for all float columns\n",
    "    float_format = \"{:.2f}\"\n",
    "\n",
    "    # Set the timedelta format\n",
    "    def format_timedelta(td):\n",
    "        days = td.days\n",
    "        hours, remainder = divmod(td.seconds, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        return f\"{days} days\" # {hours:02}:{minutes:02}:{seconds:02}\n",
    "    \n",
    "    # Format date\n",
    "    def format_date(dt):\n",
    "        return dt.strftime(\"%Y-%m-%d\") # %H:%M:%S\n",
    "\n",
    "    # Add rows to the tables\n",
    "    for row in description_table.itertuples(index=False):\n",
    "        # Convert timedelta values to formatted strings\n",
    "        row = list(row)\n",
    "        for i, value in enumerate(row):\n",
    "            if isinstance(value, pd.Timedelta):\n",
    "                row[i] = format_timedelta(value)\n",
    "            elif isinstance(value, pd.Timestamp):\n",
    "                row[i] = format_date(value)\n",
    "        # Format float values\n",
    "        row = [float_format.format(value) if isinstance(value, float) else value for value in row]\n",
    "        # Add row to the first table\n",
    "        table1.add_row(row[:1+len(description_table.columns)//2])\n",
    "        # Add row to the second table\n",
    "        table2.add_row([row[0]] + row[1+len(description_table.columns)//2:])\n",
    "\n",
    "    # Print the tables\n",
    "    print(table1)\n",
    "    print(table2)\n",
    "\n",
    "describe_dataset(dataset=df_gpt3_before, name='GPT-3 model before release')\n",
    "describe_dataset(dataset=df_gpt3_after, name='GPT-3 model after release')\n",
    "describe_dataset(dataset=df_gpt4_before, name='GPT-4 model before release')\n",
    "describe_dataset(dataset=df_gpt4_after, name='GPT-4 model after release')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MLflow experiment\n",
    "Linear regression analysis. Remove \"stickied\" Reddit posts from data.\n",
    "\n",
    "Test model against data after GPT-4 launch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable automatic logging to MLflow\n",
    "mlflow.set_experiment(\"Reddit GPT Hype\")\n",
    "mlflow.autolog()\n",
    "\n",
    "def trim_dataset(dataset, q_lower = .1, q_upper = .9):\n",
    "    global target_name\n",
    "    quantile = target_name\n",
    "    _dataset = dataset.copy()\n",
    "    # Trim dataset by the quantile for the target for training\n",
    "    _dataset = _dataset[(_dataset['stickied'] == False)]\n",
    "    _q_lower = _dataset[quantile].quantile(q_lower)\n",
    "    _q_upper = _dataset[quantile].quantile(q_upper)\n",
    "    _dataset = _dataset[(_dataset[quantile] >= _q_lower) &\n",
    "                        (_dataset[quantile] <= _q_upper)]\n",
    "    return _dataset\n",
    "\n",
    "def model_testing(dataset, test):\n",
    "    _dataset = dataset.copy()\n",
    "    _test = test.copy()\n",
    "    # Trim upper and lower quantiles\n",
    "    _dataset = trim_dataset(_dataset)\n",
    "    _test = trim_dataset(_test)\n",
    "    # Sort values for displaying in graph\n",
    "    _dataset = dataset\n",
    "    _test = _test\n",
    "    # Set X features and y targets\n",
    "    X_test = _test.loc[:, _test.columns[:,None] == feature_names]\n",
    "    y_test = _test.loc[:, _test.columns == target_name].values\n",
    "    X = _dataset.loc[:, _dataset.columns[:,None] == feature_names]\n",
    "    y = _dataset.loc[:, _dataset.columns == target_name].values\n",
    "\n",
    "    lr_params =  {}\n",
    "    lr = LinearRegression(**lr_params)\n",
    "\n",
    "    # MLflow triggers logging automatically upon model fitting\n",
    "    lr.fit(X, y)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    return {'X': X, 'y': y, 'X_test': X_test, 'y_actual': y_test, 'y_pred': y_pred, 'coef': lr.coef_}\n",
    "\n",
    "gpt3_model = model_testing(df_gpt3_before, df_gpt3_after)\n",
    "gpt4_model = model_testing(df_gpt4_before, df_gpt4_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy of the models\n",
    "def plot_accuracy(model, name):\n",
    "    actual_values = model['y_actual']\n",
    "    predicted_values = model['y_pred']\n",
    "\n",
    "    # Scatter plot of actual versus predicted values\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(actual_values, predicted_values, alpha=0.5)\n",
    "    plt.plot(actual_values, actual_values, color='red', linestyle='--')\n",
    "    plt.xlabel(\"Actual Values\")\n",
    "    plt.ylabel(\"Predicted Values\")\n",
    "    plt.title(name + \": Actual vs. Predicted Values\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Residual plot\n",
    "    residuals = actual_values - predicted_values\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(predicted_values, residuals, alpha=0.5)\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.xlabel(\"Predicted Values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.title(name + \": Residual Plot\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Coefficient plot (if coefficients are available in the MLflow run)\n",
    "    if \"coefficients\" in model:\n",
    "        coefficients = model[\"coef\"]\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x=coefficients.index, y=coefficients.values)\n",
    "        plt.xlabel(\"Independent Variables\")\n",
    "        plt.ylabel(\"Coefficients\")\n",
    "        plt.title(\"Coefficient Plot\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "plot_accuracy(model=gpt3_model, name='GPT-3 model')\n",
    "plot_accuracy(model=gpt4_model, name='GPT-4 model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(model, name):\n",
    "    for coef in feature_names:\n",
    "        feature = coef\n",
    "        plt.scatter(model['X'][feature], model['y'], color='red', label='Training Data')\n",
    "        plt.scatter(model['X_test'][feature], model['y_pred'], color='purple', label='Predictions')\n",
    "        y_fit = model['X'][feature] * model['coef'][0][feature_names.index(feature)]\n",
    "        plt.plot(model['X'][feature], y_fit, color='blue', linewidth=3, label='Linear Regression')\n",
    "        plt.xlabel(f\"{feature}\")\n",
    "        plt.ylabel(f\"{target_name}\")\n",
    "        plt.title(f\"Linear Regression: {name} - {feature} vs. {target_name}\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print(f\"{coef}={model['coef'][0][feature_names.index(coef)]}\")\n",
    "plot_features(model=gpt3_model, name='GPT-3 model')\n",
    "plot_features(model=gpt4_model, name='GPT-4 model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(dataset, name, category):\n",
    "    # Count the occurrences of each category value\n",
    "    category_counts = dataset[category].value_counts()\n",
    "\n",
    "    # Plot the distribution as a bar chart\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = category_counts.plot(kind='bar', color='skyblue')\n",
    "    plt.title(f'Distribution of {category} in {name}')\n",
    "    plt.xlabel(category)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y')\n",
    "    ax.grid(False)  # Remove gridlines\n",
    "\n",
    "\n",
    "    # Annotate each bar with its count\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), \n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "    # Add total count outside the plot\n",
    "    total_count = dataset[category].count()\n",
    "    plt.text(1, 1, f'Total: {total_count}', ha='right', va='top', transform=ax.transAxes, fontsize=10,\n",
    "             bbox=dict(facecolor='white', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "for category in ['subreddit', 'query']:\n",
    "    plot_distributions(dataset=df_gpt3_before, name='GPT-3 model before announcement', category=category)\n",
    "    plot_distributions(dataset=df_gpt3_after, name='GPT-3 model after announcement', category=category)\n",
    "    plot_distributions(dataset=df_gpt4_before, name='GPT-4 model before announcement', category=category)\n",
    "    plot_distributions(dataset=df_gpt4_after, name='GPT-4 model after announcement', category=category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap of MLflow runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data from MLflow\n",
    "experiments = mlflow.search_runs()\n",
    "\n",
    "# Convert 'start_time' column to datetime\n",
    "experiments['start_time'] = pd.to_datetime(experiments['start_time'])\n",
    "# Format 'start_time' to include date, hour, minute, and second\n",
    "experiments['start_time'] = experiments['start_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Trim the values in 'metrics.training_r2_score' to two decimal places\n",
    "experiments['metrics.training_r2_score'] = experiments['metrics.training_r2_score'].apply(lambda x: round(x, 2))\n",
    "\n",
    "# Sort by 'start_time' column in descending order\n",
    "experiments_sorted = experiments.sort_values(by='start_time', ascending=False)\n",
    "\n",
    "# Take every 4 experiments and collate them\n",
    "experiments_sorted['start_time_grouped'] = experiments_sorted.groupby(experiments_sorted.index // 2)['start_time'].transform(lambda x: x.iloc[0])\n",
    "\n",
    "# Take the most recent 5 experiments\n",
    "num_experiments = 10\n",
    "recent_experiments = experiments_sorted.head(num_experiments*2)\n",
    "\n",
    "# Organize the data into a DataFrame\n",
    "heatmap_data = recent_experiments.pivot_table(index='start_time_grouped', columns='metrics.training_r2_score', values='metrics.training_mean_squared_error')\n",
    "\n",
    "# Sort the index in descending order\n",
    "heatmap_data = heatmap_data.sort_index(ascending=False)\n",
    "\n",
    "# Create the heatmap using Seaborn\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_data, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "plt.title('Heatmap of Mean Squared Error by Grouped Run Time and R2 Score')\n",
    "plt.xlabel('Training R2 Score')\n",
    "plt.ylabel('Run Time')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
