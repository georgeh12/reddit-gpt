,id,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,url,num_comments,created,body
0,13ilm03,datascience,ChatGPT,top,2023-05-15 21:45:36,I investigated the Underground Economy of Glassdoor Reviews,ibsurvivors,False,0.99,1158,https://www.reddit.com/r/datascience/comments/13ilm03/i_investigated_the_underground_economy_of/,63,1684187136.0,"Online company reviews are high stakes.

Top reviews on sites like Glassdoor and Google can get thousands of impressions each month and are major drivers of brand perception.

Employers know this. And when I come across multiple 5 star reviews left with no cons, or a Pulitzer worthy essay from a former intern, I become suspicious.

These reviews start to resemble 30 under 30 lists: so artificially constructed that you begin to question their credibility in the first place.

The scrutiny around company reviews is well documented; some companies file lawsuits worth over a million dollars to reveal anonymous reviewers that complain about their jobs.

Whilst it's the flashy lawsuits that make the headlines, there also exists an underground economy of company reviews operating quietly every single day.

In this underground economy, some companies pay over $150 to freelancers to try and get a negative review removed. If they want ‚Äúbetter‚Äù results, they go to the plethora of Online Reputation Management services (ORMs) in the United States that can charge retainers worth thousands of dollars.

The supply of positive reviews exists too. My research led me to find companies, including a prominent Y-Combinator backed startup, that solicit fake positive reviews from online freelancers to improve their rating.

Many of these mercenary fake reviewers, often based in South East Asia, make a full time living doing this, netting over $2,000 per month.

Some of these run such sophisticated operations that they‚Äôve even created their own pricing tiers (e.g $35 per original review, $20 to post an already created review from an email address), a la SaaS offering.

Others operate on a contingency fee agreement model, where they only get paid if they‚Äôre able to take a negative review down.

The underground economy of company reviews is well and truly alive. And today we‚Äôre going to find out how it operates.

***Note***: For more content like this, [*subscribe*](https://www.careerfair.io/subscribe) *to my newsletter. In a couple of weeks, I'll be releasing my guide to writing a killer resume.*

**Adding reviews**

The barriers to entry for adding fake reviews are much lower than for getting reviews removed, so that‚Äôs where we‚Äôll start.

To write an employer review, all you really need is the ability to create an email address. For most sites, you don‚Äôt need any proof of employment (say like a company specific email address).

I went on a gig marketplace site and posted a pretty vague post related to wanting to find out more on how to improve a company‚Äôs online presence.

Within minutes of posting a gig, my inbox was flooded with proposals:

https://preview.redd.it/esx3904qa20b1.png?width=3064&format=png&auto=webp&s=2ff3a2f8528fee99aabb830f27ea71a7569ebb2e

After a bit of chatting, I narrowed the scope of their services and summarized their rates into the table below:

|Channel|Cost|Timeline|Model|
|:-|:-|:-|:-|
|Freelancer #1|$10 per review|Monthly|Unlimited|
|Freelancer #2|$35 per original review, $20 per already created review|Monthly|Unlimited|
|Freelancer #3|$25 per review|Monthly|Unlimited|
|Freelancer #4|$25 per review|Monthly|10 reviews|
|Freelancer #5|$20 per review|Monthly|Unlimited|
|Online Reputation Management Agency|$300 subscription|Monthly|8 reviews|

Let‚Äôs dive a bit deeper into the services that Freelancer #5 offered.

Freelancer #5 explained to me he had been writing reviews for one particular company for the past 4 months now. Each month he wrote them 10 reviews.

&#x200B;

https://preview.redd.it/n1ddox6cb20b1.png?width=2684&format=png&auto=webp&s=5c271d0eec4328cb78d7d2cb85dfffa3f9eb72f8

In another message, he tells me he‚Äôs offering the same services to 5 other companies. Doing some quick math:

5 companies x 10 reviews per company x $25 per review = $1,250 per month

Considering the average person in Pakistan earns $150 per month, that‚Äôs not bad change at all.

One of the companies that he‚Äôs offering his services to includes a Y-Combinator backed startup. I won‚Äôt name the company, but here‚Äôs what its average Glassdoor review rating distribution looks like:

https://preview.redd.it/2np5b6fdb20b1.png?width=2420&format=png&auto=webp&s=f8cafaa85453b0933a18eb5c30f931b3bb893c46

5 star reviews account for over 77% of the company‚Äôs total reviews. Obviously, no one is buying fake reviews that make them look bad.

But here‚Äôs the thing: freelancers are getting quite smart when it comes to writing reviews that don‚Äôt look too fishy. They tend to do this by spacing the reviews out (so that they don‚Äôt come in ‚Äúspikes‚Äù ‚Äì more on this later) and they also make sure that they‚Äôre not always leaving the ‚Äúcons‚Äù section blank.

Don‚Äôt get me wrong, if you come across this company‚Äôs reviews, it‚Äôd be pretty easy to tell they‚Äôre quite strange. In fact, I can‚Äôt even post some screenshots here because it‚Äôd give the company away immediately.

But it would be challenging to conclude that the above company is buying reviews just by analyzing review volume and distribution without actually reading some of the reviews.

The same company is also buying reviews on Google Reviews.

Sidenote: I got curious about how he‚Äôs been writing 50 reviews from 50 different emails per month. Would he actually create 50 different email addresses? And what about the IP address ‚Äì doesn‚Äôt Glassdoor flag multiple reviews from the same IP?

One of the freelancers answered my question:

&#x200B;

https://preview.redd.it/g4id2yqeb20b1.png?width=2572&format=png&auto=webp&s=c2a77fdea8834a6d90f02b8b3eb67b3a874f3df2

Moving on ‚Äì another company that seems to buy fake reviews seems to be having some more trouble. Approximately a month after a freelancer linked me to fake reviews he had written for this company, all five reviews that he had linked me to had been removed:

&#x200B;

https://preview.redd.it/99fdvcgfb20b1.png?width=3116&format=png&auto=webp&s=b7e244529fc62b5c824d925feb61fd2cc16cbfd5

Based on this [Glassdoor webinar](https://youtu.be/3iy0JWOS1gs) from 2018, ‚Äúif it is found that a user has created multiple email accounts to submit reviews, then ALL submissions from that user are deleted‚Äù ‚Äì so likely Glassdoor‚Äôs content moderation team flagged one of the initial reviews and the same freelancer who was writing reviews for that company had all the fake reviews deleted.

So far, it looks like the key to an effective fake review creation strategy lies in:

* Spacing the fake reviews out
* Writing each review from a different IP address (i.e benefit of being part of a team)
* Using language that isn‚Äôt an obvious giveaway

On that third point: the reality is that many of these freelancers‚Äô first language is not English.

As an experiment, I turned to everybody‚Äôs favorite new toy, ChatGPT, and asked it to write me a positive Glassdoor review:

https://preview.redd.it/8w7cal9gb20b1.png?width=3164&format=png&auto=webp&s=860c39b11c5813e8b7fabdbb038d73c565cc98cf

And I‚Äôd say that the above answer was better than 95% of the fake reviews I came across.

**Removing reviews**

The process for removing an employer review usually works like this:

1. You identify one or multiple reviews that you want removed
2. You verify whether the review violates the site's Guidelines, or whether there‚Äôs something else about the review(s) that could get it removed.
3. You file an appeal to get it removed.

As an example, Glassdoor‚Äôs Review guidelines can be found [here](https://help.glassdoor.com/s/article/Community-Guidelines?language=en_US#:~:text=See%20More-,Review%C2%A0Guidelines,-Millions%20of%20job). Mainly, they forbid mentioning anyone by name who‚Äôs not an executive and revealing proprietary or confidential information, amongst a host of other things.

Sounds simple enough right? Well, according to one of the freelancers I messaged:

&#x200B;

https://preview.redd.it/x6s8hsyac20b1.png?width=2036&format=png&auto=webp&s=f86c386f864198dc43faeb41faea378090c20107

After some research, I summarized the different vendors and prices in the table below:

&#x200B;

|Channel|Cost|Timeline|Model|Self reported success rate|
|:-|:-|:-|:-|:-|
|Freelancer #1|$100 per review|3 days|Contingency Agreement Model|100%|
|Freelancer #2|$30 per review|7 days|Contingency Agreement Model|100%|
|Reputation management service #2|$450 per review|21 business days|Contingency Agreement Model|Unknown|
|Reputation management service #3|$1000 per review|Undefined|Contingency Agreement Model|100%|
|Reputation management service #4 Plan 1|$550 per review|5-6 weeks|Contingency Agreement Model|50-75%|
|Reputation management service #4 Plan 2|$300 Subscription + $100 per each review removed|Monthly service|Subscription plan|50-75%|
|Freelancer #3|$20|Undefined|Pay regardless|Undefined|
|Freelancer #4|$500|Undefined|Contingency Agreement Model|Undefined|

As you can see, unlike the fake review generation market, the prices vary quite a bit for getting reviews removed.

At one end, you have freelancers on gig marketplaces that will attempt to remove a review for less than $100. And then on the other end, you have ORMs (Online Reputation Management Agencies) that have multiple employees and more comprehensive packages in place. The one constant seems to be that most companies operate on a contingency agreement model (i.e pay only if review gets removed).

**Analyzing reviews**

ReviewMeta is a site that analyzes Amazon reviews and tells you how many are legitimate. The creator of the site, Tommy Noonan, mentions in an [interview with NPR](https://www.npr.org/sections/money/2018/06/27/623990036/episode-850-the-fake-review-hunter) that the main giveaway that a product is soliciting fake reviews is:

* A large, suspicious flood of positive reviews at the exact same time. For example, a 3 day stretch of time constituting 30% of total reviews.
* Phrases and words that are constantly repeated, especially in the section with no cons
* Brand monogamists (only review products from one company)

Whilst the last two bullets are hard to track, the first can be used to analyze different companies‚Äô reviews and to check if there might be some funky business going on.

After a couple of days, I have the ability to track review volume and review ratings over time for any company that I specify:

https://preview.redd.it/ehcbw2oje20b1.png?width=1653&format=png&auto=webp&s=b448ff35eb9878fbb1686de2fa8cf031e4ed3e05

Let the games begin.

## Voluntary Response Bias

One of the biggest challenges that review platforms face is the Voluntary Response bias.

Research shows many of today‚Äôs most popular online review platforms (e.g Amazon) have a distribution of opinion that is highly polarized, with many extreme positive and/or negative reviews, and few moderate opinions.

Think about it: have you ever felt moderately satisfied at your job and thought to yourself, now would be a great time to leave a Glassdoor review? Probably not.

On the other hand, if you‚Äôve had a terrible experience or even just had one thing really flip you off, you might be quite likely to leave an angry review.

Consider when a company goes through layoffs. You‚Äôre going to have a flood of angry reviews coming your way and are likely going to experience a ‚Äúspike‚Äù in reviews.

**Note:** Just like the Wall Street Journal‚Äôs methodology described [here](https://archive.is/20201016094732/https://www.wsj.com/articles/companies-manipulate-glassdoor-by-inflating-rankings-and-pressuring-employees-11548171977#selection-3965.0-3968.0), I considered there to be a spike if the total number of reviews in the month was greater than three standard deviations above the mean of the surrounding months.

Let‚Äôs take the company below. Here‚Äôs a graph of of their review volume since Jan 2020, including when they announced one of their first round of layoffs in June 2022:

https://preview.redd.it/n6kd9ejle20b1.png?width=3216&format=png&auto=webp&s=9eea2f3836617feca37eb88b1d3f67c8fa1b6fe2

In June 2022, approximately 19% of this company's 52 reviews were 1 star reviews (compared to an overall average of around 10%). This is what we could call a statistically significant spike in reviews. It also illustrates how the employees most likely to leave reviews are the ones that obviously had a bad experience (i.e getting laid off).

Here‚Äôs another company that had a similar spike in negative reviews due to layoffs in November 2022:

https://preview.redd.it/4vcnr1ine20b1.png?width=2408&format=png&auto=webp&s=f3877fb315ccc5d9a9294306a9f86616cb0fabd2

This company had an approximate 20% 1 star review rate (compared to an overall average of 12%) in November 2022, as well as an Avg Rating of 2.96 that month (compared to an overall average rating of 3.73).Unless HR is proactive, their reviews page risks succumbing to an echochamber of negative reviews that can really tilt one way.

**Note:** Glassdoor does state (based on [this video](https://www.youtube.com/watch?v=3iy0JWOS1gs) from 2017) that about 75% of the reviews on their platform are neutral. Their ‚Äúgive to get policy‚Äù has helped in keeping the platform from becoming too polarized.

I can understand why HR teams, like the ones that Nader talked to me about earlier, take a proactive stance towards managing their reviews. If they don‚Äôt try to control their reputation themselves, then their reputation risks getting controlled by the employees that had the worst possible experience.

## Goodhart‚Äôs Law

Goodhart‚Äôs law states the following:

*""When a measure becomes a target, it ceases to be a good measure""*

Every October, Glassdoor publishes their Best Places To Work ranking.

In a [report](https://www.wsj.com/articles/companies-manipulate-glassdoor-by-inflating-rankings-and-pressuring-employees-11548171977) that the WSJ did a couple of years ago, they found large spikes in the number of reviews that some companies (e.g SpaceX, Bain & Co, etc) got in September. The logic here is that some companies try to artificially inflate their Glassdoor reviews right before the October deadline.

I decided to revisit some of this analysis with Glassdoor‚Äôs 2023 Best Places To Work Ranking.

One of the companies I examined is rated as one of the best places to work in 2023. Let‚Äôs refer to this company as FunPlaceToWork.

Here is how their review volume looks like for all of 2022:

https://preview.redd.it/4e656zkqe20b1.png?width=2516&format=png&auto=webp&s=07141a66c56be7a6818efb9b1a4d912ee0021c91

FunPlaceToWork got around 50 reviews in September 2022. Of those 50 reviews, 96% were 5 star reviews.

FunPlaceToWork averaged 12 reviews per month up till then in 2022. Also, in the prior six months, the average percent of 5 star reviews received every month was \~75%.

Both the spike in volume of reviews and the spike in percentage of five star reviews are statistically significant.

I find it strange that Glassdoor‚Äôs proprietary algorithm and/or Human Content Moderation team did not find a spike of this nature unusual. If we look at Glassdoor‚Äôs eligibility criteria for the award, it‚Äôs as follows:

https://preview.redd.it/hag04y7se20b1.png?width=2868&format=png&auto=webp&s=ec2b920e126a8ea42b40d35aaa55d5341e69d022

The goal, according to Glassdoor, is to collect ‚Äúauthentic and unbiased reviews‚Äù.

Whilst there‚Äôs nothing against the rules for asking your employees to leave you reviews, I find the statistically significant spike of reviews at odds with the goal of collecting ""unbiased and authentic"" reviews (which Glassdoor states is the purpose of the awards).

Glassdoor states that an employer is allowed to ask its employees to leave reviews, but that they are not allowed to ‚Äúcoerce‚Äù them. Examples of what you can‚Äôt do:

* Offer incentives like Gift Cards in exchange for positive reviews.
* Withholding their reference letter unless they leave you a positive review.
* Anything that leads you to require proof for the employee to show you that they wrote a review.

It is possible to play by the rules (i.e not break any of the above rules) and to still in my opinion not collect authentic and unbiased reviews.

They say that you shouldn‚Äôt hate the player but the game ‚Äì I think **FunPlaceToWork** played by the rules, won fair and square, and that this is simply a perfect example of Goodhart‚Äôs Law.

I reached out to Glassdoor ([awards@glassdoor.com](mailto:awards@glassdoor.com)) about the above and this is the reply I got:

https://preview.redd.it/x0dqq39ue20b1.png?width=4800&format=png&auto=webp&s=c0102c963be9486370b340f2f473cbc6650fc48a

**Conclusion**

When I was 22, on an [F1 visa with 3 months to find work](https://www.careerfair.io/job-hunt-story), I didn‚Äôt give a damn about bad reviews. I needed a job and I‚Äôd sign any piece of paper you put in front of me.

Compare that to someone at the peak of their career, someone with optionality and a multitude of job offers; an ‚ÄúA-Player‚Äù, as the experts call it, would absolutely have the luxury of choice and discard a job offer based on bad company reviews.

For most people, the impact of online company reviews lies somewhere in the middle. In marketing, there‚Äôs a concept of a ‚Äúmarketing touchpoint‚Äù - an interaction with the brand over the course of the whole buying journey.

Company reviews are one of the many touchpoints a job seeker experiences over their interview process. And with the technology industry booming the past couple of years, companies couldn‚Äôt afford to slack on any touchpoints, including this one.

After all, when others start to game the system, you‚Äôre at a disadvantage if you don‚Äôt. The rewards can be quite high. Certainly higher than just trying to be as transparent as possible.

HR leaders are often more incentivized to inflate their metrics than to get honest feedback. Fake review writers have bills to pay. ORMs know that companies are desperate. And the platforms, well, aren‚Äôt always paying attention.

The result is a potluck of interests that leads to an underground economy.

One that ends up hurting the job seeker.

\*\*\*

Whew. That took a while (about 3 months in fact). Thanks for reading. For more content like this, [subscribe](https://www.careerfair.io/subscribe) to my newsletter. It's my best content delivered to your inbox once every 2 weeks."
1,zpraee,datascience,ChatGPT,top,2022-12-19 13:15:11,The real reason ChatGPT was created,xdonvanx,False,0.94,738,https://i.redd.it/g5z2t4zeuu6a1.png,73,1671455711.0,
2,10k528k,datascience,ChatGPT,top,2023-01-24 13:07:12,ChatGPT got 50% more marks on data science assignment than me. What‚Äôs next?,rifat_monzur,False,0.92,504,https://www.reddit.com/r/datascience/comments/10k528k/chatgpt_got_50_more_marks_on_data_science/,208,1674565632.0,"For context, in my data science master course, one of my classmate submit his assignment report using chatgpt and got almost 80%. Though, my report wasn‚Äôt the best, still bit sad, isn‚Äôt it?"
3,zgoxwa,datascience,ChatGPT,top,2022-12-09 06:18:39,Gaussian Processes for pirates. Courtesy of ChatGPT,Sid__darthVader,False,0.98,499,https://i.redd.it/4cs2kirjwu4a1.jpg,34,1670566719.0,
4,10eye8i,datascience,ChatGPT,top,2023-01-18 04:50:28,"I asked ChatGPT to explain ROC AUC, the level of collaboration is beyond my expectation",trantrikien239,False,0.9,479,https://master-data.science/assets/images/eli5ml-meth1.jpg,78,1674017428.0,
5,zev449,datascience,ChatGPT,top,2022-12-07 07:32:52,ChatGPT's response to Michael Bromley's question about humans,RunOrDieTrying,False,0.93,458,https://i.redd.it/1du2r7vaif4a1.jpg,49,1670398372.0,
6,123tx9p,datascience,ChatGPT,top,2023-03-27 17:25:43,Has ChatGPT killed doomers?,GreatStats4ItsCost,False,0.89,439,https://www.reddit.com/r/datascience/comments/123tx9p/has_chatgpt_killed_doomers/,90,1679937943.0,"Sorry for another ChatGPT post but I think it really is the end of asking whether certain job sectors will exist on r/DataScience due to ChatGPT making them redundant.

Whilst reading all of the 100's of doomer posts 'Will Data Science survive because ChatGPT' - it dawned on me that Chat GPT can replace all of the users creating these posts. They've all been made redundant. A simple prompt to an AI like 'Write a profoundly dumb Reddit post asking if Chat GPT has made Data Science redundant' - will return exactly that. With a simple workflow/pipeline the response from the API can be posted directly to r/DataScience. 

This really is the future and I'm worried."
7,zwppsu,datascience,ChatGPT,top,2022-12-27 20:48:02,ChatGPT Extension for Jupyter Notebooks: Personal Code Assistant,Tieskeman,False,0.98,420,https://www.reddit.com/r/datascience/comments/zwppsu/chatgpt_extension_for_jupyter_notebooks_personal/,32,1672174082.0,"Hi!

I want to share a [browser extension](https://github.com/TiesdeKok/chat-gpt-jupyter-extension) that I have been working on. This extension is designed to help programmers get assistance with their code directly from within their Jupyter Notebooks, through ChatGPT.

The extension can help with code formatting (e.g., auto-comments), it can explain code snippets or errors, or you can use it to generate code based on your instructions. It's like having a personal code assistant right at your fingertips!

I find it boosts my coding productivity, and I hope you find it useful too. Give it a try, and let me know what you think!

You can find an early version here: 
https://github.com/TiesdeKok/chat-gpt-jupyter-extension"
8,10a7kq4,datascience,ChatGPT,top,2023-01-12 19:01:24,I wrote up a guide showing how to do Data Science with ChatGPT.,Own-Anteater4164,False,0.83,276,https://www.reddit.com/r/datascience/comments/10a7kq4/i_wrote_up_a_guide_showing_how_to_do_data_science/,93,1673550084.0,"Just recently, I wrote up a guide on how to use [ChatGPT to build a website with Replit](https://buildspace.so/notes/chatgpt-replit-website?utm_source=r).

Got some pretty good responses, so I decided to write + document more of the applications I'm discovering.

**I'm actually really excited about this one, since I was in a graduate program for statistics.**

[Here's the guide](https://buildspace.so/notes/chatgpt-data-science?utm_source=r) for doing data sci with ChatGPT

The tl;dr is that I show you some of the crazy data sci stuff ChatGPT can do:

\- Read and analyze raw CSV data. I just had to copy and paste.

\- It could tell what kind of data you're feeding it judging by the header columns!

\- It will give you the python/r code on how to run specific analysis.

\- It even knew how to use scikit-learn to run regression models ü§Ø (I mean, this makes sense since it's an AI tool lol).

Honestly, this is just crazy to me.

**Before I dropped out of graduate school for statistics, I often consulted non-technical researchers in the social sciences. It was always a pain for them to run datasets by themselves just to get some answers to their questions.**

Although ChatGPT isn't perfect (and does make mistakes), it's crazy where the tool is going.

I think this is really good news for a lot of people who are interested in doing research, but might feel too intimidated by needing to do stats. Obvi...some bad stuff could come from it. We'll see!

https://preview.redd.it/ggd96gyhnnba1.png?width=619&format=png&auto=webp&s=5aa2f39199bb0ce56518e2972e0ec8a36ccbb69d"
9,zejzzs,datascience,ChatGPT,top,2022-12-06 22:21:47,Chat_GPT,WeirdDiscipline1862,False,0.92,272,https://www.reddit.com/r/datascience/comments/zejzzs/chat_gpt/,136,1670365307.0,"This weekend millions of people rushed to check the Chat_GPT. This fueled many discussions regarding the job security of the future. People like Paul Krugman started talking about the future of job and massive job loss as the result of the AI which will be disruptive of course. And this time unless previously that the job loss was happening in the low skilled job categories, it will happen to the skilled workers. Any thoughts about what to do and how to persuade a new job specially after knowing that data analysis related jobs will be very vulnerable to AI technologies. 

‚ÄúIt's true that as AI and machine learning technologies continue to advance, they are likely to have an impact on many different fields, including data science. However, it's important to remember that while AI may automate some tasks and make certain job roles obsolete, it is also likely to create new job opportunities in areas such as AI research, development, and implementation.

In terms of what job you should pursue in the future, it's difficult to say for certain. The best thing to do is to stay up-to-date on the latest developments in AI and machine learning, and consider pursuing education and training in these areas. This will give you the skills and knowledge you need to adapt to the changing job market and take advantage of the new opportunities that are likely to arise.

It's also important to remember that there will always be a need for human expertise and creativity in many fields, including data science. So, even as AI continues to advance, there will likely still be plenty of opportunities for skilled data scientists who are able to think critically, solve complex problems, and apply their expertise to new challenges.‚Äù


This is the Chat_GPT‚Äôs answer to what to do as data scientist question. üòÄ"
10,12vl384,datascience,ChatGPT,top,2023-04-22 22:04:04,Found this on an analyst position job ad on LinkedIn. Do you think the shade is reasonable?,BiggusCinnamusRollus,False,0.98,253,https://i.redd.it/cxcftudodiva1.png,64,1682201044.0,
11,125fd6p,datascience,ChatGPT,top,2023-03-29 06:33:08,[D] Very good article about the current limitations of GPT-n models,fripperML,False,0.98,236,https://www.reddit.com/r/datascience/comments/125fd6p/d_very_good_article_about_the_current_limitations/,95,1680071588.0,"I count myself among the people that are amazed of what those models can do and how they can impact our society.

However, it's very important to understand that they are not magical solutions for every problem and that they cannot reason at all.

[ChatGPT as a query engine on a giant corpus of text ‚Äì r y x, r (ryxcommar.com)](https://ryxcommar.com/2023/03/28/chatgpt-as-a-query-engine-on-a-giant-corpus-of-text/)

What is more impressing is that, given this mental model of ChatGPT as a giant query engine, how can it perform activities that involve creativity outside of his training data? Like, for example, writing a poem in the style of Shakespeare about the proof that there are infinite prime numbers? Surely there are no examples of that in the training data! My answer would be that for some tasks interpolation works well (you can somehow get something meaningful by interpolating known stylistic elements and known semantical elements into something ""new""). But when the task is more symbolic or discrete, instead of interpolative, like true reasoning, and there are no examples to retrieve an answer from, the system has a much harder time.

That is, I am alligned with F. Chollet views on this:

[Fran√ßois Chollet en Twitter: ""You can retrieve not just what was seen at training time, but arbitrary combinations of it. It's an interpolative database and program store, with a natural language interface. https://t.co/2mv2gnI3oM"" / Twitter](https://twitter.com/fchollet/status/1637122108357738496)

[Fran√ßois Chollet en Twitter: ""This paper has the right idea: use symbolic logic for discrete reasoning and lean on deep learning models for perception and common-sense intuition. https://t.co/9lP8eDZKkO I expect to see a lot more progress along these lines in the coming months / years."" / Twitter](https://twitter.com/fchollet/status/1636838039703126016)"
12,1162ssq,datascience,ChatGPT,top,2023-02-19 05:43:37,Buzz around new Deep Learning Models and Incorrect Usage of them.,brokened00,False,0.94,188,https://www.reddit.com/r/datascience/comments/1162ssq/buzz_around_new_deep_learning_models_and/,100,1676785417.0," In my job as a data scientist, I use deep learning models regularly to classify a lot of textual data (mostly transformer models like BERT finetuned for the needs of the company). Sentiment analysis and topic classification are the two most common natural language processing tasks that I perform, or rather, that is performed downstream in a pipeline that I am building for a company. 

The other day someone high up (with no technical knowledge) was telling me, during a meeting, that we should be harnessing the power of ChatGPT to perform sentiment analysis and do other various data analysis tasks, noting that it should be a particularly powerful tool to analyze large volumes of data coming in (both in sentiment analysis and in querying and summarizing data tables). I mentioned that the tools we are currently using are more specialized for our analysis needs than this chat bot. They pushed back, insisting that ChatGPT is the way to go for data analysis and that I'm not doing my due diligence. I feel that AI becoming a topic of mainstream interest is emboldening people to speak confidently on it when they have no education or experience in the field. 

After just a few minutes playing around with ChatGPT, I was able to get it to give me a wrong answer to a VERY EASY question (see below for the transcript). It spoke so confidently in it's answer, even going as far as to provide a formula, which it basically abandoned in practice. Then, when I pointed out it's mistake, it corrected the answer to another wrong one. 

The point of this long post was to point out that AI tool have their uses, but they should not be given the benefit of the doubt in every scenario, simply due to hype. If a model is to be used for a specific task, it should be rigorously tested and benchmarked before replacing more thoroughly proven methods.

ChatGPT is a really promising chat bot and it can definitely seem knowledgeable about a wide range of topics, since it was trained on basically the entire internet, but I wouldn't trust it to do something that  a simple pandas query could accomplish. Nor would I use it to perform sentiment analysis when there are a million other transformer models that were specifically trained to predict sentiment labels and were rigorously evaluated on industry standard benchmarks (like GLUE).

https://preview.redd.it/sz3ejc1313ja1.png?width=1700&format=png&auto=webp&s=76c48939903f8d34810000d1a71cb25f86237130"
13,11l5jqm,datascience,ChatGPT,top,2023-03-07 17:31:31,"My AI tool to writes SQL queries for me now, so I don't have to. Thoughts?",slingshoota,False,0.89,126,https://www.reddit.com/r/datascience/comments/11l5jqm/my_ai_tool_to_writes_sql_queries_for_me_now_so_i/,60,1678210291.0,"I often write SQL queries for my Data Science job, but it can be really tedious and time-consuming. First I have to think about how to even approach the query, and then I have to google stuff to fix issues and refresh my memory.

I started using ChatGPT for help, but it was annoying to have to explain the tables/views every time.

To fix this, I built a tool that remembers your whole schema. It gives you a query to extract all the necessary info in one go and then you just copy-paste it once (it's saved with encryption). Then, all you have to do is write what you need in plain English, Ex. ""Users who have been online over 5 days this week"", and it writes the SQL query for you.

I showed it to my colleagues and they went crazy and are obsessed with it, as are my ex-colleagues from my last company.

What do you think? Would love to get your feedback. It's 100% free, you couldn't pay me even if you wanted to: www.blazesql.com"
14,10a1mik,datascience,ChatGPT,top,2023-01-12 14:59:04,New Research From Google Shines Light On The Future Of Language Models ‚≠ï,LesleyFair,False,0.84,122,https://www.reddit.com/r/datascience/comments/10a1mik/new_research_from_google_shines_light_on_the/,18,1673535544.0,"Last year, large language models (LLM) have broken record after record. ChatGPT got to 1 million users faster than Facebook, Spotify, and Instagram did. They helped create [billion-dollar companies](https://www.marketsgermany.com/translation-tool-deepl-is-now-a-unicorn/#:~:text=Cologne%2Dbased%20artificial%20neural%20network,sources%20close%20to%20the%20company), and most notably they helped us recognize the [divine nature of ducks](https://twitter.com/drnelk/status/1598048054724423681?t=LWzI2RdbSO0CcY9zuJ-4lQ&s=08).

2023 has started and ML progress is likely to continue at a break-neck speed. This is a great time to take a look at one of the most interesting papers from last year.

Emergent Abilities in LLMs

In a recent [paper from Google Brain](https://arxiv.org/pdf/2206.07682.pdf), Jason Wei and his colleagues allowed us a peak into the future. This beautiful research showed how scaling LLMs will allow them, among other things, to:

* Become better at math
* Understand even more subtleties of human language
* Stop hallucinating and answer truthfully
* ...

(See the plot on break-out performance below for a full list)

**Some Context:**

If you played around with ChatGPT or any of the other LLMs, you will likely have been as impressed as I was. However, you have probably also seen the models go off the rails here and there. The model might hallucinate gibberish, give untrue answers, or fail at performing math.

**Why does this happen?**

LLMs are commonly trained by [maximizing the likelihood](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf) over all tokens in a body of text. Put more simply, they learn to predict the next word in a sequence of words.

Hence, if such a model learns to do any math at all, it learns it by figuring concepts present in human language (and thereby math).

Let's look at the following sentence.

""The sum of two plus two is ...""

The model figures out that the most likely missing word is ""four"".

The fact that LLMs learn this at all is mind-bending to me! However, once the math gets more complicated [LLMs begin to struggle](https://twitter.com/Richvn/status/1598714487711756288?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1598714487711756288%7Ctwgr%5E478ce47357ad71a72873d1a482af5e5ff73d228f%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fanalyticsindiamag.com%2Ffreaky-chatgpt-fails-that-caught-our-eyes%2F).

There are many other cases where the models fail to capture the elaborate interactions and meanings behind words. One other example are words that change their meaning with context. When the model encounters the word ""bed"", it needs to figure out from the context, if the text is talking about a ""river bed"" or a ""bed"" to sleep in.

**What they discovered:**

For smaller models, the performance on the challenging tasks outline above remains approximately random. However, the performance shoots up once a certain number of training FLOPs (proxy for model size) is reached.

The figure below visualizes this effect on eight benchmarks. The critical number of training FLOPs is around 10\^23. The big version of GPT-3 already lies to the right of this point, but we seem to be at the beginning stages of performance increases.

&#x200B;

[Break-Out Performance At Critical Scale](https://preview.redd.it/w7xffqjimmba1.png?width=800&format=png&auto=webp&s=e2d9cb63f750efcbfa45c4bb7a985d4dcb5b0319)

They observed similar improvements on (few-shot) prompting strategies, such as multi-step reasoning and instruction following. If you are interested, I also encourage you to check out Jason Wei's personal blog. There he [listed a total of 137](https://www.jasonwei.net/blog/emergence) emergent abilities observable in LLMs.

Looking at the results, one could be forgiven for thinking: simply making models bigger will make them more powerful. That would only be half the story.

(Language) models are primarily scaled along three dimensions: number of parameters, amount of training compute, and dataset size. Hence, emergent abilities are likely to also occur with e.g. bigger and/or cleaner datasets.

There is [other research](https://arxiv.org/abs/2203.15556) suggesting that current models, such as GPT-3, are undertrained. Therefore, scaling datasets promises to boost performance in the near-term, without using more parameters.

**So what does this mean exactly?**

This beautiful paper shines a light on the fact that our understanding of how to train these large models is still very limited. The lack of understanding is largely due to the sheer cost of training LLMs. Running the same number of experiments as people do for smaller models would cost in the hundreds of millions.

However, the results strongly hint that further scaling will continue the exhilarating performance gains of the last years.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you.  
At **TheDecoding** ‚≠ï, I send out a thoughtful newsletter about ML research and the data economy once a week.  
No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)"
15,122nwrk,datascience,ChatGPT,top,2023-03-26 14:31:39,I asked ChatGPT for the best random state value,liquidInkRocks,False,0.89,96,https://www.reddit.com/r/datascience/comments/122nwrk/i_asked_chatgpt_for_the_best_random_state_value/,36,1679841099.0,"This thing is like a student forced to write 1000 words on the topic. 

**me:**  What is a good random state value to use in general 

**Bot:**  

In machine learning, a random state is used to initialize the random number generator. The random number generator is used to shuffle the data, split the data into training and test sets, initialize the parameters of the model, and make other random decisions during training and evaluation.

Choosing a good random state value is important because it can affect the results of your model. If you use a different random state, you may get different results.

In general, there is no one ""best"" random state value to use. The value you choose depends on the specific problem you're working on and the specific data you're working with.

However, it's a good practice to set a random state to ensure reproducibility of your results. You can choose any integer value for the random state, but it's common to use numbers like 0, 42, or 2022.

It's also common to use cross-validation techniques like k-fold cross-validation, which helps to reduce the variability of your results due to different random state values."
16,zcgpbp,datascience,ChatGPT,top,2022-12-04 18:05:07,What do you guys think of OpenAI‚Äôs ChatGPT?,Loud_Ad_6272,False,0.95,56,https://www.reddit.com/r/datascience/comments/zcgpbp/what_do_you_guys_think_of_openais_chatgpt/,77,1670177107.0,"As the title goes, what do you guys think of this and what effect do you think it would have on the discipline and field going forward?"
17,11lt96v,datascience,ChatGPT,top,2023-03-08 10:51:40,[Q] Are you wary of using ChatGPT because of sensitive data concerns?,limedove,False,0.83,33,https://www.reddit.com/r/datascience/comments/11lt96v/q_are_you_wary_of_using_chatgpt_because_of/,37,1678272700.0,
18,11szca1,datascience,ChatGPT,top,2023-03-16 16:45:29,"What is your digital workspace, tools, setup, etc. for ETL, research, production?",BreathAether,False,0.92,35,https://www.reddit.com/r/datascience/comments/11szca1/what_is_your_digital_workspace_tools_setup_etc/,16,1678985129.0,"I'm new to this and so I've been wanting to know what other people have been using to make their work feel as smooth as butter. Since I've been learning lots and not just the industry standard stuff, I wanted to share what little I found to be valuable which others may want to try. **The main goal of this post is to share, critique, and provide suggestions so that we can all find the setup we like most. I  am also looking for new, up and coming tech, and definitely not afraid to try new things!**

IDE: **VSCode with the Jupyter Notebook Extension**. What I like about it is that I can view data structures like series/dataframes in a table format by clicking the variable in the Jupyter: Variables pane at the bottom. I started with plain vanilla jupyter notebooks from Anaconda so this was pretty nice. I have seen demos that **Jupyter Lab** has something like this, so if anyone has used both VSCode's notebooks and used Lab, your input would be appreciated. I hear good things about **PyCharm and Spyder**. Some people also use **Google Collab, DataSpell, and DeepNote** but I don't know enough about it. I did play around with DeepNote, and it was very cool but I didn't feel compelled to switch (and you have to pay for it!). 

Tools:

* A code helper: A few months back I was googling everything and I would've listed **Stackoverflow**. I might actually use that occasionally, but these days I use **ChatGPT** and **Bing AI**. For more current info or news-based I'll use Bing AI since it uses live search results, and for information that is knowledge based I might use ChatGPT. ChatGPT saves conversations so it's great for exploring topics in depth and referencing that conversation later. For those who have used both, maybe you know what I'm talking about and can provide a better explanation as to which is better for what purpose.
* Software: **Excel** is an obvious one. For instance, if I have a huge dataset and I just want to delete out columns that I don't need with Ctrl+click to select, it's easier and quicker than copy + pasting or typing out each of the string column names I want to ""df.drop()"". Excel is great for quick and simple stuff. Some software I have been learning about are I guess what I would consider as no- or low-code data analytics platforms, such as **Alteryx, KNIME, and Orange**. These software let you practically run an entire ETL pipeline. I believe Alteryx and KNIME are the gold-standard in this category, and Orange is a ""lite"" version of the two and is available in Anaconda. I think these are pretty cool, and I personally haven't found a huge use case for them since I've been chugging away in my notebooks with Python, but I can see the value. Would love for someone to chime in on these tools and how they compare to manually doing stuff in code, especially for large datasets.
* Version Control: This is where I'm primarily lacking, but I know that **Github** is the go-to. I don't use this but I know that a ton of people do. I don't even know where to start to be honest. I usually just create a new .ipynb file for each analysis or phase of an ETL pipeline haha. I'm also not too aware of what other innovative tools for version control exist.
* Python Libraries: Besides the obvious stuff like Pandas/NumPy, MatplotLib/Seaborn, and your popular ML libraries, I've recently found out about this library called **Polars**. It's basically a Rust version of Pandas, and it's super powerful. Some operations that I've run, that would've taken hours with Pandas, took me minutes. But I've been hearing that **Pandas 2.0** which will be released some time this month, has been looking at using PyArrow dtypes (if I recall correctly) and the speed is comparable to Polars. I mean these two are FAST. Another contender is **DuckDB** but I think the new Pandas and Polars are still faster. I mostly use Pandas but if there is some heavy lifting, I'll swap the dataframe to a polars one with a quick function, run it with polars, then back to pandas.

Anyway, that's just some things I can immediately think of. Looking forward to your suggestions! Bonus points for anything new and innovative. Cheers.

https://preview.redd.it/qj2cywt1r4oa1.png?width=1920&format=png&auto=webp&s=c4e02f5fec0b3768df336c7a3f63cc382b3954a8"
19,117736x,datascience,ChatGPT,top,2023-02-20 13:47:54,Is NLP a sub-field with a lot of growth?,sonicking12,False,0.79,34,https://www.reddit.com/r/datascience/comments/117736x/is_nlp_a_subfield_with_a_lot_of_growth/,35,1676900874.0,I am thinking about how Amazon reportedly axed a lot of Alexa teams.  This seems to point to negative.  But ChatGPT is taking up a lot of interest. This seems to point to positive.   What are your thoughts?
20,130hqft,datascience,ChatGPT,top,2023-04-27 10:53:05,Low hanging fruit projects for business with non-mature data science/analytics?,BobzzYourUncle,False,0.87,31,https://www.reddit.com/r/datascience/comments/130hqft/low_hanging_fruit_projects_for_business_with/,23,1682592785.0,"Hey data legends,

I've just started to learn a bit of Python and it's got me going down the rabbit hole of possible business applications for data analysis/science in this small/medium business (B2B with typically only a couple of transactions per customer each year).  What's currently done is very basic stuff in excel and no machine learning etc. (I have no background in data science other than basic knowledge but I feel there is a lot of potential)

I've managed to automate a PDF report that has some basic stuff using Plotly and Pandas and am wondering where I should focus my efforts next.

What are the general low hanging fruits that I should try and start out with for a business that has very little maturity on this front?

Chat GPT has come back with some suggestions like: Customer segmentation, Churn analysis, sales forecasting, website optimisation, recommendation engines, predictive CLV.  

Any help or insights would be appreciated pointing me in the right direction.  Thanks"
21,126ndlu,datascience,ChatGPT,top,2023-03-30 13:41:51,Seeing a lot of job openings for high-level AI and Data Analytics positions...,fingin,False,0.78,26,https://www.reddit.com/r/datascience/comments/126ndlu/seeing_a_lot_of_job_openings_for_highlevel_ai_and/,20,1680183711.0,"I have noticed an uptick in jobs for things like prompt engineer, AI ethics lead, AI manager. When you look at these requirements it looks like relatively low entry: a familiarity with general AI and AI regulations (not that there is a ton of expertise to be had in this latter category). They don't require much or any technical skill. 

I'll admit, I find myself frustrated as I work in a highly technical role and feel like these opportunities are really 'low hanging fruit', due to the vagueness of the requirements. I'm sure many of us wear not just technical hats but also those of product management, coaching and training, etc. 

What do you think? Is it just a fad stemming from ChatGPT and Image gen promotion? Are you going to make a job switch and apply for these roles?"
22,zmye7g,datascience,ChatGPT,top,2022-12-15 22:34:22,Have you used ChatGPT to write code for you?,is_this_the_place,False,0.79,24,https://www.reddit.com/r/datascience/comments/zmye7g/have_you_used_chatgpt_to_write_code_for_you/,33,1671143662.0,Is so what did you ask and how did it go?
23,10mi1x8,datascience,ChatGPT,top,2023-01-27 10:52:18,‚≠ï What People Are Missing About Microsoft‚Äôs $10B Investment In OpenAI,LesleyFair,False,0.76,18,https://www.reddit.com/r/datascience/comments/10mi1x8/what_people_are_missing_about_microsofts_10b/,3,1674816738.0,"&#x200B;

[Sam Altman Might Have Just Pulled Off The Coup Of The Decade](https://preview.redd.it/35vtxrwnekea1.png?width=720&format=png&auto=webp&s=a61dd557e1d00c96448c429c9f9bb78516205a6f)

Microsoft is investing $10B into OpenAI!

There is lots of frustration in the community about OpenAI not being all that open anymore. They appear to abandon their ethos of developing AI for everyone, [free](https://openai.com/blog/introducing-openai/) of economic pressures.

The fear is that OpenAI‚Äôs models are going to become fancy MS Office plugins. Gone would be the days of open research and innovation.

However, the specifics of the deal tell a different story.

To understand what is going on, we need to peek behind the curtain of the tough business of machine learning. We will find that Sam Altman might have just orchestrated the coup of the decade!

To appreciate better why there is some three-dimensional chess going on, let‚Äôs first look at Sam Altman‚Äôs backstory.

*Let‚Äôs go!*

# A Stellar Rise

Back in 2005, Sam Altman founded [Loopt](https://en.wikipedia.org/wiki/Loopt) and was part of the first-ever YC batch. He raised a total of $30M in funding, but the company failed to gain traction. Seven years into the business Loopt was basically dead in the water and had to be shut down.

Instead of caving, he managed to sell his startup for $[43M](https://golden.com/wiki/Sam_Altman-J5GKK5) to the finTech company [Green Dot](https://www.greendot.com/). Investors got their money back and he personally made $5M from the sale.

By YC standards, this was a pretty unimpressive outcome.

However, people took note that the fire between his ears was burning hotter than that of most people. So hot in fact that Paul Graham included him in his 2009 [essay](http://www.paulgraham.com/5founders.html?viewfullsite=1) about the five founders who influenced him the most.

He listed young Sam Altman next to Steve Jobs, Larry & Sergey from Google, and Paul Buchheit (creator of GMail and AdSense). He went on to describe him as a strategic mastermind whose sheer force of will was going to get him whatever he wanted.

And Sam Altman played his hand well!

He parleyed his new connections into raising $21M from Peter Thiel and others to start investing. Within four years he 10x-ed the money \[2\]. In addition, Paul Graham made him his successor as president of YC in 2014.

Within one decade of selling his first startup for $5M, he grew his net worth to a mind-bending $250M and rose to the circle of the most influential people in Silicon Valley.

Today, he is the CEO of OpenAI ‚Äî one of the most exciting and impactful organizations in all of tech.

However, OpenAI ‚Äî the rocket ship of AI innovation ‚Äî is in dire straights.

# OpenAI is Bleeding Cash

Back in 2015, OpenAI was kickstarted with $1B in donations from famous donors such as Elon Musk.

That money is long gone.

In 2022 OpenAI is projecting a revenue of $36M. At the same time, they spent roughly $544M. Hence the company has lost >$500M over the last year alone.

This is probably not an outlier year. OpenAI is headquartered in San Francisco and has a stable of 375 employees of mostly machine learning rockstars. Hence, salaries alone probably come out to be roughly $200M p.a.

In addition to high salaries their compute costs are stupendous. Considering it cost them $4.6M to train GPT3 once, it is likely that their cloud bill is in a very healthy nine-figure range as well \[4\].

So, where does this leave them today?

Before the Microsoft investment of $10B, OpenAI had received a total of $4B over its lifetime. With $4B in funding, a burn rate of $0.5B, and eight years of company history it doesn‚Äôt take a genius to figure out that they are running low on cash.

It would be reasonable to think: OpenAI is sitting on ChatGPT and other great models. Can‚Äôt they just lease them and make a killing?

Yes and no. OpenAI is projecting a revenue of $1B for 2024. However, it is unlikely that they could pull this off without significantly increasing their costs as well.

*Here are some reasons why!*

# The Tough Business Of Machine Learning

Machine learning companies are distinct from regular software companies. On the outside they look and feel similar: people are creating products using code, but on the inside things can be very different.

To start off, machine learning companies are usually way less profitable. Their gross margins land in the 50%-60% range, much lower than those of SaaS businesses, which can be as high as 80% \[7\].

On the one hand, the massive compute requirements and thorny data management problems drive up costs.

On the other hand, the work itself can sometimes resemble consulting more than it resembles software engineering. Everyone who has worked in the field knows that training models requires deep domain knowledge and loads of manual work on data.

To illustrate the latter point, imagine the unspeakable complexity of performing content moderation on ChatGPT‚Äôs outputs. If OpenAI scales the usage of GPT in production, they will need large teams of moderators to filter and label hate speech, slurs, tutorials on killing people, you name it.

*Alright, alright, alright! Machine learning is hard.*

*OpenAI already has ChatGPT working. That‚Äôs gotta be worth something?*

# Foundation Models Might Become Commodities:

In order to monetize GPT or any of their other models, OpenAI can go two different routes.

First, they could pick one or more verticals and sell directly to consumers. They could for example become the ultimate copywriting tool and blow [Jasper](https://app.convertkit.com/campaigns/10748016/jasper.ai) or [copy.ai](https://app.convertkit.com/campaigns/10748016/copy.ai) out of the water.

This is not going to happen. Reasons for it include:

1. To support their mission of building competitive foundational AI tools, and their huge(!) burn rate, they would need to capture one or more very large verticals.
2. They fundamentally need to re-brand themselves and diverge from their original mission. This would likely scare most of the talent away.
3. They would need to build out sales and marketing teams. Such a step would fundamentally change their culture and would inevitably dilute their focus on research.

The second option OpenAI has is to keep doing what they are doing and monetize access to their models via API. Introducing a [pro version](https://www.searchenginejournal.com/openai-chatgpt-professional/476244/) of ChatGPT is a step in this direction.

This approach has its own challenges. Models like GPT do have a defensible moat. They are just large transformer models trained on very large open-source datasets.

As an example, last week Andrej Karpathy released a [video](https://www.youtube.com/watch?v=kCc8FmEb1nY) of him coding up a version of GPT in an afternoon. Nothing could stop e.g. Google, StabilityAI, or HuggingFace from open-sourcing their own GPT.

As a result GPT inference would become a common good. This would melt OpenAI‚Äôs profits down to a tiny bit of nothing.

In this scenario, they would also have a very hard time leveraging their branding to generate returns. Since companies that integrate with OpenAI‚Äôs API control the interface to the customer, they would likely end up capturing all of the value.

An argument can be made that this is a general problem of foundation models. Their high fixed costs and lack of differentiation could end up making them akin to the [steel industry](https://www.thediff.co/archive/is-the-business-of-ai-more-like-steel-or-vba/).

To sum it up:

* They don‚Äôt have a way to sustainably monetize their models.
* They do not want and probably should not build up internal sales and marketing teams to capture verticals
* They need a lot of money to keep funding their research without getting bogged down by details of specific product development

*So, what should they do?*

# The Microsoft Deal

OpenAI and Microsoft [announced](https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/) the extension of their partnership with a $10B investment, on Monday.

At this point, Microsoft will have invested a total of $13B in OpenAI. Moreover, new VCs are in on the deal by buying up shares of employees that want to take some chips off the table.

However, the astounding size is not the only extraordinary thing about this deal.

First off, the ownership will be split across three groups. Microsoft will hold 49%, VCs another 49%, and the OpenAI foundation will control the remaining 2% of shares.

If OpenAI starts making money, the profits are distributed differently across four stages:

1. First, early investors (probably Khosla Ventures and Reid Hoffman‚Äôs foundation) get their money back with interest.
2. After that Microsoft is entitled to 75% of profits until the $13B of funding is repaid
3. When the initial funding is repaid, Microsoft and the remaining VCs each get 49% of profits. This continues until another $92B and $150B are paid out to Microsoft and the VCs, respectively.
4. Once the aforementioned money is paid to investors, 100% of shares return to the foundation, which regains total control over the company. \[3\]

# What This Means

This is absolutely crazy!

OpenAI managed to solve all of its problems at once. They raised a boatload of money and have access to all the compute they need.

On top of that, they solved their distribution problem. They now have access to Microsoft‚Äôs sales teams and their models will be integrated into MS Office products.

Microsoft also benefits heavily. They can play at the forefront AI, brush up their tools, and have OpenAI as an exclusive partner to further compete in a [bitter cloud war](https://www.projectpro.io/article/aws-vs-azure-who-is-the-big-winner-in-the-cloud-war/401) against AWS.

The synergies do not stop there.

OpenAI as well as GitHub (aubsidiary of Microsoft) e. g. will likely benefit heavily from the partnership as they continue to develop[ GitHub Copilot](https://github.com/features/copilot).

The deal creates a beautiful win-win situation, but that is not even the best part.

Sam Altman and his team at OpenAI essentially managed to place a giant hedge. If OpenAI does not manage to create anything meaningful or we enter a new AI winter, Microsoft will have paid for the party.

However, if OpenAI creates something in the direction of AGI ‚Äî whatever that looks like ‚Äî the value of it will likely be huge.

In that case, OpenAI will quickly repay the dept to Microsoft and the foundation will control 100% of whatever was created.

*Wow!*

Whether you agree with the path OpenAI has chosen or would have preferred them to stay donation-based, you have to give it to them.

*This deal is an absolute power move!*

I look forward to the future. Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

*Thank you for reading!*

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ‚≠ï.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] [https://golden.com/wiki/Sam\_Altman-J5GKK5](https://golden.com/wiki/Sam_Altman-J5GKK5)‚Äã

\[2\] [https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny](https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny)‚Äã

\[3\] [Article in Fortune magazine ](https://fortune.com/2023/01/11/structure-openai-investment-microsoft/?verification_code=DOVCVS8LIFQZOB&_ptid=%7Bkpdx%7DAAAA13NXUgHygQoKY2ZRajJmTTN6ahIQbGQ2NWZsMnMyd3loeGtvehoMRVhGQlkxN1QzMFZDIiUxODA3cnJvMGMwLTAwMDAzMWVsMzhrZzIxc2M4YjB0bmZ0Zmc0KhhzaG93T2ZmZXJXRDFSRzY0WjdXRTkxMDkwAToMT1RVVzUzRkE5UlA2Qg1PVFZLVlpGUkVaTVlNUhJ2LYIA8DIzZW55eGJhajZsWiYyYTAxOmMyMzo2NDE4OjkxMDA6NjBiYjo1NWYyOmUyMTU6NjMyZmIDZG1jaOPAtZ4GcBl4DA)‚Äã

\[4\] [https://arxiv.org/abs/2104.04473](https://arxiv.org/abs/2104.04473) Megatron NLG

\[5\] [https://www.crunchbase.com/organization/openai/company\_financials](https://www.crunchbase.com/organization/openai/company_financials)‚Äã

\[6\] Elon Musk donation [https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research](https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research)‚Äã

\[7\] [https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/](https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/)"
24,zcmlp0,datascience,ChatGPT,top,2022-12-04 21:39:24,Unofficial Python SDK for OpenAI's ChatGPT,brunneis,False,0.86,14,https://github.com/labteral/chatgpt-python,1,1670189964.0,
25,1360alu,datascience,ChatGPT,top,2023-05-02 21:06:32,How busy are you? Under/over utilization,MorningDarkMountain,False,0.84,17,https://www.reddit.com/r/datascience/comments/1360alu/how_busy_are_you_underover_utilization/,13,1683061592.0,"As simple as the title: I hear more and more often about Data Scientists feeling themselves to be under-utilized. Lack of projects, no real impact on the business, fear of being replaced by ChatGPT, stakeholders that do not really understand Data Science at all.

Are you currently under-utilized as well?"
26,10iue4e,datascience,ChatGPT,top,2023-01-22 21:12:11,"I wrote a tiny library this morning for openai's (suddenly really good, really cheap) embeddings to search stuff - Semantic search, smarter replies w/ GPT-3, easier.",morganpartee,False,0.77,11,https://www.sensibledefaults.io/blog/chatgpt/easy-python-embeddings,14,1674421931.0,"I've had a few buddies in the community ask about something like this in the last week, and then a reader did today so I finally took the time to write it up. It's basically a generic interface to try embeddings, and it's less than a hundred lines of code. Built this so you can just authenticate and test without having to fuss with numpy, pinecone, etc.

The only thing you do is put dictionaries with a name and text key, then search your embeddings instance. We return anything you stick in there with it too for your programming pleasure - think dates, page numbers, file names, whatever.

You can just... Build chat bots that are pretty smart like this for next to nothing by reading in your docs or whatever. It's cheap and incredibly effective. I know next to nothing about how to preprocess data for this thing, I've tried different sizes of chunks, lines, sentences and haven't found a one size fits all solution (other than more gpt to summarize) but - just try it, it's cheap as hell and there's so much you can do. Like the rest of the current state of gpt - it just kinda works. Start with one to five sentences (or lines for code) and experiment!

For you proper data scientists (nerds!) - you can just get the numpy array out and do regular embeddings stuff with it. If you do, I'd love to hear about it! Clustering, classification, etc are suddenly super easy, and the raw data is stored in json so you can upload it to something better when you're ready.

I know it's small, but little abstractions make life better. Anything we can do to lower the barrier to experimentation is worth doing. Hope it helps someone!"
27,13a4wtf,datascience,ChatGPT,top,2023-05-06 22:52:26,"ChatGPT Code Interpreter customer segmentation workflow demo: Data description, feature selection, preprocessing, clustering, fine-tuning, interpretation and market strategy (5:12 video)",datasciencepro,False,0.73,11,https://twitter.com/aakashg0/status/1654703707869822976/video/1,3,1683413546.0,
28,118ybon,datascience,ChatGPT,top,2023-02-22 13:15:21,Overview of state-of-art algorithms in their respective usecase?,Different_Day_3821,False,0.78,10,https://www.reddit.com/r/datascience/comments/118ybon/overview_of_stateofart_algorithms_in_their/,12,1677071721.0,"Fellow scientists... On the second year of data science i've become increasingly confused as to when, what and why to use certain algorithms... Specially in a field as rapidly developing as ours.

therefore i ask you if any of you got an overview of what the current best algorithms is according to their uses? Is there a systemisc ""cheat-sheet"" or overview of the current best libraries to import for X types of data and analysis?

For example learning NLP. First you learn Bag of Word models, then IDF-TF models. Then you learn thats outdated and people use Word2Vec models that retain semantic meaning. Then you learn thats outdated and that people use Bert models. But now even that in competition with transformer-based models as ChatGPT is based on etc.

Same thing with time series. First you like ARIMA, then you learn RNN, then LSTM, then Autoencoders, then to use autoencoders as unsupervised feature extraction into a supervised model etc.

And the more complicated you modern you get, the more specific becomes that imported libraries. Anomaly detection? Go PyOD/Prophet/PySAD etc.

How do you guys navigate in this? Is there some conversative principles that would keep your methods within some kind of boundary of usefullnes? I miss the old days of only knowing basic sklearn and basic naive bayes and clustering algorithms lol. On the otherhand if state of the art just means importing and fitting the right algorithm then i guess it ain't so bad.

tl;dr: Is there a cheat-sheet of X-kind of analsis then Y-kind of algorithm performs best? And how do you guys manage all the libraries/algorithms?"
29,12oiyni,datascience,ChatGPT,top,2023-04-16 17:57:00,Challenge: Use data science to predict ChatGPT failures,Neurosymbolic,False,0.7,10,https://www.reddit.com/r/datascience/comments/12oiyni/challenge_use_data_science_to_predict_chatgpt/,2,1681667820.0,"Last month, at the AAAI-MAKE conference, we introduced a new challenge problem: predict the failures of ChatGPT when solving math problems.

We have compiled a dataset (based on DRAW-1K) that consists of 1,000 math problem and ChatGPT's response.  We introduced some baseline models at AAAI-MAKE that showed you can predict ChatGPT's failures, we are asking the community to improve on the results.  No need to write a ChatGPT app or anything like that - you can use pure data science techniques.

The challenge results will be due in early 2024 and presented at AAAI-MAKE next year.  You can pre-register here: [https://www.aaai-make.info/next/](https://www.aaai-make.info/next/)

To learn more about the challenge, visit this website: [https://neurosymbolic.asu.edu/chatgpt-mwp-challenge/](https://neurosymbolic.asu.edu/chatgpt-mwp-challenge/)"
30,13ai0wp,datascience,ChatGPT,top,2023-05-07 08:54:50,What are your thoughts on the LLM fever going on right now?,Samirio,False,0.78,10,https://www.reddit.com/r/datascience/comments/13ai0wp/what_are_your_thoughts_on_the_llm_fever_going_on/,36,1683449690.0,"The hype is strong with this one, but do you think it is justified? 

Do you think that this will actually change our day to day in ways other than using chatgpt or other LLMs as personal assistants?

I look around and see people left and right reaching out for creating applications using LLMs, but so far I didn‚Äôt see anything other than feeding documents to an LLM and having it summarize them, which doesn‚Äôt seem that ground breaking to me.

What are your thoughts on this topic?

Edit: I understand that I have over simplified my view of LLMs just ‚Äúsummarizing‚Äù text, when instead I should be asking something like, do you think LLMs are being effective now in the way they are being hyped for?"
31,123yr9p,datascience,ChatGPT,top,2023-03-27 20:09:45,ChatGPT and made up citations,its_the_llama,False,0.67,6,https://www.reddit.com/r/datascience/comments/123yr9p/chatgpt_and_made_up_citations/,10,1679947785.0,"Hopefully this hasn't been posted here before. I was using ChatGPT to try and find a few reviews to read on parameter search strategies in system biology. Helpfully, it returned a list of seminal papers: 

 

1. ""Parameter estimation and inference for differential equations"" by P.J. Haario et al. (2006). This review article discusses various methods for parameter estimation in differential equations, including Bayesian methods, gradient-based optimization, and particle filtering.
2. ""Parameter estimation in differential equations: a Bayesian perspective"" by S. S√§rkk√§ (2013). This review article focuses on Bayesian methods for parameter estimation in differential equations, including Markov chain Monte Carlo (MCMC) methods and sequential Monte Carlo (SMC) methods.
3. ""Optimization methods for parameter estimation in nonlinear differential equation models"" by C.L. Lawson et al. (2013). This review article discusses various optimization methods for parameter estimation in nonlinear differential equation models, including gradient-based methods, genetic algorithms, and particle swarm optimization.
4. ""Parameter estimation and sensitivity analysis in computational systems biology"" by D. Ge and J.J. Liu (2019). This review article provides an overview of various methods for parameter estimation and sensitivity analysis in computational systems biology, including optimization-based methods, Bayesian methods, and global sensitivity analysis.

Great, right? Except, **none of these papers actually exist**. The authors sound similar to people in the field (""P.J. Haario is probably ""inspired"" by Heikki Haario who's well known in the field, and Simo S√§rkk√§ is an actual author who's published on this), but the work does not exist. 

In hindsight, this makes sense considering how chatGPT works. It's still pretty interesting though, and I wonder how many people have turned in college assays with completely fabricated references."
32,134o5fe,datascience,ChatGPT,top,2023-05-01 14:33:50,"[colabdog.com] I build an aggregator for AI News that combines OpenAI, Google AI, MIT, BAIR.",colabDog,False,0.86,5,https://i.redd.it/rlizo23od8xa1.png,1,1682951630.0,
33,13c8ewn,datascience,ChatGPT,top,2023-05-08 23:21:30,I asked ChatGPT4 to do some stats modelling - it was okay‚Ä¶ish,AFL_gains,False,0.61,4,https://www.reddit.com/r/datascience/comments/13c8ewn/i_asked_chatgpt4_to_do_some_stats_modelling_it/,11,1683588090.0,"Hi guys ! There‚Äôs been some debate, especially on here, about the ‚Äúfuture of data science‚Äù and ‚Äúwhose job is going to be taken‚Äù etc etc. Imo I don‚Äôt know the answer, but I think LLMs have definitely changed the landscape.

One of the really interesting things ChatGPT has unlocked is that people can now code without really knowing how to. I think if you already are familiar with coding, using ChatGPT to improve productivity is awesome. But if you‚Äôre just starting out and use it generate code you can‚Äôt explain, then I think you can get into lots of trouble. 

And I think this is especially true when there‚Äôs a mathematical modelling choice aspect to your code. My thought was that just because something works / compiles, doesn‚Äôt mean it‚Äôs a very good model and doesn‚Äôt mean that the explicit choices / assumptions make sense. This, of course, isn‚Äôt chatGPTs fault, it‚Äôs the users fault for not checking! 

Anyway, to investigate this point, I recently tested ChatGPT to write a Stan code (bayesian inference ) to predict premier league matches. My feeling was that the task simple enough for it to do an okay job, but not so generic it there‚Äôs a million examples on the internet.

I put the results on YouTube (link below), but in summary I found the following: 

1. ChatGPT made a decent model, but with some really weird choices. Eg It decided to use a normal distribution to model goal differences , where I think a Skellam would have been better. It also decided not to model the variance of this distribution , instead deciding that it was 1. Super weird!

2. It wasn‚Äôt able to rationalise about things like over parameterisation. The model it build had way too many parameters, unnecessarily. The idea of parsimony wasn‚Äôt really there. Maybe with better prompts it would have, but out of the box it made the model overly complex


3. Prompt engineering really makes a difference. I think with better prompts, the model Could have been better. There was even a point where I spotted an error and prompted chatGPT to fix it and it did! But again, this all relied on me being able to read Stan code and know what was good and bad. 


For me, I learnt that at least for tasks where lots of modelling choices need to be made, humans still beat GPT. But perhaps in the future, those that win will be the data scientists/ engineers that know what they are doing but are able to prompt GPT optimally to maximise their productivity boost.



The videos are here : 
Part 1: https://m.youtube.com/watch?v=4LTUYTxKuIk&t=66s&pp=ygUTbGVhcm4gc3RhbiB3aXRoIHJpYw%3D%3D
Part 2: https://m.youtube.com/watch?v=XjQpV6c9K5g&t=1s&pp=ygUTbGVhcm4gc3RhbiB3aXRoIHJpYw%3D%3D"
34,zy1brw,datascience,ChatGPT,top,2022-12-29 09:38:58,Adding Chat GPT to RStudio with the GPT Studio add-in package,DrLyndonWalker,False,0.73,5,https://www.reddit.com/r/datascience/comments/zy1brw/adding_chat_gpt_to_rstudio_with_the_gpt_studio/,0,1672306738.0,"You can now add the incredible functionality of Chat GPT (including writing text and code) to RStudio using the GPT Studio package. In this video I cover the steps for setting up GPT Studio and then try some basic operations including spell correction and code writing. As I demonstrated in my recent RTutor video, Chat GPT is a game-changer. It can write code and text with a scary degree of precision. 

[https://youtu.be/QQfDTLExoNU](https://youtu.be/QQfDTLExoNU)"
35,10mu9ru,datascience,ChatGPT,top,2023-01-27 19:53:34,"A python module to generate optimized prompts, Prompt-engineering & solve different NLP problems using GPT-n (GPT-3, ChatGPT) based models and return structured python object for easy parsing",StoicBatman,False,1.0,5,https://www.reddit.com/r/datascience/comments/10mu9ru/a_python_module_to_generate_optimized_prompts/,0,1674849214.0,"Hi folks,

I was working on a personal experimental project related to GPT-3, which I thought of making it open source now. It saves much time while working with LLMs.

If you are an industrial researcher or application developer, you probably have worked with GPT-3 apis. A common challenge when utilizing LLMs such as #GPT-3 and BLOOM is their tendency to produce uncontrollable & unstructured outputs, making it difficult to use them for various NLP tasks and applications.

To address this, we developed **Promptify**, a library that allows for the use of LLMs to solve NLP problems, including Named Entity Recognition, Binary Classification, Multi-Label Classification, and Question-Answering and return a python object for easy parsing to construct additional applications on top of GPT-n based models.

Features üöÄ

* üßô‚Äç‚ôÄÔ∏è NLP Tasks (NER, Binary Text Classification, Multi-Label Classification etc.) in 2 lines of code with no training data required
* üî® Easily add one-shot, two-shot, or few-shot examples to the prompt
* ‚úå Output is always provided as a Python object (e.g. list, dictionary) for easy parsing and filtering
* üí• Custom examples and samples can be easily added to the prompt
* üí∞ Optimized prompts to reduce OpenAI token costs

&#x200B;

* GITHUB: [https://github.com/promptslab/Promptify](https://github.com/promptslab/Promptify)
* Examples: [https://github.com/promptslab/Promptify/tree/main/examples](https://github.com/promptslab/Promptify/tree/main/examples)
* For quick demo -> [Colab](https://colab.research.google.com/drive/16DUUV72oQPxaZdGMH9xH1WbHYu6Jqk9Q?usp=sharing)

Try out and share your feedback. Thanks :)

Join our discord for Prompt-Engineering, LLMs and other latest research discussions  
[discord.gg/m88xfYMbK6](https://discord.gg/m88xfYMbK6)

[NER Examples](https://preview.redd.it/x232msli2nea1.png?width=1236&format=png&auto=webp&s=6071efdd8cb12801230af6572991ba8aaff1a9ec)

&#x200B;

https://preview.redd.it/5o5uqk3k2nea1.png?width=1398&format=png&auto=webp&s=96c25820a698a83dfeb0e8f7f37682d9d27c06cb"
36,zrvydv,datascience,ChatGPT,top,2022-12-21 18:04:50,Advice for a recent college graduate who majored in Computer Science and Statistics looking to start a career in data? How does job security look?,OGlogicgate,False,0.62,3,https://www.reddit.com/r/datascience/comments/zrvydv/advice_for_a_recent_college_graduate_who_majored/,3,1671645890.0,"Hello, I graduated from university (not elite but notable) this semester with a major in Computer Science and Statistics. My internship experience is limited to front end development but as I was accruing credits towards my statistics major over the past year and a half and taking a course on machine learning, I've decided that I want to go into the field of data science. Unfortunately I don't have any internship experience in the field but after alot of consideration, a career in data science seems to be what I have the most interest in.

Through my coursework and projects I've had alot of exposure to python and data and ml frameworks, namely numpy and pyTorch. I also have experience in SQL and backend query languages.  

My question is, what should I focus on doing to make myself a more appealing candidate to get into the field of data science? Are there any certificate programs like the TensorFlow developer certificate that would help in me getting a job in this field? I should note that I had my fair share of personal issues in college and that my gpa is a 2.7 which really concerns me about my chances.

I apologize if this question is too open-ended or lacks basic research on my part, I've been struggling on what career I wanna go into and just recently decided I want to orient myself towards data science. Any advice would be greatly appreciated.

Also, as a side if you can touch a little bit on what job security looks like in the field I would greatly appreciate it. I've been paying attention to the openAI language model and like I'm sure many others, was frightened by what it could do. I understand there's no way it could replace a data scientist in it's current state however who knows what it can do in future iterations? How likely is it that large language models like chatGPT will either replace or displace a large percentage of data scientists in the field?"
37,10qecvo,datascience,ChatGPT,top,2023-01-31 23:43:50,Yann LeCun Hating on ChatGPT,MGeeeeeezy,False,0.54,3,https://www.reddit.com/r/datascience/comments/10qecvo/yann_lecun_hating_on_chatgpt/,35,1675208630.0,"Has anyone else noticed how much Yan LeCun has been hating on ChatGPT lately? I think it‚Äôs one thing to call out issues, but I have a feeling he‚Äôs trying to discredit it for business politics more than anything (Meta v. Microsoft)"
38,13bnz10,datascience,ChatGPT,top,2023-05-08 12:42:59,Ontology vs. LLM for Query Expansion (or both?),FlimsyYou6861,False,0.72,3,https://www.reddit.com/r/datascience/comments/13bnz10/ontology_vs_llm_for_query_expansion_or_both/,6,1683549779.0,"
I work at a recruitment agency where as a job seeker you can search for jobs and as a recruiter you can search for candidates in our candidate pool that might fit the job description. Currently both search engines are based on Elastic Search with some handling of synonyms, but we still have problems with showing all relevant search results if the search term doesn't fit the job description or CV (for example if some specific frontend framework is required for a job, a candidate with experience in a similar framework should still be shown in the results but with slightly lower relevancy.

Without much consideration for different approaches (because we don't have much NLP Expertise in the company and have a quite new data science department), we already experimented with building an ontology based on external ontologies and our own data (e.g. Python is used in Data Science) to find closely related terms and expand the search queries based on those relationships. While this approach seems to work somewhat, it feels kind of cumbersome, outdated and will probably need a lot of maintenance in the long run. For example using a prompt in GPT yielded very similar results in a matter of seconds, which raises the question if, for example, just using the embeddings of the search terms would already be enough to expand a users search query with additional relevant terms.

What approach would you suggest when dealing with the problem of query expansion? Or would a combination of both approaches make sense (e.g. using an LLM to automate building an ontology). Are ontologies regarding that use case outdated or am i just falling for the ChatGPT hype?

I would very much appreciate your insights!"
39,zfb2e7,datascience,ChatGPT,top,2022-12-07 19:31:37,GitHub Copilot,ergodym,False,0.83,4,https://www.reddit.com/r/datascience/comments/zfb2e7/github_copilot/,6,1670441497.0,All this excitement about ChatGPT reminded me of a prior excitement (although just limited to coding) about GitHub Copilot. Anyone here using GitHub Copilot? It also doesn't look like there is an implementation for Jupyter Notebook yet.
40,11j0tcn,datascience,ChatGPT,top,2023-03-05 16:12:56,LLMs for Text Classification (7B parameters),Jakaboy,False,0.83,4,https://www.reddit.com/r/datascience/comments/11j0tcn/llms_for_text_classification_7b_parameters/,5,1678032776.0,"Hi!

I'm doing my Master's thesis on text classification of long documents in the legal domain (>100 labels). 

I'm mainly doing fine-tuning of Bert/Roberta and using GNN models. The results are not great, micro-f1 \~55%.

But I wonder if it's possible to leverage chatgpt/llama/flan. LLMs that are designed to do generative AI/chat.

Is it possible to fine-tunning them in a consumer gpu? (3090)? Can I ""train"" them by using only prompts?

I have the feeling that text classification is a ""done"" subject, if a well-fine-tunned Bert can't get the result you want, 99% is because your data is awful. Is that a correct assumption?

&#x200B;

Thanks everyone!"
41,114qfkp,datascience,ChatGPT,top,2023-02-17 16:14:47,I am worried about the future of working as a Data Scientist in industry,Slumi,False,0.51,4,https://www.reddit.com/r/datascience/comments/114qfkp/i_am_worried_about_the_future_of_working_as_a/,71,1676650487.0,"I once watched a video where someone argued that Michael Jordan had ruined basketball. As a person whose only notions of basketball come from Space Jam, this surprised me. Wasn't the guy the best out there? How could someone who's best in his field ruin it? After hearing the argument out though, I began to understand what the video was really getting at: to them, Michael Jordan had ruined the field BECAUSE he was so good. A sport that was once full of diverse personalities and strategies then turned into multiple teams trying to produce their own Michael Jordan copycat with copycat moves and copycat strategies.

I'm not well versed enough in basketball to know how right or wrong that guy was. But this concept that something could ruin an entire field simply by being too good stuck with me. And all these years later, I consistently think about it while doing my job as a Data Scientist. And the more GPT-X and ChatGPT advance, the more this concept haunts me.

I've been working in this field for 5 years. During the first 4 years, the job was exciting. Every new problem required extensive research on my part: looking for papers, datasets, implementations, implementing my own stuff, experimenting, comparing the results... That was the biggest part of my job. Yeah I still had to do some software engineering stuff here and there, but I felt like I had a well defined and specialized role at my company. Even in the NLP field, the variety of technologies I had to work with was a lot of fun: sometimes I used RNNs, sometimes embedding based similarity functions, sometimes more classic approaches, and then towards the end it was transformer after transformer, but at least I still had to finetune them myself.

Over the past few months and years, this has started to change, however. GPT-1 and 2 were promising, but were more of a proof of concept than anything realistically usable. But with GPT3's and ChatGPT's latest performance, it feels like NLP is becoming more and more standardized. I wouldn't call it a solved field, far from it. But, sadly, unless you work for a big tech company,  I think the days of exploratory research-type work in the NLP field are over.

Even in academia, the latest NLP papers I've seen come out of prestigious universities went from actual engineering/mathematical advances to ""Look, if you ""engineer"" the prompt like this, it works better sometimes!""

And now, with the exploding popularity of ChatGPT, any random lambda would come to the conclusion that if you need to use AI, ChatGPT is the answer.

Now, some of you may already be thinking ""but hold on, with my finetuned transformer I get a 1% increase in accuracy over out-of-the-box GPT-3!"". The thing is: even if you can, it doesn't really matter. I really doubt the sales team of your company is gonna pay much attention to your pleas to give you 6 months to work on a product rather than 6 minutes. Because yes, that's the increase in productivity we're dealing with: What took me months a few years ago only takes minutes now. The range of problems I can apply NLP too has also increased, as out-of-the-box GPT-3 works well enough not to require a dataset for more ""general"" tasks. And the results are either comparable or even better.

In the span of a year, NLP went from my favorite ML field to one I never see myself working in again if given the choice. And while a lot of non NLP fields are, for now, untouched by the exploding popularity of the GPT family, I'm afraid that what happened to the NLP field will be replicated in other fields, and that in a few years, only super specialized issues won't have a solution somewhere in the form of a ridiculously big model accessible via an API key provided by a big tech company. And even if GPT3 was open source, the sheer size of it makes it close to impossible to realistically train for anything less than the biggest of tech companies out there. Even finetuning it would be a challenge.

I'm not saying the job of data scientist will disappear, in fact, I'd say it will be asked more than ever since boomers who don't understand what the title actually implies will want some in their company. But we won't be doing nearly as much actual data sciency stuff as we did in the past. Instead we'll have to become even bigger software engineer/data analyst/DevOps/project manager hybrids than we already were. The only exception is for people who either work in big tech companies or on very specialized problems that require an in-house model.

It's not that much of a problem for people who like the roles I listed above. But for people like me, whose enjoyment came out of the exploratory side of the job, I believe the future to be bleak."
42,10dfbc7,datascience,ChatGPT,top,2023-01-16 14:02:26,Are you using ChatGPT for work?,Conscious-Rush-9646,False,0.64,3,https://www.reddit.com/r/datascience/comments/10dfbc7/are_you_using_chatgpt_for_work/,11,1673877746.0,I started using it just for some silly things like describe what this code does. I'm curios to see if anyone is actually using it on a daily basis and it's making a difference.
43,11vdjat,datascience,ChatGPT,top,2023-03-19 06:27:43,datasetGPT - A command-line tool to generate datasets by inferencing LLMs at scale. It can even make two ChatGPT agents talk with one another.,radi-cho,False,0.83,4,https://www.reddit.com/r/datascience/comments/11vdjat/datasetgpt_a_commandline_tool_to_generate/,0,1679207263.0,"GitHub: [https://github.com/radi-cho/datasetGPT](https://github.com/radi-cho/datasetGPT)

It can generate texts by varying input parameters and using multiple backends. But, personally, the conversations dataset generation is my favorite: It can produce dialogues between two ChatGPT agents.

Possible use cases may include:

* Constructing textual corpora to train/fine-tune detectors for content written by AI.
* Collecting datasets of LLM-produced conversations for research purposes, analysis of AI performance/impact/ethics, etc.
* Automating a task that a LLM can handle over big amounts of input texts. For example, using GPT-3 to summarize 1000 paragraphs with a single CLI command.
* Leveraging APIs of especially big LLMs to produce diverse texts for a specific task and then fine-tune a smaller model with them.

What would you use it for?"
44,1098wvy,datascience,ChatGPT,top,2023-01-11 16:30:13,Silicon Valley Generative AI Meetup,electroshock666,False,1.0,2,https://www.reddit.com/r/datascience/comments/1098wvy/silicon_valley_generative_ai_meetup/,0,1673454613.0,"Hello Folks! We are preparing to kick off the Silicon Valley Generative AI Meetup.

[https://www.meetup.com/silicon-valley-generative-ai/](https://www.meetup.com/silicon-valley-generative-ai/?succes=groupSetup&fromWelcomePage=true)

We  are looking for a few folks in the bay area that would like to help run the meetup, assist with logistics and can attend consistently.

The meetup is open to anyone including generative AI researchers, data  scientists, ML engineers, developers and anyone that wants to learn about generative AI and its applications, including those with strictly a  topical interest.

The group is not for AI generated content like AI art, ChatGPT responses and so   forth.  Although anyone showcasing their research can of course present   their model outputs.

Ideally we will have both technical and business representation, and no prior generative AI knowledge is required to join as we will conduct training  sessions, discuss generative AI papers and talk about the latest developments in the field of generative AI, both technical and commercial.

If you would like to attend the meetup feel free to join at the link above, you don't need to be in the bay area to join. If you are able to volunteer to help run the group please respond in the thread or PM  me.

Cheers,

Matt"
45,12avx58,datascience,ChatGPT,top,2023-04-03 20:01:07,Has ChatGPT/AI changed anything about your career as a data scientist?,NavidsonsCloset,False,0.54,2,https://www.reddit.com/r/datascience/comments/12avx58/has_chatgptai_changed_anything_about_your_career/,30,1680552067.0,
46,127qs9h,datascience,ChatGPT,top,2023-03-31 16:26:16,ChatGPT Survey: Performance on NLP datasets,matus_pikuliak,False,0.57,1,https://www.reddit.com/r/datascience/comments/127qs9h/chatgpt_survey_performance_on_nlp_datasets/,0,1680279976.0,"I've done a paper survey of how well ChatGPT performs on various NLP tasks as reported in arXiv papers. I have found 19 papers where they compared ChatGPT with fine-tuned models, but they are being published practically daily now. It seems that for the most of the classical NLP tasks, ChatGPT is not actually that strong and smaller fine-tuned models are often much better. According to the API page, GPT-4 is not expected to be much stronger on tasks like these. I think it is an interesting perspective that shows that for many of the tasks we need to solve, GPT models are actually not the right tool.

The full survey is in my blog post: [http://opensamizdat.com/posts/chatgpt\_survey/](http://opensamizdat.com/posts/chatgpt_survey/)

Any feedback is welcomed."
47,126id1o,datascience,ChatGPT,top,2023-03-30 10:10:02,Save all your conversations via scraping with python and chatGPT Frontend API (no apikey needed) [ GitHub - rodolflying/GPT_scraper ] https://github.com/rodolflying/GPT_scraper,Rodolflying,False,0.67,1,https://www.reddit.com/gallery/126gr0p,0,1680171002.0,
48,10k528k,datascience,ChatGPT,comments,2023-01-24 13:07:12,ChatGPT got 50% more marks on data science assignment than me. What‚Äôs next?,rifat_monzur,False,0.92,508,https://www.reddit.com/r/datascience/comments/10k528k/chatgpt_got_50_more_marks_on_data_science/,208,1674565632.0,"For context, in my data science master course, one of my classmate submit his assignment report using chatgpt and got almost 80%. Though, my report wasn‚Äôt the best, still bit sad, isn‚Äôt it?"
49,11aq3j0,datascience,ChatGPT,comments,2023-02-24 12:20:01,I genuinely think this field will die,dataentryadmin,False,0.22,0,https://www.reddit.com/r/datascience/comments/11aq3j0/i_genuinely_think_this_field_will_die/,146,1677241201.0,"The first release of Chat-GPT is already hugely transformative. We are kidding ourselves that within a few years, AI won‚Äôt be able to go from prompt to hundreds of line of working code in seconds.

The only limitation of AI currently is navigation of the physical world, which won‚Äôt be more than 10 years away.

Seriously, what was once a niche field for 1% academics is about to be taken over by a much smarter, faster AI. In hindsight, quite obviously AI would be able to navigate code and data better than us. 

The ONLY thing we have left is understanding and translating business needs of humans. We navigate complex social structures in a physical world and translating human needs into technical requirements is all we have left.

Someone prove me wrong please."
50,zejzzs,datascience,ChatGPT,comments,2022-12-06 22:21:47,Chat_GPT,WeirdDiscipline1862,False,0.92,270,https://www.reddit.com/r/datascience/comments/zejzzs/chat_gpt/,136,1670365307.0,"This weekend millions of people rushed to check the Chat_GPT. This fueled many discussions regarding the job security of the future. People like Paul Krugman started talking about the future of job and massive job loss as the result of the AI which will be disruptive of course. And this time unless previously that the job loss was happening in the low skilled job categories, it will happen to the skilled workers. Any thoughts about what to do and how to persuade a new job specially after knowing that data analysis related jobs will be very vulnerable to AI technologies. 

‚ÄúIt's true that as AI and machine learning technologies continue to advance, they are likely to have an impact on many different fields, including data science. However, it's important to remember that while AI may automate some tasks and make certain job roles obsolete, it is also likely to create new job opportunities in areas such as AI research, development, and implementation.

In terms of what job you should pursue in the future, it's difficult to say for certain. The best thing to do is to stay up-to-date on the latest developments in AI and machine learning, and consider pursuing education and training in these areas. This will give you the skills and knowledge you need to adapt to the changing job market and take advantage of the new opportunities that are likely to arise.

It's also important to remember that there will always be a need for human expertise and creativity in many fields, including data science. So, even as AI continues to advance, there will likely still be plenty of opportunities for skilled data scientists who are able to think critically, solve complex problems, and apply their expertise to new challenges.‚Äù


This is the Chat_GPT‚Äôs answer to what to do as data scientist question. üòÄ"
51,1162ssq,datascience,ChatGPT,comments,2023-02-19 05:43:37,Buzz around new Deep Learning Models and Incorrect Usage of them.,brokened00,False,0.94,190,https://www.reddit.com/r/datascience/comments/1162ssq/buzz_around_new_deep_learning_models_and/,100,1676785417.0," In my job as a data scientist, I use deep learning models regularly to classify a lot of textual data (mostly transformer models like BERT finetuned for the needs of the company). Sentiment analysis and topic classification are the two most common natural language processing tasks that I perform, or rather, that is performed downstream in a pipeline that I am building for a company. 

The other day someone high up (with no technical knowledge) was telling me, during a meeting, that we should be harnessing the power of ChatGPT to perform sentiment analysis and do other various data analysis tasks, noting that it should be a particularly powerful tool to analyze large volumes of data coming in (both in sentiment analysis and in querying and summarizing data tables). I mentioned that the tools we are currently using are more specialized for our analysis needs than this chat bot. They pushed back, insisting that ChatGPT is the way to go for data analysis and that I'm not doing my due diligence. I feel that AI becoming a topic of mainstream interest is emboldening people to speak confidently on it when they have no education or experience in the field. 

After just a few minutes playing around with ChatGPT, I was able to get it to give me a wrong answer to a VERY EASY question (see below for the transcript). It spoke so confidently in it's answer, even going as far as to provide a formula, which it basically abandoned in practice. Then, when I pointed out it's mistake, it corrected the answer to another wrong one. 

The point of this long post was to point out that AI tool have their uses, but they should not be given the benefit of the doubt in every scenario, simply due to hype. If a model is to be used for a specific task, it should be rigorously tested and benchmarked before replacing more thoroughly proven methods.

ChatGPT is a really promising chat bot and it can definitely seem knowledgeable about a wide range of topics, since it was trained on basically the entire internet, but I wouldn't trust it to do something that  a simple pandas query could accomplish. Nor would I use it to perform sentiment analysis when there are a million other transformer models that were specifically trained to predict sentiment labels and were rigorously evaluated on industry standard benchmarks (like GLUE).

https://preview.redd.it/sz3ejc1313ja1.png?width=1700&format=png&auto=webp&s=76c48939903f8d34810000d1a71cb25f86237130"
52,125fd6p,datascience,ChatGPT,comments,2023-03-29 06:33:08,[D] Very good article about the current limitations of GPT-n models,fripperML,False,0.98,234,https://www.reddit.com/r/datascience/comments/125fd6p/d_very_good_article_about_the_current_limitations/,95,1680071588.0,"I count myself among the people that are amazed of what those models can do and how they can impact our society.

However, it's very important to understand that they are not magical solutions for every problem and that they cannot reason at all.

[ChatGPT as a query engine on a giant corpus of text ‚Äì r y x, r (ryxcommar.com)](https://ryxcommar.com/2023/03/28/chatgpt-as-a-query-engine-on-a-giant-corpus-of-text/)

What is more impressing is that, given this mental model of ChatGPT as a giant query engine, how can it perform activities that involve creativity outside of his training data? Like, for example, writing a poem in the style of Shakespeare about the proof that there are infinite prime numbers? Surely there are no examples of that in the training data! My answer would be that for some tasks interpolation works well (you can somehow get something meaningful by interpolating known stylistic elements and known semantical elements into something ""new""). But when the task is more symbolic or discrete, instead of interpolative, like true reasoning, and there are no examples to retrieve an answer from, the system has a much harder time.

That is, I am alligned with F. Chollet views on this:

[Fran√ßois Chollet en Twitter: ""You can retrieve not just what was seen at training time, but arbitrary combinations of it. It's an interpolative database and program store, with a natural language interface. https://t.co/2mv2gnI3oM"" / Twitter](https://twitter.com/fchollet/status/1637122108357738496)

[Fran√ßois Chollet en Twitter: ""This paper has the right idea: use symbolic logic for discrete reasoning and lean on deep learning models for perception and common-sense intuition. https://t.co/9lP8eDZKkO I expect to see a lot more progress along these lines in the coming months / years."" / Twitter](https://twitter.com/fchollet/status/1636838039703126016)"
53,10a7kq4,datascience,ChatGPT,comments,2023-01-12 19:01:24,I wrote up a guide showing how to do Data Science with ChatGPT.,Own-Anteater4164,False,0.83,271,https://www.reddit.com/r/datascience/comments/10a7kq4/i_wrote_up_a_guide_showing_how_to_do_data_science/,93,1673550084.0,"Just recently, I wrote up a guide on how to use [ChatGPT to build a website with Replit](https://buildspace.so/notes/chatgpt-replit-website?utm_source=r).

Got some pretty good responses, so I decided to write + document more of the applications I'm discovering.

**I'm actually really excited about this one, since I was in a graduate program for statistics.**

[Here's the guide](https://buildspace.so/notes/chatgpt-data-science?utm_source=r) for doing data sci with ChatGPT

The tl;dr is that I show you some of the crazy data sci stuff ChatGPT can do:

\- Read and analyze raw CSV data. I just had to copy and paste.

\- It could tell what kind of data you're feeding it judging by the header columns!

\- It will give you the python/r code on how to run specific analysis.

\- It even knew how to use scikit-learn to run regression models ü§Ø (I mean, this makes sense since it's an AI tool lol).

Honestly, this is just crazy to me.

**Before I dropped out of graduate school for statistics, I often consulted non-technical researchers in the social sciences. It was always a pain for them to run datasets by themselves just to get some answers to their questions.**

Although ChatGPT isn't perfect (and does make mistakes), it's crazy where the tool is going.

I think this is really good news for a lot of people who are interested in doing research, but might feel too intimidated by needing to do stats. Obvi...some bad stuff could come from it. We'll see!

https://preview.redd.it/ggd96gyhnnba1.png?width=619&format=png&auto=webp&s=5aa2f39199bb0ce56518e2972e0ec8a36ccbb69d"
54,123tx9p,datascience,ChatGPT,comments,2023-03-27 17:25:43,Has ChatGPT killed doomers?,GreatStats4ItsCost,False,0.89,440,https://www.reddit.com/r/datascience/comments/123tx9p/has_chatgpt_killed_doomers/,90,1679937943.0,"Sorry for another ChatGPT post but I think it really is the end of asking whether certain job sectors will exist on r/DataScience due to ChatGPT making them redundant.

Whilst reading all of the 100's of doomer posts 'Will Data Science survive because ChatGPT' - it dawned on me that Chat GPT can replace all of the users creating these posts. They've all been made redundant. A simple prompt to an AI like 'Write a profoundly dumb Reddit post asking if Chat GPT has made Data Science redundant' - will return exactly that. With a simple workflow/pipeline the response from the API can be posted directly to r/DataScience. 

This really is the future and I'm worried."
55,10eye8i,datascience,ChatGPT,comments,2023-01-18 04:50:28,"I asked ChatGPT to explain ROC AUC, the level of collaboration is beyond my expectation",trantrikien239,False,0.9,472,https://master-data.science/assets/images/eli5ml-meth1.jpg,78,1674017428.0,
56,zcgpbp,datascience,ChatGPT,comments,2022-12-04 18:05:07,What do you guys think of OpenAI‚Äôs ChatGPT?,Loud_Ad_6272,False,0.94,55,https://www.reddit.com/r/datascience/comments/zcgpbp/what_do_you_guys_think_of_openais_chatgpt/,77,1670177107.0,"As the title goes, what do you guys think of this and what effect do you think it would have on the discipline and field going forward?"
57,zpraee,datascience,ChatGPT,comments,2022-12-19 13:15:11,The real reason ChatGPT was created,xdonvanx,False,0.94,736,https://i.redd.it/g5z2t4zeuu6a1.png,73,1671455711.0,
58,114qfkp,datascience,ChatGPT,comments,2023-02-17 16:14:47,I am worried about the future of working as a Data Scientist in industry,Slumi,False,0.51,2,https://www.reddit.com/r/datascience/comments/114qfkp/i_am_worried_about_the_future_of_working_as_a/,71,1676650487.0,"I once watched a video where someone argued that Michael Jordan had ruined basketball. As a person whose only notions of basketball come from Space Jam, this surprised me. Wasn't the guy the best out there? How could someone who's best in his field ruin it? After hearing the argument out though, I began to understand what the video was really getting at: to them, Michael Jordan had ruined the field BECAUSE he was so good. A sport that was once full of diverse personalities and strategies then turned into multiple teams trying to produce their own Michael Jordan copycat with copycat moves and copycat strategies.

I'm not well versed enough in basketball to know how right or wrong that guy was. But this concept that something could ruin an entire field simply by being too good stuck with me. And all these years later, I consistently think about it while doing my job as a Data Scientist. And the more GPT-X and ChatGPT advance, the more this concept haunts me.

I've been working in this field for 5 years. During the first 4 years, the job was exciting. Every new problem required extensive research on my part: looking for papers, datasets, implementations, implementing my own stuff, experimenting, comparing the results... That was the biggest part of my job. Yeah I still had to do some software engineering stuff here and there, but I felt like I had a well defined and specialized role at my company. Even in the NLP field, the variety of technologies I had to work with was a lot of fun: sometimes I used RNNs, sometimes embedding based similarity functions, sometimes more classic approaches, and then towards the end it was transformer after transformer, but at least I still had to finetune them myself.

Over the past few months and years, this has started to change, however. GPT-1 and 2 were promising, but were more of a proof of concept than anything realistically usable. But with GPT3's and ChatGPT's latest performance, it feels like NLP is becoming more and more standardized. I wouldn't call it a solved field, far from it. But, sadly, unless you work for a big tech company,  I think the days of exploratory research-type work in the NLP field are over.

Even in academia, the latest NLP papers I've seen come out of prestigious universities went from actual engineering/mathematical advances to ""Look, if you ""engineer"" the prompt like this, it works better sometimes!""

And now, with the exploding popularity of ChatGPT, any random lambda would come to the conclusion that if you need to use AI, ChatGPT is the answer.

Now, some of you may already be thinking ""but hold on, with my finetuned transformer I get a 1% increase in accuracy over out-of-the-box GPT-3!"". The thing is: even if you can, it doesn't really matter. I really doubt the sales team of your company is gonna pay much attention to your pleas to give you 6 months to work on a product rather than 6 minutes. Because yes, that's the increase in productivity we're dealing with: What took me months a few years ago only takes minutes now. The range of problems I can apply NLP too has also increased, as out-of-the-box GPT-3 works well enough not to require a dataset for more ""general"" tasks. And the results are either comparable or even better.

In the span of a year, NLP went from my favorite ML field to one I never see myself working in again if given the choice. And while a lot of non NLP fields are, for now, untouched by the exploding popularity of the GPT family, I'm afraid that what happened to the NLP field will be replicated in other fields, and that in a few years, only super specialized issues won't have a solution somewhere in the form of a ridiculously big model accessible via an API key provided by a big tech company. And even if GPT3 was open source, the sheer size of it makes it close to impossible to realistically train for anything less than the biggest of tech companies out there. Even finetuning it would be a challenge.

I'm not saying the job of data scientist will disappear, in fact, I'd say it will be asked more than ever since boomers who don't understand what the title actually implies will want some in their company. But we won't be doing nearly as much actual data sciency stuff as we did in the past. Instead we'll have to become even bigger software engineer/data analyst/DevOps/project manager hybrids than we already were. The only exception is for people who either work in big tech companies or on very specialized problems that require an in-house model.

It's not that much of a problem for people who like the roles I listed above. But for people like me, whose enjoyment came out of the exploratory side of the job, I believe the future to be bleak."
59,12vl384,datascience,ChatGPT,comments,2023-04-22 22:04:04,Found this on an analyst position job ad on LinkedIn. Do you think the shade is reasonable?,BiggusCinnamusRollus,False,0.98,253,https://i.redd.it/cxcftudodiva1.png,64,1682201044.0,
60,13ilm03,datascience,ChatGPT,comments,2023-05-15 21:45:36,I investigated the Underground Economy of Glassdoor Reviews,ibsurvivors,False,0.99,1166,https://www.reddit.com/r/datascience/comments/13ilm03/i_investigated_the_underground_economy_of/,63,1684187136.0,"Online company reviews are high stakes.

Top reviews on sites like Glassdoor and Google can get thousands of impressions each month and are major drivers of brand perception.

Employers know this. And when I come across multiple 5 star reviews left with no cons, or a Pulitzer worthy essay from a former intern, I become suspicious.

These reviews start to resemble 30 under 30 lists: so artificially constructed that you begin to question their credibility in the first place.

The scrutiny around company reviews is well documented; some companies file lawsuits worth over a million dollars to reveal anonymous reviewers that complain about their jobs.

Whilst it's the flashy lawsuits that make the headlines, there also exists an underground economy of company reviews operating quietly every single day.

In this underground economy, some companies pay over $150 to freelancers to try and get a negative review removed. If they want ‚Äúbetter‚Äù results, they go to the plethora of Online Reputation Management services (ORMs) in the United States that can charge retainers worth thousands of dollars.

The supply of positive reviews exists too. My research led me to find companies, including a prominent Y-Combinator backed startup, that solicit fake positive reviews from online freelancers to improve their rating.

Many of these mercenary fake reviewers, often based in South East Asia, make a full time living doing this, netting over $2,000 per month.

Some of these run such sophisticated operations that they‚Äôve even created their own pricing tiers (e.g $35 per original review, $20 to post an already created review from an email address), a la SaaS offering.

Others operate on a contingency fee agreement model, where they only get paid if they‚Äôre able to take a negative review down.

The underground economy of company reviews is well and truly alive. And today we‚Äôre going to find out how it operates.

***Note***: For more content like this, [*subscribe*](https://www.careerfair.io/subscribe) *to my newsletter. In a couple of weeks, I'll be releasing my guide to writing a killer resume.*

**Adding reviews**

The barriers to entry for adding fake reviews are much lower than for getting reviews removed, so that‚Äôs where we‚Äôll start.

To write an employer review, all you really need is the ability to create an email address. For most sites, you don‚Äôt need any proof of employment (say like a company specific email address).

I went on a gig marketplace site and posted a pretty vague post related to wanting to find out more on how to improve a company‚Äôs online presence.

Within minutes of posting a gig, my inbox was flooded with proposals:

https://preview.redd.it/esx3904qa20b1.png?width=3064&format=png&auto=webp&s=2ff3a2f8528fee99aabb830f27ea71a7569ebb2e

After a bit of chatting, I narrowed the scope of their services and summarized their rates into the table below:

|Channel|Cost|Timeline|Model|
|:-|:-|:-|:-|
|Freelancer #1|$10 per review|Monthly|Unlimited|
|Freelancer #2|$35 per original review, $20 per already created review|Monthly|Unlimited|
|Freelancer #3|$25 per review|Monthly|Unlimited|
|Freelancer #4|$25 per review|Monthly|10 reviews|
|Freelancer #5|$20 per review|Monthly|Unlimited|
|Online Reputation Management Agency|$300 subscription|Monthly|8 reviews|

Let‚Äôs dive a bit deeper into the services that Freelancer #5 offered.

Freelancer #5 explained to me he had been writing reviews for one particular company for the past 4 months now. Each month he wrote them 10 reviews.

&#x200B;

https://preview.redd.it/n1ddox6cb20b1.png?width=2684&format=png&auto=webp&s=5c271d0eec4328cb78d7d2cb85dfffa3f9eb72f8

In another message, he tells me he‚Äôs offering the same services to 5 other companies. Doing some quick math:

5 companies x 10 reviews per company x $25 per review = $1,250 per month

Considering the average person in Pakistan earns $150 per month, that‚Äôs not bad change at all.

One of the companies that he‚Äôs offering his services to includes a Y-Combinator backed startup. I won‚Äôt name the company, but here‚Äôs what its average Glassdoor review rating distribution looks like:

https://preview.redd.it/2np5b6fdb20b1.png?width=2420&format=png&auto=webp&s=f8cafaa85453b0933a18eb5c30f931b3bb893c46

5 star reviews account for over 77% of the company‚Äôs total reviews. Obviously, no one is buying fake reviews that make them look bad.

But here‚Äôs the thing: freelancers are getting quite smart when it comes to writing reviews that don‚Äôt look too fishy. They tend to do this by spacing the reviews out (so that they don‚Äôt come in ‚Äúspikes‚Äù ‚Äì more on this later) and they also make sure that they‚Äôre not always leaving the ‚Äúcons‚Äù section blank.

Don‚Äôt get me wrong, if you come across this company‚Äôs reviews, it‚Äôd be pretty easy to tell they‚Äôre quite strange. In fact, I can‚Äôt even post some screenshots here because it‚Äôd give the company away immediately.

But it would be challenging to conclude that the above company is buying reviews just by analyzing review volume and distribution without actually reading some of the reviews.

The same company is also buying reviews on Google Reviews.

Sidenote: I got curious about how he‚Äôs been writing 50 reviews from 50 different emails per month. Would he actually create 50 different email addresses? And what about the IP address ‚Äì doesn‚Äôt Glassdoor flag multiple reviews from the same IP?

One of the freelancers answered my question:

&#x200B;

https://preview.redd.it/g4id2yqeb20b1.png?width=2572&format=png&auto=webp&s=c2a77fdea8834a6d90f02b8b3eb67b3a874f3df2

Moving on ‚Äì another company that seems to buy fake reviews seems to be having some more trouble. Approximately a month after a freelancer linked me to fake reviews he had written for this company, all five reviews that he had linked me to had been removed:

&#x200B;

https://preview.redd.it/99fdvcgfb20b1.png?width=3116&format=png&auto=webp&s=b7e244529fc62b5c824d925feb61fd2cc16cbfd5

Based on this [Glassdoor webinar](https://youtu.be/3iy0JWOS1gs) from 2018, ‚Äúif it is found that a user has created multiple email accounts to submit reviews, then ALL submissions from that user are deleted‚Äù ‚Äì so likely Glassdoor‚Äôs content moderation team flagged one of the initial reviews and the same freelancer who was writing reviews for that company had all the fake reviews deleted.

So far, it looks like the key to an effective fake review creation strategy lies in:

* Spacing the fake reviews out
* Writing each review from a different IP address (i.e benefit of being part of a team)
* Using language that isn‚Äôt an obvious giveaway

On that third point: the reality is that many of these freelancers‚Äô first language is not English.

As an experiment, I turned to everybody‚Äôs favorite new toy, ChatGPT, and asked it to write me a positive Glassdoor review:

https://preview.redd.it/8w7cal9gb20b1.png?width=3164&format=png&auto=webp&s=860c39b11c5813e8b7fabdbb038d73c565cc98cf

And I‚Äôd say that the above answer was better than 95% of the fake reviews I came across.

**Removing reviews**

The process for removing an employer review usually works like this:

1. You identify one or multiple reviews that you want removed
2. You verify whether the review violates the site's Guidelines, or whether there‚Äôs something else about the review(s) that could get it removed.
3. You file an appeal to get it removed.

As an example, Glassdoor‚Äôs Review guidelines can be found [here](https://help.glassdoor.com/s/article/Community-Guidelines?language=en_US#:~:text=See%20More-,Review%C2%A0Guidelines,-Millions%20of%20job). Mainly, they forbid mentioning anyone by name who‚Äôs not an executive and revealing proprietary or confidential information, amongst a host of other things.

Sounds simple enough right? Well, according to one of the freelancers I messaged:

&#x200B;

https://preview.redd.it/x6s8hsyac20b1.png?width=2036&format=png&auto=webp&s=f86c386f864198dc43faeb41faea378090c20107

After some research, I summarized the different vendors and prices in the table below:

&#x200B;

|Channel|Cost|Timeline|Model|Self reported success rate|
|:-|:-|:-|:-|:-|
|Freelancer #1|$100 per review|3 days|Contingency Agreement Model|100%|
|Freelancer #2|$30 per review|7 days|Contingency Agreement Model|100%|
|Reputation management service #2|$450 per review|21 business days|Contingency Agreement Model|Unknown|
|Reputation management service #3|$1000 per review|Undefined|Contingency Agreement Model|100%|
|Reputation management service #4 Plan 1|$550 per review|5-6 weeks|Contingency Agreement Model|50-75%|
|Reputation management service #4 Plan 2|$300 Subscription + $100 per each review removed|Monthly service|Subscription plan|50-75%|
|Freelancer #3|$20|Undefined|Pay regardless|Undefined|
|Freelancer #4|$500|Undefined|Contingency Agreement Model|Undefined|

As you can see, unlike the fake review generation market, the prices vary quite a bit for getting reviews removed.

At one end, you have freelancers on gig marketplaces that will attempt to remove a review for less than $100. And then on the other end, you have ORMs (Online Reputation Management Agencies) that have multiple employees and more comprehensive packages in place. The one constant seems to be that most companies operate on a contingency agreement model (i.e pay only if review gets removed).

**Analyzing reviews**

ReviewMeta is a site that analyzes Amazon reviews and tells you how many are legitimate. The creator of the site, Tommy Noonan, mentions in an [interview with NPR](https://www.npr.org/sections/money/2018/06/27/623990036/episode-850-the-fake-review-hunter) that the main giveaway that a product is soliciting fake reviews is:

* A large, suspicious flood of positive reviews at the exact same time. For example, a 3 day stretch of time constituting 30% of total reviews.
* Phrases and words that are constantly repeated, especially in the section with no cons
* Brand monogamists (only review products from one company)

Whilst the last two bullets are hard to track, the first can be used to analyze different companies‚Äô reviews and to check if there might be some funky business going on.

After a couple of days, I have the ability to track review volume and review ratings over time for any company that I specify:

https://preview.redd.it/ehcbw2oje20b1.png?width=1653&format=png&auto=webp&s=b448ff35eb9878fbb1686de2fa8cf031e4ed3e05

Let the games begin.

## Voluntary Response Bias

One of the biggest challenges that review platforms face is the Voluntary Response bias.

Research shows many of today‚Äôs most popular online review platforms (e.g Amazon) have a distribution of opinion that is highly polarized, with many extreme positive and/or negative reviews, and few moderate opinions.

Think about it: have you ever felt moderately satisfied at your job and thought to yourself, now would be a great time to leave a Glassdoor review? Probably not.

On the other hand, if you‚Äôve had a terrible experience or even just had one thing really flip you off, you might be quite likely to leave an angry review.

Consider when a company goes through layoffs. You‚Äôre going to have a flood of angry reviews coming your way and are likely going to experience a ‚Äúspike‚Äù in reviews.

**Note:** Just like the Wall Street Journal‚Äôs methodology described [here](https://archive.is/20201016094732/https://www.wsj.com/articles/companies-manipulate-glassdoor-by-inflating-rankings-and-pressuring-employees-11548171977#selection-3965.0-3968.0), I considered there to be a spike if the total number of reviews in the month was greater than three standard deviations above the mean of the surrounding months.

Let‚Äôs take the company below. Here‚Äôs a graph of of their review volume since Jan 2020, including when they announced one of their first round of layoffs in June 2022:

https://preview.redd.it/n6kd9ejle20b1.png?width=3216&format=png&auto=webp&s=9eea2f3836617feca37eb88b1d3f67c8fa1b6fe2

In June 2022, approximately 19% of this company's 52 reviews were 1 star reviews (compared to an overall average of around 10%). This is what we could call a statistically significant spike in reviews. It also illustrates how the employees most likely to leave reviews are the ones that obviously had a bad experience (i.e getting laid off).

Here‚Äôs another company that had a similar spike in negative reviews due to layoffs in November 2022:

https://preview.redd.it/4vcnr1ine20b1.png?width=2408&format=png&auto=webp&s=f3877fb315ccc5d9a9294306a9f86616cb0fabd2

This company had an approximate 20% 1 star review rate (compared to an overall average of 12%) in November 2022, as well as an Avg Rating of 2.96 that month (compared to an overall average rating of 3.73).Unless HR is proactive, their reviews page risks succumbing to an echochamber of negative reviews that can really tilt one way.

**Note:** Glassdoor does state (based on [this video](https://www.youtube.com/watch?v=3iy0JWOS1gs) from 2017) that about 75% of the reviews on their platform are neutral. Their ‚Äúgive to get policy‚Äù has helped in keeping the platform from becoming too polarized.

I can understand why HR teams, like the ones that Nader talked to me about earlier, take a proactive stance towards managing their reviews. If they don‚Äôt try to control their reputation themselves, then their reputation risks getting controlled by the employees that had the worst possible experience.

## Goodhart‚Äôs Law

Goodhart‚Äôs law states the following:

*""When a measure becomes a target, it ceases to be a good measure""*

Every October, Glassdoor publishes their Best Places To Work ranking.

In a [report](https://www.wsj.com/articles/companies-manipulate-glassdoor-by-inflating-rankings-and-pressuring-employees-11548171977) that the WSJ did a couple of years ago, they found large spikes in the number of reviews that some companies (e.g SpaceX, Bain & Co, etc) got in September. The logic here is that some companies try to artificially inflate their Glassdoor reviews right before the October deadline.

I decided to revisit some of this analysis with Glassdoor‚Äôs 2023 Best Places To Work Ranking.

One of the companies I examined is rated as one of the best places to work in 2023. Let‚Äôs refer to this company as FunPlaceToWork.

Here is how their review volume looks like for all of 2022:

https://preview.redd.it/4e656zkqe20b1.png?width=2516&format=png&auto=webp&s=07141a66c56be7a6818efb9b1a4d912ee0021c91

FunPlaceToWork got around 50 reviews in September 2022. Of those 50 reviews, 96% were 5 star reviews.

FunPlaceToWork averaged 12 reviews per month up till then in 2022. Also, in the prior six months, the average percent of 5 star reviews received every month was \~75%.

Both the spike in volume of reviews and the spike in percentage of five star reviews are statistically significant.

I find it strange that Glassdoor‚Äôs proprietary algorithm and/or Human Content Moderation team did not find a spike of this nature unusual. If we look at Glassdoor‚Äôs eligibility criteria for the award, it‚Äôs as follows:

https://preview.redd.it/hag04y7se20b1.png?width=2868&format=png&auto=webp&s=ec2b920e126a8ea42b40d35aaa55d5341e69d022

The goal, according to Glassdoor, is to collect ‚Äúauthentic and unbiased reviews‚Äù.

Whilst there‚Äôs nothing against the rules for asking your employees to leave you reviews, I find the statistically significant spike of reviews at odds with the goal of collecting ""unbiased and authentic"" reviews (which Glassdoor states is the purpose of the awards).

Glassdoor states that an employer is allowed to ask its employees to leave reviews, but that they are not allowed to ‚Äúcoerce‚Äù them. Examples of what you can‚Äôt do:

* Offer incentives like Gift Cards in exchange for positive reviews.
* Withholding their reference letter unless they leave you a positive review.
* Anything that leads you to require proof for the employee to show you that they wrote a review.

It is possible to play by the rules (i.e not break any of the above rules) and to still in my opinion not collect authentic and unbiased reviews.

They say that you shouldn‚Äôt hate the player but the game ‚Äì I think **FunPlaceToWork** played by the rules, won fair and square, and that this is simply a perfect example of Goodhart‚Äôs Law.

I reached out to Glassdoor ([awards@glassdoor.com](mailto:awards@glassdoor.com)) about the above and this is the reply I got:

https://preview.redd.it/x0dqq39ue20b1.png?width=4800&format=png&auto=webp&s=c0102c963be9486370b340f2f473cbc6650fc48a

**Conclusion**

When I was 22, on an [F1 visa with 3 months to find work](https://www.careerfair.io/job-hunt-story), I didn‚Äôt give a damn about bad reviews. I needed a job and I‚Äôd sign any piece of paper you put in front of me.

Compare that to someone at the peak of their career, someone with optionality and a multitude of job offers; an ‚ÄúA-Player‚Äù, as the experts call it, would absolutely have the luxury of choice and discard a job offer based on bad company reviews.

For most people, the impact of online company reviews lies somewhere in the middle. In marketing, there‚Äôs a concept of a ‚Äúmarketing touchpoint‚Äù - an interaction with the brand over the course of the whole buying journey.

Company reviews are one of the many touchpoints a job seeker experiences over their interview process. And with the technology industry booming the past couple of years, companies couldn‚Äôt afford to slack on any touchpoints, including this one.

After all, when others start to game the system, you‚Äôre at a disadvantage if you don‚Äôt. The rewards can be quite high. Certainly higher than just trying to be as transparent as possible.

HR leaders are often more incentivized to inflate their metrics than to get honest feedback. Fake review writers have bills to pay. ORMs know that companies are desperate. And the platforms, well, aren‚Äôt always paying attention.

The result is a potluck of interests that leads to an underground economy.

One that ends up hurting the job seeker.

\*\*\*

Whew. That took a while (about 3 months in fact). Thanks for reading. For more content like this, [subscribe](https://www.careerfair.io/subscribe) to my newsletter. It's my best content delivered to your inbox once every 2 weeks."
61,11l5jqm,datascience,ChatGPT,comments,2023-03-07 17:31:31,"My AI tool to writes SQL queries for me now, so I don't have to. Thoughts?",slingshoota,False,0.89,120,https://www.reddit.com/r/datascience/comments/11l5jqm/my_ai_tool_to_writes_sql_queries_for_me_now_so_i/,60,1678210291.0,"I often write SQL queries for my Data Science job, but it can be really tedious and time-consuming. First I have to think about how to even approach the query, and then I have to google stuff to fix issues and refresh my memory.

I started using ChatGPT for help, but it was annoying to have to explain the tables/views every time.

To fix this, I built a tool that remembers your whole schema. It gives you a query to extract all the necessary info in one go and then you just copy-paste it once (it's saved with encryption). Then, all you have to do is write what you need in plain English, Ex. ""Users who have been online over 5 days this week"", and it writes the SQL query for you.

I showed it to my colleagues and they went crazy and are obsessed with it, as are my ex-colleagues from my last company.

What do you think? Would love to get your feedback. It's 100% free, you couldn't pay me even if you wanted to: www.blazesql.com"
62,10h0upu,datascience,ChatGPT,comments,2023-01-20 16:12:22,Chatgpt taking our jobs.,ayelcpl,False,0.37,0,https://www.reddit.com/r/datascience/comments/10h0upu/chatgpt_taking_our_jobs/,52,1674231142.0,"As a grad student studying data science, I can't help but feel a little worried about the future of my field. With all the advancements in AI and machine learning like chatgpt, it's making me question whether the skills and knowledge I'm gaining in my program will still be relevant by the time I graduate."
63,zev449,datascience,ChatGPT,comments,2022-12-07 07:32:52,ChatGPT's response to Michael Bromley's question about humans,RunOrDieTrying,False,0.93,455,https://i.redd.it/1du2r7vaif4a1.jpg,49,1670398372.0,
64,10qecvo,datascience,ChatGPT,comments,2023-01-31 23:43:50,Yann LeCun Hating on ChatGPT,MGeeeeeezy,False,0.56,4,https://www.reddit.com/r/datascience/comments/10qecvo/yann_lecun_hating_on_chatgpt/,35,1675208630.0,"Has anyone else noticed how much Yan LeCun has been hating on ChatGPT lately? I think it‚Äôs one thing to call out issues, but I have a feeling he‚Äôs trying to discredit it for business politics more than anything (Meta v. Microsoft)"
65,11lt96v,datascience,ChatGPT,comments,2023-03-08 10:51:40,[Q] Are you wary of using ChatGPT because of sensitive data concerns?,limedove,False,0.84,35,https://www.reddit.com/r/datascience/comments/11lt96v/q_are_you_wary_of_using_chatgpt_because_of/,37,1678272700.0,
66,13ai0wp,datascience,ChatGPT,comments,2023-05-07 08:54:50,What are your thoughts on the LLM fever going on right now?,Samirio,False,0.76,9,https://www.reddit.com/r/datascience/comments/13ai0wp/what_are_your_thoughts_on_the_llm_fever_going_on/,36,1683449690.0,"The hype is strong with this one, but do you think it is justified? 

Do you think that this will actually change our day to day in ways other than using chatgpt or other LLMs as personal assistants?

I look around and see people left and right reaching out for creating applications using LLMs, but so far I didn‚Äôt see anything other than feeding documents to an LLM and having it summarize them, which doesn‚Äôt seem that ground breaking to me.

What are your thoughts on this topic?

Edit: I understand that I have over simplified my view of LLMs just ‚Äúsummarizing‚Äù text, when instead I should be asking something like, do you think LLMs are being effective now in the way they are being hyped for?"
67,122nwrk,datascience,ChatGPT,comments,2023-03-26 14:31:39,I asked ChatGPT for the best random state value,liquidInkRocks,False,0.89,98,https://www.reddit.com/r/datascience/comments/122nwrk/i_asked_chatgpt_for_the_best_random_state_value/,36,1679841099.0,"This thing is like a student forced to write 1000 words on the topic. 

**me:**  What is a good random state value to use in general 

**Bot:**  

In machine learning, a random state is used to initialize the random number generator. The random number generator is used to shuffle the data, split the data into training and test sets, initialize the parameters of the model, and make other random decisions during training and evaluation.

Choosing a good random state value is important because it can affect the results of your model. If you use a different random state, you may get different results.

In general, there is no one ""best"" random state value to use. The value you choose depends on the specific problem you're working on and the specific data you're working with.

However, it's a good practice to set a random state to ensure reproducibility of your results. You can choose any integer value for the random state, but it's common to use numbers like 0, 42, or 2022.

It's also common to use cross-validation techniques like k-fold cross-validation, which helps to reduce the variability of your results due to different random state values."
68,117736x,datascience,ChatGPT,comments,2023-02-20 13:47:54,Is NLP a sub-field with a lot of growth?,sonicking12,False,0.78,32,https://www.reddit.com/r/datascience/comments/117736x/is_nlp_a_subfield_with_a_lot_of_growth/,35,1676900874.0,I am thinking about how Amazon reportedly axed a lot of Alexa teams.  This seems to point to negative.  But ChatGPT is taking up a lot of interest. This seems to point to positive.   What are your thoughts?
69,zgoxwa,datascience,ChatGPT,comments,2022-12-09 06:18:39,Gaussian Processes for pirates. Courtesy of ChatGPT,Sid__darthVader,False,0.98,498,https://i.redd.it/4cs2kirjwu4a1.jpg,34,1670566719.0,
70,zmye7g,datascience,ChatGPT,comments,2022-12-15 22:34:22,Have you used ChatGPT to write code for you?,is_this_the_place,False,0.77,24,https://www.reddit.com/r/datascience/comments/zmye7g/have_you_used_chatgpt_to_write_code_for_you/,33,1671143662.0,Is so what did you ask and how did it go?
71,zwppsu,datascience,ChatGPT,comments,2022-12-27 20:48:02,ChatGPT Extension for Jupyter Notebooks: Personal Code Assistant,Tieskeman,False,0.98,420,https://www.reddit.com/r/datascience/comments/zwppsu/chatgpt_extension_for_jupyter_notebooks_personal/,32,1672174082.0,"Hi!

I want to share a [browser extension](https://github.com/TiesdeKok/chat-gpt-jupyter-extension) that I have been working on. This extension is designed to help programmers get assistance with their code directly from within their Jupyter Notebooks, through ChatGPT.

The extension can help with code formatting (e.g., auto-comments), it can explain code snippets or errors, or you can use it to generate code based on your instructions. It's like having a personal code assistant right at your fingertips!

I find it boosts my coding productivity, and I hope you find it useful too. Give it a try, and let me know what you think!

You can find an early version here: 
https://github.com/TiesdeKok/chat-gpt-jupyter-extension"
72,108q84k,datascience,ChatGPT,comments,2023-01-11 00:30:20,Future of of DS? Over saturated field?,alx1056,False,0.38,0,https://www.reddit.com/r/datascience/comments/108q84k/future_of_of_ds_over_saturated_field/,30,1673397020.0,"Hello all, I wanted to ask your opinion if you think DS is over saturated? I know DS is an umbrella term since it can be applied to various industries and academia but what direction do we see the field moving? It seems with all of these new ‚Äúbreakthroughs‚Äù like ChatGPT that we will have no need for as many humans to code and work through standard data related problems if computers can just learn to solve it themselves. Maybe a pessimistic view but Ive just started learning DS and really enjoy it. Just seeing how others feel in general if their will be a big need 10 years from now."
73,12avx58,datascience,ChatGPT,comments,2023-04-03 20:01:07,Has ChatGPT/AI changed anything about your career as a data scientist?,NavidsonsCloset,False,0.56,3,https://www.reddit.com/r/datascience/comments/12avx58/has_chatgptai_changed_anything_about_your_career/,30,1680552067.0,
74,137fijm,datascience,ChatGPT,comments,2023-05-04 09:33:40,Excuse me if this has been asked before but isn‚Äôt ChatGPT going to make this entire field redundant?,data_tryingtist,False,0.22,0,https://www.reddit.com/r/datascience/comments/137fijm/excuse_me_if_this_has_been_asked_before_but_isnt/,30,1683192820.0,"I‚Äôm halfway through a certification in Data Science, and after trying ChatGPT out for a week or two I am suddenly unable to convince myself that it‚Äôs worth becoming certified in this field when AI is going to take all of the jobs. 

Anyone have any thoughts on this? Should I even bother completing the cert?"
75,zvsc8h,datascience,ChatGPT,comments,2022-12-26 17:43:47,Chat GPT taking over,BlackLotus8888,False,0.41,0,https://www.reddit.com/r/datascience/comments/zvsc8h/chat_gpt_taking_over/,29,1672076627.0,"Have y'all tried using chat GPT?  It's ridiculous!

1) I asked it to write a definition that takes in a df, imputes missing values, and returns a df and boom!

2) do t like the model it used, just ask it to use a different model

3) need cross validation?  No problem.  

4) need to get data using xx API?  You got it!  

It can do anything.  You just need to talk to it to get it right."
76,10m2qda,datascience,ChatGPT,comments,2023-01-26 21:15:30,Will Data science be automated and replaced by AI,Mysterious-Idea-9087,False,0.25,0,https://www.reddit.com/r/datascience/comments/10m2qda/will_data_science_be_automated_and_replaced_by_ai/,28,1674767730.0,"I'm beginning to second-guess my decision to get an MSc in data science. Perhaps you're wondering why? I'm beginning to think that artificial intelligence will eventually replace the necessity for data science in this scenario because the majority of huge data can now be automated. In addition, I'd like to cite that ""Data Scientists' skill set will be rendered irrelevant in 12 to 18 months as technology progresses"" ( Pedro Uria-Recio ,2018) I was amazed and worried at the same time when I first started using ChatGpt, a lately popular platform. I wondered if artificial intelligence will eventually replace the majority of currently held occupations, which would eventually lead up to more unemployment. Hence, here i am, looking for your opinion, for whether should i continue my MSc in data science or A.I? 

&#x200B;

This ,is just my understanding and opinion. Please feel free to comment your viewpoints. Regards!"
77,114zcik,datascience,ChatGPT,comments,2023-02-17 22:19:56,"What is something ChatGPT (or any LLM) could do, that it can‚Äôt currently, that would actually worry you about the future of data science?",cjrook,False,0.42,0,https://www.reddit.com/r/datascience/comments/114zcik/what_is_something_chatgpt_or_any_llm_could_do/,26,1676672396.0,"Lately on this sub there have been many ‚Äúsky is falling‚Äù posts related to ChatGPT. Most of the posts have drastically overestimated ChatGPT‚Äôs current use cases in the industry. What is a capability that if ChatGPT could do it, you would actually worry about the future of the data science field? More specifically worried about mass job loss within the field, if you foresee that."
78,137xo27,datascience,ChatGPT,comments,2023-05-04 19:42:30,"""The new ChatGPT Code Interpreter is like a Data Scientist on steroids""",datasciencepro,False,0.45,0,https://twitter.com/moritzkremb/status/1654107314528612355,23,1683229350.0,
79,130hqft,datascience,ChatGPT,comments,2023-04-27 10:53:05,Low hanging fruit projects for business with non-mature data science/analytics?,BobzzYourUncle,False,0.87,31,https://www.reddit.com/r/datascience/comments/130hqft/low_hanging_fruit_projects_for_business_with/,23,1682592785.0,"Hey data legends,

I've just started to learn a bit of Python and it's got me going down the rabbit hole of possible business applications for data analysis/science in this small/medium business (B2B with typically only a couple of transactions per customer each year).  What's currently done is very basic stuff in excel and no machine learning etc. (I have no background in data science other than basic knowledge but I feel there is a lot of potential)

I've managed to automate a PDF report that has some basic stuff using Plotly and Pandas and am wondering where I should focus my efforts next.

What are the general low hanging fruits that I should try and start out with for a business that has very little maturity on this front?

Chat GPT has come back with some suggestions like: Customer segmentation, Churn analysis, sales forecasting, website optimisation, recommendation engines, predictive CLV.  

Any help or insights would be appreciated pointing me in the right direction.  Thanks"
80,11skvpf,datascience,ChatGPT,comments,2023-03-16 05:10:41,"When hiring, how would you react if a candidate data scientist used ChatGPT heavily throughout a technical interview/coding session, but did a great job communicating what they were doing and why?",MyNotWittyHandle,False,0.48,0,https://www.reddit.com/r/datascience/comments/11skvpf/when_hiring_how_would_you_react_if_a_candidate/,21,1678943441.0,"It is the stack-overflow of 2023 and beyond, and will only get better.

Would you penalize a candidate for using a resource like ChatGPT?  Specifically if it made them more efficient, and were able to solve more problems in the same amount of time as someone who used more traditional resources (stack-overflow, google, etc.)

EDIT: to clarify, I want to emphasize my point above where in this case, the candidate needs to be able to describe what they are doing, why it works, pros and cons vs other approaches, etc.  I‚Äôm also assuming if they have gotten to the point of an in-person coding technical interview, they have already passed prior interview steps where they have demonstrated foundational knowledge of the field.

Additionally, if you are in the role of hiring and you haven‚Äôt deeply probed the capacity of ChatGPT to write effective code given an appropriate prompt, I‚Äôd say that is step 1."
81,126ndlu,datascience,ChatGPT,comments,2023-03-30 13:41:51,Seeing a lot of job openings for high-level AI and Data Analytics positions...,fingin,False,0.82,30,https://www.reddit.com/r/datascience/comments/126ndlu/seeing_a_lot_of_job_openings_for_highlevel_ai_and/,20,1680183711.0,"I have noticed an uptick in jobs for things like prompt engineer, AI ethics lead, AI manager. When you look at these requirements it looks like relatively low entry: a familiarity with general AI and AI regulations (not that there is a ton of expertise to be had in this latter category). They don't require much or any technical skill. 

I'll admit, I find myself frustrated as I work in a highly technical role and feel like these opportunities are really 'low hanging fruit', due to the vagueness of the requirements. I'm sure many of us wear not just technical hats but also those of product management, coaching and training, etc. 

What do you think? Is it just a fad stemming from ChatGPT and Image gen promotion? Are you going to make a job switch and apply for these roles?"
82,13futqv,datascience,ChatGPT,comments,2023-05-12 19:37:31,Will ChatGPT kills data science jobs?,Born-Comment3359,False,0.21,0,https://www.reddit.com/r/datascience/comments/13futqv/will_chatgpt_kills_data_science_jobs/,20,1683920251.0,
83,135536b,datascience,ChatGPT,comments,2023-05-01 23:38:33,What is there left for data analysts to do?,05confident,False,0.15,0,https://www.reddit.com/r/datascience/comments/135536b/what_is_there_left_for_data_analysts_to_do/,20,1682984313.0,"Execs will be able to self-serve. See results of chatgpt code interpreter

[https://twitter.com/backus/status/1652433895793516544](https://twitter.com/backus/status/1652433895793516544)

[https://twitter.com/emollick/status/1653069121704058883](https://twitter.com/emollick/status/1653069121704058883)

trust me, the SQL bots are also coming."
84,10a1mik,datascience,ChatGPT,comments,2023-01-12 14:59:04,New Research From Google Shines Light On The Future Of Language Models ‚≠ï,LesleyFair,False,0.84,123,https://www.reddit.com/r/datascience/comments/10a1mik/new_research_from_google_shines_light_on_the/,18,1673535544.0,"Last year, large language models (LLM) have broken record after record. ChatGPT got to 1 million users faster than Facebook, Spotify, and Instagram did. They helped create [billion-dollar companies](https://www.marketsgermany.com/translation-tool-deepl-is-now-a-unicorn/#:~:text=Cologne%2Dbased%20artificial%20neural%20network,sources%20close%20to%20the%20company), and most notably they helped us recognize the [divine nature of ducks](https://twitter.com/drnelk/status/1598048054724423681?t=LWzI2RdbSO0CcY9zuJ-4lQ&s=08).

2023 has started and ML progress is likely to continue at a break-neck speed. This is a great time to take a look at one of the most interesting papers from last year.

Emergent Abilities in LLMs

In a recent [paper from Google Brain](https://arxiv.org/pdf/2206.07682.pdf), Jason Wei and his colleagues allowed us a peak into the future. This beautiful research showed how scaling LLMs will allow them, among other things, to:

* Become better at math
* Understand even more subtleties of human language
* Stop hallucinating and answer truthfully
* ...

(See the plot on break-out performance below for a full list)

**Some Context:**

If you played around with ChatGPT or any of the other LLMs, you will likely have been as impressed as I was. However, you have probably also seen the models go off the rails here and there. The model might hallucinate gibberish, give untrue answers, or fail at performing math.

**Why does this happen?**

LLMs are commonly trained by [maximizing the likelihood](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf) over all tokens in a body of text. Put more simply, they learn to predict the next word in a sequence of words.

Hence, if such a model learns to do any math at all, it learns it by figuring concepts present in human language (and thereby math).

Let's look at the following sentence.

""The sum of two plus two is ...""

The model figures out that the most likely missing word is ""four"".

The fact that LLMs learn this at all is mind-bending to me! However, once the math gets more complicated [LLMs begin to struggle](https://twitter.com/Richvn/status/1598714487711756288?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1598714487711756288%7Ctwgr%5E478ce47357ad71a72873d1a482af5e5ff73d228f%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fanalyticsindiamag.com%2Ffreaky-chatgpt-fails-that-caught-our-eyes%2F).

There are many other cases where the models fail to capture the elaborate interactions and meanings behind words. One other example are words that change their meaning with context. When the model encounters the word ""bed"", it needs to figure out from the context, if the text is talking about a ""river bed"" or a ""bed"" to sleep in.

**What they discovered:**

For smaller models, the performance on the challenging tasks outline above remains approximately random. However, the performance shoots up once a certain number of training FLOPs (proxy for model size) is reached.

The figure below visualizes this effect on eight benchmarks. The critical number of training FLOPs is around 10\^23. The big version of GPT-3 already lies to the right of this point, but we seem to be at the beginning stages of performance increases.

&#x200B;

[Break-Out Performance At Critical Scale](https://preview.redd.it/w7xffqjimmba1.png?width=800&format=png&auto=webp&s=e2d9cb63f750efcbfa45c4bb7a985d4dcb5b0319)

They observed similar improvements on (few-shot) prompting strategies, such as multi-step reasoning and instruction following. If you are interested, I also encourage you to check out Jason Wei's personal blog. There he [listed a total of 137](https://www.jasonwei.net/blog/emergence) emergent abilities observable in LLMs.

Looking at the results, one could be forgiven for thinking: simply making models bigger will make them more powerful. That would only be half the story.

(Language) models are primarily scaled along three dimensions: number of parameters, amount of training compute, and dataset size. Hence, emergent abilities are likely to also occur with e.g. bigger and/or cleaner datasets.

There is [other research](https://arxiv.org/abs/2203.15556) suggesting that current models, such as GPT-3, are undertrained. Therefore, scaling datasets promises to boost performance in the near-term, without using more parameters.

**So what does this mean exactly?**

This beautiful paper shines a light on the fact that our understanding of how to train these large models is still very limited. The lack of understanding is largely due to the sheer cost of training LLMs. Running the same number of experiments as people do for smaller models would cost in the hundreds of millions.

However, the results strongly hint that further scaling will continue the exhilarating performance gains of the last years.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you.  
At **TheDecoding** ‚≠ï, I send out a thoughtful newsletter about ML research and the data economy once a week.  
No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)"
85,11szca1,datascience,ChatGPT,comments,2023-03-16 16:45:29,"What is your digital workspace, tools, setup, etc. for ETL, research, production?",BreathAether,False,0.93,37,https://www.reddit.com/r/datascience/comments/11szca1/what_is_your_digital_workspace_tools_setup_etc/,16,1678985129.0,"I'm new to this and so I've been wanting to know what other people have been using to make their work feel as smooth as butter. Since I've been learning lots and not just the industry standard stuff, I wanted to share what little I found to be valuable which others may want to try. **The main goal of this post is to share, critique, and provide suggestions so that we can all find the setup we like most. I  am also looking for new, up and coming tech, and definitely not afraid to try new things!**

IDE: **VSCode with the Jupyter Notebook Extension**. What I like about it is that I can view data structures like series/dataframes in a table format by clicking the variable in the Jupyter: Variables pane at the bottom. I started with plain vanilla jupyter notebooks from Anaconda so this was pretty nice. I have seen demos that **Jupyter Lab** has something like this, so if anyone has used both VSCode's notebooks and used Lab, your input would be appreciated. I hear good things about **PyCharm and Spyder**. Some people also use **Google Collab, DataSpell, and DeepNote** but I don't know enough about it. I did play around with DeepNote, and it was very cool but I didn't feel compelled to switch (and you have to pay for it!). 

Tools:

* A code helper: A few months back I was googling everything and I would've listed **Stackoverflow**. I might actually use that occasionally, but these days I use **ChatGPT** and **Bing AI**. For more current info or news-based I'll use Bing AI since it uses live search results, and for information that is knowledge based I might use ChatGPT. ChatGPT saves conversations so it's great for exploring topics in depth and referencing that conversation later. For those who have used both, maybe you know what I'm talking about and can provide a better explanation as to which is better for what purpose.
* Software: **Excel** is an obvious one. For instance, if I have a huge dataset and I just want to delete out columns that I don't need with Ctrl+click to select, it's easier and quicker than copy + pasting or typing out each of the string column names I want to ""df.drop()"". Excel is great for quick and simple stuff. Some software I have been learning about are I guess what I would consider as no- or low-code data analytics platforms, such as **Alteryx, KNIME, and Orange**. These software let you practically run an entire ETL pipeline. I believe Alteryx and KNIME are the gold-standard in this category, and Orange is a ""lite"" version of the two and is available in Anaconda. I think these are pretty cool, and I personally haven't found a huge use case for them since I've been chugging away in my notebooks with Python, but I can see the value. Would love for someone to chime in on these tools and how they compare to manually doing stuff in code, especially for large datasets.
* Version Control: This is where I'm primarily lacking, but I know that **Github** is the go-to. I don't use this but I know that a ton of people do. I don't even know where to start to be honest. I usually just create a new .ipynb file for each analysis or phase of an ETL pipeline haha. I'm also not too aware of what other innovative tools for version control exist.
* Python Libraries: Besides the obvious stuff like Pandas/NumPy, MatplotLib/Seaborn, and your popular ML libraries, I've recently found out about this library called **Polars**. It's basically a Rust version of Pandas, and it's super powerful. Some operations that I've run, that would've taken hours with Pandas, took me minutes. But I've been hearing that **Pandas 2.0** which will be released some time this month, has been looking at using PyArrow dtypes (if I recall correctly) and the speed is comparable to Polars. I mean these two are FAST. Another contender is **DuckDB** but I think the new Pandas and Polars are still faster. I mostly use Pandas but if there is some heavy lifting, I'll swap the dataframe to a polars one with a quick function, run it with polars, then back to pandas.

Anyway, that's just some things I can immediately think of. Looking forward to your suggestions! Bonus points for anything new and innovative. Cheers.

https://preview.redd.it/qj2cywt1r4oa1.png?width=1920&format=png&auto=webp&s=c4e02f5fec0b3768df336c7a3f63cc382b3954a8"
86,10iue4e,datascience,ChatGPT,comments,2023-01-22 21:12:11,"I wrote a tiny library this morning for openai's (suddenly really good, really cheap) embeddings to search stuff - Semantic search, smarter replies w/ GPT-3, easier.",morganpartee,False,0.82,14,https://www.sensibledefaults.io/blog/chatgpt/easy-python-embeddings,14,1674421931.0,"I've had a few buddies in the community ask about something like this in the last week, and then a reader did today so I finally took the time to write it up. It's basically a generic interface to try embeddings, and it's less than a hundred lines of code. Built this so you can just authenticate and test without having to fuss with numpy, pinecone, etc.

The only thing you do is put dictionaries with a name and text key, then search your embeddings instance. We return anything you stick in there with it too for your programming pleasure - think dates, page numbers, file names, whatever.

You can just... Build chat bots that are pretty smart like this for next to nothing by reading in your docs or whatever. It's cheap and incredibly effective. I know next to nothing about how to preprocess data for this thing, I've tried different sizes of chunks, lines, sentences and haven't found a one size fits all solution (other than more gpt to summarize) but - just try it, it's cheap as hell and there's so much you can do. Like the rest of the current state of gpt - it just kinda works. Start with one to five sentences (or lines for code) and experiment!

For you proper data scientists (nerds!) - you can just get the numpy array out and do regular embeddings stuff with it. If you do, I'd love to hear about it! Clustering, classification, etc are suddenly super easy, and the raw data is stored in json so you can upload it to something better when you're ready.

I know it's small, but little abstractions make life better. Anything we can do to lower the barrier to experimentation is worth doing. Hope it helps someone!"
87,1360alu,datascience,ChatGPT,comments,2023-05-02 21:06:32,How busy are you? Under/over utilization,MorningDarkMountain,False,0.81,15,https://www.reddit.com/r/datascience/comments/1360alu/how_busy_are_you_underover_utilization/,13,1683061592.0,"As simple as the title: I hear more and more often about Data Scientists feeling themselves to be under-utilized. Lack of projects, no real impact on the business, fear of being replaced by ChatGPT, stakeholders that do not really understand Data Science at all.

Are you currently under-utilized as well?"
88,135uvm8,datascience,ChatGPT,comments,2023-05-02 17:42:08,Why won‚Äôt AutoGPT take our jobs?,dataentryadmin,False,0.15,0,https://www.reddit.com/r/datascience/comments/135uvm8/why_wont_autogpt_take_our_jobs/,12,1683049328.0,"https://autogpt.net/auto-gpt-vs-chatgpt-how-do-they-differ-and-everything-you-need-to-know/

We are within years of AI handling the entirety of database management, pipelines, transformations, dash-boarding and analysis.

AutoGPT can write and recursively correct/improve its code. 

You convinced me in my last post that data would be the last industry to go, but to me it‚Äôs now looking to be the least safe. 

Data is relatively simple to a machine, and there is less nuance or requirement for a human-touch that software engineering might have (when building software for human application)."
89,118ybon,datascience,ChatGPT,comments,2023-02-22 13:15:21,Overview of state-of-art algorithms in their respective usecase?,Different_Day_3821,False,0.81,10,https://www.reddit.com/r/datascience/comments/118ybon/overview_of_stateofart_algorithms_in_their/,12,1677071721.0,"Fellow scientists... On the second year of data science i've become increasingly confused as to when, what and why to use certain algorithms... Specially in a field as rapidly developing as ours.

therefore i ask you if any of you got an overview of what the current best algorithms is according to their uses? Is there a systemisc ""cheat-sheet"" or overview of the current best libraries to import for X types of data and analysis?

For example learning NLP. First you learn Bag of Word models, then IDF-TF models. Then you learn thats outdated and people use Word2Vec models that retain semantic meaning. Then you learn thats outdated and that people use Bert models. But now even that in competition with transformer-based models as ChatGPT is based on etc.

Same thing with time series. First you like ARIMA, then you learn RNN, then LSTM, then Autoencoders, then to use autoencoders as unsupervised feature extraction into a supervised model etc.

And the more complicated you modern you get, the more specific becomes that imported libraries. Anomaly detection? Go PyOD/Prophet/PySAD etc.

How do you guys navigate in this? Is there some conversative principles that would keep your methods within some kind of boundary of usefullnes? I miss the old days of only knowing basic sklearn and basic naive bayes and clustering algorithms lol. On the otherhand if state of the art just means importing and fitting the right algorithm then i guess it ain't so bad.

tl;dr: Is there a cheat-sheet of X-kind of analsis then Y-kind of algorithm performs best? And how do you guys manage all the libraries/algorithms?"
90,13fvzkv,datascience,ChatGPT,comments,2023-05-12 20:23:46,ChatGPT code interpreter is crazy! What next?,__ped,False,0.4,0,https://www.reddit.com/r/datascience/comments/13fvzkv/chatgpt_code_interpreter_is_crazy_what_next/,12,1683923026.0,"Hey folks. I was watching a couple of videos about code interpreter plug-in for chatGPT which will he available next week for plus users.

This plug-in let's you upload text/image/gif/... files to it and then will take action on them based on what you request. As an example you can upload a CSV file and ask for some visualizations, or even clustering using K-Means. There could be more to it, but I don't have my hands on yet.

I know how generative AI has been on a fast pace forward in the past couple of months, but this one actually hit me harder. To a sense that I am questioning my knowledge and usefulness for the near future. I am genuinely clueless of how and what to train myself on for the next couple of years, in order to stay useful and creative.

If you have also thought about this and have some possible ideas or thoughts about this topic, please go on and write it down. Maybe it helps me stop freaking out."
91,13gsrkv,datascience,ChatGPT,comments,2023-05-13 21:06:58,Relying too much on ChatGPT to learn DS programming?,PhisheadS1,False,0.45,0,https://www.reddit.com/r/datascience/comments/13gsrkv/relying_too_much_on_chatgpt_to_learn_ds/,11,1684012018.0,"Hello, I've been learning DS the past few months and I really enjoy it but I find the programming part (Python) quite difficult as I'm coming from a non-DS career (though I had learned SQL pretty well). 

So while doing projects I basically us ChatGPT to tell what code to write for what I want. For example I say ""For each value in the Neighborhood column, get the median home price and rank them so I can assign a numeric value instead of categorical...and while you're add it include the code to do this to the test df""...and voil√† (of course many times I will need to correct it/tinker with the code/or re-explain my request. 

So am I making a big mistake? I mean I know I'll have to learn eventually but I kinda feel like it's like teaching a child to use a calculator without teaching him to do arithmetic. Or is this just going to be the future of learning to program?"
92,13c8ewn,datascience,ChatGPT,comments,2023-05-08 23:21:30,I asked ChatGPT4 to do some stats modelling - it was okay‚Ä¶ish,AFL_gains,False,0.61,4,https://www.reddit.com/r/datascience/comments/13c8ewn/i_asked_chatgpt4_to_do_some_stats_modelling_it/,11,1683588090.0,"Hi guys ! There‚Äôs been some debate, especially on here, about the ‚Äúfuture of data science‚Äù and ‚Äúwhose job is going to be taken‚Äù etc etc. Imo I don‚Äôt know the answer, but I think LLMs have definitely changed the landscape.

One of the really interesting things ChatGPT has unlocked is that people can now code without really knowing how to. I think if you already are familiar with coding, using ChatGPT to improve productivity is awesome. But if you‚Äôre just starting out and use it generate code you can‚Äôt explain, then I think you can get into lots of trouble. 

And I think this is especially true when there‚Äôs a mathematical modelling choice aspect to your code. My thought was that just because something works / compiles, doesn‚Äôt mean it‚Äôs a very good model and doesn‚Äôt mean that the explicit choices / assumptions make sense. This, of course, isn‚Äôt chatGPTs fault, it‚Äôs the users fault for not checking! 

Anyway, to investigate this point, I recently tested ChatGPT to write a Stan code (bayesian inference ) to predict premier league matches. My feeling was that the task simple enough for it to do an okay job, but not so generic it there‚Äôs a million examples on the internet.

I put the results on YouTube (link below), but in summary I found the following: 

1. ChatGPT made a decent model, but with some really weird choices. Eg It decided to use a normal distribution to model goal differences , where I think a Skellam would have been better. It also decided not to model the variance of this distribution , instead deciding that it was 1. Super weird!

2. It wasn‚Äôt able to rationalise about things like over parameterisation. The model it build had way too many parameters, unnecessarily. The idea of parsimony wasn‚Äôt really there. Maybe with better prompts it would have, but out of the box it made the model overly complex


3. Prompt engineering really makes a difference. I think with better prompts, the model Could have been better. There was even a point where I spotted an error and prompted chatGPT to fix it and it did! But again, this all relied on me being able to read Stan code and know what was good and bad. 


For me, I learnt that at least for tasks where lots of modelling choices need to be made, humans still beat GPT. But perhaps in the future, those that win will be the data scientists/ engineers that know what they are doing but are able to prompt GPT optimally to maximise their productivity boost.



The videos are here : 
Part 1: https://m.youtube.com/watch?v=4LTUYTxKuIk&t=66s&pp=ygUTbGVhcm4gc3RhbiB3aXRoIHJpYw%3D%3D
Part 2: https://m.youtube.com/watch?v=XjQpV6c9K5g&t=1s&pp=ygUTbGVhcm4gc3RhbiB3aXRoIHJpYw%3D%3D"
93,10dfbc7,datascience,ChatGPT,comments,2023-01-16 14:02:26,Are you using ChatGPT for work?,Conscious-Rush-9646,False,0.58,2,https://www.reddit.com/r/datascience/comments/10dfbc7/are_you_using_chatgpt_for_work/,11,1673877746.0,I started using it just for some silly things like describe what this code does. I'm curios to see if anyone is actually using it on a daily basis and it's making a difference.
94,11innm2,datascience,ChatGPT,comments,2023-03-05 04:37:52,Data Science Project Help: Future Oil Purchase based on S&P500 of different countries,_CynicalCyanide,False,0.67,1,https://www.reddit.com/r/datascience/comments/11innm2/data_science_project_help_future_oil_purchase/,10,1677991072.0,"So I need to do a Data Science project where I look at the price of Oil over the last fifty years and look at the data of the Index (S&P500 and equivalent ) and predict prices of oil based on that. 

How will this data influence purchasing decisions of big companies? 

Does that make sense? I need someone to explain how to go about this, if possible. I would appreciate a roadmap very much. 

I may be completely off here but I was thinking of taking the price datapoints from the last fifty years and then using a prediction algorithm- regression. 
Correlating the Oil prices and the S&P500 value or whatever. 

I have four weeks. Is it doable? 
Can you link me to resources that might help? I jus need some clarity on how to do this. How can I ask ChatGPT to help?"
95,12sxxbq,datascience,ChatGPT,comments,2023-04-20 13:01:57,AI eating the world,xmagedo,False,0.39,0,https://www.reddit.com/r/datascience/comments/12sxxbq/ai_eating_the_world/,9,1681995717.0,"Hello, 

I hope is all well with you all. 

This post to seek some guidance and advice from professional data scientists, ML developers and big data developers. With the latest AI tech that have been automated some jobs such chatgpt and others. It feels like that my effort of studying, reading books, understanding the match in some algorithms have been useless. A lot of things have came out to automate those things, I would be afraid to open IT company nowadays just that something might come and automated this thing. My point is that, what skills should one focus on in data science and ML? I need to keep improving and keep learning but what skills ? What will make me ahead of the curve? What books do you guys recommend? 



Thank you so much"
96,123yr9p,datascience,ChatGPT,comments,2023-03-27 20:09:45,ChatGPT and made up citations,its_the_llama,False,0.67,6,https://www.reddit.com/r/datascience/comments/123yr9p/chatgpt_and_made_up_citations/,10,1679947785.0,"Hopefully this hasn't been posted here before. I was using ChatGPT to try and find a few reviews to read on parameter search strategies in system biology. Helpfully, it returned a list of seminal papers: 

 

1. ""Parameter estimation and inference for differential equations"" by P.J. Haario et al. (2006). This review article discusses various methods for parameter estimation in differential equations, including Bayesian methods, gradient-based optimization, and particle filtering.
2. ""Parameter estimation in differential equations: a Bayesian perspective"" by S. S√§rkk√§ (2013). This review article focuses on Bayesian methods for parameter estimation in differential equations, including Markov chain Monte Carlo (MCMC) methods and sequential Monte Carlo (SMC) methods.
3. ""Optimization methods for parameter estimation in nonlinear differential equation models"" by C.L. Lawson et al. (2013). This review article discusses various optimization methods for parameter estimation in nonlinear differential equation models, including gradient-based methods, genetic algorithms, and particle swarm optimization.
4. ""Parameter estimation and sensitivity analysis in computational systems biology"" by D. Ge and J.J. Liu (2019). This review article provides an overview of various methods for parameter estimation and sensitivity analysis in computational systems biology, including optimization-based methods, Bayesian methods, and global sensitivity analysis.

Great, right? Except, **none of these papers actually exist**. The authors sound similar to people in the field (""P.J. Haario is probably ""inspired"" by Heikki Haario who's well known in the field, and Simo S√§rkk√§ is an actual author who's published on this), but the work does not exist. 

In hindsight, this makes sense considering how chatGPT works. It's still pretty interesting though, and I wonder how many people have turned in college assays with completely fabricated references."
97,zkqaz5,datascience,ChatGPT,comments,2022-12-13 08:04:51,ChatGPT business use cases?,danktank138,False,0.5,0,https://www.reddit.com/r/datascience/comments/zkqaz5/chatgpt_business_use_cases/,9,1670918691.0,"What are some good business use cases that you can see the AI model show its strength?

Clear to see that the age of writing essays by trial and error is over. From now on, students have received a tool capable of impressing even the most bitter of essay snobs. But that is hardly anything to be excited for. As I am sure there are tonnes more use cases capable of becoming a full service. 

Thus, what would be some business use cases, which one could use the chatGPT for?

P.S.
I will post this question in both tech oriented and business oriented groups. After a week or two I will sum the best reposnes with my comment üòá"
98,10m8myu,datascience,ChatGPT,comments,2023-01-27 01:36:10,Is data science just not a thing really? Like not a business reality in wide use?,MrLongJeans,False,0.5,0,https://www.reddit.com/r/datascience/comments/10m8myu/is_data_science_just_not_a_thing_really_like_not/,9,1674783370.0,"I work at a company frequently cited by articles posted on the sub describing cutting edge data science.  Our data is ubiquitous in the business world. We basically work globally with just about any store or manufacturer you can think of from Proctor  & Gamble to some Australian big box store you've never heard of that is a household name down undah. We do e-commerce, marketing, brick and mortar, basically anything but financial, insurance, and real estate (i.e. Wall Street).

And I gotta say. I've seen a lot of small data companies doing sci-fi A.I. generating unbelievable insights with perfect accuracy.  And there's a lot of self-congratulatory celebration when they build Jurassic Park and count angels on a pinhead with perfect accuracy. 

But they have no customers. Brilliant data scientists making stuff no less impressive than ChatGPT but they can't find customers. All the people in the industries that they've perfectly modeled and predicted just aren't smart enough to put perfect information into action with an ROI that could justify itself on a budget with competing priorities. And those companies are filled with super competent 'lunch pail hard hat' data engineers and architects keeping the business machine running. But there's no science or high speed BigBrain stuff being done. No information generation for information sake like the 'data science' companies are doing. Just automating automatible systems. Etc. At most some basic optimization software for process improvements. 

It just seems like there's a widening gulf between business' who demand decent ROI data work that's dumbed down and the boutique data science outfits that think if their A.I. can capture 'truth' then they can sell truth in a bottle. 

But being in the business, knowing the business needs and appetites of our clients, but also working alongside data scientists in my department, and watching them do good work that they can't commercialize into a sellable product, it just seems like data science is losing relevance economically and being replaced by much more simple, 'blue collar' data engineers making sure trains run on time without needing rocket science to accomplish it."
99,zatvv4,datascience,ChatGPT,comments,2022-12-02 18:42:51,Is anyone having a total meltdown after trying out ChatGPT?,benzall,False,0.2,0,https://www.reddit.com/r/datascience/comments/zatvv4/is_anyone_having_a_total_meltdown_after_trying/,9,1670006571.0,"Like I am not able to concentrate after seeing how good it is in either explaining complex statistical concepts, or writing sql queries, python functions. Like it is going to reduce need of human data professionals by 10x in may be 5 years right?Why wouldn't it?"
100,123tx9p,datascience,ChatGPT,relevance,2023-03-27 17:25:43,Has ChatGPT killed doomers?,GreatStats4ItsCost,False,0.89,442,https://www.reddit.com/r/datascience/comments/123tx9p/has_chatgpt_killed_doomers/,90,1679937943.0,"Sorry for another ChatGPT post but I think it really is the end of asking whether certain job sectors will exist on r/DataScience due to ChatGPT making them redundant.

Whilst reading all of the 100's of doomer posts 'Will Data Science survive because ChatGPT' - it dawned on me that Chat GPT can replace all of the users creating these posts. They've all been made redundant. A simple prompt to an AI like 'Write a profoundly dumb Reddit post asking if Chat GPT has made Data Science redundant' - will return exactly that. With a simple workflow/pipeline the response from the API can be posted directly to r/DataScience. 

This really is the future and I'm worried."
101,zpraee,datascience,ChatGPT,relevance,2022-12-19 13:15:11,The real reason ChatGPT was created,xdonvanx,False,0.94,740,https://i.redd.it/g5z2t4zeuu6a1.png,73,1671455711.0,
102,10k528k,datascience,ChatGPT,relevance,2023-01-24 13:07:12,ChatGPT got 50% more marks on data science assignment than me. What‚Äôs next?,rifat_monzur,False,0.92,502,https://www.reddit.com/r/datascience/comments/10k528k/chatgpt_got_50_more_marks_on_data_science/,208,1674565632.0,"For context, in my data science master course, one of my classmate submit his assignment report using chatgpt and got almost 80%. Though, my report wasn‚Äôt the best, still bit sad, isn‚Äôt it?"
103,zgoxwa,datascience,ChatGPT,relevance,2022-12-09 06:18:39,Gaussian Processes for pirates. Courtesy of ChatGPT,Sid__darthVader,False,0.98,498,https://i.redd.it/4cs2kirjwu4a1.jpg,34,1670566719.0,
104,zwppsu,datascience,ChatGPT,relevance,2022-12-27 20:48:02,ChatGPT Extension for Jupyter Notebooks: Personal Code Assistant,Tieskeman,False,0.98,418,https://www.reddit.com/r/datascience/comments/zwppsu/chatgpt_extension_for_jupyter_notebooks_personal/,32,1672174082.0,"Hi!

I want to share a [browser extension](https://github.com/TiesdeKok/chat-gpt-jupyter-extension) that I have been working on. This extension is designed to help programmers get assistance with their code directly from within their Jupyter Notebooks, through ChatGPT.

The extension can help with code formatting (e.g., auto-comments), it can explain code snippets or errors, or you can use it to generate code based on your instructions. It's like having a personal code assistant right at your fingertips!

I find it boosts my coding productivity, and I hope you find it useful too. Give it a try, and let me know what you think!

You can find an early version here: 
https://github.com/TiesdeKok/chat-gpt-jupyter-extension"
105,10eye8i,datascience,ChatGPT,relevance,2023-01-18 04:50:28,"I asked ChatGPT to explain ROC AUC, the level of collaboration is beyond my expectation",trantrikien239,False,0.9,477,https://master-data.science/assets/images/eli5ml-meth1.jpg,78,1674017428.0,
106,122nwrk,datascience,ChatGPT,relevance,2023-03-26 14:31:39,I asked ChatGPT for the best random state value,liquidInkRocks,False,0.89,97,https://www.reddit.com/r/datascience/comments/122nwrk/i_asked_chatgpt_for_the_best_random_state_value/,36,1679841099.0,"This thing is like a student forced to write 1000 words on the topic. 

**me:**  What is a good random state value to use in general 

**Bot:**  

In machine learning, a random state is used to initialize the random number generator. The random number generator is used to shuffle the data, split the data into training and test sets, initialize the parameters of the model, and make other random decisions during training and evaluation.

Choosing a good random state value is important because it can affect the results of your model. If you use a different random state, you may get different results.

In general, there is no one ""best"" random state value to use. The value you choose depends on the specific problem you're working on and the specific data you're working with.

However, it's a good practice to set a random state to ensure reproducibility of your results. You can choose any integer value for the random state, but it's common to use numbers like 0, 42, or 2022.

It's also common to use cross-validation techniques like k-fold cross-validation, which helps to reduce the variability of your results due to different random state values."
107,10qecvo,datascience,ChatGPT,relevance,2023-01-31 23:43:50,Yann LeCun Hating on ChatGPT,MGeeeeeezy,False,0.54,3,https://www.reddit.com/r/datascience/comments/10qecvo/yann_lecun_hating_on_chatgpt/,35,1675208630.0,"Has anyone else noticed how much Yan LeCun has been hating on ChatGPT lately? I think it‚Äôs one thing to call out issues, but I have a feeling he‚Äôs trying to discredit it for business politics more than anything (Meta v. Microsoft)"
108,13futqv,datascience,ChatGPT,relevance,2023-05-12 19:37:31,Will ChatGPT kills data science jobs?,Born-Comment3359,False,0.18,0,https://www.reddit.com/r/datascience/comments/13futqv/will_chatgpt_kills_data_science_jobs/,20,1683920251.0,
109,13fu3mh,datascience,ChatGPT,relevance,2023-05-12 19:08:42,ChatGPT In Financial Economics?,nkafr,False,0.5,0,https://www.reddit.com/r/datascience/comments/13fu3mh/chatgpt_in_financial_economics/,6,1683918522.0,"I found 2 new research papers that explore Language Models in Financial Economics.

* The first one \[Hansen et al\] shows that LLMs like ChatGPT can decode **Fedspeak** better than humans financial experts and BERT-based models.
* The second one \[Lopez-Lira et al\] uses ChatGPT to formulate trading strategies based on sentiment analysis.

I am not an economics expert, but I think both of them have some limitations. For example, the second one does not consider trading costs. What do you think?

I discuss them [here](https://medium.datadriveninvestor.com/using-chatgpt-to-decode-stock-price-movements-an-academic-survey-b1b6cf2bbf0b?sk=af3bc35f39032c0e26a908d88987916f)"
110,zmye7g,datascience,ChatGPT,relevance,2022-12-15 22:34:22,Have you used ChatGPT to write code for you?,is_this_the_place,False,0.77,23,https://www.reddit.com/r/datascience/comments/zmye7g/have_you_used_chatgpt_to_write_code_for_you/,33,1671143662.0,Is so what did you ask and how did it go?
111,11lt96v,datascience,ChatGPT,relevance,2023-03-08 10:51:40,[Q] Are you wary of using ChatGPT because of sensitive data concerns?,limedove,False,0.86,36,https://www.reddit.com/r/datascience/comments/11lt96v/q_are_you_wary_of_using_chatgpt_because_of/,37,1678272700.0,
112,123yr9p,datascience,ChatGPT,relevance,2023-03-27 20:09:45,ChatGPT and made up citations,its_the_llama,False,0.69,6,https://www.reddit.com/r/datascience/comments/123yr9p/chatgpt_and_made_up_citations/,10,1679947785.0,"Hopefully this hasn't been posted here before. I was using ChatGPT to try and find a few reviews to read on parameter search strategies in system biology. Helpfully, it returned a list of seminal papers: 

 

1. ""Parameter estimation and inference for differential equations"" by P.J. Haario et al. (2006). This review article discusses various methods for parameter estimation in differential equations, including Bayesian methods, gradient-based optimization, and particle filtering.
2. ""Parameter estimation in differential equations: a Bayesian perspective"" by S. S√§rkk√§ (2013). This review article focuses on Bayesian methods for parameter estimation in differential equations, including Markov chain Monte Carlo (MCMC) methods and sequential Monte Carlo (SMC) methods.
3. ""Optimization methods for parameter estimation in nonlinear differential equation models"" by C.L. Lawson et al. (2013). This review article discusses various optimization methods for parameter estimation in nonlinear differential equation models, including gradient-based methods, genetic algorithms, and particle swarm optimization.
4. ""Parameter estimation and sensitivity analysis in computational systems biology"" by D. Ge and J.J. Liu (2019). This review article provides an overview of various methods for parameter estimation and sensitivity analysis in computational systems biology, including optimization-based methods, Bayesian methods, and global sensitivity analysis.

Great, right? Except, **none of these papers actually exist**. The authors sound similar to people in the field (""P.J. Haario is probably ""inspired"" by Heikki Haario who's well known in the field, and Simo S√§rkk√§ is an actual author who's published on this), but the work does not exist. 

In hindsight, this makes sense considering how chatGPT works. It's still pretty interesting though, and I wonder how many people have turned in college assays with completely fabricated references."
113,zejzzs,datascience,ChatGPT,relevance,2022-12-06 22:21:47,Chat_GPT,WeirdDiscipline1862,False,0.92,272,https://www.reddit.com/r/datascience/comments/zejzzs/chat_gpt/,136,1670365307.0,"This weekend millions of people rushed to check the Chat_GPT. This fueled many discussions regarding the job security of the future. People like Paul Krugman started talking about the future of job and massive job loss as the result of the AI which will be disruptive of course. And this time unless previously that the job loss was happening in the low skilled job categories, it will happen to the skilled workers. Any thoughts about what to do and how to persuade a new job specially after knowing that data analysis related jobs will be very vulnerable to AI technologies. 

‚ÄúIt's true that as AI and machine learning technologies continue to advance, they are likely to have an impact on many different fields, including data science. However, it's important to remember that while AI may automate some tasks and make certain job roles obsolete, it is also likely to create new job opportunities in areas such as AI research, development, and implementation.

In terms of what job you should pursue in the future, it's difficult to say for certain. The best thing to do is to stay up-to-date on the latest developments in AI and machine learning, and consider pursuing education and training in these areas. This will give you the skills and knowledge you need to adapt to the changing job market and take advantage of the new opportunities that are likely to arise.

It's also important to remember that there will always be a need for human expertise and creativity in many fields, including data science. So, even as AI continues to advance, there will likely still be plenty of opportunities for skilled data scientists who are able to think critically, solve complex problems, and apply their expertise to new challenges.‚Äù


This is the Chat_GPT‚Äôs answer to what to do as data scientist question. üòÄ"
114,13fvzkv,datascience,ChatGPT,relevance,2023-05-12 20:23:46,ChatGPT code interpreter is crazy! What next?,__ped,False,0.42,0,https://www.reddit.com/r/datascience/comments/13fvzkv/chatgpt_code_interpreter_is_crazy_what_next/,12,1683923026.0,"Hey folks. I was watching a couple of videos about code interpreter plug-in for chatGPT which will he available next week for plus users.

This plug-in let's you upload text/image/gif/... files to it and then will take action on them based on what you request. As an example you can upload a CSV file and ask for some visualizations, or even clustering using K-Means. There could be more to it, but I don't have my hands on yet.

I know how generative AI has been on a fast pace forward in the past couple of months, but this one actually hit me harder. To a sense that I am questioning my knowledge and usefulness for the near future. I am genuinely clueless of how and what to train myself on for the next couple of years, in order to stay useful and creative.

If you have also thought about this and have some possible ideas or thoughts about this topic, please go on and write it down. Maybe it helps me stop freaking out."
115,zkqaz5,datascience,ChatGPT,relevance,2022-12-13 08:04:51,ChatGPT business use cases?,danktank138,False,0.5,0,https://www.reddit.com/r/datascience/comments/zkqaz5/chatgpt_business_use_cases/,9,1670918691.0,"What are some good business use cases that you can see the AI model show its strength?

Clear to see that the age of writing essays by trial and error is over. From now on, students have received a tool capable of impressing even the most bitter of essay snobs. But that is hardly anything to be excited for. As I am sure there are tonnes more use cases capable of becoming a full service. 

Thus, what would be some business use cases, which one could use the chatGPT for?

P.S.
I will post this question in both tech oriented and business oriented groups. After a week or two I will sum the best reposnes with my comment üòá"
116,132cvf9,datascience,ChatGPT,relevance,2023-04-28 23:16:15,New ChatGPT features and data science,jehan_gonzales,False,0.54,1,https://www.reddit.com/r/datascience/comments/132cvf9/new_chatgpt_features_and_data_science/,5,1682723775.0,"I'm wondering what impact updates to ChatGPT will have on data science and data scientists. 

I saw a TED talk from one of the OpenAI founders. You can see it here: https://youtu.be/C_78DM8fG6E

It's mind-blowing. He shows some new features that are coming soon to ChatGPT. He asks for a meal and uses the DALL-E integration to get an image of it. He even gets a shopping order put together on Instakart. He just needs to click and the food will be delivered to his house. 

The most impressive thing was the data analysis where he uploaded a CSV and the LLM figured out what the columns referred to on its own and then asked for plots and a prediction etc. The spat out Python code that he could dive into as well. 

It sounds like it could do data cleaning, preprocessing and modelling fairly easily. It would take some iterations, but if you have it the right direction, it would speed up the process 10x or more. 

I think this will basically simplify work for data scientists but will also enable ordinary folks with no quant backgrounds to do sophisticated analysis. 

I'm no longer a data scientist and work in product management. But if I were still in data science, I'd focus on my ability to help people self serve. I think the role will split to expert data scientists who build and productionise ML models and analytics enablers who help people get more out of the tools. 

What do you think? Is this a threat to data scientists? Or is it a productivity booster that will only make life better?"
117,10dfbc7,datascience,ChatGPT,relevance,2023-01-16 14:02:26,Are you using ChatGPT for work?,Conscious-Rush-9646,False,0.64,3,https://www.reddit.com/r/datascience/comments/10dfbc7/are_you_using_chatgpt_for_work/,11,1673877746.0,I started using it just for some silly things like describe what this code does. I'm curios to see if anyone is actually using it on a daily basis and it's making a difference.
118,13gsrkv,datascience,ChatGPT,relevance,2023-05-13 21:06:58,Relying too much on ChatGPT to learn DS programming?,PhisheadS1,False,0.44,0,https://www.reddit.com/r/datascience/comments/13gsrkv/relying_too_much_on_chatgpt_to_learn_ds/,11,1684012018.0,"Hello, I've been learning DS the past few months and I really enjoy it but I find the programming part (Python) quite difficult as I'm coming from a non-DS career (though I had learned SQL pretty well). 

So while doing projects I basically us ChatGPT to tell what code to write for what I want. For example I say ""For each value in the Neighborhood column, get the median home price and rank them so I can assign a numeric value instead of categorical...and while you're add it include the code to do this to the test df""...and voil√† (of course many times I will need to correct it/tinker with the code/or re-explain my request. 

So am I making a big mistake? I mean I know I'll have to learn eventually but I kinda feel like it's like teaching a child to use a calculator without teaching him to do arithmetic. Or is this just going to be the future of learning to program?"
119,137xo27,datascience,ChatGPT,relevance,2023-05-04 19:42:30,"""The new ChatGPT Code Interpreter is like a Data Scientist on steroids""",datasciencepro,False,0.42,0,https://twitter.com/moritzkremb/status/1654107314528612355,23,1683229350.0,
120,1360rt3,datascience,ChatGPT,relevance,2023-05-02 21:24:46,processing internet data best practice and chatGPT,SomeProfessional,False,0.5,0,https://www.reddit.com/r/datascience/comments/1360rt3/processing_internet_data_best_practice_and_chatgpt/,1,1683062686.0,"Hi, anyone here has had to collect data from the internet and analyze it as part of their jobs. Do you have to constantly going through a lot of websites to find information?

Have you try chatGPT for this purpose? If so, what is your experience?

I developed a tool to automate that process using chatGPT but not sure if it will be useful for anyone?"
121,11yh9t1,datascience,ChatGPT,relevance,2023-03-22 12:16:40,New version of SmartyGPT with ChatGPT and GPT4!,usc-ur,False,0.29,0,https://www.reddit.com/r/datascience/comments/11yh9t1/new_version_of_smartygpt_with_chatgpt_and_gpt4/,0,1679487400.0,[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)
122,127qs9h,datascience,ChatGPT,relevance,2023-03-31 16:26:16,ChatGPT Survey: Performance on NLP datasets,matus_pikuliak,False,0.57,1,https://www.reddit.com/r/datascience/comments/127qs9h/chatgpt_survey_performance_on_nlp_datasets/,0,1680279976.0,"I've done a paper survey of how well ChatGPT performs on various NLP tasks as reported in arXiv papers. I have found 19 papers where they compared ChatGPT with fine-tuned models, but they are being published practically daily now. It seems that for the most of the classical NLP tasks, ChatGPT is not actually that strong and smaller fine-tuned models are often much better. According to the API page, GPT-4 is not expected to be much stronger on tasks like these. I think it is an interesting perspective that shows that for many of the tasks we need to solve, GPT models are actually not the right tool.

The full survey is in my blog post: [http://opensamizdat.com/posts/chatgpt\_survey/](http://opensamizdat.com/posts/chatgpt_survey/)

Any feedback is welcomed."
123,12oiyni,datascience,ChatGPT,relevance,2023-04-16 17:57:00,Challenge: Use data science to predict ChatGPT failures,Neurosymbolic,False,0.66,8,https://www.reddit.com/r/datascience/comments/12oiyni/challenge_use_data_science_to_predict_chatgpt/,2,1681667820.0,"Last month, at the AAAI-MAKE conference, we introduced a new challenge problem: predict the failures of ChatGPT when solving math problems.

We have compiled a dataset (based on DRAW-1K) that consists of 1,000 math problem and ChatGPT's response.  We introduced some baseline models at AAAI-MAKE that showed you can predict ChatGPT's failures, we are asking the community to improve on the results.  No need to write a ChatGPT app or anything like that - you can use pure data science techniques.

The challenge results will be due in early 2024 and presented at AAAI-MAKE next year.  You can pre-register here: [https://www.aaai-make.info/next/](https://www.aaai-make.info/next/)

To learn more about the challenge, visit this website: [https://neurosymbolic.asu.edu/chatgpt-mwp-challenge/](https://neurosymbolic.asu.edu/chatgpt-mwp-challenge/)"
124,10e1uxn,datascience,ChatGPT,relevance,2023-01-17 03:43:04,How ChatGPT Completely Changes Data Parsing,1dolinski,False,0.67,1,https://vibehut.io/watch/63c5ea59ba3ef10015378e28,1,1673926984.0,
125,109r7lq,datascience,ChatGPT,relevance,2023-01-12 05:18:31,How to explain ChatGPT to laypeople / executives?,prawmlhandson,False,0.38,0,https://www.reddit.com/r/datascience/comments/109r7lq/how_to_explain_chatgpt_to_laypeople_executives/,5,1673500711.0,What's the best approach to explain how ChatGPT **works** to high level executives who are not aware of machine learning? Do you talk about how it is essentially doing next word prediction etc? Do you talk about how it was trained? Are there any good resources I can refer to?
126,1361tl0,datascience,ChatGPT,relevance,2023-05-02 22:03:30,127 ChatGPT prompts to 10x your data team's productivity,castor-metadata,False,0.25,0,https://www.reddit.com/r/datascience/comments/1361tl0/127_chatgpt_prompts_to_10x_your_data_teams/,0,1683065010.0,"&#x200B;

[chatgpt data prompts](https://preview.redd.it/ggj6376nqhxa1.png?width=446&format=png&auto=webp&s=0982a03f4911f5e02fe7ec8705b3e7bb6fefa51d)

if you're not leveraging GenAI technologies to write better code, design smarter data pipelines & generate documentation automatically, you are falling behind.  


This leaves opportunities to your competition to do better. If you are:  
\- data engineer  
\- data scientist  
\- data analyst  
\- head of data  
\- analytics engineer  
\- data governance  


Check this out. It will help you:  
\- Focus on high value tasks  
\- Produce higher quality work  
\- Be more productive  
[https://notion.castordoc.com/gpt-prompts](https://notion.castordoc.com/gpt-prompts)  


Have other first-hand experience to leverage ChatGPT to improve data workflows? please add in comments"
127,zi11jn,datascience,ChatGPT,relevance,2022-12-10 19:26:15,The code that ChatGPT can't write,philosophicalhacker,False,0.6,1,https://datachimp.app/blog/the-code-chat-gpt-cant-write,1,1670700375.0,
128,137fijm,datascience,ChatGPT,relevance,2023-05-04 09:33:40,Excuse me if this has been asked before but isn‚Äôt ChatGPT going to make this entire field redundant?,data_tryingtist,False,0.21,0,https://www.reddit.com/r/datascience/comments/137fijm/excuse_me_if_this_has_been_asked_before_but_isnt/,30,1683192820.0,"I‚Äôm halfway through a certification in Data Science, and after trying ChatGPT out for a week or two I am suddenly unable to convince myself that it‚Äôs worth becoming certified in this field when AI is going to take all of the jobs. 

Anyone have any thoughts on this? Should I even bother completing the cert?"
129,12in1vt,datascience,ChatGPT,relevance,2023-04-11 15:16:46,Open source libraries for ChatGPT to SQL data analysis?,adunk40,False,0.4,0,/r/dataanalysis/comments/12imui2/open_source_libraries_for_chatgpt_to_sql_data/,0,1681226206.0,
130,zcmlp0,datascience,ChatGPT,relevance,2022-12-04 21:39:24,Unofficial Python SDK for OpenAI's ChatGPT,brunneis,False,0.83,14,https://github.com/labteral/chatgpt-python,1,1670189964.0,
131,zo2pj1,datascience,ChatGPT,relevance,2022-12-17 09:31:36,Was ChatGPT trained on Kaggle and other DS coding platforms?,ikke89,False,0.5,0,https://www.reddit.com/r/datascience/comments/zo2pj1/was_chatgpt_trained_on_kaggle_and_other_ds_coding/,5,1671269496.0,"Hey everyone, does anyone know if chatGPT has been trained on Kaggle projects? If so, it should already be pretty good at a lot of DS stuff, right?

If not, I think it's only a matter of time before they will include that, which could create a very powerful DS personal assistant.

I guess it could be challenging to train it on large datasets specifically, but I'm sure there are some smart ways to make that part more efficient, like only using a sample of each data set. Plus, there is the legal question if Kaggle would allow openAI to use their data.

Do you guys have any thoughts?"
132,10nqco3,datascience,ChatGPT,relevance,2023-01-28 21:40:26,Creating Real-World AI Models by Newbies With ChatGPT,xrl9,False,0.33,0,https://xrl1.sh/posts/coordinates-model-with-ChatGPT/,0,1674942026.0,
133,12iz8n5,datascience,ChatGPT,relevance,2023-04-11 21:58:37,Five Reasons Why ChatGPT and Other AI Tools Will Never Fully Replace Developers,Asleep-Organization7,False,0.22,0,https://www.reddit.com/r/datascience/comments/12iz8n5/five_reasons_why_chatgpt_and_other_ai_tools_will/,4,1681250317.0,"Hello everyone, 
This is my opinion about the drama ""We are going to be Replaced by ChatGPT"" ü§™ 
You will see I have valid reasons here! 
https://link.medium.com/yo3WJX7aVyb"
134,13ihi3s,datascience,ChatGPT,relevance,2023-05-15 19:18:51,Connecting forecasting models to ChatGPT to make auto iterations to an investment portfolio,BenGlobalPredictions,False,0.45,0,https://twitter.com/alexharm/status/1658131209912983552,0,1684178331.0,
135,1168sew,datascience,ChatGPT,relevance,2023-02-19 12:06:24,"Google's Response To OpenAI and ChatGPT is Coming, And They've Named It...",Kolownik,False,0.1,0,https://www.technews.city/2023/02/googles-response-to-openai-and-chatgpt.html?=read,5,1676808384.0,
136,zcbvqf,datascience,ChatGPT,relevance,2022-12-04 15:01:28,OpenAI ChatGPT and DaVinci-003 experiments by me,Opitmus_Prime,False,0.33,0,https://www.reddit.com/r/datascience/comments/zcbvqf/openai_chatgpt_and_davinci003_experiments_by_me/,0,1670166088.0,"I did some experiments with both chatGPI and GPT-3 davinci release 003. The answers by AI are really impressive! Give it a read 

[https://ithinkbot.com/openai-debuts-chatgpt-50dd611278a4](https://ithinkbot.com/openai-debuts-chatgpt-50dd611278a4)

[https://pub.towardsai.net/openai-just-released-gpt-3-text-davinci-003-i-compared-it-with-002-the-results-are-impressive-dced9aed0cba](https://pub.towardsai.net/openai-just-released-gpt-3-text-davinci-003-i-compared-it-with-002-the-results-are-impressive-dced9aed0cba)"
137,125ulc9,datascience,ChatGPT,relevance,2023-03-29 17:28:26,Tutorial on how to generate synthetic text based on real named entities using ChatGPT,EliotRandals1,False,0.67,1,/r/nlpclass/comments/125ukk3/tutorial_on_how_to_generate_synthetic_text_based/,0,1680110906.0,
138,10a7kq4,datascience,ChatGPT,relevance,2023-01-12 19:01:24,I wrote up a guide showing how to do Data Science with ChatGPT.,Own-Anteater4164,False,0.83,276,https://www.reddit.com/r/datascience/comments/10a7kq4/i_wrote_up_a_guide_showing_how_to_do_data_science/,93,1673550084.0,"Just recently, I wrote up a guide on how to use [ChatGPT to build a website with Replit](https://buildspace.so/notes/chatgpt-replit-website?utm_source=r).

Got some pretty good responses, so I decided to write + document more of the applications I'm discovering.

**I'm actually really excited about this one, since I was in a graduate program for statistics.**

[Here's the guide](https://buildspace.so/notes/chatgpt-data-science?utm_source=r) for doing data sci with ChatGPT

The tl;dr is that I show you some of the crazy data sci stuff ChatGPT can do:

\- Read and analyze raw CSV data. I just had to copy and paste.

\- It could tell what kind of data you're feeding it judging by the header columns!

\- It will give you the python/r code on how to run specific analysis.

\- It even knew how to use scikit-learn to run regression models ü§Ø (I mean, this makes sense since it's an AI tool lol).

Honestly, this is just crazy to me.

**Before I dropped out of graduate school for statistics, I often consulted non-technical researchers in the social sciences. It was always a pain for them to run datasets by themselves just to get some answers to their questions.**

Although ChatGPT isn't perfect (and does make mistakes), it's crazy where the tool is going.

I think this is really good news for a lot of people who are interested in doing research, but might feel too intimidated by needing to do stats. Obvi...some bad stuff could come from it. We'll see!

https://preview.redd.it/ggd96gyhnnba1.png?width=619&format=png&auto=webp&s=5aa2f39199bb0ce56518e2972e0ec8a36ccbb69d"
139,114zcik,datascience,ChatGPT,relevance,2023-02-17 22:19:56,"What is something ChatGPT (or any LLM) could do, that it can‚Äôt currently, that would actually worry you about the future of data science?",cjrook,False,0.44,0,https://www.reddit.com/r/datascience/comments/114zcik/what_is_something_chatgpt_or_any_llm_could_do/,26,1676672396.0,"Lately on this sub there have been many ‚Äúsky is falling‚Äù posts related to ChatGPT. Most of the posts have drastically overestimated ChatGPT‚Äôs current use cases in the industry. What is a capability that if ChatGPT could do it, you would actually worry about the future of the data science field? More specifically worried about mass job loss within the field, if you foresee that."
140,10eb3h1,datascience,ChatGPT,relevance,2023-01-17 12:29:42,"Preparing for DS job interviews, thought to ask ChatGPT for help. I'm impressed!! :)",secret_4ever13,False,0.27,0,https://www.reddit.com/r/datascience/comments/10eb3h1/preparing_for_ds_job_interviews_thought_to_ask/,0,1673958582.0,"&#x200B;

&#x200B;

https://preview.redd.it/8vp545tqklca1.png?width=1245&format=png&auto=webp&s=5badb6cd2903e0aabe7fd544444f5ea147dfa7bc"
141,zctt5l,datascience,ChatGPT,relevance,2022-12-05 02:15:29,[D] Thread: Top 10 ways you can use ChatGPT for Music related stuff,dicklesworth,False,0.33,0,/r/MachineLearning/comments/zctiu3/d_thread_top_10_ways_you_can_use_chatgpt_for/,0,1670206529.0,
142,1383q4f,datascience,ChatGPT,relevance,2023-05-04 23:29:01,Can ChatGPT help choose a model if you describe your data to it? Has anyone tried it yet? (keyword: help),metalhead_nerd,False,0.2,0,https://www.reddit.com/r/datascience/comments/1383q4f/can_chatgpt_help_choose_a_model_if_you_describe/,3,1683242941.0,
143,126id1o,datascience,ChatGPT,relevance,2023-03-30 10:10:02,Save all your conversations via scraping with python and chatGPT Frontend API (no apikey needed) [ GitHub - rodolflying/GPT_scraper ] https://github.com/rodolflying/GPT_scraper,Rodolflying,False,0.67,1,https://www.reddit.com/gallery/126gr0p,0,1680171002.0,
144,13a4wtf,datascience,ChatGPT,relevance,2023-05-06 22:52:26,"ChatGPT Code Interpreter customer segmentation workflow demo: Data description, feature selection, preprocessing, clustering, fine-tuning, interpretation and market strategy (5:12 video)",datasciencepro,False,0.78,12,https://twitter.com/aakashg0/status/1654703707869822976/video/1,3,1683413546.0,
145,11vdjat,datascience,ChatGPT,relevance,2023-03-19 06:27:43,datasetGPT - A command-line tool to generate datasets by inferencing LLMs at scale. It can even make two ChatGPT agents talk with one another.,radi-cho,False,0.67,2,https://www.reddit.com/r/datascience/comments/11vdjat/datasetgpt_a_commandline_tool_to_generate/,0,1679207263.0,"GitHub: [https://github.com/radi-cho/datasetGPT](https://github.com/radi-cho/datasetGPT)

It can generate texts by varying input parameters and using multiple backends. But, personally, the conversations dataset generation is my favorite: It can produce dialogues between two ChatGPT agents.

Possible use cases may include:

* Constructing textual corpora to train/fine-tune detectors for content written by AI.
* Collecting datasets of LLM-produced conversations for research purposes, analysis of AI performance/impact/ethics, etc.
* Automating a task that a LLM can handle over big amounts of input texts. For example, using GPT-3 to summarize 1000 paragraphs with a single CLI command.
* Leveraging APIs of especially big LLMs to produce diverse texts for a specific task and then fine-tune a smaller model with them.

What would you use it for?"
146,13gco47,datascience,ChatGPT,relevance,2023-05-13 09:22:08,Why isn't ChatGPT just carry a state on the context of conversation instead of having to pass all previous messages every time?,Grgsz,False,0.33,0,https://www.reddit.com/r/datascience/comments/13gco47/why_isnt_chatgpt_just_carry_a_state_on_the/,0,1683969728.0,"I get it to some extent, they can charge more money if they charge for the same message as many times as you post a new one, but I have a feeling it may be much more effective if it would have a context state like in recurrent neural networks."
147,zcgpbp,datascience,ChatGPT,relevance,2022-12-04 18:05:07,What do you guys think of OpenAI‚Äôs ChatGPT?,Loud_Ad_6272,False,0.95,56,https://www.reddit.com/r/datascience/comments/zcgpbp/what_do_you_guys_think_of_openais_chatgpt/,77,1670177107.0,"As the title goes, what do you guys think of this and what effect do you think it would have on the discipline and field going forward?"
148,1162ssq,datascience,ChatGPT,relevance,2023-02-19 05:43:37,Buzz around new Deep Learning Models and Incorrect Usage of them.,brokened00,False,0.94,187,https://www.reddit.com/r/datascience/comments/1162ssq/buzz_around_new_deep_learning_models_and/,100,1676785417.0," In my job as a data scientist, I use deep learning models regularly to classify a lot of textual data (mostly transformer models like BERT finetuned for the needs of the company). Sentiment analysis and topic classification are the two most common natural language processing tasks that I perform, or rather, that is performed downstream in a pipeline that I am building for a company. 

The other day someone high up (with no technical knowledge) was telling me, during a meeting, that we should be harnessing the power of ChatGPT to perform sentiment analysis and do other various data analysis tasks, noting that it should be a particularly powerful tool to analyze large volumes of data coming in (both in sentiment analysis and in querying and summarizing data tables). I mentioned that the tools we are currently using are more specialized for our analysis needs than this chat bot. They pushed back, insisting that ChatGPT is the way to go for data analysis and that I'm not doing my due diligence. I feel that AI becoming a topic of mainstream interest is emboldening people to speak confidently on it when they have no education or experience in the field. 

After just a few minutes playing around with ChatGPT, I was able to get it to give me a wrong answer to a VERY EASY question (see below for the transcript). It spoke so confidently in it's answer, even going as far as to provide a formula, which it basically abandoned in practice. Then, when I pointed out it's mistake, it corrected the answer to another wrong one. 

The point of this long post was to point out that AI tool have their uses, but they should not be given the benefit of the doubt in every scenario, simply due to hype. If a model is to be used for a specific task, it should be rigorously tested and benchmarked before replacing more thoroughly proven methods.

ChatGPT is a really promising chat bot and it can definitely seem knowledgeable about a wide range of topics, since it was trained on basically the entire internet, but I wouldn't trust it to do something that  a simple pandas query could accomplish. Nor would I use it to perform sentiment analysis when there are a million other transformer models that were specifically trained to predict sentiment labels and were rigorously evaluated on industry standard benchmarks (like GLUE).

https://preview.redd.it/sz3ejc1313ja1.png?width=1700&format=png&auto=webp&s=76c48939903f8d34810000d1a71cb25f86237130"
149,10m3nlu,datascience,ChatGPT,relevance,2023-01-26 21:53:10,"If Condon can be found to commit plagiarism in his work in The Manchurian Candidate, everything ChatGPT produces is plagiarism",renok_archnmy,False,0.25,0,https://www.reddit.com/r/datascience/comments/10m3nlu/if_condon_can_be_found_to_commit_plagiarism_in/,0,1674769990.0,https://www.sfgate.com/entertainment/article/Has-a-local-software-engineer-unmasked-The-2572225.php
150,11skvpf,datascience,ChatGPT,relevance,2023-03-16 05:10:41,"When hiring, how would you react if a candidate data scientist used ChatGPT heavily throughout a technical interview/coding session, but did a great job communicating what they were doing and why?",MyNotWittyHandle,False,0.5,0,https://www.reddit.com/r/datascience/comments/11skvpf/when_hiring_how_would_you_react_if_a_candidate/,21,1678943441.0,"It is the stack-overflow of 2023 and beyond, and will only get better.

Would you penalize a candidate for using a resource like ChatGPT?  Specifically if it made them more efficient, and were able to solve more problems in the same amount of time as someone who used more traditional resources (stack-overflow, google, etc.)

EDIT: to clarify, I want to emphasize my point above where in this case, the candidate needs to be able to describe what they are doing, why it works, pros and cons vs other approaches, etc.  I‚Äôm also assuming if they have gotten to the point of an in-person coding technical interview, they have already passed prior interview steps where they have demonstrated foundational knowledge of the field.

Additionally, if you are in the role of hiring and you haven‚Äôt deeply probed the capacity of ChatGPT to write effective code given an appropriate prompt, I‚Äôd say that is step 1."
151,zvsc8h,datascience,ChatGPT,relevance,2022-12-26 17:43:47,Chat GPT taking over,BlackLotus8888,False,0.4,0,https://www.reddit.com/r/datascience/comments/zvsc8h/chat_gpt_taking_over/,29,1672076627.0,"Have y'all tried using chat GPT?  It's ridiculous!

1) I asked it to write a definition that takes in a df, imputes missing values, and returns a df and boom!

2) do t like the model it used, just ask it to use a different model

3) need cross validation?  No problem.  

4) need to get data using xx API?  You got it!  

It can do anything.  You just need to talk to it to get it right."
152,125fd6p,datascience,ChatGPT,relevance,2023-03-29 06:33:08,[D] Very good article about the current limitations of GPT-n models,fripperML,False,0.98,236,https://www.reddit.com/r/datascience/comments/125fd6p/d_very_good_article_about_the_current_limitations/,95,1680071588.0,"I count myself among the people that are amazed of what those models can do and how they can impact our society.

However, it's very important to understand that they are not magical solutions for every problem and that they cannot reason at all.

[ChatGPT as a query engine on a giant corpus of text ‚Äì r y x, r (ryxcommar.com)](https://ryxcommar.com/2023/03/28/chatgpt-as-a-query-engine-on-a-giant-corpus-of-text/)

What is more impressing is that, given this mental model of ChatGPT as a giant query engine, how can it perform activities that involve creativity outside of his training data? Like, for example, writing a poem in the style of Shakespeare about the proof that there are infinite prime numbers? Surely there are no examples of that in the training data! My answer would be that for some tasks interpolation works well (you can somehow get something meaningful by interpolating known stylistic elements and known semantical elements into something ""new""). But when the task is more symbolic or discrete, instead of interpolative, like true reasoning, and there are no examples to retrieve an answer from, the system has a much harder time.

That is, I am alligned with F. Chollet views on this:

[Fran√ßois Chollet en Twitter: ""You can retrieve not just what was seen at training time, but arbitrary combinations of it. It's an interpolative database and program store, with a natural language interface. https://t.co/2mv2gnI3oM"" / Twitter](https://twitter.com/fchollet/status/1637122108357738496)

[Fran√ßois Chollet en Twitter: ""This paper has the right idea: use symbolic logic for discrete reasoning and lean on deep learning models for perception and common-sense intuition. https://t.co/9lP8eDZKkO I expect to see a lot more progress along these lines in the coming months / years."" / Twitter](https://twitter.com/fchollet/status/1636838039703126016)"
153,12avx58,datascience,ChatGPT,relevance,2023-04-03 20:01:07,Has ChatGPT/AI changed anything about your career as a data scientist?,NavidsonsCloset,False,0.54,2,https://www.reddit.com/r/datascience/comments/12avx58/has_chatgptai_changed_anything_about_your_career/,30,1680552067.0,
154,11sp0yn,datascience,ChatGPT,relevance,2023-03-16 09:21:40,Smarty-GPT: library of prompts/contexts (connected with Awesome Prompts Chat GPT),usc-ur,False,0.57,1,https://www.reddit.com/r/datascience/comments/11sp0yn/smartygpt_library_of_promptscontexts_connected/,1,1678958500.0,"This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers in a **TRANSPARENT** way to end users.

[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)"
155,13ec41m,datascience,ChatGPT,relevance,2023-05-11 03:43:05,I built a tool to analyze CSVs with ChatGPT!,Gbox4,False,0.43,0,https://v.redd.it/acmm2b1oi4za1,4,1683776585.0,
156,10p9ffb,datascience,ChatGPT,relevance,2023-01-30 18:05:19,Code Nuts and Bolts of Chat GPT,dj_ski_mask,False,0.5,0,https://www.reddit.com/r/datascience/comments/10p9ffb/code_nuts_and_bolts_of_chat_gpt/,3,1675101919.0,"Yo first up I am sorry for YACGPTT (yet another Chat GPT Thread). This is a question about leaning resources.

For some context I did the Coursera NLP Cert a few years ago and really enjoyed it. And it does, in very good detail, hit on the nuts and bolts of manually coding transformer architecture (the ‚ÄòT‚Äô) . 

But like I said it‚Äôs a few years old and I‚Äôm looking for resources on the combination of reinforcement learning + transformer architecture.

Again,  but nuts and bolts I mean code heavy manual demonstrations of how to construct the architecture.

Thanks in advance and if you think I should delete and post in r/learnmachinelearning I will do."
157,zy1brw,datascience,ChatGPT,relevance,2022-12-29 09:38:58,Adding Chat GPT to RStudio with the GPT Studio add-in package,DrLyndonWalker,False,0.75,6,https://www.reddit.com/r/datascience/comments/zy1brw/adding_chat_gpt_to_rstudio_with_the_gpt_studio/,0,1672306738.0,"You can now add the incredible functionality of Chat GPT (including writing text and code) to RStudio using the GPT Studio package. In this video I cover the steps for setting up GPT Studio and then try some basic operations including spell correction and code writing. As I demonstrated in my recent RTutor video, Chat GPT is a game-changer. It can write code and text with a scary degree of precision. 

[https://youtu.be/QQfDTLExoNU](https://youtu.be/QQfDTLExoNU)"
158,z9ba36,datascience,ChatGPT,relevance,2022-12-01 02:21:12,OpenAI debuts ChatGPT: a conversational AI on GPT-3.5,Opitmus_Prime,False,0.6,1,https://ithinkbot.com/openai-debuts-chatgpt-50dd611278a4,0,1669861272.0,
159,13c8ewn,datascience,ChatGPT,relevance,2023-05-08 23:21:30,I asked ChatGPT4 to do some stats modelling - it was okay‚Ä¶ish,AFL_gains,False,0.61,4,https://www.reddit.com/r/datascience/comments/13c8ewn/i_asked_chatgpt4_to_do_some_stats_modelling_it/,11,1683588090.0,"Hi guys ! There‚Äôs been some debate, especially on here, about the ‚Äúfuture of data science‚Äù and ‚Äúwhose job is going to be taken‚Äù etc etc. Imo I don‚Äôt know the answer, but I think LLMs have definitely changed the landscape.

One of the really interesting things ChatGPT has unlocked is that people can now code without really knowing how to. I think if you already are familiar with coding, using ChatGPT to improve productivity is awesome. But if you‚Äôre just starting out and use it generate code you can‚Äôt explain, then I think you can get into lots of trouble. 

And I think this is especially true when there‚Äôs a mathematical modelling choice aspect to your code. My thought was that just because something works / compiles, doesn‚Äôt mean it‚Äôs a very good model and doesn‚Äôt mean that the explicit choices / assumptions make sense. This, of course, isn‚Äôt chatGPTs fault, it‚Äôs the users fault for not checking! 

Anyway, to investigate this point, I recently tested ChatGPT to write a Stan code (bayesian inference ) to predict premier league matches. My feeling was that the task simple enough for it to do an okay job, but not so generic it there‚Äôs a million examples on the internet.

I put the results on YouTube (link below), but in summary I found the following: 

1. ChatGPT made a decent model, but with some really weird choices. Eg It decided to use a normal distribution to model goal differences , where I think a Skellam would have been better. It also decided not to model the variance of this distribution , instead deciding that it was 1. Super weird!

2. It wasn‚Äôt able to rationalise about things like over parameterisation. The model it build had way too many parameters, unnecessarily. The idea of parsimony wasn‚Äôt really there. Maybe with better prompts it would have, but out of the box it made the model overly complex


3. Prompt engineering really makes a difference. I think with better prompts, the model Could have been better. There was even a point where I spotted an error and prompted chatGPT to fix it and it did! But again, this all relied on me being able to read Stan code and know what was good and bad. 


For me, I learnt that at least for tasks where lots of modelling choices need to be made, humans still beat GPT. But perhaps in the future, those that win will be the data scientists/ engineers that know what they are doing but are able to prompt GPT optimally to maximise their productivity boost.



The videos are here : 
Part 1: https://m.youtube.com/watch?v=4LTUYTxKuIk&t=66s&pp=ygUTbGVhcm4gc3RhbiB3aXRoIHJpYw%3D%3D
Part 2: https://m.youtube.com/watch?v=XjQpV6c9K5g&t=1s&pp=ygUTbGVhcm4gc3RhbiB3aXRoIHJpYw%3D%3D"
160,119q4sz,datascience,ChatGPT,relevance,2023-02-23 05:59:16,Pre-processing data to assemble in a database to try to apply GPT2 to it,marcus_samuelson,False,0.5,0,https://www.reddit.com/r/datascience/comments/119q4sz/preprocessing_data_to_assemble_in_a_database_to/,5,1677131956.0,"I haven't programmed in close to 20 years but just picked it back up. ChatGPT and Github Copilot have made it shockingly easy to figure out how to build things, pick up new languages, and efficiently leverage prebuilt libraries.

My current project is trying to use my own data source to feed into a GPT model. I've now got all my data cleansed, processed, loaded in a DB, and tokenized.

The question I have is what is the next step? I was under the impression I could use ChatGPT API to leverage their model with my data and it would be useful... but it seems all you can really do is fine tune ChatGPT so it gives more relevant answers to your prompt? Is that correct?

My project is to use about 5,000 pages of press conference (within my industry) transcripts to create a conversational querying functionality with ChatGPT like dynamism.

So could ask something like ""what was the most common product launched in 2019"". ""What were some of the companies that launched X product and what were the main features they were highlighting for the consumer?"""
