,id,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,url,num_comments,created,body
0,11sboh1,MachineLearning,Open-AI,top,2023-03-15 22:34:01,[D] Our community must get serious about opposing OpenAI,SOCSChamp,False,0.95,2965,https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/,448,1678919641.0,"OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.

They have abandoned this idea entirely.

Today, with the release of GPT4 and their direct statement that they will not release details of the model creation due to ""safety concerns"" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.

AI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.

I get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.

We need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.

This conversation will only ever get more important."
1,12nbixk,MachineLearning,Open-AI,top,2023-04-15 17:14:58,[P] OpenAssistant - The world's largest open-source replication of ChatGPT,ykilcher,False,0.97,1271,https://www.reddit.com/r/MachineLearning/comments/12nbixk/p_openassistant_the_worlds_largest_opensource/,175,1681578898.0,"We’re excited to announce the release of OpenAssistant.

The future of AI development depends heavily on high quality datasets and models being made publicly available, and that’s exactly what this project does.

Watch the annoucement video:

[https://youtu.be/ddG2fM9i4Kk](https://youtu.be/ddG2fM9i4Kk)

&#x200B;

Our team has worked tirelessly over the past several months collecting large amounts of text-based input and feedback to create an incredibly diverse and unique dataset designed specifically for training language models or other AI applications.

With over 600k human-generated data points covering a wide range of topics and styles of writing, our dataset will be an invaluable tool for any developer looking to create state-of-the-art instruction models!

To make things even better, we are making this entire dataset free and accessible to all who wish to use it. Check it out today at our HF org: OpenAssistant

On top of that, we've trained very powerful models that you can try right now at: [open-assistant.io/chat](https://open-assistant.io/chat) !"
2,137rxgw,MachineLearning,Open-AI,top,2023-05-04 16:13:30,"[D] Google ""We Have No Moat, And Neither Does OpenAI"": Leaked Internal Google Document Claims Open Source AI Will Outcompete Google and OpenAI",hardmaru,False,0.98,1174,https://www.semianalysis.com/p/google-we-have-no-moat-and-neither,206,1683216810.0,
3,124eyso,MachineLearning,Open-AI,top,2023-03-28 05:57:03,[N] OpenAI may have benchmarked GPT-4’s coding ability on it’s own training data,Balance-,False,0.97,998,https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/,135,1679983023.0,"[GPT-4 and professional benchmarks: the wrong answer to the wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks)

*OpenAI may have tested on the training data. Besides, human benchmarks are meaningless for bots.*

 **Problem 1: training data contamination**

To benchmark GPT-4’s coding ability, OpenAI evaluated it on problems from Codeforces, a website that hosts coding competitions. Surprisingly, Horace He pointed out that GPT-4 solved 10/10 pre-2021 problems and 0/10 recent problems in the easy category. The training data cutoff for GPT-4 is September 2021. This strongly suggests that the model is able to memorize solutions from its training set — or at least partly memorize them, enough that it can fill in what it can’t recall.

As further evidence for this hypothesis, we tested it on Codeforces problems from different times in 2021. We found that it could regularly solve problems in the easy category before September 5, but none of the problems after September 12.

In fact, we can definitively show that it has memorized problems in its training set: when prompted with the title of a Codeforces problem, GPT-4 includes a link to the exact contest where the problem appears (and the round number is almost correct: it is off by one). Note that GPT-4 cannot access the Internet, so memorization is the only explanation."
4,12rxtjj,MachineLearning,Open-AI,top,2023-04-19 15:29:34,"[N] Stability AI announce their open-source language model, StableLM",Philpax,False,0.99,831,https://www.reddit.com/r/MachineLearning/comments/12rxtjj/n_stability_ai_announce_their_opensource_language/,182,1681918174.0,"Repo: https://github.com/stability-AI/stableLM/

Excerpt from the Discord announcement:

> We’re incredibly excited to announce the launch of StableLM-Alpha; a nice and sparkly newly released open-sourced language model! Developers, researchers, and curious hobbyists alike can freely inspect, use, and adapt our StableLM base models for commercial and or research purposes! *Excited yet?*
>
> Let’s talk about parameters! The Alpha version of the model is available in 3 billion and 7 billion parameters, with 15 billion to 65 billion parameter models to follow. StableLM is trained on a new experimental dataset built on “The Pile” from EleutherAI (a 825GiB diverse, open source language modeling data set that consists of 22 smaller, high quality datasets combined together!) The richness of this dataset gives StableLM surprisingly high performance in conversational and coding tasks, despite its small size of 3-7 billion parameters."
5,139yc73,MachineLearning,Open-AI,top,2023-05-06 18:41:02,[R][P] I made an app for Instant Image/Text to 3D using ShapE from OpenAI,perception-eng,False,0.96,806,https://i.redd.it/1j4h1oyda9ya1.gif,63,1683398462.0,
6,12zclus,MachineLearning,Open-AI,top,2023-04-26 09:56:04,"[D] Google researchers achieve performance breakthrough, rendering Stable Diffusion images in sub-12 seconds on a mobile phone. Generative AI models running on your mobile phone is nearing reality.",Lewenhart87,False,0.96,781,https://www.reddit.com/r/MachineLearning/comments/12zclus/d_google_researchers_achieve_performance/,69,1682502964.0,"**What's important to know:**

&#x200B;

*  Stable Diffusion is an \\\~1-billion parameter model that is typically resource intensive. DALL-E sits at 3.5B parameters, so there are even heavier models out there.
*  Researchers at Google layered in a series of four GPU optimizations to enable Stable Diffusion 1.4 to run on a Samsung phone and generate images in under 12 seconds. RAM usage was also reduced heavily.
* **Their breakthrough isn't device-specific; rather it's a generalized approach that can add improvements to all latent diffusion models.** Overall image generation time decreased by 52% and 33% on a Samsung S23 Ultra and an iPhone 14 Pro, respectively.
*  Running generative AI locally on a phone, without a data connection or a cloud server, opens up a host of possibilities. This is just an example of how rapidly this space is moving as Stable Diffusion only just released last fall, and in its initial versions was slow to run on a hefty RTX 3080 desktop GPU.

&#x200B;

As small form-factor devices can run their own generative AI models, what does that mean for the future of computing? Some very exciting applications could be possible.

&#x200B;

If you're curious, the paper (very technical) [can be accessed here.](https://arxiv.org/abs/2304.11267)"
7,zubg2u,MachineLearning,Open-AI,top,2022-12-24 14:58:19,[R][P] I made an app for Instant Image/Text to 3D using PointE from OpenAI,perception-eng,False,0.97,763,https://i.redd.it/ox6urwwa1v7a1.gif,42,1671893899.0,
8,11uk8ti,MachineLearning,Open-AI,top,2023-03-18 10:15:33,[D] Totally Open Alternatives to ChatGPT,KingsmanVince,False,0.98,743,https://www.reddit.com/r/MachineLearning/comments/11uk8ti/d_totally_open_alternatives_to_chatgpt/,70,1679134533.0,"I have migrated this to GitHub for easy contribution: https://github.com/nichtdax/awesome-totally-open-chatgpt

By alternative, I mean projects feature different language model for chat system.
I do **not** count alternative **frontend** projects because they just call the API from OpenAI. 
I do **not** consider alternative **transformer decoder** to GPT 3.5 either because the training data of them are (mostly) not for chat system.

Tags:

-   B: bare (no data, no model's weight, no chat system)
-   F: full (yes data, yes model's weight, yes chat system including TUI and GUI)

| Project                                                                               | Description                                                                                                                                                                                                                                                                                                                                                                               | Tags |
| ------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---- |
| [lucidrains/PaLM-rlhf-pytorch](https://github.com/lucidrains/PaLM-rlhf-pytorch)       | Implementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Basically ChatGPT but with PaLM                                                                                                                                                                                                                                                      | B    |
| [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit)       | OpenChatKit provides a powerful, open-source base to create both specialized and general purpose chatbots for various applications. [Demo](https://huggingface.co/spaces/togethercomputer/OpenChatKit)                                                                                                                                                                                    | F    |
| [oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) | A gradio web UI for running Large Language Models like GPT-J 6B, OPT, GALACTICA, LLaMA, and Pygmalion.                                                                                                                                                                                                                                                                                    | F    |
| [KoboldAI/KoboldAI-Client](https://github.com/KoboldAI/KoboldAI-Client)               | This is a browser-based front-end for AI-assisted writing with multiple local & remote AI models. It offers the standard array of tools, including Memory, Author's Note, World Info, Save & Load, adjustable AI settings, formatting options, and the ability to import existing AI Dungeon adventures. You can also turn on Adventure mode and play the game like AI Dungeon Unleashed. | F    |
| [LAION-AI/Open-Assistant/](https://github.com/LAION-AI/Open-Assistant/)               | OpenAssistant is a chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so.                                                                                                                                                                                                                                     | F    |"
9,10bkjdk,MachineLearning,Open-AI,top,2023-01-14 09:35:51,"[N] Class-action law­suit filed against Sta­bil­ity AI, DeviantArt, and Mid­journey for using the text-to-image AI Sta­ble Dif­fu­sion",Wiskkey,False,0.95,691,https://i.redd.it/rg6vkf9xvyba1.png,724,1673688951.0,
10,11mzqxu,MachineLearning,Open-AI,top,2023-03-09 18:30:58,"[N] GPT-4 is coming next week – and it will be multimodal, says Microsoft Germany - heise online",Singularian2501,False,0.98,666,https://www.reddit.com/r/MachineLearning/comments/11mzqxu/n_gpt4_is_coming_next_week_and_it_will_be/,80,1678386658.0,"[https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html](https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html)

>**GPT-4 is coming next week**: at an approximately one-hour hybrid information event entitled ""**AI in Focus - Digital Kickoff"" on 9 March 2023**, four Microsoft Germany employees presented Large Language Models (LLM) like GPT series as a disruptive force for companies and their Azure-OpenAI offering in detail. The kickoff event took place in the German language, news outlet Heise was present. **Rather casually, Andreas Braun, CTO Microsoft Germany** and Lead Data & AI STU, **mentioned** what he said was **the imminent release of GPT-4.** The fact that **Microsoft is fine-tuning multimodality with OpenAI should no longer have been a secret since the release of Kosmos-1 at the beginning of March.**

[ Dr. Andreas Braun, CTO Microsoft Germany and Lead Data  & AI STU at the Microsoft Digital Kickoff: \\""KI im Fokus\\"" \(AI in  Focus, Screenshot\) \(Bild: Microsoft\) ](https://preview.redd.it/rnst03avarma1.jpg?width=1920&format=pjpg&auto=webp&s=c5992e2d6c6daf32e56a0a3ffeeecfe10621f73f)"
11,zfeh67,MachineLearning,Open-AI,top,2022-12-07 21:28:22,"[D] We're the Meta AI research team behind CICERO, the first AI agent to achieve human-level performance in the game Diplomacy. We’ll be answering your questions on December 8th starting at 10am PT. Ask us anything!",MetaAI_Official,False,0.93,661,https://www.reddit.com/r/MachineLearning/comments/zfeh67/d_were_the_meta_ai_research_team_behind_cicero/,163,1670448502.0,"**EDIT 11:58am PT:** Thanks for all the great questions, we stayed an almost an hour longer than originally planned to try to get through as many as possible — but we’re signing off now! We had a great time and thanks for all thoughtful questions!

PROOF: [https://i.redd.it/8skvttie6j4a1.png](https://i.redd.it/8skvttie6j4a1.png)

We’re part of the research team behind CICERO, Meta AI’s latest research in cooperative AI. CICERO is the first AI agent to achieve human-level performance in the game Diplomacy. Diplomacy is a complex strategy game involving both cooperation and competition that emphasizes natural language negotiation between seven players.   Over the course of 40 two-hour games with 82 human players, CICERO achieved more than double the average score of other players, ranked in the top 10% of players who played more than one game, and placed 2nd out of 19 participants who played at least 5 games.   Here are some highlights from our recent announcement:

* **NLP x RL/Planning:** CICERO combines techniques in NLP and RL/planning, by coupling a controllable dialogue module with a strategic reasoning engine. 
* **Controlling dialogue via plans:** In addition to being grounded in the game state and dialogue history, CICERO’s dialogue model was trained to be controllable via a set of intents or plans in the game. This allows CICERO to use language intentionally and to move beyond imitation learning by conditioning on plans selected by the strategic reasoning engine.
* **Selecting plans:** CICERO uses a strategic reasoning module to make plans (and select intents) in the game. This module runs a planning algorithm which takes into account the game state, the dialogue, and the strength/likelihood of various actions. Plans are recomputed every time CICERO sends/receives a message.
* **Filtering messages:** We built an ensemble of classifiers to detect low quality messages, like messages contradicting the game state/dialogue history or messages which have low strategic value. We used this ensemble to aggressively filter CICERO’s messages. 
* **Human-like play:** Over the course of 72 hours of play – which involved sending 5,277 messages – CICERO was not detected as an AI agent.

You can check out some of our materials and open-sourced artifacts here: 

* [Research paper](https://www.science.org/doi/10.1126/science.ade9097)
* [Project overview](https://ai.facebook.com/research/cicero/)
* [Diplomacy gameplay page](https://ai.facebook.com/research/cicero/diplomacy/)
* [Github repo](https://github.com/facebookresearch/diplomacy_cicero)
* [Our latest blog post](https://ai.facebook.com/blog/cicero-ai-negotiates-persuades-and-cooperates-with-people/)

Joining us today for the AMA are:

* Andrew Goff (AG), 3x Diplomacy World Champion
* Alexander Miller (AM), Research Engineering Manager
* Noam Brown (NB), Research Scientist [(u/NoamBrown)](https://www.reddit.com/user/NoamBrown/)
* Mike Lewis (ML), Research Scientist [(u/mikelewis0)](https://www.reddit.com/user/mikelewis0/)
* David Wu (DW), Research Engineer [(u/icosaplex)](https://www.reddit.com/user/icosaplex/)
* Emily Dinan (ED), Research Engineer
* Anton Bakhtin (AB), Research Engineer
* Adam Lerer (AL), Research Engineer
* Jonathan Gray (JG), Research Engineer
* Colin Flaherty (CF), Research Engineer [(u/c-flaherty)](https://www.reddit.com/user/c-flaherty)

We’ll be here on December 8, 2022 @ 10:00AM PT - 11:00AM PT."
12,11awp4n,MachineLearning,Open-AI,top,2023-02-24 17:21:15,[R] Meta AI open sources new SOTA LLM called LLaMA. 65B version (trained on 1.4T tokens) is competitive with Chinchilla and Palm-540B. 13B version outperforms OPT and GPT-3 175B on most benchmarks.,MysteryInc152,False,0.98,626,https://www.reddit.com/r/MachineLearning/comments/11awp4n/r_meta_ai_open_sources_new_sota_llm_called_llama/,213,1677259275.0,"[https://twitter.com/GuillaumeLample/status/1629151231800115202?t=4cLD6Ko2Ld9Y3EIU72-M2g&s=19](https://twitter.com/GuillaumeLample/status/1629151231800115202?t=4cLD6Ko2Ld9Y3EIU72-M2g&s=19)

Paper here - [https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)"
13,134r0xf,MachineLearning,Open-AI,top,2023-05-01 16:21:24,[P] SoulsGym - Beating Dark Souls III Bosses with Deep Reinforcement Learning,amacati,False,0.98,585,https://www.reddit.com/r/MachineLearning/comments/134r0xf/p_soulsgym_beating_dark_souls_iii_bosses_with/,74,1682958084.0,"# The project

I've been working on a new gym environment for quite a while, and I think it's finally at a point where I can share it. SoulsGym is an OpenAI gym extension for Dark Souls III. It allows you to train reinforcement learning agents on the bosses in the game. The Souls games are widely known in the video game community for being notoriously hard.

.. Ah, and this is my first post on r/MachineLearning, so please be gentle ;)

# What is included?

**SoulsGym**

There are really two parts to this project. The first one is [SoulsGym](https://github.com/amacati/SoulsGym), an OpenAI gym extension. It is compatible with the newest API changes after gym has transitioned to the Farama foundation. SoulsGym is essentially a game hacking layer that turns Dark Souls III into a gym environment that can be controlled with Python. However, you still need to own the game on Steam and run it before starting the gym. A detailed description on how to set everything up can be found in the package [documentation](https://soulsgym.readthedocs.io/en/latest/?badge=latest).

**Warning: If you want to try this gym, be sure that you have read the documentation and understood everything. If not handled properly, you can get banned from multiplayer.**

Below, you can find a video of an agent training in the game. The game runs on 3x speed to accelerate training. You can also watch the video on [YouTube](https://www.youtube.com/watch?v=7R5Ef69sFPE).

&#x200B;

[RL agent learning to defeat the first boss in Dark Souls III.](https://reddit.com/link/134r0xf/video/o6ctdppeo8xa1/player)

At this point, only the first boss in Dark Souls III is implemented as an environment. Nevertheless, SoulsGym can easily be extended to include other bosses in the game. Due to their similarity, it shouldn't be too hard to even extend the package to Elden Ring as well. If there is any interest in this in the ML/DS community, I'd be happy to give the other ones a shot ;)

**SoulsAI**

The second part is [SoulsAI](https://github.com/amacati/SoulsAI), a distributed deep reinforcement learning framework that I wrote to train on multiple clients simultaneously. You should be able to use it for other gym environments as well, but it was primarily designed for my rather special use case. SoulsAI enables live-monitoring of the current training setup via a webserver, is resilient to client disconnects and crashes, and contains all my training scripts. While this sounds a bit hacky, it's actually quite readable. You can find a complete documentation that goes into how everything works [here](https://soulsai.readthedocs.io/en/latest/).

Being fault tolerant is necessary since the simulator at the heart of SoulsGym is a game that does not expose any APIs and has to be hacked instead. Crashes and other instabilities are rare, but can happen when training over several days. At this moment, SoulsAI implements ApeX style DQN and PPO, but since PPO is synchronous, it is less robust to client crashes etc. Both implementations use Redis as communication backend to send training samples from worker clients to a centralized training server, and to broadcast model updates from the server to all clients. For DQN, SoulsAI is completely asynchronous, so that clients never have to stop playing in order to perform updates or send samples.

&#x200B;

[Live monitoring of an ongoing training process in SoulsAI.](https://preview.redd.it/9m060w00r8xa1.png?width=1800&format=png&auto=webp&s=abb9c15ce38c99cba9753db95ac9dfc7eeec75a5)

Note: I have not implemented more advanced training algorithms such as Rainbow etc., so it's very likely that one can achieve faster convergence with better performance. Furthermore, hyperparameter tuning is extremely challenging since training runs can easily take days across multiple machines.

# Does this actually work?

Yes, it does! It took me some time, but I was able to train an agent with Duelling Double Deep Q-Learning that has a win rate of about 45% within a few days of training. In this video you can see the trained agent playing against Iudex Gundry. You can also watch the video on [YouTube](https://www.youtube.com/watch?v=86NivRglr3Y).

&#x200B;

[RL bot vs Dark Souls III boss.](https://reddit.com/link/134r0xf/video/rkor3hroj8xa1/player)

I'm also working on a visualisation that shows the agent's policy networks reacting to the current game input. You can see a preview without the game simultaneously running here. Credit for the idea of visualisation goes to [Marijn van Vliet](https://github.com/wmvanvliet/scns).

&#x200B;

[Duelling Double Q-Learning networks reacting to changes in the game observations.](https://reddit.com/link/134r0xf/video/b0a4jzczv8xa1/player)

If you really want to dive deep into the hyperparameters that I used or load the trained policies on your machine, you can find the final checkpoints [here](https://drive.google.com/drive/folders/1cAK1TbY4e4HE4cxyAFEHRpj6MOgp5Zxe?usp=sharing). The hyperparameters are contained in the *config.json* file.

# ... But why?

Because it is a ton of fun! Training to defeat a boss in a computer game does not advance the state of the art in RL, sure. So why do it? Well, because we can! And because maybe it excites others about ML/RL/DL.

**Disclaimer: Online multiplayer**

This project is in no way oriented towards creating multiplayer bots. It would take you ages of development and training time to learn a multiplayer AI starting from my package, so just don't even try. I also do not take any precautions against cheat detections, so if you use this package while being online, you'd probably be banned within a few hours.

# Final comments

As you might guess, this project went through many iterations and it took a lot of effort to get it ""right"". I'm kind of proud to have achieved it in the end, and am happy to explain more about how things work if anyone is interested. There is a lot that I haven't covered in this post (it's really just the surface), but you can find more in the docs I linked or by writing me a pm. Also, I really have no idea how many people in ML are also active in the gaming community, but if you are a Souls fan and you want to contribute by adding other Souls games or bosses, feel free to reach out to me.

Edit: Clarified some paragraphs, added note for online multiplayer.

Edit2: Added hyperparameters and network weights."
14,11fbccz,MachineLearning,Open-AI,top,2023-03-01 18:31:12,[D] OpenAI introduces ChatGPT and Whisper APIs (ChatGPT API is 1/10th the cost of GPT-3 API),minimaxir,False,0.97,577,https://www.reddit.com/r/MachineLearning/comments/11fbccz/d_openai_introduces_chatgpt_and_whisper_apis/,119,1677695472.0,"https://openai.com/blog/introducing-chatgpt-and-whisper-apis

> It is priced at $0.002 per 1k tokens, which is 10x cheaper than our existing GPT-3.5 models.

This is a massive, massive deal. For context, the reason GPT-3 apps took off over the past few months before ChatGPT went viral is because a) text-davinci-003 was released and was a significant performance increase and b) the cost was cut from $0.06/1k tokens to $0.02/1k tokens, which made consumer applications feasible without a large upfront cost.

A much better model and a 1/10th cost warps the economics completely to the point that it may be better than in-house finetuned LLMs.

I have no idea how OpenAI can make money on this. This has to be a loss-leader to lock out competitors before they even get off the ground."
15,11okrni,MachineLearning,Open-AI,top,2023-03-11 13:54:22,[Discussion] Compare OpenAI and SentenceTransformer Sentence Embeddings,Simusid,False,0.94,541,https://i.redd.it/7muze2s684na1.png,58,1678542862.0,
16,10gtruu,MachineLearning,Open-AI,top,2023-01-20 10:41:04,[N] OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic,ChubChubkitty,False,0.83,523,https://www.reddit.com/r/MachineLearning/comments/10gtruu/n_openai_used_kenyan_workers_on_less_than_2_per/,246,1674211264.0,https://time.com/6247678/openai-chatgpt-kenya-workers/
17,10pb1y3,MachineLearning,Open-AI,top,2023-01-30 19:09:14,"[P] I launched “CatchGPT”, a supervised model trained with millions of text examples, to detect GPT created content",qthai912,False,0.75,493,https://www.reddit.com/r/MachineLearning/comments/10pb1y3/p_i_launched_catchgpt_a_supervised_model_trained/,206,1675105754.0,"I’m an ML Engineer at Hive AI and I’ve been working on a ChatGPT Detector.

Here is a free demo we have up: [https://hivemoderation.com/ai-generated-content-detection](https://hivemoderation.com/ai-generated-content-detection)

From our benchmarks it’s significantly better than similar solutions like GPTZero and OpenAI’s GPT2 Output Detector. On our internal datasets, we’re seeing balanced accuracies of >99% for our own model compared to around 60% for GPTZero and 84% for OpenAI’s GPT2 Detector.

Feel free to try it out and let us know if you have any feedback!"
18,127asin,MachineLearning,Open-AI,top,2023-03-31 05:04:02,[D][N] LAION Launches Petition to Establish an International Publicly Funded Supercomputing Facility for Open Source Large-scale AI Research and its Safety,stringShuffle,False,0.97,472,https://www.reddit.com/r/MachineLearning/comments/127asin/dn_laion_launches_petition_to_establish_an/,53,1680239042.0,"[https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety](https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety)

>Join us in our urgent mission to democratize AI research by establishing  an international, publicly funded supercomputing facility equipped with  100,000 state-of-the-art AI accelerators to train open source  foundation models. This monumental initiative will secure our  technological independence, empower global innovation, and ensure safety, while safeguarding our democratic principles for generations to  come."
19,ynz4m1,MachineLearning,Open-AI,top,2022-11-06 18:58:59,[P] Transcribe any podcast episode in just 1 minute with optimized OpenAI/whisper,thundergolfer,False,0.97,465,https://v.redd.it/wnt66ghfody91,43,1667761139.0,
20,1373nhq,MachineLearning,Open-AI,top,2023-05-03 23:48:17,[Discussion]: Mark Zuckerberg on Meta's Strategy on Open Source and AI during the earnings call,noiseinvacuum,False,0.95,426,https://www.reddit.com/r/MachineLearning/comments/1373nhq/discussion_mark_zuckerberg_on_metas_strategy_on/,85,1683157697.0,"During  the recent earnings call, Mark Zuckerberg answered a question from Eric  Sheridan of Goldman Sachs on Meta's AI strategy, opportunities to  integrate into products, and why they open source models and how it  would benefit their business.

I found the reasoning to be very sound and promising for the OSS and AI community.

The  biggest risk from AI, in my opinion, is not the doomsday scenarios that  intuitively come to mind but rather that the most powerful AI systems  will only be accessible to the most powerful and resourceful  corporations.

Quote copied from Ben Thompson's write up on Meta's earning in his [Stratechery blog post](https://stratechery.com/2023/facebook-earnings-generative-ai-and-messaging-monetization-open-source-and-ai/) which goes beyond AI. *It's behind a paywall but I highly recommend it personally.*

Some noteworthy quotes that signal the thought process at Meta FAIR and more broadly

* We’re just playing a different game on the infrastructure  than companies like Google or Microsoft or Amazon
* We would aspire to and hope to make even more open than that. So, we’ll need to figure out a way to do that.
* ...lead us to do more work in terms of open sourcing, some of the lower level models and tools
* Open sourcing low level tools make the way we run all this infrastructure more efficient over time.
* On  PyTorch: It’s generally been very valuable for us to provide that  because now  all of the best developers across the industry are using  tools that  we’re also using internally.
* I would expect us to be pushing and helping  to build out an open ecosystem.

For  all the negative that comes out of the popular discourse on Meta, I  think their work to open source key tech tools over the last 10 years  has been exceptional, here's hoping it continues into this decade of AI  and pushes other tech giants to also realize the benefits of Open  Source.

Full Transcript:

>Right  now most of the companies that are training large language  models have  business models that lead them to a closed approach to development. I  think **there’s an** **important opportunity to help create an  open ecosystem.**  If we can help be a part of this, then much of the  industry will  standardize on using these open tools and help improve  them further. So  this will make it easier for other companies to  integrate with our  products and platforms as we enable more  integrations, and that will  help our products stay at the leading edge  as well.  
Our  approach to AI and our infrastructure has always been fairly  open. We  open source many of our state of the art models so people can   experiment and build with them. This quarter we released our LLaMa LLM   to researchers. It has 65 billion parameters but outperforms larger   models and has proven quite popular. We’ve also open-sourced three other   groundbreaking visual models along with their training data and model   weights — Segment Anything, DinoV2, and our Animated Drawings tool —  and  we’ve gotten positive feedback on all of those as well.  
I  think that there’s an important distinction between the products we  offer and a lot of the technical infrastructure, especially the software  that we write to support that. And historically, whether it’s the Open  Compute project that we’ve done or just open sourcing a lot of the   infrastructure that we’ve built, we’ve historically open sourced a lot   of that infrastructure, even though we haven’t open sourced the code for   our core products or anything like that.  
And the reason why I think why we do this is that unlike some of  the other companies in the space, **we’re not selling a cloud computing service** **where we try to keep the different software infrastructure that we’re building proprietary.** For us, **it’s way better if the industry  standardizes on the basic tools that we’re using**  and therefore we can benefit from the improvements that others make and  others’ use of those tools can, in some cases like Open Compute, **drive down the costs** of  those things which make our business more efficient too. So I think to  some degree **we’re just playing a different game** on the infrastructure  than companies like Google or Microsoft or Amazon, and that creates different incentives for us.  
So overall, I think **that that’s going to lead us to do more work in terms of open sourcing, some of the lower level models and tools**.  But of  course, a lot of the product work itself is going to be  specific and  integrated with the things that we do. So it’s not that  everything we do is going to be open. Obviously, a bunch of this needs  to be developed in a way that creates unique value for our products, but  I think in  terms of the basic models, **I would expect us to be pushing and helping  to build out an open ecosystem** here, which I think is something that’s  going to be important.  
On the AI tools, and we have a bunch of history here, right? So if you  if you look at what we’ve done with **PyTorch**,  for example, which has  generally become the standard in the industry  as a tool that a lot of  folks who are building AI models and different  things in that space use,  **it’s generally been very valuable** for us to provide that because now  all of the **best developers across the industry are using tools that  we’re also using internally**.  So the tool chain is the same. So when they create some innovation, we  can easily integrate it into the things that we’re doing. When we  improve something, it improves other products too. Because it’s  integrated with our technology stack, when there are opportunities to  make integrations with products, it’s much easier to  make sure that  developers and other folks are compatible with the things  that we need  in the way that our systems work.  
So there are a lot of advantages, but **I view this more as a kind of back end infrastructure advantage with potential integrations on the  product side**,  but one that should hopefully enable us to stay at the  leading edge  and integrate more broadly with the community and also make  the way we  run all this infrastructure more efficient over time. There  are a  number of models. I just gave PyTorch as an example. Open Compute  is  another model that has worked really well for us in this way, both to   incorporate both innovation and scale efficiency into our own   infrastructure.  
So I think that  there’s, our incentives I think are basically  aligned towards moving in  this direction. Now that said, there’s a lot  to figure out, right? So  when you asked if there are going to be other opportunities, I hope so. I  can’t speak to what all those things might  be now. This is all quite  early in getting developed. **The better we do at the foundational work, the more opportunities** I think that will come and present themselves. So I think that that’s all stuff that we need to  figure out. But at least **at the base level, I think we’re generally incentivized to move in this direction**. And we also need to figure out  how to go in that direction over time.  
I  mean, I mentioned LLaMA before and I also want to be clear that  while  I’m talking about helping contribute to an open ecosystem, LLaMA  is a  model that we only really made available to researchers and there’s  a  lot of really good stuff that’s happening there. But a lot of the  work  that we’re doing, I think, **we would aspire to and hope to make even more open than that. So, we’ll need to figure out a way to do that.**"
21,yli0r7,MachineLearning,Open-AI,top,2022-11-03 23:12:45,"[D] DALL·E to be made available as API, OpenAI to give users full ownership rights to generated images",TiredOldCrow,False,0.98,423,https://www.reddit.com/r/MachineLearning/comments/yli0r7/d_dalle_to_be_made_available_as_api_openai_to/,55,1667517165.0,"Email announcement from OpenAI below:


> DALL·E is now available as an API


> You can now integrate state of the art image generation capabilities directly into your apps and products through our new DALL·E API.


> You own the generations you create with DALL·E.


> We’ve simplified our [Terms of Use](https://openai.com/api/policies/terms/) and you now have full ownership rights to the images you create with DALL·E — in addition to the usage rights you’ve already had to use and monetize your creations however you’d like. This update is possible due to improvements to our safety systems which minimize the ability to generate content that violates our content policy.


> Sort and showcase with collections.


> You can now organize your DALL·E creations in multiple collections. Share them publicly or keep them private. Check out our [sea otter collection](https://labs.openai.com/sc/w3Q8nqVN69qkEA3ePSmrGb5t)!


> We’re constantly amazed by the innovative ways you use DALL·E and love seeing your creations out in the world. Artists who would like their work to be shared on our Instagram can request to be featured using Instagram’s collab tool. DM us there to show off how you’re using the API!  

> \- The OpenAI Team"
22,105v7el,MachineLearning,Open-AI,top,2023-01-07 17:59:47,[R] Greg Yang's work on a rigorous mathematical theory for neural networks,IamTimNguyen,False,0.97,404,https://www.reddit.com/r/MachineLearning/comments/105v7el/r_greg_yangs_work_on_a_rigorous_mathematical/,41,1673114387.0," Greg Yang is a mathematician and AI researcher at Microsoft Research who for the past several years has done incredibly original theoretical work in the understanding of large artificial neural networks. His work currently spans the following five papers:

Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes: [https://arxiv.org/abs/1910.12478](https://arxiv.org/abs/1910.12478)  
Tensor Programs II: Neural Tangent Kernel for Any Architecture: [https://arxiv.org/abs/2006.14548](https://arxiv.org/abs/2006.14548)  
Tensor Programs III: Neural Matrix Laws: [https://arxiv.org/abs/2009.10685](https://arxiv.org/abs/2009.10685)  
Tensor Programs IV: Feature Learning in Infinite-Width Neural Networks: [https://proceedings.mlr.press/v139/yang21c.html](https://proceedings.mlr.press/v139/yang21c.html)  
Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer: [https://arxiv.org/abs/2203.03466](https://arxiv.org/abs/2203.03466)

In our whiteboard conversation, we get a sample of Greg's work, which goes under the name ""Tensor Programs"". The route chosen to compress Tensor Programs into the scope of a conversational video is to place its main concepts under the umbrella of one larger, central, and time-tested idea: that of taking a large N limit. This occurs most famously in the Law of Large Numbers and the Central Limit Theorem, which then play a fundamental role in the branch of mathematics known as Random Matrix Theory (RMT). We review this foundational material and then show how Tensor Programs (TP) generalizes this classical work, offering new proofs of RMT.

We conclude with the applications of Tensor Programs to a (rare!) rigorous theory of neural networks. This includes applications to a rigorous proof for the existence of the Neural Network Gaussian Process and Neural Tangent Kernel for a general class of architectures, the existence of infinite-width feature learning limits, and the muP parameterization enabling hyperparameter transfer from smaller to larger networks.

&#x200B;

https://preview.redd.it/av3ovotcunaa1.png?width=1280&format=png&auto=webp&s=dae42e6b7c41a15acd6b5eeb752b8db064d3e8da

https://preview.redd.it/hh9q6wqdunaa1.png?width=1200&format=png&auto=webp&s=b2936e129d9444fc5434a4c3f5b36315d3e06057

Youtube: [https://youtu.be/1aXOXHA7Jcw](https://youtu.be/1aXOXHA7Jcw)

Apple Podcasts: [https://podcasts.apple.com/us/podcast/the-cartesian-cafe/id1637353704](https://podcasts.apple.com/us/podcast/the-cartesian-cafe/id1637353704)

Spotify: [https://open.spotify.com/show/1X5asAByNhNr996ZsGGICG](https://open.spotify.com/show/1X5asAByNhNr996ZsGGICG)

RSS: [https://feed.podbean.com/cartesiancafe/feed.xml](https://feed.podbean.com/cartesiancafe/feed.xml)"
23,13aotyf,MachineLearning,Open-AI,top,2023-05-07 14:12:18,[P] I made a dashboard to analyze OpenAI API usage,cryptotrendz,False,0.91,402,https://v.redd.it/w7ahlql0ccya1,73,1683468738.0,
24,1323w68,MachineLearning,Open-AI,top,2023-04-28 17:30:18,"[N] LAION publishes an open letter to ""protect open-source AI in Europe"" with Schmidhuber and Hochreiter as signatories",Philpax,False,0.98,399,https://www.reddit.com/r/MachineLearning/comments/1323w68/n_laion_publishes_an_open_letter_to_protect/,61,1682703018.0,https://laion.ai/notes/letter-to-the-eu-parliament/
25,1194wm0,MachineLearning,Open-AI,top,2023-02-22 17:00:26,[P] MIT Introduction to Data-Centric AI,anishathalye,False,0.97,390,https://www.reddit.com/r/MachineLearning/comments/1194wm0/p_mit_introduction_to_datacentric_ai/,9,1677085226.0,"Announcing the [first-ever course on Data-Centric AI](https://dcai.csail.mit.edu/). Learn how to train better ML models by improving the data.

[Course homepage](https://dcai.csail.mit.edu/) | [Lecture videos on YouTube](https://www.youtube.com/watch?v=ayzOzZGHZy4&list=PLnSYPjg2dHQKdig0vVbN-ZnEU0yNJ1mo5) | [Lab Assignments](https://github.com/dcai-course/dcai-lab)

The course covers:

- [Data-Centric AI vs. Model-Centric AI](https://dcai.csail.mit.edu/lectures/data-centric-model-centric/)
- [Label Errors](https://dcai.csail.mit.edu/lectures/label-errors/)
- [Dataset Creation and Curation](https://dcai.csail.mit.edu/lectures/dataset-creation-curation/)
- [Data-centric Evaluation of ML Models](https://dcai.csail.mit.edu/lectures/data-centric-evaluation/)
- [Class Imbalance, Outliers, and Distribution Shift](https://dcai.csail.mit.edu/lectures/imbalance-outliers-shift/)
- [Growing or Compressing Datasets](https://dcai.csail.mit.edu/lectures/growing-compressing-datasets/)
- [Interpretability in Data-Centric ML](https://dcai.csail.mit.edu/lectures/interpretable-features/)
- [Encoding Human Priors: Data Augmentation and Prompt Engineering](https://dcai.csail.mit.edu/lectures/human-priors/)
- [Data Privacy and Security](https://dcai.csail.mit.edu/lectures/data-privacy-security/)

MIT, like most universities, has many courses on machine learning (6.036, 6.867, and many others). Those classes teach techniques to produce effective models for a given dataset, and the classes focus heavily on the mathematical details of models rather than practical applications. However, in real-world applications of ML, the dataset is not fixed, and focusing on improving the data often gives better results than improving the model. We’ve personally seen this time and time again in our applied ML work as well as our research.

Data-Centric AI (DCAI) is an emerging science that studies techniques to improve datasets in a systematic/algorithmic way — given that this topic wasn’t covered in the standard curriculum, we (a group of PhD candidates and grads) thought that we should put together a new class! We taught this intensive 2-week course in January over MIT’s IAP term, and we’ve just published all the course material, including lecture videos, lecture notes, hands-on lab assignments, and lab solutions, in hopes that people outside the MIT community would find these resources useful.

We’d be happy to answer any questions related to the class or DCAI in general, and we’d love to hear any feedback on how we can improve the course material. Introduction to Data-Centric AI is open-source opencourseware, so feel free to make improvements directly: [https://github.com/dcai-course/dcai-course](https://github.com/dcai-course/dcai-course)."
26,yw6s1i,MachineLearning,Open-AI,top,2022-11-15 19:17:19,[D] AMA: The Stability AI Team,stabilityai,False,0.96,359,https://www.reddit.com/r/MachineLearning/comments/yw6s1i/d_ama_the_stability_ai_team/,216,1668539839.0,"Hi all,

We are the Stability AI team supporting open source ML models, code and communities.

Ask away!

Edit 1 (UTC+0 21:30): Thanks for the great questions! Taking a short break, will come back later and answer as we have time.

Edit 2 (UTC+0 22:24): Closing new questions, still answering some existing Q's posted before now."
27,zstequ,MachineLearning,Open-AI,top,2022-12-22 18:39:30,[D] When chatGPT stops being free: Run SOTA LLM in cloud,_underlines_,False,0.95,348,https://www.reddit.com/r/MachineLearning/comments/zstequ/d_when_chatgpt_stops_being_free_run_sota_llm_in/,95,1671734370.0,"Edit: Found [LAION-AI/OPEN-ASSISTANT](https://github.com/LAION-AI/Open-Assistant) a very promising project opensourcing the idea of chatGPT. [video here](https://www.youtube.com/watch?v=8gVYC_QX1DI)

**TL;DR: I found GPU compute to be [generally cheap](https://github.com/full-stack-deep-learning/website/blob/main/docs/cloud-gpus/cloud-gpus.csv) and spot or on-demand instances can be launched on AWS for a few USD / hour up to over 100GB vRAM. So I thought it would make sense to run your own SOTA LLM like Bloomz 176B inference endpoint whenever you need it for a few questions to answer. I thought it would still make more sense than shoving money into a closed walled garden like ""not-so-OpenAi"" when they make ChatGPT or GPT-4 available for $$$. But I struggle due to lack of tutorials/resources.**

Therefore, I carefully checked benchmarks, model parameters and sizes as well as training sources for all SOTA LLMs [here](https://docs.google.com/spreadsheets/d/1O5KVQW1Hx5ZAkcg8AIRjbQLQzx2wVaLl0SqUu-ir9Fs/edit#gid=1158069878).

Knowing since reading the Chinchilla paper that Model Scaling according to OpenAI was wrong and more params != better quality generation. So I was looking for the best performing LLM openly available in terms of quality and broadness to use for multilingual everyday questions/code completion/reasoning similar to what chatGPT provides (minus the fine-tuning for chat-style conversations).

My choice fell on [Bloomz](https://huggingface.co/bigscience/bloomz) (because that handles multi-lingual questions well and has good zero shot performance for instructions and Q&A style text generation. Confusingly Galactica seems to outperform Bloom on several benchmarks. But since Galactica had a very narrow training set only using scientific papers, I guess usage is probably limited for answers on non-scientific topics.

Therefore I tried running the original bloom 176B and alternatively also Bloomz 176B on AWS SageMaker JumpStart, which should be a one click deployment. This fails after 20min. On Azure ML, I tried using DeepSpeed-MII which also supports bloom but also fails due the instance size of max 12GB vRAM I guess.

From my understanding to save costs on inference, it's probably possible to use one or multiple of the following solutions:

- Precision: int8 instead of fp16
- [Microsoft/DeepSpeed-MII](https://github.com/microsoft/DeepSpeed-MII) for an up 40x reduction on inference cost on Azure, this thing also supports int8 and fp16 bloom out of the box, but it fails on Azure due to instance size.
- [facebook/xformer](https://github.com/facebookresearch/xformers) not sure, but if I remember correctly this brought inference requirements down to 4GB vRAM for StableDiffusion and DreamBooth fine-tuning to 10GB. No idea if this is usefull for Bloom(z) inference cost reduction though

I have a CompSci background but I am not familiar with most stuff, except that I was running StableDiffusion since day one on my rtx3080 using linux and also doing fine-tuning with DreamBooth. But that was all just following youtube tutorials. I can't find a single post or youtube video of anyone explaining a full BLOOM / Galactica / BLOOMZ inference deployment on cloud platforms like AWS/Azure using one of the optimizations mentioned above, yet alone deployment of the raw model. :(

I still can't figure it out by myself after 3 days.

**TL;DR2: Trying to find likeminded people who are interested to run open source SOTA LLMs for when chatGPT will be paid or just for fun.**

Any comments, inputs, rants, counter-arguments are welcome.

/end of rant"
28,13b6miy,MachineLearning,Open-AI,top,2023-05-07 23:26:29,"[D] ClosedAI license, open-source license which restricts only OpenAI, Microsoft, Google, and Meta from commercial use",wemsyn,False,0.8,344,https://www.reddit.com/r/MachineLearning/comments/13b6miy/d_closedai_license_opensource_license_which/,191,1683501989.0,"After reading [this article](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither), I realized it might be nice if the open-source AI community could exclude ""closed AI"" players from taking advantage of community-generated models and datasets. I was wondering if it would be possible to write a license that is completely permissive (like Apache 2.0 or MIT), except to certain companies, which are completely barred from using the software in any context.

Maybe this could be called the ""ClosedAI"" license. I'm not any sort of legal expert so I have no idea how best to write this license such that it protects model weights and derivations thereof.

I prompted ChatGPT for an example license and this is what it gave me:

    <PROJECT NAME> ClosedAI License v1.0
    
    Permission is hereby granted, free of charge, to any person or organization obtaining a copy of this software and associated documentation files (the ""Software""), to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, subject to the following conditions:
    
    1. The above copyright notice and this license notice shall be included in all copies or substantial portions of the Software.
    
    2. The Software and any derivative works thereof may not be used, in whole or in part, by or on behalf of OpenAI Inc., Google LLC, or Microsoft Corporation (collectively, the ""Prohibited Entities"") in any capacity, including but not limited to training, inference, or serving of neural network models, or any other usage of the Software or neural network weights generated by the Software.
    
    3. Any attempt by the Prohibited Entities to use the Software or neural network weights generated by the Software is a material breach of this license.
    
    THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

No idea if this is valid or not. Looking for advice.

&#x200B;

**Edit:** Thanks for the input. Removed non-commercial clause (whoops, proofread what ChatGPT gives you). Also removed Meta from the excluded companies list due to popular demand."
29,10bkjdk,MachineLearning,Open-AI,comments,2023-01-14 09:35:51,"[N] Class-action law­suit filed against Sta­bil­ity AI, DeviantArt, and Mid­journey for using the text-to-image AI Sta­ble Dif­fu­sion",Wiskkey,False,0.95,697,https://i.redd.it/rg6vkf9xvyba1.png,724,1673688951.0,
30,11sboh1,MachineLearning,Open-AI,comments,2023-03-15 22:34:01,[D] Our community must get serious about opposing OpenAI,SOCSChamp,False,0.95,2967,https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/,448,1678919641.0,"OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.

They have abandoned this idea entirely.

Today, with the release of GPT4 and their direct statement that they will not release details of the model creation due to ""safety concerns"" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.

AI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.

I get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.

We need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.

This conversation will only ever get more important."
31,12cvkvn,MachineLearning,Open-AI,comments,2023-04-05 19:44:09,"[D] ""Our Approach to AI Safety"" by OpenAI",mckirkus,False,0.88,304,https://www.reddit.com/r/MachineLearning/comments/12cvkvn/d_our_approach_to_ai_safety_by_openai/,297,1680723849.0,"It seems OpenAI are steering the conversation away from the existential threat narrative and into things like accuracy, decency, privacy, economic risk, etc.

To the extent that they do buy the existential risk argument, they don't seem concerned much about GPT-4 making a leap into something dangerous, even if it's at the heart of autonomous agents that are currently emerging.  

>""Despite extensive research and testing, we cannot predict all of the [beneficial ways people will use our technology](https://openai.com/customer-stories), nor all the ways people will abuse it. That’s why we believe that learning from real-world use is a critical component of creating and releasing increasingly safe AI systems over time. ""

Article headers:

* Building increasingly safe AI systems
* Learning from real-world use to improve safeguards
* Protecting children
* Respecting privacy
* Improving factual accuracy

&#x200B;

[https://openai.com/blog/our-approach-to-ai-safety](https://openai.com/blog/our-approach-to-ai-safety)"
32,10gtruu,MachineLearning,Open-AI,comments,2023-01-20 10:41:04,[N] OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic,ChubChubkitty,False,0.83,528,https://www.reddit.com/r/MachineLearning/comments/10gtruu/n_openai_used_kenyan_workers_on_less_than_2_per/,246,1674211264.0,https://time.com/6247678/openai-chatgpt-kenya-workers/
33,yw6s1i,MachineLearning,Open-AI,comments,2022-11-15 19:17:19,[D] AMA: The Stability AI Team,stabilityai,False,0.96,363,https://www.reddit.com/r/MachineLearning/comments/yw6s1i/d_ama_the_stability_ai_team/,216,1668539839.0,"Hi all,

We are the Stability AI team supporting open source ML models, code and communities.

Ask away!

Edit 1 (UTC+0 21:30): Thanks for the great questions! Taking a short break, will come back later and answer as we have time.

Edit 2 (UTC+0 22:24): Closing new questions, still answering some existing Q's posted before now."
34,11awp4n,MachineLearning,Open-AI,comments,2023-02-24 17:21:15,[R] Meta AI open sources new SOTA LLM called LLaMA. 65B version (trained on 1.4T tokens) is competitive with Chinchilla and Palm-540B. 13B version outperforms OPT and GPT-3 175B on most benchmarks.,MysteryInc152,False,0.98,618,https://www.reddit.com/r/MachineLearning/comments/11awp4n/r_meta_ai_open_sources_new_sota_llm_called_llama/,213,1677259275.0,"[https://twitter.com/GuillaumeLample/status/1629151231800115202?t=4cLD6Ko2Ld9Y3EIU72-M2g&s=19](https://twitter.com/GuillaumeLample/status/1629151231800115202?t=4cLD6Ko2Ld9Y3EIU72-M2g&s=19)

Paper here - [https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)"
35,126oiey,MachineLearning,Open-AI,comments,2023-03-30 14:18:50,[D] AI Policy Group CAIDP Asks FTC To Stop OpenAI From Launching New GPT Models,vadhavaniyafaijan,False,0.84,205,https://www.reddit.com/r/MachineLearning/comments/126oiey/d_ai_policy_group_caidp_asks_ftc_to_stop_openai/,213,1680185930.0,"The Center for AI and Digital Policy (CAIDP), a tech ethics group, has asked the Federal Trade Commission to investigate OpenAI for violating consumer protection rules. CAIDP claims that OpenAI's AI text generation tools have been ""biased, deceptive, and a risk to public safety.""

CAIDP's complaint raises concerns about potential threats from OpenAI's GPT-4 generative text model, which was announced in mid-March. It warns of the potential for GPT-4 to produce malicious code and highly tailored propaganda and the risk that biased training data could result in baked-in stereotypes or unfair race and gender preferences in hiring. 

The complaint also mentions significant privacy failures with OpenAI's product interface, such as a recent bug that exposed OpenAI ChatGPT histories and possibly payment details of ChatGPT plus subscribers.

CAIDP seeks to hold OpenAI accountable for violating Section 5 of the FTC Act, which prohibits unfair and deceptive trade practices. The complaint claims that OpenAI knowingly released GPT-4 to the public for commercial use despite the risks, including potential bias and harmful behavior. 

[Source](https://www.theinsaneapp.com/2023/03/stop-openai-from-launching-gpt-5.html) | [Case](https://www.caidp.org/cases/openai/)| [PDF](https://www.caidp.org/app/download/8450269463/CAIDP-FTC-Complaint-OpenAI-GPT-033023.pdf)"
36,137rxgw,MachineLearning,Open-AI,comments,2023-05-04 16:13:30,"[D] Google ""We Have No Moat, And Neither Does OpenAI"": Leaked Internal Google Document Claims Open Source AI Will Outcompete Google and OpenAI",hardmaru,False,0.98,1173,https://www.semianalysis.com/p/google-we-have-no-moat-and-neither,206,1683216810.0,
37,10pb1y3,MachineLearning,Open-AI,comments,2023-01-30 19:09:14,"[P] I launched “CatchGPT”, a supervised model trained with millions of text examples, to detect GPT created content",qthai912,False,0.75,501,https://www.reddit.com/r/MachineLearning/comments/10pb1y3/p_i_launched_catchgpt_a_supervised_model_trained/,206,1675105754.0,"I’m an ML Engineer at Hive AI and I’ve been working on a ChatGPT Detector.

Here is a free demo we have up: [https://hivemoderation.com/ai-generated-content-detection](https://hivemoderation.com/ai-generated-content-detection)

From our benchmarks it’s significantly better than similar solutions like GPTZero and OpenAI’s GPT2 Output Detector. On our internal datasets, we’re seeing balanced accuracies of >99% for our own model compared to around 60% for GPTZero and 84% for OpenAI’s GPT2 Detector.

Feel free to try it out and let us know if you have any feedback!"
38,13b6miy,MachineLearning,Open-AI,comments,2023-05-07 23:26:29,"[D] ClosedAI license, open-source license which restricts only OpenAI, Microsoft, Google, and Meta from commercial use",wemsyn,False,0.8,349,https://www.reddit.com/r/MachineLearning/comments/13b6miy/d_closedai_license_opensource_license_which/,191,1683501989.0,"After reading [this article](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither), I realized it might be nice if the open-source AI community could exclude ""closed AI"" players from taking advantage of community-generated models and datasets. I was wondering if it would be possible to write a license that is completely permissive (like Apache 2.0 or MIT), except to certain companies, which are completely barred from using the software in any context.

Maybe this could be called the ""ClosedAI"" license. I'm not any sort of legal expert so I have no idea how best to write this license such that it protects model weights and derivations thereof.

I prompted ChatGPT for an example license and this is what it gave me:

    <PROJECT NAME> ClosedAI License v1.0
    
    Permission is hereby granted, free of charge, to any person or organization obtaining a copy of this software and associated documentation files (the ""Software""), to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, subject to the following conditions:
    
    1. The above copyright notice and this license notice shall be included in all copies or substantial portions of the Software.
    
    2. The Software and any derivative works thereof may not be used, in whole or in part, by or on behalf of OpenAI Inc., Google LLC, or Microsoft Corporation (collectively, the ""Prohibited Entities"") in any capacity, including but not limited to training, inference, or serving of neural network models, or any other usage of the Software or neural network weights generated by the Software.
    
    3. Any attempt by the Prohibited Entities to use the Software or neural network weights generated by the Software is a material breach of this license.
    
    THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

No idea if this is valid or not. Looking for advice.

&#x200B;

**Edit:** Thanks for the input. Removed non-commercial clause (whoops, proofread what ChatGPT gives you). Also removed Meta from the excluded companies list due to popular demand."
39,12rxtjj,MachineLearning,Open-AI,comments,2023-04-19 15:29:34,"[N] Stability AI announce their open-source language model, StableLM",Philpax,False,0.99,832,https://www.reddit.com/r/MachineLearning/comments/12rxtjj/n_stability_ai_announce_their_opensource_language/,182,1681918174.0,"Repo: https://github.com/stability-AI/stableLM/

Excerpt from the Discord announcement:

> We’re incredibly excited to announce the launch of StableLM-Alpha; a nice and sparkly newly released open-sourced language model! Developers, researchers, and curious hobbyists alike can freely inspect, use, and adapt our StableLM base models for commercial and or research purposes! *Excited yet?*
>
> Let’s talk about parameters! The Alpha version of the model is available in 3 billion and 7 billion parameters, with 15 billion to 65 billion parameter models to follow. StableLM is trained on a new experimental dataset built on “The Pile” from EleutherAI (a 825GiB diverse, open source language modeling data set that consists of 22 smaller, high quality datasets combined together!) The richness of this dataset gives StableLM surprisingly high performance in conversational and coding tasks, despite its small size of 3-7 billion parameters."
40,12nbixk,MachineLearning,Open-AI,comments,2023-04-15 17:14:58,[P] OpenAssistant - The world's largest open-source replication of ChatGPT,ykilcher,False,0.97,1270,https://www.reddit.com/r/MachineLearning/comments/12nbixk/p_openassistant_the_worlds_largest_opensource/,175,1681578898.0,"We’re excited to announce the release of OpenAssistant.

The future of AI development depends heavily on high quality datasets and models being made publicly available, and that’s exactly what this project does.

Watch the annoucement video:

[https://youtu.be/ddG2fM9i4Kk](https://youtu.be/ddG2fM9i4Kk)

&#x200B;

Our team has worked tirelessly over the past several months collecting large amounts of text-based input and feedback to create an incredibly diverse and unique dataset designed specifically for training language models or other AI applications.

With over 600k human-generated data points covering a wide range of topics and styles of writing, our dataset will be an invaluable tool for any developer looking to create state-of-the-art instruction models!

To make things even better, we are making this entire dataset free and accessible to all who wish to use it. Check it out today at our HF org: OpenAssistant

On top of that, we've trained very powerful models that you can try right now at: [open-assistant.io/chat](https://open-assistant.io/chat) !"
41,zfeh67,MachineLearning,Open-AI,comments,2022-12-07 21:28:22,"[D] We're the Meta AI research team behind CICERO, the first AI agent to achieve human-level performance in the game Diplomacy. We’ll be answering your questions on December 8th starting at 10am PT. Ask us anything!",MetaAI_Official,False,0.93,656,https://www.reddit.com/r/MachineLearning/comments/zfeh67/d_were_the_meta_ai_research_team_behind_cicero/,163,1670448502.0,"**EDIT 11:58am PT:** Thanks for all the great questions, we stayed an almost an hour longer than originally planned to try to get through as many as possible — but we’re signing off now! We had a great time and thanks for all thoughtful questions!

PROOF: [https://i.redd.it/8skvttie6j4a1.png](https://i.redd.it/8skvttie6j4a1.png)

We’re part of the research team behind CICERO, Meta AI’s latest research in cooperative AI. CICERO is the first AI agent to achieve human-level performance in the game Diplomacy. Diplomacy is a complex strategy game involving both cooperation and competition that emphasizes natural language negotiation between seven players.   Over the course of 40 two-hour games with 82 human players, CICERO achieved more than double the average score of other players, ranked in the top 10% of players who played more than one game, and placed 2nd out of 19 participants who played at least 5 games.   Here are some highlights from our recent announcement:

* **NLP x RL/Planning:** CICERO combines techniques in NLP and RL/planning, by coupling a controllable dialogue module with a strategic reasoning engine. 
* **Controlling dialogue via plans:** In addition to being grounded in the game state and dialogue history, CICERO’s dialogue model was trained to be controllable via a set of intents or plans in the game. This allows CICERO to use language intentionally and to move beyond imitation learning by conditioning on plans selected by the strategic reasoning engine.
* **Selecting plans:** CICERO uses a strategic reasoning module to make plans (and select intents) in the game. This module runs a planning algorithm which takes into account the game state, the dialogue, and the strength/likelihood of various actions. Plans are recomputed every time CICERO sends/receives a message.
* **Filtering messages:** We built an ensemble of classifiers to detect low quality messages, like messages contradicting the game state/dialogue history or messages which have low strategic value. We used this ensemble to aggressively filter CICERO’s messages. 
* **Human-like play:** Over the course of 72 hours of play – which involved sending 5,277 messages – CICERO was not detected as an AI agent.

You can check out some of our materials and open-sourced artifacts here: 

* [Research paper](https://www.science.org/doi/10.1126/science.ade9097)
* [Project overview](https://ai.facebook.com/research/cicero/)
* [Diplomacy gameplay page](https://ai.facebook.com/research/cicero/diplomacy/)
* [Github repo](https://github.com/facebookresearch/diplomacy_cicero)
* [Our latest blog post](https://ai.facebook.com/blog/cicero-ai-negotiates-persuades-and-cooperates-with-people/)

Joining us today for the AMA are:

* Andrew Goff (AG), 3x Diplomacy World Champion
* Alexander Miller (AM), Research Engineering Manager
* Noam Brown (NB), Research Scientist [(u/NoamBrown)](https://www.reddit.com/user/NoamBrown/)
* Mike Lewis (ML), Research Scientist [(u/mikelewis0)](https://www.reddit.com/user/mikelewis0/)
* David Wu (DW), Research Engineer [(u/icosaplex)](https://www.reddit.com/user/icosaplex/)
* Emily Dinan (ED), Research Engineer
* Anton Bakhtin (AB), Research Engineer
* Adam Lerer (AL), Research Engineer
* Jonathan Gray (JG), Research Engineer
* Colin Flaherty (CF), Research Engineer [(u/c-flaherty)](https://www.reddit.com/user/c-flaherty)

We’ll be here on December 8, 2022 @ 10:00AM PT - 11:00AM PT."
42,11njpb9,MachineLearning,Open-AI,comments,2023-03-10 08:50:32,[D] Is ML a big boys game now?,TheStartIs2019,False,0.83,174,https://www.reddit.com/r/MachineLearning/comments/11njpb9/d_is_ml_a_big_boys_game_now/,146,1678438232.0,"As much as I enjoy ML as a whole, I am a bit skeptical of the future for individuals. With OpenAI trying to monopolize the market along with Microsoft, which part remains for the small time researchers/developers?

It seems everything now is just a ChatGPT wrapper, and with GPT-4 around the corner I assume itll be even more prominent.

What are your thoughts?"
43,124eyso,MachineLearning,Open-AI,comments,2023-03-28 05:57:03,[N] OpenAI may have benchmarked GPT-4’s coding ability on it’s own training data,Balance-,False,0.97,1002,https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/,135,1679983023.0,"[GPT-4 and professional benchmarks: the wrong answer to the wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks)

*OpenAI may have tested on the training data. Besides, human benchmarks are meaningless for bots.*

 **Problem 1: training data contamination**

To benchmark GPT-4’s coding ability, OpenAI evaluated it on problems from Codeforces, a website that hosts coding competitions. Surprisingly, Horace He pointed out that GPT-4 solved 10/10 pre-2021 problems and 0/10 recent problems in the easy category. The training data cutoff for GPT-4 is September 2021. This strongly suggests that the model is able to memorize solutions from its training set — or at least partly memorize them, enough that it can fill in what it can’t recall.

As further evidence for this hypothesis, we tested it on Codeforces problems from different times in 2021. We found that it could regularly solve problems in the easy category before September 5, but none of the problems after September 12.

In fact, we can definitively show that it has memorized problems in its training set: when prompted with the title of a Codeforces problem, GPT-4 includes a link to the exact contest where the problem appears (and the round number is almost correct: it is off by one). Note that GPT-4 cannot access the Internet, so memorization is the only explanation."
44,10ijzi2,MachineLearning,Open-AI,comments,2023-01-22 13:44:49,[D] Couldn't devs of major GPTs have added an invisible but detectable watermark in the models?,scarynut,False,0.79,148,https://www.reddit.com/r/MachineLearning/comments/10ijzi2/d_couldnt_devs_of_major_gpts_have_added_an/,127,1674395089.0,"So LLMs like GPT3 have understandably raised concerns about the disruptiveness of faked texts, faked images and video, faked speech and so on. While this may likely change soon, as of now OpenAI controls the most accessible and competent LLM. And OpenAIs agenda is said in their own words to be to benefit mankind.

If so, wouldn't it make sense to add a sort of watermark to the output? A watermark built into the model parameters so that it could not easily be removed, but still detectable with some key or some other model. While it may not matter in the long run, it would set a precedent to further development and demonstrate some kind of responsibility for the disruptive nature of LLMs/GPTs.

Would it not be technically possible, nä would it make sense?"
45,13i8v1o,MachineLearning,Open-AI,comments,2023-05-15 13:48:19,[D] What do you think of new EU AI Act ?,BeautyInUgly,False,0.89,83,https://www.reddit.com/r/MachineLearning/comments/13i8v1o/d_what_do_you_think_of_new_eu_ai_act/,121,1684158499.0,"[https://technomancers.ai/eu-ai-act-to-target-us-open-source-software/](https://technomancers.ai/eu-ai-act-to-target-us-open-source-software/#more-561)

Will really change how AI will be deployed / regulated in BOTH the EU and the US is they pass, unless the US govt decides to pick and fight and does not comply"
46,11fbccz,MachineLearning,Open-AI,comments,2023-03-01 18:31:12,[D] OpenAI introduces ChatGPT and Whisper APIs (ChatGPT API is 1/10th the cost of GPT-3 API),minimaxir,False,0.97,575,https://www.reddit.com/r/MachineLearning/comments/11fbccz/d_openai_introduces_chatgpt_and_whisper_apis/,119,1677695472.0,"https://openai.com/blog/introducing-chatgpt-and-whisper-apis

> It is priced at $0.002 per 1k tokens, which is 10x cheaper than our existing GPT-3.5 models.

This is a massive, massive deal. For context, the reason GPT-3 apps took off over the past few months before ChatGPT went viral is because a) text-davinci-003 was released and was a significant performance increase and b) the cost was cut from $0.06/1k tokens to $0.02/1k tokens, which made consumer applications feasible without a large upfront cost.

A much better model and a 1/10th cost warps the economics completely to the point that it may be better than in-house finetuned LLMs.

I have no idea how OpenAI can make money on this. This has to be a loss-leader to lock out competitors before they even get off the ground."
47,11tenm7,MachineLearning,Open-AI,comments,2023-03-17 02:34:28,LLMs are getting much cheaper — business impact? [D],DamnMyAPGoinCrazy,False,0.96,298,https://www.reddit.com/r/MachineLearning/comments/11tenm7/llms_are_getting_much_cheaper_business_impact_d/,111,1679020468.0,"Saw this out of Stanford. Apologies if it’s been shared here already. 

*We introduce Alpaca 7B, a model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. On our preliminary evaluation of single-turn instruction following, Alpaca behaves qualitatively similarly to OpenAI’s text-davinci-003, while being surprisingly small and easy/cheap to reproduce (<600$).*

Basically, starting w an open source Meta 7B LLaMa model, they recruited GPT-3.5 to use for self-instruct training (as opposed to RLHF) and were able to produce a model that behaved similar to GPT-3.5. Amazingly, the process only took few weeks and $600 in compute cost.  

Any thoughts on how such low cost to train/deploy LLMs could affect companies like AMD, Nvidia and Intel etc? This seems like new idiom of AI tech and trying to wrap my head around CPU/GPU demand implications given the apparent orders of magnitude training cost reduction. 

Link: https://crfm.stanford.edu/2023/03/13/alpaca.html"
48,13fiw7r,MachineLearning,Open-AI,comments,2023-05-12 11:49:42,Open-source LLMs cherry-picking? [D],CacheMeUp,False,0.9,195,https://www.reddit.com/r/MachineLearning/comments/13fiw7r/opensource_llms_cherrypicking_d/,110,1683892182.0," Tried many small (<13B parameters) open-source LLMs on zero-shot classification tasks as instruction following (""Below is an input, answer the following yes/no question...""). All of them (except Flan-T5 family) yielded very poor results, including non-sensical text, failure to follow even single-step instructions and sometimes just copying the whole input to the output.

This is in strike contrast to the demos and results posted on the internet. Only OpenAI models provide consistently good (though inaccurate sometimes) results out of the box.

What could cause of this gap? Is it the generation hyperparameters or do these model require fine-tuning for classification?"
49,12bc8ym,MachineLearning,Open-AI,comments,2023-04-04 07:52:12,[D] What to do in this brave new world?,FeelingFirst756,False,0.75,77,https://www.reddit.com/r/MachineLearning/comments/12bc8ym/d_what_to_do_in_this_brave_new_world/,108,1680594732.0," I am 35. Few years ago it occurred to me that my Software Engineering job might be not enough for the future. For last (5?) years, I have started to meddle in machine learning. Slowly at first, but it even motivated me to finish my masters degree and land job as reseacher in one small company. Its more ML engineering than research but why not , I though. Then last year Open AI launched GPT-4. I feel like I wasted my time. In Cental Europe, where I live, ml research is on really weak level. Pursuing PhD probably doesn't make sense. I could land some position, but I would still have to work full time to feed my famil. I would make it, but I doubt, that anyone would take me to serious research program.I can imagine, that jobs in IT will slowly evaporate. It's not realistic to starte company in this time and to be honest - i dont see myself as some kind of big founder. In short, I see my future in very pesimistic light right now. I was wondering how you deal with this new reality, maybe you can suggest something that I didn't think about before? Where you plan to go? What you plan to do?"
50,1271po7,MachineLearning,Open-AI,comments,2023-03-30 22:40:29,[P] Introducing Vicuna: An open-source language model based on LLaMA 13B,Business-Lead2679,False,0.95,286,https://www.reddit.com/r/MachineLearning/comments/1271po7/p_introducing_vicuna_an_opensource_language_model/,107,1680216029.0,"We introduce Vicuna-13B, an open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Preliminary evaluation using GPT-4 as a judge shows Vicuna-13B achieves more than 90%\* quality of OpenAI ChatGPT and Google Bard while outperforming other models like LLaMA and Stanford Alpaca in more than 90%\* of cases. The cost of training Vicuna-13B is around $300. The training and serving [code](https://github.com/lm-sys/FastChat), along with an online [demo](https://chat.lmsys.org/), are publicly available for non-commercial use.

# Training details

Vicuna is created by fine-tuning a LLaMA base model using approximately 70K user-shared conversations gathered from ShareGPT.com with public APIs. To ensure data quality, we convert the HTML back to markdown and filter out some inappropriate or low-quality samples. Additionally, we divide lengthy conversations into smaller segments that fit the model’s maximum context length.

Our training recipe builds on top of [Stanford’s alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html) with the following improvements.

* **Memory Optimizations:** To enable Vicuna’s understanding of long context, we expand the max context length from 512 in alpaca to 2048, which substantially increases GPU memory requirements. We tackle the memory pressure by utilizing [gradient checkpointing](https://arxiv.org/abs/1604.06174) and [flash attention](https://arxiv.org/abs/2205.14135).
* **Multi-round conversations:** We adjust the training loss to account for multi-round conversations and compute the fine-tuning loss solely on the chatbot’s output.
* **Cost Reduction via Spot Instance:** The 40x larger dataset and 4x sequence length for training poses a considerable challenge in training expenses. We employ [SkyPilot](https://github.com/skypilot-org/skypilot) [managed spot](https://skypilot.readthedocs.io/en/latest/examples/spot-jobs.html) to reduce the cost by leveraging the cheaper spot instances with auto-recovery for preemptions and auto zone switch. This solution slashes costs for training the 7B model from $500 to around $140 and the 13B model from around $1K to $300.

&#x200B;

[Vicuna - Online demo](https://reddit.com/link/1271po7/video/0qsiu08kdyqa1/player)

# Limitations

We have noticed that, similar to other large language models, Vicuna has certain limitations. For instance, it is not good at tasks involving reasoning or mathematics, and it may have limitations in accurately identifying itself or ensuring the factual accuracy of its outputs. Additionally, it has not been sufficiently optimized to guarantee safety or mitigate potential toxicity or bias. To address the safety concerns, we use the OpenAI [moderation](https://platform.openai.com/docs/guides/moderation/overview) API to filter out inappropriate user inputs in our online demo. Nonetheless, we anticipate that Vicuna can serve as an open starting point for future research to tackle these limitations.

[Relative Response Quality Assessed by GPT-4](https://preview.redd.it/1rnmhv01eyqa1.png?width=599&format=png&auto=webp&s=02b4d415b5d378851bb70e225f1b1ebce98bfd83)

&#x200B;

For more information, check [https://vicuna.lmsys.org/](https://vicuna.lmsys.org/)

Online demo: [https://chat.lmsys.org/](https://chat.lmsys.org/)

&#x200B;

All credits go to the creators of this model. I did not participate in the creation of this model nor in the fine-tuning process. Usage of this model falls under a non-commercial license."
51,ysc7gs,MachineLearning,Open-AI,comments,2022-11-11 14:32:39,[D] Current Job Market in ML,diffusion-xgb,False,0.96,237,https://www.reddit.com/r/MachineLearning/comments/ysc7gs/d_current_job_market_in_ml/,100,1668177159.0,"Hi,

We all have heard about the layoffs in tech companies. How about ML/AI jobs? Do you observe a decrease in the number of job openings etc? 

I am a bit confused because there are so many AI startups now announcing getting funded. Someone in the industry who has more experience can maybe shed some light?"
52,137rxgw,MachineLearning,Open-AI,relevance,2023-05-04 16:13:30,"[D] Google ""We Have No Moat, And Neither Does OpenAI"": Leaked Internal Google Document Claims Open Source AI Will Outcompete Google and OpenAI",hardmaru,False,0.98,1178,https://www.semianalysis.com/p/google-we-have-no-moat-and-neither,206,1683216810.0,
53,11sboh1,MachineLearning,Open-AI,relevance,2023-03-15 22:34:01,[D] Our community must get serious about opposing OpenAI,SOCSChamp,False,0.95,2968,https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/,448,1678919641.0,"OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.

They have abandoned this idea entirely.

Today, with the release of GPT4 and their direct statement that they will not release details of the model creation due to ""safety concerns"" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.

AI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.

I get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.

We need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.

This conversation will only ever get more important."
54,12cvkvn,MachineLearning,Open-AI,relevance,2023-04-05 19:44:09,"[D] ""Our Approach to AI Safety"" by OpenAI",mckirkus,False,0.88,295,https://www.reddit.com/r/MachineLearning/comments/12cvkvn/d_our_approach_to_ai_safety_by_openai/,297,1680723849.0,"It seems OpenAI are steering the conversation away from the existential threat narrative and into things like accuracy, decency, privacy, economic risk, etc.

To the extent that they do buy the existential risk argument, they don't seem concerned much about GPT-4 making a leap into something dangerous, even if it's at the heart of autonomous agents that are currently emerging.  

>""Despite extensive research and testing, we cannot predict all of the [beneficial ways people will use our technology](https://openai.com/customer-stories), nor all the ways people will abuse it. That’s why we believe that learning from real-world use is a critical component of creating and releasing increasingly safe AI systems over time. ""

Article headers:

* Building increasingly safe AI systems
* Learning from real-world use to improve safeguards
* Protecting children
* Respecting privacy
* Improving factual accuracy

&#x200B;

[https://openai.com/blog/our-approach-to-ai-safety](https://openai.com/blog/our-approach-to-ai-safety)"
55,13b6miy,MachineLearning,Open-AI,relevance,2023-05-07 23:26:29,"[D] ClosedAI license, open-source license which restricts only OpenAI, Microsoft, Google, and Meta from commercial use",wemsyn,False,0.8,349,https://www.reddit.com/r/MachineLearning/comments/13b6miy/d_closedai_license_opensource_license_which/,191,1683501989.0,"After reading [this article](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither), I realized it might be nice if the open-source AI community could exclude ""closed AI"" players from taking advantage of community-generated models and datasets. I was wondering if it would be possible to write a license that is completely permissive (like Apache 2.0 or MIT), except to certain companies, which are completely barred from using the software in any context.

Maybe this could be called the ""ClosedAI"" license. I'm not any sort of legal expert so I have no idea how best to write this license such that it protects model weights and derivations thereof.

I prompted ChatGPT for an example license and this is what it gave me:

    <PROJECT NAME> ClosedAI License v1.0
    
    Permission is hereby granted, free of charge, to any person or organization obtaining a copy of this software and associated documentation files (the ""Software""), to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, subject to the following conditions:
    
    1. The above copyright notice and this license notice shall be included in all copies or substantial portions of the Software.
    
    2. The Software and any derivative works thereof may not be used, in whole or in part, by or on behalf of OpenAI Inc., Google LLC, or Microsoft Corporation (collectively, the ""Prohibited Entities"") in any capacity, including but not limited to training, inference, or serving of neural network models, or any other usage of the Software or neural network weights generated by the Software.
    
    3. Any attempt by the Prohibited Entities to use the Software or neural network weights generated by the Software is a material breach of this license.
    
    THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

No idea if this is valid or not. Looking for advice.

&#x200B;

**Edit:** Thanks for the input. Removed non-commercial clause (whoops, proofread what ChatGPT gives you). Also removed Meta from the excluded companies list due to popular demand."
56,126oiey,MachineLearning,Open-AI,relevance,2023-03-30 14:18:50,[D] AI Policy Group CAIDP Asks FTC To Stop OpenAI From Launching New GPT Models,vadhavaniyafaijan,False,0.84,205,https://www.reddit.com/r/MachineLearning/comments/126oiey/d_ai_policy_group_caidp_asks_ftc_to_stop_openai/,213,1680185930.0,"The Center for AI and Digital Policy (CAIDP), a tech ethics group, has asked the Federal Trade Commission to investigate OpenAI for violating consumer protection rules. CAIDP claims that OpenAI's AI text generation tools have been ""biased, deceptive, and a risk to public safety.""

CAIDP's complaint raises concerns about potential threats from OpenAI's GPT-4 generative text model, which was announced in mid-March. It warns of the potential for GPT-4 to produce malicious code and highly tailored propaganda and the risk that biased training data could result in baked-in stereotypes or unfair race and gender preferences in hiring. 

The complaint also mentions significant privacy failures with OpenAI's product interface, such as a recent bug that exposed OpenAI ChatGPT histories and possibly payment details of ChatGPT plus subscribers.

CAIDP seeks to hold OpenAI accountable for violating Section 5 of the FTC Act, which prohibits unfair and deceptive trade practices. The complaint claims that OpenAI knowingly released GPT-4 to the public for commercial use despite the risks, including potential bias and harmful behavior. 

[Source](https://www.theinsaneapp.com/2023/03/stop-openai-from-launching-gpt-5.html) | [Case](https://www.caidp.org/cases/openai/)| [PDF](https://www.caidp.org/app/download/8450269463/CAIDP-FTC-Complaint-OpenAI-GPT-033023.pdf)"
57,124eyso,MachineLearning,Open-AI,relevance,2023-03-28 05:57:03,[N] OpenAI may have benchmarked GPT-4’s coding ability on it’s own training data,Balance-,False,0.97,1001,https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/,135,1679983023.0,"[GPT-4 and professional benchmarks: the wrong answer to the wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks)

*OpenAI may have tested on the training data. Besides, human benchmarks are meaningless for bots.*

 **Problem 1: training data contamination**

To benchmark GPT-4’s coding ability, OpenAI evaluated it on problems from Codeforces, a website that hosts coding competitions. Surprisingly, Horace He pointed out that GPT-4 solved 10/10 pre-2021 problems and 0/10 recent problems in the easy category. The training data cutoff for GPT-4 is September 2021. This strongly suggests that the model is able to memorize solutions from its training set — or at least partly memorize them, enough that it can fill in what it can’t recall.

As further evidence for this hypothesis, we tested it on Codeforces problems from different times in 2021. We found that it could regularly solve problems in the easy category before September 5, but none of the problems after September 12.

In fact, we can definitively show that it has memorized problems in its training set: when prompted with the title of a Codeforces problem, GPT-4 includes a link to the exact contest where the problem appears (and the round number is almost correct: it is off by one). Note that GPT-4 cannot access the Internet, so memorization is the only explanation."
58,11okrni,MachineLearning,Open-AI,relevance,2023-03-11 13:54:22,[Discussion] Compare OpenAI and SentenceTransformer Sentence Embeddings,Simusid,False,0.94,536,https://i.redd.it/7muze2s684na1.png,58,1678542862.0,
59,10gtruu,MachineLearning,Open-AI,relevance,2023-01-20 10:41:04,[N] OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic,ChubChubkitty,False,0.83,523,https://www.reddit.com/r/MachineLearning/comments/10gtruu/n_openai_used_kenyan_workers_on_less_than_2_per/,246,1674211264.0,https://time.com/6247678/openai-chatgpt-kenya-workers/
60,13aotyf,MachineLearning,Open-AI,relevance,2023-05-07 14:12:18,[P] I made a dashboard to analyze OpenAI API usage,cryptotrendz,False,0.91,414,https://v.redd.it/w7ahlql0ccya1,73,1683468738.0,
61,12rxtjj,MachineLearning,Open-AI,relevance,2023-04-19 15:29:34,"[N] Stability AI announce their open-source language model, StableLM",Philpax,False,0.99,829,https://www.reddit.com/r/MachineLearning/comments/12rxtjj/n_stability_ai_announce_their_opensource_language/,182,1681918174.0,"Repo: https://github.com/stability-AI/stableLM/

Excerpt from the Discord announcement:

> We’re incredibly excited to announce the launch of StableLM-Alpha; a nice and sparkly newly released open-sourced language model! Developers, researchers, and curious hobbyists alike can freely inspect, use, and adapt our StableLM base models for commercial and or research purposes! *Excited yet?*
>
> Let’s talk about parameters! The Alpha version of the model is available in 3 billion and 7 billion parameters, with 15 billion to 65 billion parameter models to follow. StableLM is trained on a new experimental dataset built on “The Pile” from EleutherAI (a 825GiB diverse, open source language modeling data set that consists of 22 smaller, high quality datasets combined together!) The richness of this dataset gives StableLM surprisingly high performance in conversational and coding tasks, despite its small size of 3-7 billion parameters."
62,139yc73,MachineLearning,Open-AI,relevance,2023-05-06 18:41:02,[R][P] I made an app for Instant Image/Text to 3D using ShapE from OpenAI,perception-eng,False,0.96,813,https://i.redd.it/1j4h1oyda9ya1.gif,63,1683398462.0,
63,12arwkf,MachineLearning,Open-AI,relevance,2023-04-03 17:47:06,[D] Is there currently anything comparable to the OpenAI API?,AltruisticDiamond915,False,0.9,174,https://www.reddit.com/r/MachineLearning/comments/12arwkf/d_is_there_currently_anything_comparable_to_the/,74,1680544026.0,"I am a designer and a small frontend developer. The OpenAI API makes it extremely easy for me to build AI functionality into apps, although I only have a very basic understanding of AI. Though of course I can't make any deep changes, I am even able to fine tune models and adapt them for my intended use. 

Now I was wondering if there is anything comparable on the market at the moment. I know of Meta's LLaMA, but you can only use it locally, which makes it harder to easily implement into applications. Also, you are not allowed to use it for commercial purposes. 

I haven't found much from Google or other tech companies. Does OpenAI have a monopoly here or are there alternatives worth mentioning that could be used?"
64,11fbccz,MachineLearning,Open-AI,relevance,2023-03-01 18:31:12,[D] OpenAI introduces ChatGPT and Whisper APIs (ChatGPT API is 1/10th the cost of GPT-3 API),minimaxir,False,0.97,579,https://www.reddit.com/r/MachineLearning/comments/11fbccz/d_openai_introduces_chatgpt_and_whisper_apis/,119,1677695472.0,"https://openai.com/blog/introducing-chatgpt-and-whisper-apis

> It is priced at $0.002 per 1k tokens, which is 10x cheaper than our existing GPT-3.5 models.

This is a massive, massive deal. For context, the reason GPT-3 apps took off over the past few months before ChatGPT went viral is because a) text-davinci-003 was released and was a significant performance increase and b) the cost was cut from $0.06/1k tokens to $0.02/1k tokens, which made consumer applications feasible without a large upfront cost.

A much better model and a 1/10th cost warps the economics completely to the point that it may be better than in-house finetuned LLMs.

I have no idea how OpenAI can make money on this. This has to be a loss-leader to lock out competitors before they even get off the ground."
65,zc5sg6,MachineLearning,Open-AI,relevance,2022-12-04 09:57:44,[D] OpenAI’s ChatGPT is unbelievable good in telling stories!,Far_Pineapple770,False,0.91,245,https://www.reddit.com/r/MachineLearning/comments/zc5sg6/d_openais_chatgpt_is_unbelievable_good_in_telling/,85,1670147864.0,"
I started playing with ChatGPT, the new chatbot created by OpenAI and is free to use at the moment. 

I asked it to describe a scene between Batman and Joker on a subway platform and the result is mind blowing! I let you have a read of the story yourself:

Generated by ChatGPT:

The scene is set in a dimly lit subway station, with the Joker standing on the platform, gazing up at Batman who is perched on a nearby overhead beam. The Joker is dressed in his signature purple suit and green hair, a wicked grin plastered across his face.

In his hand, he holds a deck of playing cards, flipping them expertly through his fingers. The sound of the cards shuffling echoes through the empty station.

Batman, dressed in his dark suit and cape, stares down at the Joker with a steely gaze. His muscles are tense, ready for any sudden movements from the villain.

The Joker cackles, his laughter bouncing off the walls of the station. ""Hello, Batsy! Long time no see. How's the crime-fighting business these days?""

Batman remains silent, watching the Joker carefully.

The Joker's grin widens. ""Come on, Bats. Don't be so serious all the time. Let's have some fun."" He tosses a card at Batman, who easily catches it.

""I'm not here to play games, Joker,"" Batman says in a grave tone.

The Joker's laughter turns into a maniacal cackle. ""But that's the whole point, Batsy! Life is a game. And I'm the master of it.""

He pulls out a bomb from his pocket and holds it up, the timer ticking down. ""Let's see how well you can play, shall we?""

Batman leaps down from the beam, landing gracefully on the platform. He advances towards the Joker, who backs away, still holding the bomb.

The tension in the air is palpable as the two foes face off, each ready to outsmart the other. The sound of the bomb's timer counts down, adding to the tension of the scene.

The Joker's grin never fades, even as Batman inches closer. ""It's always a pleasure to play with you, Batsy. But I think it's time for me to make my exit.""

With a flourish, the Joker disappears in a cloud of smoke, leaving Batman standing alone on the platform. The bomb detonates, causing a small explosion and sending debris flying.

But Batman remains unharmed, ready to continue the never-ending battle against the Joker and all the evil that plagues the city.

End of the story.

I used the first two paragraphs in OpenAI’s Dall E 2 to generate an image and [this](https://labs.openai.com/s/p8L8Z6c3S7qZ26U7owfbx7lS) is the result I got.

Please keep in mind that this is the very beginning of this tool and think about the endless possibilities it can create."
66,zubg2u,MachineLearning,Open-AI,relevance,2022-12-24 14:58:19,[R][P] I made an app for Instant Image/Text to 3D using PointE from OpenAI,perception-eng,False,0.97,767,https://i.redd.it/ox6urwwa1v7a1.gif,42,1671893899.0,
67,ynz4m1,MachineLearning,Open-AI,relevance,2022-11-06 18:58:59,[P] Transcribe any podcast episode in just 1 minute with optimized OpenAI/whisper,thundergolfer,False,0.97,465,https://v.redd.it/wnt66ghfody91,43,1667761139.0,
68,122tddh,MachineLearning,Open-AI,relevance,2023-03-26 17:31:18,[P] SimpleAI : A self-hosted alternative to OpenAI API,lhenault,False,0.96,129,https://www.reddit.com/r/MachineLearning/comments/122tddh/p_simpleai_a_selfhosted_alternative_to_openai_api/,21,1679851878.0,"Hey everyone,

I wanted to share with you [SimpleAI](https://github.com/lhenault/simpleAI), a self-hosted alternative to OpenAI API.

The aim of this project is to replicate the (main) endpoints of [OpenAI API](https://platform.openai.com/docs/introduction), and to let you easily and quickly plug in any new model. It basically allows you to deploy your custom model wherever you want and easily, while minimizing the amount of changes both on server and client sides.

It's compatible with the [OpenAI client](https://github.com/openai/openai-python) so you don't have to change much in your existing code (or can use it to easily query your API).

Wether you like or not the AI-as-a-service approach of OpenAI, I think that project could be of interest to many. Even if you are fully satisfied with a paid API, you might be interested in this if:

* You need a model fine tuned on some specific language and don't see any good alternative, or your company data is too sensitive to send it to an external service

* You’ve developped your own awesome model, and want a drop-in replacement to switch to yours, to be able to A/B test the two approaches.

* You're deploying your services in an infrastructure with an unreliable internet connection, so you would rather have your service locally

* You're just another AI enthusiast with a lot of spare time and free GPU

I've personally really enjoyed how open the ML(Ops) community has been in the past years, and seeing how the industry seems to be moving towards paid API and black box systems can be a bit worrying. This project might be useful to expose great, community-based alternatives.


If that sounds interesting, please have a look at the [examples](https://github.com/lhenault/simpleAI/tree/main/examples). I also have a [blogpost](https://louishenault.com/p/replicating-openai-api-for-llama-alpaca-or-any-animal-shaped-llm/) explaining a few more things.


Thank you!"
69,13a5baq,MachineLearning,Open-AI,relevance,2023-05-06 23:08:09,[P] OpenAI vs Open Source LLM Comparison for Document Q&A,georgesung,False,0.95,94,https://www.reddit.com/r/MachineLearning/comments/13a5baq/p_openai_vs_open_source_llm_comparison_for/,16,1683414489.0,"Ran a fun comparison between OpenAI vs open source (Apache 2.0) LLMs for Wikipedia document Q&A -- open source is looking good (and getting better).

TLDR:

For simple Wikipedia article Q&A, I compared OpenAI GPT 3.5, FastChat-T5, FLAN-T5-XXL, and FLAN-T5-XL. GPT 3.5 provided the best answers, but FastChat-T5 was very close in performance (with a basic guardrail). The T5 models I tested are all licensed under Apache 2.0, so they are commercially viable.

For the embedding model, I compared OpenAI text-embedding-ada-002 and the open source INSTRUCTOR-XL models. The INSTRUCTOR-XL model performed better, which is encouraging since INSTRUCTOR-XL is also licensed under Apache 2.0.

Full blog post:

[https://georgesung.github.io/ai/llm-qa-eval-wikipedia/](https://georgesung.github.io/ai/llm-qa-eval-wikipedia/)"
70,12fdnad,MachineLearning,Open-AI,relevance,2023-04-08 06:23:40,[D] Alternatives to OpenAI for summarization and instruction following?,du_keule,False,0.92,58,https://www.reddit.com/r/MachineLearning/comments/12fdnad/d_alternatives_to_openai_for_summarization_and/,34,1680935020.0,"Hey y’all. As privacy concerns are mounting about OpenAI, and as someone who has built a product on top of their platform, I’m wondering what kind of alternatives exist that could accomplish the same results as GPT 3.5 and be able to be used commercially? It looks like Alpaca would do well, but it’s not able to be used commercially. 

Basically my product summarizes Slack threads and answers questions based on a given prompt. Some users have expressed concern about sending their company’s data to OpenAI, and honestly it would be an edge to have in the market if I could run an LLM  in my VPC. Thanks!"
71,zjbsie,MachineLearning,Open-AI,relevance,2022-12-11 22:16:43,"[D] - Has Open AI said what ChatGPT's architecture is? What technique is it using to ""remember"" previous prompts?",029187,False,0.95,244,https://www.reddit.com/r/MachineLearning/comments/zjbsie/d_has_open_ai_said_what_chatgpts_architecture_is/,88,1670797003.0,"Has Open AI said what ChatGPT's architecture is? What technique is it using to ""remember"" previous prompts? Have they come up with some way to add recurrence to the transformer or is it just using a feedforward sliding window approach?"
72,yli0r7,MachineLearning,Open-AI,relevance,2022-11-03 23:12:45,"[D] DALL·E to be made available as API, OpenAI to give users full ownership rights to generated images",TiredOldCrow,False,0.98,422,https://www.reddit.com/r/MachineLearning/comments/yli0r7/d_dalle_to_be_made_available_as_api_openai_to/,55,1667517165.0,"Email announcement from OpenAI below:


> DALL·E is now available as an API


> You can now integrate state of the art image generation capabilities directly into your apps and products through our new DALL·E API.


> You own the generations you create with DALL·E.


> We’ve simplified our [Terms of Use](https://openai.com/api/policies/terms/) and you now have full ownership rights to the images you create with DALL·E — in addition to the usage rights you’ve already had to use and monetize your creations however you’d like. This update is possible due to improvements to our safety systems which minimize the ability to generate content that violates our content policy.


> Sort and showcase with collections.


> You can now organize your DALL·E creations in multiple collections. Share them publicly or keep them private. Check out our [sea otter collection](https://labs.openai.com/sc/w3Q8nqVN69qkEA3ePSmrGb5t)!


> We’re constantly amazed by the innovative ways you use DALL·E and love seeing your creations out in the world. Artists who would like their work to be shared on our Instagram can request to be featured using Instagram’s collab tool. DM us there to show off how you’re using the API!  

> \- The OpenAI Team"
73,1323w68,MachineLearning,Open-AI,relevance,2023-04-28 17:30:18,"[N] LAION publishes an open letter to ""protect open-source AI in Europe"" with Schmidhuber and Hochreiter as signatories",Philpax,False,0.98,402,https://www.reddit.com/r/MachineLearning/comments/1323w68/n_laion_publishes_an_open_letter_to_protect/,61,1682703018.0,https://laion.ai/notes/letter-to-the-eu-parliament/
74,12q8rp1,MachineLearning,Open-AI,relevance,2023-04-18 03:30:03,[Discussion] OpenAI Embeddings API alternative?,HueX1,False,0.83,18,https://www.reddit.com/r/MachineLearning/comments/12q8rp1/discussion_openai_embeddings_api_alternative/,15,1681788603.0,"Do you know an API which hosts an OpenAI embeddings alternative? If have the criteria that the embedding size needs to be max. 1024.

I know there are interesting models like [e5-large](https://huggingface.co/intfloat/e5-large) and Instructor-xl, but I specifically need an API as I don't want to set up my own server.The Huggingface Hosted Inference API is too expensive, as I need to pay for it even if I don't use it, by just keeping it running."
75,11waamh,MachineLearning,Open-AI,relevance,2023-03-20 06:00:51,[News] Prompt engineering blog from OpenAI applied AI head,LouisAckerman,False,0.92,92,https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/,6,1679292051.0,
76,12dkla0,MachineLearning,Open-AI,relevance,2023-04-06 13:35:43,[D] Working with Various OpenAI Models - My Thoughts and Experiences,bart_so,False,0.86,186,https://www.reddit.com/r/MachineLearning/comments/12dkla0/d_working_with_various_openai_models_my_thoughts/,20,1680788143.0,"I'd like to share some of my insights from working with OpenAI models on my project. I'm not exactly a tech person, so some of these observations might be obvious to some of you, but I think they're worth sharing for those with less experience or who aren't directly in the field.

**Intro:**

In early February, my friends and I started a side project where we aimed to build an AI portal called DoMoreAI. For the first two months, we focused on creating an AI tools catalog. Our experiment is based on the idea that in the future, companies will be ""Managed by AI, and Driven by Humans."" So, our goal was to leave as much as possible to AI and automation, with all the consequences that come with it. As mentioned before, I'm not a tech guy, but I've been playing with OpenAI models for the past few years, so I had some experience when starting this project.

**Tasks We Assigned to AI:**

Based on an AI tool's front page, we had the AI write a one-sentence summary of an AI project + write a more in-depth review of the project, categorize the project into different categories (WHAT category, like blog; TASK category, like writing; FOR category, like content creator), decide if the project offers iOS app, Android app, browser extension, API, find social media links, process information about prices and pricing policy, and more.

**Interesting Findings:**

1. When working on a more complex prompt, particularly one with several tasks, you have to be patient when crafting it. You might eventually find the right wording to achieve the desired results, but it takes time and lots of trial and error. You might even be surprised by what works and what doesn't. 
2. If cost isn't an issue, you can always break up one complex prompt into several smaller prompts. However, the more requests you send, the higher the chance of encountering errors like the 429 error, which may require setting up more sophisticated error handlers for the whole process. 
3. You need error handlers because, without them, the automation process will suffer. 
4. With more complex prompts, there are no prompts that always yield the expected results, so you have to plan for what to do if the results aren't satisfactory and how to determine if the result meets your expectations or not. 
5. GPT-3.0 struggled with outputting JSON strings as requested, but GPT-3.5 is much better at this task. I'd say the number of errors from improperly formatting the response in JSON is 3-4 times lower for GPT-3.5. 
6. AI models have trouble distinguishing words singular forms from plural forms. 
7. Just because you can use AI for a given task doesn't mean you should. Often, standard techniques like using regex can yield better results when extracting something from text than relying solely on AI. A hybrid solution often provides the best results. 
8. We're using ADA vector embeddings and Pinecone for semantic search in our catalog, and I was really surprised to find that this kind of semantic search works in any language. Even if all the content on our page is in English, you can search in another language and still get decent results.

**The Best Mishaps:**

* As you may know, there's a token limit for requests, so we have to ensure that we don't send too long a part of the front page to the model. Sometimes, this led to funny situations. If the HTML of the page consists mainly of styles and the model is fed only with styles, then when you ask the AI to write a review of the project, it writes about how beautiful, mobile-friendly, etc., the project is. 
* For one project, instead of writing the one-sentence summary, the model's output only included the prompt we were using to generate the summary (needless to say, it was automatically published on our website ;))

&#x200B;

I hope this post will be useful. We are currently running a campaign on Product Hunt: [https://www.producthunt.com/posts/domore-ai](https://www.producthunt.com/posts/domore-ai)

So, if you have any feedback for us or think what we're doing is cool, don't hesitate to support us :)"
