,id,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,url,num_comments,created,body
0,11vdhrb,datasets,LLM,top,2023-03-19 06:25:24,[Synthetic] datasetGPT - A command-line tool to generate datasets by inferencing LLMs at scale. It can even make two ChatGPT agents talk with one another.,radi-cho,False,0.97,64,https://www.reddit.com/r/datasets/comments/11vdhrb/synthetic_datasetgpt_a_commandline_tool_to/,0,1679207124.0,"GitHub: [https://github.com/radi-cho/datasetGPT](https://github.com/radi-cho/datasetGPT)

It can generate texts by varying input parameters and using multiple backends. But, personally, the conversations dataset generation is my favorite: It can produce dialogues between two ChatGPT agents.

Possible use cases may include:

* Constructing textual corpora to train/fine-tune detectors for content written by AI.
* Collecting datasets of LLM-produced conversations for research purposes, analysis of AI performance/impact/ethics, etc.
* Automating a task that a LLM can handle over big amounts of input texts. For example, using GPT-3 to summarize 1000 paragraphs with a single CLI command.
* Leveraging APIs of especially big LLMs to produce diverse texts for a specific task and then fine-tune a smaller model with them.

What would you use it for?"
1,12ttcc2,datasets,LLM,top,2023-04-21 06:59:26,"Diifferent LLM scores on 6 different measurements, plus their RAM usage",cavedave,False,1.0,25,https://docs.google.com/spreadsheets/d/1kT4or6b0Fedd-W_jMwYpb63e1ZR3aePczz3zlbJW-Y4/edit?usp=drivesdk,0,1682060366.0,
2,12ptimn,datasets,LLM,top,2023-04-17 19:21:48,Anthropic RLHF Dataset: Human Preference Data (+ errors I found),cmauck10,False,0.96,24,https://www.reddit.com/r/datasets/comments/12ptimn/anthropic_rlhf_dataset_human_preference_data/,1,1681759308.0,"Hello friends!

I recently found this RLHF-style dataset while browsing Hugging Face Datasets. With Reinforcement Learning from Human Feedback (RLHF) becoming the primary way to train AI assistants, it’s great to see organizations like [Anthropic](https://www.anthropic.com/) making their RLHF dataset publicly available (released as: [hh-rlhf](https://huggingface.co/datasets/Anthropic/hh-rlhf)). 

Like other RLHF datasets, every example in this one includes an input prompt and two outputs generated by the LLM: a chosen output and a rejected output, where a human-rater preferred the former over the latter."
3,zkib1h,datasets,LLM,top,2022-12-13 01:29:12,36% of HellaSwag benchmark contains errors [self-promotion],BB4evaTB12,False,0.69,8,https://www.reddit.com/r/datasets/comments/zkib1h/36_of_hellaswag_benchmark_contains_errors/,0,1670894952.0,"Continuing my analysis of errors in widely-used large language model benchmarks (post on Google's GoEmotions [here](https://www.reddit.com/r/MachineLearning/comments/vye69k/30_of_googles_reddit_emotions_dataset_is/)) — I analyzed HellaSwag and found 36% contains errors.

For example, here's a prompt and set of possible completions from the dataset. Which completion do you think is most appropriate? See if you can figure it out through the haze of typos and generally non-sensical writing.

*Men are standing in a large green field playing lacrosse. People* *is* *around the field watching the game. men*

* *are holding tshirts watching* *int* *lacrosse playing.*
* *are being interviewed in a podium in front of a large group and a gymnast is holding a microphone for the announcers.*
* *are running side to side* *of* *the* *ield* *playing lacrosse trying to score.*
* *are in a field running around playing lacrosse.*

I'll keep it spoiler-free here, but the full blog post goes into detail on this example (and others) and explains why they are so problematic.

Link: [https://www.surgehq.ai/blog/hellaswag-or-hellabad-36-of-this-popular-llm-benchmark-contains-errors](https://www.surgehq.ai/blog/hellaswag-or-hellabad-36-of-this-popular-llm-benchmark-contains-errors)"
4,139w4m6,datasets,LLM,top,2023-05-06 17:20:18,Best tools/techniques for capturing workflow data?,Constant-Potato-4712,False,1.0,1,https://www.reddit.com/r/datasets/comments/139w4m6/best_toolstechniques_for_capturing_workflow_data/,1,1683393618.0,"Are there any good tools/techniques for capturing workflow data, specifically to help train an LLM? Use case is accurate question answering around processes/best practices inside an organization.

Is this where something like a UiPath would be necessary?"
5,13dibzt,datasets,LLM,top,2023-05-10 06:28:07,Looking for dataset for LLM tokenization: need around 1GB multi-lingual + code,Pan000,False,1.0,1,https://www.reddit.com/r/datasets/comments/13dibzt/looking_for_dataset_for_llm_tokenization_need/,1,1683700087.0,"I've been working on a tokenizer that determines the best possible tokens to represent the test dataset in the least number of tokens for various different vocabulary sizes.

It works well but I've been testing with The Pile test data, but it's mostly English so it's a not good representation for multi-lingual. It also lacks a fair amount of code and tags.

I need around 1-2GB raw text uncleaned and uncensored, that represents a few different languages and a fair amount of code from different programming languages. Better to be raw, and include data both with HTML tags as it would be when scraped, and also without HTML tags (as it would prioritize the HTML tags too heavily if they were always present).

So just a good representation of general text.

I know I could build my own dataset from various different ones, but it seems to me that a dataset like this should already exist. Any leads would be helpful. Thank you."
6,139w4m6,datasets,LLM,comments,2023-05-06 17:20:18,Best tools/techniques for capturing workflow data?,Constant-Potato-4712,False,1.0,1,https://www.reddit.com/r/datasets/comments/139w4m6/best_toolstechniques_for_capturing_workflow_data/,1,1683393618.0,"Are there any good tools/techniques for capturing workflow data, specifically to help train an LLM? Use case is accurate question answering around processes/best practices inside an organization.

Is this where something like a UiPath would be necessary?"
7,13dibzt,datasets,LLM,comments,2023-05-10 06:28:07,Looking for dataset for LLM tokenization: need around 1GB multi-lingual + code,Pan000,False,1.0,1,https://www.reddit.com/r/datasets/comments/13dibzt/looking_for_dataset_for_llm_tokenization_need/,1,1683700087.0,"I've been working on a tokenizer that determines the best possible tokens to represent the test dataset in the least number of tokens for various different vocabulary sizes.

It works well but I've been testing with The Pile test data, but it's mostly English so it's a not good representation for multi-lingual. It also lacks a fair amount of code and tags.

I need around 1-2GB raw text uncleaned and uncensored, that represents a few different languages and a fair amount of code from different programming languages. Better to be raw, and include data both with HTML tags as it would be when scraped, and also without HTML tags (as it would prioritize the HTML tags too heavily if they were always present).

So just a good representation of general text.

I know I could build my own dataset from various different ones, but it seems to me that a dataset like this should already exist. Any leads would be helpful. Thank you."
8,12ptimn,datasets,LLM,comments,2023-04-17 19:21:48,Anthropic RLHF Dataset: Human Preference Data (+ errors I found),cmauck10,False,0.96,24,https://www.reddit.com/r/datasets/comments/12ptimn/anthropic_rlhf_dataset_human_preference_data/,1,1681759308.0,"Hello friends!

I recently found this RLHF-style dataset while browsing Hugging Face Datasets. With Reinforcement Learning from Human Feedback (RLHF) becoming the primary way to train AI assistants, it’s great to see organizations like [Anthropic](https://www.anthropic.com/) making their RLHF dataset publicly available (released as: [hh-rlhf](https://huggingface.co/datasets/Anthropic/hh-rlhf)). 

Like other RLHF datasets, every example in this one includes an input prompt and two outputs generated by the LLM: a chosen output and a rejected output, where a human-rater preferred the former over the latter."
9,12ttcc2,datasets,LLM,comments,2023-04-21 06:59:26,"Diifferent LLM scores on 6 different measurements, plus their RAM usage",cavedave,False,1.0,25,https://docs.google.com/spreadsheets/d/1kT4or6b0Fedd-W_jMwYpb63e1ZR3aePczz3zlbJW-Y4/edit?usp=drivesdk,0,1682060366.0,
10,11vdhrb,datasets,LLM,comments,2023-03-19 06:25:24,[Synthetic] datasetGPT - A command-line tool to generate datasets by inferencing LLMs at scale. It can even make two ChatGPT agents talk with one another.,radi-cho,False,0.96,62,https://www.reddit.com/r/datasets/comments/11vdhrb/synthetic_datasetgpt_a_commandline_tool_to/,0,1679207124.0,"GitHub: [https://github.com/radi-cho/datasetGPT](https://github.com/radi-cho/datasetGPT)

It can generate texts by varying input parameters and using multiple backends. But, personally, the conversations dataset generation is my favorite: It can produce dialogues between two ChatGPT agents.

Possible use cases may include:

* Constructing textual corpora to train/fine-tune detectors for content written by AI.
* Collecting datasets of LLM-produced conversations for research purposes, analysis of AI performance/impact/ethics, etc.
* Automating a task that a LLM can handle over big amounts of input texts. For example, using GPT-3 to summarize 1000 paragraphs with a single CLI command.
* Leveraging APIs of especially big LLMs to produce diverse texts for a specific task and then fine-tune a smaller model with them.

What would you use it for?"
11,zkib1h,datasets,LLM,comments,2022-12-13 01:29:12,36% of HellaSwag benchmark contains errors [self-promotion],BB4evaTB12,False,0.69,8,https://www.reddit.com/r/datasets/comments/zkib1h/36_of_hellaswag_benchmark_contains_errors/,0,1670894952.0,"Continuing my analysis of errors in widely-used large language model benchmarks (post on Google's GoEmotions [here](https://www.reddit.com/r/MachineLearning/comments/vye69k/30_of_googles_reddit_emotions_dataset_is/)) — I analyzed HellaSwag and found 36% contains errors.

For example, here's a prompt and set of possible completions from the dataset. Which completion do you think is most appropriate? See if you can figure it out through the haze of typos and generally non-sensical writing.

*Men are standing in a large green field playing lacrosse. People* *is* *around the field watching the game. men*

* *are holding tshirts watching* *int* *lacrosse playing.*
* *are being interviewed in a podium in front of a large group and a gymnast is holding a microphone for the announcers.*
* *are running side to side* *of* *the* *ield* *playing lacrosse trying to score.*
* *are in a field running around playing lacrosse.*

I'll keep it spoiler-free here, but the full blog post goes into detail on this example (and others) and explains why they are so problematic.

Link: [https://www.surgehq.ai/blog/hellaswag-or-hellabad-36-of-this-popular-llm-benchmark-contains-errors](https://www.surgehq.ai/blog/hellaswag-or-hellabad-36-of-this-popular-llm-benchmark-contains-errors)"
12,12ttcc2,datasets,LLM,relevance,2023-04-21 06:59:26,"Diifferent LLM scores on 6 different measurements, plus their RAM usage",cavedave,False,1.0,25,https://docs.google.com/spreadsheets/d/1kT4or6b0Fedd-W_jMwYpb63e1ZR3aePczz3zlbJW-Y4/edit?usp=drivesdk,0,1682060366.0,
13,13dibzt,datasets,LLM,relevance,2023-05-10 06:28:07,Looking for dataset for LLM tokenization: need around 1GB multi-lingual + code,Pan000,False,1.0,1,https://www.reddit.com/r/datasets/comments/13dibzt/looking_for_dataset_for_llm_tokenization_need/,1,1683700087.0,"I've been working on a tokenizer that determines the best possible tokens to represent the test dataset in the least number of tokens for various different vocabulary sizes.

It works well but I've been testing with The Pile test data, but it's mostly English so it's a not good representation for multi-lingual. It also lacks a fair amount of code and tags.

I need around 1-2GB raw text uncleaned and uncensored, that represents a few different languages and a fair amount of code from different programming languages. Better to be raw, and include data both with HTML tags as it would be when scraped, and also without HTML tags (as it would prioritize the HTML tags too heavily if they were always present).

So just a good representation of general text.

I know I could build my own dataset from various different ones, but it seems to me that a dataset like this should already exist. Any leads would be helpful. Thank you."
14,11vdhrb,datasets,LLM,relevance,2023-03-19 06:25:24,[Synthetic] datasetGPT - A command-line tool to generate datasets by inferencing LLMs at scale. It can even make two ChatGPT agents talk with one another.,radi-cho,False,0.97,62,https://www.reddit.com/r/datasets/comments/11vdhrb/synthetic_datasetgpt_a_commandline_tool_to/,0,1679207124.0,"GitHub: [https://github.com/radi-cho/datasetGPT](https://github.com/radi-cho/datasetGPT)

It can generate texts by varying input parameters and using multiple backends. But, personally, the conversations dataset generation is my favorite: It can produce dialogues between two ChatGPT agents.

Possible use cases may include:

* Constructing textual corpora to train/fine-tune detectors for content written by AI.
* Collecting datasets of LLM-produced conversations for research purposes, analysis of AI performance/impact/ethics, etc.
* Automating a task that a LLM can handle over big amounts of input texts. For example, using GPT-3 to summarize 1000 paragraphs with a single CLI command.
* Leveraging APIs of especially big LLMs to produce diverse texts for a specific task and then fine-tune a smaller model with them.

What would you use it for?"
15,139w4m6,datasets,LLM,relevance,2023-05-06 17:20:18,Best tools/techniques for capturing workflow data?,Constant-Potato-4712,False,1.0,1,https://www.reddit.com/r/datasets/comments/139w4m6/best_toolstechniques_for_capturing_workflow_data/,1,1683393618.0,"Are there any good tools/techniques for capturing workflow data, specifically to help train an LLM? Use case is accurate question answering around processes/best practices inside an organization.

Is this where something like a UiPath would be necessary?"
16,zkib1h,datasets,LLM,relevance,2022-12-13 01:29:12,36% of HellaSwag benchmark contains errors [self-promotion],BB4evaTB12,False,0.63,6,https://www.reddit.com/r/datasets/comments/zkib1h/36_of_hellaswag_benchmark_contains_errors/,0,1670894952.0,"Continuing my analysis of errors in widely-used large language model benchmarks (post on Google's GoEmotions [here](https://www.reddit.com/r/MachineLearning/comments/vye69k/30_of_googles_reddit_emotions_dataset_is/)) — I analyzed HellaSwag and found 36% contains errors.

For example, here's a prompt and set of possible completions from the dataset. Which completion do you think is most appropriate? See if you can figure it out through the haze of typos and generally non-sensical writing.

*Men are standing in a large green field playing lacrosse. People* *is* *around the field watching the game. men*

* *are holding tshirts watching* *int* *lacrosse playing.*
* *are being interviewed in a podium in front of a large group and a gymnast is holding a microphone for the announcers.*
* *are running side to side* *of* *the* *ield* *playing lacrosse trying to score.*
* *are in a field running around playing lacrosse.*

I'll keep it spoiler-free here, but the full blog post goes into detail on this example (and others) and explains why they are so problematic.

Link: [https://www.surgehq.ai/blog/hellaswag-or-hellabad-36-of-this-popular-llm-benchmark-contains-errors](https://www.surgehq.ai/blog/hellaswag-or-hellabad-36-of-this-popular-llm-benchmark-contains-errors)"
17,12ptimn,datasets,LLM,relevance,2023-04-17 19:21:48,Anthropic RLHF Dataset: Human Preference Data (+ errors I found),cmauck10,False,0.96,24,https://www.reddit.com/r/datasets/comments/12ptimn/anthropic_rlhf_dataset_human_preference_data/,1,1681759308.0,"Hello friends!

I recently found this RLHF-style dataset while browsing Hugging Face Datasets. With Reinforcement Learning from Human Feedback (RLHF) becoming the primary way to train AI assistants, it’s great to see organizations like [Anthropic](https://www.anthropic.com/) making their RLHF dataset publicly available (released as: [hh-rlhf](https://huggingface.co/datasets/Anthropic/hh-rlhf)). 

Like other RLHF datasets, every example in this one includes an input prompt and two outputs generated by the LLM: a chosen output and a rejected output, where a human-rater preferred the former over the latter."
18,12jtedc,datasets,LLM,relevance,2023-04-12 17:39:31,What are the best tools for web scraping and analysis of natural language to populate a dataset?,adjectivenounnr,False,1.0,6,/r/ArtificialInteligence/comments/12jrxhv/what_are_the_best_tools_for_web_scraping_and/,6,1681321171.0,
