,id,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,url,num_comments,created,body
0,11vdhrb,datasets,ChatGPT,top,2023-03-19 06:25:24,[Synthetic] datasetGPT - A command-line tool to generate datasets by inferencing LLMs at scale. It can even make two ChatGPT agents talk with one another.,radi-cho,False,0.96,61,https://www.reddit.com/r/datasets/comments/11vdhrb/synthetic_datasetgpt_a_commandline_tool_to/,0,1679207124.0,"GitHub: [https://github.com/radi-cho/datasetGPT](https://github.com/radi-cho/datasetGPT)

It can generate texts by varying input parameters and using multiple backends. But, personally, the conversations dataset generation is my favorite: It can produce dialogues between two ChatGPT agents.

Possible use cases may include:

* Constructing textual corpora to train/fine-tune detectors for content written by AI.
* Collecting datasets of LLM-produced conversations for research purposes, analysis of AI performance/impact/ethics, etc.
* Automating a task that a LLM can handle over big amounts of input texts. For example, using GPT-3 to summarize 1000 paragraphs with a single CLI command.
* Leveraging APIs of especially big LLMs to produce diverse texts for a specific task and then fine-tune a smaller model with them.

What would you use it for?"
1,12jqweq,datasets,ChatGPT,top,2023-04-12 16:07:30,Unlimited data for creating dataset for Intent Recognition and other NLU models,KMiNT21,False,0.67,1,https://www.reddit.com/r/datasets/comments/12jqweq/unlimited_data_for_creating_dataset_for_intent/,0,1681315650.0,"Nice idea to use chatGPT. It would be great if someone took on the task of creating an open datasets, so that resources wouldn't be wasted on work that has  already been done.

[Breaking Through the Limits: How Unlimited Data Collection and Generation Can Overcome Traditional Barriers in Intent Recognition](https://icexp.com/diy/breaking-through-the-limits-how-unlimited-data-collection-and-generation-can-overcome-traditional-barriers-in-intent-recognition-04-12.html)"
2,11vdhrb,datasets,ChatGPT,comments,2023-03-19 06:25:24,[Synthetic] datasetGPT - A command-line tool to generate datasets by inferencing LLMs at scale. It can even make two ChatGPT agents talk with one another.,radi-cho,False,0.97,62,https://www.reddit.com/r/datasets/comments/11vdhrb/synthetic_datasetgpt_a_commandline_tool_to/,0,1679207124.0,"GitHub: [https://github.com/radi-cho/datasetGPT](https://github.com/radi-cho/datasetGPT)

It can generate texts by varying input parameters and using multiple backends. But, personally, the conversations dataset generation is my favorite: It can produce dialogues between two ChatGPT agents.

Possible use cases may include:

* Constructing textual corpora to train/fine-tune detectors for content written by AI.
* Collecting datasets of LLM-produced conversations for research purposes, analysis of AI performance/impact/ethics, etc.
* Automating a task that a LLM can handle over big amounts of input texts. For example, using GPT-3 to summarize 1000 paragraphs with a single CLI command.
* Leveraging APIs of especially big LLMs to produce diverse texts for a specific task and then fine-tune a smaller model with them.

What would you use it for?"
3,12jqweq,datasets,ChatGPT,comments,2023-04-12 16:07:30,Unlimited data for creating dataset for Intent Recognition and other NLU models,KMiNT21,False,0.67,1,https://www.reddit.com/r/datasets/comments/12jqweq/unlimited_data_for_creating_dataset_for_intent/,0,1681315650.0,"Nice idea to use chatGPT. It would be great if someone took on the task of creating an open datasets, so that resources wouldn't be wasted on work that has  already been done.

[Breaking Through the Limits: How Unlimited Data Collection and Generation Can Overcome Traditional Barriers in Intent Recognition](https://icexp.com/diy/breaking-through-the-limits-how-unlimited-data-collection-and-generation-can-overcome-traditional-barriers-in-intent-recognition-04-12.html)"
4,11vdhrb,datasets,ChatGPT,relevance,2023-03-19 06:25:24,[Synthetic] datasetGPT - A command-line tool to generate datasets by inferencing LLMs at scale. It can even make two ChatGPT agents talk with one another.,radi-cho,False,0.96,62,https://www.reddit.com/r/datasets/comments/11vdhrb/synthetic_datasetgpt_a_commandline_tool_to/,0,1679207124.0,"GitHub: [https://github.com/radi-cho/datasetGPT](https://github.com/radi-cho/datasetGPT)

It can generate texts by varying input parameters and using multiple backends. But, personally, the conversations dataset generation is my favorite: It can produce dialogues between two ChatGPT agents.

Possible use cases may include:

* Constructing textual corpora to train/fine-tune detectors for content written by AI.
* Collecting datasets of LLM-produced conversations for research purposes, analysis of AI performance/impact/ethics, etc.
* Automating a task that a LLM can handle over big amounts of input texts. For example, using GPT-3 to summarize 1000 paragraphs with a single CLI command.
* Leveraging APIs of especially big LLMs to produce diverse texts for a specific task and then fine-tune a smaller model with them.

What would you use it for?"
5,12jqweq,datasets,ChatGPT,relevance,2023-04-12 16:07:30,Unlimited data for creating dataset for Intent Recognition and other NLU models,KMiNT21,False,0.67,1,https://www.reddit.com/r/datasets/comments/12jqweq/unlimited_data_for_creating_dataset_for_intent/,0,1681315650.0,"Nice idea to use chatGPT. It would be great if someone took on the task of creating an open datasets, so that resources wouldn't be wasted on work that has  already been done.

[Breaking Through the Limits: How Unlimited Data Collection and Generation Can Overcome Traditional Barriers in Intent Recognition](https://icexp.com/diy/breaking-through-the-limits-how-unlimited-data-collection-and-generation-can-overcome-traditional-barriers-in-intent-recognition-04-12.html)"
6,120lpox,datasets,ChatGPT,relevance,2023-03-24 14:17:51,Similarity semantic search sentences or paragraphs,MultiTiger,False,0.88,6,https://www.reddit.com/r/datasets/comments/120lpox/similarity_semantic_search_sentences_or_paragraphs/,5,1679667471.0,"Hi! I am doing experiments in semantic similarity search. Given a sentence, I need to find the most similar sentence to the given sentence in a data set that consists of sentences or paragraphs, using semantic search. Which means I need to have sentences, that I know are similar. How would I go about finding similar sentences and comprising the data set?"
7,118vn33,datasets,ChatGPT,relevance,2023-02-22 11:19:01,How stream processing can provide several benefits that other data management techniques cannot.,hardik-s,False,0.67,1,https://www.reddit.com/r/datasets/comments/118vn33/how_stream_processing_can_provide_several/,2,1677064741.0,"Stream processing refers to the real-time analysis of data streams, providing several advantages. These include:

1. Processing in real-time: Stream processing enables quick insights and prompt responses to changes and occurrences by allowing data to be evaluated and processed in real-time.
2. Scalability: Stream processing frameworks have the potential to scale horizontally, which allows for the addition of extra processing power as data volumes grow.
3. Cost-effectiveness: Stream processing can lower overall storage costs by removing the need for data storage for batch processing.
4. Better decision-making is made possible by real-time data processing, which gives rapid insights and enables quicker and wiser decisions.
5. High availability: Stream processing frameworks can tolerate hardware or software faults and offer high availability.
6. Stream processing can process user interactions in real-time, creating experiences that are tailored and context-aware.
7. Enhanced security: Stream processing can aid in the early detection and avertance of security threats.

For enterprises wishing to handle and evaluate data in real-time, stream processing is a useful tool. Faster insights, better judgment, better user experiences, and higher security are some of its advantages."
8,105upav,datasets,ChatGPT,relevance,2023-01-07 17:38:54,"looking for ""New phone who dis"" card game dataset",a_p_squared,False,0.82,7,https://www.reddit.com/r/datasets/comments/105upav/looking_for_new_phone_who_dis_card_game_dataset/,66,1673113134.0,I am looking for a data set of all the cards in the game [New phone who dis](https://whatdoyoumeme.com/products/new-phone-who-dis). Something similar to [this json file of all cards in Cards against humanity](https://crhallberg.com/cah/). It's not for any commercial use.
9,13cljiu,datasets,ChatGPT,relevance,2023-05-09 10:19:55,"Inmate population datasets for California, Colorado, and Texas",ljr_2k,False,0.73,5,https://www.reddit.com/r/datasets/comments/13cljiu/inmate_population_datasets_for_california/,2,1683627595.0,"Hello, I'm currently working on my dissertation and one of the variables I'm planning on using is inmate population. Does anyone have any links to where I can find them?

Thanks!"
10,zt61pe,datasets,ChatGPT,relevance,2022-12-23 04:12:02,Does anyone know of a database market place?,dant-cri,False,0.88,6,https://www.reddit.com/r/datasets/comments/zt61pe/does_anyone_know_of_a_database_market_place/,6,1671768722.0,"Hello everyone! Over time I have acquired a good amount of databases, I would like to know if there is a website or marketplace where these could be sold?"
11,zbcr60,datasets,ChatGPT,relevance,2022-12-03 09:50:15,Dataset of the full list of Youtube channels,etrader58,False,1.0,2,https://www.reddit.com/r/datasets/comments/zbcr60/dataset_of_the_full_list_of_youtube_channels/,4,1670061015.0,"I look for a dataset providing the full list of Youtube channels. I found [this dataset on Kaggle](https://www.kaggle.com/datasets/harshithgupta/youtubes-channels-dataset?resource=download), but it is 3 years old. 

&#x200B;

Can anyone suggest a more recent list of Youtube channels?"
