,id,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,url,num_comments,created,body
0,11yyoth,datasets,OpenAI,top,2023-03-22 22:13:02,4682 episodes of The Alex Jones Show (15875 hours) transcribed [self-promotion?],fudgie,False,0.96,148,https://www.reddit.com/r/datasets/comments/11yyoth/4682_episodes_of_the_alex_jones_show_15875_hours/,66,1679523182.0,"I've spent a few months running [OpenAI Whisper](https://github.com/openai/whisper) on the available episodes of The Alex Jones show, and was pointed to this subreddit by u/UglyChihuahua. I used the medium English model, as that's all I had GPU memory for, but used [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) and the large model when the medium model got confused. 

It's about 1.2GB of text with timestamps. 

I've added all the transcripts to a [github repository](https://github.com/Fudge/infowars), and also created a simple [web site](http://fight.fudgie.org) with search, simple stats, and links into the relevant audio clip."
1,z3cys6,datasets,OpenAI,top,2022-11-24 06:55:59,100 frames Football Semantic Segmentation of the Real vs. ManU matchup for the UEFA Super Cup in 2017 (of course dedicated towards the 2022 FIFA season),SithisR,False,0.81,6,https://www.reddit.com/r/datasets/comments/z3cys6/100_frames_football_semantic_segmentation_of_the/,0,1669272959.0,"**DEDICATING THIS FULL SEMANTIC DATASET TO THE ONGOING FIFA 2022 IN QATAR.**

Checkout the dataset here: [https://www.kaggle.com/datasets/sadhliroomyprime/football-semantic-segmentation](https://www.kaggle.com/datasets/sadhliroomyprime/football-semantic-segmentation)

The 100 frames are taken at every 12th frame (with some blurred frames and outliers replaced) from the match between Real Madrid and Manchester United from open media. The dataset is appropriate for training detection models in respect to sports analytics, of course biased towards soccer.

The source data was collected from the UEFA Super Cup match between Real Madrid and Manchester United in 2017 (Highlights).

11 standard classes are used which includes: **Goal Bar**, **Referee**, **Advertisement**, **Ground**, **Ball**, **Coaches & Officials**, **Audience**, **Goalkeeper A**, **Goalkeeper B**, **Team A**, and **Team B**.

We used SuperAnnotateâ€™s pixel editor to label and classify the images following instance segmentation principles. Export was made in COCO with fused labels to optimise interoperability and visual understanding.

Dataset is created by Acme AI Ltd. ([www.acmeai.tech](http://www.acmeai.tech/)) and is #openaccess ðŸ˜Š ðŸ˜Š"
2,11ym95l,datasets,OpenAI,top,2023-03-22 15:20:31,CleanVision: Audit your Image Datasets for better Computer Vision,jonas__m,False,0.78,5,https://www.reddit.com/r/datasets/comments/11ym95l/cleanvision_audit_your_image_datasets_for_better/,5,1679498431.0,"To all my computer vision friends working on real-world applications with messy image data, I just open-sourced a Python library you may find useful!

CleanVision audits any image dataset to automatically detect common issues such as images that are blurry, under/over-exposed, oddly sized, or near duplicates of others. Itâ€™s just 3 lines of code to discover what issues lurk in your data before you dive into modeling, and CleanVision can be used for **any** image dataset â€” regardless of whether your task is image generation, classification, segmentation, object detection, etc.

    from cleanvision.imagelab import Imagelab 
    imagelab = Imagelab(data_path=""path_to_dataset"")
    imagelab.find_issues()
    imagelab.report()

As leaders like Andrew Ng and OpenAI have lately repeated: models can only be as good as the data they are trained on. Before diving into modeling, quickly run your images through CleanVision to make sure they are ok â€” itâ€™s super easy!

Github:  [https://github.com/cleanlab/cleanvision](https://github.com/cleanlab/cleanvision)

Disclaimer: I am affiliated with Cleanlab."
3,z3cw9p,datasets,OpenAI,top,2022-11-24 06:52:02,100 frames Football Semantic Segmentation of the Real vs. ManU matchup for the UEFA Super Cup in 2017 (of course dedicated towards the 2022 FIFA season),SithisR,False,1.0,1,https://www.reddit.com/r/datasets/comments/z3cw9p/100_frames_football_semantic_segmentation_of_the/,1,1669272722.0,"**DEDICATING THIS FULL SEMANTIC DATASET TO THE ONGOING FIFA 2022 IN QATAR.**

Checkout the dataset here: [https://www.kaggle.com/datasets/sadhliroomyprime/football-semantic-segmentation](https://www.kaggle.com/datasets/sadhliroomyprime/football-semantic-segmentation)

The 100 frames are taken at every 12th frame (with some blurred frames and outliers replaced) from the match between Real Madrid and Manchester United from open media. The dataset is appropriate for training detection models in respect to sports analytics, of course biased towards soccer.

The source data was collected from the [UEFA Super Cup match between Real Madrid and Manchester United in 2017 (Highlights)](https://youtu.be/I8RoMceZ7W8).

11 standard classes are used which includes: **Goal Bar**, **Referee**, **Advertisement**, **Ground**, **Ball**, **Coaches & Officials**, **Audience**, **Goalkeeper A**, **Goalkeeper B**, **Team A**, and **Team B**.

We used SuperAnnotateâ€™s pixel editor to label and classify the images following instance segmentation principles. Export was made in COCO with fused labels to optimise interoperability and visual understanding.

Dataset is created by Acme AI Ltd. ([www.acmeai.tech](http://www.acmeai.tech/)) and is #openaccess ðŸ˜Š ðŸ˜Š"
4,ym868z,datasets,OpenAI,top,2022-11-04 19:36:24,[self-promotion] Spatial Vehicle Detection (Bounding Box); featuring 10 class labels in 100 images taken from open media to enable testing for vehicle detection and/or urban mobility AI solutions.,SithisR,False,1.0,1,https://www.reddit.com/r/datasets/comments/ym868z/selfpromotion_spatial_vehicle_detection_bounding/,0,1667590584.0,"**BOUNDING BOXES TO DETECT VEHICLE FORMS FROM 700 FEET ABOVE.**

Checkout the dataset on Kaggle: [https://www.kaggle.com/datasets/sadhliroomyprime/spatial-vehicle-detection](https://www.kaggle.com/datasets/sadhliroomyprime/spatial-vehicle-detection)

100 images taken from **Google Earth Pro** appropriate for training spatial and computer vision-based detection models focused on urban mobility and traffic concentrations. The source data was collected from open media, as mentioned previously, from satellite imagery available in Google Earth Pro. We collected this particular dataset from **Edogawa, Tokyo in Japan**. A total of 10 classes were used which are: **Car, Motorbike, Truck, Pickup Truck, Van, Truck with Trailer, Bus, Bicycle, Miscellaneous, Car-Trailer**.

We used SuperAnnotateâ€™s vector editor to label and classify the images using bounding boxes. Export was made in COCO with fused labels to optimise interoperability and visual understanding.

Dataset is created by Acme AI Ltd. ([www.acmeai.tech](https://www.acmeai.tech/)) and is #openaccess ðŸ˜Š ðŸ˜Š"
5,11yyoth,datasets,OpenAI,comments,2023-03-22 22:13:02,4682 episodes of The Alex Jones Show (15875 hours) transcribed [self-promotion?],fudgie,False,0.96,148,https://www.reddit.com/r/datasets/comments/11yyoth/4682_episodes_of_the_alex_jones_show_15875_hours/,66,1679523182.0,"I've spent a few months running [OpenAI Whisper](https://github.com/openai/whisper) on the available episodes of The Alex Jones show, and was pointed to this subreddit by u/UglyChihuahua. I used the medium English model, as that's all I had GPU memory for, but used [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) and the large model when the medium model got confused. 

It's about 1.2GB of text with timestamps. 

I've added all the transcripts to a [github repository](https://github.com/Fudge/infowars), and also created a simple [web site](http://fight.fudgie.org) with search, simple stats, and links into the relevant audio clip."
6,11ym95l,datasets,OpenAI,comments,2023-03-22 15:20:31,CleanVision: Audit your Image Datasets for better Computer Vision,jonas__m,False,0.78,5,https://www.reddit.com/r/datasets/comments/11ym95l/cleanvision_audit_your_image_datasets_for_better/,5,1679498431.0,"To all my computer vision friends working on real-world applications with messy image data, I just open-sourced a Python library you may find useful!

CleanVision audits any image dataset to automatically detect common issues such as images that are blurry, under/over-exposed, oddly sized, or near duplicates of others. Itâ€™s just 3 lines of code to discover what issues lurk in your data before you dive into modeling, and CleanVision can be used for **any** image dataset â€” regardless of whether your task is image generation, classification, segmentation, object detection, etc.

    from cleanvision.imagelab import Imagelab 
    imagelab = Imagelab(data_path=""path_to_dataset"")
    imagelab.find_issues()
    imagelab.report()

As leaders like Andrew Ng and OpenAI have lately repeated: models can only be as good as the data they are trained on. Before diving into modeling, quickly run your images through CleanVision to make sure they are ok â€” itâ€™s super easy!

Github:  [https://github.com/cleanlab/cleanvision](https://github.com/cleanlab/cleanvision)

Disclaimer: I am affiliated with Cleanlab."
7,z3cw9p,datasets,OpenAI,comments,2022-11-24 06:52:02,100 frames Football Semantic Segmentation of the Real vs. ManU matchup for the UEFA Super Cup in 2017 (of course dedicated towards the 2022 FIFA season),SithisR,False,1.0,1,https://www.reddit.com/r/datasets/comments/z3cw9p/100_frames_football_semantic_segmentation_of_the/,1,1669272722.0,"**DEDICATING THIS FULL SEMANTIC DATASET TO THE ONGOING FIFA 2022 IN QATAR.**

Checkout the dataset here: [https://www.kaggle.com/datasets/sadhliroomyprime/football-semantic-segmentation](https://www.kaggle.com/datasets/sadhliroomyprime/football-semantic-segmentation)

The 100 frames are taken at every 12th frame (with some blurred frames and outliers replaced) from the match between Real Madrid and Manchester United from open media. The dataset is appropriate for training detection models in respect to sports analytics, of course biased towards soccer.

The source data was collected from the [UEFA Super Cup match between Real Madrid and Manchester United in 2017 (Highlights)](https://youtu.be/I8RoMceZ7W8).

11 standard classes are used which includes: **Goal Bar**, **Referee**, **Advertisement**, **Ground**, **Ball**, **Coaches & Officials**, **Audience**, **Goalkeeper A**, **Goalkeeper B**, **Team A**, and **Team B**.

We used SuperAnnotateâ€™s pixel editor to label and classify the images following instance segmentation principles. Export was made in COCO with fused labels to optimise interoperability and visual understanding.

Dataset is created by Acme AI Ltd. ([www.acmeai.tech](http://www.acmeai.tech/)) and is #openaccess ðŸ˜Š ðŸ˜Š"
8,z3cys6,datasets,OpenAI,comments,2022-11-24 06:55:59,100 frames Football Semantic Segmentation of the Real vs. ManU matchup for the UEFA Super Cup in 2017 (of course dedicated towards the 2022 FIFA season),SithisR,False,0.89,7,https://www.reddit.com/r/datasets/comments/z3cys6/100_frames_football_semantic_segmentation_of_the/,0,1669272959.0,"**DEDICATING THIS FULL SEMANTIC DATASET TO THE ONGOING FIFA 2022 IN QATAR.**

Checkout the dataset here: [https://www.kaggle.com/datasets/sadhliroomyprime/football-semantic-segmentation](https://www.kaggle.com/datasets/sadhliroomyprime/football-semantic-segmentation)

The 100 frames are taken at every 12th frame (with some blurred frames and outliers replaced) from the match between Real Madrid and Manchester United from open media. The dataset is appropriate for training detection models in respect to sports analytics, of course biased towards soccer.

The source data was collected from the UEFA Super Cup match between Real Madrid and Manchester United in 2017 (Highlights).

11 standard classes are used which includes: **Goal Bar**, **Referee**, **Advertisement**, **Ground**, **Ball**, **Coaches & Officials**, **Audience**, **Goalkeeper A**, **Goalkeeper B**, **Team A**, and **Team B**.

We used SuperAnnotateâ€™s pixel editor to label and classify the images following instance segmentation principles. Export was made in COCO with fused labels to optimise interoperability and visual understanding.

Dataset is created by Acme AI Ltd. ([www.acmeai.tech](http://www.acmeai.tech/)) and is #openaccess ðŸ˜Š ðŸ˜Š"
9,ym868z,datasets,OpenAI,comments,2022-11-04 19:36:24,[self-promotion] Spatial Vehicle Detection (Bounding Box); featuring 10 class labels in 100 images taken from open media to enable testing for vehicle detection and/or urban mobility AI solutions.,SithisR,False,1.0,1,https://www.reddit.com/r/datasets/comments/ym868z/selfpromotion_spatial_vehicle_detection_bounding/,0,1667590584.0,"**BOUNDING BOXES TO DETECT VEHICLE FORMS FROM 700 FEET ABOVE.**

Checkout the dataset on Kaggle: [https://www.kaggle.com/datasets/sadhliroomyprime/spatial-vehicle-detection](https://www.kaggle.com/datasets/sadhliroomyprime/spatial-vehicle-detection)

100 images taken from **Google Earth Pro** appropriate for training spatial and computer vision-based detection models focused on urban mobility and traffic concentrations. The source data was collected from open media, as mentioned previously, from satellite imagery available in Google Earth Pro. We collected this particular dataset from **Edogawa, Tokyo in Japan**. A total of 10 classes were used which are: **Car, Motorbike, Truck, Pickup Truck, Van, Truck with Trailer, Bus, Bicycle, Miscellaneous, Car-Trailer**.

We used SuperAnnotateâ€™s vector editor to label and classify the images using bounding boxes. Export was made in COCO with fused labels to optimise interoperability and visual understanding.

Dataset is created by Acme AI Ltd. ([www.acmeai.tech](https://www.acmeai.tech/)) and is #openaccess ðŸ˜Š ðŸ˜Š"
10,11yyoth,datasets,OpenAI,relevance,2023-03-22 22:13:02,4682 episodes of The Alex Jones Show (15875 hours) transcribed [self-promotion?],fudgie,False,0.96,148,https://www.reddit.com/r/datasets/comments/11yyoth/4682_episodes_of_the_alex_jones_show_15875_hours/,66,1679523182.0,"I've spent a few months running [OpenAI Whisper](https://github.com/openai/whisper) on the available episodes of The Alex Jones show, and was pointed to this subreddit by u/UglyChihuahua. I used the medium English model, as that's all I had GPU memory for, but used [Whisper.cpp](https://github.com/ggerganov/whisper.cpp) and the large model when the medium model got confused. 

It's about 1.2GB of text with timestamps. 

I've added all the transcripts to a [github repository](https://github.com/Fudge/infowars), and also created a simple [web site](http://fight.fudgie.org) with search, simple stats, and links into the relevant audio clip."
11,11ym95l,datasets,OpenAI,relevance,2023-03-22 15:20:31,CleanVision: Audit your Image Datasets for better Computer Vision,jonas__m,False,0.73,5,https://www.reddit.com/r/datasets/comments/11ym95l/cleanvision_audit_your_image_datasets_for_better/,5,1679498431.0,"To all my computer vision friends working on real-world applications with messy image data, I just open-sourced a Python library you may find useful!

CleanVision audits any image dataset to automatically detect common issues such as images that are blurry, under/over-exposed, oddly sized, or near duplicates of others. Itâ€™s just 3 lines of code to discover what issues lurk in your data before you dive into modeling, and CleanVision can be used for **any** image dataset â€” regardless of whether your task is image generation, classification, segmentation, object detection, etc.

    from cleanvision.imagelab import Imagelab 
    imagelab = Imagelab(data_path=""path_to_dataset"")
    imagelab.find_issues()
    imagelab.report()

As leaders like Andrew Ng and OpenAI have lately repeated: models can only be as good as the data they are trained on. Before diving into modeling, quickly run your images through CleanVision to make sure they are ok â€” itâ€™s super easy!

Github:  [https://github.com/cleanlab/cleanvision](https://github.com/cleanlab/cleanvision)

Disclaimer: I am affiliated with Cleanlab."
12,ym868z,datasets,OpenAI,relevance,2022-11-04 19:36:24,[self-promotion] Spatial Vehicle Detection (Bounding Box); featuring 10 class labels in 100 images taken from open media to enable testing for vehicle detection and/or urban mobility AI solutions.,SithisR,False,1.0,1,https://www.reddit.com/r/datasets/comments/ym868z/selfpromotion_spatial_vehicle_detection_bounding/,0,1667590584.0,"**BOUNDING BOXES TO DETECT VEHICLE FORMS FROM 700 FEET ABOVE.**

Checkout the dataset on Kaggle: [https://www.kaggle.com/datasets/sadhliroomyprime/spatial-vehicle-detection](https://www.kaggle.com/datasets/sadhliroomyprime/spatial-vehicle-detection)

100 images taken from **Google Earth Pro** appropriate for training spatial and computer vision-based detection models focused on urban mobility and traffic concentrations. The source data was collected from open media, as mentioned previously, from satellite imagery available in Google Earth Pro. We collected this particular dataset from **Edogawa, Tokyo in Japan**. A total of 10 classes were used which are: **Car, Motorbike, Truck, Pickup Truck, Van, Truck with Trailer, Bus, Bicycle, Miscellaneous, Car-Trailer**.

We used SuperAnnotateâ€™s vector editor to label and classify the images using bounding boxes. Export was made in COCO with fused labels to optimise interoperability and visual understanding.

Dataset is created by Acme AI Ltd. ([www.acmeai.tech](https://www.acmeai.tech/)) and is #openaccess ðŸ˜Š ðŸ˜Š"
13,z3cw9p,datasets,OpenAI,relevance,2022-11-24 06:52:02,100 frames Football Semantic Segmentation of the Real vs. ManU matchup for the UEFA Super Cup in 2017 (of course dedicated towards the 2022 FIFA season),SithisR,False,1.0,1,https://www.reddit.com/r/datasets/comments/z3cw9p/100_frames_football_semantic_segmentation_of_the/,1,1669272722.0,"**DEDICATING THIS FULL SEMANTIC DATASET TO THE ONGOING FIFA 2022 IN QATAR.**

Checkout the dataset here: [https://www.kaggle.com/datasets/sadhliroomyprime/football-semantic-segmentation](https://www.kaggle.com/datasets/sadhliroomyprime/football-semantic-segmentation)

The 100 frames are taken at every 12th frame (with some blurred frames and outliers replaced) from the match between Real Madrid and Manchester United from open media. The dataset is appropriate for training detection models in respect to sports analytics, of course biased towards soccer.

The source data was collected from the [UEFA Super Cup match between Real Madrid and Manchester United in 2017 (Highlights)](https://youtu.be/I8RoMceZ7W8).

11 standard classes are used which includes: **Goal Bar**, **Referee**, **Advertisement**, **Ground**, **Ball**, **Coaches & Officials**, **Audience**, **Goalkeeper A**, **Goalkeeper B**, **Team A**, and **Team B**.

We used SuperAnnotateâ€™s pixel editor to label and classify the images following instance segmentation principles. Export was made in COCO with fused labels to optimise interoperability and visual understanding.

Dataset is created by Acme AI Ltd. ([www.acmeai.tech](http://www.acmeai.tech/)) and is #openaccess ðŸ˜Š ðŸ˜Š"
14,z3cys6,datasets,OpenAI,relevance,2022-11-24 06:55:59,100 frames Football Semantic Segmentation of the Real vs. ManU matchup for the UEFA Super Cup in 2017 (of course dedicated towards the 2022 FIFA season),SithisR,False,0.9,8,https://www.reddit.com/r/datasets/comments/z3cys6/100_frames_football_semantic_segmentation_of_the/,0,1669272959.0,"**DEDICATING THIS FULL SEMANTIC DATASET TO THE ONGOING FIFA 2022 IN QATAR.**

Checkout the dataset here: [https://www.kaggle.com/datasets/sadhliroomyprime/football-semantic-segmentation](https://www.kaggle.com/datasets/sadhliroomyprime/football-semantic-segmentation)

The 100 frames are taken at every 12th frame (with some blurred frames and outliers replaced) from the match between Real Madrid and Manchester United from open media. The dataset is appropriate for training detection models in respect to sports analytics, of course biased towards soccer.

The source data was collected from the UEFA Super Cup match between Real Madrid and Manchester United in 2017 (Highlights).

11 standard classes are used which includes: **Goal Bar**, **Referee**, **Advertisement**, **Ground**, **Ball**, **Coaches & Officials**, **Audience**, **Goalkeeper A**, **Goalkeeper B**, **Team A**, and **Team B**.

We used SuperAnnotateâ€™s pixel editor to label and classify the images following instance segmentation principles. Export was made in COCO with fused labels to optimise interoperability and visual understanding.

Dataset is created by Acme AI Ltd. ([www.acmeai.tech](http://www.acmeai.tech/)) and is #openaccess ðŸ˜Š ðŸ˜Š"
15,113z837,datasets,OpenAI,relevance,2023-02-16 19:45:42,blood sugar count dataset needed for AI training,AccomplishedDance478,False,0.81,3,https://www.reddit.com/r/datasets/comments/113z837/blood_sugar_count_dataset_needed_for_ai_training/,3,1676576742.0,"I need a dataset of blood sugar rate, I didn't find any open source one."
