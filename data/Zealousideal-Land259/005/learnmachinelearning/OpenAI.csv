,id,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,url,num_comments,created,body
0,12apw9o,learnmachinelearning,OpenAI,top,2023-04-03 16:39:55,"If you are looking for courses about Artificial Intelligence, I created the repository with links to resources that I found super high quality and helpful. The link is in the comment.",RandomForests92,False,0.99,599,https://i.redd.it/jczyjswj6pra1.png,62,1680539995.0,
1,1087ady,learnmachinelearning,OpenAI,top,2023-01-10 11:12:01,Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI,BackgroundResult,False,0.97,451,https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion,102,1673349121.0,
2,10fw2df,learnmachinelearning,OpenAI,top,2023-01-19 07:56:20,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.96,331,https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/,47,1674114980.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
3,13eympz,learnmachinelearning,OpenAI,top,2023-05-11 20:15:46,Top 20 Large Language Models based on the Elo rating system.,kingabzpro,False,0.96,248,https://i.redd.it/7xfqr5crf9za1.png,43,1683836146.0,
4,11biozs,learnmachinelearning,OpenAI,top,2023-02-25 11:19:05,Any MLOps platform you use?,squalidaesthetics20,False,0.98,241,https://www.reddit.com/r/learnmachinelearning/comments/11biozs/any_mlops_platform_you_use/,31,1677323945.0,"I've been searching for some MLOps platforms for my some projects that I’m working on. I am creating a list that will hopefully help out with productivity and help mr build better apps and services. Also hopefully faster.

I've looked at some of the more popular ones out there and here’s my top 4 so far. Let me know what you guys think about these:

* [Vertex AI](https://cloud.google.com/vertex-ai) \- An ML platform by Google Cloud. They have AI-powered tools to ingest, analyze, and store video data. Good for image classification, NLP, recommendation systems etc.
* [Jina AI](https://jina.ai/) \-They offer a neural search solution that can help build smarter, more efficient search engines. They also have a list of [cool github repos](https://github.com/jina-ai/jina) that you can check out. Similar to Vertex AI, they have image classification tools, NLPs, fine tuners etc.
* [MLflow](https://mlflow.org/) \- an open-source platform for managing your ML lifecycle. What’s great is that they also support popular Python libraries like TensorFlow, PyTorch, scikit-learn, and R.
* Neptune.ai, which promises to streamline your workflows and make collaboration a breeze.

Have you guys tried any of these platforms? I know a lot of AI tools and platforms have been popping up lately especially with the rise of AI tools but what are your thoughts?"
5,113nizs,learnmachinelearning,OpenAI,top,2023-02-16 10:29:31,OpenAI Has Purchased AI.Com For ChatGPT For $11M,vadhavaniyafaijan,False,0.93,213,https://www.theinsaneapp.com/2023/02/openai-purchased-ai-com-domain.html,23,1676543371.0,
6,10ddc1f,learnmachinelearning,OpenAI,top,2023-01-16 12:28:25,I benchmarked OpenAI's GPT API vs other proprietary APIs on different NLP tasks,AImSamy,False,0.9,197,https://www.reddit.com/gallery/10ddc1f,37,1673872105.0,
7,116yj78,learnmachinelearning,OpenAI,top,2023-02-20 05:19:31,"Voice.AI Stole Open-Source Code, Banned The Developer Who Informed Them About This, From Discord Server",TheInsaneApp,False,0.98,169,https://www.theinsaneapp.com/2023/02/voice-ai-stole-open-source-code.html,7,1676870371.0,
8,13e8of2,learnmachinelearning,OpenAI,top,2023-05-11 00:54:18,What do actual ML engineers think of ChatGPT?,PhillConners,False,0.96,150,https://www.reddit.com/r/learnmachinelearning/comments/13e8of2/what_do_actual_ml_engineers_think_of_chatgpt/,106,1683766458.0,"You have been doing this for awhile, now the world is obsessed with OpenAI and suddenly all full of AI “experts”."
9,yrgnuq,learnmachinelearning,OpenAI,top,2022-11-10 14:29:23,[P] Transcribe any podcast episode in just 1 minute with optimized OpenAI/whisper,thundergolfer,False,0.97,121,https://v.redd.it/wnt66ghfody91,6,1668090563.0,
10,1194vsn,learnmachinelearning,OpenAI,top,2023-02-22 16:59:33,MIT Introduction to Data-Centric AI,anishathalye,False,0.97,101,https://www.reddit.com/r/learnmachinelearning/comments/1194vsn/mit_introduction_to_datacentric_ai/,4,1677085173.0,"Announcing the [first-ever course on Data-Centric AI](https://dcai.csail.mit.edu/). Learn how to train better ML models by improving the data.

[Course homepage](https://dcai.csail.mit.edu/) | [Lecture videos on YouTube](https://www.youtube.com/watch?v=ayzOzZGHZy4&list=PLnSYPjg2dHQKdig0vVbN-ZnEU0yNJ1mo5) | [Lab Assignments](https://github.com/dcai-course/dcai-lab)

The course covers:

* [Data-Centric AI vs. Model-Centric AI](https://dcai.csail.mit.edu/lectures/data-centric-model-centric/)
* [Label Errors](https://dcai.csail.mit.edu/lectures/label-errors/)
* [Dataset Creation and Curation](https://dcai.csail.mit.edu/lectures/dataset-creation-curation/)
* [Data-centric Evaluation of ML Models](https://dcai.csail.mit.edu/lectures/data-centric-evaluation/)
* [Class Imbalance, Outliers, and Distribution Shift](https://dcai.csail.mit.edu/lectures/imbalance-outliers-shift/)
* [Growing or Compressing Datasets](https://dcai.csail.mit.edu/lectures/growing-compressing-datasets/)
* [Interpretability in Data-Centric ML](https://dcai.csail.mit.edu/lectures/interpretable-features/)
* [Encoding Human Priors: Data Augmentation and Prompt Engineering](https://dcai.csail.mit.edu/lectures/human-priors/)
* [Data Privacy and Security](https://dcai.csail.mit.edu/lectures/data-privacy-security/)

MIT, like most universities, has many courses on machine learning (6.036, 6.867, and many others). Those classes teach techniques to produce effective models for a given dataset, and the classes focus heavily on the mathematical details of models rather than practical applications. However, in real-world applications of ML, the dataset is not fixed, and focusing on improving the data often gives better results than improving the model. We’ve personally seen this time and time again in our applied ML work as well as our research.

Data-Centric AI (DCAI) is an emerging science that studies techniques to improve datasets in a systematic/algorithmic way — given that this topic wasn’t covered in the standard curriculum, we (a group of PhD candidates and grads) thought that we should put together a new class! We taught this intensive 2-week course in January over MIT’s IAP term, and we’ve just published all the course material, including lecture videos, lecture notes, hands-on lab assignments, and lab solutions, in hopes that people outside the MIT community would find these resources useful.

We’d be happy to answer any questions related to the class or DCAI in general, and we’d love to hear any feedback on how we can improve the course material. Introduction to Data-Centric AI is open-source opencourseware, so feel free to make improvements directly: [https://github.com/dcai-course/dcai-course](https://github.com/dcai-course/dcai-course)."
11,10mmofg,learnmachinelearning,OpenAI,top,2023-01-27 14:51:14,Fine-tuning open source models to emulate ChatGPT for code explanation.,awesomequantity,False,0.88,87,https://www.reddit.com/r/learnmachinelearning/comments/10mmofg/finetuning_open_source_models_to_emulate_chatgpt/,13,1674831074.0,"I'm looking to step up my game and emulate ChatGPT for specific use-cases like explaining code. I'm thinking about using open source models like GPT-J, or OPT to get beyond the limitations of the closed-source nature of ChatGPT, like the amount of text it can read or respond with.

I got the funding for training, hardware, etc, and I want the end product to be on-premises, so no worries there. The inference doesn't have to be super fast either. I know there are projects like OpenAssistant and petals.ml but haven’t made enough research just yet.

One option I’m considering is using fine tuners like the one from [HuggingFace](https://github.com/subhasisj/HuggingFace-Transformers-FineTuning) or [Jina AI](https://github.com/jina-ai/finetuner) to fine-tune open source models like GPT-J or OPT to improve specific use-cases like code explanation. With the funding that we have, I wouldn’t want to cheap out on fine-tuning and expect something good.

So, can anyone help out and point me in the right direction? Which model is the best to fine-tune and how do I fine-tune to improve specific use cases? Any help would be appreciated. Thanks!"
12,121cvgi,learnmachinelearning,OpenAI,top,2023-03-25 06:14:22,Does it make sense to specialize in NLP now?,Aromatic_Eye_6268,False,0.91,75,https://www.reddit.com/r/learnmachinelearning/comments/121cvgi/does_it_make_sense_to_specialize_in_nlp_now/,20,1679724862.0,"With the explosion of Large Language Models, it is clear that most of the cutting edge work is being done in a handful of companies around the world. Does it make sense to specialize in NLP? Will someone be able to do novel research work in NLP without being a part of places like OpenAI?"
13,10c509n,learnmachinelearning,OpenAI,top,2023-01-15 00:08:37,Is it still worth learning NLP in the age of API-accessibles LLM like GPT?,CrimsonPilgrim,False,0.93,62,https://www.reddit.com/r/learnmachinelearning/comments/10c509n/is_it_still_worth_learning_nlp_in_the_age_of/,24,1673741317.0,"A question that, I hope, you will find legitimate from a data science student.

I am speaking from the point of view of a data scientist not working in research.

Until now, learning NLP could be used to meet occasional business needs like sentiment analysis, text classification, topic modeling....

With the opening of GPT-3 to the public, the rise of ChatGPT, and the huge wave of applications, sites, plug-ins and extensions based on this technology that are accessible with a simple API request, it's impossible not to wonder if spending dozens of hours diving into this field if ML wouldn't be as useful today as learning the source code of the Pandas library. 

In some specialized cases, it could be useful, but GPT-3, and the models that will follow, seem to offer more than sufficient results for the immensity of the cases and for almost all classical NLP tasks. Not only that, but there is a good chance that the models trained by giants like Open-AI (Microsoft) or Google can never be replicated outside these companies anyway.  With ChatGPT and its incomparable mastery of language, its ability to code, summarize, extract topics, understand... why would I bother to use BERT or a TF-IDF vectorizer when an API will be released? Not only it would be easily accessible, but it also would be much better at the task, faster and cheaper.

In fact, it's a concern regarding all the machine learning field in general with the arrival of powerful ""no-code"" applications, which abstract a large part of the inherent complexity of the field. There will always be a need for experts, for safeguards, but in the end, won't the Data Scientist who masters the features of GPT-3 or 4 and knows a bit of NLP be more efficient than the one who has spent hours reading Google papers and practicing on Gensim, NLTK, spacy... It is the purpose of an API to make things simpler eventually... At what point is there no more reason to be interested in the behind-the-scenes of these tools and to become simple users rather than trying to develop our own techniques?"
14,121qvqn,learnmachinelearning,OpenAI,top,2023-03-25 16:23:09,What's the current state of actually free and open source LLMs?,maquinary,False,0.97,58,https://www.reddit.com/r/learnmachinelearning/comments/121qvqn/whats_the_current_state_of_actually_free_and_open/,25,1679761389.0,"*People, take easy on me, I just a newbie that tests stuff made by A.I. in a very amateur manner.*

---------------------

Yesterday a played a bit with [Alpaca.cpp](https://github.com/antimatter15/alpaca.cpp), but despite the fact that the software itself is in the MIT license, it has serious limitations because of licensing factors, as you can see [here](https://crfm.stanford.edu/2023/03/13/alpaca.html):

>[...]

>

> We emphasize that Alpaca is intended only for academic research and any commercial use is prohibited. There are three factors in this decision: First, Alpaca is based on LLaMA, which has a non-commercial license, so we necessarily inherit this decision. Second, the instruction data is based on OpenAI’s text-davinci-003, whose terms of use prohibit developing models that compete with OpenAI. Finally, we have not designed adequate safety measures, so Alpaca is not ready to be deployed for general use.

>

> [...]

So, do we have anything that is **completely free** that reaches at least the level of GTP-3?

And what about the data that people use to train the models? Those big companies can ""scan"" the entire web to get insane amounts of data, but can free software developers use these already harvested data to train their own models? Or, in order to have a completely free LLM, people will have to collect data again from the Internet?

-------------

*When I say ""free"", I mean free from licensing limitations, in a sense that I can implement the A.I. in my software without the need of being forced to apply a limited range of licenses, or without the need to pay.*"
15,10oitli,learnmachinelearning,OpenAI,top,2023-01-29 21:14:13,Create a Serverless Search Engine using the OpenAI Embeddings API,sopmac21379,False,0.95,53,https://medium.com/sopmac-ai/create-a-serverless-search-engine-using-the-openai-embeddings-api-50e5ac8ca6e3,1,1675026853.0,
16,132o8tt,learnmachinelearning,OpenAI,top,2023-04-29 09:21:53,Prompt Engineering Free Course For Beginners By OpenAI And Deep Learning AI,vadhavaniyafaijan,False,0.78,51,https://www.theinsaneapp.com/2023/04/free-prompt-engineering-course-for-beginners.html,7,1682760113.0,
17,z80iww,learnmachinelearning,OpenAI,top,2022-11-29 17:39:16,How To: Automatically Detect Annotation Errors in Image/Text Tagging Datasets,cmauck10,False,1.0,43,https://www.reddit.com/r/learnmachinelearning/comments/z80iww/how_to_automatically_detect_annotation_errors_in/,0,1669743556.0,"Hey guys! Many of us in ML work with **multi-label data**, where the image or text is tagged with multiple labels. Often these datasets contain **frequent label errors** and/or **missing tags** (check what we found below in the CelebA dataset) that make it hard to train highly accurate ML models. Support for multi-label data was one of the top features requested — so we [added it](https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html), [benchmarked it](https://cleanlab.ai/blog/multilabel/), and published all of the [research](https://cleanlab.ai/blog/multilabel/).

[Find errors and missing labels in multi-label datasets.](https://preview.redd.it/av14p6ko7x2a1.png?width=1250&format=png&auto=webp&s=63f63bd93e4195e070e08a088cbc5c630c333430)

We are excited to share this newest research on algorithms to automatically find label errors in multi-label classification datasets.  Image/document tagging represents important instances of **multi-label classification** tasks, where each example can belong to multiple (or none) of K possible classes.  Because annotating such data requires many decisions for each example, often multi-label classification datasets contain tons of label errors, which harm the performance of ML models.

We’ve open-sourced our algorithms in the [recent release of cleanlab v2.2](https://github.com/cleanlab/cleanlab/releases/tag/v2.2.0). All you need to do to use them is write one line of open-source code via [cleanlab.filter.find\_label\_issues](https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html).

    from cleanlab.filter import find_label_issues
    
    ranked_label_issues = find_label_issues(
        labels=labels,
        pred_probs=pred_probs,
        multi_label=True,
        return_indices_ranked_by=""self_confidence"",
    )
    # labels: list of lists of (multiple) labels of each example
    # pred_probs: predicted class probabilities from any trained classifier

Running the new `find_label_issues()` function on the [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) image tagging dataset reveals around **30,000 mislabeled images**! Check out a few of them in the blog post!

Resources:

* Blog post: [https://cleanlab.ai/blog/multilabel/](https://cleanlab.ai/blog/multilabel/)
* Paper: [https://arxiv.org/abs/2211.13895](https://arxiv.org/abs/2211.13895)
* Tutorial: [https://docs.cleanlab.ai/stable/tutorials/multilabel\_classification.html](https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html)
* Benchmarks: [https://github.com/cleanlab/multilabel-error-detection-benchmarks](https://github.com/cleanlab/multilabel-error-detection-benchmarks)
* Code: [https://github.com/cleanlab/cleanlab](https://github.com/cleanlab/cleanlab)

Hope you find these practical tools useful in your real-world ML applications!"
18,124nsy8,learnmachinelearning,OpenAI,top,2023-03-28 12:51:54,I am creating a tool that uses OpenAI models and an OCR to translate screenshots,K-RT-DEV,False,0.88,40,https://www.reddit.com/r/learnmachinelearning/comments/124nsy8/i_am_creating_a_tool_that_uses_openai_models_and/,15,1680007914.0,"Currently, the OCR is specifically for translating from Japanese, but I plan to add a range of OCRs and different translators to the system to accommodate the user's needs.  


https://i.redd.it/8ymk99uf8hqa1.gif

My idea is to have a system that leverages OpenAI models for *bagging*. This way, I can combine the output of multiple OCRs  to increase the accuracy of the recognized characters. Similarly, I can combine the output of multiple translators for the same phrase to improve the final result . Chat models can be particularly useful in providing **context** and a translation history to help the system understand how to conjugate phrases for translation.   


You can find the source code and an executable version on the [project's GitHub](https://github.com/K-RT-Dev/VGT)"
19,127c7sb,learnmachinelearning,OpenAI,top,2023-03-31 06:20:23,LAION Launches Petition to Establish an International Publicly Funded Supercomputing Facility for Open Source Large-scale AI Research and its Safety,stringShuffle,False,0.98,36,https://www.reddit.com/r/learnmachinelearning/comments/127c7sb/laion_launches_petition_to_establish_an/,0,1680243623.0,"[https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety](https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety)

>Join us in our urgent mission to democratize AI research by establishing an international, publicly funded supercomputing facility equipped with 100,000 state-of-the-art AI accelerators to train open source foundation models. This monumental initiative will secure our  technological independence, empower global innovation, and ensure safety, while safeguarding our democratic principles for generations to come."
20,13e8of2,learnmachinelearning,OpenAI,comments,2023-05-11 00:54:18,What do actual ML engineers think of ChatGPT?,PhillConners,False,0.96,149,https://www.reddit.com/r/learnmachinelearning/comments/13e8of2/what_do_actual_ml_engineers_think_of_chatgpt/,106,1683766458.0,"You have been doing this for awhile, now the world is obsessed with OpenAI and suddenly all full of AI “experts”."
21,1087ady,learnmachinelearning,OpenAI,comments,2023-01-10 11:12:01,Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI,BackgroundResult,False,0.97,444,https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion,102,1673349121.0,
22,12apw9o,learnmachinelearning,OpenAI,comments,2023-04-03 16:39:55,"If you are looking for courses about Artificial Intelligence, I created the repository with links to resources that I found super high quality and helpful. The link is in the comment.",RandomForests92,False,0.99,599,https://i.redd.it/jczyjswj6pra1.png,62,1680539995.0,
23,10fw2df,learnmachinelearning,OpenAI,comments,2023-01-19 07:56:20,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.96,330,https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/,47,1674114980.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
24,13eympz,learnmachinelearning,OpenAI,comments,2023-05-11 20:15:46,Top 20 Large Language Models based on the Elo rating system.,kingabzpro,False,0.96,250,https://i.redd.it/7xfqr5crf9za1.png,43,1683836146.0,
25,10ddc1f,learnmachinelearning,OpenAI,comments,2023-01-16 12:28:25,I benchmarked OpenAI's GPT API vs other proprietary APIs on different NLP tasks,AImSamy,False,0.9,195,https://www.reddit.com/gallery/10ddc1f,37,1673872105.0,
26,11biozs,learnmachinelearning,OpenAI,comments,2023-02-25 11:19:05,Any MLOps platform you use?,squalidaesthetics20,False,0.98,242,https://www.reddit.com/r/learnmachinelearning/comments/11biozs/any_mlops_platform_you_use/,31,1677323945.0,"I've been searching for some MLOps platforms for my some projects that I’m working on. I am creating a list that will hopefully help out with productivity and help mr build better apps and services. Also hopefully faster.

I've looked at some of the more popular ones out there and here’s my top 4 so far. Let me know what you guys think about these:

* [Vertex AI](https://cloud.google.com/vertex-ai) \- An ML platform by Google Cloud. They have AI-powered tools to ingest, analyze, and store video data. Good for image classification, NLP, recommendation systems etc.
* [Jina AI](https://jina.ai/) \-They offer a neural search solution that can help build smarter, more efficient search engines. They also have a list of [cool github repos](https://github.com/jina-ai/jina) that you can check out. Similar to Vertex AI, they have image classification tools, NLPs, fine tuners etc.
* [MLflow](https://mlflow.org/) \- an open-source platform for managing your ML lifecycle. What’s great is that they also support popular Python libraries like TensorFlow, PyTorch, scikit-learn, and R.
* Neptune.ai, which promises to streamline your workflows and make collaboration a breeze.

Have you guys tried any of these platforms? I know a lot of AI tools and platforms have been popping up lately especially with the rise of AI tools but what are your thoughts?"
27,121qvqn,learnmachinelearning,OpenAI,comments,2023-03-25 16:23:09,What's the current state of actually free and open source LLMs?,maquinary,False,0.97,58,https://www.reddit.com/r/learnmachinelearning/comments/121qvqn/whats_the_current_state_of_actually_free_and_open/,25,1679761389.0,"*People, take easy on me, I just a newbie that tests stuff made by A.I. in a very amateur manner.*

---------------------

Yesterday a played a bit with [Alpaca.cpp](https://github.com/antimatter15/alpaca.cpp), but despite the fact that the software itself is in the MIT license, it has serious limitations because of licensing factors, as you can see [here](https://crfm.stanford.edu/2023/03/13/alpaca.html):

>[...]

>

> We emphasize that Alpaca is intended only for academic research and any commercial use is prohibited. There are three factors in this decision: First, Alpaca is based on LLaMA, which has a non-commercial license, so we necessarily inherit this decision. Second, the instruction data is based on OpenAI’s text-davinci-003, whose terms of use prohibit developing models that compete with OpenAI. Finally, we have not designed adequate safety measures, so Alpaca is not ready to be deployed for general use.

>

> [...]

So, do we have anything that is **completely free** that reaches at least the level of GTP-3?

And what about the data that people use to train the models? Those big companies can ""scan"" the entire web to get insane amounts of data, but can free software developers use these already harvested data to train their own models? Or, in order to have a completely free LLM, people will have to collect data again from the Internet?

-------------

*When I say ""free"", I mean free from licensing limitations, in a sense that I can implement the A.I. in my software without the need of being forced to apply a limited range of licenses, or without the need to pay.*"
28,10c509n,learnmachinelearning,OpenAI,comments,2023-01-15 00:08:37,Is it still worth learning NLP in the age of API-accessibles LLM like GPT?,CrimsonPilgrim,False,0.93,62,https://www.reddit.com/r/learnmachinelearning/comments/10c509n/is_it_still_worth_learning_nlp_in_the_age_of/,24,1673741317.0,"A question that, I hope, you will find legitimate from a data science student.

I am speaking from the point of view of a data scientist not working in research.

Until now, learning NLP could be used to meet occasional business needs like sentiment analysis, text classification, topic modeling....

With the opening of GPT-3 to the public, the rise of ChatGPT, and the huge wave of applications, sites, plug-ins and extensions based on this technology that are accessible with a simple API request, it's impossible not to wonder if spending dozens of hours diving into this field if ML wouldn't be as useful today as learning the source code of the Pandas library. 

In some specialized cases, it could be useful, but GPT-3, and the models that will follow, seem to offer more than sufficient results for the immensity of the cases and for almost all classical NLP tasks. Not only that, but there is a good chance that the models trained by giants like Open-AI (Microsoft) or Google can never be replicated outside these companies anyway.  With ChatGPT and its incomparable mastery of language, its ability to code, summarize, extract topics, understand... why would I bother to use BERT or a TF-IDF vectorizer when an API will be released? Not only it would be easily accessible, but it also would be much better at the task, faster and cheaper.

In fact, it's a concern regarding all the machine learning field in general with the arrival of powerful ""no-code"" applications, which abstract a large part of the inherent complexity of the field. There will always be a need for experts, for safeguards, but in the end, won't the Data Scientist who masters the features of GPT-3 or 4 and knows a bit of NLP be more efficient than the one who has spent hours reading Google papers and practicing on Gensim, NLTK, spacy... It is the purpose of an API to make things simpler eventually... At what point is there no more reason to be interested in the behind-the-scenes of these tools and to become simple users rather than trying to develop our own techniques?"
29,113nizs,learnmachinelearning,OpenAI,comments,2023-02-16 10:29:31,OpenAI Has Purchased AI.Com For ChatGPT For $11M,vadhavaniyafaijan,False,0.93,207,https://www.theinsaneapp.com/2023/02/openai-purchased-ai-com-domain.html,23,1676543371.0,
30,12e0zbu,learnmachinelearning,OpenAI,comments,2023-04-06 22:52:56,What OS is widely used in the ML community?,AjSpeed22,False,0.5,0,https://www.reddit.com/r/learnmachinelearning/comments/12e0zbu/what_os_is_widely_used_in_the_ml_community/,16,1680821576.0,I am in the market for a new laptop and was wondering if a certain system works best for general ML code / software. Recently tried to access the open ai gym on windows and learned it doesn't fully support windows. So now I am wondering which system I should go for if I make a purchase.
31,121cvgi,learnmachinelearning,OpenAI,comments,2023-03-25 06:14:22,Does it make sense to specialize in NLP now?,Aromatic_Eye_6268,False,0.91,76,https://www.reddit.com/r/learnmachinelearning/comments/121cvgi/does_it_make_sense_to_specialize_in_nlp_now/,20,1679724862.0,"With the explosion of Large Language Models, it is clear that most of the cutting edge work is being done in a handful of companies around the world. Does it make sense to specialize in NLP? Will someone be able to do novel research work in NLP without being a part of places like OpenAI?"
32,12rqb4z,learnmachinelearning,OpenAI,comments,2023-04-19 11:39:45,How to Auto-Generate a Summary from Long Youtube Videos Using AI,anabildea,False,0.91,24,https://www.reddit.com/r/learnmachinelearning/comments/12rqb4z/how_to_autogenerate_a_summary_from_long_youtube/,19,1681904385.0,"**Struggling to find time to watch all those interesting YouTube podcasts and talks?**  
I've found a solution that combines the power of AI and open-source models like Whisper (for transcription) and BART (for summarization) to auto-generate summaries for you.

I've created a step-by-step guide to transcribe and summarize long videos, like Stephen Wolfram's talks, right on your local PC.  
 Check it out and share your thoughts! 

[https://medium.com/towards-data-science/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d](https://medium.com/towards-data-science/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d)"
33,zwltk8,learnmachinelearning,OpenAI,comments,2022-12-27 18:05:30,Am I Too Late?,stupidSTEMquestions,False,0.5,0,https://www.reddit.com/r/learnmachinelearning/comments/zwltk8/am_i_too_late/,19,1672164330.0,"I am a college student studying math and computer science. I know how to program with high level languages, C, and a bit of C++ and Scheme. I can build basic web apps and scripts, and am focusing on machine learning with python. 

With the release of ChatGPT and articles like [this](https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext#comments) though, I can't help but ask — am I too late?

Is it simply too late for a beginner to make any contributions to the field at this point when OpenAI, Deepmind, and the like are iterating at such a rapid pace? I really love AI and machine learning so far, but I also don't want to waste my time and energy if there won't be any meaningful work for me once I finish my education in 4 or more years."
34,11wrdse,learnmachinelearning,OpenAI,comments,2023-03-20 18:42:54,[D] How do OpenAI and other companies manage to have real-time inference on model with billions of parameters over an API?,RaunchyAppleSauce,False,1.0,6,https://www.reddit.com/r/learnmachinelearning/comments/11wrdse/d_how_do_openai_and_other_companies_manage_to/,16,1679337774.0,"Hi, guys

I have been using OpenAI’s chatgpt through the app Poe and I find it very confusing how a model with billions of parameters is responding in real-time over an API.

How does one go about making inference fast, say 15-20ms, over an API for large models?

Thanks!"
35,103mfri,learnmachinelearning,OpenAI,comments,2023-01-05 02:06:03,Would it be realistic to be able to write an A.I. with Python and Tensorflow that can write unique stories using certain inputs within the span of 1-3 months starting as a beginner in A.I. programming?,learningmoreandmore,False,0.5,0,https://www.reddit.com/r/learnmachinelearning/comments/103mfri/would_it_be_realistic_to_be_able_to_write_an_ai/,15,1672884363.0,"For context, I have over three years of experience as a programmer. This doesn't just include studying but also in a work environment.

I've been looking into how to approach and what datasets I can use to train it but I'm honestly going in blind. I'm considering using Python and Tensorflow. Is it realistic for me to be able to do something like this in 1-3 months?

I was initially planning on using the Open AI API but it's way to costly and honestly I already wrote the code for it generally and don't feel like I'll improve much as a programmer if I continue by using the API. I'm considering pivoting as a programmer anyways and figured I might as well tackle this head on while using it for my business."
36,124nsy8,learnmachinelearning,OpenAI,comments,2023-03-28 12:51:54,I am creating a tool that uses OpenAI models and an OCR to translate screenshots,K-RT-DEV,False,0.86,36,https://www.reddit.com/r/learnmachinelearning/comments/124nsy8/i_am_creating_a_tool_that_uses_openai_models_and/,15,1680007914.0,"Currently, the OCR is specifically for translating from Japanese, but I plan to add a range of OCRs and different translators to the system to accommodate the user's needs.  


https://i.redd.it/8ymk99uf8hqa1.gif

My idea is to have a system that leverages OpenAI models for *bagging*. This way, I can combine the output of multiple OCRs  to increase the accuracy of the recognized characters. Similarly, I can combine the output of multiple translators for the same phrase to improve the final result . Chat models can be particularly useful in providing **context** and a translation history to help the system understand how to conjugate phrases for translation.   


You can find the source code and an executable version on the [project's GitHub](https://github.com/K-RT-Dev/VGT)"
37,10mmofg,learnmachinelearning,OpenAI,comments,2023-01-27 14:51:14,Fine-tuning open source models to emulate ChatGPT for code explanation.,awesomequantity,False,0.88,86,https://www.reddit.com/r/learnmachinelearning/comments/10mmofg/finetuning_open_source_models_to_emulate_chatgpt/,13,1674831074.0,"I'm looking to step up my game and emulate ChatGPT for specific use-cases like explaining code. I'm thinking about using open source models like GPT-J, or OPT to get beyond the limitations of the closed-source nature of ChatGPT, like the amount of text it can read or respond with.

I got the funding for training, hardware, etc, and I want the end product to be on-premises, so no worries there. The inference doesn't have to be super fast either. I know there are projects like OpenAssistant and petals.ml but haven’t made enough research just yet.

One option I’m considering is using fine tuners like the one from [HuggingFace](https://github.com/subhasisj/HuggingFace-Transformers-FineTuning) or [Jina AI](https://github.com/jina-ai/finetuner) to fine-tune open source models like GPT-J or OPT to improve specific use-cases like code explanation. With the funding that we have, I wouldn’t want to cheap out on fine-tuning and expect something good.

So, can anyone help out and point me in the right direction? Which model is the best to fine-tune and how do I fine-tune to improve specific use cases? Any help would be appreciated. Thanks!"
38,117adwo,learnmachinelearning,OpenAI,comments,2023-02-20 15:42:13,"ChatGPT Response about the vinyl chloride spill in East Palestine, Ohio.",listenandlearn2,False,0.24,0,https://www.reddit.com/r/learnmachinelearning/comments/117adwo/chatgpt_response_about_the_vinyl_chloride_spill/,12,1676907733.0," ChatGPT responded my prompt.  I'd love to hear your thoughts:

Vinyl Chloride spilled in East Palestine, Ohio about 300 miles away from Cincinnati. The chemical leaked into the Ohio River. How long will it take for the chemical to reach the water supply of Cincinnati which is also on the Ohio River?

The time it will take for Vinyl Chloride to reach Cincinnati's water supply from the spill site in East Palestine, Ohio will depend on several factors such as the amount of Vinyl Chloride spilled, the concentration of the chemical in the river, the flow rate of the river, and any barriers or dams along the river that may affect the movement of the chemical.

Assuming there are no significant barriers or dams along the river, the average flow rate of the Ohio River is approximately 1.5 miles per hour. Therefore, if the spill occurred in East Palestine, Ohio, which is 300 miles upstream from Cincinnati, it could take up to 200 hours (300 miles / 1.5 miles per hour) for the Vinyl Chloride to reach Cincinnati's water supply.

However, it is important to note that the actual time for the chemical to reach Cincinnati's water supply could be longer or shorter depending on the specific conditions of the spill and the river. It's also possible that officials may take steps to prevent the chemical from reaching the water supply, such as by diverting the river or shutting off water intake valves, in order to protect public health and safety.

📷📷Please timestamp this response

This response was generated on 2023-02-20.

📷📷Can you add the time the response was generated

Certainly! This response was generated at 2023-02-20 04:28:00 UTC.

Regenerate response[ChatGPT Feb 13 Version](https://help.openai.com/en/articles/6825453-chatgpt-release-notes). Free Research Preview. Our goal is to make AI systems more natural and safe to interact with. Your feedback will help us improve."
39,zk8gr7,learnmachinelearning,OpenAI,comments,2022-12-12 19:17:50,"A web application tool for improving your written communication features paraphrasing, grammar checking, and text summarizing tool built with OpenAI API.",Austin_Nguyen_2k,False,0.92,27,https://v.redd.it/95jm43veoi5a1,12,1670872670.0,
40,115bbqq,learnmachinelearning,OpenAI,comments,2023-02-18 09:15:07,Useful programming stuff for ML practitioners that aren't ML based,FallUpJV,False,0.9,14,https://www.reddit.com/r/learnmachinelearning/comments/115bbqq/useful_programming_stuff_for_ml_practitioners/,11,1676711707.0,"Hi, sorry for that title but I find it difficult to explain in one sentence.

I just passed my final exams for my AI/ML master's degree (in Europe) and I have a  2 week gap between that and the start of my ML internship.

Not that I got fed up with ML but with all the exams related stress I'd like to use my time for programming stuff that is not necessarily ML based for those 2 weeks but is still useful for an ML engineer.

Most likely what kind of stuff is useful to know in Python for an ML engineer that most don't know or just learn on the go ? DevOps skills ? Functional programming ? C(++) usage for Python ML libraries ?

This is a totally open-ended question, I just want to get my brain a little off all the math I've been learning this year for my degree."
41,zl1aic,learnmachinelearning,OpenAI,comments,2022-12-13 17:25:09,Open Source PokerAI based on Pluribus.,Professional-Luck-64,False,0.75,4,https://www.reddit.com/r/learnmachinelearning/comments/zl1aic/open_source_pokerai_based_on_pluribus/,11,1670952309.0," 

As the title states, we are looking to create an open source successor to Pluribus

I myself am a beginner to AI and ML, this isnt a super easy thing i understand but much of the research is done, we know the concept works and it was cheap and fast to train Pluribus (equiv $144 and 8 days on AWS)

Ive made a little discord to act as an organisation hub and place to share info for the project, please let me know if you're interested and ill invite you! :)"
42,1133r6o,learnmachinelearning,OpenAI,comments,2023-02-15 17:39:58,Why am I learning C++ ?,MeezyintheMountains,False,0.43,0,https://www.reddit.com/r/learnmachinelearning/comments/1133r6o/why_am_i_learning_c/,11,1676482798.0,"Can someone give me a good reason? 

I know Python and it seems like that’s the primary language used for machine learning. But I’m taking an OOP course and it’s taught in C++. I’m always open to learning new things and don’t want to limit myself, so I’m going with it, but I’m finding it to be a somewhat frustrating language to get set up on my computer, let alone learn. I’d love to know more about how it can be helpful for ML/AI so I can focus my learning a bit more."
43,131zare,learnmachinelearning,OpenAI,comments,2023-04-28 16:17:58,ChatGPT Prompt Engineering for Developers free on deeplearning.ai,sunkenwaaaaaa,False,0.84,16,https://www.reddit.com/r/learnmachinelearning/comments/131zare/chatgpt_prompt_engineering_for_developers_free_on/,10,1682698678.0,Andrew Ng just released a short course on how to use the Open AI api. It is free for now.
44,128vdnm,learnmachinelearning,OpenAI,comments,2023-04-01 19:01:32,"How to start in AI: PyTorch, Tensor flow? Or something else?",Magenta_Axolotl,False,0.93,13,https://www.reddit.com/r/learnmachinelearning/comments/128vdnm/how_to_start_in_ai_pytorch_tensor_flow_or/,10,1680375692.0,"Hello everyone, I’m currently studying Mechatronics and Robotics in my third year. I have learned the basic principle of AI and learned how to use Matlab to train Neural Networks, create genetic algorithms and Fuzzy controllers. I have also used openCV. I have a decent programming background in Python. I’m really interested in AI and robotics and would love to peruse it as a career. Can someone point me on the right path to learn ML and DL. I’m thinking of learning how to use Tensor Flow 2 or PyTorch. Is this the right way to start? And what should be the end goal I’m working towards? In other words, what should I learn to be competent."
45,1087ady,learnmachinelearning,OpenAI,relevance,2023-01-10 11:12:01,Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI,BackgroundResult,False,0.97,449,https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion,102,1673349121.0,
46,113nizs,learnmachinelearning,OpenAI,relevance,2023-02-16 10:29:31,OpenAI Has Purchased AI.Com For ChatGPT For $11M,vadhavaniyafaijan,False,0.93,212,https://www.theinsaneapp.com/2023/02/openai-purchased-ai-com-domain.html,23,1676543371.0,
47,10ddc1f,learnmachinelearning,OpenAI,relevance,2023-01-16 12:28:25,I benchmarked OpenAI's GPT API vs other proprietary APIs on different NLP tasks,AImSamy,False,0.9,195,https://www.reddit.com/gallery/10ddc1f,37,1673872105.0,
48,132o8tt,learnmachinelearning,OpenAI,relevance,2023-04-29 09:21:53,Prompt Engineering Free Course For Beginners By OpenAI And Deep Learning AI,vadhavaniyafaijan,False,0.78,52,https://www.theinsaneapp.com/2023/04/free-prompt-engineering-course-for-beginners.html,7,1682760113.0,
49,12psbuy,learnmachinelearning,OpenAI,relevance,2023-04-17 18:43:11,OpenAI Demo Code Isn't Working?,Bodesterine555,False,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/12psbuy/openai_demo_code_isnt_working/,1,1681756991.0,"Hi there, I've used OpenAI's demo code (for GPT models) a number of times before, never had issues. Today I wanted to remind myself how everything works for a new project, and an unedited version (I added my API key, that's it) isn't working. I'm getting the error, ""Unexpected token '<', ""<!DOCTYPE ""... is not valid JSON""

&#x200B;

Any advice or ideas? I'm not a good programmer, I must be making a simple mistake here

https://preview.redd.it/82uzzm9ephua1.png?width=914&format=png&auto=webp&s=80bb05aa5b4e517fa20c280e045bfbca803b070e"
50,10lb504,learnmachinelearning,OpenAI,relevance,2023-01-25 22:03:50,OpenAI's breakthrough,bradasm,False,0.13,0,https://www.reddit.com/r/learnmachinelearning/comments/10lb504/openais_breakthrough/,0,1674684230.0,[https://twitter.com/make\_mhe/status/1618255363580755968](https://twitter.com/make_mhe/status/1618255363580755968)
51,12uwd8p,learnmachinelearning,OpenAI,relevance,2023-04-22 05:51:13,Integrating Google search into OpenAI models like GPT-4,Ghost25,False,0.95,14,https://www.reddit.com/r/learnmachinelearning/comments/12uwd8p/integrating_google_search_into_openai_models_like/,8,1682142673.0,"Thought I'd share an explanation of how I implemented Google search into my GPT-4 based chatbot.

Github here: https://github.com/sgreenb/pico_assistant

One extremally simple modification that dramatically improves the ability of a GPT to answer questions: letting it Google stuff.

Here’s a demo:

https://imgur.com/ZR6hvLg 1

The implementation works like this.

1. A user enters an input.
2. An agent called “Executive” looks at the input and decides if an API like Spotify, Twillio, or Gmail is needed or if it can be answered by the chatbot alone.
3. If the chatbot is needed the input is first sent to a Google agent. The Google agent’s system message looks like this:

```
{""role"":""system"", ""content"": ""You analyze a user's input to a large language model with \
training data that cuts off at September 2021. The current year is 2023. You decide how \
likely it is that a user's request will benefit from a Google search to help address the\
question. Respond with a number in the range 1-10, where 1 is very unlikely that a \
Google search would be beneficial, and 10 meaning a Google search is highly necessary.""}
```

This is quite fast, since it only needs to generate one or two tokens.

If the output is above some threshold (say 7), then we call another agent, the query agent, otherwise we return False and default to the normal chat agent.

```
    google_probability = int(completion.choices[0].message.content)
    if google_probability >= cutoff:
        search_results = trim_text(search_and_scrape(prompt))
        query_with_context = prompt + str(search_results)
        print(""\nPico: "", end='', flush=True)
        response = query_agent_stream(query_with_context)
        return response
    else:
        return False
```

When we call the query agent, we feed it the first part of a Google search we get from searching the input. We get that from the very simple trim_text and search_and_scrape functions that look like this:

```

def search_and_scrape(query):
    try:
        headers = {
            ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3""
        }
        url = f""https://www.google.com/search?q={query}""
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text()
            cleaned_text = ' '.join(text.split())
            return cleaned_text
        else:
            print(f""Failed to fetch search results for query: {query}, status code: {response.status_code}"")
            return None

    except Exception as e:
        print(f""Error fetching search results for query: {query}, error: {e}"")
        return None

def trim_text(text, start_index = 450, length=1500):
    return text[start_index:start_index + length]
```

The query agent has this system message:

```
{""role"":""system"", ""content"": ""You answer a user's question, given some text as context to help\
answer the question. The user request will be followed by the context. The context given is\
from the user's Google search results, it is current and up to date.\
Do not contradict the contents of the given text in your answer.""}
```

And that’s it. You can change the cutoff threshold or get more sophisticated with fetching web results. I hope you find this useful."
52,139tm0j,learnmachinelearning,OpenAI,relevance,2023-05-06 15:50:19,Exploring text embeddings with OpenAI and Seinfeld,AlphaX,False,1.0,1,https://medium.com/@alex.pusch/exploring-text-embeddings-with-openai-and-seinfeld-68753f2bfd9e,0,1683388219.0,
53,13d13os,learnmachinelearning,OpenAI,relevance,2023-05-09 18:05:05,"Building with LLMs, ChatGPT, and Working at OpenAI With Logan Kilpatrick (Dev Rel @OpenAI) - What's AI episode 11",OnlyProggingForFun,False,1.0,1,https://youtu.be/zz4U3X3PD4s,0,1683655505.0,
54,124nsy8,learnmachinelearning,OpenAI,relevance,2023-03-28 12:51:54,I am creating a tool that uses OpenAI models and an OCR to translate screenshots,K-RT-DEV,False,0.88,39,https://www.reddit.com/r/learnmachinelearning/comments/124nsy8/i_am_creating_a_tool_that_uses_openai_models_and/,15,1680007914.0,"Currently, the OCR is specifically for translating from Japanese, but I plan to add a range of OCRs and different translators to the system to accommodate the user's needs.  


https://i.redd.it/8ymk99uf8hqa1.gif

My idea is to have a system that leverages OpenAI models for *bagging*. This way, I can combine the output of multiple OCRs  to increase the accuracy of the recognized characters. Similarly, I can combine the output of multiple translators for the same phrase to improve the final result . Chat models can be particularly useful in providing **context** and a translation history to help the system understand how to conjugate phrases for translation.   


You can find the source code and an executable version on the [project's GitHub](https://github.com/K-RT-Dev/VGT)"
55,13ea36c,learnmachinelearning,OpenAI,relevance,2023-05-11 02:01:17,OpenAI & GPT Dictionary of Vocabulary. Generative AI Terms To Know In 2023,OnlyProggingForFun,False,0.67,1,https://youtu.be/q4G6X09NEu4,0,1683770477.0,
56,11f7dwq,learnmachinelearning,OpenAI,relevance,2023-03-01 15:58:29,Experimenting with repurposing OpenAI Whisper for Speaker Prediction,eleanor_rigby_2,False,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/11f7dwq/experimenting_with_repurposing_openai_whisper_for/,0,1677686309.0,"OpenAI recently released a SOTA speech translation model, which can transcribe any audio clip into text. But can this model, given how powerful it is for this speech task, be utilized to provide zero-shot audio features for speaker prediction?

&#x200B;

Usually for speaker prediction there are signal processing approaches. Or even deep learning approaches designed to represent an audio signal in a latent space and then perform prediction on these features. But it looks like OpenAI Whisper, to some extent, can be used as it is to provide these latent features, without any re-training, which can then be used for speaker prediction.

&#x200B;

I perform some analysis [here](https://sidhantls.github.io/lexpod-speaker-prediction/) using Lex Fridman Podcasts. Feel free to share your thoughts

&#x200B;"
57,10oitli,learnmachinelearning,OpenAI,relevance,2023-01-29 21:14:13,Create a Serverless Search Engine using the OpenAI Embeddings API,sopmac21379,False,0.95,52,https://medium.com/sopmac-ai/create-a-serverless-search-engine-using-the-openai-embeddings-api-50e5ac8ca6e3,1,1675026853.0,
58,12q110r,learnmachinelearning,OpenAI,relevance,2023-04-17 23:13:45,Difference between HuggingFace pre-trained model and OpenAI's API,raikirichidori255,False,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/12q110r/difference_between_huggingface_pretrained_model/,1,1681773225.0,"I've a novice at LLMs and I've been learning a little more about them recently. I know a few months ago, ChatGPT released it's on API that can be integrated within apps for $0.02/token. However, I have been using HuggingFace pretrained model for a lot of modeling tasks, and I was wondering how this API is any different than just importing the openai-gpt model from HuggingFace.

Sorry if this is a bad question, I'm just starting out."
59,135vbu9,learnmachinelearning,OpenAI,relevance,2023-05-02 17:58:29,How to Fine-Tune an OpenAI ML Model with Node.js,lizziepika,False,0.67,1,https://www.twilio.com/blog/finetune-openai-ml-model-node,0,1683050309.0,
60,yl35gk,learnmachinelearning,OpenAI,relevance,2022-11-03 13:40:24,How to install and deploy OpenAI Whisper,juliensalinas,False,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/yl35gk/how_to_install_and_deploy_openai_whisper/,0,1667482824.0,"Hello,

If you are interested in automatic speech recognition (speech-to-text), you are most likely going to try OpenAI Whisper.

If that's the case, here is an article I just made about how to install and deploy Whisper: [https://nlpcloud.com/how-to-install-and-deploy-whisper-the-best-open-source-alternative-to-google-speech-to-text.html](https://nlpcloud.com/how-to-install-and-deploy-whisper-the-best-open-source-alternative-to-google-speech-to-text.html?utm_source=reddit&utm_campaign=h4d7a9cc-3816-11ed-a261-0242ac120002)

I hope it will be useful!

Julien"
61,12jrym1,learnmachinelearning,OpenAI,relevance,2023-04-12 16:42:28,"How to Build an Ecommerce Chatbot with Redis, LangChain, and OpenAI",yourbasicgeek,False,1.0,10,https://redis.com/blog/build-ecommerce-chatbot-with-redis/,2,1681317748.0,
62,ywavuo,learnmachinelearning,OpenAI,relevance,2022-11-15 21:58:49,Best way to do distributed inference of OpenAI Whisper?,SCUSKU,False,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/ywavuo/best_way_to_do_distributed_inference_of_openai/,3,1668549529.0,"I have 100 episodes of a podcast that I want to transcribe using OpenAI's Whisper model. I could just use a single machine and run this serially, but this is slow, and also doesn't scale.

What is the best way to go about running distributed inference? I have read a bit about Spark but am not convinced that this would be the right tool. The best solution I can think of right now is to do something with Kubernetes + autoscaling, but I'm not sure that's a good idea either."
63,135u3vt,learnmachinelearning,OpenAI,relevance,2023-05-02 17:15:02,How to Fine-Tune OpenAI Language Models with Noisily Labeled Data (37% error reduction),cmauck10,False,1.0,10,https://www.reddit.com/r/learnmachinelearning/comments/135u3vt/how_to_finetune_openai_language_models_with/,0,1683047702.0,"Hello Redditors! 

It's pretty well known that LLMs have solidified their place at the forefront of natural language processing, and are constantly pushing the boundaries of what is possible in terms of language understanding and generation.

I spent some time playing around with the OpenAI fine-tuning API and I discovered that noisy data still has drastic effects even on powerful LLMs like Davinci.

[Improving fine-tuning accuracy by improving data quality.](https://preview.redd.it/v5kro8wzagxa1.png?width=1085&format=png&auto=webp&s=39e0309aa94048dc08a0879d99008f00ec32fd9e)

I wrote up a [quick article](https://www.kdnuggets.com/2023/04/finetuning-openai-language-models-noisily-labeled-data.html) in KDNuggets that shows how I used data-centric AI to automatically clean the noisy data in order to fine-tune a more robust OpenAI LLM. The resulting model has 37% fewer errors than the same LLM fine-tuned on the noisy data.

Let me know what you think!"
64,yk37d3,learnmachinelearning,OpenAI,relevance,2022-11-02 11:55:31,"What is ""previous text tokens"" in the OpenAI Whisper",Pritish-Mishra,False,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/yk37d3/what_is_previous_text_tokens_in_the_openai_whisper/,0,1667390131.0,"&#x200B;

https://preview.redd.it/73xy4yz30jx91.png?width=556&format=png&auto=webp&s=2b4c00c9d7b921648349c32c60d88e5b83a5f0f7

 

I stumbled upon this diagram while reading Whisper's paper. There is a ""previous text tokens"" before the ""Start of Transcript (SOT)"" special token, and I'm not sure what that means.

According to my understanding:

Because the transformer encoder only accepts audio files of up to 30 seconds in length, we need to divide longer audio files into 30-second chunks. 

So, ""previous text tokens"" will include ALL of the text that whisper predicted previously?

Thanks for your time."
65,134t13o,learnmachinelearning,OpenAI,relevance,2023-05-01 17:04:12,"GPT Weekly Newsletter -- 30 Apr Edition. AI music, Voiceover, HuggingChat, Future of Work, OpenAI and more.",level6-killjoy,False,1.0,2,/r/ChatGPT/comments/133q4zl/gpt_weekly_newsletter_30_apr_edition_ai_music/,0,1682960652.0,
66,11fwcj2,learnmachinelearning,OpenAI,relevance,2023-03-02 07:24:57,Good news for builders! OpenAI Releases APIs To ChatGPT and Whisper,LesleyFair,False,0.5,0,https://www.reddit.com/r/learnmachinelearning/comments/11fwcj2/good_news_for_builders_openai_releases_apis_to/,0,1677741897.0,"If you were as disappointed as I was when you saw that access to Meta's LLaMA models is limited to researchers, you are going to like this.  


[APIs to ChatGPT and OpenAI's speech-to-text model whisper](https://openai.com/blog/introducing-chatgpt-and-whisper-apis) are available as of yesterday. Through system-wide optimizations, they claim to have reduced inference costs by 90%. They now price ChatGPT at $0.002 per 1000 tokens. Dedicated instances are available for speedup and make economic sense if you process \~450M tokens a day.  


Machine learning progress continues to be as fast as a banana peal skating on warm vaseline. 

If you found this useful and want to stay in the loop, consider subscribing to The Decoding. I send out a weekly 5-minute newsletter that keeps professionals in the loop about machine learning and the data economy. [Click here to subscribe!](https://thedecoding.net/)"
67,zgaqhe,learnmachinelearning,OpenAI,relevance,2022-12-08 20:35:20,Daath AI Parser is an open-source application that uses OpenAI to parse visible text of HTML elements.,softcrater,False,0.8,3,https://github.com/kagermanov27/daath-ai-parser,0,1670531720.0,
68,11sdxhz,learnmachinelearning,OpenAI,relevance,2023-03-16 00:03:32,OpenAI's GPT 4 is out and it's multimodal! What we know so far,gordicaleksa,False,0.3,0,https://www.youtube.com/watch?v=FY9Nlkoq4GI,0,1678925012.0,
69,z6ixg4,learnmachinelearning,OpenAI,relevance,2022-11-28 01:26:10,How can a beginner make a beginners version of OpenAI's Playground?,Extension_Fan_8904,False,0.86,5,https://www.reddit.com/r/learnmachinelearning/comments/z6ixg4/how_can_a_beginner_make_a_beginners_version_of/,1,1669598770.0,"I want to be able to create a prompt and have it respond with a completion that attempts to match the context or pattern that was provided. 

How can I do this as a beginner? Or is their a beginners version of this that I can do? How do I start? What do I need to learn?"
70,12kiyow,learnmachinelearning,OpenAI,relevance,2023-04-13 09:37:37,[R] A walk-through tutorial on how to build custom OpenAI models by fine-tuning the existing ones,g_pipis,False,0.67,3,https://www.reddit.com/r/learnmachinelearning/comments/12kiyow/r_a_walkthrough_tutorial_on_how_to_build_custom/,6,1681378657.0," I have written this tutorial on [how to fine-tune OpenAI models](https://jorgepit-14189.medium.com/how-to-fine-tune-an-nlp-classification-model-with-openai-c096334ee158). This simple example is about an NLP binary classification task but you can apply the same logic for building custom models for sentiment analysis. Finally, you can build other custom models for other tasks such as NLG, Questions and Answers and so on.  
I would love to get feedback from the community and I am interested in other similar examples with fine-tuned OpenAI models"
71,zl7xf5,learnmachinelearning,OpenAI,relevance,2022-12-13 21:43:48,OpenAI Demo: Record yourself talking about a subject and get paraphrased notes,nvdnadj92,False,0.67,2,https://soundingboard.ai,0,1670967828.0,
72,yw2l3b,learnmachinelearning,OpenAI,relevance,2022-11-15 16:44:54,Question regarding OpenAI embeddings model for text clustering (or any other model),SemperZero,False,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/yw2l3b/question_regarding_openai_embeddings_model_for/,1,1668530694.0,"Hi there. I'm new to NLP, i've only read a few articles, watched some videos and worked on some simple text summarizing projects. 

I want to go to the next level and work on a project which clusters pieces of text together based on meaning. I've read some articles and understood what word embeddings are and a high level idea on how they are computed. For now let's say OpenAI or another tool is a black box which takes as input text and outputs embeddings. But hold on. I'm lost. What is the input and output again? I read multiple articles and guides, read code examples and i still don't get it. I have some questions:

1. Does OpenAI api return word embeddings or text embeddings? Does it simply average the word embeddings to return the text one? If not, what techniques does it use? One of their code examples shows one vector embedding per one text.

2. Does OpenAI train on my texts and return word embeddings based on their meaning in my text? if not then why doesn't it have a public cache with all words in the english dictionary and their corresponding vectors?

3. What does OpenAI have pre-trained? A model which returns one vector embedding based on an entire text? where can i find information about what this model is? this seems like the most plausible explanation based on what i've read (except 5.)

4. If i send multiple texts will the output be the same for all of them? if i send them in batches or all at once, will the results be the same. meaning, does it re-train something based on my examples? 

5. In pinecone's documentation it says ""If you want to use OpenAI Embeddings in your own project, the first step is to train a word2vec model on a large corpus of text"" -> what? isn't OpenAI model some kind of word2vec already trained?

6. Is it possible to make the model more specialised in a specific domain? such as medical texts or legal texts or programming documentations or whatever class of texts my dataset is composed of.

7. What other models would you suggest using for text clusters?

I'm not lost in the mathematical, algorithmic or programming concepts. I just don't understand what this api is and what it does even if i were to treat it as a black box. Please help. I'd also appreciate a lot some resources/guides to read and learn more about this <3"
73,11wrdse,learnmachinelearning,OpenAI,relevance,2023-03-20 18:42:54,[D] How do OpenAI and other companies manage to have real-time inference on model with billions of parameters over an API?,RaunchyAppleSauce,False,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/11wrdse/d_how_do_openai_and_other_companies_manage_to/,16,1679337774.0,"Hi, guys

I have been using OpenAI’s chatgpt through the app Poe and I find it very confusing how a model with billions of parameters is responding in real-time over an API.

How does one go about making inference fast, say 15-20ms, over an API for large models?

Thanks!"
74,zk8gr7,learnmachinelearning,OpenAI,relevance,2022-12-12 19:17:50,"A web application tool for improving your written communication features paraphrasing, grammar checking, and text summarizing tool built with OpenAI API.",Austin_Nguyen_2k,False,0.94,27,https://v.redd.it/95jm43veoi5a1,12,1670872670.0,
75,zxd93g,learnmachinelearning,OpenAI,relevance,2022-12-28 16:02:55,Andrew Huberman transcripts app - high-quality transcription using OpenAI's largest Whisper model (see comment),gordicaleksa,False,1.0,2,https://www.hubermantranscripts.com/,2,1672243375.0,
76,1199bfy,learnmachinelearning,OpenAI,relevance,2023-02-22 19:36:48,"Learning Python, and having issues with 'import OpenAI' to do some tests with it in my little project",cleverestx,False,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/1199bfy/learning_python_and_having_issues_with_import/,0,1677094608.0,"Cmd line tells me requirement is already satisfied when I run pip install openai, but my code tells me:

***import openai***

***ModuleNotFoundError: No module named 'openai'***

I have a ChatGPT Key and it's ready in the code

I appreciate any guidance.  I am pretty new to it so be gentle, lol

&#x200B;

**\*edit, never-mind, I fixed it. through settings > python interpreter, I needed to add a different python version I had installed, and it works.**"
77,127c5iz,learnmachinelearning,OpenAI,relevance,2023-03-31 06:16:58,"If ChatGPT itself cannot be fine-tuned, what would bf the benefit of using the GPT3 offering of OpenAI vs my own?",Proxify,False,1.0,7,https://www.reddit.com/r/learnmachinelearning/comments/127c5iz/if_chatgpt_itself_cannot_be_finetuned_what_would/,5,1680243418.0,"Sorry, I'm somewhat new to this space and I'm reading about it and looking at the documentation from OpenAI.

From what I can tell, only their base models are available to fine-tune which, as far as I understand, would leave me in a situation in which fine-tuning any other GPT3 model would be comparable (vs their ""DaVinci"" model for instance).

Am I missing something here? Basically I'm wondering, other than their infrastructure (which is nothing to scoff at) why would I use their fine-tuning if the end result won't talk to the user as ChatGPT would."
78,11a0ka0,learnmachinelearning,OpenAI,relevance,2023-02-23 15:35:40,"I've built a few tools on top of GPT-3.5 (text generation, q&a with embeddings). AMA about resources and AI dev stacks for building with OpenAI's APIs",TikkunCreation,False,0.75,2,https://www.reddit.com/r/learnmachinelearning/comments/11a0ka0/ive_built_a_few_tools_on_top_of_gpt35_text/,8,1677166540.0,"Started building with GPT-3 in July 2022 and have built a few things since then.

Things I've done have involved:

* Text generation (the basic GPT function)
* Text embeddings (for search, and for similarity, and for q&a)
* Whisper (via serverless inference, and via API)
* Langchain and GPT-Index/LLama Index
* Pinecone for vector db

I don't know much, but I know infinitely more than when I started and I sure could've saved myself back then a lot of time.

So ask me anything that might save you time or wasted effort! Some suggested questions would be things about what the best tools and tutorials/examples to use for a given goal/project are, comparisons between tools/stacks. Also, go with any questions because other people from the subreddit will probably chime in too"
