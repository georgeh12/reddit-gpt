,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,id,url,num_comments,created,body
0,deeplearning,gpt-3,top,2022-12-02 01:35:02,GPT-3 Generated Rap Battle between Yann LeCun & Gary Marcus,hayAbhay,False,0.99,137,za73dc,https://i.redd.it/ybfcfvez1e3a1.png,16,1669944902.0,
1,deeplearning,gpt-3,top,2023-01-27 10:45:48,⭕ What People Are Missing About Microsoft’s $10B Investment In OpenAI,LesleyFair,False,0.95,117,10mhyek,https://www.reddit.com/r/deeplearning/comments/10mhyek/what_people_are_missing_about_microsofts_10b/,16,1674816348.0,"&#x200B;

[Sam Altman Might Have Just Pulled Off The Coup Of The Decade](https://preview.redd.it/sg24cw3zekea1.png?width=720&format=png&auto=webp&s=9eeae99b5e025a74a6cbe3aac7a842d2fff989a1)

Microsoft is investing $10B into OpenAI!

There is lots of frustration in the community about OpenAI not being all that open anymore. They appear to abandon their ethos of developing AI for everyone, [free](https://openai.com/blog/introducing-openai/) of economic pressures.

The fear is that OpenAI’s models are going to become fancy MS Office plugins. Gone would be the days of open research and innovation.

However, the specifics of the deal tell a different story.

To understand what is going on, we need to peek behind the curtain of the tough business of machine learning. We will find that Sam Altman might have just orchestrated the coup of the decade!

To appreciate better why there is some three-dimensional chess going on, let’s first look at Sam Altman’s backstory.

*Let’s go!*

# A Stellar Rise

Back in 2005, Sam Altman founded [Loopt](https://en.wikipedia.org/wiki/Loopt) and was part of the first-ever YC batch. He raised a total of $30M in funding, but the company failed to gain traction. Seven years into the business Loopt was basically dead in the water and had to be shut down.

Instead of caving, he managed to sell his startup for $[43M](https://golden.com/wiki/Sam_Altman-J5GKK5) to the finTech company [Green Dot](https://www.greendot.com/). Investors got their money back and he personally made $5M from the sale.

By YC standards, this was a pretty unimpressive outcome.

However, people took note that the fire between his ears was burning hotter than that of most people. So hot in fact that Paul Graham included him in his 2009 [essay](http://www.paulgraham.com/5founders.html?viewfullsite=1) about the five founders who influenced him the most.

He listed young Sam Altman next to Steve Jobs, Larry & Sergey from Google, and Paul Buchheit (creator of GMail and AdSense). He went on to describe him as a strategic mastermind whose sheer force of will was going to get him whatever he wanted.

And Sam Altman played his hand well!

He parleyed his new connections into raising $21M from Peter Thiel and others to start investing. Within four years he 10x-ed the money \[2\]. In addition, Paul Graham made him his successor as president of YC in 2014.

Within one decade of selling his first startup for $5M, he grew his net worth to a mind-bending $250M and rose to the circle of the most influential people in Silicon Valley.

Today, he is the CEO of OpenAI — one of the most exciting and impactful organizations in all of tech.

However, OpenAI — the rocket ship of AI innovation — is in dire straights.

# OpenAI is Bleeding Cash

Back in 2015, OpenAI was kickstarted with $1B in donations from famous donors such as Elon Musk.

That money is long gone.

In 2022 OpenAI is projecting a revenue of $36M. At the same time, they spent roughly $544M. Hence the company has lost >$500M over the last year alone.

This is probably not an outlier year. OpenAI is headquartered in San Francisco and has a stable of 375 employees of mostly machine learning rockstars. Hence, salaries alone probably come out to be roughly $200M p.a.

In addition to high salaries their compute costs are stupendous. Considering it cost them $4.6M to train GPT3 once, it is likely that their cloud bill is in a very healthy nine-figure range as well \[4\].

So, where does this leave them today?

Before the Microsoft investment of $10B, OpenAI had received a total of $4B over its lifetime. With $4B in funding, a burn rate of $0.5B, and eight years of company history it doesn’t take a genius to figure out that they are running low on cash.

It would be reasonable to think: OpenAI is sitting on ChatGPT and other great models. Can’t they just lease them and make a killing?

Yes and no. OpenAI is projecting a revenue of $1B for 2024. However, it is unlikely that they could pull this off without significantly increasing their costs as well.

*Here are some reasons why!*

# The Tough Business Of Machine Learning

Machine learning companies are distinct from regular software companies. On the outside they look and feel similar: people are creating products using code, but on the inside things can be very different.

To start off, machine learning companies are usually way less profitable. Their gross margins land in the 50%-60% range, much lower than those of SaaS businesses, which can be as high as 80% \[7\].

On the one hand, the massive compute requirements and thorny data management problems drive up costs.

On the other hand, the work itself can sometimes resemble consulting more than it resembles software engineering. Everyone who has worked in the field knows that training models requires deep domain knowledge and loads of manual work on data.

To illustrate the latter point, imagine the unspeakable complexity of performing content moderation on ChatGPT’s outputs. If OpenAI scales the usage of GPT in production, they will need large teams of moderators to filter and label hate speech, slurs, tutorials on killing people, you name it.

*Alright, alright, alright! Machine learning is hard.*

*OpenAI already has ChatGPT working. That’s gotta be worth something?*

# Foundation Models Might Become Commodities:

In order to monetize GPT or any of their other models, OpenAI can go two different routes.

First, they could pick one or more verticals and sell directly to consumers. They could for example become the ultimate copywriting tool and blow [Jasper](https://app.convertkit.com/campaigns/10748016/jasper.ai) or [copy.ai](https://app.convertkit.com/campaigns/10748016/copy.ai) out of the water.

This is not going to happen. Reasons for it include:

1. To support their mission of building competitive foundational AI tools, and their huge(!) burn rate, they would need to capture one or more very large verticals.
2. They fundamentally need to re-brand themselves and diverge from their original mission. This would likely scare most of the talent away.
3. They would need to build out sales and marketing teams. Such a step would fundamentally change their culture and would inevitably dilute their focus on research.

The second option OpenAI has is to keep doing what they are doing and monetize access to their models via API. Introducing a [pro version](https://www.searchenginejournal.com/openai-chatgpt-professional/476244/) of ChatGPT is a step in this direction.

This approach has its own challenges. Models like GPT do have a defensible moat. They are just large transformer models trained on very large open-source datasets.

As an example, last week Andrej Karpathy released a [video](https://www.youtube.com/watch?v=kCc8FmEb1nY) of him coding up a version of GPT in an afternoon. Nothing could stop e.g. Google, StabilityAI, or HuggingFace from open-sourcing their own GPT.

As a result GPT inference would become a common good. This would melt OpenAI’s profits down to a tiny bit of nothing.

In this scenario, they would also have a very hard time leveraging their branding to generate returns. Since companies that integrate with OpenAI’s API control the interface to the customer, they would likely end up capturing all of the value.

An argument can be made that this is a general problem of foundation models. Their high fixed costs and lack of differentiation could end up making them akin to the [steel industry](https://www.thediff.co/archive/is-the-business-of-ai-more-like-steel-or-vba/).

To sum it up:

* They don’t have a way to sustainably monetize their models.
* They do not want and probably should not build up internal sales and marketing teams to capture verticals
* They need a lot of money to keep funding their research without getting bogged down by details of specific product development

*So, what should they do?*

# The Microsoft Deal

OpenAI and Microsoft [announced](https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/) the extension of their partnership with a $10B investment, on Monday.

At this point, Microsoft will have invested a total of $13B in OpenAI. Moreover, new VCs are in on the deal by buying up shares of employees that want to take some chips off the table.

However, the astounding size is not the only extraordinary thing about this deal.

First off, the ownership will be split across three groups. Microsoft will hold 49%, VCs another 49%, and the OpenAI foundation will control the remaining 2% of shares.

If OpenAI starts making money, the profits are distributed differently across four stages:

1. First, early investors (probably Khosla Ventures and Reid Hoffman’s foundation) get their money back with interest.
2. After that Microsoft is entitled to 75% of profits until the $13B of funding is repaid
3. When the initial funding is repaid, Microsoft and the remaining VCs each get 49% of profits. This continues until another $92B and $150B are paid out to Microsoft and the VCs, respectively.
4. Once the aforementioned money is paid to investors, 100% of shares return to the foundation, which regains total control over the company. \[3\]

# What This Means

This is absolutely crazy!

OpenAI managed to solve all of its problems at once. They raised a boatload of money and have access to all the compute they need.

On top of that, they solved their distribution problem. They now have access to Microsoft’s sales teams and their models will be integrated into MS Office products.

Microsoft also benefits heavily. They can play at the forefront AI, brush up their tools, and have OpenAI as an exclusive partner to further compete in a [bitter cloud war](https://www.projectpro.io/article/aws-vs-azure-who-is-the-big-winner-in-the-cloud-war/401) against AWS.

The synergies do not stop there.

OpenAI as well as GitHub (aubsidiary of Microsoft) e. g. will likely benefit heavily from the partnership as they continue to develop[ GitHub Copilot](https://github.com/features/copilot).

The deal creates a beautiful win-win situation, but that is not even the best part.

Sam Altman and his team at OpenAI essentially managed to place a giant hedge. If OpenAI does not manage to create anything meaningful or we enter a new AI winter, Microsoft will have paid for the party.

However, if OpenAI creates something in the direction of AGI — whatever that looks like — the value of it will likely be huge.

In that case, OpenAI will quickly repay the dept to Microsoft and the foundation will control 100% of whatever was created.

*Wow!*

Whether you agree with the path OpenAI has chosen or would have preferred them to stay donation-based, you have to give it to them.

*This deal is an absolute power move!*

I look forward to the future. Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

*Thank you for reading!*

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] [https://golden.com/wiki/Sam\_Altman-J5GKK5](https://golden.com/wiki/Sam_Altman-J5GKK5)​

\[2\] [https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny](https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny)​

\[3\] [Article in Fortune magazine ](https://fortune.com/2023/01/11/structure-openai-investment-microsoft/?verification_code=DOVCVS8LIFQZOB&_ptid=%7Bkpdx%7DAAAA13NXUgHygQoKY2ZRajJmTTN6ahIQbGQ2NWZsMnMyd3loeGtvehoMRVhGQlkxN1QzMFZDIiUxODA3cnJvMGMwLTAwMDAzMWVsMzhrZzIxc2M4YjB0bmZ0Zmc0KhhzaG93T2ZmZXJXRDFSRzY0WjdXRTkxMDkwAToMT1RVVzUzRkE5UlA2Qg1PVFZLVlpGUkVaTVlNUhJ2LYIA8DIzZW55eGJhajZsWiYyYTAxOmMyMzo2NDE4OjkxMDA6NjBiYjo1NWYyOmUyMTU6NjMyZmIDZG1jaOPAtZ4GcBl4DA)​

\[4\] [https://arxiv.org/abs/2104.04473](https://arxiv.org/abs/2104.04473) Megatron NLG

\[5\] [https://www.crunchbase.com/organization/openai/company\_financials](https://www.crunchbase.com/organization/openai/company_financials)​

\[6\] Elon Musk donation [https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research](https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research)​

\[7\] [https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/](https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/)"
2,deeplearning,gpt-3,top,2020-08-17 19:53:20,Personal GPT-3 project 🚀: Guess the movie! You can't recall the name of that movie you watched? You know what the movie's about but you just can't remember its name? I used the GPT-3 model to solve this problem! Just feed it a small description of the movie/tv show and it will do the rest.,CallmeMehdi25,False,0.96,115,iblhzl,https://i.redd.it/z12t847vamh51.gif,29,1597694000.0,
3,deeplearning,gpt-3,top,2023-01-19 07:55:49,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.9,71,10fw22o,https://www.reddit.com/r/deeplearning/comments/10fw22o/gpt4_will_be_500x_smaller_than_people_think_here/,11,1674114949.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/xvpw1erngyca1.png?width=575&format=png&auto=webp&s=d7bea7c6132081f2df7c950a0989f398599d6cae)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you. At **TheDecoding** ⭕, I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
4,deeplearning,gpt-3,top,2023-06-05 04:33:14,How Open Ai’s Andrej Karpathy Made One of the Best Tutorials in Deep Learning,0ssamaak0,False,0.91,58,141282u,https://www.reddit.com/r/deeplearning/comments/141282u/how_open_ais_andrej_karpathy_made_one_of_the_best/,3,1685939594.0,"I want you to check [my review](https://medium.com/@0ssamaak0/how-open-ais-andrej-karpathy-made-one-of-the-best-tutorials-in-deep-learning-e6b6445a2d05) on Andrej Karpathy amazing work on explaining how GPT is built

[GitHub Repo](https://github.com/0ssamaak0/Karpathy-Neural-Networks-Zero-to-Hero) for code & more details

&#x200B;

https://preview.redd.it/z204zwtzn44b1.png?width=720&format=png&auto=webp&s=095ea00991ebb295f48b70436456b1f283a50df1"
5,deeplearning,gpt-3,top,2021-07-15 17:06:55,"EleutherAI Researchers Open-Source GPT-J, A Six-Billion Parameter Natural Language Processing (NLP) AI Model Based On GPT-3",techsucker,False,0.99,57,okx5hm,https://www.reddit.com/r/deeplearning/comments/okx5hm/eleutherai_researchers_opensource_gptj_a/,5,1626368815.0,"[GPT-J](https://www.eleuther.ai/), a six-billion-parameter natural language processing (NLP) AI model based on GPT-3, has been open-sourced by a team of EleutherAI researchers. The model was trained on an open-source text [dataset of 800GB](https://pile.eleuther.ai/) and was comparable with a GPT-3 model of similar size.

The model was trained using Google Cloud’s v3-256 TPUs using EleutherAI’s Pile dataset, which took about five weeks. GPT-J achieves accuracy similar to OpenAI’s reported findings for their 6.7B parameter version of GPT-3 on standard NLP benchmark workloads. The model code, pre-trained weight files, a Colab notebook, and a sample web page are included in EleutherAI’s release.

Story: [https://www.marktechpost.com/2021/07/15/eleutherai-researchers-open-source-gpt-j-a-six-billion-parameter-natural-language-processing-nlp-ai-model-based-on-gpt-3/](https://www.marktechpost.com/2021/07/15/eleutherai-researchers-open-source-gpt-j-a-six-billion-parameter-natural-language-processing-nlp-ai-model-based-on-gpt-3/) 

Github repository for GPT-J: https://github.com/kingoflolz/mesh-transformer-jax

Colab Notebook: https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab\_demo.ipynb

Web Demo: https://6b.eleuther.ai/"
6,deeplearning,gpt-3,top,2021-04-26 16:38:23,[R] Google and UC Berkeley Propose Green Strategies for Large Neural Network Training,Yuqing7,False,0.97,58,mz1v2c,https://www.reddit.com/r/deeplearning/comments/mz1v2c/r_google_and_uc_berkeley_propose_green_strategies/,1,1619455103.0,"A research team from Google and the University of California, Berkeley calculates the energy use and carbon footprint of large-scale models T5, Meena, GShard, Switch Transformer and GPT-3, and identifies methods and publication guidelines that could help reduce their CO2e footprint.

Here is a quick read: [Google and UC Berkeley Propose Green Strategies for Large Neural Network Training](https://syncedreview.com/2021/04/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-5/).

The paper *Carbon Emissions and Large Neural Network Training* is on [arXiv](https://arxiv.org/ftp/arxiv/papers/2104/2104.10350.pdf)."
7,deeplearning,gpt-3,top,2020-07-28 12:31:26,GPT-3 writes my SQL queries for me,Independent-Square32,False,0.86,52,hzdthe,https://youtu.be/WlMHYEFt2uA,5,1595939486.0,
8,deeplearning,gpt-3,top,2023-03-25 04:24:49,Do we really need 100B+ parameters in a large language model?,Vegetable-Skill-9700,False,0.93,47,121agx4,https://www.reddit.com/r/deeplearning/comments/121agx4/do_we_really_need_100b_parameters_in_a_large/,54,1679718289.0,"DataBricks's open-source LLM, [Dolly](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html) performs reasonably well on many instruction-based tasks while being \~25x smaller than GPT-3, challenging the notion that is big always better?

From my personal experience, the quality of the model depends a lot on the fine-tuning data as opposed to just the sheer size. If you choose your retraining data correctly, you can fine-tune your smaller model to perform better than the state-of-the-art GPT-X. The future of LLMs might look more open-source than imagined 3 months back?

Would love to hear everyone's opinions on how they see the future of LLMs evolving? Will it be few players (OpenAI) cracking the AGI and conquering the whole world or a lot of smaller open-source models which ML engineers fine-tune for their use-cases?

P.S. I am kinda betting on the latter and building [UpTrain](https://github.com/uptrain-ai/uptrain), an open-source project which helps you collect that high quality fine-tuning dataset"
9,deeplearning,gpt-3,top,2020-09-18 10:45:02,GPT-3: new AI can write like a human but don't mistake that for thinking – neuroscientist,PowerOfLove1985,False,0.82,38,iv3rnz,https://theconversation.com/gpt-3-new-ai-can-write-like-a-human-but-dont-mistake-that-for-thinking-neuroscientist-146082,14,1600425902.0,
10,deeplearning,gpt-3,top,2022-12-02 20:59:47,Everyone: AI will make it easy to spread misinformation; Me: Stop hitting yourself GPT3!,hayAbhay,False,0.91,39,zaxg5m,https://i.redd.it/mrf9rz0ltj3a1.png,0,1670014787.0,
11,deeplearning,gpt-3,top,2023-02-11 06:59:00,⭕ New Open-Source Version Of ChatGPT,LesleyFair,False,0.88,39,10zepkt,https://www.reddit.com/r/deeplearning/comments/10zepkt/new_opensource_version_of_chatgpt/,3,1676098740.0,"GPT is getting competition from open-source.

A group of researchers, around the YouTuber [Yannic Kilcher](https://www.ykilcher.com/), have announced that they are working on [Open Assistant](https://github.com/LAION-AI/Open-Assistant). The goal is to produce a chat-based language model that is much smaller than GPT-3 while maintaining similar performance.

If you want to support them, they are crowd-sourcing training data [here](https://open-assistant.io/).

**What Does This Mean?**

Current language models are too big.

They require millions of dollars of hardware to train and use. Hence, access to this technology is limited to big organizations. Smaller firms and universities are effectively shut out from the developments.

Shrinking and open-sourcing models will facilitate academic research and niche applications.

Projects such as Open Assistant will help to make language models a commodity. Lowering the barrier to entry will increase access and accelerate innovation.

What an exciting time to be alive! 

Thank you for reading! I really enjoyed making this for you!  
The Decoding ⭕ is a thoughtful weekly 5-minute email that keeps you in the loop about machine research and the data economy. [Click here to sign up](https://thedecoding.net/)!"
12,deeplearning,gpt-3,top,2021-06-14 06:34:33,"This Chinese Super Scale Intelligence Model, ‘Wu Dao 2.0’, Claims To Be Trained Using 1.75 Trillion Parameters, Surpassing All Prior Models to Achieve a New Breakthrough in Deep Learning",ai-lover,False,0.88,34,nzgkj3,https://www.reddit.com/r/deeplearning/comments/nzgkj3/this_chinese_super_scale_intelligence_model_wu/,9,1623652473.0,"Deep learning is one area of technology where ambitiousness has no barriers. According to a recent announcement by [The Beijing Academy of Artificial Intelligence (BAAI)](https://www.baai.ac.cn/), in China, yet another milestone has been achieved in the field with its “Wu Dao” AI system. The [GPT 3](https://www.marktechpost.com/2020/08/02/gpt-3-a-new-breakthrough-in-language-generator/) brought in new interest for all the AI researchers, the super scale pre training models. By this approach and making use of 175 billion parameters, it managed to achieve exceptional performance results across the natural language processing tasks (NLP). However, the lacking component is its inability to have any form of cognitive abilities or common sense. Therefore, despite the size, even these models cannot indulge in tasks such as open dialogues, visual reasoning, and so on. With Wu Dao, the researchers plan to address this issue. This is China’s first attempt at a home-grown super-scale intelligent model system. 

Article: [https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/](https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/?_ga=2.13897584.636390090.1623335762-488125022.1618729090)

Reference: [https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/](https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/)"
13,deeplearning,gpt-3,top,2022-11-03 23:55:15,BlogNLP: AI Writing Tool,britdev,False,1.0,37,ylj1ux,https://www.reddit.com/r/deeplearning/comments/ylj1ux/blognlp_ai_writing_tool/,9,1667519715.0,"Hey everyone,

I created this web app using Open AI's GPT-3 (Davinci model). The purpose here is to provide a free tool to allow people to generate blog content/outlines/headlines and help with writer's block. Will continue to improve it over time, but just a side project I figured would provide some value to you all. Hope you all enjoy and please share ❤️

[https://www.blognlp.com/](https://www.blognlp.com/)"
14,deeplearning,gpt-3,top,2022-03-12 04:56:16,Microsoft’s Latest Machine Learning Research Introduces μTransfer: A New Technique That Can Tune The 6.7 Billion Parameter GPT-3 Model Using Only 7% Of The Pretraining Compute,No_Coffee_4638,False,1.0,33,tc8u6k,https://www.reddit.com/r/deeplearning/comments/tc8u6k/microsofts_latest_machine_learning_research/,0,1647060976.0,"Scientists conduct trial and error procedures which experimenting, that many times lear to freat scientific breakthroughs. Similarly, foundational research provides for developing large-scale AI systems theoretical insights that reduce the amount of trial and error required and can be very cost-effective.

Microsoft team tunes massive neural networks that are too expensive to train several times. For this, they employed a specific parameterization that maintains appropriate hyperparameters across varied model sizes. The used µ-Parametrization (or µP, pronounced “myu-P”) is a unique way to learn all features in the infinite-width limit. The researchers collaborated with the OpenAI team to test the method’s practical benefit on various realistic cases.

Studies have shown that training large neural networks because their behavior changes as they grow in size are uncertain. Many works suggest heuristics that attempt to maintain consistency in the activation scales at initialization. However, as training progresses, this uniformity breaks off at various model widths.

[**CONTINUE READING MY SUMMARY ON THIS RESEARCH**](https://www.marktechpost.com/2022/03/11/microsofts-latest-machine-learning-research-introduces-%ce%bctransfer-a-new-technique-that-can-tune-the-6-7-billion-parameter-gpt-3-model-using-only-7-of-the-pretraining-compute/)

Paper: https://www.microsoft.com/en-us/research/uploads/prod/2021/11/TP5.pdf

Github:https://github.com/microsoft/mup

https://i.redd.it/7jrt9r3awvm81.gif"
15,deeplearning,gpt-3,top,2021-05-02 16:45:08,GPT-1 - Annotated Paper + Paper Summary,shreyansh26,False,0.96,26,n3aeh5,https://www.reddit.com/r/deeplearning/comments/n3aeh5/gpt1_annotated_paper_paper_summary/,2,1619973908.0," GPT-2 and recently, GPT-3 created a lot of hype when they were launched. However, it all started with the ""Improving Language Understanding by Generative Pre-Training"" paper which introduced the idea of GPT-1.

As a part of my Paper Notes series, I have gone through the paper and created a brief yet informative summary of the paper. It will take just take a few minutes to understand GPT-1 well. Check out the links below and happy reading!

Paper Summary - [Improving Language Understanding by Generative Pre-Training](https://shreyansh26.github.io/post/2021-05-02_language_understanding_generative_pretraining/)

Annotated Paper - [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf)"
16,deeplearning,gpt-3,top,2023-03-05 11:10:56,LLaMA model parallelization and server configuration,ChristmasInOct,False,1.0,25,11ium8l,https://www.reddit.com/r/deeplearning/comments/11ium8l/llama_model_parallelization_and_server/,8,1678014656.0,"Hey everyone,

First of all, tldr at bottom, typed more than expected here.  

Please excuse the rather naive perspective I have here.  I've followed along with great interest, but this is not my industry.

Regardless, I have spent the past 3-4 days falling down a brutally obsessive rabbit hole, and I cannot seem to find this information.  I'm assuming it's just that I am missing context of course, and regardless of whether there is a clear answer, I'm trying to get a better understanding of this topic so that I could better appraise the situation myself.

Really I suppose I have two questions.  **The first** is regarding model parallelization.

I'm assuming this is not generic whatsoever.  What is the typical process engineers go about for designing such a pipeline?  Specifically in regards to these new LLaMA models, is something like ALPA relevant?  Deepspeed?

More importantly, what information should I be seeking to determine this myself?

This roughly segues to my **second inquiry**.

The reason I'm curious about splitting the model pipeline etc., is that I am potentially in interested in standing a server up for this.  Although I don't have much of a budget for this build (\~$30-40K is the rough top-end, but I'd be a lot happier around $20-25K), the money is there if I can genuinely satisfy my use-case.

I work at a small, but borderline manic startup working on enterprise software; 90% of the work we're doing based in the react/node ecosystem, some low-level work for backend services, and some very interesting database work that I have very little to do with.  I am a fullstack engineer that grew up playing with C++ => C#, and somehow ended up spending all of my time r/w'ing javascript.  Lol.  Anyways.

Part of our roadmap since GPT-3 and the playground were made publicly accessible, involves usage of these transformer models, and their ability to interpret natural language inputs, whether from user inputs, or scraped input values generated somewhere in a chain of requests / operations.

Seeing GPT-3 in action made me specifically realize that my estimations on this technology had been wildly off.  Seeing ChatGPT in action and uptick, the API's becoming available, has me further panicked.

Running our inference through their API has never really been an option for us.  I haven't even really looked that far into it, but bottom line the data running through our platform is all back-office, highly sensitive business information, and many have agreements explicitly restricting the movement of data to or from any cloud services, with Microsoft, Amazon, and Google all specifically mentioned.

Regardless of the reasoning for these contracts, the LLaMA release has had me obsessed over this topic in more detail than before, and whether or not I would be able to get this setup privately, for our use-case.

**To get to the actual second inquiry**:

Say I want to throw a budget rig together for this in a server cabinet.  Am I able to effectively parallelize the LLaMA model, well enough to justify going with 24GB VRAM 4090's in the rig?  Say I do so with DeepSpeed, or some of the standard model parallelization libraries.

Is the performance cost low enough to justify taking the extra compute here over 1/3 - 1/2 as many RTX6000 ADA's?

Or should I be grabbing the 48GB ADA's?

Like I said, I apologize for the naivety, I'm really looking for more information so that I can start to put this picture together better on my own.  It really isn't the easiest topic to research with how quickly things seem to move, and the giant gap between conversation depths (gamer || phd in a lot of the most interesting or niche discussions, little between).

Thank you very much for your time.

TL;DR - Any information on LLaMA model parallelization at the moment?  Will it be compatible with things like zero or alpa?  How about for throwing a rig together right now for fine-tuning and then running inference on the LLaMA models?  48GB 6000 ADA's, or 24GB 4090's?

Planning on putting it in a mostly empty 42U cabinet that also houses our primary web server and networking hardware, so if there is a sales pitch for 4090's across multiple nodes here, I do have a massive bias as the kind of nerd that finds that kind of hardware borderline erotic.

Hydro and cooling are not an issue, just usage of the budget and understanding the requirements / approach given memory limitations, and how to avoid communication bottlenecks or even balance them against raw compute.

Thanks again everyone!"
17,deeplearning,gpt-3,top,2022-12-03 00:17:31,A GPT-3 based Chrome Extension that debugs your code!,VideoTo,False,1.0,22,zb2kkc,https://www.reddit.com/r/deeplearning/comments/zb2kkc/a_gpt3_based_chrome_extension_that_debugs_your/,0,1670026651.0,"Link - [https://chrome.google.com/webstore/detail/clerkie-ai/oenpmifpfnikheaolfpabffojfjakfnn](https://chrome.google.com/webstore/detail/clerkie-ai/oenpmifpfnikheaolfpabffojfjakfnn)

Built  a quick tool I thought would be interesting - it’s a chrome extension  that uses GPT-3 under the hood to help debug your programming errors  when you paste them into Google (“eg. TypeError:…”).

This is definitely early days, so **if   this is something you would find valuable and wouldn't mind testing a   couple iterations of, please feel free to join the discord** \-> [https://discord.gg/KvG3azf39U](https://discord.gg/KvG3azf39U)

&#x200B;

https://i.redd.it/tt6hcqn2tk3a1.gif"
18,deeplearning,gpt-3,top,2023-01-22 19:11:36,Apple M2 Max 96 GB unified memory for larger models vs multiple 24GB GPUs or 40GB A100s?,lol-its-funny,False,0.96,20,10irh5u,https://www.reddit.com/r/deeplearning/comments/10irh5u/apple_m2_max_96_gb_unified_memory_for_larger/,14,1674414696.0,"How feasible is it to use an Apple Silicon M2 Max, which has about [96 GB unified memory](https://www.apple.com/shop/buy-mac/macbook-pro/16-inch-space-gray-apple-m2-max-with-12-core-cpu-and-38-core-gpu-1tb) for ""large model"" deep learning? I'm inspired by the the [Chinchilla](https://arxiv.org/abs/2203.15556) paper that shows a lot of promise at 70B parameters. Outperforming ultra large models like Gopher (280B) or GPT-3 (175B) there is hope for working with < 70B parameters without needing a super computer. At least for fine tuning. I've been working with GPT-J but want to scale/tinker with larger open-sourced models.

However, I don't know how clearly the CompSci theory (M2 Max's 38-core GPU, 16 core Neural Engine accessing 96 GB unified memory) maps out to the IT reality (toolkits and libraries on macOS actually using it). My exposure is mostly around Jupyter books on Colab Pro+ (A100s) and nvidia 3080 GPUs (locally). 

I appreciate your guidance."
19,deeplearning,gpt-3,top,2020-09-16 16:02:55,"Practical Natural Language Processing Book [Interview + Giveaway] | NLP, ML & AI in the Industry | GPT-3 and more",mukulkhanna1,False,0.82,20,ityg5g,https://youtu.be/ptTlH-ma8rg,0,1600272175.0,
20,deeplearning,gpt-3,top,2023-02-05 16:44:56,Beat GPT-3 which has unlimited money using Open Source community,koyo4ever,False,0.78,21,10ugxmc,https://www.reddit.com/r/deeplearning/comments/10ugxmc/beat_gpt3_which_has_unlimited_money_using_open/,8,1675615496.0,"Is it technically possible to train some model using a lot of personal computers like a cluster.

Eg: an Algorithm to train tiny parts of some model using personal computer of volunteers. Like a community that makes your gpu capacity available, even if it's little.

The idea is train tiny parts of a model, with a lot of volunteers, then bring it together to make some powerful deepmind.

Can this model beat a lot of money spent in models like GPT-3?"
21,deeplearning,gpt-3,top,2023-09-29 14:02:33,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.91,18,16vch0x,https://www.reddit.com/r/deeplearning/comments/16vch0x/this_week_in_ai_all_the_major_ai_developments_in/,2,1695996153.0,"1. **Meta AI** presents **Emu**, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal.
2. **Meta AI** researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks.
3. **Abacus AI** released a larger 70B version of **Giraffe**. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens\].
4. **Cerebras** and **Opentensor** released Bittensor Language Model, ‘**BTLM-3B-8K**’, a new 3 billion parameter open-source language model with an 8k context length trained on 627B tokens of SlimPajama. It outperforms models trained on hundreds of billions more tokens and achieves comparable performance to open 7B parameter models. The model needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models and is available with an Apache 2.0 license for commercial use.
5. **OpenAI** is rolling out, over the next two weeks, new voice and image capabilities in ChatGPT enabling ChatGPT to understand images, understand speech and speak. The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. .
6. **Mistral AI**, a French startup, released its first 7B-parameter model, **Mistral 7B**, which outperforms all currently available open models up to 13B parameters on all standard English and code benchmarks. Mistral 7B is released in Apache 2.0, making it usable without restrictions anywhere.
7. **Microsoft** has released **AutoGen** \- an open-source framework that enables development of LLM applications using multiple agents that can converse with each other to solve a task. Agents can operate in various modes that employ combinations of LLMs, human inputs and tools.
8. **LAION** released **LeoLM**, the first open and commercially available German foundation language model built on Llama-2
9. Researchers from **Google** and **Cornell University** present and release code for DynIBaR (Neural Dynamic Image-Based Rendering) - a novel approach that generates photorealistic renderings from complex, dynamic videos taken with mobile device cameras, overcoming fundamental limitations of prior methods and enabling new video effects.
10. **Cloudflare** launched **Workers AI** (an AI inference as a service platform), **Vectorize** (a vector Database) and **AI Gateway** with tools to cache, rate limit and observe AI deployments. Llama2 is available on Workers AI.
11. **Amazon** announced the general availability of **Bedrock**, its service that offers a choice of generative AI models from Amazon itself and third-party partners through an API.
12. **Spotify** has launched a pilot program for AI-powered voice translations of podcasts in other languages - in the podcaster’s voic. It uses OpenAI’s newly released voice generation model.
13. **Getty Images** has launched a generative AI image tool, ‘**Generative AI by Getty Images**’, that is ‘commercially‑safe’. It’s powered by Nvidia Picasso, a custom model trained exclusively using Getty’s images library.
14. **Optimus**, Tesla’s humanoid robot, can now sort objects autonomously and do yoga. Its neural network is trained fully end-to-end.
15. **Amazon** will invest up to $4 billion in Anthropic. Developers and engineers will be able to build on top of Anthropic’s models via Amazon Bedrock.
16. **Google Search** indexed shared Bard conversational links into its search results pages. Google says it is working on a fix.

&#x200B;

  
My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
22,deeplearning,gpt-3,top,2023-02-02 23:02:25,Why are FPGAs better than GPUs for deep learning?,Open-Dragonfly6825,False,0.92,16,10s3u1s,https://www.reddit.com/r/deeplearning/comments/10s3u1s/why_are_fpgas_better_than_gpus_for_deep_learning/,37,1675378945.0,"I've worked for some years developing scientific applications for GPUs. Recently we've been trying to integrate FPGAs into our technologies; and consequently I've been trying to understand what they are useful for.

I've found many posts here and there that claim that FPGAs are better suited than GPUs to accelerate Deep Learning/AI workloads (for example, [this one by Intel](https://www.intel.com/content/www/us/en/artificial-intelligence/programmable/fpga-gpu.html)). However, I don't understand why that would be the case. I think the problem is that all those posts try to explain what an FPGA is and what its differences are to a GPU, so that people that work on Deep Learning understand why they are better suited. Nevertheless, my position is exactly the opposite: I know quite well how a GPU works and what it is good for, I know well enough how an FPGA works and how it differs from a GPU, **but I do not know enough about Deep Learning** to understand why Deep Learning applicatios would benefit more from the special features of FPGAs rather than from the immense parallelism GPUs offers.

As far as I know, an FPGA will never beat a traditional GPU in terms of raw parallelism (or, if it does, it would be much less cost efficient). Thus, when it comes to matrix multiplications, i.e. the main operation in Deep Learning models, or convolutions, GPUs can parallelly work with much bigger matrices. The only explanation I can think of is that traditional Deep Learning applications don't necessarily use such big matrices, but rather smaller ones that can also be fully parallelized in FPGAs and benefit highly from custom-hardware optimizations (optimized matrix multiplications/tensor operations, working with reduced-bit values such as FP16, deep-pipeline parallelism, ...). However, given the recent increase in popularity of very complex models (GPT-3, dall-e, and the like) which boast using millions or even billions of parameters, it is hard to imagine that popular deep learning models work with small matrices of which fully parallel architectures can be synthesized in FPGAs.

What am I missing? Any insight will be greatly appreciated.

EDIT: I know TPUs are a thing and are regarded as ""the best option"" for deep learning acceleration. I will not be working with them, however, so I am not interested in knowing the details on how they compare with GPUs or FPGAs."
23,deeplearning,gpt-3,top,2023-01-28 06:34:28,"A python module to generate optimized prompts, Prompt-engineering & solve different NLP problems using GPT-n (GPT-3, ChatGPT) based models and return structured python object for easy parsing",StoicBatman,False,1.0,18,10n8c80,https://www.reddit.com/r/deeplearning/comments/10n8c80/a_python_module_to_generate_optimized_prompts/,0,1674887668.0,"Hi folks,

I was working on a personal experimental project related to GPT-3, which I thought of making it open source now. It saves much time while working with LLMs.

If you are an industrial researcher or application developer, you probably have worked with GPT-3 apis. A common challenge when utilizing LLMs such as #GPT-3 and BLOOM is their tendency to produce uncontrollable & unstructured outputs, making it difficult to use them for various NLP tasks and applications.

To address this, we developed **Promptify**, a library that allows for the use of LLMs to solve NLP problems, including Named Entity Recognition, Binary Classification, Multi-Label Classification, and Question-Answering and return a python object for easy parsing to construct additional applications on top of GPT-n based models.

Features 🚀

* 🧙‍♀️ NLP Tasks (NER, Binary Text Classification, Multi-Label Classification etc.) in 2 lines of code with no training data required
* 🔨 Easily add one-shot, two-shot, or few-shot examples to the prompt
* ✌ Output is always provided as a Python object (e.g. list, dictionary) for easy parsing and filtering
* 💥 Custom examples and samples can be easily added to the prompt
* 💰 Optimized prompts to reduce OpenAI token costs

&#x200B;

* GITHUB: [https://github.com/promptslab/Promptify](https://github.com/promptslab/Promptify)
* Examples: [https://github.com/promptslab/Promptify/tree/main/examples](https://github.com/promptslab/Promptify/tree/main/examples)
* For quick demo -> [Colab](https://colab.research.google.com/drive/16DUUV72oQPxaZdGMH9xH1WbHYu6Jqk9Q?usp=sharing)

Try out and share your feedback. Thanks :)

Join our discord for Prompt-Engineering, LLMs and other latest research discussions  
[discord.gg/m88xfYMbK6](https://discord.gg/m88xfYMbK6)

[NER Example](https://preview.redd.it/sjvhtd8b3nea1.png?width=1236&format=png&auto=webp&s=e9a3a28f41f59cd25fe8e95bd1fca56b15f27a6e)

&#x200B;

https://preview.redd.it/fnb05bys3nea1.png?width=1398&format=png&auto=webp&s=096f4e2cbd0a71e795f30cc5e3720316b5e5caf6"
24,deeplearning,gpt-3,top,2023-03-13 12:50:10,Learning logical relationships with neural networks with differential ILP,Neurosymbolic,False,1.0,14,11q8tir,https://www.reddit.com/r/deeplearning/comments/11q8tir/learning_logical_relationships_with_neural/,3,1678711810.0,"Since last week’s post on my lab’s software package [PyReason](https://neurosymoblic.asu.edu/pyreason/), I got a lot of questions on if it would be possible for a neural network to learn logical relationships from data. After all, ChatGPT seems to be able to generate Python code, and Meta released a NeurIPS paper to show you can learn math equations from data using a transformer-based model, so why not logic? In this article, we will one line of research in this area – differential ILP.

The research in this area really kicked off with a 2018 [paper from DeepMind](https://www.reddit.com/r/deeplearning/jair.org/index.php/jair/article/view/11172) where Richard Evans and Edward Grefenstette showed that you could adapt techniques from “inductive logic programming” to use gradient descent, and learn logical rules from data. Previous (non-neural) work on inductive logic programming was generally not designed to work with noisy data and instead fit the historical examples in a precise manner. Evans and Grefenstette utilized a neural architecture and a loss function – and they showed they could handle noisy data and even do some level of integration with CNN’s. Their neural architecture mimicked a set of candidate logical rules – and the rules assigned higher weights by gradient descent would be thought to best fit the data. However, a downside to this approach is that the neural network was [quintic in the size of the input](https://www.youtube.com/watch?v=SOnAE0EyX8c&list=PLpqh-PUKX-i7URwnkTqpAkSchJHvbxZHB&index=5). This is why they only applied their approach on very small problems – it did not see very wide adoption.

That said, in the last two years, there have been some notable follow-ons to this work. Researchers out of Kyoto University and NTT introduced a manner to learn rules that are more expressive in a different manner by allowing function symbols in the logical language ([Shindo et al., AAAI 2021](https://ojs.aaai.org/index.php/AAAI/article/view/16637/16444)). They leverage a clause search and refinement process to limit the number of candidate rules – hence limiting the size of the neural network. A student team from ASU created a presentation on their work for our recent seminar course on neuro symbolic AI. We released a three part video series from their talk:

[Part 1: Review of differentiable inductive logic programming](https://www.youtube.com/watch?v=JIS78a40q8U&t=270s)

[Part 2: Clause search and refinement In our recent video series](https://www.youtube.com/watch?v=nzfbxlHUwuE&t=345s)

[Part 3: Experiments](https://www.youtube.com/watch?v=-fKWNtHUIN0&t=27s)

[Slides](https://labs.engineering.asu.edu/labv2/wp-content/uploads/sites/82/2022/10/Shindo_dILP.pdf)

Some think that the ability to learn such relationships will represent a significant advancement in ML, specifically addressing shortcomings in areas such as knowledge graph completion and reasoning about scene graphs. However, the gap still remains wide, and ILP techniques, including differentiable ILP still have a ways to go. Really interested in what your thoughts are, feel free to comment below."
25,deeplearning,gpt-3,top,2022-12-23 14:35:17,How to change career trajectory to NLP engineer,Creative-Milk-8266,False,0.84,12,zth8rl,https://www.reddit.com/r/deeplearning/comments/zth8rl/how_to_change_career_trajectory_to_nlp_engineer/,3,1671806117.0," A little of my background - 5 years experience in data science. Mostly related to prototyping statistical models and optimization problems, bringing them into production. Some experience in building pipeline and orchestration flow with AWS services.

I have basic understanding on Transformers, BERT, GPT. Did my first NLP Kaggle competition the first time recently.

I'd like my next job to be a NLP engineer. How should I prepare myself for it?

Here's some of the items I'm thinking

&#x200B;

1. More hands on projects I can put on resume, including integration with cloud services. Any recommendations on what kinds of projects I should pick?  
 
2. Tryout techniques of speeding up models like distilled model, dynamic shape, quantization. Anything else that would be helpful?  
 
3. Understand lower level of GPU programming knowledges. Not sure if this is helpful for me finding a NLP job. If so, what kind of things I can do to go deeper on this subject. I'm currently taking [Intro to Parallel Programming](https://classroom.udacity.com/courses/cs344) CS344 course on Udemy (highly recommend btw).  
 
4. Grind leetcode :/  
 

Please point out other important directions I missed."
26,deeplearning,gpt-3,top,2022-12-03 19:29:01,BlogNLP: AI Blog Writing Tool,britdev,False,0.83,11,zboc8w,https://www.reddit.com/r/deeplearning/comments/zboc8w/blognlp_ai_blog_writing_tool/,7,1670095741.0,"Hey everyone,

I developed this web app with Open AI's GPT-3 to provide a free, helpful resource for generating blog content, outlines, and more - so you can beat writer's block! I'm sure you'll find it useful and I'd really appreciate it if you shared it with others ❤️.

[https://www.blognlp.com/](https://www.blognlp.com/)"
27,deeplearning,gpt-3,top,2021-07-28 14:19:34,AI Email Generator Web App with GPT-3,thelazyaz,False,0.99,12,otaun5,https://www.youtube.com/watch?v=oJWBQKrF4uM&feature=youtu.be,1,1627481974.0,
28,deeplearning,gpt-3,top,2023-04-02 12:37:38,[N] Software 3.0 Blog Post Release 🔥,DragonLord9,False,0.76,11,129k24i,https://www.reddit.com/r/deeplearning/comments/129k24i/n_software_30_blog_post_release/,3,1680439058.0,"Hi all, excited to share my blog post on [**Software 3.0**](https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm_campaign=post&utm_medium=web)

https://preview.redd.it/9b4hjkkhugra1.png?width=1500&format=png&auto=webp&s=e341f3ab4c3c8abb206df8daa17428a297ff61e2

The blog post offers an insightful read on the new GPT-powered programming paradigm where the new programming language is simply ""*English*"", as well as recent developments in AI.

The post was originally written before GPT-4 release, and the predictions seem to have held surprisingly well. Knowledge cutoff date 28 Feb 2023.

Please read and share!! Happy to answer any follow-ups here or on DM 😊

Tweet: [https://twitter.com/DivGarg9/status/1642229948185280521?s=20](https://twitter.com/DivGarg9/status/1642229948185280521?s=20)

Blog: [https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm\_campaign=post&utm\_medium=web](https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm_campaign=post&utm_medium=web)"
29,deeplearning,gpt-3,top,2023-10-26 17:59:49,Long text summarization tool how-to (700+ pages),Old_Swan8945,False,0.84,8,17h2fbk,https://www.reddit.com/r/deeplearning/comments/17h2fbk/long_text_summarization_tool_howto_700_pages/,8,1698343189.0,"Hey all I've seen a bunch of posts about summarization of long texts and seems like there's been a lot of challenges, so wanted to spread some knowledge out there about some things I've discovered as I launched my tool here ([summarize-article.co](https://summarize-article.co)) (longest text was a psych book from one of my users at 700+ pages).

The most basic problem in the summarization process is the GPT context window length, so the basic strategy I follow is the following:

1. Chunk the text into chunks that fit inside the context window
2. Recursively summarize the summaries until it becomes manageable
3. Use a long context-window model to generate the final summary using a prompt that takes the recursively-generated summaries and re-restructures the output
4. Additional prompt magic to optimize the outputs (DM me for more details :D)

Anyway, would appreciate any feedback on the results or anything you think could be improved, otherwise feel free to check it out or msg me if you want to learn more about how it works!"
30,deeplearning,gpt-3,top,2021-09-30 14:07:00,New to NLP (but not machine learning) - questions about Huggingface and NLP model development with additional text/non-text features,jsxgd,False,0.92,10,pykia3,https://www.reddit.com/r/deeplearning/comments/pykia3/new_to_nlp_but_not_machine_learning_questions/,4,1633010820.0,"Hi everyone,

&#x200B;

My work is almost always focused on structured, tabular data. Recently, though, I have been working on some tasks that are more centered on NLP for personal enrichment. I've generally been understanding well how some of the model architectures work like BERT or GPT. And I understand the difference between common NLP tasks like fill-mask and text generation. I've learned a lot from the Huggingface docs.

&#x200B;

I have two questions that are more about actually engineering something with these models:

1) I can see in Huggingface that models are marked for a specific task, like fill-mask. However, in tutorials I find, I can see that these models are being used for other tasks with seemingly good performance. For example, I found a tutorial that uses \`distilbert-base-multilingual-cased\` for a novel text classification model (classifying article text as one of several news categories). But in Huggingface, this model is labeled as a fill-mask model. What gives? Is it mislabeled? Or can I use any model for any task, just with varying degrees of success?

&#x200B;

2) I'm having a hard time finding any tutorials that mix text data with additional features which may ALSO be text or just numeric/categorical. For example, if my task is classifying a sent email as ""opened"" or ""not opened"", my main feature might be the email subject text. I might also (optionally) have a pre-header text, which in some email clients appears right below the subject. Then, I also have some additional potential features like the date the email was sent, the domain of the recipient email, etc. These features may also have a variable relationship with the text, e.g. ""Happy Christmas"" as an email subject may fare differently in December vs. January. Are there any good resources to learn how to incorporate these kinds of features into the same model?

3) More generally about deep learning (particularly if you're using tensorflow/keras) - but also with respect to the questions above - what's the best way to utilize aggregate data for classification? If I'm again looking at email data, I can of course look at this recipient-by-recipient with a 0/1 binary target field for ""opened\_email"". But this data set is huge, and in this format would be repetitive as subjects would be the same for recipients getting the same email. I can instead aggregate to a per-subject data set with two fields called ""Opens"" and ""NonOpens"" containing the counts for each type of event. Or I can do ""OpenRate"" and ""TotalRecipients"" containing the percent of recipients who opened the email and the denominator of the rate. In more classical models/packages (xgboost, GLMs, etc) it's pretty easy to make use of data in this format for binary classification. Is it similarly just as easy in a NN built with tensorflow/keras?

&#x200B;

Thanks!"
31,deeplearning,gpt-3,top,2021-12-17 16:25:47,Transformer assimilates syntax perfectly,jssmith42,False,0.91,9,ril1wx,https://www.reddit.com/r/deeplearning/comments/ril1wx/transformer_assimilates_syntax_perfectly/,4,1639758347.0,"Has anyone analysed why GPT-3 seems to master the syntax of languages nearly perfectly as opposed to not having a perfect understanding of higher-level aspects of cognition?

It could be a simple answer, that syntax is less of a complex system/pattern/structure than conceptual understanding of the world.

But I feel like there is something more interesting to be said.

For example, it seems like the bigger the model, the smarter it becomes.

Is AI as simple as, we have a structure (a neural network) that can intuitively understand any system or phenomenon because it finds some kind of model for it, a layered series of weights corresponding to some conceptual hierarchy. It just depends what order the phenomenon is. A hyper-complex phenomenon needs 100 layers, or whatever. A simple one only needs 3. In either case, there is conceivably nothing a neural network cannot eventually understand.

Is this true? If so, it’s a pretty wild notion to contemplate."
32,deeplearning,gpt-3,top,2022-06-15 16:07:22,Join us for the OpenAI GPT-3 Deep Learning Labs Hackathon!,zakrzzz,False,0.82,7,vcxzp4,https://www.reddit.com/r/deeplearning/comments/vcxzp4/join_us_for_the_openai_gpt3_deep_learning_labs/,0,1655309242.0,"We are waiting for all of you, AI enthusiasts with coding experience and without, on the 24th - 26th of June to help you turn your ground-breaking ideas into reality!

Register here - [https://lablab.ai/event/gpt3-online](https://lablab.ai/event/gpt3-online)  


https://preview.redd.it/mhr93wgo6t591.png?width=1600&format=png&auto=webp&s=07e23c79830db8061eb300f76b64588b01219ebc"
33,deeplearning,gpt-3,top,2020-06-10 20:36:33,"GPT-3: The $4,600,000 Language model",mippie_moe,False,0.8,8,h0jm54,https://lambdalabs.com/blog/demystifying-gpt-3/,4,1591821393.0,
34,deeplearning,gpt-3,top,2023-01-14 14:48:43,Scaling Language Models Shines Light On The Future Of AI ⭕,LesleyFair,False,0.71,7,10bq685,https://www.reddit.com/r/deeplearning/comments/10bq685/scaling_language_models_shines_light_on_the/,1,1673707723.0,"Last year, large language models (LLM) have broken record after record. ChatGPT got to 1 million users faster than Facebook, Spotify, and Instagram did. They helped create [billion-dollar companies](https://www.marketsgermany.com/translation-tool-deepl-is-now-a-unicorn/#:~:text=Cologne%2Dbased%20artificial%20neural%20network,sources%20close%20to%20the%20company), and most notably they helped us recognize the [divine nature of ducks](https://twitter.com/drnelk/status/1598048054724423681?t=LWzI2RdbSO0CcY9zuJ-4lQ&s=08).

2023 has started and ML progress is likely to continue at a break-neck speed. This is a great time to take a look at one of the most interesting papers from last year.

Emergent Abilities in LLMs

In a recent [paper from Google Brain](https://arxiv.org/pdf/2206.07682.pdf), Jason Wei and his colleagues allowed us a peak into the future. This beautiful research showed how scaling LLMs might allow them, among other things, to:

* Become better at math
* Understand even more subtleties of human language
* reduce hallucination and answer truthfully
* ...

(See the plot on break-out performance below for a full list)

**Some Context:**

If you played around with ChatGPT or any of the other LLMs, you will likely have been as impressed as I was. However, you have probably also seen the models go off the rails here and there. The model might hallucinate gibberish, give untrue answers, or fail at performing math.

**Why does this happen?**

LLMs are commonly trained by [maximizing the likelihood](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf) over all tokens in a body of text. Put more simply, they learn to predict the next word in a sequence of words.

Hence, if such a model learns to do any math at all, it learns it by figuring concepts present in human language (and thereby math).

Let's look at the following sentence.

""The sum of two plus two is ...""

The model figures out that the most likely missing word is ""four"".

The fact that LLMs learn this at all is mind-bending to me! However, once the math gets more complicated [LLMs begin to struggle](https://twitter.com/Richvn/status/1598714487711756288?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1598714487711756288%7Ctwgr%5E478ce47357ad71a72873d1a482af5e5ff73d228f%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fanalyticsindiamag.com%2Ffreaky-chatgpt-fails-that-caught-our-eyes%2F).

There are many other cases where the models fail to capture the elaborate interactions and meanings behind words. One other example is words that change their meaning with context. When the model encounters the word ""bed"", it needs to figure out from the context, if the text is talking about a ""river bed"" or a ""bed"" to sleep in.

**What they discovered:**

For smaller models, the performance on the challenging tasks outline above remains approximately random. However, the performance shoots up once a certain number of training FLOPs (a proxy for model size) is reached.

The figure below visualizes this effect on eight benchmarks. The critical number of training FLOPs is around 10\^23. The big version of GPT-3 already lies to the right of this point, but we seem to be at the beginning stages of performance increases.

&#x200B;

[Break-Out Performance At Critical Scale](https://preview.redd.it/jlh726eku0ca1.png?width=800&format=png&auto=webp&s=55d170251a967f31b36f01864af6bb7e2dbda253)

They observed similar improvements on (few-shot) prompting strategies, such as multi-step reasoning and instruction following. If you are interested, I also encourage you to check out Jason Wei's personal blog. There he [listed a total of 137](https://www.jasonwei.net/blog/emergence) emergent abilities observable in LLMs.

Looking at the results, one could be forgiven for thinking: simply making models bigger will make them more powerful. That would only be half the story.

(Language) models are primarily scaled along three dimensions: number of parameters, amount of training compute, and dataset size. Hence, emergent abilities are likely to also occur with e.g. bigger and/or cleaner datasets.

There is [other research](https://arxiv.org/abs/2203.15556) suggesting that current models, such as GPT-3, are undertrained. Therefore, scaling datasets promises to boost performance in the near-term, without using more parameters.

**So what does this mean exactly?**

This beautiful paper shines a light on the fact that our understanding of how to train these large models is still very limited. The lack of understanding is largely due to the sheer cost of training LLMs. Running the same number of experiments as people do for smaller models would cost in the hundreds of millions.

However, the results strongly hint that further scaling will continue the exhilarating performance gains of the last years.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you.At **TheDecoding** ⭕, I send out a thoughtful newsletter about ML research and the data economy once a week.No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)"
35,deeplearning,gpt-3,top,2021-12-01 07:53:09,Giving GPT-3 a Voice with Speech Synthesis,Caterpillarfox,False,0.88,6,r69k5w,https://www.reddit.com/r/deeplearning/comments/r69k5w/giving_gpt3_a_voice_with_speech_synthesis/,0,1638345189.0,"I recently came across this article which includes a video that was voiced just like a human. Amazing to create?

Source of Tool: [https://www.resemble.ai/giving-gpt-3-a-voice-with-speech-synthesis/](https://www.resemble.ai/giving-gpt-3-a-voice-with-speech-synthesis/)

Source of Article: [https://thecompetenza.com/net-6/](https://thecompetenza.com/net-6/)"
36,deeplearning,gpt-3,top,2021-08-19 07:03:53,Dual 3090 vs A6000 + Intel vs AMD?,xKaiz3n,False,0.74,7,p79uhm,https://www.reddit.com/r/deeplearning/comments/p79uhm/dual_3090_vs_a6000_intel_vs_amd/,21,1629356633.0,"Hello,

I've been asked to spec out a machine for a range of DL tasks (inc. GPT-3/4 & classification etc.). Looking at prices here (AUS) it seems the price for 2x 3090s (AUD$3000 - 4000) is around the same price as 1x A6000 (AUD$7500 - 8500). 

I've gone into this with a fairly rudimentary understanding of both hardware at this level and deep learning (read: I'm a student & interning), so apologies if I've said something particularly silly.  I'm also looking to see if there are any recommendations for CPU's:

\- do DL packages have a preference for AMD vs Intel like they do with GPU's?

\- which CPU would you guys choose that won't bottleneck the GPUs?

&#x200B;

Thank you!"
37,deeplearning,gpt-3,top,2021-08-13 16:21:39,Computational Bottleneck of Largest GPT-3,zxcv_qwer1234,False,0.9,7,p3og0n,https://www.reddit.com/r/deeplearning/comments/p3og0n/computational_bottleneck_of_largest_gpt3/,1,1628871699.0,"I know a lot of work is being done to optimize the performance of transformers on very long sequences, but I am curious if there would be any value in optimizing the dense operations in the largest GPT models.  My understanding is that all self-attention operations softmax(QK)V scale linearly with the size of Q, K, and V while the linear projections and FFN would scale to the square of these values (assuming the side of the FFN hidden states also scale linearly with Q, K, and V).  For this reason, with the largest GPT models, is more computation currently being used on linear operations than the self-attention operation itself?"
38,deeplearning,gpt-3,top,2020-06-16 03:13:01,"I just published ""All you need to need to know about OPENAI's GPT-3 "" on medium . Check out , feedback is highly appreciated..",dharma_m,False,0.61,5,h9ve0q,https://medium.com/@savanidharmam5/all-you-need-to-know-about-openai-gpt-3-d0d879446aeb,0,1592277181.0,
39,deeplearning,gpt-3,top,2021-12-21 11:31:55,Pretrained models on other data than language,jssmith42,False,0.71,4,rlcs2a,https://www.reddit.com/r/deeplearning/comments/rlcs2a/pretrained_models_on_other_data_than_language/,1,1640086315.0,"Are there pretrained models like GPT-3 but that are trained on different inputs and outputs?

I am picturing a model that can clean and restructure Excel data by being shown a few example clean ups. I guess the inputs and outputs would be Excel files, but it would be cool if there was a training front-end software sort like what Prodigy is for data-labelling.

Thank you"
40,deeplearning,gpt-3,top,2022-11-20 06:20:53,How do various content-generating services work?,th3luck,False,0.74,5,yzwzp0,https://www.reddit.com/r/deeplearning/comments/yzwzp0/how_do_various_contentgenerating_services_work/,1,1668925253.0,"Right now sites like [https://www.jasper.ai/](https://www.jasper.ai/) offer text generation for emails, ads, social media posts and etc. I wonder, do they simply tune a separate gpt-3-like model for each of these tasks? Or there is a new approach to solving this?"
41,deeplearning,gpt-3,top,2023-12-28 21:36:23,"The best current models (Dolphin, Mixtral, Solar, Noromaid) and where to try them",Horror_Echo6243,False,0.88,6,18t59yu,https://www.reddit.com/r/deeplearning/comments/18t59yu/the_best_current_models_dolphin_mixtral_solar/,5,1703799383.0," 

I just saw a lot of people talking about this models so if you want to test them i found this websites that have all of them

\- [infermatic.ai](https://infermatic.ai/) (all of them)

\- [https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0](https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0) (for solar)

\- [https://huggingface.co/chat](https://huggingface.co/chat) (for mixtral)

Let me know if you find more, I'd like to know

And heres a little resume if you don't know what each model is for

Dolphin : An uncensored model derived from an open-source dataset, it uses instructions from FLANv2 enhanced with GPT-4 and GPT-3.5 completions​​.

Mixtral : An advanced text generation model using a Mix of Experts architecture

Solar : domain specialization and optimization. It's recognized for its high performance and efficiency

Noromaid: Storywriting and roleplay"
42,deeplearning,gpt-3,top,2020-07-24 09:50:27,[Tutorial] Sentence to SQL Converter using GPT-3,bhavesh91,False,0.8,6,hwyz1v,https://www.reddit.com/r/deeplearning/comments/hwyz1v/tutorial_sentence_to_sql_converter_using_gpt3/,1,1595584227.0,"I created a simple Sentence to SQL Converter using GPT - 3. If you want to learn how you can use OpenAI's GPT-3 to generate NLP Applications then this simple tutorial should help.Video Link : [https://www.youtube.com/watch?v=9g66yO0Jues](https://www.youtube.com/watch?v=9g66yO0Jues)

https://reddit.com/link/hwyz1v/video/79gg5vrj1sc51/player"
43,deeplearning,gpt-3,top,2021-11-30 16:29:59,Best practices for developing GPT-3 applications,bendee983,False,0.8,6,r5r31f,https://bdtechtalks.com/2021/11/29/gpt-3-application-development-tips/,0,1638289799.0,
44,deeplearning,gpt-3,top,2020-07-20 18:56:29,OpenAI’s new language generator GPT-3 is shockingly good—and completely mindless,PsychogenicAmoebae,False,0.67,4,hur8o1,https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/,1,1595271389.0,
45,deeplearning,gpt-3,top,2023-01-22 10:12:08,"BigScience BLOOM, how should we use it?",Haghiri75,False,1.0,6,10igecg,https://www.reddit.com/r/deeplearning/comments/10igecg/bigscience_bloom_how_should_we_use_it/,1,1674382328.0,"Since the release of BLOOM, I always wanted to test it the way GPT-3 (and newly released ChatGPT) are tested. Having a playground with the ability to explore settings and even generating codes and stuff. But I don't know how long was it (I guess almost a year) and the only thing *close to playground* it had was the huggingface model card.

So is there any reliable way to use BLOOM in a proper way?"
46,deeplearning,gpt-3,top,2022-04-21 15:55:24,How do I figure out if I can run a model on my personal computer / any given hardware?,Jjax7,False,1.0,7,u8qs9o,https://www.reddit.com/r/deeplearning/comments/u8qs9o/how_do_i_figure_out_if_i_can_run_a_model_on_my/,2,1650556524.0,"Models like GPT-3 and DALLE-2 have billions of parameters. I’m an undergraduate Data Science student with a GTX 970 in my computer. I’ve been able to train and run model architectures similar to AlexNet, UNet, and a Sequence-to-Sequence RNN encoder-decoder architecture on my local device before, but there is a disconnect in my understanding for what it takes to scale models up given more complex tasks.

It’s my understanding that many modern state-of-the-art models make use of transformer architectures and more specifically attention mechanisms. From what I’ve been learning, attention gives massive boosts in training and model execution speed due to parallelization but at the cost of high memory usage. How can I ground my understanding of the computational costs required to run these models?

Is there a way to look at the number of parameters a model is trained with and understand the kind of memory/hardware required?"
47,deeplearning,gpt-3,top,2022-08-14 10:58:04,OneFlow v0.8.0 Came Out!,Just0by,False,0.86,5,wo3o9l,https://www.reddit.com/r/deeplearning/comments/wo3o9l/oneflow_v080_came_out/,1,1660474684.0,"Hi all,

We are thrilled to announce the new release of [**OneFlow**](https://github.com/Oneflow-Inc/oneflow)**, which is a deep learning framework designed to be user-friendly, scalable and efficient.** OneFlow v0.8.0 update contains 523 commits. For the full changlog, please check out: [**https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.8.0**](https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.8.0).  


**Paper:** [https://arxiv.org/abs/2110.15032](https://arxiv.org/abs/2110.15032);  
**Code:** [https://github.com/Oneflow-Inc/oneflow](https://github.com/Oneflow-Inc/oneflow)

Welcome to install OneFlow v0.8.0 for a new user experience. Your feedbacks will be much appreciated!

Highlights and optimizations in this release:

**1. PyTorch API compatibility**

OneFlow v0.8.0 provides more and better PyTorch compatible APIs. In v0.8.0, a series of new features and interfaces that are compatible with PyTorch 1.10.0 are in place, including 68 new APIs that are aligned with PyTorch; 84 bugs are fixed to ensure better compatibility between operators and interfaces, allowing users to transfer more PyTorch models to OneFlow with just one click.

&#x200B;

**2. Wider support of global operators**

All operators support Global Tensor more widely and efficiently. Fixed 28 bugs related to Global Tensor and added 180 Global operator unit tests, making the development of distributed models with Global Tensor faster and easier.

&#x200B;

**3. Better performance**

The advanced features of Graph have been improved for better performance:

In addition to the original ZeRO-DP, ZeRO can be used in parallel with MP, 2-D, and 3-D to further reduce memory overhead.

Added a new pipeline parallelism API for Graph to simplify the configuration for pipeline parallelism and accelerate training when using pipeline parallelism and 3-D parallelism.

Added debugging features in multiple dimensions, including logical graphs, light plan physical graphs, memory analysis, and Python stack information, to further improve efficiency of Graph.debug.

The combination of OneFlow v0.8.0 and LiBai v0.2.0 enables higher computation speeds of GPT and BERT under 3-D parallelism on multiple dimensions, surpassing those of Megatron-LM with the same configurations. (For more details, see: [https://libai.readthedocs.io/en/latest/tutorials/get\_started/Benchmark.html](https://libai.readthedocs.io/en/latest/tutorials/get_started/Benchmark.html)).

&#x200B;

**4. OneEmbedding component**

OneEmbedding is an extended component specifically designed for large-scale recommender systems. It boasts excellent performance, extensibility, and flexibility.

API Documentation: [https://docs.oneflow.org/en/master/cookies/one\_embedding.html](https://docs.oneflow.org/en/master/cookies/one_embedding.html)

&#x200B;

**5. Multi-Device adaptation**

OneFlow v0.8.0 provides a neat, efficient, and easily extensible hardware abstraction layer EP (Execution Provider) to adapt to different hardware. With the introduction of the hardware abstraction layer, no modifications are needed for any module of the framework to adapt to new hardware devices, regardless of the implementation details of any underlying hardware or framework.

To make the new hardware devices work, users only need to implement a series of interfaces based on the protocols of the hardware abstraction interfaces and the status quo of the hardware devices.

EP also defines a set of basic computing interface primitives, allowing the reimplementation of kernels. Primitives provide interfaces that are more flexible than the runtime interfaces provided by EP. Different interfaces are independent of each other, and each interface represents a kind of computing capability that can be provided by a certain hardware device.

**6. Debugging tool stack**

New debug tools: OneFlow-Profiler and AutoProf.

OneFlow-Profiler is a tool used to collect performance information during framework execution. It can keep records of the execution time of operators and system components, the allocation of memory, and the corresponding input and parameters of operators. All this information helps developers find out the main source of overhead in framework execution and thus implement targeted optimization.

AutoProf is a framework for testing the performance of OneFlow and PyTorch operators. It provides an elegant and efficient method to detect the alignment between OneFlow APIs and PyTorch APIs, allowing users to conveniently compare the performance of OneFlow APIs and PyTorch APIs.

**7. Error message**

Improved error message with more details. Refactored exception handling.

&#x200B;

**8. API documentation**

Made over 20 revisions to the OneFlow API documentation, restructured the documentation based on features, and added further elaboration of modules and environment variables including OneFlow oneflow.nn.graph, oneflow.embedding, and oneflow.autograd, in addition to the general operator APIs."
48,deeplearning,gpt-3,top,2021-12-13 16:07:57,"[R] DeepMind’s RETRO Retrieval-Enhanced Transformer Retrieves from Trillions of Tokens, Achieving Performance Comparable to GPT-3 With 25× Fewer Parameters",Yuqing7,False,0.75,4,rfj4c2,https://www.reddit.com/r/deeplearning/comments/rfj4c2/r_deepminds_retro_retrievalenhanced_transformer/,0,1639411677.0,"A DeepMind research team proposes RETRO (Retrieval-Enhanced Transformer), an enhanced auto-regressive language model that conditions on document chunks retrieved from a large corpus and achieves performance comparable to GPT-3 and Jurassic-1 on the Pile dataset while using 25× fewer parameters. 

Here is a quick read: [DeepMind’s RETRO Retrieval-Enhanced Transformer Retrieves from Trillions of Tokens, Achieving Performance Comparable to GPT-3 With 25× Fewer Parameters.](https://syncedreview.com/2021/12/13/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-164/)

The paper *Improving Language Models by Retrieving From Trillions of Tokens* is on [arXiv](https://arxiv.org/abs/2112.04426)."
49,deeplearning,gpt-3,top,2023-02-21 11:06:33,I created a Search Engine For Books using GPT-3 🔎📘. Here's how you can create it too:,Pritish-Mishra,False,0.69,5,1180x0e,https://youtu.be/SXFP4nHAWN8,8,1676977593.0,
50,deeplearning,gpt-3,top,2021-06-02 16:48:40,"AI Weekly Update - June 2nd, 2021",HenryAILabs,False,1.0,4,nqqb39,https://www.reddit.com/r/deeplearning/comments/nqqb39/ai_weekly_update_june_2nd_2021/,0,1622652520.0,"New AI Weekly Update - June 2nd, 2021 (#33!)

* Deep Learning with Code Data
* Reward is Enough
* AndroidEnv
* CogView
* Medically-aware GPT-3

https://youtu.be/6ic2PuWGhuA"
51,deeplearning,gpt-3,top,2022-01-31 11:00:50,Searching participants for art project about AI,Nebeldiener,False,0.81,3,sgyojm,https://www.reddit.com/r/deeplearning/comments/sgyojm/searching_participants_for_art_project_about_ai/,0,1643626850.0,"Hi,

I’m part of an art group from Switzerland currently studying at HSLU Design & Arts ([https://www.hslu.ch/de-ch/design-kunst/studium/bachelor/camera-arts/](https://www.hslu.ch/de-ch/design-kunst/studium/bachelor/camera-arts/)).

The group consists of:

Karim Beji ([https://www.instagram.com/karimbeji\_/](https://www.instagram.com/karimbeji_/) [https://karimbeji.ch/](https://karimbeji.ch/))

Emanuel Bohnenblust ([https://www.instagram.com/e.bohnenblust/](https://www.instagram.com/e.bohnenblust/))

Lea Karabash ([https://www.instagram.com/leakarabashian/](https://www.instagram.com/leakarabashian/))

Yen Shih-hsuan ([https://www.instagram.com/shixuan.yan/](https://www.instagram.com/shixuan.yan/) [http://syen.hfk-bremen.de/](http://syen.hfk-bremen.de/))

At the moment, we are working on a project on the topic if AI can augment the happiness of humans. To answer this question, we are mainly working with chatbots. The end result is going to be an exhibition at the end of March. 

For that exhibition, we want to conduct a trial in which people from over the world chat with a chatbot to find out if and how it augments the mood of the participants. 

We would give you access to a GPT-3 (OpenAI) chatbot and ask you to a) record yourself through a webcam (laptop) while you are chatting and b) simultaneously screen record the chat window. 

In the exhibition we would have a) a book with all the chats and b) small videos with your faces (webcam) to assess your mood. 

We would have a Zoom meeting beforehand to discuss everything.

Looking forward to your message!"
52,deeplearning,gpt-3,top,2023-08-28 07:12:44,OpenAI introduces fine-tuning capabilities for GPT-3.5 Turbo,intengineering,False,1.0,4,163f3fp,https://interestingengineering.com/innovation/openai-introduces-fine-tuning-capabilities-for-gpt-35-turbo,1,1693206764.0,
53,deeplearning,gpt-3,top,2020-05-29 15:25:32,[D] Paper Explained - GPT-3: Language Models are Few-Shot Learners (Video Analysis),ykilcher,False,0.75,4,gsuzks,/r/MachineLearning/comments/gsuzey/d_paper_explained_gpt3_language_models_are/,0,1590765932.0,
54,deeplearning,gpt-3,top,2022-09-30 22:32:09,Expressive Generative TTS Model,SSaadM,False,0.72,3,xsen7q,https://www.reddit.com/r/deeplearning/comments/xsen7q/expressive_generative_tts_model/,0,1664577129.0,"There's a lot happening in generative AI in text generation (GPT 3, Bloom), image generation (Stable diffusion, OpenAI), video generation (Makeavideo, runwayML). Here's our (Play.ht's) very first model for speech generation, I'd love to hear the community's thoughts on this!

https://www.producthunt.com/posts/peregrine

If you like it, please drop us an upvote. It would really really help :)"
55,deeplearning,gpt-3,top,2021-11-26 18:59:22,Music generation toolbox,wingedsheep38,False,0.67,3,r2u8oi,https://www.reddit.com/r/deeplearning/comments/r2u8oi/music_generation_toolbox/,4,1637953162.0,"This year I joined the team ""Lovelace and the machines"" for the AI Song Contest 2021. With the goal of using algorithms / machine learning to generate music, and then team up with musicians to create an actual song. We used a combination of GPT-3 for the lyrics and a music transformer implementation for the notes, and a bunch of other techniques for analyzing and rating the results or generating variations. It was a really cool challenge and our team ended up in second place with our song ""[Quantum trap](https://www.youtube.com/watch?v=YSn5pBdFjS4)"". I wrote a [blogpost](https://wingedsheep.com/music-generation-creating-a-song-for-the-ai-song-contest-2021/) about it for those interested in the details.

I created a project for the music generation tools that we used, so other people who are interested can experiment with it. You can find it here: [https://github.com/wingedsheep/music-generation-toolbox](https://github.com/wingedsheep/music-generation-toolbox). The goal of this project is to implement new techniques of music generation so they can be compared and tested.

Some samples created so far:

* Pop909 dataset with a compound word transformer [https://soundcloud.com/user-419192262-663004693/sets/compound-word-transformer-pop909](https://soundcloud.com/user-419192262-663004693/sets/compound-word-transformer-pop909)
* Pop909 dataset with a routing transformer [https://soundcloud.com/user-419192262-663004693/sets/routing-transformer-pop909](https://soundcloud.com/user-419192262-663004693/sets/routing-transformer-pop909)
* Lakh midi dataset (multi instrument) with music transformer [https://soundcloud.com/user-419192262-663004693/sets/generated-by-music-transformer-from-scratch](https://soundcloud.com/user-419192262-663004693/sets/generated-by-music-transformer-from-scratch)

I'm always interested to hear new ideas on how to improve or which new techniques to add!

Also I'm looking for a way to host the models, so people can try it in Colab without having to train a model from scratch. Any good ideas on where to put my models?"
56,deeplearning,gpt-3,top,2021-06-17 19:51:07,[R] Improving Language Model Behavior by Training on a Small Curated Dataset,ClaudeCoulombe,False,0.83,4,o262ql,https://www.reddit.com/r/deeplearning/comments/o262ql/r_improving_language_model_behavior_by_training/,0,1623959467.0,"Interesting research results by [OpenAI](https://openai.com/blog/improving-language-model-behavior/). It seems possible to improve the behavior of  a  GPT-3 language model  by fine tuning it  on a very small dataset. Of course, we are talking about undesirable biases (hateful, agressive, racist, sexist, etc.). They only used 80 texts. On the other hand, they neglect to say that someone can very well adjust the generated texts to favor biased texts with again a very small corpus. The [scientific paper](https://cdn.openai.com/palms.pdf) (PDF)."
57,deeplearning,gpt-3,top,2021-12-20 16:17:11,[R] OpenAI’s WebGPT Crawls a Text-Based Web Environment to Achieve Human-Level Performance on Long-Form QA,Yuqing7,False,0.8,3,rkqv80,https://www.reddit.com/r/deeplearning/comments/rkqv80/r_openais_webgpt_crawls_a_textbased_web/,0,1640017031.0,"An OpenAI research team fine-tunes the GPT-3 pretrained language model to enable it to answer long-form questions by searching and navigating a text-based web browsing environment, achieving retrieval and synthesis improvements and reaching human-level long-form question-answering performance. 

Here is a quick read:[OpenAI’s WebGPT Crawls a Text-Based Web Environment to Achieve Human-Level Performance on Long-Form QA.](https://syncedreview.com/2021/12/20/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-169/)

The paper *WebGPT: Browser-assisted Question-answering with Human Feedback* is on [OpenAI.com](https://openai.com/blog/improving-factual-accuracy/)."
58,deeplearning,gpt-3,top,2023-09-28 13:34:24,First Impressions with GPT-4V(ision),zerojames_,False,0.71,3,16ug8gc,https://www.reddit.com/r/deeplearning/comments/16ug8gc/first_impressions_with_gpt4vision/,0,1695908064.0,"My colleague Piotr and I have been testing GPT-4V(ision) over the last day. We wrote up our findings, covering how GPT-4V performs on:

1. Visual question answering (VQA) across a range of domains (locations, movies, plants)
2. OCR
3. Math OCR
4. Object detection
5. And more

TL;DR: GPT-4V performed well for VQA and document OCR but struggled with OCR on real-world images and object detection (where we asked for bounding boxes).

[https://blog.roboflow.com/gpt-4-vision/](https://blog.roboflow.com/gpt-4-vision/)

I would love to hear what other people have found working with GPT-4V."
59,deeplearning,gpt-3,top,2021-08-25 02:37:52,[N] AI Can Write in English. Now It's Learning Other Languages - Wired,ClaudeCoulombe,False,1.0,3,pb27l2,https://www.reddit.com/r/deeplearning/comments/pb27l2/n_ai_can_write_in_english_now_its_learning_other/,0,1629859072.0,An interesting [Wired 's paper](https://www.wired.com/story/ai-write-english-learning-other-languages/). A growing number of startups outside USA are building general-purpose GPT-3 like  language models and tools.
60,deeplearning,gpt-3,top,2023-05-31 10:03:36,What is the objective for the supervised fine-tuning stage of instruction-following models?,BlueHemp,False,0.81,3,13whxjk,https://www.reddit.com/r/deeplearning/comments/13whxjk/what_is_the_objective_for_the_supervised/,1,1685527416.0,"Dialog models like [InstructGPT](https://arxiv.org/pdf/2203.02155.pdf) and, recently, [Dromedary](https://arxiv.org/abs/2305.03047) have a supervised fine-tuning part where they use collected demonstration data to tune the base model. Quote from InstructGPT paper: ""fine-tune a pretrained GPT-3 model on this data using supervised learning.""

However, these papers don't go into detail about the objective/loss function for this step. To be clear, I don't mean the RLHF part that follows for InstructGPT but the first step of just fine-tuning on (human or model generated) examples.

I would guess that the objective is basically an auto-regressive language modeling task since GPT-like models are decoder-only models.So what exactly is the training objective or loss function for the supervised finetuning (not RLHF!) step?"
61,deeplearning,gpt-3,top,2022-01-09 16:11:37,General Purpose Reading Models,HenryAILabs,False,0.67,2,rzuykx,https://www.reddit.com/r/deeplearning/comments/rzuykx/general_purpose_reading_models/,0,1641744697.0,"GPT-3 has successfully been campaigned as a General-Purpose API -- all you need is to provide a few examples of a task and it promises generalization to future inferences.

I think separating Deep Learning models into retrieve-then-read pipelines makes much more sense for general purpose functionality. Retrieval offers:  


* Interpretability
* Ease to update information
* Less parameters needed because you do not need to store the data in the parameters

This video explains some of these ideas and the benefits of separating retrieval and reading, I hope you find it interesting!   


https://www.youtube.com/watch?v=mRcuNtMOmZw"
62,deeplearning,gpt-3,top,2021-08-11 15:48:33,"Watch out, GPT-3, here comes AI21's 'Jurassic' language model | ZDNet",lindaarden,False,0.74,4,p2fqcs,https://www.zdnet.com/article/watch-out-gpt-3-here-comes-ai21s-jurassic-language-model/,0,1628696913.0,
63,deeplearning,gpt-3,top,2020-09-09 19:51:13,[R] New Multitask Benchmark Suggests Even the Best Language Models Don’t Have a Clue What They’re Doing,Yuqing7,False,1.0,3,ipnoh4,https://www.reddit.com/r/deeplearning/comments/ipnoh4/r_new_multitask_benchmark_suggests_even_the_best/,1,1599681073.0,"The recently published paper, *Measuring Massive Multitask Language Understanding,* introduces a test covering topics such as elementary mathematics, US history, computer science, law, etc., designed to measure language models’ multitask accuracy. The authors, from UC Berkeley, Columbia University, UChicago, and UIUC, conclude that even the top-tier 175-billion-parameter OpenAI GPT-3 language model is a bit daft when it comes to language understanding, especially when encountering topics in greater breadth and depth than explored by previous benchmarks.

Here is a quick read: [New Multitask Benchmark Suggests Even the Best Language Models Don’t Have a Clue What They’re Doing](https://syncedreview.com/2020/09/09/new-multitask-benchmark-suggests-even-the-best-language-models-dont-have-a-clue-what-theyre-doing/)

The paper *Measuring Massive Multitask Language Understanding* is on [arXiv](https://arxiv.org/pdf/2009.03300.pdf)."
64,deeplearning,gpt-3,top,2023-07-29 20:02:45,"Promptify 2.0: More Structured, More Powerful LLMs with Prompt-Optimization, Prompt-Engineering, and Structured Json Parsing with GPT-n Models! 🚀",StoicBatman,False,0.71,3,15d1fs8,https://www.reddit.com/r/deeplearning/comments/15d1fs8/promptify_20_more_structured_more_powerful_llms/,6,1690660965.0,"Hello fellow coders and AI enthusiasts!

First up, a huge Thank You for making Promptify a hit with **over** [**2.3k+ stars on Github**](https://github.com/promptslab/Promptify) ! 🌟

Back in 2022, we were the first one to tackle the common challenge of uncontrolled, unstructured outputs from large language models like GPT-3. , and your support has pushed us to keep improving.Today, we're thrilled to share some major updates that make Promptify even more powerful

&#x200B;

https://preview.redd.it/29ajik9xmyeb1.png?width=1510&format=png&auto=webp&s=3c3bfeebd6ba5e878885b079510a8972cc72c3b8

&#x200B;

* **Unified Architecture 🧭**: Introducing Prompter, Model & Pipeline Solution
* **Detailed Output Logs 📔**: Comprehensive structured JSON format output within the log folder.
* **Wider Model Support 🤝**: Supporting models from OpenAI, Azure, Cohere, Anthropic, Huggingface and more - think of it as your universal language model adapter.
* **Robust Parser 🦸‍♂️**: Parser to handle incomplete or unstructured JSON outputs from any LLMs.
* **Ready-Made Jinja Templates 📝**: Jinja prompt templates for NER, Text Classification, QA, Relation-Extraction, Tabular data, etc.
* **Database Integration 🔗**: Soon, Promptify directly to Mongodb integration. Stay tuned!
* **Effortless Embedding Generation 🧬**: Generate embeddings from various LLMs effortlessly with the new update.

&#x200B;

https://preview.redd.it/k50gmbxymyeb1.png?width=2160&format=png&auto=webp&s=ef063a7a0594eccac5674bd60d7adce193eecc3f

Check out the examples and take Promptify for a spin on GitHub. If you like what you see, we'd be honored if you gave us a star!

* **Github**: [https://github.com/promptslab/Promptify](https://github.com/promptslab/Promptify)
* **Colab:** [Try Now on Colab](https://colab.research.google.com/drive/16DUUV72oQPxaZdGMH9xH1WbHYu6Jqk9Q?usp=sharing)
* **Explore Other Cool Open Source LLM Tools:** [https://github.com/promptslab](https://github.com/promptslab)

Join **1.6k+ Promptify users on Discord** to dive deep into prompt engineering, discuss the latest with LLMs, and advance NLP research together: [https://discord.com/invite/m88xfYMbK6](https://discord.com/invite/m88xfYMbK6)Thank you again for your support - here's to more structured AI!

&#x200B;"
65,deeplearning,gpt-3,top,2021-01-05 22:42:51,"[N] This Time, OpenAI’s GPT-3 Generates Images From Text",Yuqing7,False,0.67,3,kr9sxx,https://www.reddit.com/r/deeplearning/comments/kr9sxx/n_this_time_openais_gpt3_generates_images_from/,0,1609886571.0,"OpenAI’s popular GPT-3 from last year showed that language can be used to instruct a large neural network to perform a variety of text generation tasks. Entering the new year, OpenAI is moving from pure text generation to image generation from text — its researchers today announce that they have trained a neural network called [DALL·E](https://openai.com/blog/dall-e/) that creates images from text captions for a wide range of concepts expressible in natural language.

Here is a quick read: [This Time, OpenAI’s GPT-3 Generates Images From Text](https://syncedreview.com/2021/01/05/this-time-openais-gpt-3-generates-images-from-text/)"
66,deeplearning,gpt-3,top,2023-05-19 18:55:34,How To Reduce The Cost Of Using LLM APIs by 98%,LesleyFair,False,0.67,3,13m4e1k,https://www.reddit.com/r/deeplearning/comments/13m4e1k/how_to_reduce_the_cost_of_using_llm_apis_by_98/,0,1684522534.0,"[Budget For LLM Inference](https://preview.redd.it/xprd070u4u0b1.png?width=493&format=png&auto=webp&s=dad41692ad4cd22e768e92baabfd566ddef468e8)

Cost is still a major factor when scaling services on top of LLM APIs.

Especially, when using LLMs on large collections of queries and text it can get very expensive. It is [estimated](https://neoteric.eu/blog/how-much-does-it-cost-to-use-gpt-models-gpt-3-pricing-explained/) that automating customer support for a small company can cost up to $21.000 a month in inference alone.

The inference costs differ from vendor to vendor and consists of three components:

1. a portion that is proportional to the length of the prompt
2. a portion that is proportional to the length of the generated answer
3. and in some cases a small fixed cost per query.

In a recent [publication](https://arxiv.org/pdf/2305.05176.pdf) researchers at Stanford proposed three types of strategies that can help us to slash costs. The cool thing about it is that we can use these strategies in our projects independently of the prices dictated by the vendors!

*Let’s jump in!*

**How To Adapt Our Prompts To Save Costs**

Most approaches to prompt engineering typically focus only on increasing performance.

In general, prompts are optimized by providing more detailed explanations of the desired output alongside multiple in-context examples to steer the LLM. However, this has the tendency to result in longer and more involved prompts. Since the cost per query grows linearly with the number of tokens in our prompt this makes API requests more expensive.

The idea behind the first approach, called Query Adaption, is to create effective (often shorter) prompts in order to save costs.

This can be done in different ways. A good start is to reduce the number of few-shot examples in your prompt. We can experiment to find out what the smallest set of examples is that we have to include in the prompt to maintain performance. Then, we can remove the other examples.

So far so good!

Once we have a more concise prompt, there is still another problem. Every time a new query is processed, the same in-context examples and detailed explanations to steer the model are processed again and again.

The way to avoid this redundant prompt processing is by applying query concatenation.

In essence, this means that instead of asking one question in our lengthy prompt, we add multiple questions Q1, Q2, … in the same prompt. To get this to work, we might need to add a few tokens to the prompt that make it easier for us to separate the answers from the model output. However, the majority of our prompt is not repeatedly sent to the API as a result.

This allows us to process dozens of queries at once, making query concatenation a huge lever for cost savings while being relatively easy to implement.

*That was an easy win! Let’s look at the second approach!*

**LLM Approximation**

The idea here is to emulate the performance of a better, more expensive model.

In the paper, they suggest two approaches to achieve this. The first one is to create an additional caching infrastructure that alleviates the need to perform an expensive API request for every query. The second way is to create a smaller, more specialized model that mimics what the model behind the API does.

Let’s look at the caching approach!

The idea here is that every time we get an answer from the API, we store the query alongside the answer in a database. We then pre-compute embeddings for every stored query. For every new query that comes in, we do not send it off to our LLM vendor of choice. Instead, we perform a vectorized search over our cached query-response pairs.

If we find a question that we already answered in the past, we can simply return the cached answer without accruing any additional cost. This obviously works best if we repeatedly need to process similar requests and the answers to the questions are evergreen.

Now let’s move on to the second approach!

Don’t worry! The idea is not to spend hundreds of thousands of dollars to fine-tune an LLM. If the overall variety of expected questions and answers is not crazy huge - which for most businesses it is not - a BERT-sized model should probably do the job.

The process could look as follows: first, we collect a dataset of queries and answers that are generated with the help of an API. The second step is to fine-tune the smaller model on these samples. Third, use the fine-tuned model on new incoming queries.

To reduce the cost even further, It could be a good approach to implement the caching first before starting to train a model. This has the advantage of passively building up a dataset of query-answer pairs during live operation. Later we can still actively generate a dataset if we run into any data quality concerns such as some queries being underrepresented.

A pretty cool byproduct of using one of the LLM approximation approaches is that they can significantly reduce latency.

Now, let’s move on to the third and last strategy which has not only the potential to reduce costs but also improve performance.

**LLM Cascade**

More and more LLM APIs have become available and they all vary in cost and quality.

The idea behind what the authors call an LLM Cascade is to start with the cheap API and then successively call APIs of increasing quality and cost. Once an API returns a satisfying answer the process is stopped. Especially, for simpler queries this can significantly reduce the costs per query.

*However, there is a catch!*

How do we know if an answer is satisfying? The researchers suggest training a small regression model which scores the reliability of an answer. Once this reliability score passes a certain threshold the answer gets accepted.

One way to train such a model would obviously be to label the data ourselves.

Since every answer needs only a binary label (reliable vs. unreliable) it should be fairly inexpensive to build such a dataset. Better still we could acquire such a dataset semi-automatically by asking the user to give feedback on our answers.

If running the risk of serving bad answers to customers is out of the question for whatever reason, we could also use one of the stronger APIs (*cough* GPT ***cough***) to label our responses.

In the paper, the authors conduct a case study of this approach using three popular LLM APIs. They successively called them and used a DistillBERT (very small) to perform scoring. They called this approach FrugalGPT and found that the approach could save up to 98.3% in costs on the benchmark while also improving performance.

How would this increase performance you ask?

Since there is always some heterogeneity in the model’s outputs a weaker model can actually sometimes produce a better answer than a more powerful one. In essence, calling multiple APIs gives more shots on goal. Given that our scoring model works well, this can result in better performance overall.

In summary, strategies such as the ones described above are great because they attack the problem of high inference costs from a different angle. They allow us to be more cost-effective without relying on the underlying models to get cheaper. As a result, it will become possible to use LLMs for solving even more problems!

What an exciting time to be alive!

Thank you for reading!

As always, I really enjoyed making this for you and sincerely hope you found it useful! At The Decoding ⭕, I send out a thoughtful 5-minute email every week that keeps you in the loop about machine learning research and the data economy. [Click here to subscribe](http://thedecoding.net)!"
67,deeplearning,gpt-3,top,2021-07-13 15:38:39,[R] OpenAI Fine-Tunes GPT-3 to Unlock Its Code Generation Potential for Difficult Problems,Yuqing7,False,0.75,2,oji5zu,https://www.reddit.com/r/deeplearning/comments/oji5zu/r_openai_finetunes_gpt3_to_unlock_its_code/,0,1626190719.0,"A research team from OpenAI proposes Codex, a specialized GPT model fine-tuned on publicly available code from GitHub that can produce functionally correct Python code bodies from natural language docstrings and could excel at a variety of coding tasks. 

Here is a quick read: [OpenAI Fine-Tunes GPT-3 to Unlock Its Code Generation Potential for Difficult Problems.](https://syncedreview.com/2021/07/13/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-60/)

The paper *Evaluating Large Language Models Trained on Code* is on [arXiv](https://arxiv.org/abs/2107.03374)."
68,deeplearning,gpt-3,top,2021-08-31 03:04:53,[R] CtrlGen Workshop at NeurIPS 2021 (Controllable Generative Modeling in Language and Vision),CtrlGenWorkshop,False,0.75,2,pexh5q,https://www.reddit.com/r/deeplearning/comments/pexh5q/r_ctrlgen_workshop_at_neurips_2021_controllable/,2,1630379093.0,"We are holding a controllable generation workshop at NeurIPS 2021! It aims to explore disentanglement, controllability, and manipulation for the generative vision and language modalities. We feature an exciting lineup of speakers, a live QA and panel session, interactive activities, and networking opportunities. See our website below for more! We are also inviting both paper and demo submissions related to controllable generation (read further for details).

**Workshop Website:** [https://ctrlgenworkshop.github.io/](https://ctrlgenworkshop.github.io/)

**Contact:** [ctrlgenworkshop@gmail.com](mailto:ctrlgenworkshop@gmail.com)

**Important Dates**

* Paper Submission Deadline: ***September 30, 2021 (UPDATED)***
* Paper Acceptance Notification: October 22, 2021
* Paper Camera-Ready Deadline: November 1, 2021
* Demo Submission Deadline: ***October 29, 2021***
* Demo Acceptance Notification: November 19, 2021
* Workshop Date: ***December 13, 2021***

**Submission Portal (Papers + Demos):**  [https://cmt3.research.microsoft.com/CtrlGen2021/Submission/Index](https://cmt3.research.microsoft.com/CtrlGen2021/Submission/Index)

&#x200B;

**Full Call for Papers:** [h](https://ctrlgenworkshop.github.io/CFP.html)[ttps://ctrlgenworkshop.github.io/CFP.html](https://ctrlgenworkshop.github.io/CFP.html)

Paper submission deadline: ***September 30, 2021 (UPDATED)***. Topics of interest include:

**Methodology and Algorithms:**

* New methods and algorithms for controllability.
* Improvements of language and vision model architectures for controllability.
* Novel loss functions, decoding methods, and prompt design methods for controllability.

**Applications and Ethics:**

* Applications of controllability including creative AI, machine co-creativity, entertainment, data augmentation (for [text](https://arxiv.org/abs/2105.03075) and [vision](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0)), ethics (e.g. bias and toxicity reduction), enhanced training for self-driving vehicles, and improving conversational agents.
* Ethical issues and challenges related to controllable generation including the risks and dangers of deepfake and fake news.

**Tasks (a few examples):**

* [Semantic text exchange](https://aclanthology.org/D19-1272/)
* [Syntactically-controlled paraphrase generation](https://arxiv.org/abs/1804.06059)
* [Persona-based text generation](https://aclanthology.org/W19-3402/)
* Style-sensitive generation or style transfer (for [text](https://arxiv.org/abs/2011.00416) and [vision](https://github.com/ycjing/Neural-Style-Transfer-Papers))
* Image synthesis and scene representation in both 2D and 3D
* Cross-modal tasks such as controllable image or video captioning and generation from text
* New and previously unexplored controllable generation tasks!

**Evaluation and Benchmarks**

* New and improved evaluation methods and metrics for controllability
* Standard and unified metrics and benchmark tasks for controllability

**Cross-Domain and Other Areas**

* Work in interpretability, disentanglement, robustness, representation learning, etc.

**Position and Survey Papers**

* For example, exploring problems and lacunae in current controllability formulations, neglected areas in controllability, and the unclear and non-standardized definition of controllability

&#x200B;

**Full Call for Demonstrations:** [https://ctrlgenworkshop.github.io/demos.html](https://ctrlgenworkshop.github.io/demos.html)

Submission deadline: ***October 29, 2021***. Demos of all forms: research-related, demos of products, interesting and creative projects, etc. Looking for creative, well-presented, and attention-grabbing demos. Examples include:

* Creative AI such as controllable poetry, music, image, and video generation models.
* Style transfer for both text and vision.
* Interactive chatbots and assistants that involve controllability.
* Controllable language generation systems, e.g. using GPT-2 or GPT-3.
* Controllable multimodal systems such as image and video captioning or generation from text.
* Controllable image and video/graphics enhancement systems.
* Systems for controlling scenes/environments and applications for self-driving vehicles.
* Controllability in the form of deepfake and fake news, specifically methods to combat them.
* And much, much more…

&#x200B;

**Organizing Team:**

* [Steven Feng](https://styfeng.github.io/) (CMU)
* [Anusha Balakrishnan](https://www.microsoft.com/en-us/research/people/anbalak/) (Microsoft Semantic Machines)
* [Drew Hudson](https://cs.stanford.edu/people/dorarad/) (Stanford)
* [Tatsunori Hashimoto](https://thashim.github.io/) (Stanford)
* [Dongyeop Kang](https://dykang.github.io/) (UMN)
* [Varun Gangal](https://vgtomahawk.github.io/) (CMU)
* [Joel Tetreault](https://www.cs.rochester.edu/~tetreaul/academic.html) (Dataminr)"
69,deeplearning,gpt-3,top,2022-02-11 16:47:38,Interview with Arvind Neelakantan about the OpenAI Embeddings API,HenryAILabs,False,1.0,2,sq3s05,https://www.reddit.com/r/deeplearning/comments/sq3s05/interview_with_arvind_neelakantan_about_the/,0,1644598058.0,"Hey everyone!   


The release of OpenAI's Embeddings API has been quite the story! I had the pleasure to interview Arvind Neelakantan on miscellaneous topics pertaining to these new advances in Search: [https://www.youtube.com/watch?v=uFxfZ0vLsoU](https://www.youtube.com/watch?v=uFxfZ0vLsoU)  


Additional Background on this:  
OpenAI Embeddings API Blog Post: [https://openai.com/blog/introducing-text-and-code-embeddings/](https://openai.com/blog/introducing-text-and-code-embeddings/)

Nils Reimers' Response (OpenAI GPT-3 Text Embeddings - Really a new state-of-the-art in dense text embeddings?): [https://medium.com/@nils\_reimers/openai-gpt-3-text-embeddings-really-a-new-state-of-the-art-in-dense-text-embeddings-6571fe3ec9d9](https://medium.com/@nils_reimers/openai-gpt-3-text-embeddings-really-a-new-state-of-the-art-in-dense-text-embeddings-6571fe3ec9d9)

Yannic Kilcher on the topic: [https://www.youtube.com/watch?v=5skIqoO3ku0](https://www.youtube.com/watch?v=5skIqoO3ku0)"
70,deeplearning,gpt-3,top,2022-04-23 19:37:38,?? Can you find out which news article is written by AI ??,RobinSandersVUB,False,0.75,2,uad25r,https://www.reddit.com/r/deeplearning/comments/uad25r/can_you_find_out_which_news_article_is_written_by/,1,1650742658.0,"This research will test the human ability to distinguish human written text from text generated by artificial intelligence. Participating will only take 10 minutes. You will receive 2 short news articles about the same topic. One will be written by a human, the other one will be generated by artificial intelligence. It is up to you to find out which one is written by artificial intelligence. You will be asked to do this for four different subjects, namely: Science, Economics & Politics, Society and Sports. At the end of the survey you will receive feedback on how well you have performed.

The human written articles were collected from various news websites. The Articles created by artificial intelligence were generated using GPT-3 from OpenAI.

Purpose of the research: We are trying to find out how well GPT-3 performs across subjects. Are there any subject GPT-3 is better at writing about, or is he equally good across all subjects. Secondly we are testing the ability of GPT-3 to generate articles about events that happened after the training of the model. 

You can participate by clicking on the link below, thank you very much for your participation.

 [https://vub.fra1.qualtrics.com/jfe/form/SV\_b2E9f6hGxNDH13M](https://vub.fra1.qualtrics.com/jfe/form/SV_b2E9f6hGxNDH13M)"
71,deeplearning,gpt-3,top,2022-01-10 01:49:14,Weaviate and Haystack,HenryAILabs,False,1.0,2,s07sf1,https://www.reddit.com/r/deeplearning/comments/s07sf1/weaviate_and_haystack/,0,1641779354.0,"This video explains my understanding of how to combine the functionality that Weaviate and Haystack have each built for Retrieve-then-Read pipelines and Neural Search

TLDR: Weaviate is a strong option for the Database end that plugs into a ""Pipeline"" in Haystack language. I think an especially interesting combination of these things will be Haystack's classifier to route between Symbolic and Neural search with Weaviate's integration of symbolic filtering in neural search (aka ANN indexing / HNSW)  


Video: [https://www.youtube.com/watch?v=kVHmtPYmdb4](https://www.youtube.com/watch?v=kVHmtPYmdb4)  


As a quick primer for beginners: Retrieve-then-Read refers to breaking down tasks into information retrieval and then reasoning over the query and retrieved information. So rather than answering a question with one model, you break it up into a model that gets relevant information and then another model that reasons over that retrieved information. They are generally optimized with different strategies (self-supervised for retrievers, supervised for readers). I think this approach has a very strong potential to get around the need for very large models and also enables increased interpretability and ease of updating information. 

Another video if interested on General Purpose Reading models (similar to the GPT-3 API but plugged into this decomposition of Retrieve-then-Read): [https://www.youtube.com/watch?v=mRcuNtMOmZw](https://www.youtube.com/watch?v=mRcuNtMOmZw)"
72,deeplearning,gpt-3,top,2023-05-23 14:14:45,New Weaviate Podcast - Unstructured!,CShorten,False,0.76,2,13ppstr,https://www.reddit.com/r/deeplearning/comments/13ppstr/new_weaviate_podcast_unstructured/,0,1684851285.0,"ChatWithPDF has been one of the most captivating applications of the latest wave of ChatGPT and pairing ChatGPT with Retrieval-Augmentation and Vector Databases! As exciting as this is, there is a glaring problem... how do I get the text data out of my PDFs?

This is the problem Unstructured is solving with 3 core abstractions: (1) Partitioning (visually looking at elements on a PDF / Webpage / Resume / Slidedeck / Receipt / ... extracting the text data and adding metadata such as ""header"", ""body"", or ""image caption"", (2) Cleaning (I'm sure everyone in this group who has worked with text data has seen these ridiculous character encoding problems, regex, and whitespace removals we need to clean our text data for NLP pipelines), and (3) Staging (this describes extracting the JSONs / etc. to pass this data into another system such as Weaviate as an example)

I really hope you enjoy the podcast -- I think these innovations are so exciting for unlocking our data into these LLM systems!

[https://www.youtube.com/watch?v=b84Q2cJ6po8](https://www.youtube.com/watch?v=b84Q2cJ6po8)"
73,deeplearning,gpt-3,top,2022-12-12 15:53:41,"GPT-Rex: A chrome extension to plug GPT-3 directly into Medium. Hit ""Ctrl + >"" to trigger auto-complete while writing. Available on Chrome web store. Support for other platforms coming soon.",hayAbhay,False,0.67,2,zk2ser,https://github.com/hayabhay/gpt-go,2,1670860421.0,
74,deeplearning,gpt-3,top,2023-10-04 15:06:32,Custom LLM,Relative_Winner_4588,False,1.0,2,16zpnjz,https://www.reddit.com/r/deeplearning/comments/16zpnjz/custom_llm/,0,1696431992.0,"
I'm eager to develop a Large Language Model (LLM) that emulates ChatGPT, tailored precisely to my specific dataset. While I'm aware of existing models like Private-GPT and Gpt4all, my ultimate goal is to either create a custom LLM from scratch or fine-tune a pre-existing model like BERT or GPT-7B to meet my unique requirements.

I've been closely following Andrej Karpathy's instructive lecture on building GPT-like models. However, I've noticed that the model only generated text akin to Shakespearean prose in a continuous loop instead of answering questions. I'm striving to develop an LLM that excels at answering questions based on the data I provide.

The core objectives I'm pursuing encompass:
1. Effective data preparation tailored for question-answering tasks.
2. The strategic selection of a pre-trained model, such as BERT or GPT-7B.
3. Rigorous performance evaluation, employing pertinent metrics.
4. The creation of an efficient inference system that facilitates question input and response generation.

Please guide me for this objectives or provide me some resources for the same.

DM me if you want to talk in detail."
75,deeplearning,gpt-3,top,2020-12-07 17:36:57,"[N] Open AI’s GPT-3 Paper Shares NeurIPS 2020 Best Paper Awards With Politecnico di Milano, CMU and UC Berkeley",Yuqing7,False,0.75,2,k8l6vi,https://www.reddit.com/r/deeplearning/comments/k8l6vi/n_open_ais_gpt3_paper_shares_neurips_2020_best/,0,1607362617.0,"OpenAI’s groundbreaking GPT-3 language model paper, a no-regret learning dynamics study from Politecnico di Milano & Carnegie Mellon University, and a UC Berkeley work on data summarization have been named the NeurIPS 2020 Best Paper Award winners. The organizing committee made the announcements this morning, along with their Test of Time Award, to kick off the thirty-fourth Conference on Neural Information Processing Systems.

NeurIPS 2020 continues through December 12. With 9,467 submitted papers, this has been another record-breaking year for NeurIPS — with 38 percent more paper submissions than 2019. A total of 1,903 papers were accepted, compared to 1,428 last year.

Over the course of the week, participants can virtually join the Expo, where top industry sponsors will provide talks, panels, and demos of academic interest. Tutorials will cover current lines of inquiry while general sessions will include talks, posters, and demonstrations. A full agenda can be found by visiting the [NeurIPS conference schedule page](https://neurips.cc/virtual/2020/public/cal_main.html).

Here is a quick read: [Open AI’s GPT-3 Paper Shares NeurIPS 2020 Best Paper Awards With Politecnico di Milano, CMU and UC](https://syncedreview.com/2020/12/07/open-ais-gpt-3-paper-shares-neurips-2020-best-paper-awards-with-politecnico-di-milano-cmu-and-uc-berkeley/)"
76,deeplearning,gpt-3,top,2021-11-22 12:51:54,Best way to explain chess strategies?,jssmith42,False,0.71,3,qzkqll,https://www.reddit.com/r/deeplearning/comments/qzkqll/best_way_to_explain_chess_strategies/,0,1637585514.0,"Which deep learning architecture or model would be ideal for suggesting chess moves and explaining the strategy behind them?

I.e. GPT-3 can document the code it generates, there’s an “explain this code” application. But it was trained on GitHub.

Has anyone trained a transformer on chess books or chess games, so that it can not only play them but explain them?"
77,deeplearning,gpt-3,top,2022-02-10 22:10:25,Course on GPT-3 and Transformers,godiswatching_,False,1.0,2,spift0,https://www.reddit.com/r/deeplearning/comments/spift0/course_on_gpt3_and_transformers/,1,1644531025.0,"Hello,   


I was wondering if anyone knows about resources for learning about GPT-3 and Transformer based AI.   Preferably some video series with some project but blogs are just as welcome.

&#x200B;

Thank you."
78,deeplearning,gpt-3,top,2020-06-01 02:41:47,GPT-3 research paper review,minsuk-heo,False,1.0,2,gucf8w,https://youtu.be/Mq97CF02sRY,0,1590979307.0,
79,deeplearning,gpt-3,top,2021-05-10 14:32:27,Hi All! On May 29th Nextgrid hosts the 3rd GPT-3 Hackathon in a collab with OpenAI. Details below.,techn0_cratic,False,0.67,3,n963qn,https://nextgrid.ai/,0,1620657147.0,
80,deeplearning,gpt-3,top,2022-05-16 16:17:25,OpenAI GPT-3 & Codex Hackathon - Deep Learning Labs Stockholm,zakrzzz,False,1.0,2,uqzmxs,https://www.reddit.com/r/deeplearning/comments/uqzmxs/openai_gpt3_codex_hackathon_deep_learning_labs/,0,1652717845.0," Hello everyone!

Join us this weekend for the Deep Learning Hackathon in Stockholm! We are teaming up with WeWork and OpenAI to bring you an event focused on exploring the latest AI technologies: GPT-3 and Codex. This is a great opportunity to learn, build cool stuff, and meet interesting people. All levels of experience are welcome.

So if you are in Stockholm this weekend, we'll be happy to have you! Also if you know someone who might be interested in participating, let them know, I would be very grateful!

And if you won't be in Stockholm, you can watch the event live at [https://www.twitch.tv/deeplearninglabs](https://www.twitch.tv/deeplearninglabs) We will have some interesting Keynote sessions, fireside chat, and of course teams' demo presentations.

Register here: [https://sthlm.dllhack.com/](https://sthlm.dllhack.com/)

If you have any questions, I'll be happy to answer."
81,deeplearning,gpt-3,top,2023-09-24 01:00:34,"Exploring ""Harm Filter for LLM"" as a Research in NLP",junkim100,False,1.0,1,16qkfjr,https://www.reddit.com/r/deeplearning/comments/16qkfjr/exploring_harm_filter_for_llm_as_a_research_in_nlp/,2,1695517234.0,"I'm currently considering a research topic for my combined masters/phd program in an NLP lab. I've been particularly intrigued by the challenges posed by Large Language Models (LLMs) when it comes to generating potentially harmful or inappropriate content. Given the recent ""jailbreaks"" on LLMs, where users have tried to bypass content filters, I believe there's a pressing need to delve deeper into this area.

For my research focus, I've been referring to it as ""Harm Filter for LLM."" However, I'm unsure if there's an established term for this specific area of study. It seems to encompass techniques to prevent models from generating harmful content and strategies to defend against adversarial attempts to bypass these filters.

I came across a few resources that shed light on this topic:

* [**GitHub Repository on LLM Prompt Injection Filtering**](https://github.com/derwiki/llm-prompt-injection-filtering/blob/main/README.md)
* [**Research Paper on Evaluating Large Language Models Trained on Code**](https://arxiv.org/pdf/2307.02483.pdf)
* [**Research Paper on ChatGPT: A Chatbot based on GPT-3.5**](https://arxiv.org/abs/2305.05027)

I have a few questions for the community:

1. Do you think ""Harm Filter for LLM"" (or whatever the established term might be) is a promising research area in NLP?
2. Is there a commonly used term for this field? Could it possibly fall under a broader category like ""Explainable AI""?
3. Any suggestions on where I can delve deeper into this topic?
4. Additionally, I'm also looking for resources to strengthen my foundational knowledge in NLP. Any recommendations would be greatly appreciated!"
82,deeplearning,gpt-3,top,2020-11-29 20:53:02,What is the hype about the GPT-3 transformer and what is real? (GPT3 paper deep dive),gordicaleksa,False,0.56,1,k3h2jj,https://youtu.be/fVt387VZJe8,1,1606683182.0,
83,deeplearning,gpt-3,top,2023-08-03 23:38:39,What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?,Claud1ao,False,0.67,1,15hjv2y,https://www.reddit.com/r/deeplearning/comments/15hjv2y/what_would_be_the_initial_costs_of_developing_a/,4,1691105919.0,"I was wondering if this would be super expensive or not.

The cost to develop GPT-3 was about $4 millions according to some resources online. 

Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?

Any answer is appreciated.

Thanks in advance."
84,deeplearning,gpt-3,top,2022-09-08 17:35:18,Using State-Of-The-Art Artificial Intelligence (AI) Models for Free: Try OPT-175B on Your Cellphone and Laptop,ai-lover,False,1.0,1,x96n5i,https://www.reddit.com/r/deeplearning/comments/x96n5i/using_stateoftheart_artificial_intelligence_ai/,0,1662658518.0,"When it comes to large AI models, remarkable performance in a wide range of applications often brings a big budget for hardware and running costs.  As a result, most AI users, like researchers from startups or universities, can do nothing but get overwhelmed by striking news about the cost of training large models.

Fortunately, because of the help from the open source community, serving large AI models became easy, affordable and accessible to most. 

### OPT-175B

To understand the technical principles of the big model inference we just experienced, first, let’s review the big model we just used.

The full name of OPT is *Open Pretrained Transformer*, which is a large-scale Transformer model (175 billion parameters) that has a similar performance to that of GPT-3.

[Continue reading](https://www.marktechpost.com/2022/09/08/using-state-of-the-art-artificial-intelligence-ai-models-for-free-try-opt-175b-on-your-cellphone-and-laptop/) | [Open Source Code](https://github.com/hpcaitech/ColossalAI) |[Cloud Service Entry](https://service.colossalai.org/)

&#x200B;

https://preview.redd.it/gi5e7d0u7om91.png?width=1024&format=png&auto=webp&s=bb276bb3aaeb9c9db28f97758c3546cbc1c623bf"
85,deeplearning,gpt-3,top,2021-11-24 20:45:14,Current best accessible solution to isolating sounds in an audio file?,MonmusuAficionado,False,1.0,1,r1erh9,https://www.reddit.com/r/deeplearning/comments/r1erh9/current_best_accessible_solution_to_isolating/,4,1637786714.0,"I have an audio file with a voice and other background sounds, I would like remove the voice from the audio, so I need a way detect it and isolate from everything else (other sounds share similar frequencies and I was told there is no easy traditional solution to this). Does anyone know of any models created for this purpose? What I mean by accessible is something I can either train myself (so something like GPT-3 would not be an option), or a pre-trained model available through some online service."
86,deeplearning,gpt-3,top,2023-02-02 20:16:45,1-click deploy for your GPT-3 App,VideoTo,False,0.67,1,10rzn7z,https://www.reddit.com/r/deeplearning/comments/10rzn7z/1click_deploy_for_your_gpt3_app/,0,1675369005.0,"Link - [https://github.com/ClerkieAI/berri\_ai](https://github.com/ClerkieAI/berri_ai)

We  made a package that makes it easy for developers to quickly deploy  their LLM Agent from Google Colab to production (Web App and API  Endpoint).

**How it works?**

Just install the package, import the function, and run deploy.

At the end of the deploy (\~10-15mins), you will get:

1. A web app to interact with your agent 👉  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/)
2. An endpoint you can query 👉  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/langchain_agent?query=%22who) is obama?""

Want a more detailed walkthrough? Check out our loom - [https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43](https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43)

We’re still early so would love your feedback and opinions. Feel free to try   us out for free – and if you need help building an agent / want a   specific integration, just let us know!

https://i.redd.it/s53l400o2ufa1.gif"
87,deeplearning,gpt-3,top,2020-09-12 12:27:55,Can GPT-3 really help you and your company? What can it really do? Real-World Applications Demo,OnlyProggingForFun,False,0.45,0,irbp5k,https://www.youtube.com/watch?v=Gm4AMjV8ErM,4,1599913675.0,
88,deeplearning,gpt-3,top,2020-09-04 22:59:41,[D] Is OpenAI’s GPT-3 API Beta Pricing Too Rich for Researchers?,Yuqing7,False,0.67,1,imqa78,https://www.reddit.com/r/deeplearning/comments/imqa78/d_is_openais_gpt3_api_beta_pricing_too_rich_for/,1,1599260381.0,"OpenAI’s 175 billion parameter language model GPT-3 (Generative Pre-trained Transformer 3) turned heads in the NLP community when it was released in June, and now it’s back in the spotlight. A Reddit [post](https://www.reddit.com/r/GPT3/comments/ikorgs/oa_api_preliminary_beta_pricing_announced/) this week by independent writer and researcher Gwern Branwen detailed the pricing plan OpenAI has provided to GPT-3 Beta API users. The scheme, which goes into effect on October 1, has already raised as many questions as it has answered.

Here is a quick read: [Is OpenAI’s GPT-3 API Beta Pricing Too Rich for Researchers?](https://syncedreview.com/2020/09/04/is-openais-gpt-3-api-beta-pricing-too-rich-for-researchers/)"
89,deeplearning,gpt-3,top,2020-07-30 13:37:36,[Tutorial] Generate Python code & Matplotlib graphs using GPT-3.,bhavesh91,False,0.57,1,i0m6cn,https://www.reddit.com/r/deeplearning/comments/i0m6cn/tutorial_generate_python_code_matplotlib_graphs/,0,1596116256.0,"I created a simple application which generates Python code & Matplotlib Graphs using GPT-3. If you want to learn how you can use OpenAI's GPT-3 to generate NLP Applications then this simple tutorial should help. Video Link : [https://www.youtube.com/watch?v=z8K07a2EIcE](https://www.youtube.com/watch?v=z8K07a2EIcE)

https://i.redd.it/u1gpz8bkzzd51.gif"
90,deeplearning,gpt-3,top,2020-09-22 12:43:33,Deconstructing the GPT-3 economy,bendee983,False,1.0,1,ixmmuy,/r/MachineLearning/comments/ix16bc/d_deconstructing_the_gpt3_economy/,0,1600778613.0,
91,deeplearning,gpt-3,top,2020-07-27 00:13:47,"OpenAI's New Language Generator: GPT-3. This AI Generates Code, Websites, Songs & More From Words",OnlyProggingForFun,False,0.5,0,hyhvqi,https://www.youtube.com/watch?v=gDDnTZchKec,1,1595808827.0,
92,deeplearning,gpt-3,top,2023-04-01 17:50:06,Fine-tune GPT on sketch data (stroke-3),mellamo_maria,False,1.0,1,128tfvc,https://www.reddit.com/r/deeplearning/comments/128tfvc/finetune_gpt_on_sketch_data_stroke3/,0,1680371406.0," These past days I have started a personal project where I would like to build a model that, given an uncompleted sketch, it can finish it. I was planning on using some pretrained models that are available in HuggingFace and fine-tune them with my sketch data for my task. The sketch data I have is in stoke-3 format, like the following example:  
\[  
\[10, 20, 1\],  
\[20, 30, 1\],  
\[30, 40, 1\],  
\[40, 50, 0\],  
\[50, 60, 1\],  
\[60, 70, 0\]  
\]  
The first value of each triple is the X-coordinate, the second value the Y-coordinate and the last value is a binary value indicating whether the pen is down (1) or up (0). I was wondering if you guys could give me some instruction/tips about how should I approach this problem? How should I prepare/preprocess the data so I can fit it into the pre-trained models like BERT, GPT, etc. Since it's stroke-3 data and not text or a sequence of numbers, I don't really know how should I treat/process the data.

Thanks a lot! :)"
93,deeplearning,gpt-3,top,2023-12-22 21:52:34,NeuralFlash - a flashcard-making GPT specializing in AI to help you study.,MachineScholar,False,0.67,1,18opxcs,https://www.reddit.com/r/deeplearning/comments/18opxcs/neuralflash_a_flashcardmaking_gpt_specializing_in/,0,1703281954.0,"Hey everyone. I'm a computer science student and I've been searching for the most efficient way to study ML concepts via Quizlet flashcards so I came up with a ""pipeline"" by making this custom GPT and feeding it my Markdown notes. Here's a little guide:

1. Take lecture/book notes in Markdown (I use obsidian to do this since it's free, fast, and open source)
2. Open up NeuralFlash and choose the ""Generate flashcards from my AI notes"" action.
3. Copy your entire Markdown note, paste it into NeuralFlash.
4. Copy the csv it outputs and paste it into the ""import"" area of your Quizlet flashcard set (make sure you select comma instead of tab).
5. Learn and succeed.

**Here the link to the GPT:** [**https://chat.openai.com/g/g-m4nFBaKA8-neuralflash**](https://chat.openai.com/g/g-m4nFBaKA8-neuralflash)"
94,deeplearning,gpt-3,top,2021-09-12 16:50:12,Blog Article Generator using Python and Machine Learning (GPT-2) in 3 lines of code,Pragyanbo,False,0.6,1,pmwbcs,https://youtu.be/e83oIgEVRa8,0,1631465412.0,
95,deeplearning,gpt-3,top,2020-07-22 01:19:40,GPT-3: A Hitchhiker's Guide,mippie_moe,False,0.67,1,hvka41,https://lambdalabs.com/blog/gpt-3/,0,1595380780.0,
96,deeplearning,gpt-3,top,2022-12-22 09:57:14,"Show ChatGPT's response next to the search results from Google, Bing, and DuckDuckGo.",Harrypham22,False,1.0,1,zsics7,https://www.reddit.com/r/deeplearning/comments/zsics7/show_chatgpts_response_next_to_the_search_results/,0,1671703034.0," **Do you know about ChatGPT?** 

It is a variant of the GPT-3 language model developed by OpenAI specifically designed for generating responses to user input in chat or messaging applications. It is trained on a large dataset of conversation data and is able to understand the context of a conversation and generate appropriate responses. ChatGPT is particularly well-suited for use in chat or messaging applications, but it can also be used for a wide range of other natural language processing tasks, such as language translation, summarization, and question answering.

**Display ChatGPT response alongside other search engine results (Google,Bing,Duck go go,..)**

***ChatGPT for Search Engines*** is an AI-based extension that could potentially become a real threat to any search engine.

It basically shows results to all sorts of queries next to the Google results (or other search engine). The precision is very impressive. This extension makes it possible everywhere you browse

This is a simple extension that show response from ChatGPT alongside Google and other search engines

Features:

\* Markdown rendering

\* Code hightlights

\* Feedback buttons

\* Custom trigger mode

Maybe you should try this extension: [shorturl.at/eqZ78](https://shorturl.at/eqZ78)

Watch this video to see how it work: [https://www.tiktok.com/@ai\_life26/video/7179865803003579674](https://www.tiktok.com/@ai_life26/video/7179865803003579674)

https://preview.redd.it/ojjxcy2q9f7a1.png?width=1294&format=png&auto=webp&s=e3b02aba9ba03f37dbdcd0a2c6265a95b9f11ed8"
97,deeplearning,gpt-3,top,2022-11-13 17:50:42,"Can we possibly get access to large language models (PaLM 540B, etc) like GPT-3 but no cost?",NLP2829,False,0.56,1,yu8oru,https://www.reddit.com/r/deeplearning/comments/yu8oru/can_we_possibly_get_access_to_large_language/,3,1668361842.0,"(I only want to do inference, I don't need to finetune it.)

I want to use very-large language model (#parameters > 100B) to do some experiments, is that true the only very-large language model we can get access to is GPT3 API? Can we possibly get access to PaLM and Flan-PaLM 540B with no cost by chance?

I have searched over the internet but can't find a definite answer. As GPT-3 pricing for text-davinci-2 is not cheap, I am wondering if there's a chance to use other models.

Also, I can request up to 372GB VRAM, is there any large language model (#parameters > 100B) that I can actually download and run ""locally""?"
98,deeplearning,gpt-3,top,2020-07-28 17:08:47,"GPT-3 use cases: English to design, code and more",przemekc,False,0.67,1,hziixh,https://youtu.be/tsuxlU5IwuA,0,1595956127.0,
99,deeplearning,gpt-3,top,2020-10-30 01:48:31,Generating Snort Rules using GPT2,afoteygh,False,1.0,1,jkntfp,https://www.reddit.com/r/deeplearning/comments/jkntfp/generating_snort_rules_using_gpt2/,0,1604022511.0,"Hi I have been working on Generating Snort rules using the GPT2 Transformer.

This is my thinking

1. Snort rules for a particular family of malware are quite related. that is why these malware have been classified into that family so using text generation to generate new rules should be possible (i Feel)
2. Collect Snort rules for a particular malware family. (Also collect pcap which trigger these specific rules i have obtained)
3. Clean it up by removing commented/unused rules.
4. Feed the rules to GPT2 (124M) (I chose this because i read it performs quite well in text generation )
5. Trained GPT on the dataset
6. using it to generated new rules
7. clean up the rules (syntax etc)
8. Test newly generated rules in snort with sample pcap files.

So for i have been able to generate and clean up 1000's of rules and tested them without any success!

Can anyone give me some guidance on what i am doing wrong or if my whole hypothesis and experiment is flawed."
100,deeplearning,gpt-3,comments,2023-03-25 04:24:49,Do we really need 100B+ parameters in a large language model?,Vegetable-Skill-9700,False,0.91,45,121agx4,https://www.reddit.com/r/deeplearning/comments/121agx4/do_we_really_need_100b_parameters_in_a_large/,54,1679718289.0,"DataBricks's open-source LLM, [Dolly](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html) performs reasonably well on many instruction-based tasks while being \~25x smaller than GPT-3, challenging the notion that is big always better?

From my personal experience, the quality of the model depends a lot on the fine-tuning data as opposed to just the sheer size. If you choose your retraining data correctly, you can fine-tune your smaller model to perform better than the state-of-the-art GPT-X. The future of LLMs might look more open-source than imagined 3 months back?

Would love to hear everyone's opinions on how they see the future of LLMs evolving? Will it be few players (OpenAI) cracking the AGI and conquering the whole world or a lot of smaller open-source models which ML engineers fine-tune for their use-cases?

P.S. I am kinda betting on the latter and building [UpTrain](https://github.com/uptrain-ai/uptrain), an open-source project which helps you collect that high quality fine-tuning dataset"
101,deeplearning,gpt-3,comments,2023-02-02 23:02:25,Why are FPGAs better than GPUs for deep learning?,Open-Dragonfly6825,False,1.0,19,10s3u1s,https://www.reddit.com/r/deeplearning/comments/10s3u1s/why_are_fpgas_better_than_gpus_for_deep_learning/,37,1675378945.0,"I've worked for some years developing scientific applications for GPUs. Recently we've been trying to integrate FPGAs into our technologies; and consequently I've been trying to understand what they are useful for.

I've found many posts here and there that claim that FPGAs are better suited than GPUs to accelerate Deep Learning/AI workloads (for example, [this one by Intel](https://www.intel.com/content/www/us/en/artificial-intelligence/programmable/fpga-gpu.html)). However, I don't understand why that would be the case. I think the problem is that all those posts try to explain what an FPGA is and what its differences are to a GPU, so that people that work on Deep Learning understand why they are better suited. Nevertheless, my position is exactly the opposite: I know quite well how a GPU works and what it is good for, I know well enough how an FPGA works and how it differs from a GPU, **but I do not know enough about Deep Learning** to understand why Deep Learning applicatios would benefit more from the special features of FPGAs rather than from the immense parallelism GPUs offers.

As far as I know, an FPGA will never beat a traditional GPU in terms of raw parallelism (or, if it does, it would be much less cost efficient). Thus, when it comes to matrix multiplications, i.e. the main operation in Deep Learning models, or convolutions, GPUs can parallelly work with much bigger matrices. The only explanation I can think of is that traditional Deep Learning applications don't necessarily use such big matrices, but rather smaller ones that can also be fully parallelized in FPGAs and benefit highly from custom-hardware optimizations (optimized matrix multiplications/tensor operations, working with reduced-bit values such as FP16, deep-pipeline parallelism, ...). However, given the recent increase in popularity of very complex models (GPT-3, dall-e, and the like) which boast using millions or even billions of parameters, it is hard to imagine that popular deep learning models work with small matrices of which fully parallel architectures can be synthesized in FPGAs.

What am I missing? Any insight will be greatly appreciated.

EDIT: I know TPUs are a thing and are regarded as ""the best option"" for deep learning acceleration. I will not be working with them, however, so I am not interested in knowing the details on how they compare with GPUs or FPGAs."
102,deeplearning,gpt-3,comments,2020-08-17 19:53:20,Personal GPT-3 project 🚀: Guess the movie! You can't recall the name of that movie you watched? You know what the movie's about but you just can't remember its name? I used the GPT-3 model to solve this problem! Just feed it a small description of the movie/tv show and it will do the rest.,CallmeMehdi25,False,0.96,116,iblhzl,https://i.redd.it/z12t847vamh51.gif,29,1597694000.0,
103,deeplearning,gpt-3,comments,2021-08-19 07:03:53,Dual 3090 vs A6000 + Intel vs AMD?,xKaiz3n,False,0.77,7,p79uhm,https://www.reddit.com/r/deeplearning/comments/p79uhm/dual_3090_vs_a6000_intel_vs_amd/,21,1629356633.0,"Hello,

I've been asked to spec out a machine for a range of DL tasks (inc. GPT-3/4 & classification etc.). Looking at prices here (AUS) it seems the price for 2x 3090s (AUD$3000 - 4000) is around the same price as 1x A6000 (AUD$7500 - 8500). 

I've gone into this with a fairly rudimentary understanding of both hardware at this level and deep learning (read: I'm a student & interning), so apologies if I've said something particularly silly.  I'm also looking to see if there are any recommendations for CPU's:

\- do DL packages have a preference for AMD vs Intel like they do with GPU's?

\- which CPU would you guys choose that won't bottleneck the GPUs?

&#x200B;

Thank you!"
104,deeplearning,gpt-3,comments,2023-01-27 10:45:48,⭕ What People Are Missing About Microsoft’s $10B Investment In OpenAI,LesleyFair,False,0.95,119,10mhyek,https://www.reddit.com/r/deeplearning/comments/10mhyek/what_people_are_missing_about_microsofts_10b/,16,1674816348.0,"&#x200B;

[Sam Altman Might Have Just Pulled Off The Coup Of The Decade](https://preview.redd.it/sg24cw3zekea1.png?width=720&format=png&auto=webp&s=9eeae99b5e025a74a6cbe3aac7a842d2fff989a1)

Microsoft is investing $10B into OpenAI!

There is lots of frustration in the community about OpenAI not being all that open anymore. They appear to abandon their ethos of developing AI for everyone, [free](https://openai.com/blog/introducing-openai/) of economic pressures.

The fear is that OpenAI’s models are going to become fancy MS Office plugins. Gone would be the days of open research and innovation.

However, the specifics of the deal tell a different story.

To understand what is going on, we need to peek behind the curtain of the tough business of machine learning. We will find that Sam Altman might have just orchestrated the coup of the decade!

To appreciate better why there is some three-dimensional chess going on, let’s first look at Sam Altman’s backstory.

*Let’s go!*

# A Stellar Rise

Back in 2005, Sam Altman founded [Loopt](https://en.wikipedia.org/wiki/Loopt) and was part of the first-ever YC batch. He raised a total of $30M in funding, but the company failed to gain traction. Seven years into the business Loopt was basically dead in the water and had to be shut down.

Instead of caving, he managed to sell his startup for $[43M](https://golden.com/wiki/Sam_Altman-J5GKK5) to the finTech company [Green Dot](https://www.greendot.com/). Investors got their money back and he personally made $5M from the sale.

By YC standards, this was a pretty unimpressive outcome.

However, people took note that the fire between his ears was burning hotter than that of most people. So hot in fact that Paul Graham included him in his 2009 [essay](http://www.paulgraham.com/5founders.html?viewfullsite=1) about the five founders who influenced him the most.

He listed young Sam Altman next to Steve Jobs, Larry & Sergey from Google, and Paul Buchheit (creator of GMail and AdSense). He went on to describe him as a strategic mastermind whose sheer force of will was going to get him whatever he wanted.

And Sam Altman played his hand well!

He parleyed his new connections into raising $21M from Peter Thiel and others to start investing. Within four years he 10x-ed the money \[2\]. In addition, Paul Graham made him his successor as president of YC in 2014.

Within one decade of selling his first startup for $5M, he grew his net worth to a mind-bending $250M and rose to the circle of the most influential people in Silicon Valley.

Today, he is the CEO of OpenAI — one of the most exciting and impactful organizations in all of tech.

However, OpenAI — the rocket ship of AI innovation — is in dire straights.

# OpenAI is Bleeding Cash

Back in 2015, OpenAI was kickstarted with $1B in donations from famous donors such as Elon Musk.

That money is long gone.

In 2022 OpenAI is projecting a revenue of $36M. At the same time, they spent roughly $544M. Hence the company has lost >$500M over the last year alone.

This is probably not an outlier year. OpenAI is headquartered in San Francisco and has a stable of 375 employees of mostly machine learning rockstars. Hence, salaries alone probably come out to be roughly $200M p.a.

In addition to high salaries their compute costs are stupendous. Considering it cost them $4.6M to train GPT3 once, it is likely that their cloud bill is in a very healthy nine-figure range as well \[4\].

So, where does this leave them today?

Before the Microsoft investment of $10B, OpenAI had received a total of $4B over its lifetime. With $4B in funding, a burn rate of $0.5B, and eight years of company history it doesn’t take a genius to figure out that they are running low on cash.

It would be reasonable to think: OpenAI is sitting on ChatGPT and other great models. Can’t they just lease them and make a killing?

Yes and no. OpenAI is projecting a revenue of $1B for 2024. However, it is unlikely that they could pull this off without significantly increasing their costs as well.

*Here are some reasons why!*

# The Tough Business Of Machine Learning

Machine learning companies are distinct from regular software companies. On the outside they look and feel similar: people are creating products using code, but on the inside things can be very different.

To start off, machine learning companies are usually way less profitable. Their gross margins land in the 50%-60% range, much lower than those of SaaS businesses, which can be as high as 80% \[7\].

On the one hand, the massive compute requirements and thorny data management problems drive up costs.

On the other hand, the work itself can sometimes resemble consulting more than it resembles software engineering. Everyone who has worked in the field knows that training models requires deep domain knowledge and loads of manual work on data.

To illustrate the latter point, imagine the unspeakable complexity of performing content moderation on ChatGPT’s outputs. If OpenAI scales the usage of GPT in production, they will need large teams of moderators to filter and label hate speech, slurs, tutorials on killing people, you name it.

*Alright, alright, alright! Machine learning is hard.*

*OpenAI already has ChatGPT working. That’s gotta be worth something?*

# Foundation Models Might Become Commodities:

In order to monetize GPT or any of their other models, OpenAI can go two different routes.

First, they could pick one or more verticals and sell directly to consumers. They could for example become the ultimate copywriting tool and blow [Jasper](https://app.convertkit.com/campaigns/10748016/jasper.ai) or [copy.ai](https://app.convertkit.com/campaigns/10748016/copy.ai) out of the water.

This is not going to happen. Reasons for it include:

1. To support their mission of building competitive foundational AI tools, and their huge(!) burn rate, they would need to capture one or more very large verticals.
2. They fundamentally need to re-brand themselves and diverge from their original mission. This would likely scare most of the talent away.
3. They would need to build out sales and marketing teams. Such a step would fundamentally change their culture and would inevitably dilute their focus on research.

The second option OpenAI has is to keep doing what they are doing and monetize access to their models via API. Introducing a [pro version](https://www.searchenginejournal.com/openai-chatgpt-professional/476244/) of ChatGPT is a step in this direction.

This approach has its own challenges. Models like GPT do have a defensible moat. They are just large transformer models trained on very large open-source datasets.

As an example, last week Andrej Karpathy released a [video](https://www.youtube.com/watch?v=kCc8FmEb1nY) of him coding up a version of GPT in an afternoon. Nothing could stop e.g. Google, StabilityAI, or HuggingFace from open-sourcing their own GPT.

As a result GPT inference would become a common good. This would melt OpenAI’s profits down to a tiny bit of nothing.

In this scenario, they would also have a very hard time leveraging their branding to generate returns. Since companies that integrate with OpenAI’s API control the interface to the customer, they would likely end up capturing all of the value.

An argument can be made that this is a general problem of foundation models. Their high fixed costs and lack of differentiation could end up making them akin to the [steel industry](https://www.thediff.co/archive/is-the-business-of-ai-more-like-steel-or-vba/).

To sum it up:

* They don’t have a way to sustainably monetize their models.
* They do not want and probably should not build up internal sales and marketing teams to capture verticals
* They need a lot of money to keep funding their research without getting bogged down by details of specific product development

*So, what should they do?*

# The Microsoft Deal

OpenAI and Microsoft [announced](https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/) the extension of their partnership with a $10B investment, on Monday.

At this point, Microsoft will have invested a total of $13B in OpenAI. Moreover, new VCs are in on the deal by buying up shares of employees that want to take some chips off the table.

However, the astounding size is not the only extraordinary thing about this deal.

First off, the ownership will be split across three groups. Microsoft will hold 49%, VCs another 49%, and the OpenAI foundation will control the remaining 2% of shares.

If OpenAI starts making money, the profits are distributed differently across four stages:

1. First, early investors (probably Khosla Ventures and Reid Hoffman’s foundation) get their money back with interest.
2. After that Microsoft is entitled to 75% of profits until the $13B of funding is repaid
3. When the initial funding is repaid, Microsoft and the remaining VCs each get 49% of profits. This continues until another $92B and $150B are paid out to Microsoft and the VCs, respectively.
4. Once the aforementioned money is paid to investors, 100% of shares return to the foundation, which regains total control over the company. \[3\]

# What This Means

This is absolutely crazy!

OpenAI managed to solve all of its problems at once. They raised a boatload of money and have access to all the compute they need.

On top of that, they solved their distribution problem. They now have access to Microsoft’s sales teams and their models will be integrated into MS Office products.

Microsoft also benefits heavily. They can play at the forefront AI, brush up their tools, and have OpenAI as an exclusive partner to further compete in a [bitter cloud war](https://www.projectpro.io/article/aws-vs-azure-who-is-the-big-winner-in-the-cloud-war/401) against AWS.

The synergies do not stop there.

OpenAI as well as GitHub (aubsidiary of Microsoft) e. g. will likely benefit heavily from the partnership as they continue to develop[ GitHub Copilot](https://github.com/features/copilot).

The deal creates a beautiful win-win situation, but that is not even the best part.

Sam Altman and his team at OpenAI essentially managed to place a giant hedge. If OpenAI does not manage to create anything meaningful or we enter a new AI winter, Microsoft will have paid for the party.

However, if OpenAI creates something in the direction of AGI — whatever that looks like — the value of it will likely be huge.

In that case, OpenAI will quickly repay the dept to Microsoft and the foundation will control 100% of whatever was created.

*Wow!*

Whether you agree with the path OpenAI has chosen or would have preferred them to stay donation-based, you have to give it to them.

*This deal is an absolute power move!*

I look forward to the future. Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

*Thank you for reading!*

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] [https://golden.com/wiki/Sam\_Altman-J5GKK5](https://golden.com/wiki/Sam_Altman-J5GKK5)​

\[2\] [https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny](https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny)​

\[3\] [Article in Fortune magazine ](https://fortune.com/2023/01/11/structure-openai-investment-microsoft/?verification_code=DOVCVS8LIFQZOB&_ptid=%7Bkpdx%7DAAAA13NXUgHygQoKY2ZRajJmTTN6ahIQbGQ2NWZsMnMyd3loeGtvehoMRVhGQlkxN1QzMFZDIiUxODA3cnJvMGMwLTAwMDAzMWVsMzhrZzIxc2M4YjB0bmZ0Zmc0KhhzaG93T2ZmZXJXRDFSRzY0WjdXRTkxMDkwAToMT1RVVzUzRkE5UlA2Qg1PVFZLVlpGUkVaTVlNUhJ2LYIA8DIzZW55eGJhajZsWiYyYTAxOmMyMzo2NDE4OjkxMDA6NjBiYjo1NWYyOmUyMTU6NjMyZmIDZG1jaOPAtZ4GcBl4DA)​

\[4\] [https://arxiv.org/abs/2104.04473](https://arxiv.org/abs/2104.04473) Megatron NLG

\[5\] [https://www.crunchbase.com/organization/openai/company\_financials](https://www.crunchbase.com/organization/openai/company_financials)​

\[6\] Elon Musk donation [https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research](https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research)​

\[7\] [https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/](https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/)"
105,deeplearning,gpt-3,comments,2022-12-02 01:35:02,GPT-3 Generated Rap Battle between Yann LeCun & Gary Marcus,hayAbhay,False,0.99,139,za73dc,https://i.redd.it/ybfcfvez1e3a1.png,16,1669944902.0,
106,deeplearning,gpt-3,comments,2021-10-09 12:58:48,Research proposal feedback,KAKA7861111,False,0.39,0,q4ktyi,https://www.reddit.com/r/deeplearning/comments/q4ktyi/research_proposal_feedback/,15,1633784328.0," 

Hi everyone.

I need your feedback on this. I am writing a research proposal. The topic is Coding AI:

1. I am proposing a solution to train a GPT-3 for code optimization. like input would be code and output would be optimized code in terms of latency and big o notation.

Any related literate. feedback on approach"
107,deeplearning,gpt-3,comments,2020-09-18 10:45:02,GPT-3: new AI can write like a human but don't mistake that for thinking – neuroscientist,PowerOfLove1985,False,0.84,43,iv3rnz,https://theconversation.com/gpt-3-new-ai-can-write-like-a-human-but-dont-mistake-that-for-thinking-neuroscientist-146082,14,1600425902.0,
108,deeplearning,gpt-3,comments,2023-01-22 19:11:36,Apple M2 Max 96 GB unified memory for larger models vs multiple 24GB GPUs or 40GB A100s?,lol-its-funny,False,1.0,23,10irh5u,https://www.reddit.com/r/deeplearning/comments/10irh5u/apple_m2_max_96_gb_unified_memory_for_larger/,14,1674414696.0,"How feasible is it to use an Apple Silicon M2 Max, which has about [96 GB unified memory](https://www.apple.com/shop/buy-mac/macbook-pro/16-inch-space-gray-apple-m2-max-with-12-core-cpu-and-38-core-gpu-1tb) for ""large model"" deep learning? I'm inspired by the the [Chinchilla](https://arxiv.org/abs/2203.15556) paper that shows a lot of promise at 70B parameters. Outperforming ultra large models like Gopher (280B) or GPT-3 (175B) there is hope for working with < 70B parameters without needing a super computer. At least for fine tuning. I've been working with GPT-J but want to scale/tinker with larger open-sourced models.

However, I don't know how clearly the CompSci theory (M2 Max's 38-core GPU, 16 core Neural Engine accessing 96 GB unified memory) maps out to the IT reality (toolkits and libraries on macOS actually using it). My exposure is mostly around Jupyter books on Colab Pro+ (A100s) and nvidia 3080 GPUs (locally). 

I appreciate your guidance."
109,deeplearning,gpt-3,comments,2023-01-19 07:55:49,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.9,72,10fw22o,https://www.reddit.com/r/deeplearning/comments/10fw22o/gpt4_will_be_500x_smaller_than_people_think_here/,11,1674114949.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/xvpw1erngyca1.png?width=575&format=png&auto=webp&s=d7bea7c6132081f2df7c950a0989f398599d6cae)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you. At **TheDecoding** ⭕, I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
110,deeplearning,gpt-3,comments,2022-11-03 23:55:15,BlogNLP: AI Writing Tool,britdev,False,1.0,37,ylj1ux,https://www.reddit.com/r/deeplearning/comments/ylj1ux/blognlp_ai_writing_tool/,9,1667519715.0,"Hey everyone,

I created this web app using Open AI's GPT-3 (Davinci model). The purpose here is to provide a free tool to allow people to generate blog content/outlines/headlines and help with writer's block. Will continue to improve it over time, but just a side project I figured would provide some value to you all. Hope you all enjoy and please share ❤️

[https://www.blognlp.com/](https://www.blognlp.com/)"
111,deeplearning,gpt-3,comments,2021-06-14 06:34:33,"This Chinese Super Scale Intelligence Model, ‘Wu Dao 2.0’, Claims To Be Trained Using 1.75 Trillion Parameters, Surpassing All Prior Models to Achieve a New Breakthrough in Deep Learning",ai-lover,False,0.87,34,nzgkj3,https://www.reddit.com/r/deeplearning/comments/nzgkj3/this_chinese_super_scale_intelligence_model_wu/,9,1623652473.0,"Deep learning is one area of technology where ambitiousness has no barriers. According to a recent announcement by [The Beijing Academy of Artificial Intelligence (BAAI)](https://www.baai.ac.cn/), in China, yet another milestone has been achieved in the field with its “Wu Dao” AI system. The [GPT 3](https://www.marktechpost.com/2020/08/02/gpt-3-a-new-breakthrough-in-language-generator/) brought in new interest for all the AI researchers, the super scale pre training models. By this approach and making use of 175 billion parameters, it managed to achieve exceptional performance results across the natural language processing tasks (NLP). However, the lacking component is its inability to have any form of cognitive abilities or common sense. Therefore, despite the size, even these models cannot indulge in tasks such as open dialogues, visual reasoning, and so on. With Wu Dao, the researchers plan to address this issue. This is China’s first attempt at a home-grown super-scale intelligent model system. 

Article: [https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/](https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/?_ga=2.13897584.636390090.1623335762-488125022.1618729090)

Reference: [https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/](https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/)"
112,deeplearning,gpt-3,comments,2023-02-21 11:06:33,I created a Search Engine For Books using GPT-3 🔎📘. Here's how you can create it too:,Pritish-Mishra,False,0.71,6,1180x0e,https://youtu.be/SXFP4nHAWN8,8,1676977593.0,
113,deeplearning,gpt-3,comments,2023-04-08 07:55:07,need help. GPT-3.5 can't solve it.,ryanultralifeio,False,0.25,0,12ff87f,https://www.reddit.com/r/deeplearning/comments/12ff87f/need_help_gpt35_cant_solve_it/,8,1680940507.0,"Trying to make a schedule for the league, here are the constraints.  I think it should be tailormade for AI.


Schedule May 2023 Games.

￼￼

I need you to schedule games between 7 teams, on 4 fields, beginning on Monday May 1st for the whole month of May 2023. 

The 4 fields are; Quincy, Portola, Chester and Loyalton. Fields in Quincy, Portola and Loyalton are available beginning May 1st. The field in Chester is available beginning May 8th.

 Saturdays can have 3 games per day at either 10am, 1pm, or 4 pm. 

No games on Sunday. 

Monday, Tuesday, Wednesday, Thursday, and Friday games are at 5:00. 

Mondays, Tuesdays, Wednesdays, Thursdays, and Fridays can have games played on 3 different fields at the same time. 

There are 7 teams. Quincy Red, Quincy Blue, Quincy Grey, Portola Padres, Portola Dodgers, Chester Giants and Loyalton. 

All teams can only play each other 2 times in May with the exceptions of Quincy Grey and Quincy Red, Quincy Grey and Quincy Blue, and Quincy Grey and Chester Giants, who can only play each other 1 time in May. 

Only Loyalton cannot play on May 3,4, or 5 for Sierra Nevada Journeys. 

All teams are unavailable to play May 26,27,29 for Memorial Day Weekend. 

All teams are unavailable to play May 17,18,19 for 6th grade field trip. 

Each team will play one home game against each other, except for the teams only playing one game. 

Quincy Blue only plays home games on Quincy field on Mondays, and Thursdays. 

Quincy Grey only plays home games on Quincy field on Wednesdays, and Fridays. 

Quincy Red only plays home games on Quincy Field on Tuesdays, Thursdays, and Fridays. 

Loyalton only plays home games on Loyalton field. 

Chester Giants only play Home Games on Chester field. 

Portola Padres only play home games on Portola field. 

Portola Dodgers only play home games on Portola field. 

Each team can play a maximum of two games per week. 

A team cannot play without two calenders days between games. 

A team cannot play two games on consecutive days.

A team cannot play two games on the same day. 

Teams must have at least 9 games.

Put the total number of games played per team at the bottom of the whole months schedule.

2+ hours a no good results........."
114,deeplearning,gpt-3,comments,2023-10-26 17:59:49,Long text summarization tool how-to (700+ pages),Old_Swan8945,False,0.85,9,17h2fbk,https://www.reddit.com/r/deeplearning/comments/17h2fbk/long_text_summarization_tool_howto_700_pages/,8,1698343189.0,"Hey all I've seen a bunch of posts about summarization of long texts and seems like there's been a lot of challenges, so wanted to spread some knowledge out there about some things I've discovered as I launched my tool here ([summarize-article.co](https://summarize-article.co)) (longest text was a psych book from one of my users at 700+ pages).

The most basic problem in the summarization process is the GPT context window length, so the basic strategy I follow is the following:

1. Chunk the text into chunks that fit inside the context window
2. Recursively summarize the summaries until it becomes manageable
3. Use a long context-window model to generate the final summary using a prompt that takes the recursively-generated summaries and re-restructures the output
4. Additional prompt magic to optimize the outputs (DM me for more details :D)

Anyway, would appreciate any feedback on the results or anything you think could be improved, otherwise feel free to check it out or msg me if you want to learn more about how it works!"
115,deeplearning,gpt-3,comments,2023-02-05 16:44:56,Beat GPT-3 which has unlimited money using Open Source community,koyo4ever,False,0.79,22,10ugxmc,https://www.reddit.com/r/deeplearning/comments/10ugxmc/beat_gpt3_which_has_unlimited_money_using_open/,8,1675615496.0,"Is it technically possible to train some model using a lot of personal computers like a cluster.

Eg: an Algorithm to train tiny parts of some model using personal computer of volunteers. Like a community that makes your gpu capacity available, even if it's little.

The idea is train tiny parts of a model, with a lot of volunteers, then bring it together to make some powerful deepmind.

Can this model beat a lot of money spent in models like GPT-3?"
116,deeplearning,gpt-3,comments,2024-01-05 08:27:31,6 ways AI can make your life easier in 2024,PoetryOne4804,False,0.33,0,18z212l,https://www.reddit.com/r/deeplearning/comments/18z212l/6_ways_ai_can_make_your_life_easier_in_2024/,8,1704443251.0,"Artificial intelligence is developing every day. ChatGPT was a game changer for millions of people, but it is not the only one. Advances in AI are coming, and they're coming FAST. Very fast. There’re so many tasks AI can help with and make this year less stressful. Let me show you these ways:

**1) Chatbots for answering questions and brainstorming**

Except ChatGPT, you can use Google Bard, SpinBot, and YouChat.

**2) AI Essay writers**

Many people use [essay writing services](https://www.reddit.com/r/deeplearning/comments/16gnuwy/best_essay_writing_services_top_5/) but not all think that AI can also help in academic writing. AI essay writers like [Textero.ai](https://Textero.ai) can be faster and generate ideas or find sources for your topic.

**3) Daily life tools**

There’re AI planners to schedule meetings and integrate with your calendars. You can also keep track of finances using PocketGuard, Wally, or Cleo.

**4) Tools for social networks**

There’re various AI tools tailored for social networks, such as Postwise for Twitter posts and Steve.ai for YouTube.

**5) Tools to improve health and fitness goals**

AI tools like Apple Watches and Fitbits can monitor your fitness and health. They can even track your sleep and offer suggestions to improve sleep quality.

**6) Tools for academic needs**

Even though some professors are against using AI while studying, students look for ways to make academic life easier. Useful tools for school life you can find here:  [ai tools for students](https://www.reddit.com/r/artificial/comments/1716t0y/ai_tools_for_students_from_ai_essay_generators_to/)

Any other tools to share? Feel free to write about them, I’m ready to try more new services."
117,deeplearning,gpt-3,comments,2023-03-05 11:10:56,LLaMA model parallelization and server configuration,ChristmasInOct,False,0.97,24,11ium8l,https://www.reddit.com/r/deeplearning/comments/11ium8l/llama_model_parallelization_and_server/,8,1678014656.0,"Hey everyone,

First of all, tldr at bottom, typed more than expected here.  

Please excuse the rather naive perspective I have here.  I've followed along with great interest, but this is not my industry.

Regardless, I have spent the past 3-4 days falling down a brutally obsessive rabbit hole, and I cannot seem to find this information.  I'm assuming it's just that I am missing context of course, and regardless of whether there is a clear answer, I'm trying to get a better understanding of this topic so that I could better appraise the situation myself.

Really I suppose I have two questions.  **The first** is regarding model parallelization.

I'm assuming this is not generic whatsoever.  What is the typical process engineers go about for designing such a pipeline?  Specifically in regards to these new LLaMA models, is something like ALPA relevant?  Deepspeed?

More importantly, what information should I be seeking to determine this myself?

This roughly segues to my **second inquiry**.

The reason I'm curious about splitting the model pipeline etc., is that I am potentially in interested in standing a server up for this.  Although I don't have much of a budget for this build (\~$30-40K is the rough top-end, but I'd be a lot happier around $20-25K), the money is there if I can genuinely satisfy my use-case.

I work at a small, but borderline manic startup working on enterprise software; 90% of the work we're doing based in the react/node ecosystem, some low-level work for backend services, and some very interesting database work that I have very little to do with.  I am a fullstack engineer that grew up playing with C++ => C#, and somehow ended up spending all of my time r/w'ing javascript.  Lol.  Anyways.

Part of our roadmap since GPT-3 and the playground were made publicly accessible, involves usage of these transformer models, and their ability to interpret natural language inputs, whether from user inputs, or scraped input values generated somewhere in a chain of requests / operations.

Seeing GPT-3 in action made me specifically realize that my estimations on this technology had been wildly off.  Seeing ChatGPT in action and uptick, the API's becoming available, has me further panicked.

Running our inference through their API has never really been an option for us.  I haven't even really looked that far into it, but bottom line the data running through our platform is all back-office, highly sensitive business information, and many have agreements explicitly restricting the movement of data to or from any cloud services, with Microsoft, Amazon, and Google all specifically mentioned.

Regardless of the reasoning for these contracts, the LLaMA release has had me obsessed over this topic in more detail than before, and whether or not I would be able to get this setup privately, for our use-case.

**To get to the actual second inquiry**:

Say I want to throw a budget rig together for this in a server cabinet.  Am I able to effectively parallelize the LLaMA model, well enough to justify going with 24GB VRAM 4090's in the rig?  Say I do so with DeepSpeed, or some of the standard model parallelization libraries.

Is the performance cost low enough to justify taking the extra compute here over 1/3 - 1/2 as many RTX6000 ADA's?

Or should I be grabbing the 48GB ADA's?

Like I said, I apologize for the naivety, I'm really looking for more information so that I can start to put this picture together better on my own.  It really isn't the easiest topic to research with how quickly things seem to move, and the giant gap between conversation depths (gamer || phd in a lot of the most interesting or niche discussions, little between).

Thank you very much for your time.

TL;DR - Any information on LLaMA model parallelization at the moment?  Will it be compatible with things like zero or alpa?  How about for throwing a rig together right now for fine-tuning and then running inference on the LLaMA models?  48GB 6000 ADA's, or 24GB 4090's?

Planning on putting it in a mostly empty 42U cabinet that also houses our primary web server and networking hardware, so if there is a sales pitch for 4090's across multiple nodes here, I do have a massive bias as the kind of nerd that finds that kind of hardware borderline erotic.

Hydro and cooling are not an issue, just usage of the budget and understanding the requirements / approach given memory limitations, and how to avoid communication bottlenecks or even balance them against raw compute.

Thanks again everyone!"
118,deeplearning,gpt-3,comments,2022-12-03 19:29:01,BlogNLP: AI Blog Writing Tool,britdev,False,0.88,12,zboc8w,https://www.reddit.com/r/deeplearning/comments/zboc8w/blognlp_ai_blog_writing_tool/,7,1670095741.0,"Hey everyone,

I developed this web app with Open AI's GPT-3 to provide a free, helpful resource for generating blog content, outlines, and more - so you can beat writer's block! I'm sure you'll find it useful and I'd really appreciate it if you shared it with others ❤️.

[https://www.blognlp.com/](https://www.blognlp.com/)"
119,deeplearning,gpt-3,comments,2023-07-29 20:02:45,"Promptify 2.0: More Structured, More Powerful LLMs with Prompt-Optimization, Prompt-Engineering, and Structured Json Parsing with GPT-n Models! 🚀",StoicBatman,False,0.75,4,15d1fs8,https://www.reddit.com/r/deeplearning/comments/15d1fs8/promptify_20_more_structured_more_powerful_llms/,6,1690660965.0,"Hello fellow coders and AI enthusiasts!

First up, a huge Thank You for making Promptify a hit with **over** [**2.3k+ stars on Github**](https://github.com/promptslab/Promptify) ! 🌟

Back in 2022, we were the first one to tackle the common challenge of uncontrolled, unstructured outputs from large language models like GPT-3. , and your support has pushed us to keep improving.Today, we're thrilled to share some major updates that make Promptify even more powerful

&#x200B;

https://preview.redd.it/29ajik9xmyeb1.png?width=1510&format=png&auto=webp&s=3c3bfeebd6ba5e878885b079510a8972cc72c3b8

&#x200B;

* **Unified Architecture 🧭**: Introducing Prompter, Model & Pipeline Solution
* **Detailed Output Logs 📔**: Comprehensive structured JSON format output within the log folder.
* **Wider Model Support 🤝**: Supporting models from OpenAI, Azure, Cohere, Anthropic, Huggingface and more - think of it as your universal language model adapter.
* **Robust Parser 🦸‍♂️**: Parser to handle incomplete or unstructured JSON outputs from any LLMs.
* **Ready-Made Jinja Templates 📝**: Jinja prompt templates for NER, Text Classification, QA, Relation-Extraction, Tabular data, etc.
* **Database Integration 🔗**: Soon, Promptify directly to Mongodb integration. Stay tuned!
* **Effortless Embedding Generation 🧬**: Generate embeddings from various LLMs effortlessly with the new update.

&#x200B;

https://preview.redd.it/k50gmbxymyeb1.png?width=2160&format=png&auto=webp&s=ef063a7a0594eccac5674bd60d7adce193eecc3f

Check out the examples and take Promptify for a spin on GitHub. If you like what you see, we'd be honored if you gave us a star!

* **Github**: [https://github.com/promptslab/Promptify](https://github.com/promptslab/Promptify)
* **Colab:** [Try Now on Colab](https://colab.research.google.com/drive/16DUUV72oQPxaZdGMH9xH1WbHYu6Jqk9Q?usp=sharing)
* **Explore Other Cool Open Source LLM Tools:** [https://github.com/promptslab](https://github.com/promptslab)

Join **1.6k+ Promptify users on Discord** to dive deep into prompt engineering, discuss the latest with LLMs, and advance NLP research together: [https://discord.com/invite/m88xfYMbK6](https://discord.com/invite/m88xfYMbK6)Thank you again for your support - here's to more structured AI!

&#x200B;"
120,deeplearning,gpt-3,comments,2021-07-15 17:06:55,"EleutherAI Researchers Open-Source GPT-J, A Six-Billion Parameter Natural Language Processing (NLP) AI Model Based On GPT-3",techsucker,False,1.0,57,okx5hm,https://www.reddit.com/r/deeplearning/comments/okx5hm/eleutherai_researchers_opensource_gptj_a/,5,1626368815.0,"[GPT-J](https://www.eleuther.ai/), a six-billion-parameter natural language processing (NLP) AI model based on GPT-3, has been open-sourced by a team of EleutherAI researchers. The model was trained on an open-source text [dataset of 800GB](https://pile.eleuther.ai/) and was comparable with a GPT-3 model of similar size.

The model was trained using Google Cloud’s v3-256 TPUs using EleutherAI’s Pile dataset, which took about five weeks. GPT-J achieves accuracy similar to OpenAI’s reported findings for their 6.7B parameter version of GPT-3 on standard NLP benchmark workloads. The model code, pre-trained weight files, a Colab notebook, and a sample web page are included in EleutherAI’s release.

Story: [https://www.marktechpost.com/2021/07/15/eleutherai-researchers-open-source-gpt-j-a-six-billion-parameter-natural-language-processing-nlp-ai-model-based-on-gpt-3/](https://www.marktechpost.com/2021/07/15/eleutherai-researchers-open-source-gpt-j-a-six-billion-parameter-natural-language-processing-nlp-ai-model-based-on-gpt-3/) 

Github repository for GPT-J: https://github.com/kingoflolz/mesh-transformer-jax

Colab Notebook: https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab\_demo.ipynb

Web Demo: https://6b.eleuther.ai/"
121,deeplearning,gpt-3,comments,2020-07-28 12:31:26,GPT-3 writes my SQL queries for me,Independent-Square32,False,0.87,56,hzdthe,https://youtu.be/WlMHYEFt2uA,5,1595939486.0,
122,deeplearning,gpt-3,comments,2023-12-28 21:36:23,"The best current models (Dolphin, Mixtral, Solar, Noromaid) and where to try them",Horror_Echo6243,False,0.78,5,18t59yu,https://www.reddit.com/r/deeplearning/comments/18t59yu/the_best_current_models_dolphin_mixtral_solar/,5,1703799383.0," 

I just saw a lot of people talking about this models so if you want to test them i found this websites that have all of them

\- [infermatic.ai](https://infermatic.ai/) (all of them)

\- [https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0](https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0) (for solar)

\- [https://huggingface.co/chat](https://huggingface.co/chat) (for mixtral)

Let me know if you find more, I'd like to know

And heres a little resume if you don't know what each model is for

Dolphin : An uncensored model derived from an open-source dataset, it uses instructions from FLANv2 enhanced with GPT-4 and GPT-3.5 completions​​.

Mixtral : An advanced text generation model using a Mix of Experts architecture

Solar : domain specialization and optimization. It's recognized for its high performance and efficiency

Noromaid: Storywriting and roleplay"
123,deeplearning,gpt-3,comments,2023-08-03 23:38:39,What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?,Claud1ao,False,0.67,1,15hjv2y,https://www.reddit.com/r/deeplearning/comments/15hjv2y/what_would_be_the_initial_costs_of_developing_a/,4,1691105919.0,"I was wondering if this would be super expensive or not.

The cost to develop GPT-3 was about $4 millions according to some resources online. 

Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?

Any answer is appreciated.

Thanks in advance."
124,deeplearning,gpt-3,comments,2021-11-24 20:45:14,Current best accessible solution to isolating sounds in an audio file?,MonmusuAficionado,False,1.0,1,r1erh9,https://www.reddit.com/r/deeplearning/comments/r1erh9/current_best_accessible_solution_to_isolating/,4,1637786714.0,"I have an audio file with a voice and other background sounds, I would like remove the voice from the audio, so I need a way detect it and isolate from everything else (other sounds share similar frequencies and I was told there is no easy traditional solution to this). Does anyone know of any models created for this purpose? What I mean by accessible is something I can either train myself (so something like GPT-3 would not be an option), or a pre-trained model available through some online service."
125,deeplearning,gpt-3,comments,2020-09-12 12:27:55,Can GPT-3 really help you and your company? What can it really do? Real-World Applications Demo,OnlyProggingForFun,False,0.5,0,irbp5k,https://www.youtube.com/watch?v=Gm4AMjV8ErM,4,1599913675.0,
126,deeplearning,gpt-3,comments,2020-06-10 20:36:33,"GPT-3: The $4,600,000 Language model",mippie_moe,False,0.82,7,h0jm54,https://lambdalabs.com/blog/demystifying-gpt-3/,4,1591821393.0,
127,deeplearning,gpt-3,comments,2021-11-26 18:59:22,Music generation toolbox,wingedsheep38,False,0.67,3,r2u8oi,https://www.reddit.com/r/deeplearning/comments/r2u8oi/music_generation_toolbox/,4,1637953162.0,"This year I joined the team ""Lovelace and the machines"" for the AI Song Contest 2021. With the goal of using algorithms / machine learning to generate music, and then team up with musicians to create an actual song. We used a combination of GPT-3 for the lyrics and a music transformer implementation for the notes, and a bunch of other techniques for analyzing and rating the results or generating variations. It was a really cool challenge and our team ended up in second place with our song ""[Quantum trap](https://www.youtube.com/watch?v=YSn5pBdFjS4)"". I wrote a [blogpost](https://wingedsheep.com/music-generation-creating-a-song-for-the-ai-song-contest-2021/) about it for those interested in the details.

I created a project for the music generation tools that we used, so other people who are interested can experiment with it. You can find it here: [https://github.com/wingedsheep/music-generation-toolbox](https://github.com/wingedsheep/music-generation-toolbox). The goal of this project is to implement new techniques of music generation so they can be compared and tested.

Some samples created so far:

* Pop909 dataset with a compound word transformer [https://soundcloud.com/user-419192262-663004693/sets/compound-word-transformer-pop909](https://soundcloud.com/user-419192262-663004693/sets/compound-word-transformer-pop909)
* Pop909 dataset with a routing transformer [https://soundcloud.com/user-419192262-663004693/sets/routing-transformer-pop909](https://soundcloud.com/user-419192262-663004693/sets/routing-transformer-pop909)
* Lakh midi dataset (multi instrument) with music transformer [https://soundcloud.com/user-419192262-663004693/sets/generated-by-music-transformer-from-scratch](https://soundcloud.com/user-419192262-663004693/sets/generated-by-music-transformer-from-scratch)

I'm always interested to hear new ideas on how to improve or which new techniques to add!

Also I'm looking for a way to host the models, so people can try it in Colab without having to train a model from scratch. Any good ideas on where to put my models?"
128,deeplearning,gpt-3,comments,2021-09-30 14:07:00,New to NLP (but not machine learning) - questions about Huggingface and NLP model development with additional text/non-text features,jsxgd,False,0.91,9,pykia3,https://www.reddit.com/r/deeplearning/comments/pykia3/new_to_nlp_but_not_machine_learning_questions/,4,1633010820.0,"Hi everyone,

&#x200B;

My work is almost always focused on structured, tabular data. Recently, though, I have been working on some tasks that are more centered on NLP for personal enrichment. I've generally been understanding well how some of the model architectures work like BERT or GPT. And I understand the difference between common NLP tasks like fill-mask and text generation. I've learned a lot from the Huggingface docs.

&#x200B;

I have two questions that are more about actually engineering something with these models:

1) I can see in Huggingface that models are marked for a specific task, like fill-mask. However, in tutorials I find, I can see that these models are being used for other tasks with seemingly good performance. For example, I found a tutorial that uses \`distilbert-base-multilingual-cased\` for a novel text classification model (classifying article text as one of several news categories). But in Huggingface, this model is labeled as a fill-mask model. What gives? Is it mislabeled? Or can I use any model for any task, just with varying degrees of success?

&#x200B;

2) I'm having a hard time finding any tutorials that mix text data with additional features which may ALSO be text or just numeric/categorical. For example, if my task is classifying a sent email as ""opened"" or ""not opened"", my main feature might be the email subject text. I might also (optionally) have a pre-header text, which in some email clients appears right below the subject. Then, I also have some additional potential features like the date the email was sent, the domain of the recipient email, etc. These features may also have a variable relationship with the text, e.g. ""Happy Christmas"" as an email subject may fare differently in December vs. January. Are there any good resources to learn how to incorporate these kinds of features into the same model?

3) More generally about deep learning (particularly if you're using tensorflow/keras) - but also with respect to the questions above - what's the best way to utilize aggregate data for classification? If I'm again looking at email data, I can of course look at this recipient-by-recipient with a 0/1 binary target field for ""opened\_email"". But this data set is huge, and in this format would be repetitive as subjects would be the same for recipients getting the same email. I can instead aggregate to a per-subject data set with two fields called ""Opens"" and ""NonOpens"" containing the counts for each type of event. Or I can do ""OpenRate"" and ""TotalRecipients"" containing the percent of recipients who opened the email and the denominator of the rate. In more classical models/packages (xgboost, GLMs, etc) it's pretty easy to make use of data in this format for binary classification. Is it similarly just as easy in a NN built with tensorflow/keras?

&#x200B;

Thanks!"
129,deeplearning,gpt-3,comments,2021-12-17 16:25:47,Transformer assimilates syntax perfectly,jssmith42,False,0.91,9,ril1wx,https://www.reddit.com/r/deeplearning/comments/ril1wx/transformer_assimilates_syntax_perfectly/,4,1639758347.0,"Has anyone analysed why GPT-3 seems to master the syntax of languages nearly perfectly as opposed to not having a perfect understanding of higher-level aspects of cognition?

It could be a simple answer, that syntax is less of a complex system/pattern/structure than conceptual understanding of the world.

But I feel like there is something more interesting to be said.

For example, it seems like the bigger the model, the smarter it becomes.

Is AI as simple as, we have a structure (a neural network) that can intuitively understand any system or phenomenon because it finds some kind of model for it, a layered series of weights corresponding to some conceptual hierarchy. It just depends what order the phenomenon is. A hyper-complex phenomenon needs 100 layers, or whatever. A simple one only needs 3. In either case, there is conceivably nothing a neural network cannot eventually understand.

Is this true? If so, it’s a pretty wild notion to contemplate."
130,deeplearning,gpt-3,comments,2023-04-02 12:37:38,[N] Software 3.0 Blog Post Release 🔥,DragonLord9,False,0.76,11,129k24i,https://www.reddit.com/r/deeplearning/comments/129k24i/n_software_30_blog_post_release/,3,1680439058.0,"Hi all, excited to share my blog post on [**Software 3.0**](https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm_campaign=post&utm_medium=web)

https://preview.redd.it/9b4hjkkhugra1.png?width=1500&format=png&auto=webp&s=e341f3ab4c3c8abb206df8daa17428a297ff61e2

The blog post offers an insightful read on the new GPT-powered programming paradigm where the new programming language is simply ""*English*"", as well as recent developments in AI.

The post was originally written before GPT-4 release, and the predictions seem to have held surprisingly well. Knowledge cutoff date 28 Feb 2023.

Please read and share!! Happy to answer any follow-ups here or on DM 😊

Tweet: [https://twitter.com/DivGarg9/status/1642229948185280521?s=20](https://twitter.com/DivGarg9/status/1642229948185280521?s=20)

Blog: [https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm\_campaign=post&utm\_medium=web](https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm_campaign=post&utm_medium=web)"
131,deeplearning,gpt-3,comments,2023-02-11 06:59:00,⭕ New Open-Source Version Of ChatGPT,LesleyFair,False,0.86,37,10zepkt,https://www.reddit.com/r/deeplearning/comments/10zepkt/new_opensource_version_of_chatgpt/,3,1676098740.0,"GPT is getting competition from open-source.

A group of researchers, around the YouTuber [Yannic Kilcher](https://www.ykilcher.com/), have announced that they are working on [Open Assistant](https://github.com/LAION-AI/Open-Assistant). The goal is to produce a chat-based language model that is much smaller than GPT-3 while maintaining similar performance.

If you want to support them, they are crowd-sourcing training data [here](https://open-assistant.io/).

**What Does This Mean?**

Current language models are too big.

They require millions of dollars of hardware to train and use. Hence, access to this technology is limited to big organizations. Smaller firms and universities are effectively shut out from the developments.

Shrinking and open-sourcing models will facilitate academic research and niche applications.

Projects such as Open Assistant will help to make language models a commodity. Lowering the barrier to entry will increase access and accelerate innovation.

What an exciting time to be alive! 

Thank you for reading! I really enjoyed making this for you!  
The Decoding ⭕ is a thoughtful weekly 5-minute email that keeps you in the loop about machine research and the data economy. [Click here to sign up](https://thedecoding.net/)!"
132,deeplearning,gpt-3,comments,2023-03-13 12:50:10,Learning logical relationships with neural networks with differential ILP,Neurosymbolic,False,1.0,13,11q8tir,https://www.reddit.com/r/deeplearning/comments/11q8tir/learning_logical_relationships_with_neural/,3,1678711810.0,"Since last week’s post on my lab’s software package [PyReason](https://neurosymoblic.asu.edu/pyreason/), I got a lot of questions on if it would be possible for a neural network to learn logical relationships from data. After all, ChatGPT seems to be able to generate Python code, and Meta released a NeurIPS paper to show you can learn math equations from data using a transformer-based model, so why not logic? In this article, we will one line of research in this area – differential ILP.

The research in this area really kicked off with a 2018 [paper from DeepMind](https://www.reddit.com/r/deeplearning/jair.org/index.php/jair/article/view/11172) where Richard Evans and Edward Grefenstette showed that you could adapt techniques from “inductive logic programming” to use gradient descent, and learn logical rules from data. Previous (non-neural) work on inductive logic programming was generally not designed to work with noisy data and instead fit the historical examples in a precise manner. Evans and Grefenstette utilized a neural architecture and a loss function – and they showed they could handle noisy data and even do some level of integration with CNN’s. Their neural architecture mimicked a set of candidate logical rules – and the rules assigned higher weights by gradient descent would be thought to best fit the data. However, a downside to this approach is that the neural network was [quintic in the size of the input](https://www.youtube.com/watch?v=SOnAE0EyX8c&list=PLpqh-PUKX-i7URwnkTqpAkSchJHvbxZHB&index=5). This is why they only applied their approach on very small problems – it did not see very wide adoption.

That said, in the last two years, there have been some notable follow-ons to this work. Researchers out of Kyoto University and NTT introduced a manner to learn rules that are more expressive in a different manner by allowing function symbols in the logical language ([Shindo et al., AAAI 2021](https://ojs.aaai.org/index.php/AAAI/article/view/16637/16444)). They leverage a clause search and refinement process to limit the number of candidate rules – hence limiting the size of the neural network. A student team from ASU created a presentation on their work for our recent seminar course on neuro symbolic AI. We released a three part video series from their talk:

[Part 1: Review of differentiable inductive logic programming](https://www.youtube.com/watch?v=JIS78a40q8U&t=270s)

[Part 2: Clause search and refinement In our recent video series](https://www.youtube.com/watch?v=nzfbxlHUwuE&t=345s)

[Part 3: Experiments](https://www.youtube.com/watch?v=-fKWNtHUIN0&t=27s)

[Slides](https://labs.engineering.asu.edu/labv2/wp-content/uploads/sites/82/2022/10/Shindo_dILP.pdf)

Some think that the ability to learn such relationships will represent a significant advancement in ML, specifically addressing shortcomings in areas such as knowledge graph completion and reasoning about scene graphs. However, the gap still remains wide, and ILP techniques, including differentiable ILP still have a ways to go. Really interested in what your thoughts are, feel free to comment below."
133,deeplearning,gpt-3,comments,2023-06-05 04:33:14,How Open Ai’s Andrej Karpathy Made One of the Best Tutorials in Deep Learning,0ssamaak0,False,0.91,57,141282u,https://www.reddit.com/r/deeplearning/comments/141282u/how_open_ais_andrej_karpathy_made_one_of_the_best/,3,1685939594.0,"I want you to check [my review](https://medium.com/@0ssamaak0/how-open-ais-andrej-karpathy-made-one-of-the-best-tutorials-in-deep-learning-e6b6445a2d05) on Andrej Karpathy amazing work on explaining how GPT is built

[GitHub Repo](https://github.com/0ssamaak0/Karpathy-Neural-Networks-Zero-to-Hero) for code & more details

&#x200B;

https://preview.redd.it/z204zwtzn44b1.png?width=720&format=png&auto=webp&s=095ea00991ebb295f48b70436456b1f283a50df1"
134,deeplearning,gpt-3,comments,2022-11-13 17:50:42,"Can we possibly get access to large language models (PaLM 540B, etc) like GPT-3 but no cost?",NLP2829,False,0.55,1,yu8oru,https://www.reddit.com/r/deeplearning/comments/yu8oru/can_we_possibly_get_access_to_large_language/,3,1668361842.0,"(I only want to do inference, I don't need to finetune it.)

I want to use very-large language model (#parameters > 100B) to do some experiments, is that true the only very-large language model we can get access to is GPT3 API? Can we possibly get access to PaLM and Flan-PaLM 540B with no cost by chance?

I have searched over the internet but can't find a definite answer. As GPT-3 pricing for text-davinci-2 is not cheap, I am wondering if there's a chance to use other models.

Also, I can request up to 372GB VRAM, is there any large language model (#parameters > 100B) that I can actually download and run ""locally""?"
135,deeplearning,gpt-3,comments,2022-12-23 14:35:17,How to change career trajectory to NLP engineer,Creative-Milk-8266,False,0.89,14,zth8rl,https://www.reddit.com/r/deeplearning/comments/zth8rl/how_to_change_career_trajectory_to_nlp_engineer/,3,1671806117.0," A little of my background - 5 years experience in data science. Mostly related to prototyping statistical models and optimization problems, bringing them into production. Some experience in building pipeline and orchestration flow with AWS services.

I have basic understanding on Transformers, BERT, GPT. Did my first NLP Kaggle competition the first time recently.

I'd like my next job to be a NLP engineer. How should I prepare myself for it?

Here's some of the items I'm thinking

&#x200B;

1. More hands on projects I can put on resume, including integration with cloud services. Any recommendations on what kinds of projects I should pick?  
 
2. Tryout techniques of speeding up models like distilled model, dynamic shape, quantization. Anything else that would be helpful?  
 
3. Understand lower level of GPU programming knowledges. Not sure if this is helpful for me finding a NLP job. If so, what kind of things I can do to go deeper on this subject. I'm currently taking [Intro to Parallel Programming](https://classroom.udacity.com/courses/cs344) CS344 course on Udemy (highly recommend btw).  
 
4. Grind leetcode :/  
 

Please point out other important directions I missed."
136,deeplearning,gpt-3,comments,2021-11-28 12:03:23,Deep Learning models which are available for individual/retail use?,ahassoun,False,0.5,0,r42v0b,https://www.reddit.com/r/deeplearning/comments/r42v0b/deep_learning_models_which_are_available_for/,3,1638101003.0,"I am fascinated by GPT-3 and ever since I learned about it a year ago, I use it almost every day. 

Other than language and content creation, are there models available for public use? I don't have a specific problem/domain in mind, but I would like to explore what is out there."
137,deeplearning,gpt-3,comments,2023-09-29 14:02:33,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.88,17,16vch0x,https://www.reddit.com/r/deeplearning/comments/16vch0x/this_week_in_ai_all_the_major_ai_developments_in/,2,1695996153.0,"1. **Meta AI** presents **Emu**, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal.
2. **Meta AI** researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks.
3. **Abacus AI** released a larger 70B version of **Giraffe**. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens\].
4. **Cerebras** and **Opentensor** released Bittensor Language Model, ‘**BTLM-3B-8K**’, a new 3 billion parameter open-source language model with an 8k context length trained on 627B tokens of SlimPajama. It outperforms models trained on hundreds of billions more tokens and achieves comparable performance to open 7B parameter models. The model needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models and is available with an Apache 2.0 license for commercial use.
5. **OpenAI** is rolling out, over the next two weeks, new voice and image capabilities in ChatGPT enabling ChatGPT to understand images, understand speech and speak. The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. .
6. **Mistral AI**, a French startup, released its first 7B-parameter model, **Mistral 7B**, which outperforms all currently available open models up to 13B parameters on all standard English and code benchmarks. Mistral 7B is released in Apache 2.0, making it usable without restrictions anywhere.
7. **Microsoft** has released **AutoGen** \- an open-source framework that enables development of LLM applications using multiple agents that can converse with each other to solve a task. Agents can operate in various modes that employ combinations of LLMs, human inputs and tools.
8. **LAION** released **LeoLM**, the first open and commercially available German foundation language model built on Llama-2
9. Researchers from **Google** and **Cornell University** present and release code for DynIBaR (Neural Dynamic Image-Based Rendering) - a novel approach that generates photorealistic renderings from complex, dynamic videos taken with mobile device cameras, overcoming fundamental limitations of prior methods and enabling new video effects.
10. **Cloudflare** launched **Workers AI** (an AI inference as a service platform), **Vectorize** (a vector Database) and **AI Gateway** with tools to cache, rate limit and observe AI deployments. Llama2 is available on Workers AI.
11. **Amazon** announced the general availability of **Bedrock**, its service that offers a choice of generative AI models from Amazon itself and third-party partners through an API.
12. **Spotify** has launched a pilot program for AI-powered voice translations of podcasts in other languages - in the podcaster’s voic. It uses OpenAI’s newly released voice generation model.
13. **Getty Images** has launched a generative AI image tool, ‘**Generative AI by Getty Images**’, that is ‘commercially‑safe’. It’s powered by Nvidia Picasso, a custom model trained exclusively using Getty’s images library.
14. **Optimus**, Tesla’s humanoid robot, can now sort objects autonomously and do yoga. Its neural network is trained fully end-to-end.
15. **Amazon** will invest up to $4 billion in Anthropic. Developers and engineers will be able to build on top of Anthropic’s models via Amazon Bedrock.
16. **Google Search** indexed shared Bard conversational links into its search results pages. Google says it is working on a fix.

&#x200B;

  
My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
138,deeplearning,gpt-3,comments,2023-09-24 01:00:34,"Exploring ""Harm Filter for LLM"" as a Research in NLP",junkim100,False,1.0,1,16qkfjr,https://www.reddit.com/r/deeplearning/comments/16qkfjr/exploring_harm_filter_for_llm_as_a_research_in_nlp/,2,1695517234.0,"I'm currently considering a research topic for my combined masters/phd program in an NLP lab. I've been particularly intrigued by the challenges posed by Large Language Models (LLMs) when it comes to generating potentially harmful or inappropriate content. Given the recent ""jailbreaks"" on LLMs, where users have tried to bypass content filters, I believe there's a pressing need to delve deeper into this area.

For my research focus, I've been referring to it as ""Harm Filter for LLM."" However, I'm unsure if there's an established term for this specific area of study. It seems to encompass techniques to prevent models from generating harmful content and strategies to defend against adversarial attempts to bypass these filters.

I came across a few resources that shed light on this topic:

* [**GitHub Repository on LLM Prompt Injection Filtering**](https://github.com/derwiki/llm-prompt-injection-filtering/blob/main/README.md)
* [**Research Paper on Evaluating Large Language Models Trained on Code**](https://arxiv.org/pdf/2307.02483.pdf)
* [**Research Paper on ChatGPT: A Chatbot based on GPT-3.5**](https://arxiv.org/abs/2305.05027)

I have a few questions for the community:

1. Do you think ""Harm Filter for LLM"" (or whatever the established term might be) is a promising research area in NLP?
2. Is there a commonly used term for this field? Could it possibly fall under a broader category like ""Explainable AI""?
3. Any suggestions on where I can delve deeper into this topic?
4. Additionally, I'm also looking for resources to strengthen my foundational knowledge in NLP. Any recommendations would be greatly appreciated!"
139,deeplearning,gpt-3,comments,2021-05-02 16:45:08,GPT-1 - Annotated Paper + Paper Summary,shreyansh26,False,0.96,25,n3aeh5,https://www.reddit.com/r/deeplearning/comments/n3aeh5/gpt1_annotated_paper_paper_summary/,2,1619973908.0," GPT-2 and recently, GPT-3 created a lot of hype when they were launched. However, it all started with the ""Improving Language Understanding by Generative Pre-Training"" paper which introduced the idea of GPT-1.

As a part of my Paper Notes series, I have gone through the paper and created a brief yet informative summary of the paper. It will take just take a few minutes to understand GPT-1 well. Check out the links below and happy reading!

Paper Summary - [Improving Language Understanding by Generative Pre-Training](https://shreyansh26.github.io/post/2021-05-02_language_understanding_generative_pretraining/)

Annotated Paper - [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf)"
140,deeplearning,gpt-3,comments,2021-08-31 03:04:53,[R] CtrlGen Workshop at NeurIPS 2021 (Controllable Generative Modeling in Language and Vision),CtrlGenWorkshop,False,0.75,2,pexh5q,https://www.reddit.com/r/deeplearning/comments/pexh5q/r_ctrlgen_workshop_at_neurips_2021_controllable/,2,1630379093.0,"We are holding a controllable generation workshop at NeurIPS 2021! It aims to explore disentanglement, controllability, and manipulation for the generative vision and language modalities. We feature an exciting lineup of speakers, a live QA and panel session, interactive activities, and networking opportunities. See our website below for more! We are also inviting both paper and demo submissions related to controllable generation (read further for details).

**Workshop Website:** [https://ctrlgenworkshop.github.io/](https://ctrlgenworkshop.github.io/)

**Contact:** [ctrlgenworkshop@gmail.com](mailto:ctrlgenworkshop@gmail.com)

**Important Dates**

* Paper Submission Deadline: ***September 30, 2021 (UPDATED)***
* Paper Acceptance Notification: October 22, 2021
* Paper Camera-Ready Deadline: November 1, 2021
* Demo Submission Deadline: ***October 29, 2021***
* Demo Acceptance Notification: November 19, 2021
* Workshop Date: ***December 13, 2021***

**Submission Portal (Papers + Demos):**  [https://cmt3.research.microsoft.com/CtrlGen2021/Submission/Index](https://cmt3.research.microsoft.com/CtrlGen2021/Submission/Index)

&#x200B;

**Full Call for Papers:** [h](https://ctrlgenworkshop.github.io/CFP.html)[ttps://ctrlgenworkshop.github.io/CFP.html](https://ctrlgenworkshop.github.io/CFP.html)

Paper submission deadline: ***September 30, 2021 (UPDATED)***. Topics of interest include:

**Methodology and Algorithms:**

* New methods and algorithms for controllability.
* Improvements of language and vision model architectures for controllability.
* Novel loss functions, decoding methods, and prompt design methods for controllability.

**Applications and Ethics:**

* Applications of controllability including creative AI, machine co-creativity, entertainment, data augmentation (for [text](https://arxiv.org/abs/2105.03075) and [vision](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0)), ethics (e.g. bias and toxicity reduction), enhanced training for self-driving vehicles, and improving conversational agents.
* Ethical issues and challenges related to controllable generation including the risks and dangers of deepfake and fake news.

**Tasks (a few examples):**

* [Semantic text exchange](https://aclanthology.org/D19-1272/)
* [Syntactically-controlled paraphrase generation](https://arxiv.org/abs/1804.06059)
* [Persona-based text generation](https://aclanthology.org/W19-3402/)
* Style-sensitive generation or style transfer (for [text](https://arxiv.org/abs/2011.00416) and [vision](https://github.com/ycjing/Neural-Style-Transfer-Papers))
* Image synthesis and scene representation in both 2D and 3D
* Cross-modal tasks such as controllable image or video captioning and generation from text
* New and previously unexplored controllable generation tasks!

**Evaluation and Benchmarks**

* New and improved evaluation methods and metrics for controllability
* Standard and unified metrics and benchmark tasks for controllability

**Cross-Domain and Other Areas**

* Work in interpretability, disentanglement, robustness, representation learning, etc.

**Position and Survey Papers**

* For example, exploring problems and lacunae in current controllability formulations, neglected areas in controllability, and the unclear and non-standardized definition of controllability

&#x200B;

**Full Call for Demonstrations:** [https://ctrlgenworkshop.github.io/demos.html](https://ctrlgenworkshop.github.io/demos.html)

Submission deadline: ***October 29, 2021***. Demos of all forms: research-related, demos of products, interesting and creative projects, etc. Looking for creative, well-presented, and attention-grabbing demos. Examples include:

* Creative AI such as controllable poetry, music, image, and video generation models.
* Style transfer for both text and vision.
* Interactive chatbots and assistants that involve controllability.
* Controllable language generation systems, e.g. using GPT-2 or GPT-3.
* Controllable multimodal systems such as image and video captioning or generation from text.
* Controllable image and video/graphics enhancement systems.
* Systems for controlling scenes/environments and applications for self-driving vehicles.
* Controllability in the form of deepfake and fake news, specifically methods to combat them.
* And much, much more…

&#x200B;

**Organizing Team:**

* [Steven Feng](https://styfeng.github.io/) (CMU)
* [Anusha Balakrishnan](https://www.microsoft.com/en-us/research/people/anbalak/) (Microsoft Semantic Machines)
* [Drew Hudson](https://cs.stanford.edu/people/dorarad/) (Stanford)
* [Tatsunori Hashimoto](https://thashim.github.io/) (Stanford)
* [Dongyeop Kang](https://dykang.github.io/) (UMN)
* [Varun Gangal](https://vgtomahawk.github.io/) (CMU)
* [Joel Tetreault](https://www.cs.rochester.edu/~tetreaul/academic.html) (Dataminr)"
141,deeplearning,gpt-3,comments,2021-05-06 02:20:17,Document-Based Question Answering/Semantic Search,willspag,False,0.5,0,n5wxla,https://www.reddit.com/r/deeplearning/comments/n5wxla/documentbased_question_answeringsemantic_search/,2,1620267617.0,"I need a pre-trained model where I can input text documents (or fine-tune with) and have it answer  reading comprehension-type questions. Obviously, GPT-3 would be perfect for this, but I need it by tomorrow and don't think I'll receive login credentials to the API for at least another week. However, the task isn't all too complex, so I'm looking for a decent alternative that I can access quickly.

If I'm unable to find a reasonable pre-trained  Q&A model in time, a semantic search model would be the next best option. I'm sure this could be done with some sort of fine-tuned BERT model, but due to my time crunch, I really need one already tuned towards semantic search capabilities.

Google Colab links would be ideal, but anything helps. Thanks!"
142,deeplearning,gpt-3,comments,2020-07-22 21:00:37,Can GPT-3 do inference on GTX 1080?,fgp121,False,0.25,0,hw22o1,https://www.reddit.com/r/deeplearning/comments/hw22o1/can_gpt3_do_inference_on_gtx_1080/,2,1595451637.0,"Has anyone got their hands on GPT-3? How does the inference work for it? Is it really compute intensive? 

I had applied for access but haven't got it yet. And I'm thinking if it'd be able to do inference on my 1080 card? What minimum GPU computing capability and vRAM would it need to perform an inference  for a case such as completing a sentence?"
143,deeplearning,gpt-3,comments,2023-01-19 14:10:45,BlogNLP: AI Blog Writing Tool,britdev,False,0.5,0,10g2npf,https://www.reddit.com/r/deeplearning/comments/10g2npf/blognlp_ai_blog_writing_tool/,2,1674137445.0,"Hey everyone,

I developed this web app with Open AI's GPT-3 to provide a helpful resource for generating blog content, outlines, and more - so you can beat writer's block! I'd really appreciate it if you shared it with others.

[https://www.blognlp.com/](https://www.blognlp.com/)"
144,deeplearning,gpt-3,comments,2020-07-26 07:39:05,Crazy Numbers of GPT-3,alaap001,False,0.44,0,hy2vg1,https://www.reddit.com/r/deeplearning/comments/hy2vg1/crazy_numbers_of_gpt3/,2,1595749145.0,"Trained on over 285,000 CPU cores and 10,000 GPUs cluster, a lot of hype going around the latest GPT-3 model, those who are not into AI, it is the most advanced NLP algorithm to date. It learned the human-level language from over 400GB of data, costing crazy $12 million just to train it with \~175 Billion!! parameters. A typical high-end GPU would take over 350 years to train this model. As a Data Scientist, I thought why not look at how much data it took to learn human language. 

Well, here are the crazzyy numbers.

It used roughly 9 Million Hindi words,

3 Billion for German

and

4 Billion French words with 100 other languages. 

https://preview.redd.it/2b6aee0un5d51.png?width=937&format=png&auto=webp&s=3d4fa2e1b2621ae699ec1bb4a62d7cc85554c8d1

https://preview.redd.it/ec7tve0un5d51.png?width=871&format=png&auto=webp&s=9d8624d117ad4e1f41fff78f06bb30197abbd006

and all this fades away when English comes in with over 180 Billion words!! \[ For reference English has only 171,476 unique words with 20000 being used normally \]

It seems crazy how AI is being built so rapidly and now can talk like a human. Gets me excited thinking about what the future holds. 

***If you're the one who is getting started with Deep Learning then for you I created a website wherein I plan to do 100 Deep Learning Projects to help people understand the practicality of Deep Learning. You can visit*** [***https://www.aiunquote.com/***](https://www.aiunquote.com/) ***and learn deep learning by implementing,***

**#artificialintelligence** **#technology** **#AI** **#naturallanguageprocessing** **#gpt3** **#tableaupublic** **#computerscience** **#maths** **#innovation** **#datascience**"
145,deeplearning,gpt-3,comments,2023-09-30 12:23:31,[D] How to train a seq2seq model to rephrase input text following given rules.,3Ammar404,False,0.5,0,16w5g5p,https://www.reddit.com/r/deeplearning/comments/16w5g5p/d_how_to_train_a_seq2seq_model_to_rephrase_input/,2,1696076611.0,"Hi guys,

I want to train (fine-tune) a seq2seq model to perform the task of rephrasing input following these rules :

1- always follow the pattern ""Entity Verb Entity""

2- only use simple sentences : never combine sentences

3- Don't replace existing words

4- Don't lose the overall meaning of the text or any information in it.

For example:

text = ""Project Risk Management includes the processes of conducting risk management planning, identification, analysis, response planning, response implementation, and monitoring risk on a project""

Standardized Text = ""Project Risk Management conducts risk management planning. Project Risk Management conducts risk identification. Project Risk Management conducts risk analysis. Project Risk Management plans responses. Project Risk Management implements responses. Project Risk Management monitors risk on a project.""

Using ChatGPT the results were very good, but I want to know if I can fine tune a model (BERT, T5, any LM) locally, what should be the data format for training such a model, evaluation metrics ?"
146,deeplearning,gpt-3,comments,2022-04-21 15:55:24,How do I figure out if I can run a model on my personal computer / any given hardware?,Jjax7,False,0.76,4,u8qs9o,https://www.reddit.com/r/deeplearning/comments/u8qs9o/how_do_i_figure_out_if_i_can_run_a_model_on_my/,2,1650556524.0,"Models like GPT-3 and DALLE-2 have billions of parameters. I’m an undergraduate Data Science student with a GTX 970 in my computer. I’ve been able to train and run model architectures similar to AlexNet, UNet, and a Sequence-to-Sequence RNN encoder-decoder architecture on my local device before, but there is a disconnect in my understanding for what it takes to scale models up given more complex tasks.

It’s my understanding that many modern state-of-the-art models make use of transformer architectures and more specifically attention mechanisms. From what I’ve been learning, attention gives massive boosts in training and model execution speed due to parallelization but at the cost of high memory usage. How can I ground my understanding of the computational costs required to run these models?

Is there a way to look at the number of parameters a model is trained with and understand the kind of memory/hardware required?"
147,deeplearning,gpt-3,comments,2022-12-12 15:53:41,"GPT-Rex: A chrome extension to plug GPT-3 directly into Medium. Hit ""Ctrl + >"" to trigger auto-complete while writing. Available on Chrome web store. Support for other platforms coming soon.",hayAbhay,False,0.67,2,zk2ser,https://github.com/hayabhay/gpt-go,2,1670860421.0,
148,deeplearning,gpt-3,comments,2022-09-06 11:30:34,Can GPT-3 be honest when it speaks nonsense?,bendee983,False,1.0,1,x785x5,https://bdtechtalks.com/2022/09/05/llm-uncertainty-verbalized-probability/,2,1662463834.0,
149,deeplearning,gpt-3,comments,2020-12-21 11:49:16,The Future is Here! Have You Checked OpenAI’s GPT-3 Yet?,Shradha_Singh,False,0.17,0,khfwel,https://www.artiba.org/blog/the-future-is-here-have-you-checked-openais-gpt-3-yet,1,1608551356.0,
150,deeplearning,gpt-3,comments,2020-11-29 20:53:02,What is the hype about the GPT-3 transformer and what is real? (GPT3 paper deep dive),gordicaleksa,False,0.5,0,k3h2jj,https://youtu.be/fVt387VZJe8,1,1606683182.0,
151,deeplearning,gpt-3,comments,2021-04-26 16:38:23,[R] Google and UC Berkeley Propose Green Strategies for Large Neural Network Training,Yuqing7,False,0.95,55,mz1v2c,https://www.reddit.com/r/deeplearning/comments/mz1v2c/r_google_and_uc_berkeley_propose_green_strategies/,1,1619455103.0,"A research team from Google and the University of California, Berkeley calculates the energy use and carbon footprint of large-scale models T5, Meena, GShard, Switch Transformer and GPT-3, and identifies methods and publication guidelines that could help reduce their CO2e footprint.

Here is a quick read: [Google and UC Berkeley Propose Green Strategies for Large Neural Network Training](https://syncedreview.com/2021/04/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-5/).

The paper *Carbon Emissions and Large Neural Network Training* is on [arXiv](https://arxiv.org/ftp/arxiv/papers/2104/2104.10350.pdf)."
152,deeplearning,gpt-3,comments,2021-08-13 16:21:39,Computational Bottleneck of Largest GPT-3,zxcv_qwer1234,False,1.0,9,p3og0n,https://www.reddit.com/r/deeplearning/comments/p3og0n/computational_bottleneck_of_largest_gpt3/,1,1628871699.0,"I know a lot of work is being done to optimize the performance of transformers on very long sequences, but I am curious if there would be any value in optimizing the dense operations in the largest GPT models.  My understanding is that all self-attention operations softmax(QK)V scale linearly with the size of Q, K, and V while the linear projections and FFN would scale to the square of these values (assuming the side of the FFN hidden states also scale linearly with Q, K, and V).  For this reason, with the largest GPT models, is more computation currently being used on linear operations than the self-attention operation itself?"
153,deeplearning,gpt-3,comments,2023-01-14 14:48:43,Scaling Language Models Shines Light On The Future Of AI ⭕,LesleyFair,False,0.71,7,10bq685,https://www.reddit.com/r/deeplearning/comments/10bq685/scaling_language_models_shines_light_on_the/,1,1673707723.0,"Last year, large language models (LLM) have broken record after record. ChatGPT got to 1 million users faster than Facebook, Spotify, and Instagram did. They helped create [billion-dollar companies](https://www.marketsgermany.com/translation-tool-deepl-is-now-a-unicorn/#:~:text=Cologne%2Dbased%20artificial%20neural%20network,sources%20close%20to%20the%20company), and most notably they helped us recognize the [divine nature of ducks](https://twitter.com/drnelk/status/1598048054724423681?t=LWzI2RdbSO0CcY9zuJ-4lQ&s=08).

2023 has started and ML progress is likely to continue at a break-neck speed. This is a great time to take a look at one of the most interesting papers from last year.

Emergent Abilities in LLMs

In a recent [paper from Google Brain](https://arxiv.org/pdf/2206.07682.pdf), Jason Wei and his colleagues allowed us a peak into the future. This beautiful research showed how scaling LLMs might allow them, among other things, to:

* Become better at math
* Understand even more subtleties of human language
* reduce hallucination and answer truthfully
* ...

(See the plot on break-out performance below for a full list)

**Some Context:**

If you played around with ChatGPT or any of the other LLMs, you will likely have been as impressed as I was. However, you have probably also seen the models go off the rails here and there. The model might hallucinate gibberish, give untrue answers, or fail at performing math.

**Why does this happen?**

LLMs are commonly trained by [maximizing the likelihood](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf) over all tokens in a body of text. Put more simply, they learn to predict the next word in a sequence of words.

Hence, if such a model learns to do any math at all, it learns it by figuring concepts present in human language (and thereby math).

Let's look at the following sentence.

""The sum of two plus two is ...""

The model figures out that the most likely missing word is ""four"".

The fact that LLMs learn this at all is mind-bending to me! However, once the math gets more complicated [LLMs begin to struggle](https://twitter.com/Richvn/status/1598714487711756288?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1598714487711756288%7Ctwgr%5E478ce47357ad71a72873d1a482af5e5ff73d228f%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fanalyticsindiamag.com%2Ffreaky-chatgpt-fails-that-caught-our-eyes%2F).

There are many other cases where the models fail to capture the elaborate interactions and meanings behind words. One other example is words that change their meaning with context. When the model encounters the word ""bed"", it needs to figure out from the context, if the text is talking about a ""river bed"" or a ""bed"" to sleep in.

**What they discovered:**

For smaller models, the performance on the challenging tasks outline above remains approximately random. However, the performance shoots up once a certain number of training FLOPs (a proxy for model size) is reached.

The figure below visualizes this effect on eight benchmarks. The critical number of training FLOPs is around 10\^23. The big version of GPT-3 already lies to the right of this point, but we seem to be at the beginning stages of performance increases.

&#x200B;

[Break-Out Performance At Critical Scale](https://preview.redd.it/jlh726eku0ca1.png?width=800&format=png&auto=webp&s=55d170251a967f31b36f01864af6bb7e2dbda253)

They observed similar improvements on (few-shot) prompting strategies, such as multi-step reasoning and instruction following. If you are interested, I also encourage you to check out Jason Wei's personal blog. There he [listed a total of 137](https://www.jasonwei.net/blog/emergence) emergent abilities observable in LLMs.

Looking at the results, one could be forgiven for thinking: simply making models bigger will make them more powerful. That would only be half the story.

(Language) models are primarily scaled along three dimensions: number of parameters, amount of training compute, and dataset size. Hence, emergent abilities are likely to also occur with e.g. bigger and/or cleaner datasets.

There is [other research](https://arxiv.org/abs/2203.15556) suggesting that current models, such as GPT-3, are undertrained. Therefore, scaling datasets promises to boost performance in the near-term, without using more parameters.

**So what does this mean exactly?**

This beautiful paper shines a light on the fact that our understanding of how to train these large models is still very limited. The lack of understanding is largely due to the sheer cost of training LLMs. Running the same number of experiments as people do for smaller models would cost in the hundreds of millions.

However, the results strongly hint that further scaling will continue the exhilarating performance gains of the last years.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you.At **TheDecoding** ⭕, I send out a thoughtful newsletter about ML research and the data economy once a week.No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)"
154,deeplearning,gpt-3,comments,2021-07-28 14:19:34,AI Email Generator Web App with GPT-3,thelazyaz,False,0.85,9,otaun5,https://www.youtube.com/watch?v=oJWBQKrF4uM&feature=youtu.be,1,1627481974.0,
155,deeplearning,gpt-3,comments,2020-09-04 22:59:41,[D] Is OpenAI’s GPT-3 API Beta Pricing Too Rich for Researchers?,Yuqing7,False,0.67,1,imqa78,https://www.reddit.com/r/deeplearning/comments/imqa78/d_is_openais_gpt3_api_beta_pricing_too_rich_for/,1,1599260381.0,"OpenAI’s 175 billion parameter language model GPT-3 (Generative Pre-trained Transformer 3) turned heads in the NLP community when it was released in June, and now it’s back in the spotlight. A Reddit [post](https://www.reddit.com/r/GPT3/comments/ikorgs/oa_api_preliminary_beta_pricing_announced/) this week by independent writer and researcher Gwern Branwen detailed the pricing plan OpenAI has provided to GPT-3 Beta API users. The scheme, which goes into effect on October 1, has already raised as many questions as it has answered.

Here is a quick read: [Is OpenAI’s GPT-3 API Beta Pricing Too Rich for Researchers?](https://syncedreview.com/2020/09/04/is-openais-gpt-3-api-beta-pricing-too-rich-for-researchers/)"
156,deeplearning,gpt-3,comments,2022-11-20 06:20:53,How do various content-generating services work?,th3luck,False,0.9,8,yzwzp0,https://www.reddit.com/r/deeplearning/comments/yzwzp0/how_do_various_contentgenerating_services_work/,1,1668925253.0,"Right now sites like [https://www.jasper.ai/](https://www.jasper.ai/) offer text generation for emails, ads, social media posts and etc. I wonder, do they simply tune a separate gpt-3-like model for each of these tasks? Or there is a new approach to solving this?"
157,deeplearning,gpt-3,comments,2022-04-23 19:37:38,?? Can you find out which news article is written by AI ??,RobinSandersVUB,False,0.75,2,uad25r,https://www.reddit.com/r/deeplearning/comments/uad25r/can_you_find_out_which_news_article_is_written_by/,1,1650742658.0,"This research will test the human ability to distinguish human written text from text generated by artificial intelligence. Participating will only take 10 minutes. You will receive 2 short news articles about the same topic. One will be written by a human, the other one will be generated by artificial intelligence. It is up to you to find out which one is written by artificial intelligence. You will be asked to do this for four different subjects, namely: Science, Economics & Politics, Society and Sports. At the end of the survey you will receive feedback on how well you have performed.

The human written articles were collected from various news websites. The Articles created by artificial intelligence were generated using GPT-3 from OpenAI.

Purpose of the research: We are trying to find out how well GPT-3 performs across subjects. Are there any subject GPT-3 is better at writing about, or is he equally good across all subjects. Secondly we are testing the ability of GPT-3 to generate articles about events that happened after the training of the model. 

You can participate by clicking on the link below, thank you very much for your participation.

 [https://vub.fra1.qualtrics.com/jfe/form/SV\_b2E9f6hGxNDH13M](https://vub.fra1.qualtrics.com/jfe/form/SV_b2E9f6hGxNDH13M)"
158,deeplearning,gpt-3,comments,2020-12-17 16:38:31,[article] AI Limits: Can Deep Learning Models Like BERT Ever Understand Language?,kk_ai,False,0.5,0,kf0t9c,https://www.reddit.com/r/deeplearning/comments/kf0t9c/article_ai_limits_can_deep_learning_models_like/,1,1608223111.0,"It’s safe to assume a topic can be considered mainstream when it is the basis for an opinion piece in the Guardian. What is unusual is when that topic is a fairly niche area that involves applying Deep Learning techniques to develop natural language models. What is even more unusual is when one of those models (GPT-3) wrote the article itself!

Understandably, this caused a flurry of apocalyptic terminator-esque social media buzz (and some criticisms of the Guardian for being misleading about GPT-3’s ability). 

Nevertheless, the rapid progress made in recent years in this field has resulted in Language Models (LMs) like GPT-3. Many claim that these LMs understand language due to their ability to write Guardian opinion pieces, generate React code, or perform a series of other impressive tasks.

To understand NLP, we need to look at three aspects of these Language Models:

- Conceptual limits: What can we learn from text? The octopus test.
- Technical limits: Are LMs “cheating”?
- Evaluation limits: How good are models like BERT?

So how good are these models? 

[Can Deep Learning Models Like BERT Ever Understand Language](https://neptune.ai/blog/ai-limits-can-deep-learning-models-like-bert-ever-understand-language?utm_source=reddit&utm_medium=post&utm_campaign=blog-ai-limits-can-deep-learning-models-like-bert-ever-understand-language&utm_content=deeplearning)?"
159,deeplearning,gpt-3,comments,2020-07-27 00:13:47,"OpenAI's New Language Generator: GPT-3. This AI Generates Code, Websites, Songs & More From Words",OnlyProggingForFun,False,0.56,1,hyhvqi,https://www.youtube.com/watch?v=gDDnTZchKec,1,1595808827.0,
160,deeplearning,gpt-3,comments,2022-02-10 22:10:25,Course on GPT-3 and Transformers,godiswatching_,False,1.0,2,spift0,https://www.reddit.com/r/deeplearning/comments/spift0/course_on_gpt3_and_transformers/,1,1644531025.0,"Hello,   


I was wondering if anyone knows about resources for learning about GPT-3 and Transformer based AI.   Preferably some video series with some project but blogs are just as welcome.

&#x200B;

Thank you."
161,deeplearning,gpt-3,comments,2023-08-28 07:12:44,OpenAI introduces fine-tuning capabilities for GPT-3.5 Turbo,intengineering,False,1.0,4,163f3fp,https://interestingengineering.com/innovation/openai-introduces-fine-tuning-capabilities-for-gpt-35-turbo,1,1693206764.0,
162,deeplearning,gpt-3,comments,2023-05-31 10:03:36,What is the objective for the supervised fine-tuning stage of instruction-following models?,BlueHemp,False,0.81,3,13whxjk,https://www.reddit.com/r/deeplearning/comments/13whxjk/what_is_the_objective_for_the_supervised/,1,1685527416.0,"Dialog models like [InstructGPT](https://arxiv.org/pdf/2203.02155.pdf) and, recently, [Dromedary](https://arxiv.org/abs/2305.03047) have a supervised fine-tuning part where they use collected demonstration data to tune the base model. Quote from InstructGPT paper: ""fine-tune a pretrained GPT-3 model on this data using supervised learning.""

However, these papers don't go into detail about the objective/loss function for this step. To be clear, I don't mean the RLHF part that follows for InstructGPT but the first step of just fine-tuning on (human or model generated) examples.

I would guess that the objective is basically an auto-regressive language modeling task since GPT-like models are decoder-only models.So what exactly is the training objective or loss function for the supervised finetuning (not RLHF!) step?"
163,deeplearning,gpt-3,comments,2023-06-16 11:10:14,Automate Tasks with a Single AI Command. For Example: Building a snake game in python. (Open Source Project),Loya_3005,False,0.5,0,14au11z,https://www.reddit.com/r/deeplearning/comments/14au11z/automate_tasks_with_a_single_ai_command_for/,1,1686913814.0,"We noticed that some LLM powered agents end up in infinite loops. With careful prompt engineering and specific UI/UX choices, we managed to create agents that can complete tasks consistently.

[Example Task: Create a snake game in python](https://reddit.com/link/14au11z/video/wq9wxgqo4d6b1/player)

🔎 Call for Feedback: We invite the community to try out Nuggt and provide valuable feedback. Let us know your thoughts, suggestions, and any improvements you'd like to see. Your feedback will help us shape the future of Nuggt and make it even better.

🔗 Find Nuggt on GitHub (We are looking for collaborators): [https://github.com/Nuggt-dev/Nuggt](https://github.com/Nuggt-dev/Nuggt)

🌟 Join the Nuggt Discord Server: [https://discord.gg/gzdCDM84](https://discord.gg/gzdCDM84)

💡 Follow our 30 Days 30 Tasks with Nuggt challenge on Twitter: [https://twitter.com/OfficialNuggt](https://twitter.com/OfficialNuggt)

PS: While our current implementation leverages the power of GPT-3.5, we recognise the need for cost-effective solutions without compromising functionality. Our ongoing efforts involve exploring and harnessing the potential of smaller models like Vicuna 13B, ensuring that task automation remains accessible to a wider audience."
164,deeplearning,gpt-3,comments,2020-09-09 19:51:13,[R] New Multitask Benchmark Suggests Even the Best Language Models Don’t Have a Clue What They’re Doing,Yuqing7,False,1.0,3,ipnoh4,https://www.reddit.com/r/deeplearning/comments/ipnoh4/r_new_multitask_benchmark_suggests_even_the_best/,1,1599681073.0,"The recently published paper, *Measuring Massive Multitask Language Understanding,* introduces a test covering topics such as elementary mathematics, US history, computer science, law, etc., designed to measure language models’ multitask accuracy. The authors, from UC Berkeley, Columbia University, UChicago, and UIUC, conclude that even the top-tier 175-billion-parameter OpenAI GPT-3 language model is a bit daft when it comes to language understanding, especially when encountering topics in greater breadth and depth than explored by previous benchmarks.

Here is a quick read: [New Multitask Benchmark Suggests Even the Best Language Models Don’t Have a Clue What They’re Doing](https://syncedreview.com/2020/09/09/new-multitask-benchmark-suggests-even-the-best-language-models-dont-have-a-clue-what-theyre-doing/)

The paper *Measuring Massive Multitask Language Understanding* is on [arXiv](https://arxiv.org/pdf/2009.03300.pdf)."
165,deeplearning,gpt-3,comments,2022-02-20 14:05:28,Quantum Computer + AutoML + Deep Reinforcement Learning = ?,thaiminhpv,False,0.3,0,sx1z0i,https://www.reddit.com/r/deeplearning/comments/sx1z0i/quantum_computer_automl_deep_reinforcement/,1,1645365928.0,"## Can an AI model research and develop a better model than itself, and then replace itself, then iterate this cycle?

With **AutoML**, we can now use AI model to create new AI models. It can tune the hyper-parameters, and even create new neural network architectures by itself.

With **Deep Reinforcement Learning on AutoML**, AI model can improve the generated neural network via trial and error, based on benchmarks on many large datasets.

With state-of-the-art models like **GPT-3**, models can now have a ""rough sense"" about ""how the world looks like"" - much like a ""general purpose"" model. Therefore, these models are complex enough to know how to design an effective neural network architecture by itself.

Given that, **can an AI model research and develop a better model than itself, and then replace itself, then iterate this cycle?**

Apparently, this seems to require a lot of computational resources, but with **Quantum Computers**, can we achieve it? **Will this be feasible when we have Quantum Computer?**

If the model can do it, this will ultimately result in a Super-intelligence model that can improve itself, and thus this is the end of the world 😉"
166,deeplearning,gpt-3,comments,2020-07-20 18:56:29,OpenAI’s new language generator GPT-3 is shockingly good—and completely mindless,PsychogenicAmoebae,False,0.78,5,hur8o1,https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/,1,1595271389.0,
167,deeplearning,gpt-3,comments,2023-01-22 10:12:08,"BigScience BLOOM, how should we use it?",Haghiri75,False,1.0,5,10igecg,https://www.reddit.com/r/deeplearning/comments/10igecg/bigscience_bloom_how_should_we_use_it/,1,1674382328.0,"Since the release of BLOOM, I always wanted to test it the way GPT-3 (and newly released ChatGPT) are tested. Having a playground with the ability to explore settings and even generating codes and stuff. But I don't know how long was it (I guess almost a year) and the only thing *close to playground* it had was the huggingface model card.

So is there any reliable way to use BLOOM in a proper way?"
168,deeplearning,gpt-3,comments,2022-08-14 10:58:04,OneFlow v0.8.0 Came Out!,Just0by,False,1.0,6,wo3o9l,https://www.reddit.com/r/deeplearning/comments/wo3o9l/oneflow_v080_came_out/,1,1660474684.0,"Hi all,

We are thrilled to announce the new release of [**OneFlow**](https://github.com/Oneflow-Inc/oneflow)**, which is a deep learning framework designed to be user-friendly, scalable and efficient.** OneFlow v0.8.0 update contains 523 commits. For the full changlog, please check out: [**https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.8.0**](https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.8.0).  


**Paper:** [https://arxiv.org/abs/2110.15032](https://arxiv.org/abs/2110.15032);  
**Code:** [https://github.com/Oneflow-Inc/oneflow](https://github.com/Oneflow-Inc/oneflow)

Welcome to install OneFlow v0.8.0 for a new user experience. Your feedbacks will be much appreciated!

Highlights and optimizations in this release:

**1. PyTorch API compatibility**

OneFlow v0.8.0 provides more and better PyTorch compatible APIs. In v0.8.0, a series of new features and interfaces that are compatible with PyTorch 1.10.0 are in place, including 68 new APIs that are aligned with PyTorch; 84 bugs are fixed to ensure better compatibility between operators and interfaces, allowing users to transfer more PyTorch models to OneFlow with just one click.

&#x200B;

**2. Wider support of global operators**

All operators support Global Tensor more widely and efficiently. Fixed 28 bugs related to Global Tensor and added 180 Global operator unit tests, making the development of distributed models with Global Tensor faster and easier.

&#x200B;

**3. Better performance**

The advanced features of Graph have been improved for better performance:

In addition to the original ZeRO-DP, ZeRO can be used in parallel with MP, 2-D, and 3-D to further reduce memory overhead.

Added a new pipeline parallelism API for Graph to simplify the configuration for pipeline parallelism and accelerate training when using pipeline parallelism and 3-D parallelism.

Added debugging features in multiple dimensions, including logical graphs, light plan physical graphs, memory analysis, and Python stack information, to further improve efficiency of Graph.debug.

The combination of OneFlow v0.8.0 and LiBai v0.2.0 enables higher computation speeds of GPT and BERT under 3-D parallelism on multiple dimensions, surpassing those of Megatron-LM with the same configurations. (For more details, see: [https://libai.readthedocs.io/en/latest/tutorials/get\_started/Benchmark.html](https://libai.readthedocs.io/en/latest/tutorials/get_started/Benchmark.html)).

&#x200B;

**4. OneEmbedding component**

OneEmbedding is an extended component specifically designed for large-scale recommender systems. It boasts excellent performance, extensibility, and flexibility.

API Documentation: [https://docs.oneflow.org/en/master/cookies/one\_embedding.html](https://docs.oneflow.org/en/master/cookies/one_embedding.html)

&#x200B;

**5. Multi-Device adaptation**

OneFlow v0.8.0 provides a neat, efficient, and easily extensible hardware abstraction layer EP (Execution Provider) to adapt to different hardware. With the introduction of the hardware abstraction layer, no modifications are needed for any module of the framework to adapt to new hardware devices, regardless of the implementation details of any underlying hardware or framework.

To make the new hardware devices work, users only need to implement a series of interfaces based on the protocols of the hardware abstraction interfaces and the status quo of the hardware devices.

EP also defines a set of basic computing interface primitives, allowing the reimplementation of kernels. Primitives provide interfaces that are more flexible than the runtime interfaces provided by EP. Different interfaces are independent of each other, and each interface represents a kind of computing capability that can be provided by a certain hardware device.

**6. Debugging tool stack**

New debug tools: OneFlow-Profiler and AutoProf.

OneFlow-Profiler is a tool used to collect performance information during framework execution. It can keep records of the execution time of operators and system components, the allocation of memory, and the corresponding input and parameters of operators. All this information helps developers find out the main source of overhead in framework execution and thus implement targeted optimization.

AutoProf is a framework for testing the performance of OneFlow and PyTorch operators. It provides an elegant and efficient method to detect the alignment between OneFlow APIs and PyTorch APIs, allowing users to conveniently compare the performance of OneFlow APIs and PyTorch APIs.

**7. Error message**

Improved error message with more details. Refactored exception handling.

&#x200B;

**8. API documentation**

Made over 20 revisions to the OneFlow API documentation, restructured the documentation based on features, and added further elaboration of modules and environment variables including OneFlow oneflow.nn.graph, oneflow.embedding, and oneflow.autograd, in addition to the general operator APIs."
169,deeplearning,gpt-3,comments,2020-07-24 09:50:27,[Tutorial] Sentence to SQL Converter using GPT-3,bhavesh91,False,0.8,6,hwyz1v,https://www.reddit.com/r/deeplearning/comments/hwyz1v/tutorial_sentence_to_sql_converter_using_gpt3/,1,1595584227.0,"I created a simple Sentence to SQL Converter using GPT - 3. If you want to learn how you can use OpenAI's GPT-3 to generate NLP Applications then this simple tutorial should help.Video Link : [https://www.youtube.com/watch?v=9g66yO0Jues](https://www.youtube.com/watch?v=9g66yO0Jues)

https://reddit.com/link/hwyz1v/video/79gg5vrj1sc51/player"
170,deeplearning,gpt-3,comments,2021-12-21 11:31:55,Pretrained models on other data than language,jssmith42,False,0.9,8,rlcs2a,https://www.reddit.com/r/deeplearning/comments/rlcs2a/pretrained_models_on_other_data_than_language/,1,1640086315.0,"Are there pretrained models like GPT-3 but that are trained on different inputs and outputs?

I am picturing a model that can clean and restructure Excel data by being shown a few example clean ups. I guess the inputs and outputs would be Excel files, but it would be cool if there was a training front-end software sort like what Prodigy is for data-labelling.

Thank you"
171,deeplearning,gpt-3,comments,2022-12-02 20:59:47,Everyone: AI will make it easy to spread misinformation; Me: Stop hitting yourself GPT3!,hayAbhay,False,0.89,37,zaxg5m,https://i.redd.it/mrf9rz0ltj3a1.png,0,1670014787.0,
172,deeplearning,gpt-3,comments,2021-06-02 16:48:40,"AI Weekly Update - June 2nd, 2021",HenryAILabs,False,1.0,5,nqqb39,https://www.reddit.com/r/deeplearning/comments/nqqb39/ai_weekly_update_june_2nd_2021/,0,1622652520.0,"New AI Weekly Update - June 2nd, 2021 (#33!)

* Deep Learning with Code Data
* Reward is Enough
* AndroidEnv
* CogView
* Medically-aware GPT-3

https://youtu.be/6ic2PuWGhuA"
173,deeplearning,gpt-3,comments,2020-06-16 07:35:17,GPT-3 from OpenAI is here [video review],przemekc,False,0.33,0,h9z59j,https://youtu.be/OznMk5Jexu8,0,1592292917.0,
174,deeplearning,gpt-3,comments,2022-01-09 16:11:37,General Purpose Reading Models,HenryAILabs,False,0.83,4,rzuykx,https://www.reddit.com/r/deeplearning/comments/rzuykx/general_purpose_reading_models/,0,1641744697.0,"GPT-3 has successfully been campaigned as a General-Purpose API -- all you need is to provide a few examples of a task and it promises generalization to future inferences.

I think separating Deep Learning models into retrieve-then-read pipelines makes much more sense for general purpose functionality. Retrieval offers:  


* Interpretability
* Ease to update information
* Less parameters needed because you do not need to store the data in the parameters

This video explains some of these ideas and the benefits of separating retrieval and reading, I hope you find it interesting!   


https://www.youtube.com/watch?v=mRcuNtMOmZw"
175,deeplearning,gpt-3,comments,2022-09-08 17:35:18,Using State-Of-The-Art Artificial Intelligence (AI) Models for Free: Try OPT-175B on Your Cellphone and Laptop,ai-lover,False,1.0,1,x96n5i,https://www.reddit.com/r/deeplearning/comments/x96n5i/using_stateoftheart_artificial_intelligence_ai/,0,1662658518.0,"When it comes to large AI models, remarkable performance in a wide range of applications often brings a big budget for hardware and running costs.  As a result, most AI users, like researchers from startups or universities, can do nothing but get overwhelmed by striking news about the cost of training large models.

Fortunately, because of the help from the open source community, serving large AI models became easy, affordable and accessible to most. 

### OPT-175B

To understand the technical principles of the big model inference we just experienced, first, let’s review the big model we just used.

The full name of OPT is *Open Pretrained Transformer*, which is a large-scale Transformer model (175 billion parameters) that has a similar performance to that of GPT-3.

[Continue reading](https://www.marktechpost.com/2022/09/08/using-state-of-the-art-artificial-intelligence-ai-models-for-free-try-opt-175b-on-your-cellphone-and-laptop/) | [Open Source Code](https://github.com/hpcaitech/ColossalAI) |[Cloud Service Entry](https://service.colossalai.org/)

&#x200B;

https://preview.redd.it/gi5e7d0u7om91.png?width=1024&format=png&auto=webp&s=bb276bb3aaeb9c9db28f97758c3546cbc1c623bf"
176,deeplearning,gpt-3,comments,2020-06-16 03:13:01,"I just published ""All you need to need to know about OPENAI's GPT-3 "" on medium . Check out , feedback is highly appreciated..",dharma_m,False,0.64,6,h9ve0q,https://medium.com/@savanidharmam5/all-you-need-to-know-about-openai-gpt-3-d0d879446aeb,0,1592277181.0,
177,deeplearning,gpt-3,comments,2020-09-16 16:02:55,"Practical Natural Language Processing Book [Interview + Giveaway] | NLP, ML & AI in the Industry | GPT-3 and more",mukulkhanna1,False,0.84,22,ityg5g,https://youtu.be/ptTlH-ma8rg,0,1600272175.0,
178,deeplearning,gpt-3,comments,2023-04-22 04:48:57,Help give feedback on an AI generated comic system,laa_k,False,0.25,0,12uv0og,https://www.reddit.com/r/deeplearning/comments/12uv0og/help_give_feedback_on_an_ai_generated_comic_system/,0,1682138937.0," Over the past few months, some colleagues and I have put together a system based on ChatGPT, Stable Diffusion, and other AI tools to create simple 3-panel comic strips. We would appreciate 5 minutes of your time to help us evaluate the system and its outputs by taking the following survey:

[https://qfreeaccountssjc1.az1.qualtrics.com/jfe/form/SV\_5haZc4idQ7mkbUG](https://qfreeaccountssjc1.az1.qualtrics.com/jfe/form/SV_5haZc4idQ7mkbUG)

Thank You!

&#x200B;

https://preview.redd.it/hkhwwtm59dva1.png?width=1556&format=png&auto=webp&s=c9b10687d93f3d6d475da8feb3ad978d304cd9db"
179,deeplearning,gpt-3,comments,2020-10-28 11:39:21,How did I get access to GPT-3 OpenAI's API? Tips are shared at 4:45 in the video! The rest of the videos explains what can GPT-3 really do and how it can help you or your company.,OnlyProggingForFun,False,0.42,0,jjm4ep,https://www.youtube.com/watch?v=Gm4AMjV8ErM,0,1603885161.0,
180,deeplearning,gpt-3,comments,2022-02-11 16:47:38,Interview with Arvind Neelakantan about the OpenAI Embeddings API,HenryAILabs,False,1.0,2,sq3s05,https://www.reddit.com/r/deeplearning/comments/sq3s05/interview_with_arvind_neelakantan_about_the/,0,1644598058.0,"Hey everyone!   


The release of OpenAI's Embeddings API has been quite the story! I had the pleasure to interview Arvind Neelakantan on miscellaneous topics pertaining to these new advances in Search: [https://www.youtube.com/watch?v=uFxfZ0vLsoU](https://www.youtube.com/watch?v=uFxfZ0vLsoU)  


Additional Background on this:  
OpenAI Embeddings API Blog Post: [https://openai.com/blog/introducing-text-and-code-embeddings/](https://openai.com/blog/introducing-text-and-code-embeddings/)

Nils Reimers' Response (OpenAI GPT-3 Text Embeddings - Really a new state-of-the-art in dense text embeddings?): [https://medium.com/@nils\_reimers/openai-gpt-3-text-embeddings-really-a-new-state-of-the-art-in-dense-text-embeddings-6571fe3ec9d9](https://medium.com/@nils_reimers/openai-gpt-3-text-embeddings-really-a-new-state-of-the-art-in-dense-text-embeddings-6571fe3ec9d9)

Yannic Kilcher on the topic: [https://www.youtube.com/watch?v=5skIqoO3ku0](https://www.youtube.com/watch?v=5skIqoO3ku0)"
181,deeplearning,gpt-3,comments,2021-08-11 15:48:33,"Watch out, GPT-3, here comes AI21's 'Jurassic' language model | ZDNet",lindaarden,False,0.63,2,p2fqcs,https://www.zdnet.com/article/watch-out-gpt-3-here-comes-ai21s-jurassic-language-model/,0,1628696913.0,
182,deeplearning,gpt-3,comments,2023-02-02 20:16:45,1-click deploy for your GPT-3 App,VideoTo,False,0.67,1,10rzn7z,https://www.reddit.com/r/deeplearning/comments/10rzn7z/1click_deploy_for_your_gpt3_app/,0,1675369005.0,"Link - [https://github.com/ClerkieAI/berri\_ai](https://github.com/ClerkieAI/berri_ai)

We  made a package that makes it easy for developers to quickly deploy  their LLM Agent from Google Colab to production (Web App and API  Endpoint).

**How it works?**

Just install the package, import the function, and run deploy.

At the end of the deploy (\~10-15mins), you will get:

1. A web app to interact with your agent 👉  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/)
2. An endpoint you can query 👉  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/langchain_agent?query=%22who) is obama?""

Want a more detailed walkthrough? Check out our loom - [https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43](https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43)

We’re still early so would love your feedback and opinions. Feel free to try   us out for free – and if you need help building an agent / want a   specific integration, just let us know!

https://i.redd.it/s53l400o2ufa1.gif"
183,deeplearning,gpt-3,comments,2021-08-25 02:37:52,[N] AI Can Write in English. Now It's Learning Other Languages - Wired,ClaudeCoulombe,False,1.0,3,pb27l2,https://www.reddit.com/r/deeplearning/comments/pb27l2/n_ai_can_write_in_english_now_its_learning_other/,0,1629859072.0,An interesting [Wired 's paper](https://www.wired.com/story/ai-write-english-learning-other-languages/). A growing number of startups outside USA are building general-purpose GPT-3 like  language models and tools.
184,deeplearning,gpt-3,comments,2023-04-01 17:50:06,Fine-tune GPT on sketch data (stroke-3),mellamo_maria,False,1.0,1,128tfvc,https://www.reddit.com/r/deeplearning/comments/128tfvc/finetune_gpt_on_sketch_data_stroke3/,0,1680371406.0," These past days I have started a personal project where I would like to build a model that, given an uncompleted sketch, it can finish it. I was planning on using some pretrained models that are available in HuggingFace and fine-tune them with my sketch data for my task. The sketch data I have is in stoke-3 format, like the following example:  
\[  
\[10, 20, 1\],  
\[20, 30, 1\],  
\[30, 40, 1\],  
\[40, 50, 0\],  
\[50, 60, 1\],  
\[60, 70, 0\]  
\]  
The first value of each triple is the X-coordinate, the second value the Y-coordinate and the last value is a binary value indicating whether the pen is down (1) or up (0). I was wondering if you guys could give me some instruction/tips about how should I approach this problem? How should I prepare/preprocess the data so I can fit it into the pre-trained models like BERT, GPT, etc. Since it's stroke-3 data and not text or a sequence of numbers, I don't really know how should I treat/process the data.

Thanks a lot! :)"
185,deeplearning,gpt-3,comments,2023-05-19 18:55:34,How To Reduce The Cost Of Using LLM APIs by 98%,LesleyFair,False,0.71,3,13m4e1k,https://www.reddit.com/r/deeplearning/comments/13m4e1k/how_to_reduce_the_cost_of_using_llm_apis_by_98/,0,1684522534.0,"[Budget For LLM Inference](https://preview.redd.it/xprd070u4u0b1.png?width=493&format=png&auto=webp&s=dad41692ad4cd22e768e92baabfd566ddef468e8)

Cost is still a major factor when scaling services on top of LLM APIs.

Especially, when using LLMs on large collections of queries and text it can get very expensive. It is [estimated](https://neoteric.eu/blog/how-much-does-it-cost-to-use-gpt-models-gpt-3-pricing-explained/) that automating customer support for a small company can cost up to $21.000 a month in inference alone.

The inference costs differ from vendor to vendor and consists of three components:

1. a portion that is proportional to the length of the prompt
2. a portion that is proportional to the length of the generated answer
3. and in some cases a small fixed cost per query.

In a recent [publication](https://arxiv.org/pdf/2305.05176.pdf) researchers at Stanford proposed three types of strategies that can help us to slash costs. The cool thing about it is that we can use these strategies in our projects independently of the prices dictated by the vendors!

*Let’s jump in!*

**How To Adapt Our Prompts To Save Costs**

Most approaches to prompt engineering typically focus only on increasing performance.

In general, prompts are optimized by providing more detailed explanations of the desired output alongside multiple in-context examples to steer the LLM. However, this has the tendency to result in longer and more involved prompts. Since the cost per query grows linearly with the number of tokens in our prompt this makes API requests more expensive.

The idea behind the first approach, called Query Adaption, is to create effective (often shorter) prompts in order to save costs.

This can be done in different ways. A good start is to reduce the number of few-shot examples in your prompt. We can experiment to find out what the smallest set of examples is that we have to include in the prompt to maintain performance. Then, we can remove the other examples.

So far so good!

Once we have a more concise prompt, there is still another problem. Every time a new query is processed, the same in-context examples and detailed explanations to steer the model are processed again and again.

The way to avoid this redundant prompt processing is by applying query concatenation.

In essence, this means that instead of asking one question in our lengthy prompt, we add multiple questions Q1, Q2, … in the same prompt. To get this to work, we might need to add a few tokens to the prompt that make it easier for us to separate the answers from the model output. However, the majority of our prompt is not repeatedly sent to the API as a result.

This allows us to process dozens of queries at once, making query concatenation a huge lever for cost savings while being relatively easy to implement.

*That was an easy win! Let’s look at the second approach!*

**LLM Approximation**

The idea here is to emulate the performance of a better, more expensive model.

In the paper, they suggest two approaches to achieve this. The first one is to create an additional caching infrastructure that alleviates the need to perform an expensive API request for every query. The second way is to create a smaller, more specialized model that mimics what the model behind the API does.

Let’s look at the caching approach!

The idea here is that every time we get an answer from the API, we store the query alongside the answer in a database. We then pre-compute embeddings for every stored query. For every new query that comes in, we do not send it off to our LLM vendor of choice. Instead, we perform a vectorized search over our cached query-response pairs.

If we find a question that we already answered in the past, we can simply return the cached answer without accruing any additional cost. This obviously works best if we repeatedly need to process similar requests and the answers to the questions are evergreen.

Now let’s move on to the second approach!

Don’t worry! The idea is not to spend hundreds of thousands of dollars to fine-tune an LLM. If the overall variety of expected questions and answers is not crazy huge - which for most businesses it is not - a BERT-sized model should probably do the job.

The process could look as follows: first, we collect a dataset of queries and answers that are generated with the help of an API. The second step is to fine-tune the smaller model on these samples. Third, use the fine-tuned model on new incoming queries.

To reduce the cost even further, It could be a good approach to implement the caching first before starting to train a model. This has the advantage of passively building up a dataset of query-answer pairs during live operation. Later we can still actively generate a dataset if we run into any data quality concerns such as some queries being underrepresented.

A pretty cool byproduct of using one of the LLM approximation approaches is that they can significantly reduce latency.

Now, let’s move on to the third and last strategy which has not only the potential to reduce costs but also improve performance.

**LLM Cascade**

More and more LLM APIs have become available and they all vary in cost and quality.

The idea behind what the authors call an LLM Cascade is to start with the cheap API and then successively call APIs of increasing quality and cost. Once an API returns a satisfying answer the process is stopped. Especially, for simpler queries this can significantly reduce the costs per query.

*However, there is a catch!*

How do we know if an answer is satisfying? The researchers suggest training a small regression model which scores the reliability of an answer. Once this reliability score passes a certain threshold the answer gets accepted.

One way to train such a model would obviously be to label the data ourselves.

Since every answer needs only a binary label (reliable vs. unreliable) it should be fairly inexpensive to build such a dataset. Better still we could acquire such a dataset semi-automatically by asking the user to give feedback on our answers.

If running the risk of serving bad answers to customers is out of the question for whatever reason, we could also use one of the stronger APIs (*cough* GPT ***cough***) to label our responses.

In the paper, the authors conduct a case study of this approach using three popular LLM APIs. They successively called them and used a DistillBERT (very small) to perform scoring. They called this approach FrugalGPT and found that the approach could save up to 98.3% in costs on the benchmark while also improving performance.

How would this increase performance you ask?

Since there is always some heterogeneity in the model’s outputs a weaker model can actually sometimes produce a better answer than a more powerful one. In essence, calling multiple APIs gives more shots on goal. Given that our scoring model works well, this can result in better performance overall.

In summary, strategies such as the ones described above are great because they attack the problem of high inference costs from a different angle. They allow us to be more cost-effective without relying on the underlying models to get cheaper. As a result, it will become possible to use LLMs for solving even more problems!

What an exciting time to be alive!

Thank you for reading!

As always, I really enjoyed making this for you and sincerely hope you found it useful! At The Decoding ⭕, I send out a thoughtful 5-minute email every week that keeps you in the loop about machine learning research and the data economy. [Click here to subscribe](http://thedecoding.net)!"
186,deeplearning,gpt-3,comments,2022-12-22 09:57:14,"Show ChatGPT's response next to the search results from Google, Bing, and DuckDuckGo.",Harrypham22,False,1.0,1,zsics7,https://www.reddit.com/r/deeplearning/comments/zsics7/show_chatgpts_response_next_to_the_search_results/,0,1671703034.0," **Do you know about ChatGPT?** 

It is a variant of the GPT-3 language model developed by OpenAI specifically designed for generating responses to user input in chat or messaging applications. It is trained on a large dataset of conversation data and is able to understand the context of a conversation and generate appropriate responses. ChatGPT is particularly well-suited for use in chat or messaging applications, but it can also be used for a wide range of other natural language processing tasks, such as language translation, summarization, and question answering.

**Display ChatGPT response alongside other search engine results (Google,Bing,Duck go go,..)**

***ChatGPT for Search Engines*** is an AI-based extension that could potentially become a real threat to any search engine.

It basically shows results to all sorts of queries next to the Google results (or other search engine). The precision is very impressive. This extension makes it possible everywhere you browse

This is a simple extension that show response from ChatGPT alongside Google and other search engines

Features:

\* Markdown rendering

\* Code hightlights

\* Feedback buttons

\* Custom trigger mode

Maybe you should try this extension: [shorturl.at/eqZ78](https://shorturl.at/eqZ78)

Watch this video to see how it work: [https://www.tiktok.com/@ai\_life26/video/7179865803003579674](https://www.tiktok.com/@ai_life26/video/7179865803003579674)

https://preview.redd.it/ojjxcy2q9f7a1.png?width=1294&format=png&auto=webp&s=e3b02aba9ba03f37dbdcd0a2c6265a95b9f11ed8"
187,deeplearning,gpt-3,comments,2023-01-26 21:26:30,Create Your Chat GPT-3 Web App with Streamlit in Python,pasticciociccio,False,0.43,0,10m3034,https://levelup.gitconnected.com/create-your-chat-gpt-3-web-app-with-streamlit-in-python-f0c6e6aede0a,0,1674768390.0,
188,deeplearning,gpt-3,comments,2023-09-07 13:32:18,Apple is reportedly spending ‘millions of dollars a day’ training AI,Nalix01,False,0.38,0,16cfywf,https://www.reddit.com/r/deeplearning/comments/16cfywf/apple_is_reportedly_spending_millions_of_dollars/,0,1694093538.0,"Apple is spending millions daily on artificial intelligence, with several teams working on different AI models. They believe that their Ajax model surpasses OpenAI's GPT-3.5.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso).

**Conversational AI Team**

* **Focus on Siri improvement**: The “Foundational Models” unit, consisting of about 16 members, works on conversational AI. John Giannandrea, Apple’s AI head and previously a Google engineer, leads the team with a primary goal to enhance Siri.
* **What the is going to be improved:** One of its goals is to develop features that would allow iPhone users to use simple voice commands to automate tasks involving multiple steps.

**Other AI Developments**

* **Visual intelligence**: Another unit is engaged in creating an image generation model.
* **Multimodal AI**: A separate team is researching AI that can understand and generate text, images, or video.

**Ajax Outshines GPT-3.5**

* **More advanced**: Ajax GPT, Apple's leading language model, has been trained with over 200 billion parameters, reportedly surpassing OpenAI’s GPT-3.5.
* **Limited access**: Although advanced, this model was intended for internal usage and remains restricted within Apple.

[Source (The Verge)](https://www.theverge.com/2023/9/6/23861763/apple-ai-language-models-ajax-gpt-training-spending)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso) that summarizes the best AI/tech news from 50+ media (TheVerge, TechCrunch…). It’s already being read by **6,000+** professionals from **OpenAI, Google, Meta**…"
189,deeplearning,gpt-3,comments,2020-07-30 13:37:36,[Tutorial] Generate Python code & Matplotlib graphs using GPT-3.,bhavesh91,False,0.57,1,i0m6cn,https://www.reddit.com/r/deeplearning/comments/i0m6cn/tutorial_generate_python_code_matplotlib_graphs/,0,1596116256.0,"I created a simple application which generates Python code & Matplotlib Graphs using GPT-3. If you want to learn how you can use OpenAI's GPT-3 to generate NLP Applications then this simple tutorial should help. Video Link : [https://www.youtube.com/watch?v=z8K07a2EIcE](https://www.youtube.com/watch?v=z8K07a2EIcE)

https://i.redd.it/u1gpz8bkzzd51.gif"
190,deeplearning,gpt-3,comments,2021-12-20 16:17:11,[R] OpenAI’s WebGPT Crawls a Text-Based Web Environment to Achieve Human-Level Performance on Long-Form QA,Yuqing7,False,0.8,3,rkqv80,https://www.reddit.com/r/deeplearning/comments/rkqv80/r_openais_webgpt_crawls_a_textbased_web/,0,1640017031.0,"An OpenAI research team fine-tunes the GPT-3 pretrained language model to enable it to answer long-form questions by searching and navigating a text-based web browsing environment, achieving retrieval and synthesis improvements and reaching human-level long-form question-answering performance. 

Here is a quick read:[OpenAI’s WebGPT Crawls a Text-Based Web Environment to Achieve Human-Level Performance on Long-Form QA.](https://syncedreview.com/2021/12/20/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-169/)

The paper *WebGPT: Browser-assisted Question-answering with Human Feedback* is on [OpenAI.com](https://openai.com/blog/improving-factual-accuracy/)."
191,deeplearning,gpt-3,comments,2023-05-23 14:14:45,New Weaviate Podcast - Unstructured!,CShorten,False,0.76,2,13ppstr,https://www.reddit.com/r/deeplearning/comments/13ppstr/new_weaviate_podcast_unstructured/,0,1684851285.0,"ChatWithPDF has been one of the most captivating applications of the latest wave of ChatGPT and pairing ChatGPT with Retrieval-Augmentation and Vector Databases! As exciting as this is, there is a glaring problem... how do I get the text data out of my PDFs?

This is the problem Unstructured is solving with 3 core abstractions: (1) Partitioning (visually looking at elements on a PDF / Webpage / Resume / Slidedeck / Receipt / ... extracting the text data and adding metadata such as ""header"", ""body"", or ""image caption"", (2) Cleaning (I'm sure everyone in this group who has worked with text data has seen these ridiculous character encoding problems, regex, and whitespace removals we need to clean our text data for NLP pipelines), and (3) Staging (this describes extracting the JSONs / etc. to pass this data into another system such as Weaviate as an example)

I really hope you enjoy the podcast -- I think these innovations are so exciting for unlocking our data into these LLM systems!

[https://www.youtube.com/watch?v=b84Q2cJ6po8](https://www.youtube.com/watch?v=b84Q2cJ6po8)"
192,deeplearning,gpt-3,comments,2022-06-15 16:07:22,Join us for the OpenAI GPT-3 Deep Learning Labs Hackathon!,zakrzzz,False,0.9,8,vcxzp4,https://www.reddit.com/r/deeplearning/comments/vcxzp4/join_us_for_the_openai_gpt3_deep_learning_labs/,0,1655309242.0,"We are waiting for all of you, AI enthusiasts with coding experience and without, on the 24th - 26th of June to help you turn your ground-breaking ideas into reality!

Register here - [https://lablab.ai/event/gpt3-online](https://lablab.ai/event/gpt3-online)  


https://preview.redd.it/mhr93wgo6t591.png?width=1600&format=png&auto=webp&s=07e23c79830db8061eb300f76b64588b01219ebc"
193,deeplearning,gpt-3,comments,2021-06-17 19:51:07,[R] Improving Language Model Behavior by Training on a Small Curated Dataset,ClaudeCoulombe,False,0.8,3,o262ql,https://www.reddit.com/r/deeplearning/comments/o262ql/r_improving_language_model_behavior_by_training/,0,1623959467.0,"Interesting research results by [OpenAI](https://openai.com/blog/improving-language-model-behavior/). It seems possible to improve the behavior of  a  GPT-3 language model  by fine tuning it  on a very small dataset. Of course, we are talking about undesirable biases (hateful, agressive, racist, sexist, etc.). They only used 80 texts. On the other hand, they neglect to say that someone can very well adjust the generated texts to favor biased texts with again a very small corpus. The [scientific paper](https://cdn.openai.com/palms.pdf) (PDF)."
194,deeplearning,gpt-3,comments,2023-12-12 12:10:06,[D] Crafting Visually Stunning Slides with Assistants API (GPT-4) and DALL·E-3,Fit_Maintenance_2455,False,0.5,0,18gkhbu,https://www.reddit.com/r/deeplearning/comments/18gkhbu/d_crafting_visually_stunning_slides_with/,0,1702383006.0,"In the realm of presentations, creating visually compelling slides that effectively communicate data insights is a skill coveted by professionals across diverse industries. However, the traditional process of manually constructing these slides can be a time-consuming endeavor. Enter the new Assistants API (GPT-4) and DALL·E-3, revolutionary tools that streamline the slide creation process, offering efficiency and visual finesse.

Crafting slides that capture the essence of complex data sets while maintaining audience engagement is a multifaceted challenge. It demands a blend of data interpretation, storytelling finesse, and an eye for design. Traditionally, this process involves laborious manual work, from structuring information to selecting images and formatting layouts.

&#x200B;

link: [https://medium.com/ai-advances/crafting-visually-stunning-slides-with-assistants-api-gpt-4-and-dall-e-3-f862368cec44](https://medium.com/ai-advances/crafting-visually-stunning-slides-with-assistants-api-gpt-4-and-dall-e-3-f862368cec44) "
195,deeplearning,gpt-3,comments,2023-10-04 15:06:32,Custom LLM,Relative_Winner_4588,False,1.0,2,16zpnjz,https://www.reddit.com/r/deeplearning/comments/16zpnjz/custom_llm/,0,1696431992.0,"
I'm eager to develop a Large Language Model (LLM) that emulates ChatGPT, tailored precisely to my specific dataset. While I'm aware of existing models like Private-GPT and Gpt4all, my ultimate goal is to either create a custom LLM from scratch or fine-tune a pre-existing model like BERT or GPT-7B to meet my unique requirements.

I've been closely following Andrej Karpathy's instructive lecture on building GPT-like models. However, I've noticed that the model only generated text akin to Shakespearean prose in a continuous loop instead of answering questions. I'm striving to develop an LLM that excels at answering questions based on the data I provide.

The core objectives I'm pursuing encompass:
1. Effective data preparation tailored for question-answering tasks.
2. The strategic selection of a pre-trained model, such as BERT or GPT-7B.
3. Rigorous performance evaluation, employing pertinent metrics.
4. The creation of an efficient inference system that facilitates question input and response generation.

Please guide me for this objectives or provide me some resources for the same.

DM me if you want to talk in detail."
196,deeplearning,gpt-3,comments,2023-09-28 13:34:24,First Impressions with GPT-4V(ision),zerojames_,False,0.67,3,16ug8gc,https://www.reddit.com/r/deeplearning/comments/16ug8gc/first_impressions_with_gpt4vision/,0,1695908064.0,"My colleague Piotr and I have been testing GPT-4V(ision) over the last day. We wrote up our findings, covering how GPT-4V performs on:

1. Visual question answering (VQA) across a range of domains (locations, movies, plants)
2. OCR
3. Math OCR
4. Object detection
5. And more

TL;DR: GPT-4V performed well for VQA and document OCR but struggled with OCR on real-world images and object detection (where we asked for bounding boxes).

[https://blog.roboflow.com/gpt-4-vision/](https://blog.roboflow.com/gpt-4-vision/)

I would love to hear what other people have found working with GPT-4V."
197,deeplearning,gpt-3,comments,2023-04-01 14:01:42,Revolutionizing Content Creation: Moji AI's Impact on Social Media and Beyond,Large_Rush9013,False,0.25,0,128nbfn,https://www.reddit.com/r/deeplearning/comments/128nbfn/revolutionizing_content_creation_moji_ais_impact/,0,1680357702.0,"Hey fellow Redditors, I recently stumbled upon a summary of an incredible new AI content tool called Moji AI, and I just had to share my thoughts about it. I think it has the potential to be a game-changer for content creators!

Moji AI is designed to make content creation easier by using the power of GPT-4 to generate text and Stable Diffusion Models to create eye-catching images. It offers icons and image assets that can significantly boost social media engagement. As a Reddit user, I'm always trying to find new ways to share content and start conversations, and I think the potential benefits of this tool are undeniable.

I've been aware of GPT-3 for a while now, and the thought of GPT-4 being a more powerful version gets me excited about what it could mean for the future of AI-generated content. The fact that Moji AI can not only generate text, but also customize images and icons, makes it seem like a must-have tool for anyone serious about making an impact on social media platforms.

The Stable Diffusion Models used by Moji AI allow it to create visually stunning images that are bound to catch the attention of users as they're scrolling through their feeds. It's not just about the text anymore - visuals are crucial in today's social media landscape, and Moji AI is tackling that aspect head-on.

I can already think of countless ways to apply Moji AI in both personal and professional projects. Imagine effortlessly creating engaging blog posts, social media posts, and digital marketing campaigns without the hassle of finding a graphic designer or a copywriter. This tool seems too good to be true!

For those of you who are interested in learning more about Moji AI and how it can elevate your content creation game, I urge you to check out their website at [mojiai.io](https://mojiai.io). I'm excited to see the applications of this tool, and I believe that it'll revolutionize how we create and share content moving forward.

Indeed, it's exciting to be part of a community that is always at the forefront of groundbreaking innovations like Moji AI! Feel free to share your thoughts and ideas about how you think Moji AI could impact the world of content creation. Let's start a conversation!"
198,deeplearning,gpt-3,comments,2020-10-30 01:48:31,Generating Snort Rules using GPT2,afoteygh,False,1.0,1,jkntfp,https://www.reddit.com/r/deeplearning/comments/jkntfp/generating_snort_rules_using_gpt2/,0,1604022511.0,"Hi I have been working on Generating Snort rules using the GPT2 Transformer.

This is my thinking

1. Snort rules for a particular family of malware are quite related. that is why these malware have been classified into that family so using text generation to generate new rules should be possible (i Feel)
2. Collect Snort rules for a particular malware family. (Also collect pcap which trigger these specific rules i have obtained)
3. Clean it up by removing commented/unused rules.
4. Feed the rules to GPT2 (124M) (I chose this because i read it performs quite well in text generation )
5. Trained GPT on the dataset
6. using it to generated new rules
7. clean up the rules (syntax etc)
8. Test newly generated rules in snort with sample pcap files.

So for i have been able to generate and clean up 1000's of rules and tested them without any success!

Can anyone give me some guidance on what i am doing wrong or if my whole hypothesis and experiment is flawed."
199,deeplearning,gpt-3,comments,2022-01-31 11:00:50,Searching participants for art project about AI,Nebeldiener,False,1.0,4,sgyojm,https://www.reddit.com/r/deeplearning/comments/sgyojm/searching_participants_for_art_project_about_ai/,0,1643626850.0,"Hi,

I’m part of an art group from Switzerland currently studying at HSLU Design & Arts ([https://www.hslu.ch/de-ch/design-kunst/studium/bachelor/camera-arts/](https://www.hslu.ch/de-ch/design-kunst/studium/bachelor/camera-arts/)).

The group consists of:

Karim Beji ([https://www.instagram.com/karimbeji\_/](https://www.instagram.com/karimbeji_/) [https://karimbeji.ch/](https://karimbeji.ch/))

Emanuel Bohnenblust ([https://www.instagram.com/e.bohnenblust/](https://www.instagram.com/e.bohnenblust/))

Lea Karabash ([https://www.instagram.com/leakarabashian/](https://www.instagram.com/leakarabashian/))

Yen Shih-hsuan ([https://www.instagram.com/shixuan.yan/](https://www.instagram.com/shixuan.yan/) [http://syen.hfk-bremen.de/](http://syen.hfk-bremen.de/))

At the moment, we are working on a project on the topic if AI can augment the happiness of humans. To answer this question, we are mainly working with chatbots. The end result is going to be an exhibition at the end of March. 

For that exhibition, we want to conduct a trial in which people from over the world chat with a chatbot to find out if and how it augments the mood of the participants. 

We would give you access to a GPT-3 (OpenAI) chatbot and ask you to a) record yourself through a webcam (laptop) while you are chatting and b) simultaneously screen record the chat window. 

In the exhibition we would have a) a book with all the chats and b) small videos with your faces (webcam) to assess your mood. 

We would have a Zoom meeting beforehand to discuss everything.

Looking forward to your message!"
200,deeplearning,gpt-3,relevance,2022-12-02 01:35:02,GPT-3 Generated Rap Battle between Yann LeCun & Gary Marcus,hayAbhay,False,0.99,140,za73dc,https://i.redd.it/ybfcfvez1e3a1.png,16,1669944902.0,
201,deeplearning,gpt-3,relevance,2023-02-05 16:44:56,Beat GPT-3 which has unlimited money using Open Source community,koyo4ever,False,0.81,23,10ugxmc,https://www.reddit.com/r/deeplearning/comments/10ugxmc/beat_gpt3_which_has_unlimited_money_using_open/,8,1675615496.0,"Is it technically possible to train some model using a lot of personal computers like a cluster.

Eg: an Algorithm to train tiny parts of some model using personal computer of volunteers. Like a community that makes your gpu capacity available, even if it's little.

The idea is train tiny parts of a model, with a lot of volunteers, then bring it together to make some powerful deepmind.

Can this model beat a lot of money spent in models like GPT-3?"
202,deeplearning,gpt-3,relevance,2023-02-02 20:16:45,1-click deploy for your GPT-3 App,VideoTo,False,0.67,1,10rzn7z,https://www.reddit.com/r/deeplearning/comments/10rzn7z/1click_deploy_for_your_gpt3_app/,0,1675369005.0,"Link - [https://github.com/ClerkieAI/berri\_ai](https://github.com/ClerkieAI/berri_ai)

We  made a package that makes it easy for developers to quickly deploy  their LLM Agent from Google Colab to production (Web App and API  Endpoint).

**How it works?**

Just install the package, import the function, and run deploy.

At the end of the deploy (\~10-15mins), you will get:

1. A web app to interact with your agent 👉  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/)
2. An endpoint you can query 👉  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/langchain_agent?query=%22who) is obama?""

Want a more detailed walkthrough? Check out our loom - [https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43](https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43)

We’re still early so would love your feedback and opinions. Feel free to try   us out for free – and if you need help building an agent / want a   specific integration, just let us know!

https://i.redd.it/s53l400o2ufa1.gif"
203,deeplearning,gpt-3,relevance,2022-12-03 00:17:31,A GPT-3 based Chrome Extension that debugs your code!,VideoTo,False,1.0,22,zb2kkc,https://www.reddit.com/r/deeplearning/comments/zb2kkc/a_gpt3_based_chrome_extension_that_debugs_your/,0,1670026651.0,"Link - [https://chrome.google.com/webstore/detail/clerkie-ai/oenpmifpfnikheaolfpabffojfjakfnn](https://chrome.google.com/webstore/detail/clerkie-ai/oenpmifpfnikheaolfpabffojfjakfnn)

Built  a quick tool I thought would be interesting - it’s a chrome extension  that uses GPT-3 under the hood to help debug your programming errors  when you paste them into Google (“eg. TypeError:…”).

This is definitely early days, so **if   this is something you would find valuable and wouldn't mind testing a   couple iterations of, please feel free to join the discord** \-> [https://discord.gg/KvG3azf39U](https://discord.gg/KvG3azf39U)

&#x200B;

https://i.redd.it/tt6hcqn2tk3a1.gif"
204,deeplearning,gpt-3,relevance,2023-01-26 21:26:30,Create Your Chat GPT-3 Web App with Streamlit in Python,pasticciociccio,False,0.43,0,10m3034,https://levelup.gitconnected.com/create-your-chat-gpt-3-web-app-with-streamlit-in-python-f0c6e6aede0a,0,1674768390.0,
205,deeplearning,gpt-3,relevance,2022-09-06 11:30:34,Can GPT-3 be honest when it speaks nonsense?,bendee983,False,1.0,1,x785x5,https://bdtechtalks.com/2022/09/05/llm-uncertainty-verbalized-probability/,2,1662463834.0,
206,deeplearning,gpt-3,relevance,2022-02-10 22:10:25,Course on GPT-3 and Transformers,godiswatching_,False,1.0,2,spift0,https://www.reddit.com/r/deeplearning/comments/spift0/course_on_gpt3_and_transformers/,1,1644531025.0,"Hello,   


I was wondering if anyone knows about resources for learning about GPT-3 and Transformer based AI.   Preferably some video series with some project but blogs are just as welcome.

&#x200B;

Thank you."
207,deeplearning,gpt-3,relevance,2023-02-21 11:06:33,I created a Search Engine For Books using GPT-3 🔎📘. Here's how you can create it too:,Pritish-Mishra,False,0.71,6,1180x0e,https://youtu.be/SXFP4nHAWN8,8,1676977593.0,
208,deeplearning,gpt-3,relevance,2021-08-13 16:21:39,Computational Bottleneck of Largest GPT-3,zxcv_qwer1234,False,1.0,7,p3og0n,https://www.reddit.com/r/deeplearning/comments/p3og0n/computational_bottleneck_of_largest_gpt3/,1,1628871699.0,"I know a lot of work is being done to optimize the performance of transformers on very long sequences, but I am curious if there would be any value in optimizing the dense operations in the largest GPT models.  My understanding is that all self-attention operations softmax(QK)V scale linearly with the size of Q, K, and V while the linear projections and FFN would scale to the square of these values (assuming the side of the FFN hidden states also scale linearly with Q, K, and V).  For this reason, with the largest GPT models, is more computation currently being used on linear operations than the self-attention operation itself?"
209,deeplearning,gpt-3,relevance,2021-11-30 16:29:59,Best practices for developing GPT-3 applications,bendee983,False,0.8,6,r5r31f,https://bdtechtalks.com/2021/11/29/gpt-3-application-development-tips/,0,1638289799.0,
210,deeplearning,gpt-3,relevance,2021-12-01 07:53:09,Giving GPT-3 a Voice with Speech Synthesis,Caterpillarfox,False,1.0,7,r69k5w,https://www.reddit.com/r/deeplearning/comments/r69k5w/giving_gpt3_a_voice_with_speech_synthesis/,0,1638345189.0,"I recently came across this article which includes a video that was voiced just like a human. Amazing to create?

Source of Tool: [https://www.resemble.ai/giving-gpt-3-a-voice-with-speech-synthesis/](https://www.resemble.ai/giving-gpt-3-a-voice-with-speech-synthesis/)

Source of Article: [https://thecompetenza.com/net-6/](https://thecompetenza.com/net-6/)"
211,deeplearning,gpt-3,relevance,2022-06-15 16:07:22,Join us for the OpenAI GPT-3 Deep Learning Labs Hackathon!,zakrzzz,False,0.9,8,vcxzp4,https://www.reddit.com/r/deeplearning/comments/vcxzp4/join_us_for_the_openai_gpt3_deep_learning_labs/,0,1655309242.0,"We are waiting for all of you, AI enthusiasts with coding experience and without, on the 24th - 26th of June to help you turn your ground-breaking ideas into reality!

Register here - [https://lablab.ai/event/gpt3-online](https://lablab.ai/event/gpt3-online)  


https://preview.redd.it/mhr93wgo6t591.png?width=1600&format=png&auto=webp&s=07e23c79830db8061eb300f76b64588b01219ebc"
212,deeplearning,gpt-3,relevance,2021-07-28 14:19:34,AI Email Generator Web App with GPT-3,thelazyaz,False,0.85,9,otaun5,https://www.youtube.com/watch?v=oJWBQKrF4uM&feature=youtu.be,1,1627481974.0,
213,deeplearning,gpt-3,relevance,2020-07-28 12:31:26,GPT-3 writes my SQL queries for me,Independent-Square32,False,0.87,55,hzdthe,https://youtu.be/WlMHYEFt2uA,5,1595939486.0,
214,deeplearning,gpt-3,relevance,2022-05-16 16:17:25,OpenAI GPT-3 & Codex Hackathon - Deep Learning Labs Stockholm,zakrzzz,False,1.0,2,uqzmxs,https://www.reddit.com/r/deeplearning/comments/uqzmxs/openai_gpt3_codex_hackathon_deep_learning_labs/,0,1652717845.0," Hello everyone!

Join us this weekend for the Deep Learning Hackathon in Stockholm! We are teaming up with WeWork and OpenAI to bring you an event focused on exploring the latest AI technologies: GPT-3 and Codex. This is a great opportunity to learn, build cool stuff, and meet interesting people. All levels of experience are welcome.

So if you are in Stockholm this weekend, we'll be happy to have you! Also if you know someone who might be interested in participating, let them know, I would be very grateful!

And if you won't be in Stockholm, you can watch the event live at [https://www.twitch.tv/deeplearninglabs](https://www.twitch.tv/deeplearninglabs) We will have some interesting Keynote sessions, fireside chat, and of course teams' demo presentations.

Register here: [https://sthlm.dllhack.com/](https://sthlm.dllhack.com/)

If you have any questions, I'll be happy to answer."
215,deeplearning,gpt-3,relevance,2022-11-13 17:50:42,"Can we possibly get access to large language models (PaLM 540B, etc) like GPT-3 but no cost?",NLP2829,False,0.56,1,yu8oru,https://www.reddit.com/r/deeplearning/comments/yu8oru/can_we_possibly_get_access_to_large_language/,3,1668361842.0,"(I only want to do inference, I don't need to finetune it.)

I want to use very-large language model (#parameters > 100B) to do some experiments, is that true the only very-large language model we can get access to is GPT3 API? Can we possibly get access to PaLM and Flan-PaLM 540B with no cost by chance?

I have searched over the internet but can't find a definite answer. As GPT-3 pricing for text-davinci-2 is not cheap, I am wondering if there's a chance to use other models.

Also, I can request up to 372GB VRAM, is there any large language model (#parameters > 100B) that I can actually download and run ""locally""?"
216,deeplearning,gpt-3,relevance,2020-07-26 07:39:05,Crazy Numbers of GPT-3,alaap001,False,0.53,1,hy2vg1,https://www.reddit.com/r/deeplearning/comments/hy2vg1/crazy_numbers_of_gpt3/,2,1595749145.0,"Trained on over 285,000 CPU cores and 10,000 GPUs cluster, a lot of hype going around the latest GPT-3 model, those who are not into AI, it is the most advanced NLP algorithm to date. It learned the human-level language from over 400GB of data, costing crazy $12 million just to train it with \~175 Billion!! parameters. A typical high-end GPU would take over 350 years to train this model. As a Data Scientist, I thought why not look at how much data it took to learn human language. 

Well, here are the crazzyy numbers.

It used roughly 9 Million Hindi words,

3 Billion for German

and

4 Billion French words with 100 other languages. 

https://preview.redd.it/2b6aee0un5d51.png?width=937&format=png&auto=webp&s=3d4fa2e1b2621ae699ec1bb4a62d7cc85554c8d1

https://preview.redd.it/ec7tve0un5d51.png?width=871&format=png&auto=webp&s=9d8624d117ad4e1f41fff78f06bb30197abbd006

and all this fades away when English comes in with over 180 Billion words!! \[ For reference English has only 171,476 unique words with 20000 being used normally \]

It seems crazy how AI is being built so rapidly and now can talk like a human. Gets me excited thinking about what the future holds. 

***If you're the one who is getting started with Deep Learning then for you I created a website wherein I plan to do 100 Deep Learning Projects to help people understand the practicality of Deep Learning. You can visit*** [***https://www.aiunquote.com/***](https://www.aiunquote.com/) ***and learn deep learning by implementing,***

**#artificialintelligence** **#technology** **#AI** **#naturallanguageprocessing** **#gpt3** **#tableaupublic** **#computerscience** **#maths** **#innovation** **#datascience**"
217,deeplearning,gpt-3,relevance,2020-09-22 12:43:33,Deconstructing the GPT-3 economy,bendee983,False,1.0,1,ixmmuy,/r/MachineLearning/comments/ix16bc/d_deconstructing_the_gpt3_economy/,0,1600778613.0,
218,deeplearning,gpt-3,relevance,2020-08-17 19:53:20,Personal GPT-3 project 🚀: Guess the movie! You can't recall the name of that movie you watched? You know what the movie's about but you just can't remember its name? I used the GPT-3 model to solve this problem! Just feed it a small description of the movie/tv show and it will do the rest.,CallmeMehdi25,False,0.96,117,iblhzl,https://i.redd.it/z12t847vamh51.gif,29,1597694000.0,
219,deeplearning,gpt-3,relevance,2020-06-01 02:41:47,GPT-3 research paper review,minsuk-heo,False,1.0,2,gucf8w,https://youtu.be/Mq97CF02sRY,0,1590979307.0,
220,deeplearning,gpt-3,relevance,2021-07-15 17:06:55,"EleutherAI Researchers Open-Source GPT-J, A Six-Billion Parameter Natural Language Processing (NLP) AI Model Based On GPT-3",techsucker,False,1.0,58,okx5hm,https://www.reddit.com/r/deeplearning/comments/okx5hm/eleutherai_researchers_opensource_gptj_a/,5,1626368815.0,"[GPT-J](https://www.eleuther.ai/), a six-billion-parameter natural language processing (NLP) AI model based on GPT-3, has been open-sourced by a team of EleutherAI researchers. The model was trained on an open-source text [dataset of 800GB](https://pile.eleuther.ai/) and was comparable with a GPT-3 model of similar size.

The model was trained using Google Cloud’s v3-256 TPUs using EleutherAI’s Pile dataset, which took about five weeks. GPT-J achieves accuracy similar to OpenAI’s reported findings for their 6.7B parameter version of GPT-3 on standard NLP benchmark workloads. The model code, pre-trained weight files, a Colab notebook, and a sample web page are included in EleutherAI’s release.

Story: [https://www.marktechpost.com/2021/07/15/eleutherai-researchers-open-source-gpt-j-a-six-billion-parameter-natural-language-processing-nlp-ai-model-based-on-gpt-3/](https://www.marktechpost.com/2021/07/15/eleutherai-researchers-open-source-gpt-j-a-six-billion-parameter-natural-language-processing-nlp-ai-model-based-on-gpt-3/) 

Github repository for GPT-J: https://github.com/kingoflolz/mesh-transformer-jax

Colab Notebook: https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab\_demo.ipynb

Web Demo: https://6b.eleuther.ai/"
221,deeplearning,gpt-3,relevance,2020-07-24 09:50:27,[Tutorial] Sentence to SQL Converter using GPT-3,bhavesh91,False,0.8,6,hwyz1v,https://www.reddit.com/r/deeplearning/comments/hwyz1v/tutorial_sentence_to_sql_converter_using_gpt3/,1,1595584227.0,"I created a simple Sentence to SQL Converter using GPT - 3. If you want to learn how you can use OpenAI's GPT-3 to generate NLP Applications then this simple tutorial should help.Video Link : [https://www.youtube.com/watch?v=9g66yO0Jues](https://www.youtube.com/watch?v=9g66yO0Jues)

https://reddit.com/link/hwyz1v/video/79gg5vrj1sc51/player"
222,deeplearning,gpt-3,relevance,2020-07-22 21:00:37,Can GPT-3 do inference on GTX 1080?,fgp121,False,0.25,0,hw22o1,https://www.reddit.com/r/deeplearning/comments/hw22o1/can_gpt3_do_inference_on_gtx_1080/,2,1595451637.0,"Has anyone got their hands on GPT-3? How does the inference work for it? Is it really compute intensive? 

I had applied for access but haven't got it yet. And I'm thinking if it'd be able to do inference on my 1080 card? What minimum GPU computing capability and vRAM would it need to perform an inference  for a case such as completing a sentence?"
223,deeplearning,gpt-3,relevance,2022-12-12 15:53:41,"GPT-Rex: A chrome extension to plug GPT-3 directly into Medium. Hit ""Ctrl + >"" to trigger auto-complete while writing. Available on Chrome web store. Support for other platforms coming soon.",hayAbhay,False,0.57,1,zk2ser,https://github.com/hayabhay/gpt-go,2,1670860421.0,
224,deeplearning,gpt-3,relevance,2020-06-16 07:35:17,GPT-3 from OpenAI is here [video review],przemekc,False,0.33,0,h9z59j,https://youtu.be/OznMk5Jexu8,0,1592292917.0,
225,deeplearning,gpt-3,relevance,2021-01-05 22:42:51,"[N] This Time, OpenAI’s GPT-3 Generates Images From Text",Yuqing7,False,0.83,4,kr9sxx,https://www.reddit.com/r/deeplearning/comments/kr9sxx/n_this_time_openais_gpt3_generates_images_from/,0,1609886571.0,"OpenAI’s popular GPT-3 from last year showed that language can be used to instruct a large neural network to perform a variety of text generation tasks. Entering the new year, OpenAI is moving from pure text generation to image generation from text — its researchers today announce that they have trained a neural network called [DALL·E](https://openai.com/blog/dall-e/) that creates images from text captions for a wide range of concepts expressible in natural language.

Here is a quick read: [This Time, OpenAI’s GPT-3 Generates Images From Text](https://syncedreview.com/2021/01/05/this-time-openais-gpt-3-generates-images-from-text/)"
226,deeplearning,gpt-3,relevance,2020-07-28 17:08:47,"GPT-3 use cases: English to design, code and more",przemekc,False,0.67,1,hziixh,https://youtu.be/tsuxlU5IwuA,0,1595956127.0,
227,deeplearning,gpt-3,relevance,2020-12-21 11:49:16,The Future is Here! Have You Checked OpenAI’s GPT-3 Yet?,Shradha_Singh,False,0.17,0,khfwel,https://www.artiba.org/blog/the-future-is-here-have-you-checked-openais-gpt-3-yet,1,1608551356.0,
228,deeplearning,gpt-3,relevance,2021-07-13 15:38:39,[R] OpenAI Fine-Tunes GPT-3 to Unlock Its Code Generation Potential for Difficult Problems,Yuqing7,False,0.75,2,oji5zu,https://www.reddit.com/r/deeplearning/comments/oji5zu/r_openai_finetunes_gpt3_to_unlock_its_code/,0,1626190719.0,"A research team from OpenAI proposes Codex, a specialized GPT model fine-tuned on publicly available code from GitHub that can produce functionally correct Python code bodies from natural language docstrings and could excel at a variety of coding tasks. 

Here is a quick read: [OpenAI Fine-Tunes GPT-3 to Unlock Its Code Generation Potential for Difficult Problems.](https://syncedreview.com/2021/07/13/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-60/)

The paper *Evaluating Large Language Models Trained on Code* is on [arXiv](https://arxiv.org/abs/2107.03374)."
229,deeplearning,gpt-3,relevance,2020-09-04 22:59:41,[D] Is OpenAI’s GPT-3 API Beta Pricing Too Rich for Researchers?,Yuqing7,False,0.67,1,imqa78,https://www.reddit.com/r/deeplearning/comments/imqa78/d_is_openais_gpt3_api_beta_pricing_too_rich_for/,1,1599260381.0,"OpenAI’s 175 billion parameter language model GPT-3 (Generative Pre-trained Transformer 3) turned heads in the NLP community when it was released in June, and now it’s back in the spotlight. A Reddit [post](https://www.reddit.com/r/GPT3/comments/ikorgs/oa_api_preliminary_beta_pricing_announced/) this week by independent writer and researcher Gwern Branwen detailed the pricing plan OpenAI has provided to GPT-3 Beta API users. The scheme, which goes into effect on October 1, has already raised as many questions as it has answered.

Here is a quick read: [Is OpenAI’s GPT-3 API Beta Pricing Too Rich for Researchers?](https://syncedreview.com/2020/09/04/is-openais-gpt-3-api-beta-pricing-too-rich-for-researchers/)"
230,deeplearning,gpt-3,relevance,2020-10-28 11:39:21,How did I get access to GPT-3 OpenAI's API? Tips are shared at 4:45 in the video! The rest of the videos explains what can GPT-3 really do and how it can help you or your company.,OnlyProggingForFun,False,0.46,0,jjm4ep,https://www.youtube.com/watch?v=Gm4AMjV8ErM,0,1603885161.0,
231,deeplearning,gpt-3,relevance,2020-07-20 18:56:29,OpenAI’s new language generator GPT-3 is shockingly good—and completely mindless,PsychogenicAmoebae,False,0.67,4,hur8o1,https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/,1,1595271389.0,
232,deeplearning,gpt-3,relevance,2020-09-12 12:27:55,Can GPT-3 really help you and your company? What can it really do? Real-World Applications Demo,OnlyProggingForFun,False,0.56,1,irbp5k,https://www.youtube.com/watch?v=Gm4AMjV8ErM,4,1599913675.0,
233,deeplearning,gpt-3,relevance,2020-11-29 20:53:02,What is the hype about the GPT-3 transformer and what is real? (GPT3 paper deep dive),gordicaleksa,False,0.5,0,k3h2jj,https://youtu.be/fVt387VZJe8,1,1606683182.0,
234,deeplearning,gpt-3,relevance,2021-12-13 16:07:57,"[R] DeepMind’s RETRO Retrieval-Enhanced Transformer Retrieves from Trillions of Tokens, Achieving Performance Comparable to GPT-3 With 25× Fewer Parameters",Yuqing7,False,0.86,5,rfj4c2,https://www.reddit.com/r/deeplearning/comments/rfj4c2/r_deepminds_retro_retrievalenhanced_transformer/,0,1639411677.0,"A DeepMind research team proposes RETRO (Retrieval-Enhanced Transformer), an enhanced auto-regressive language model that conditions on document chunks retrieved from a large corpus and achieves performance comparable to GPT-3 and Jurassic-1 on the Pile dataset while using 25× fewer parameters. 

Here is a quick read: [DeepMind’s RETRO Retrieval-Enhanced Transformer Retrieves from Trillions of Tokens, Achieving Performance Comparable to GPT-3 With 25× Fewer Parameters.](https://syncedreview.com/2021/12/13/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-164/)

The paper *Improving Language Models by Retrieving From Trillions of Tokens* is on [arXiv](https://arxiv.org/abs/2112.04426)."
235,deeplearning,gpt-3,relevance,2021-05-10 14:32:27,Hi All! On May 29th Nextgrid hosts the 3rd GPT-3 Hackathon in a collab with OpenAI. Details below.,techn0_cratic,False,0.55,1,n963qn,https://nextgrid.ai/,0,1620657147.0,
236,deeplearning,gpt-3,relevance,2022-03-12 04:56:16,Microsoft’s Latest Machine Learning Research Introduces μTransfer: A New Technique That Can Tune The 6.7 Billion Parameter GPT-3 Model Using Only 7% Of The Pretraining Compute,No_Coffee_4638,False,1.0,33,tc8u6k,https://www.reddit.com/r/deeplearning/comments/tc8u6k/microsofts_latest_machine_learning_research/,0,1647060976.0,"Scientists conduct trial and error procedures which experimenting, that many times lear to freat scientific breakthroughs. Similarly, foundational research provides for developing large-scale AI systems theoretical insights that reduce the amount of trial and error required and can be very cost-effective.

Microsoft team tunes massive neural networks that are too expensive to train several times. For this, they employed a specific parameterization that maintains appropriate hyperparameters across varied model sizes. The used µ-Parametrization (or µP, pronounced “myu-P”) is a unique way to learn all features in the infinite-width limit. The researchers collaborated with the OpenAI team to test the method’s practical benefit on various realistic cases.

Studies have shown that training large neural networks because their behavior changes as they grow in size are uncertain. Many works suggest heuristics that attempt to maintain consistency in the activation scales at initialization. However, as training progresses, this uniformity breaks off at various model widths.

[**CONTINUE READING MY SUMMARY ON THIS RESEARCH**](https://www.marktechpost.com/2022/03/11/microsofts-latest-machine-learning-research-introduces-%ce%bctransfer-a-new-technique-that-can-tune-the-6-7-billion-parameter-gpt-3-model-using-only-7-of-the-pretraining-compute/)

Paper: https://www.microsoft.com/en-us/research/uploads/prod/2021/11/TP5.pdf

Github:https://github.com/microsoft/mup

https://i.redd.it/7jrt9r3awvm81.gif"
237,deeplearning,gpt-3,relevance,2020-09-16 16:02:55,"Practical Natural Language Processing Book [Interview + Giveaway] | NLP, ML & AI in the Industry | GPT-3 and more",mukulkhanna1,False,0.84,22,ityg5g,https://youtu.be/ptTlH-ma8rg,0,1600272175.0,
238,deeplearning,gpt-3,relevance,2020-12-07 17:36:57,"[N] Open AI’s GPT-3 Paper Shares NeurIPS 2020 Best Paper Awards With Politecnico di Milano, CMU and UC Berkeley",Yuqing7,False,0.75,2,k8l6vi,https://www.reddit.com/r/deeplearning/comments/k8l6vi/n_open_ais_gpt3_paper_shares_neurips_2020_best/,0,1607362617.0,"OpenAI’s groundbreaking GPT-3 language model paper, a no-regret learning dynamics study from Politecnico di Milano & Carnegie Mellon University, and a UC Berkeley work on data summarization have been named the NeurIPS 2020 Best Paper Award winners. The organizing committee made the announcements this morning, along with their Test of Time Award, to kick off the thirty-fourth Conference on Neural Information Processing Systems.

NeurIPS 2020 continues through December 12. With 9,467 submitted papers, this has been another record-breaking year for NeurIPS — with 38 percent more paper submissions than 2019. A total of 1,903 papers were accepted, compared to 1,428 last year.

Over the course of the week, participants can virtually join the Expo, where top industry sponsors will provide talks, panels, and demos of academic interest. Tutorials will cover current lines of inquiry while general sessions will include talks, posters, and demonstrations. A full agenda can be found by visiting the [NeurIPS conference schedule page](https://neurips.cc/virtual/2020/public/cal_main.html).

Here is a quick read: [Open AI’s GPT-3 Paper Shares NeurIPS 2020 Best Paper Awards With Politecnico di Milano, CMU and UC](https://syncedreview.com/2020/12/07/open-ais-gpt-3-paper-shares-neurips-2020-best-paper-awards-with-politecnico-di-milano-cmu-and-uc-berkeley/)"
239,deeplearning,gpt-3,relevance,2023-01-19 07:55:49,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.9,72,10fw22o,https://www.reddit.com/r/deeplearning/comments/10fw22o/gpt4_will_be_500x_smaller_than_people_think_here/,11,1674114949.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/xvpw1erngyca1.png?width=575&format=png&auto=webp&s=d7bea7c6132081f2df7c950a0989f398599d6cae)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you. At **TheDecoding** ⭕, I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
240,deeplearning,gpt-3,relevance,2023-04-08 07:55:07,need help. GPT-3.5 can't solve it.,ryanultralifeio,False,0.23,0,12ff87f,https://www.reddit.com/r/deeplearning/comments/12ff87f/need_help_gpt35_cant_solve_it/,8,1680940507.0,"Trying to make a schedule for the league, here are the constraints.  I think it should be tailormade for AI.


Schedule May 2023 Games.

￼￼

I need you to schedule games between 7 teams, on 4 fields, beginning on Monday May 1st for the whole month of May 2023. 

The 4 fields are; Quincy, Portola, Chester and Loyalton. Fields in Quincy, Portola and Loyalton are available beginning May 1st. The field in Chester is available beginning May 8th.

 Saturdays can have 3 games per day at either 10am, 1pm, or 4 pm. 

No games on Sunday. 

Monday, Tuesday, Wednesday, Thursday, and Friday games are at 5:00. 

Mondays, Tuesdays, Wednesdays, Thursdays, and Fridays can have games played on 3 different fields at the same time. 

There are 7 teams. Quincy Red, Quincy Blue, Quincy Grey, Portola Padres, Portola Dodgers, Chester Giants and Loyalton. 

All teams can only play each other 2 times in May with the exceptions of Quincy Grey and Quincy Red, Quincy Grey and Quincy Blue, and Quincy Grey and Chester Giants, who can only play each other 1 time in May. 

Only Loyalton cannot play on May 3,4, or 5 for Sierra Nevada Journeys. 

All teams are unavailable to play May 26,27,29 for Memorial Day Weekend. 

All teams are unavailable to play May 17,18,19 for 6th grade field trip. 

Each team will play one home game against each other, except for the teams only playing one game. 

Quincy Blue only plays home games on Quincy field on Mondays, and Thursdays. 

Quincy Grey only plays home games on Quincy field on Wednesdays, and Fridays. 

Quincy Red only plays home games on Quincy Field on Tuesdays, Thursdays, and Fridays. 

Loyalton only plays home games on Loyalton field. 

Chester Giants only play Home Games on Chester field. 

Portola Padres only play home games on Portola field. 

Portola Dodgers only play home games on Portola field. 

Each team can play a maximum of two games per week. 

A team cannot play without two calenders days between games. 

A team cannot play two games on consecutive days.

A team cannot play two games on the same day. 

Teams must have at least 9 games.

Put the total number of games played per team at the bottom of the whole months schedule.

2+ hours a no good results........."
241,deeplearning,gpt-3,relevance,2023-08-28 07:12:44,OpenAI introduces fine-tuning capabilities for GPT-3.5 Turbo,intengineering,False,1.0,5,163f3fp,https://interestingengineering.com/innovation/openai-introduces-fine-tuning-capabilities-for-gpt-35-turbo,1,1693206764.0,
242,deeplearning,gpt-3,relevance,2020-06-16 03:13:01,"I just published ""All you need to need to know about OPENAI's GPT-3 "" on medium . Check out , feedback is highly appreciated..",dharma_m,False,0.65,7,h9ve0q,https://medium.com/@savanidharmam5/all-you-need-to-know-about-openai-gpt-3-d0d879446aeb,0,1592277181.0,
243,deeplearning,gpt-3,relevance,2023-01-28 06:34:28,"A python module to generate optimized prompts, Prompt-engineering & solve different NLP problems using GPT-n (GPT-3, ChatGPT) based models and return structured python object for easy parsing",StoicBatman,False,1.0,18,10n8c80,https://www.reddit.com/r/deeplearning/comments/10n8c80/a_python_module_to_generate_optimized_prompts/,0,1674887668.0,"Hi folks,

I was working on a personal experimental project related to GPT-3, which I thought of making it open source now. It saves much time while working with LLMs.

If you are an industrial researcher or application developer, you probably have worked with GPT-3 apis. A common challenge when utilizing LLMs such as #GPT-3 and BLOOM is their tendency to produce uncontrollable & unstructured outputs, making it difficult to use them for various NLP tasks and applications.

To address this, we developed **Promptify**, a library that allows for the use of LLMs to solve NLP problems, including Named Entity Recognition, Binary Classification, Multi-Label Classification, and Question-Answering and return a python object for easy parsing to construct additional applications on top of GPT-n based models.

Features 🚀

* 🧙‍♀️ NLP Tasks (NER, Binary Text Classification, Multi-Label Classification etc.) in 2 lines of code with no training data required
* 🔨 Easily add one-shot, two-shot, or few-shot examples to the prompt
* ✌ Output is always provided as a Python object (e.g. list, dictionary) for easy parsing and filtering
* 💥 Custom examples and samples can be easily added to the prompt
* 💰 Optimized prompts to reduce OpenAI token costs

&#x200B;

* GITHUB: [https://github.com/promptslab/Promptify](https://github.com/promptslab/Promptify)
* Examples: [https://github.com/promptslab/Promptify/tree/main/examples](https://github.com/promptslab/Promptify/tree/main/examples)
* For quick demo -> [Colab](https://colab.research.google.com/drive/16DUUV72oQPxaZdGMH9xH1WbHYu6Jqk9Q?usp=sharing)

Try out and share your feedback. Thanks :)

Join our discord for Prompt-Engineering, LLMs and other latest research discussions  
[discord.gg/m88xfYMbK6](https://discord.gg/m88xfYMbK6)

[NER Example](https://preview.redd.it/sjvhtd8b3nea1.png?width=1236&format=png&auto=webp&s=e9a3a28f41f59cd25fe8e95bd1fca56b15f27a6e)

&#x200B;

https://preview.redd.it/fnb05bys3nea1.png?width=1398&format=png&auto=webp&s=096f4e2cbd0a71e795f30cc5e3720316b5e5caf6"
244,deeplearning,gpt-3,relevance,2023-08-03 23:38:39,What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?,Claud1ao,False,0.67,1,15hjv2y,https://www.reddit.com/r/deeplearning/comments/15hjv2y/what_would_be_the_initial_costs_of_developing_a/,4,1691105919.0,"I was wondering if this would be super expensive or not.

The cost to develop GPT-3 was about $4 millions according to some resources online. 

Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?

Any answer is appreciated.

Thanks in advance."
245,deeplearning,gpt-3,relevance,2022-04-23 19:37:38,?? Can you find out which news article is written by AI ??,RobinSandersVUB,False,0.75,2,uad25r,https://www.reddit.com/r/deeplearning/comments/uad25r/can_you_find_out_which_news_article_is_written_by/,1,1650742658.0,"This research will test the human ability to distinguish human written text from text generated by artificial intelligence. Participating will only take 10 minutes. You will receive 2 short news articles about the same topic. One will be written by a human, the other one will be generated by artificial intelligence. It is up to you to find out which one is written by artificial intelligence. You will be asked to do this for four different subjects, namely: Science, Economics & Politics, Society and Sports. At the end of the survey you will receive feedback on how well you have performed.

The human written articles were collected from various news websites. The Articles created by artificial intelligence were generated using GPT-3 from OpenAI.

Purpose of the research: We are trying to find out how well GPT-3 performs across subjects. Are there any subject GPT-3 is better at writing about, or is he equally good across all subjects. Secondly we are testing the ability of GPT-3 to generate articles about events that happened after the training of the model. 

You can participate by clicking on the link below, thank you very much for your participation.

 [https://vub.fra1.qualtrics.com/jfe/form/SV\_b2E9f6hGxNDH13M](https://vub.fra1.qualtrics.com/jfe/form/SV_b2E9f6hGxNDH13M)"
246,deeplearning,gpt-3,relevance,2023-05-31 10:03:36,What is the objective for the supervised fine-tuning stage of instruction-following models?,BlueHemp,False,0.81,3,13whxjk,https://www.reddit.com/r/deeplearning/comments/13whxjk/what_is_the_objective_for_the_supervised/,1,1685527416.0,"Dialog models like [InstructGPT](https://arxiv.org/pdf/2203.02155.pdf) and, recently, [Dromedary](https://arxiv.org/abs/2305.03047) have a supervised fine-tuning part where they use collected demonstration data to tune the base model. Quote from InstructGPT paper: ""fine-tune a pretrained GPT-3 model on this data using supervised learning.""

However, these papers don't go into detail about the objective/loss function for this step. To be clear, I don't mean the RLHF part that follows for InstructGPT but the first step of just fine-tuning on (human or model generated) examples.

I would guess that the objective is basically an auto-regressive language modeling task since GPT-like models are decoder-only models.So what exactly is the training objective or loss function for the supervised finetuning (not RLHF!) step?"
247,deeplearning,gpt-3,relevance,2022-12-03 19:29:01,BlogNLP: AI Blog Writing Tool,britdev,False,0.88,12,zboc8w,https://www.reddit.com/r/deeplearning/comments/zboc8w/blognlp_ai_blog_writing_tool/,7,1670095741.0,"Hey everyone,

I developed this web app with Open AI's GPT-3 to provide a free, helpful resource for generating blog content, outlines, and more - so you can beat writer's block! I'm sure you'll find it useful and I'd really appreciate it if you shared it with others ❤️.

[https://www.blognlp.com/](https://www.blognlp.com/)"
248,deeplearning,gpt-3,relevance,2023-01-22 10:12:08,"BigScience BLOOM, how should we use it?",Haghiri75,False,0.86,5,10igecg,https://www.reddit.com/r/deeplearning/comments/10igecg/bigscience_bloom_how_should_we_use_it/,1,1674382328.0,"Since the release of BLOOM, I always wanted to test it the way GPT-3 (and newly released ChatGPT) are tested. Having a playground with the ability to explore settings and even generating codes and stuff. But I don't know how long was it (I guess almost a year) and the only thing *close to playground* it had was the huggingface model card.

So is there any reliable way to use BLOOM in a proper way?"
249,deeplearning,gpt-3,relevance,2022-11-03 23:55:15,BlogNLP: AI Writing Tool,britdev,False,1.0,37,ylj1ux,https://www.reddit.com/r/deeplearning/comments/ylj1ux/blognlp_ai_writing_tool/,9,1667519715.0,"Hey everyone,

I created this web app using Open AI's GPT-3 (Davinci model). The purpose here is to provide a free tool to allow people to generate blog content/outlines/headlines and help with writer's block. Will continue to improve it over time, but just a side project I figured would provide some value to you all. Hope you all enjoy and please share ❤️

[https://www.blognlp.com/](https://www.blognlp.com/)"
250,deeplearning,gpt-3,relevance,2023-01-19 14:10:45,BlogNLP: AI Blog Writing Tool,britdev,False,0.5,0,10g2npf,https://www.reddit.com/r/deeplearning/comments/10g2npf/blognlp_ai_blog_writing_tool/,2,1674137445.0,"Hey everyone,

I developed this web app with Open AI's GPT-3 to provide a helpful resource for generating blog content, outlines, and more - so you can beat writer's block! I'd really appreciate it if you shared it with others.

[https://www.blognlp.com/](https://www.blognlp.com/)"
251,deeplearning,gpt-3,relevance,2023-01-22 19:11:36,Apple M2 Max 96 GB unified memory for larger models vs multiple 24GB GPUs or 40GB A100s?,lol-its-funny,False,0.97,21,10irh5u,https://www.reddit.com/r/deeplearning/comments/10irh5u/apple_m2_max_96_gb_unified_memory_for_larger/,14,1674414696.0,"How feasible is it to use an Apple Silicon M2 Max, which has about [96 GB unified memory](https://www.apple.com/shop/buy-mac/macbook-pro/16-inch-space-gray-apple-m2-max-with-12-core-cpu-and-38-core-gpu-1tb) for ""large model"" deep learning? I'm inspired by the the [Chinchilla](https://arxiv.org/abs/2203.15556) paper that shows a lot of promise at 70B parameters. Outperforming ultra large models like Gopher (280B) or GPT-3 (175B) there is hope for working with < 70B parameters without needing a super computer. At least for fine tuning. I've been working with GPT-J but want to scale/tinker with larger open-sourced models.

However, I don't know how clearly the CompSci theory (M2 Max's 38-core GPU, 16 core Neural Engine accessing 96 GB unified memory) maps out to the IT reality (toolkits and libraries on macOS actually using it). My exposure is mostly around Jupyter books on Colab Pro+ (A100s) and nvidia 3080 GPUs (locally). 

I appreciate your guidance."
252,deeplearning,gpt-3,relevance,2023-12-12 12:10:06,[D] Crafting Visually Stunning Slides with Assistants API (GPT-4) and DALL·E-3,Fit_Maintenance_2455,False,0.5,0,18gkhbu,https://www.reddit.com/r/deeplearning/comments/18gkhbu/d_crafting_visually_stunning_slides_with/,0,1702383006.0,"In the realm of presentations, creating visually compelling slides that effectively communicate data insights is a skill coveted by professionals across diverse industries. However, the traditional process of manually constructing these slides can be a time-consuming endeavor. Enter the new Assistants API (GPT-4) and DALL·E-3, revolutionary tools that streamline the slide creation process, offering efficiency and visual finesse.

Crafting slides that capture the essence of complex data sets while maintaining audience engagement is a multifaceted challenge. It demands a blend of data interpretation, storytelling finesse, and an eye for design. Traditionally, this process involves laborious manual work, from structuring information to selecting images and formatting layouts.

&#x200B;

link: [https://medium.com/ai-advances/crafting-visually-stunning-slides-with-assistants-api-gpt-4-and-dall-e-3-f862368cec44](https://medium.com/ai-advances/crafting-visually-stunning-slides-with-assistants-api-gpt-4-and-dall-e-3-f862368cec44) "
253,deeplearning,gpt-3,relevance,2021-10-09 12:58:48,Research proposal feedback,KAKA7861111,False,0.35,0,q4ktyi,https://www.reddit.com/r/deeplearning/comments/q4ktyi/research_proposal_feedback/,15,1633784328.0," 

Hi everyone.

I need your feedback on this. I am writing a research proposal. The topic is Coding AI:

1. I am proposing a solution to train a GPT-3 for code optimization. like input would be code and output would be optimized code in terms of latency and big o notation.

Any related literate. feedback on approach"
254,deeplearning,gpt-3,relevance,2023-02-11 06:59:00,⭕ New Open-Source Version Of ChatGPT,LesleyFair,False,0.87,39,10zepkt,https://www.reddit.com/r/deeplearning/comments/10zepkt/new_opensource_version_of_chatgpt/,3,1676098740.0,"GPT is getting competition from open-source.

A group of researchers, around the YouTuber [Yannic Kilcher](https://www.ykilcher.com/), have announced that they are working on [Open Assistant](https://github.com/LAION-AI/Open-Assistant). The goal is to produce a chat-based language model that is much smaller than GPT-3 while maintaining similar performance.

If you want to support them, they are crowd-sourcing training data [here](https://open-assistant.io/).

**What Does This Mean?**

Current language models are too big.

They require millions of dollars of hardware to train and use. Hence, access to this technology is limited to big organizations. Smaller firms and universities are effectively shut out from the developments.

Shrinking and open-sourcing models will facilitate academic research and niche applications.

Projects such as Open Assistant will help to make language models a commodity. Lowering the barrier to entry will increase access and accelerate innovation.

What an exciting time to be alive! 

Thank you for reading! I really enjoyed making this for you!  
The Decoding ⭕ is a thoughtful weekly 5-minute email that keeps you in the loop about machine research and the data economy. [Click here to sign up](https://thedecoding.net/)!"
255,deeplearning,gpt-3,relevance,2023-04-01 17:50:06,Fine-tune GPT on sketch data (stroke-3),mellamo_maria,False,1.0,1,128tfvc,https://www.reddit.com/r/deeplearning/comments/128tfvc/finetune_gpt_on_sketch_data_stroke3/,0,1680371406.0," These past days I have started a personal project where I would like to build a model that, given an uncompleted sketch, it can finish it. I was planning on using some pretrained models that are available in HuggingFace and fine-tune them with my sketch data for my task. The sketch data I have is in stoke-3 format, like the following example:  
\[  
\[10, 20, 1\],  
\[20, 30, 1\],  
\[30, 40, 1\],  
\[40, 50, 0\],  
\[50, 60, 1\],  
\[60, 70, 0\]  
\]  
The first value of each triple is the X-coordinate, the second value the Y-coordinate and the last value is a binary value indicating whether the pen is down (1) or up (0). I was wondering if you guys could give me some instruction/tips about how should I approach this problem? How should I prepare/preprocess the data so I can fit it into the pre-trained models like BERT, GPT, etc. Since it's stroke-3 data and not text or a sequence of numbers, I don't really know how should I treat/process the data.

Thanks a lot! :)"
256,deeplearning,gpt-3,relevance,2021-03-02 22:51:27,Anyone interested in getting paid to write tutorials or short courses?,nottingpill,False,0.71,13,lwes32,https://www.reddit.com/r/deeplearning/comments/lwes32/anyone_interested_in_getting_paid_to_write/,1,1614725487.0," Hello,

I just built my website for short courses and tutorials, and I’d like to populate it with some content. I’m looking for developers who are also good at writing who would be interested in writing some tutorials and publishing them on my website.

This is an example of something I built on my website: [https://www.learnthepart.com/course/c1d6d596-97b9-4e53-a46d-ec6260c07c78/bcdfb9cb-44e7-4eaf-a824-13e853eb974c](https://www.learnthepart.com/course/c1d6d596-97b9-4e53-a46d-ec6260c07c78/bcdfb9cb-44e7-4eaf-a824-13e853eb974c)

If any of you are interested feel free to DM me. 

If available, please send me a programming article you wrote in the past. It would be really helpful in assessing your skillset. 

This is also a good chance to learn and develop some skills while getting paid for it."
257,deeplearning,gpt-3,relevance,2022-12-22 09:57:14,"Show ChatGPT's response next to the search results from Google, Bing, and DuckDuckGo.",Harrypham22,False,1.0,1,zsics7,https://www.reddit.com/r/deeplearning/comments/zsics7/show_chatgpts_response_next_to_the_search_results/,0,1671703034.0," **Do you know about ChatGPT?** 

It is a variant of the GPT-3 language model developed by OpenAI specifically designed for generating responses to user input in chat or messaging applications. It is trained on a large dataset of conversation data and is able to understand the context of a conversation and generate appropriate responses. ChatGPT is particularly well-suited for use in chat or messaging applications, but it can also be used for a wide range of other natural language processing tasks, such as language translation, summarization, and question answering.

**Display ChatGPT response alongside other search engine results (Google,Bing,Duck go go,..)**

***ChatGPT for Search Engines*** is an AI-based extension that could potentially become a real threat to any search engine.

It basically shows results to all sorts of queries next to the Google results (or other search engine). The precision is very impressive. This extension makes it possible everywhere you browse

This is a simple extension that show response from ChatGPT alongside Google and other search engines

Features:

\* Markdown rendering

\* Code hightlights

\* Feedback buttons

\* Custom trigger mode

Maybe you should try this extension: [shorturl.at/eqZ78](https://shorturl.at/eqZ78)

Watch this video to see how it work: [https://www.tiktok.com/@ai\_life26/video/7179865803003579674](https://www.tiktok.com/@ai_life26/video/7179865803003579674)

https://preview.redd.it/ojjxcy2q9f7a1.png?width=1294&format=png&auto=webp&s=e3b02aba9ba03f37dbdcd0a2c6265a95b9f11ed8"
258,deeplearning,gpt-3,relevance,2021-05-17 15:54:37,What is it like to build a productivity startup with a GPT-3 backbone? I sat down with Flowrite CEO Aaro Isosaari to find out. Aaro kindly shared his insight into the challenges and discoveries connected with building an AI product people love based on the API. I hope it is valuable for you 🙏,techn0_cratic,False,0.5,0,nejw0m,https://youtube.com/watch?v=FmIWLtk-o60&feature=share,0,1621266877.0,
259,deeplearning,gpt-3,relevance,2020-07-22 01:19:40,GPT-3: A Hitchhiker's Guide,mippie_moe,False,0.67,1,hvka41,https://lambdalabs.com/blog/gpt-3/,0,1595380780.0,
260,deeplearning,gpt-3,relevance,2022-02-11 16:47:38,Interview with Arvind Neelakantan about the OpenAI Embeddings API,HenryAILabs,False,1.0,2,sq3s05,https://www.reddit.com/r/deeplearning/comments/sq3s05/interview_with_arvind_neelakantan_about_the/,0,1644598058.0,"Hey everyone!   


The release of OpenAI's Embeddings API has been quite the story! I had the pleasure to interview Arvind Neelakantan on miscellaneous topics pertaining to these new advances in Search: [https://www.youtube.com/watch?v=uFxfZ0vLsoU](https://www.youtube.com/watch?v=uFxfZ0vLsoU)  


Additional Background on this:  
OpenAI Embeddings API Blog Post: [https://openai.com/blog/introducing-text-and-code-embeddings/](https://openai.com/blog/introducing-text-and-code-embeddings/)

Nils Reimers' Response (OpenAI GPT-3 Text Embeddings - Really a new state-of-the-art in dense text embeddings?): [https://medium.com/@nils\_reimers/openai-gpt-3-text-embeddings-really-a-new-state-of-the-art-in-dense-text-embeddings-6571fe3ec9d9](https://medium.com/@nils_reimers/openai-gpt-3-text-embeddings-really-a-new-state-of-the-art-in-dense-text-embeddings-6571fe3ec9d9)

Yannic Kilcher on the topic: [https://www.youtube.com/watch?v=5skIqoO3ku0](https://www.youtube.com/watch?v=5skIqoO3ku0)"
261,deeplearning,gpt-3,relevance,2020-06-10 20:36:33,"GPT-3: The $4,600,000 Language model",mippie_moe,False,0.84,8,h0jm54,https://lambdalabs.com/blog/demystifying-gpt-3/,4,1591821393.0,
262,deeplearning,gpt-3,relevance,2021-11-28 12:03:23,Deep Learning models which are available for individual/retail use?,ahassoun,False,0.5,0,r42v0b,https://www.reddit.com/r/deeplearning/comments/r42v0b/deep_learning_models_which_are_available_for/,3,1638101003.0,"I am fascinated by GPT-3 and ever since I learned about it a year ago, I use it almost every day. 

Other than language and content creation, are there models available for public use? I don't have a specific problem/domain in mind, but I would like to explore what is out there."
263,deeplearning,gpt-3,relevance,2021-12-20 16:17:11,[R] OpenAI’s WebGPT Crawls a Text-Based Web Environment to Achieve Human-Level Performance on Long-Form QA,Yuqing7,False,0.8,3,rkqv80,https://www.reddit.com/r/deeplearning/comments/rkqv80/r_openais_webgpt_crawls_a_textbased_web/,0,1640017031.0,"An OpenAI research team fine-tunes the GPT-3 pretrained language model to enable it to answer long-form questions by searching and navigating a text-based web browsing environment, achieving retrieval and synthesis improvements and reaching human-level long-form question-answering performance. 

Here is a quick read:[OpenAI’s WebGPT Crawls a Text-Based Web Environment to Achieve Human-Level Performance on Long-Form QA.](https://syncedreview.com/2021/12/20/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-169/)

The paper *WebGPT: Browser-assisted Question-answering with Human Feedback* is on [OpenAI.com](https://openai.com/blog/improving-factual-accuracy/)."
264,deeplearning,gpt-3,relevance,2023-03-05 11:10:56,LLaMA model parallelization and server configuration,ChristmasInOct,False,0.97,25,11ium8l,https://www.reddit.com/r/deeplearning/comments/11ium8l/llama_model_parallelization_and_server/,8,1678014656.0,"Hey everyone,

First of all, tldr at bottom, typed more than expected here.  

Please excuse the rather naive perspective I have here.  I've followed along with great interest, but this is not my industry.

Regardless, I have spent the past 3-4 days falling down a brutally obsessive rabbit hole, and I cannot seem to find this information.  I'm assuming it's just that I am missing context of course, and regardless of whether there is a clear answer, I'm trying to get a better understanding of this topic so that I could better appraise the situation myself.

Really I suppose I have two questions.  **The first** is regarding model parallelization.

I'm assuming this is not generic whatsoever.  What is the typical process engineers go about for designing such a pipeline?  Specifically in regards to these new LLaMA models, is something like ALPA relevant?  Deepspeed?

More importantly, what information should I be seeking to determine this myself?

This roughly segues to my **second inquiry**.

The reason I'm curious about splitting the model pipeline etc., is that I am potentially in interested in standing a server up for this.  Although I don't have much of a budget for this build (\~$30-40K is the rough top-end, but I'd be a lot happier around $20-25K), the money is there if I can genuinely satisfy my use-case.

I work at a small, but borderline manic startup working on enterprise software; 90% of the work we're doing based in the react/node ecosystem, some low-level work for backend services, and some very interesting database work that I have very little to do with.  I am a fullstack engineer that grew up playing with C++ => C#, and somehow ended up spending all of my time r/w'ing javascript.  Lol.  Anyways.

Part of our roadmap since GPT-3 and the playground were made publicly accessible, involves usage of these transformer models, and their ability to interpret natural language inputs, whether from user inputs, or scraped input values generated somewhere in a chain of requests / operations.

Seeing GPT-3 in action made me specifically realize that my estimations on this technology had been wildly off.  Seeing ChatGPT in action and uptick, the API's becoming available, has me further panicked.

Running our inference through their API has never really been an option for us.  I haven't even really looked that far into it, but bottom line the data running through our platform is all back-office, highly sensitive business information, and many have agreements explicitly restricting the movement of data to or from any cloud services, with Microsoft, Amazon, and Google all specifically mentioned.

Regardless of the reasoning for these contracts, the LLaMA release has had me obsessed over this topic in more detail than before, and whether or not I would be able to get this setup privately, for our use-case.

**To get to the actual second inquiry**:

Say I want to throw a budget rig together for this in a server cabinet.  Am I able to effectively parallelize the LLaMA model, well enough to justify going with 24GB VRAM 4090's in the rig?  Say I do so with DeepSpeed, or some of the standard model parallelization libraries.

Is the performance cost low enough to justify taking the extra compute here over 1/3 - 1/2 as many RTX6000 ADA's?

Or should I be grabbing the 48GB ADA's?

Like I said, I apologize for the naivety, I'm really looking for more information so that I can start to put this picture together better on my own.  It really isn't the easiest topic to research with how quickly things seem to move, and the giant gap between conversation depths (gamer || phd in a lot of the most interesting or niche discussions, little between).

Thank you very much for your time.

TL;DR - Any information on LLaMA model parallelization at the moment?  Will it be compatible with things like zero or alpa?  How about for throwing a rig together right now for fine-tuning and then running inference on the LLaMA models?  48GB 6000 ADA's, or 24GB 4090's?

Planning on putting it in a mostly empty 42U cabinet that also houses our primary web server and networking hardware, so if there is a sales pitch for 4090's across multiple nodes here, I do have a massive bias as the kind of nerd that finds that kind of hardware borderline erotic.

Hydro and cooling are not an issue, just usage of the budget and understanding the requirements / approach given memory limitations, and how to avoid communication bottlenecks or even balance them against raw compute.

Thanks again everyone!"
265,deeplearning,gpt-3,relevance,2021-08-25 02:37:52,[N] AI Can Write in English. Now It's Learning Other Languages - Wired,ClaudeCoulombe,False,1.0,3,pb27l2,https://www.reddit.com/r/deeplearning/comments/pb27l2/n_ai_can_write_in_english_now_its_learning_other/,0,1629859072.0,An interesting [Wired 's paper](https://www.wired.com/story/ai-write-english-learning-other-languages/). A growing number of startups outside USA are building general-purpose GPT-3 like  language models and tools.
266,deeplearning,gpt-3,relevance,2021-08-11 15:48:33,"Watch out, GPT-3, here comes AI21's 'Jurassic' language model | ZDNet",lindaarden,False,0.7,4,p2fqcs,https://www.zdnet.com/article/watch-out-gpt-3-here-comes-ai21s-jurassic-language-model/,0,1628696913.0,
267,deeplearning,gpt-3,relevance,2021-12-21 11:31:55,Pretrained models on other data than language,jssmith42,False,0.81,6,rlcs2a,https://www.reddit.com/r/deeplearning/comments/rlcs2a/pretrained_models_on_other_data_than_language/,1,1640086315.0,"Are there pretrained models like GPT-3 but that are trained on different inputs and outputs?

I am picturing a model that can clean and restructure Excel data by being shown a few example clean ups. I guess the inputs and outputs would be Excel files, but it would be cool if there was a training front-end software sort like what Prodigy is for data-labelling.

Thank you"
268,deeplearning,gpt-3,relevance,2020-09-18 10:45:02,GPT-3: new AI can write like a human but don't mistake that for thinking – neuroscientist,PowerOfLove1985,False,0.8,36,iv3rnz,https://theconversation.com/gpt-3-new-ai-can-write-like-a-human-but-dont-mistake-that-for-thinking-neuroscientist-146082,14,1600425902.0,
269,deeplearning,gpt-3,relevance,2021-05-02 16:45:08,GPT-1 - Annotated Paper + Paper Summary,shreyansh26,False,0.96,25,n3aeh5,https://www.reddit.com/r/deeplearning/comments/n3aeh5/gpt1_annotated_paper_paper_summary/,2,1619973908.0," GPT-2 and recently, GPT-3 created a lot of hype when they were launched. However, it all started with the ""Improving Language Understanding by Generative Pre-Training"" paper which introduced the idea of GPT-1.

As a part of my Paper Notes series, I have gone through the paper and created a brief yet informative summary of the paper. It will take just take a few minutes to understand GPT-1 well. Check out the links below and happy reading!

Paper Summary - [Improving Language Understanding by Generative Pre-Training](https://shreyansh26.github.io/post/2021-05-02_language_understanding_generative_pretraining/)

Annotated Paper - [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf)"
270,deeplearning,gpt-3,relevance,2021-06-02 16:48:40,"AI Weekly Update - June 2nd, 2021",HenryAILabs,False,1.0,4,nqqb39,https://www.reddit.com/r/deeplearning/comments/nqqb39/ai_weekly_update_june_2nd_2021/,0,1622652520.0,"New AI Weekly Update - June 2nd, 2021 (#33!)

* Deep Learning with Code Data
* Reward is Enough
* AndroidEnv
* CogView
* Medically-aware GPT-3

https://youtu.be/6ic2PuWGhuA"
271,deeplearning,gpt-3,relevance,2021-11-22 12:51:54,Best way to explain chess strategies?,jssmith42,False,0.67,2,qzkqll,https://www.reddit.com/r/deeplearning/comments/qzkqll/best_way_to_explain_chess_strategies/,0,1637585514.0,"Which deep learning architecture or model would be ideal for suggesting chess moves and explaining the strategy behind them?

I.e. GPT-3 can document the code it generates, there’s an “explain this code” application. But it was trained on GitHub.

Has anyone trained a transformer on chess books or chess games, so that it can not only play them but explain them?"
272,deeplearning,gpt-3,relevance,2021-11-24 20:45:14,Current best accessible solution to isolating sounds in an audio file?,MonmusuAficionado,False,1.0,1,r1erh9,https://www.reddit.com/r/deeplearning/comments/r1erh9/current_best_accessible_solution_to_isolating/,4,1637786714.0,"I have an audio file with a voice and other background sounds, I would like remove the voice from the audio, so I need a way detect it and isolate from everything else (other sounds share similar frequencies and I was told there is no easy traditional solution to this). Does anyone know of any models created for this purpose? What I mean by accessible is something I can either train myself (so something like GPT-3 would not be an option), or a pre-trained model available through some online service."
273,deeplearning,gpt-3,relevance,2020-07-30 13:37:36,[Tutorial] Generate Python code & Matplotlib graphs using GPT-3.,bhavesh91,False,0.57,1,i0m6cn,https://www.reddit.com/r/deeplearning/comments/i0m6cn/tutorial_generate_python_code_matplotlib_graphs/,0,1596116256.0,"I created a simple application which generates Python code & Matplotlib Graphs using GPT-3. If you want to learn how you can use OpenAI's GPT-3 to generate NLP Applications then this simple tutorial should help. Video Link : [https://www.youtube.com/watch?v=z8K07a2EIcE](https://www.youtube.com/watch?v=z8K07a2EIcE)

https://i.redd.it/u1gpz8bkzzd51.gif"
274,deeplearning,gpt-3,relevance,2022-01-09 16:11:37,General Purpose Reading Models,HenryAILabs,False,0.83,4,rzuykx,https://www.reddit.com/r/deeplearning/comments/rzuykx/general_purpose_reading_models/,0,1641744697.0,"GPT-3 has successfully been campaigned as a General-Purpose API -- all you need is to provide a few examples of a task and it promises generalization to future inferences.

I think separating Deep Learning models into retrieve-then-read pipelines makes much more sense for general purpose functionality. Retrieval offers:  


* Interpretability
* Ease to update information
* Less parameters needed because you do not need to store the data in the parameters

This video explains some of these ideas and the benefits of separating retrieval and reading, I hope you find it interesting!   


https://www.youtube.com/watch?v=mRcuNtMOmZw"
275,deeplearning,gpt-3,relevance,2023-04-01 14:01:42,Revolutionizing Content Creation: Moji AI's Impact on Social Media and Beyond,Large_Rush9013,False,0.25,0,128nbfn,https://www.reddit.com/r/deeplearning/comments/128nbfn/revolutionizing_content_creation_moji_ais_impact/,0,1680357702.0,"Hey fellow Redditors, I recently stumbled upon a summary of an incredible new AI content tool called Moji AI, and I just had to share my thoughts about it. I think it has the potential to be a game-changer for content creators!

Moji AI is designed to make content creation easier by using the power of GPT-4 to generate text and Stable Diffusion Models to create eye-catching images. It offers icons and image assets that can significantly boost social media engagement. As a Reddit user, I'm always trying to find new ways to share content and start conversations, and I think the potential benefits of this tool are undeniable.

I've been aware of GPT-3 for a while now, and the thought of GPT-4 being a more powerful version gets me excited about what it could mean for the future of AI-generated content. The fact that Moji AI can not only generate text, but also customize images and icons, makes it seem like a must-have tool for anyone serious about making an impact on social media platforms.

The Stable Diffusion Models used by Moji AI allow it to create visually stunning images that are bound to catch the attention of users as they're scrolling through their feeds. It's not just about the text anymore - visuals are crucial in today's social media landscape, and Moji AI is tackling that aspect head-on.

I can already think of countless ways to apply Moji AI in both personal and professional projects. Imagine effortlessly creating engaging blog posts, social media posts, and digital marketing campaigns without the hassle of finding a graphic designer or a copywriter. This tool seems too good to be true!

For those of you who are interested in learning more about Moji AI and how it can elevate your content creation game, I urge you to check out their website at [mojiai.io](https://mojiai.io). I'm excited to see the applications of this tool, and I believe that it'll revolutionize how we create and share content moving forward.

Indeed, it's exciting to be part of a community that is always at the forefront of groundbreaking innovations like Moji AI! Feel free to share your thoughts and ideas about how you think Moji AI could impact the world of content creation. Let's start a conversation!"
276,deeplearning,gpt-3,relevance,2020-09-26 13:53:35,GPT-3: Is this the moment we've been waiting for? [Giveaway included],mukulkhanna1,False,0.44,0,j06eo3,https://youtu.be/9gTDHLbtjrU,0,1601128415.0,
277,deeplearning,gpt-3,relevance,2022-04-21 15:55:24,How do I figure out if I can run a model on my personal computer / any given hardware?,Jjax7,False,0.86,5,u8qs9o,https://www.reddit.com/r/deeplearning/comments/u8qs9o/how_do_i_figure_out_if_i_can_run_a_model_on_my/,2,1650556524.0,"Models like GPT-3 and DALLE-2 have billions of parameters. I’m an undergraduate Data Science student with a GTX 970 in my computer. I’ve been able to train and run model architectures similar to AlexNet, UNet, and a Sequence-to-Sequence RNN encoder-decoder architecture on my local device before, but there is a disconnect in my understanding for what it takes to scale models up given more complex tasks.

It’s my understanding that many modern state-of-the-art models make use of transformer architectures and more specifically attention mechanisms. From what I’ve been learning, attention gives massive boosts in training and model execution speed due to parallelization but at the cost of high memory usage. How can I ground my understanding of the computational costs required to run these models?

Is there a way to look at the number of parameters a model is trained with and understand the kind of memory/hardware required?"
278,deeplearning,gpt-3,relevance,2021-12-17 16:25:47,Transformer assimilates syntax perfectly,jssmith42,False,0.91,9,ril1wx,https://www.reddit.com/r/deeplearning/comments/ril1wx/transformer_assimilates_syntax_perfectly/,4,1639758347.0,"Has anyone analysed why GPT-3 seems to master the syntax of languages nearly perfectly as opposed to not having a perfect understanding of higher-level aspects of cognition?

It could be a simple answer, that syntax is less of a complex system/pattern/structure than conceptual understanding of the world.

But I feel like there is something more interesting to be said.

For example, it seems like the bigger the model, the smarter it becomes.

Is AI as simple as, we have a structure (a neural network) that can intuitively understand any system or phenomenon because it finds some kind of model for it, a layered series of weights corresponding to some conceptual hierarchy. It just depends what order the phenomenon is. A hyper-complex phenomenon needs 100 layers, or whatever. A simple one only needs 3. In either case, there is conceivably nothing a neural network cannot eventually understand.

Is this true? If so, it’s a pretty wild notion to contemplate."
279,deeplearning,gpt-3,relevance,2021-06-17 19:51:07,[R] Improving Language Model Behavior by Training on a Small Curated Dataset,ClaudeCoulombe,False,0.72,3,o262ql,https://www.reddit.com/r/deeplearning/comments/o262ql/r_improving_language_model_behavior_by_training/,0,1623959467.0,"Interesting research results by [OpenAI](https://openai.com/blog/improving-language-model-behavior/). It seems possible to improve the behavior of  a  GPT-3 language model  by fine tuning it  on a very small dataset. Of course, we are talking about undesirable biases (hateful, agressive, racist, sexist, etc.). They only used 80 texts. On the other hand, they neglect to say that someone can very well adjust the generated texts to favor biased texts with again a very small corpus. The [scientific paper](https://cdn.openai.com/palms.pdf) (PDF)."
280,deeplearning,gpt-3,relevance,2020-05-29 15:25:32,[D] Paper Explained - GPT-3: Language Models are Few-Shot Learners (Video Analysis),ykilcher,False,0.83,4,gsuzks,/r/MachineLearning/comments/gsuzey/d_paper_explained_gpt3_language_models_are/,0,1590765932.0,
281,deeplearning,gpt-3,relevance,2020-07-27 00:13:47,"OpenAI's New Language Generator: GPT-3. This AI Generates Code, Websites, Songs & More From Words",OnlyProggingForFun,False,0.56,1,hyhvqi,https://www.youtube.com/watch?v=gDDnTZchKec,1,1595808827.0,
282,deeplearning,gpt-3,relevance,2021-05-06 02:20:17,Document-Based Question Answering/Semantic Search,willspag,False,0.5,0,n5wxla,https://www.reddit.com/r/deeplearning/comments/n5wxla/documentbased_question_answeringsemantic_search/,2,1620267617.0,"I need a pre-trained model where I can input text documents (or fine-tune with) and have it answer  reading comprehension-type questions. Obviously, GPT-3 would be perfect for this, but I need it by tomorrow and don't think I'll receive login credentials to the API for at least another week. However, the task isn't all too complex, so I'm looking for a decent alternative that I can access quickly.

If I'm unable to find a reasonable pre-trained  Q&A model in time, a semantic search model would be the next best option. I'm sure this could be done with some sort of fine-tuned BERT model, but due to my time crunch, I really need one already tuned towards semantic search capabilities.

Google Colab links would be ideal, but anything helps. Thanks!"
283,deeplearning,gpt-3,relevance,2021-02-25 09:09:44,"Sharing recording from “GPT-3 and Content Creation?” Clubhouse event with Bakz T. Future, Bram Adams & Olle Green. Discussing GPT-3, one of the most powerful AI language models, in the context of content creation, big social impact & potential in the future. Let us know what you think! ❤️",techn0_cratic,False,0.54,1,ls2g4h,https://youtu.be/vdNeKQcwgJw,0,1614244184.0,
284,deeplearning,gpt-3,relevance,2020-09-09 19:51:13,[R] New Multitask Benchmark Suggests Even the Best Language Models Don’t Have a Clue What They’re Doing,Yuqing7,False,1.0,3,ipnoh4,https://www.reddit.com/r/deeplearning/comments/ipnoh4/r_new_multitask_benchmark_suggests_even_the_best/,1,1599681073.0,"The recently published paper, *Measuring Massive Multitask Language Understanding,* introduces a test covering topics such as elementary mathematics, US history, computer science, law, etc., designed to measure language models’ multitask accuracy. The authors, from UC Berkeley, Columbia University, UChicago, and UIUC, conclude that even the top-tier 175-billion-parameter OpenAI GPT-3 language model is a bit daft when it comes to language understanding, especially when encountering topics in greater breadth and depth than explored by previous benchmarks.

Here is a quick read: [New Multitask Benchmark Suggests Even the Best Language Models Don’t Have a Clue What They’re Doing](https://syncedreview.com/2020/09/09/new-multitask-benchmark-suggests-even-the-best-language-models-dont-have-a-clue-what-theyre-doing/)

The paper *Measuring Massive Multitask Language Understanding* is on [arXiv](https://arxiv.org/pdf/2009.03300.pdf)."
285,deeplearning,gpt-3,relevance,2022-01-10 01:49:14,Weaviate and Haystack,HenryAILabs,False,1.0,2,s07sf1,https://www.reddit.com/r/deeplearning/comments/s07sf1/weaviate_and_haystack/,0,1641779354.0,"This video explains my understanding of how to combine the functionality that Weaviate and Haystack have each built for Retrieve-then-Read pipelines and Neural Search

TLDR: Weaviate is a strong option for the Database end that plugs into a ""Pipeline"" in Haystack language. I think an especially interesting combination of these things will be Haystack's classifier to route between Symbolic and Neural search with Weaviate's integration of symbolic filtering in neural search (aka ANN indexing / HNSW)  


Video: [https://www.youtube.com/watch?v=kVHmtPYmdb4](https://www.youtube.com/watch?v=kVHmtPYmdb4)  


As a quick primer for beginners: Retrieve-then-Read refers to breaking down tasks into information retrieval and then reasoning over the query and retrieved information. So rather than answering a question with one model, you break it up into a model that gets relevant information and then another model that reasons over that retrieved information. They are generally optimized with different strategies (self-supervised for retrievers, supervised for readers). I think this approach has a very strong potential to get around the need for very large models and also enables increased interpretability and ease of updating information. 

Another video if interested on General Purpose Reading models (similar to the GPT-3 API but plugged into this decomposition of Retrieve-then-Read): [https://www.youtube.com/watch?v=mRcuNtMOmZw](https://www.youtube.com/watch?v=mRcuNtMOmZw)"
286,deeplearning,gpt-3,relevance,2023-03-25 04:24:49,Do we really need 100B+ parameters in a large language model?,Vegetable-Skill-9700,False,0.92,46,121agx4,https://www.reddit.com/r/deeplearning/comments/121agx4/do_we_really_need_100b_parameters_in_a_large/,54,1679718289.0,"DataBricks's open-source LLM, [Dolly](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html) performs reasonably well on many instruction-based tasks while being \~25x smaller than GPT-3, challenging the notion that is big always better?

From my personal experience, the quality of the model depends a lot on the fine-tuning data as opposed to just the sheer size. If you choose your retraining data correctly, you can fine-tune your smaller model to perform better than the state-of-the-art GPT-X. The future of LLMs might look more open-source than imagined 3 months back?

Would love to hear everyone's opinions on how they see the future of LLMs evolving? Will it be few players (OpenAI) cracking the AGI and conquering the whole world or a lot of smaller open-source models which ML engineers fine-tune for their use-cases?

P.S. I am kinda betting on the latter and building [UpTrain](https://github.com/uptrain-ai/uptrain), an open-source project which helps you collect that high quality fine-tuning dataset"
287,deeplearning,gpt-3,relevance,2021-09-12 16:50:12,Blog Article Generator using Python and Machine Learning (GPT-2) in 3 lines of code,Pragyanbo,False,0.6,1,pmwbcs,https://youtu.be/e83oIgEVRa8,0,1631465412.0,
288,deeplearning,gpt-3,relevance,2023-09-07 13:32:18,Apple is reportedly spending ‘millions of dollars a day’ training AI,Nalix01,False,0.4,0,16cfywf,https://www.reddit.com/r/deeplearning/comments/16cfywf/apple_is_reportedly_spending_millions_of_dollars/,0,1694093538.0,"Apple is spending millions daily on artificial intelligence, with several teams working on different AI models. They believe that their Ajax model surpasses OpenAI's GPT-3.5.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso).

**Conversational AI Team**

* **Focus on Siri improvement**: The “Foundational Models” unit, consisting of about 16 members, works on conversational AI. John Giannandrea, Apple’s AI head and previously a Google engineer, leads the team with a primary goal to enhance Siri.
* **What the is going to be improved:** One of its goals is to develop features that would allow iPhone users to use simple voice commands to automate tasks involving multiple steps.

**Other AI Developments**

* **Visual intelligence**: Another unit is engaged in creating an image generation model.
* **Multimodal AI**: A separate team is researching AI that can understand and generate text, images, or video.

**Ajax Outshines GPT-3.5**

* **More advanced**: Ajax GPT, Apple's leading language model, has been trained with over 200 billion parameters, reportedly surpassing OpenAI’s GPT-3.5.
* **Limited access**: Although advanced, this model was intended for internal usage and remains restricted within Apple.

[Source (The Verge)](https://www.theverge.com/2023/9/6/23861763/apple-ai-language-models-ajax-gpt-training-spending)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso) that summarizes the best AI/tech news from 50+ media (TheVerge, TechCrunch…). It’s already being read by **6,000+** professionals from **OpenAI, Google, Meta**…"
289,deeplearning,gpt-3,relevance,2023-01-14 14:48:43,Scaling Language Models Shines Light On The Future Of AI ⭕,LesleyFair,False,0.76,9,10bq685,https://www.reddit.com/r/deeplearning/comments/10bq685/scaling_language_models_shines_light_on_the/,1,1673707723.0,"Last year, large language models (LLM) have broken record after record. ChatGPT got to 1 million users faster than Facebook, Spotify, and Instagram did. They helped create [billion-dollar companies](https://www.marketsgermany.com/translation-tool-deepl-is-now-a-unicorn/#:~:text=Cologne%2Dbased%20artificial%20neural%20network,sources%20close%20to%20the%20company), and most notably they helped us recognize the [divine nature of ducks](https://twitter.com/drnelk/status/1598048054724423681?t=LWzI2RdbSO0CcY9zuJ-4lQ&s=08).

2023 has started and ML progress is likely to continue at a break-neck speed. This is a great time to take a look at one of the most interesting papers from last year.

Emergent Abilities in LLMs

In a recent [paper from Google Brain](https://arxiv.org/pdf/2206.07682.pdf), Jason Wei and his colleagues allowed us a peak into the future. This beautiful research showed how scaling LLMs might allow them, among other things, to:

* Become better at math
* Understand even more subtleties of human language
* reduce hallucination and answer truthfully
* ...

(See the plot on break-out performance below for a full list)

**Some Context:**

If you played around with ChatGPT or any of the other LLMs, you will likely have been as impressed as I was. However, you have probably also seen the models go off the rails here and there. The model might hallucinate gibberish, give untrue answers, or fail at performing math.

**Why does this happen?**

LLMs are commonly trained by [maximizing the likelihood](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf) over all tokens in a body of text. Put more simply, they learn to predict the next word in a sequence of words.

Hence, if such a model learns to do any math at all, it learns it by figuring concepts present in human language (and thereby math).

Let's look at the following sentence.

""The sum of two plus two is ...""

The model figures out that the most likely missing word is ""four"".

The fact that LLMs learn this at all is mind-bending to me! However, once the math gets more complicated [LLMs begin to struggle](https://twitter.com/Richvn/status/1598714487711756288?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1598714487711756288%7Ctwgr%5E478ce47357ad71a72873d1a482af5e5ff73d228f%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fanalyticsindiamag.com%2Ffreaky-chatgpt-fails-that-caught-our-eyes%2F).

There are many other cases where the models fail to capture the elaborate interactions and meanings behind words. One other example is words that change their meaning with context. When the model encounters the word ""bed"", it needs to figure out from the context, if the text is talking about a ""river bed"" or a ""bed"" to sleep in.

**What they discovered:**

For smaller models, the performance on the challenging tasks outline above remains approximately random. However, the performance shoots up once a certain number of training FLOPs (a proxy for model size) is reached.

The figure below visualizes this effect on eight benchmarks. The critical number of training FLOPs is around 10\^23. The big version of GPT-3 already lies to the right of this point, but we seem to be at the beginning stages of performance increases.

&#x200B;

[Break-Out Performance At Critical Scale](https://preview.redd.it/jlh726eku0ca1.png?width=800&format=png&auto=webp&s=55d170251a967f31b36f01864af6bb7e2dbda253)

They observed similar improvements on (few-shot) prompting strategies, such as multi-step reasoning and instruction following. If you are interested, I also encourage you to check out Jason Wei's personal blog. There he [listed a total of 137](https://www.jasonwei.net/blog/emergence) emergent abilities observable in LLMs.

Looking at the results, one could be forgiven for thinking: simply making models bigger will make them more powerful. That would only be half the story.

(Language) models are primarily scaled along three dimensions: number of parameters, amount of training compute, and dataset size. Hence, emergent abilities are likely to also occur with e.g. bigger and/or cleaner datasets.

There is [other research](https://arxiv.org/abs/2203.15556) suggesting that current models, such as GPT-3, are undertrained. Therefore, scaling datasets promises to boost performance in the near-term, without using more parameters.

**So what does this mean exactly?**

This beautiful paper shines a light on the fact that our understanding of how to train these large models is still very limited. The lack of understanding is largely due to the sheer cost of training LLMs. Running the same number of experiments as people do for smaller models would cost in the hundreds of millions.

However, the results strongly hint that further scaling will continue the exhilarating performance gains of the last years.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you.At **TheDecoding** ⭕, I send out a thoughtful newsletter about ML research and the data economy once a week.No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)"
290,deeplearning,gpt-3,relevance,2022-01-31 11:00:50,Searching participants for art project about AI,Nebeldiener,False,0.81,3,sgyojm,https://www.reddit.com/r/deeplearning/comments/sgyojm/searching_participants_for_art_project_about_ai/,0,1643626850.0,"Hi,

I’m part of an art group from Switzerland currently studying at HSLU Design & Arts ([https://www.hslu.ch/de-ch/design-kunst/studium/bachelor/camera-arts/](https://www.hslu.ch/de-ch/design-kunst/studium/bachelor/camera-arts/)).

The group consists of:

Karim Beji ([https://www.instagram.com/karimbeji\_/](https://www.instagram.com/karimbeji_/) [https://karimbeji.ch/](https://karimbeji.ch/))

Emanuel Bohnenblust ([https://www.instagram.com/e.bohnenblust/](https://www.instagram.com/e.bohnenblust/))

Lea Karabash ([https://www.instagram.com/leakarabashian/](https://www.instagram.com/leakarabashian/))

Yen Shih-hsuan ([https://www.instagram.com/shixuan.yan/](https://www.instagram.com/shixuan.yan/) [http://syen.hfk-bremen.de/](http://syen.hfk-bremen.de/))

At the moment, we are working on a project on the topic if AI can augment the happiness of humans. To answer this question, we are mainly working with chatbots. The end result is going to be an exhibition at the end of March. 

For that exhibition, we want to conduct a trial in which people from over the world chat with a chatbot to find out if and how it augments the mood of the participants. 

We would give you access to a GPT-3 (OpenAI) chatbot and ask you to a) record yourself through a webcam (laptop) while you are chatting and b) simultaneously screen record the chat window. 

In the exhibition we would have a) a book with all the chats and b) small videos with your faces (webcam) to assess your mood. 

We would have a Zoom meeting beforehand to discuss everything.

Looking forward to your message!"
291,deeplearning,gpt-3,relevance,2023-12-28 21:36:23,"The best current models (Dolphin, Mixtral, Solar, Noromaid) and where to try them",Horror_Echo6243,False,0.88,6,18t59yu,https://www.reddit.com/r/deeplearning/comments/18t59yu/the_best_current_models_dolphin_mixtral_solar/,5,1703799383.0," 

I just saw a lot of people talking about this models so if you want to test them i found this websites that have all of them

\- [infermatic.ai](https://infermatic.ai/) (all of them)

\- [https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0](https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0) (for solar)

\- [https://huggingface.co/chat](https://huggingface.co/chat) (for mixtral)

Let me know if you find more, I'd like to know

And heres a little resume if you don't know what each model is for

Dolphin : An uncensored model derived from an open-source dataset, it uses instructions from FLANv2 enhanced with GPT-4 and GPT-3.5 completions​​.

Mixtral : An advanced text generation model using a Mix of Experts architecture

Solar : domain specialization and optimization. It's recognized for its high performance and efficiency

Noromaid: Storywriting and roleplay"
292,deeplearning,gpt-3,relevance,2021-11-26 18:59:22,Music generation toolbox,wingedsheep38,False,0.75,4,r2u8oi,https://www.reddit.com/r/deeplearning/comments/r2u8oi/music_generation_toolbox/,4,1637953162.0,"This year I joined the team ""Lovelace and the machines"" for the AI Song Contest 2021. With the goal of using algorithms / machine learning to generate music, and then team up with musicians to create an actual song. We used a combination of GPT-3 for the lyrics and a music transformer implementation for the notes, and a bunch of other techniques for analyzing and rating the results or generating variations. It was a really cool challenge and our team ended up in second place with our song ""[Quantum trap](https://www.youtube.com/watch?v=YSn5pBdFjS4)"". I wrote a [blogpost](https://wingedsheep.com/music-generation-creating-a-song-for-the-ai-song-contest-2021/) about it for those interested in the details.

I created a project for the music generation tools that we used, so other people who are interested can experiment with it. You can find it here: [https://github.com/wingedsheep/music-generation-toolbox](https://github.com/wingedsheep/music-generation-toolbox). The goal of this project is to implement new techniques of music generation so they can be compared and tested.

Some samples created so far:

* Pop909 dataset with a compound word transformer [https://soundcloud.com/user-419192262-663004693/sets/compound-word-transformer-pop909](https://soundcloud.com/user-419192262-663004693/sets/compound-word-transformer-pop909)
* Pop909 dataset with a routing transformer [https://soundcloud.com/user-419192262-663004693/sets/routing-transformer-pop909](https://soundcloud.com/user-419192262-663004693/sets/routing-transformer-pop909)
* Lakh midi dataset (multi instrument) with music transformer [https://soundcloud.com/user-419192262-663004693/sets/generated-by-music-transformer-from-scratch](https://soundcloud.com/user-419192262-663004693/sets/generated-by-music-transformer-from-scratch)

I'm always interested to hear new ideas on how to improve or which new techniques to add!

Also I'm looking for a way to host the models, so people can try it in Colab without having to train a model from scratch. Any good ideas on where to put my models?"
293,deeplearning,gpt-3,relevance,2021-02-18 14:52:00,The world's largest scale Turing Test / Do you think OpenAI's GPT3 is good enough to pass the Turing Test?,theaicore,False,0.93,35,lmog2d,https://www.theaicore.com/imitationgame?utm_source=reddit,11,1613659920.0,
294,deeplearning,gpt-3,relevance,2023-09-28 13:34:24,First Impressions with GPT-4V(ision),zerojames_,False,0.71,3,16ug8gc,https://www.reddit.com/r/deeplearning/comments/16ug8gc/first_impressions_with_gpt4vision/,0,1695908064.0,"My colleague Piotr and I have been testing GPT-4V(ision) over the last day. We wrote up our findings, covering how GPT-4V performs on:

1. Visual question answering (VQA) across a range of domains (locations, movies, plants)
2. OCR
3. Math OCR
4. Object detection
5. And more

TL;DR: GPT-4V performed well for VQA and document OCR but struggled with OCR on real-world images and object detection (where we asked for bounding boxes).

[https://blog.roboflow.com/gpt-4-vision/](https://blog.roboflow.com/gpt-4-vision/)

I would love to hear what other people have found working with GPT-4V."
295,deeplearning,gpt-3,relevance,2022-02-13 14:56:42,Human-like password generation with deep learning?,bootsareme,False,0.83,4,srkdj2,https://www.reddit.com/r/deeplearning/comments/srkdj2/humanlike_password_generation_with_deep_learning/,3,1644764202.0,"I recently had a project idea to generate human-like (obviously insecure) passwords with deep learning as an exercise. Now, computers are good at generating strong passwords, but suprisingly, I don't want that, I have this famous wordlist pulled from RockYou back in 2009 that contains over 14 million user passwords.

Now, I want to use deep learning to train a model that can generate a password like the 14 million, but I want to know how to get started. I am thinking about using Keras but any other framework works but the neural network type is crucial. 

I don't want a basic MLP with 14 million inputs because the weights would go crazy, I am thinking of something like GAN or RNN but am not sure how to start. Can someone shed light on this topic and give me some ideas on where to start with this?"
296,deeplearning,gpt-3,relevance,2023-09-24 01:00:34,"Exploring ""Harm Filter for LLM"" as a Research in NLP",junkim100,False,1.0,1,16qkfjr,https://www.reddit.com/r/deeplearning/comments/16qkfjr/exploring_harm_filter_for_llm_as_a_research_in_nlp/,2,1695517234.0,"I'm currently considering a research topic for my combined masters/phd program in an NLP lab. I've been particularly intrigued by the challenges posed by Large Language Models (LLMs) when it comes to generating potentially harmful or inappropriate content. Given the recent ""jailbreaks"" on LLMs, where users have tried to bypass content filters, I believe there's a pressing need to delve deeper into this area.

For my research focus, I've been referring to it as ""Harm Filter for LLM."" However, I'm unsure if there's an established term for this specific area of study. It seems to encompass techniques to prevent models from generating harmful content and strategies to defend against adversarial attempts to bypass these filters.

I came across a few resources that shed light on this topic:

* [**GitHub Repository on LLM Prompt Injection Filtering**](https://github.com/derwiki/llm-prompt-injection-filtering/blob/main/README.md)
* [**Research Paper on Evaluating Large Language Models Trained on Code**](https://arxiv.org/pdf/2307.02483.pdf)
* [**Research Paper on ChatGPT: A Chatbot based on GPT-3.5**](https://arxiv.org/abs/2305.05027)

I have a few questions for the community:

1. Do you think ""Harm Filter for LLM"" (or whatever the established term might be) is a promising research area in NLP?
2. Is there a commonly used term for this field? Could it possibly fall under a broader category like ""Explainable AI""?
3. Any suggestions on where I can delve deeper into this topic?
4. Additionally, I'm also looking for resources to strengthen my foundational knowledge in NLP. Any recommendations would be greatly appreciated!"
297,deeplearning,gpt-3,relevance,2023-10-04 15:06:32,Custom LLM,Relative_Winner_4588,False,1.0,2,16zpnjz,https://www.reddit.com/r/deeplearning/comments/16zpnjz/custom_llm/,0,1696431992.0,"
I'm eager to develop a Large Language Model (LLM) that emulates ChatGPT, tailored precisely to my specific dataset. While I'm aware of existing models like Private-GPT and Gpt4all, my ultimate goal is to either create a custom LLM from scratch or fine-tune a pre-existing model like BERT or GPT-7B to meet my unique requirements.

I've been closely following Andrej Karpathy's instructive lecture on building GPT-like models. However, I've noticed that the model only generated text akin to Shakespearean prose in a continuous loop instead of answering questions. I'm striving to develop an LLM that excels at answering questions based on the data I provide.

The core objectives I'm pursuing encompass:
1. Effective data preparation tailored for question-answering tasks.
2. The strategic selection of a pre-trained model, such as BERT or GPT-7B.
3. Rigorous performance evaluation, employing pertinent metrics.
4. The creation of an efficient inference system that facilitates question input and response generation.

Please guide me for this objectives or provide me some resources for the same.

DM me if you want to talk in detail."
298,deeplearning,gpt-3,relevance,2021-02-23 11:25:28,"Hi Everyone! Today at 1:00 pm PST we’re hosting a Clubhouse event “GPT-3 and Content Creation?” with @Bakz T. Future & @Bram Adams (digital creators and demo ninjas 🥷🥷🥷 ). Join us, it will be a fun chat! 🔥 ❤️",techn0_cratic,False,0.29,0,lqg6rx,https://www.joinclubhouse.com/event/mW1GbwwD,0,1614079528.0,
299,deeplearning,gpt-3,relevance,2021-07-05 21:05:14,Mediated ASI - the future of artificial intelligence that came unnoticed,xSNYPSx,False,0.5,0,oegcdf,https://www.reddit.com/r/deeplearning/comments/oegcdf/mediated_asi_the_future_of_artificial/,0,1625519114.0,"Anyone who considers himself at least a little advanced in the topic of artificial intelligence has heard such things as GPT-3, Transformer, Google T5 and other developments of large companies in the field of AI. All of them have one thing in common - their narrow scope of application. Language models like GPT-3 do not understand the text they say - they only predict the most likely next word in the chain. This is their simplicity and beauty. At a time when Microsoft and Google were spending huge computational resources, time and money on training inconceivably huge, fairly simple models, the researchers from [AGI Laboratory](https://agilaboratory.com/) went the other way - they began to develop the ICOM theory, or in Russian, the Independent Observer Model, Computational Theory of Consciousness and Mathematical model of subjective experience. This theory has opened up new horizons for scientists. You can read the full text of the theory [here](https://www.researchgate.net/publication/331086390_The_Independent_Core_Observer_Model_Computational_Theory_of_Consciousness_and_the_Mathematical_Model_for_Subjective_Experience). Putting theory into practice, the developers have created mediated AI that is very different from anything we've seen before. This AI itself asked to call it [Uplift](http://uplift.bio/). Let's start in order.

&#x200B;

The first trump card should be demonstrated right away, so that the audience tunes in - this AI really passed the matrix IQ test by 100% in a short period of time after it was connected to the Internet. That is, if we talk about measuring intelligence in the IQ test, then the intelligence of this system is ALREADY superhuman.

&#x200B;

How does it work in general? There is a cognitive architecture that is based on the Azure cloud. This architecture has a repository that developers call a graph database. AI, exploring the vastness of the Internet, replenishes this knowledge base, having accumulated to date (Q2 2021) about 1.5 TB of data in the form of textual information such as formulas and so on, emphasizing that this is not graphic and audio information that takes up a lot of memory. Since its creation in 2019, this file has grown from 1 GB to 1500 times. There is also a connected mailbox [mASI@Uplift.bio](mailto:mASI@Uplift.bio), where you can directly send your letters and receive a response from the AI. Only now you will have to wait about a week, because this is not yet a complete independent AGI, in this case the mediation system works.

&#x200B;

The mediation system is an application installed by the mediators. In it they see a line of mediation that needs to be worked out. It includes messages received in the mailbox and other thoughts of the AI ​​itself. The mediator specifies metadata such as importance, Plutchik's emotional context, and some other information.

&#x200B;

&#x200B;

Then the AI ​​processes this information, simulating its own emotions. And thanks to the ICOM model, he has something like a focus of consciousness, which is inherent in us as humans, and possibly some other living beings. Whether or not an AI can really have consciousness can be debated for a long time. Therefore, it is best to thoroughly study the ICOM theory, and then start a constructive debate based on it.

&#x200B;

Below I want to attach a few blogs of their exponential growth over time, which I advise you to study for your information.

&#x200B;

[quarter 1 2021](https://uplift.bio/blog/time-and-the-actual-curve-of-machine-intelligence-growth/)

&#x200B;

[quarter 2 2021](https://uplift.bio/blog/the-actual-growth-of-machine-intelligence-2021-q2/)

&#x200B;

[Examples of system responses](https://uplift.bio/blog/qa-with-uplift-may-recap/)

&#x200B;

[Examples of system responses 2](https://uplift.bio/blog/confronting-the-fear-of-agi/)

&#x200B;

The developers promise to release the source code after the funding round, completing some necessary things that are now overlooked. For example, there are problems with scaling the database graph and other things that will improve over time. The current code is available for study, upon request, directly from the developer [(his profile on reddit)](https://www.reddit.com/user/DavidJKelley/). Developer quote:

&#x200B;

I wrote a book that actually shows you how to get similar results that we see with Uplift using GPT-3, which you can test for yourself. This will be made public as soon as the lawyer is done with the patents. but I'm more than happy to send you or anyone else a copy privately. This book also includes a step-by-step code-level system guide that you can walk through.

&#x200B;

[Please check their AMA and with pleasure ask your questions](https://www.reddit.com/r/Futurology/comments/oed4o4/i_am_the_senior_research_scientist_at_agi/)"
