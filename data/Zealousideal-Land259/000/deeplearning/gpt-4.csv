,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,id,url,num_comments,created,body
0,deeplearning,gpt-4,top,2023-01-27 10:45:48,⭕ What People Are Missing About Microsoft’s $10B Investment In OpenAI,LesleyFair,False,0.95,116,10mhyek,https://www.reddit.com/r/deeplearning/comments/10mhyek/what_people_are_missing_about_microsofts_10b/,16,1674816348.0,"&#x200B;

[Sam Altman Might Have Just Pulled Off The Coup Of The Decade](https://preview.redd.it/sg24cw3zekea1.png?width=720&format=png&auto=webp&s=9eeae99b5e025a74a6cbe3aac7a842d2fff989a1)

Microsoft is investing $10B into OpenAI!

There is lots of frustration in the community about OpenAI not being all that open anymore. They appear to abandon their ethos of developing AI for everyone, [free](https://openai.com/blog/introducing-openai/) of economic pressures.

The fear is that OpenAI’s models are going to become fancy MS Office plugins. Gone would be the days of open research and innovation.

However, the specifics of the deal tell a different story.

To understand what is going on, we need to peek behind the curtain of the tough business of machine learning. We will find that Sam Altman might have just orchestrated the coup of the decade!

To appreciate better why there is some three-dimensional chess going on, let’s first look at Sam Altman’s backstory.

*Let’s go!*

# A Stellar Rise

Back in 2005, Sam Altman founded [Loopt](https://en.wikipedia.org/wiki/Loopt) and was part of the first-ever YC batch. He raised a total of $30M in funding, but the company failed to gain traction. Seven years into the business Loopt was basically dead in the water and had to be shut down.

Instead of caving, he managed to sell his startup for $[43M](https://golden.com/wiki/Sam_Altman-J5GKK5) to the finTech company [Green Dot](https://www.greendot.com/). Investors got their money back and he personally made $5M from the sale.

By YC standards, this was a pretty unimpressive outcome.

However, people took note that the fire between his ears was burning hotter than that of most people. So hot in fact that Paul Graham included him in his 2009 [essay](http://www.paulgraham.com/5founders.html?viewfullsite=1) about the five founders who influenced him the most.

He listed young Sam Altman next to Steve Jobs, Larry & Sergey from Google, and Paul Buchheit (creator of GMail and AdSense). He went on to describe him as a strategic mastermind whose sheer force of will was going to get him whatever he wanted.

And Sam Altman played his hand well!

He parleyed his new connections into raising $21M from Peter Thiel and others to start investing. Within four years he 10x-ed the money \[2\]. In addition, Paul Graham made him his successor as president of YC in 2014.

Within one decade of selling his first startup for $5M, he grew his net worth to a mind-bending $250M and rose to the circle of the most influential people in Silicon Valley.

Today, he is the CEO of OpenAI — one of the most exciting and impactful organizations in all of tech.

However, OpenAI — the rocket ship of AI innovation — is in dire straights.

# OpenAI is Bleeding Cash

Back in 2015, OpenAI was kickstarted with $1B in donations from famous donors such as Elon Musk.

That money is long gone.

In 2022 OpenAI is projecting a revenue of $36M. At the same time, they spent roughly $544M. Hence the company has lost >$500M over the last year alone.

This is probably not an outlier year. OpenAI is headquartered in San Francisco and has a stable of 375 employees of mostly machine learning rockstars. Hence, salaries alone probably come out to be roughly $200M p.a.

In addition to high salaries their compute costs are stupendous. Considering it cost them $4.6M to train GPT3 once, it is likely that their cloud bill is in a very healthy nine-figure range as well \[4\].

So, where does this leave them today?

Before the Microsoft investment of $10B, OpenAI had received a total of $4B over its lifetime. With $4B in funding, a burn rate of $0.5B, and eight years of company history it doesn’t take a genius to figure out that they are running low on cash.

It would be reasonable to think: OpenAI is sitting on ChatGPT and other great models. Can’t they just lease them and make a killing?

Yes and no. OpenAI is projecting a revenue of $1B for 2024. However, it is unlikely that they could pull this off without significantly increasing their costs as well.

*Here are some reasons why!*

# The Tough Business Of Machine Learning

Machine learning companies are distinct from regular software companies. On the outside they look and feel similar: people are creating products using code, but on the inside things can be very different.

To start off, machine learning companies are usually way less profitable. Their gross margins land in the 50%-60% range, much lower than those of SaaS businesses, which can be as high as 80% \[7\].

On the one hand, the massive compute requirements and thorny data management problems drive up costs.

On the other hand, the work itself can sometimes resemble consulting more than it resembles software engineering. Everyone who has worked in the field knows that training models requires deep domain knowledge and loads of manual work on data.

To illustrate the latter point, imagine the unspeakable complexity of performing content moderation on ChatGPT’s outputs. If OpenAI scales the usage of GPT in production, they will need large teams of moderators to filter and label hate speech, slurs, tutorials on killing people, you name it.

*Alright, alright, alright! Machine learning is hard.*

*OpenAI already has ChatGPT working. That’s gotta be worth something?*

# Foundation Models Might Become Commodities:

In order to monetize GPT or any of their other models, OpenAI can go two different routes.

First, they could pick one or more verticals and sell directly to consumers. They could for example become the ultimate copywriting tool and blow [Jasper](https://app.convertkit.com/campaigns/10748016/jasper.ai) or [copy.ai](https://app.convertkit.com/campaigns/10748016/copy.ai) out of the water.

This is not going to happen. Reasons for it include:

1. To support their mission of building competitive foundational AI tools, and their huge(!) burn rate, they would need to capture one or more very large verticals.
2. They fundamentally need to re-brand themselves and diverge from their original mission. This would likely scare most of the talent away.
3. They would need to build out sales and marketing teams. Such a step would fundamentally change their culture and would inevitably dilute their focus on research.

The second option OpenAI has is to keep doing what they are doing and monetize access to their models via API. Introducing a [pro version](https://www.searchenginejournal.com/openai-chatgpt-professional/476244/) of ChatGPT is a step in this direction.

This approach has its own challenges. Models like GPT do have a defensible moat. They are just large transformer models trained on very large open-source datasets.

As an example, last week Andrej Karpathy released a [video](https://www.youtube.com/watch?v=kCc8FmEb1nY) of him coding up a version of GPT in an afternoon. Nothing could stop e.g. Google, StabilityAI, or HuggingFace from open-sourcing their own GPT.

As a result GPT inference would become a common good. This would melt OpenAI’s profits down to a tiny bit of nothing.

In this scenario, they would also have a very hard time leveraging their branding to generate returns. Since companies that integrate with OpenAI’s API control the interface to the customer, they would likely end up capturing all of the value.

An argument can be made that this is a general problem of foundation models. Their high fixed costs and lack of differentiation could end up making them akin to the [steel industry](https://www.thediff.co/archive/is-the-business-of-ai-more-like-steel-or-vba/).

To sum it up:

* They don’t have a way to sustainably monetize their models.
* They do not want and probably should not build up internal sales and marketing teams to capture verticals
* They need a lot of money to keep funding their research without getting bogged down by details of specific product development

*So, what should they do?*

# The Microsoft Deal

OpenAI and Microsoft [announced](https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/) the extension of their partnership with a $10B investment, on Monday.

At this point, Microsoft will have invested a total of $13B in OpenAI. Moreover, new VCs are in on the deal by buying up shares of employees that want to take some chips off the table.

However, the astounding size is not the only extraordinary thing about this deal.

First off, the ownership will be split across three groups. Microsoft will hold 49%, VCs another 49%, and the OpenAI foundation will control the remaining 2% of shares.

If OpenAI starts making money, the profits are distributed differently across four stages:

1. First, early investors (probably Khosla Ventures and Reid Hoffman’s foundation) get their money back with interest.
2. After that Microsoft is entitled to 75% of profits until the $13B of funding is repaid
3. When the initial funding is repaid, Microsoft and the remaining VCs each get 49% of profits. This continues until another $92B and $150B are paid out to Microsoft and the VCs, respectively.
4. Once the aforementioned money is paid to investors, 100% of shares return to the foundation, which regains total control over the company. \[3\]

# What This Means

This is absolutely crazy!

OpenAI managed to solve all of its problems at once. They raised a boatload of money and have access to all the compute they need.

On top of that, they solved their distribution problem. They now have access to Microsoft’s sales teams and their models will be integrated into MS Office products.

Microsoft also benefits heavily. They can play at the forefront AI, brush up their tools, and have OpenAI as an exclusive partner to further compete in a [bitter cloud war](https://www.projectpro.io/article/aws-vs-azure-who-is-the-big-winner-in-the-cloud-war/401) against AWS.

The synergies do not stop there.

OpenAI as well as GitHub (aubsidiary of Microsoft) e. g. will likely benefit heavily from the partnership as they continue to develop[ GitHub Copilot](https://github.com/features/copilot).

The deal creates a beautiful win-win situation, but that is not even the best part.

Sam Altman and his team at OpenAI essentially managed to place a giant hedge. If OpenAI does not manage to create anything meaningful or we enter a new AI winter, Microsoft will have paid for the party.

However, if OpenAI creates something in the direction of AGI — whatever that looks like — the value of it will likely be huge.

In that case, OpenAI will quickly repay the dept to Microsoft and the foundation will control 100% of whatever was created.

*Wow!*

Whether you agree with the path OpenAI has chosen or would have preferred them to stay donation-based, you have to give it to them.

*This deal is an absolute power move!*

I look forward to the future. Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

*Thank you for reading!*

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] [https://golden.com/wiki/Sam\_Altman-J5GKK5](https://golden.com/wiki/Sam_Altman-J5GKK5)​

\[2\] [https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny](https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny)​

\[3\] [Article in Fortune magazine ](https://fortune.com/2023/01/11/structure-openai-investment-microsoft/?verification_code=DOVCVS8LIFQZOB&_ptid=%7Bkpdx%7DAAAA13NXUgHygQoKY2ZRajJmTTN6ahIQbGQ2NWZsMnMyd3loeGtvehoMRVhGQlkxN1QzMFZDIiUxODA3cnJvMGMwLTAwMDAzMWVsMzhrZzIxc2M4YjB0bmZ0Zmc0KhhzaG93T2ZmZXJXRDFSRzY0WjdXRTkxMDkwAToMT1RVVzUzRkE5UlA2Qg1PVFZLVlpGUkVaTVlNUhJ2LYIA8DIzZW55eGJhajZsWiYyYTAxOmMyMzo2NDE4OjkxMDA6NjBiYjo1NWYyOmUyMTU6NjMyZmIDZG1jaOPAtZ4GcBl4DA)​

\[4\] [https://arxiv.org/abs/2104.04473](https://arxiv.org/abs/2104.04473) Megatron NLG

\[5\] [https://www.crunchbase.com/organization/openai/company\_financials](https://www.crunchbase.com/organization/openai/company_financials)​

\[6\] Elon Musk donation [https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research](https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research)​

\[7\] [https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/](https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/)"
1,deeplearning,gpt-4,top,2023-04-05 01:36:40,Vicuna : an open source chatbot impresses GPT-4 with 90% of the quality of ChatGPT,Time_Key8052,False,0.95,86,12c43uu,https://www.reddit.com/r/deeplearning/comments/12c43uu/vicuna_an_open_source_chatbot_impresses_gpt4_with/,19,1680658600.0,"Vicuna : ChatGPT Alternative, Open-Source, High Quality and Low Cost 

&#x200B;

[ Relative Response Quality Assessed by GPT-4 ](https://preview.redd.it/oaj1s995zyra1.png?width=599&format=png&auto=webp&s=1fb01b017b3b8b4f9149d4b80f40c48d3a072b91)

Vicuna-13B has demonstrated competitive performance against other open-source models, such as Stanford Alpaca, by fine-tuning a LLaMA base model on user-shared conversations collected from ShareGPT.

Evaluation using GPT-4 as a judge shows that Vicuna-13B achieves more than 90% of the quality of OpenAI ChatGPT and Google Bard AI, while outperforming other models such as Meta LLaMA (Large Language Model Meta AI) and Stanford Alpaca in more than 90% of cases.

The cost of training Vicuna-13B is approximately $300.

The training and serving code, along with an online demo, are publicly available for non-commercial use.

&#x200B;

More Information : [https://gpt4chatgpt.tistory.com/entry/Vicuna-an-open-source-chatbot-impresses-GPT-4-with-90-of-the-quality-of-ChatGPT](https://gpt4chatgpt.tistory.com/entry/Vicuna-an-open-source-chatbot-impresses-GPT-4-with-90-of-the-quality-of-ChatGPT)

Discord Server : [https://discord.gg/h6kCZb72G7](https://discord.gg/h6kCZb72G7)

Twitter : [https://twitter.com/lmsysorg](https://twitter.com/lmsysorg)"
2,deeplearning,gpt-4,top,2023-01-19 07:55:49,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.9,72,10fw22o,https://www.reddit.com/r/deeplearning/comments/10fw22o/gpt4_will_be_500x_smaller_than_people_think_here/,11,1674114949.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/xvpw1erngyca1.png?width=575&format=png&auto=webp&s=d7bea7c6132081f2df7c950a0989f398599d6cae)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you. At **TheDecoding** ⭕, I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
3,deeplearning,gpt-4,top,2023-06-05 04:33:14,How Open Ai’s Andrej Karpathy Made One of the Best Tutorials in Deep Learning,0ssamaak0,False,0.92,61,141282u,https://www.reddit.com/r/deeplearning/comments/141282u/how_open_ais_andrej_karpathy_made_one_of_the_best/,3,1685939594.0,"I want you to check [my review](https://medium.com/@0ssamaak0/how-open-ais-andrej-karpathy-made-one-of-the-best-tutorials-in-deep-learning-e6b6445a2d05) on Andrej Karpathy amazing work on explaining how GPT is built

[GitHub Repo](https://github.com/0ssamaak0/Karpathy-Neural-Networks-Zero-to-Hero) for code & more details

&#x200B;

https://preview.redd.it/z204zwtzn44b1.png?width=720&format=png&auto=webp&s=095ea00991ebb295f48b70436456b1f283a50df1"
4,deeplearning,gpt-4,top,2023-08-25 13:21:12,AI Meets AI: A Conversation Between GPT-4 and Google's Bard,Ubica123,False,0.8,33,160z5pp,https://www.youtube.com/watch?v=3H45IncZ7gs,3,1692969672.0,
5,deeplearning,gpt-4,top,2023-04-12 05:21:13,Is OpenAI’s Study On The Labor Market Impacts Of AI Flawed?,LesleyFair,False,0.94,26,12jb4xz,https://www.reddit.com/r/deeplearning/comments/12jb4xz/is_openais_study_on_the_labor_market_impacts_of/,1,1681276873.0,"[Example img\_name](https://preview.redd.it/f3hrmeet1eta1.png?width=1451&format=png&auto=webp&s=20e20b142a2f88c3d495177e540f34bc8ea4312b)

We all have heard an uncountable amount of predictions about how AI will ***terk err jerbs!***

However, here we have a proper study on the topic from OpenAI and the University of Pennsylvania. They investigate how Generative Pre-trained Transformers (GPTs) could automate tasks across different occupations \[1\].

Although I’m going to discuss how the study comes with a set of “imperfections”, the findings still make me really excited. The findings suggest that machine learning is going to deliver some serious productivity gains.

People in the data science world fought tooth and nail for years to squeeze some value out of incomplete data sets from scattered sources while hand-holding people on their way toward a data-driven organization. At the same time, the media was flooded with predictions of omniscient AI right around the corner.

*Let’s dive in and take an* exciting glimpse into the future of labor markets\*!\*

# What They Did

The study looks at all US occupations. It breaks them down into tasks and assesses the possible level of for each task. They use that to estimate how much automation is possible for a given occupation.

The researchers used the [O\*NET database,](https://www.onetcenter.org/database.html) which is an occupation database specifically for the U.S. market. It lists 1,016 occupations along with its standardized descriptions of tasks.

The researchers annotated each task once manually and once using GPT-4. Thereby, each task was labeled as either somewhat (<50%) or significantly (>50%) automatable through LLMs. In their judgment, they considered both the direct “exposure” of a task to GPT as well as to a secondary GPT-powered system, e.g. LLMs integrated with image generation systems.

To reiterate, a higher “exposure” means that an occupation is more likely to get automated.

Lastly, they enriched the occupation data with wages and demographic information. This was used to determine whether e. g. high or low-paying jobs are at higher risk to be automated.

So far so good. This all sounds pretty decent. Sure, there is a lot of qualitative judgment going into their data acquisition process. However, we gotta cut them some slag. These kinds of studies always struggle to get any hard data and so far they did a good job.

However, there are a few obvious things to criticize. But before we get to that let’s look at their results.

# Key Findings

The study finds that 80% of the US workforce, across all industries, could have at least some tasks affected. Even more significantly, 19% of occupations are expected to have at least half of their tasks significantly automated!

Furthermore, they find that higher levels of automation exposure are associated with:

* Programming and writing skills
* Higher wages (contrary to previous research!)
* Higher levels of education (Bachelor’s and up)

Lower levels of exposure are associated with:

* Science and critical thinking skills
* Manual work and tasks that might potentially be done using physical robots

This is somewhat unsurprising. We of course know that LLMs will likely not increase productivity in the plumbing business. However, their findings underline again how different this wave is. In the past, simple and repetitive tasks fell prey to automation.

*This time it’s the suits!*

If we took this study at face value, many of us could start thinking about life as full-time pensioners.

But not so fast! This, like all the other studies on the topic, has a number of flaws.

# Necessary Criticism

First, let’s address the elephant in the room!

OpenAI co-authored the study. They have a vested interest in the hype around AI, both for commercial and regulatory reasons. Even if the external researchers performed their work with the utmost thoroughness and integrity, which I am sure they did, the involvement of OpenAI could have introduced an unconscious bias.

*But there’s more!*

The occupation database contains over 1000 occupations broken down into tasks. Neither GPT-4 nor the human labelers can possibly have a complete understanding of all the tasks across all occupations. Hence, their judgment about how much a certain task can be automated has to be rather hand-wavy in many cases.

Flaws in the data also arise from the GPT-based labeling itself.

The internet is flooded with countless sensationalist articles about how AI will replace jobs. It is hard to gauge whether this actually causes GPT models to be more optimistic when it comes to their own impact on society. However, it is possible and should not be neglected.

The authors do also not really distinguish between labor-augmenting and labor-displacing effects and it is hard to know what “affected by” or “exposed to LLMs” actually means. Will people be replaced or will they just be able to do more?

Last but not least, lists of tasks most likely do not capture all requirements in a given occupation. For instance ""making someone feel cared for"" can be an essential part of a job but might be neglected in such a list.

# Take-Away And Implications

GPT models have the world in a frenzy - rightfully so.

Nobody knows whether 19% of knowledge work gets heavily automated or if it is only 10%.

As the dust settles, we will begin to see how the ecosystem develops and how productivity in different industries can be increased. Time will tell whether foundational LLMs, specialized smaller models, or vertical tools built on top of APIs will be having the biggest impact.

In any case, these technologies have the potential to create unimaginable value for the world. At the same time, change rarely happens without pain. I strongly believe in human ingenuity and our ability to adapt to change. All in all, the study - flaws aside - represents an honest attempt at gauging the future.

Efforts like this and their scrutiny are our best shot at navigating the future. Well, or we all get chased out of the city by pitchforks.

Jokes aside!

What an exciting time for science and humanity!

As always, I really enjoyed making this for you and I sincerely hope you found value in it!

If you are not subscribed to the newsletter yet, [click here to sign up](https://thedecoding.net/)! I send out a thoughtful 5-minute email every week to keep you in the loop about machine learning research and the data economy.

*Thank you for reading and I see you next week ⭕!*

**References:**

\[1\] [https://arxiv.org/abs/2303.10130](https://arxiv.org/abs/2303.10130)"
6,deeplearning,gpt-4,top,2023-03-05 11:10:56,LLaMA model parallelization and server configuration,ChristmasInOct,False,1.0,25,11ium8l,https://www.reddit.com/r/deeplearning/comments/11ium8l/llama_model_parallelization_and_server/,8,1678014656.0,"Hey everyone,

First of all, tldr at bottom, typed more than expected here.  

Please excuse the rather naive perspective I have here.  I've followed along with great interest, but this is not my industry.

Regardless, I have spent the past 3-4 days falling down a brutally obsessive rabbit hole, and I cannot seem to find this information.  I'm assuming it's just that I am missing context of course, and regardless of whether there is a clear answer, I'm trying to get a better understanding of this topic so that I could better appraise the situation myself.

Really I suppose I have two questions.  **The first** is regarding model parallelization.

I'm assuming this is not generic whatsoever.  What is the typical process engineers go about for designing such a pipeline?  Specifically in regards to these new LLaMA models, is something like ALPA relevant?  Deepspeed?

More importantly, what information should I be seeking to determine this myself?

This roughly segues to my **second inquiry**.

The reason I'm curious about splitting the model pipeline etc., is that I am potentially in interested in standing a server up for this.  Although I don't have much of a budget for this build (\~$30-40K is the rough top-end, but I'd be a lot happier around $20-25K), the money is there if I can genuinely satisfy my use-case.

I work at a small, but borderline manic startup working on enterprise software; 90% of the work we're doing based in the react/node ecosystem, some low-level work for backend services, and some very interesting database work that I have very little to do with.  I am a fullstack engineer that grew up playing with C++ => C#, and somehow ended up spending all of my time r/w'ing javascript.  Lol.  Anyways.

Part of our roadmap since GPT-3 and the playground were made publicly accessible, involves usage of these transformer models, and their ability to interpret natural language inputs, whether from user inputs, or scraped input values generated somewhere in a chain of requests / operations.

Seeing GPT-3 in action made me specifically realize that my estimations on this technology had been wildly off.  Seeing ChatGPT in action and uptick, the API's becoming available, has me further panicked.

Running our inference through their API has never really been an option for us.  I haven't even really looked that far into it, but bottom line the data running through our platform is all back-office, highly sensitive business information, and many have agreements explicitly restricting the movement of data to or from any cloud services, with Microsoft, Amazon, and Google all specifically mentioned.

Regardless of the reasoning for these contracts, the LLaMA release has had me obsessed over this topic in more detail than before, and whether or not I would be able to get this setup privately, for our use-case.

**To get to the actual second inquiry**:

Say I want to throw a budget rig together for this in a server cabinet.  Am I able to effectively parallelize the LLaMA model, well enough to justify going with 24GB VRAM 4090's in the rig?  Say I do so with DeepSpeed, or some of the standard model parallelization libraries.

Is the performance cost low enough to justify taking the extra compute here over 1/3 - 1/2 as many RTX6000 ADA's?

Or should I be grabbing the 48GB ADA's?

Like I said, I apologize for the naivety, I'm really looking for more information so that I can start to put this picture together better on my own.  It really isn't the easiest topic to research with how quickly things seem to move, and the giant gap between conversation depths (gamer || phd in a lot of the most interesting or niche discussions, little between).

Thank you very much for your time.

TL;DR - Any information on LLaMA model parallelization at the moment?  Will it be compatible with things like zero or alpa?  How about for throwing a rig together right now for fine-tuning and then running inference on the LLaMA models?  48GB 6000 ADA's, or 24GB 4090's?

Planning on putting it in a mostly empty 42U cabinet that also houses our primary web server and networking hardware, so if there is a sales pitch for 4090's across multiple nodes here, I do have a massive bias as the kind of nerd that finds that kind of hardware borderline erotic.

Hydro and cooling are not an issue, just usage of the budget and understanding the requirements / approach given memory limitations, and how to avoid communication bottlenecks or even balance them against raw compute.

Thanks again everyone!"
7,deeplearning,gpt-4,top,2023-04-25 17:53:47,"Microsoft releases SynapseMl v0.11 with support for ChatGPT, GPT-4, causal learning, and more",mhamilton723,False,0.86,23,12yqpnp,https://www.reddit.com/r/deeplearning/comments/12yqpnp/microsoft_releases_synapseml_v011_with_support/,0,1682445227.0,"Today Microsoft launched SynapseML v0.11 with support for ChatGPT, GPT-4, distributed training of huggingface and torchvision models, an ONNX Model hub integration, Causal Learning with EconML, 10x memory reductions for LightGBM, and a newly refactored integration with Vowpal Wabbit. To learn more check out our release notes and please feel give us a star if you enjoy the project!

Release Notes: [https://github.com/microsoft/SynapseML/releases/tag/v0.11.0](https://github.com/microsoft/SynapseML/releases/tag/v0.11.0)

Blog: [https://techcommunity.microsoft.com/t5/azure-synapse-analytics-blog/what-s-new-in-synapseml-v0-11/ba-p/3804919](https://techcommunity.microsoft.com/t5/azure-synapse-analytics-blog/what-s-new-in-synapseml-v0-11/ba-p/3804919)

Thank you to all the contributors in the community who made the release possible!

&#x200B;

[What's new in SynapseML v0.11](https://preview.redd.it/9pqj1mowj2wa1.png?width=4125&format=png&auto=webp&s=a358e73760c847a09cc76f2ed17dc58e15aed5ed)"
8,deeplearning,gpt-4,top,2023-10-24 15:34:49,MemGPT Explained!,CShorten,False,0.96,21,17ffmuu,https://www.reddit.com/r/deeplearning/comments/17ffmuu/memgpt_explained/,2,1698161689.0,"Hey everyone! I am SUPER excited to publish a new paper summary video of MemGPT from Packer et al. at UC Berkeley!

MemGPT is a massive step forward in the evolution from naive Retrieval-Augmented Generation (RAG) to creating an OPERATING SYSTEM for LLM applications!

This works by telling the LLM about its limited input window and giving it new ""tools"" / APIs to manage its own memory. For example, the LLM processes the conversation history in a chatbot or the next paragraph in document processing and determines what is important to add to its working context.

The authors design a operating system around this concept complete with events, functions, and of a virtual context management algorithm inspired by operating system concepts such as page replacement. When the LLM determines it needs more context to answer a question, it searches into it's external context (could be recall storage (complete history of events such as dialogue in a chatbot across 4 months), or its archival storage (information such as Wikipedia entries stored in a Vector DB) -- it then parses the search results to determine what is worth adding to its working context.

The authors test MemGPT on chatbots and the experiments from Lost in the Middle, finding that this explicit memory management overcomes the problems of losing relevant information in the middle of search results!

I think there are tons of exciting implications of this work such as the intersection with the Gorilla LLMs (trying to allocate as few tokens as possible in describing a tool to an LLM), as well as this general phenomenon of connecting LLMs to Operating Systems!

Here is my review of the paper in more detail, I hope you find it useful!

[https://www.youtube.com/watch?v=nQmZmFERmrg](https://www.youtube.com/watch?v=nQmZmFERmrg)"
9,deeplearning,gpt-4,top,2023-12-28 16:22:37,Do Large Vision-language Models Understand Charts? We found that the answer is NO!,steeveHuang,False,1.0,18,18sxs1r,https://www.reddit.com/r/deeplearning/comments/18sxs1r/do_large_visionlanguage_models_understand_charts/,2,1703780557.0,"We've just wrapped up a collaborative study with Columbia University and the University of Macau that probes into the capabilities of Large Vision-Language Models (LVLMs) when it comes to understanding and describing charts. The findings are quite startling.

Despite advancements in LVLMs, our research reveals that even the most advanced LVLMs like GPT-4V and Bard fall short. A striking 🚨**81.27%** (321/ 395) 🚨 of the captions they generated contained factual errors, misinterpreting data from charts. This suggests a significant gap in these models' ability to grasp the nuances and relationships between data points in visual representations.

🔍 Explore our findings in detail with the full paper on [Arxiv](https://arxiv.org/abs/2312.10160).

💻: Code and data are also available on [GitHub](https://github.com/khuangaf/CHOCOLATE)

&#x200B;

https://preview.redd.it/448ty01q929c1.png?width=1362&format=png&auto=webp&s=c6ce27262247ce6978ae7ff169f6fc844fda63de"
10,deeplearning,gpt-4,top,2023-09-29 14:02:33,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.91,18,16vch0x,https://www.reddit.com/r/deeplearning/comments/16vch0x/this_week_in_ai_all_the_major_ai_developments_in/,2,1695996153.0,"1. **Meta AI** presents **Emu**, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal.
2. **Meta AI** researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks.
3. **Abacus AI** released a larger 70B version of **Giraffe**. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens\].
4. **Cerebras** and **Opentensor** released Bittensor Language Model, ‘**BTLM-3B-8K**’, a new 3 billion parameter open-source language model with an 8k context length trained on 627B tokens of SlimPajama. It outperforms models trained on hundreds of billions more tokens and achieves comparable performance to open 7B parameter models. The model needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models and is available with an Apache 2.0 license for commercial use.
5. **OpenAI** is rolling out, over the next two weeks, new voice and image capabilities in ChatGPT enabling ChatGPT to understand images, understand speech and speak. The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. .
6. **Mistral AI**, a French startup, released its first 7B-parameter model, **Mistral 7B**, which outperforms all currently available open models up to 13B parameters on all standard English and code benchmarks. Mistral 7B is released in Apache 2.0, making it usable without restrictions anywhere.
7. **Microsoft** has released **AutoGen** \- an open-source framework that enables development of LLM applications using multiple agents that can converse with each other to solve a task. Agents can operate in various modes that employ combinations of LLMs, human inputs and tools.
8. **LAION** released **LeoLM**, the first open and commercially available German foundation language model built on Llama-2
9. Researchers from **Google** and **Cornell University** present and release code for DynIBaR (Neural Dynamic Image-Based Rendering) - a novel approach that generates photorealistic renderings from complex, dynamic videos taken with mobile device cameras, overcoming fundamental limitations of prior methods and enabling new video effects.
10. **Cloudflare** launched **Workers AI** (an AI inference as a service platform), **Vectorize** (a vector Database) and **AI Gateway** with tools to cache, rate limit and observe AI deployments. Llama2 is available on Workers AI.
11. **Amazon** announced the general availability of **Bedrock**, its service that offers a choice of generative AI models from Amazon itself and third-party partners through an API.
12. **Spotify** has launched a pilot program for AI-powered voice translations of podcasts in other languages - in the podcaster’s voic. It uses OpenAI’s newly released voice generation model.
13. **Getty Images** has launched a generative AI image tool, ‘**Generative AI by Getty Images**’, that is ‘commercially‑safe’. It’s powered by Nvidia Picasso, a custom model trained exclusively using Getty’s images library.
14. **Optimus**, Tesla’s humanoid robot, can now sort objects autonomously and do yoga. Its neural network is trained fully end-to-end.
15. **Amazon** will invest up to $4 billion in Anthropic. Developers and engineers will be able to build on top of Anthropic’s models via Amazon Bedrock.
16. **Google Search** indexed shared Bard conversational links into its search results pages. Google says it is working on a fix.

&#x200B;

  
My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
11,deeplearning,gpt-4,top,2023-04-07 10:58:54,Text-to-image Diffusion Models in Generative AI: A Survey,Learningforeverrrrr,False,0.91,15,12ehc2m,https://www.reddit.com/r/deeplearning/comments/12ehc2m/texttoimage_diffusion_models_in_generative_ai_a/,0,1680865134.0,"Diffusion models have become a SOTA generative modeling method for numerous content types, such as images, audio, graph, etc. As the number of articles on diffusion models has grown exponentially over the past few years, there is an increasing need for survey works to summarize them. Recognizing the existence of such works, our team has completed multiple field-specific surveys on diffusion models. We promote our works here and hope they can be helpful to researchers in relative fields: text-to-image diffusion models [\[a survey\]](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey), audio diffusion models [\[a survey\]](https://www.researchgate.net/publication/369477230_A_Survey_on_Audio_Diffusion_Models_Text_To_Speech_Synthesis_and_Enhancement_in_Generative_AI), and graph diffusion models [\[a survey\]](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material) .

In the following, we briefly summarize our survey on text-to-image diffusion models.

[Text-to-image Diffusion Models in Generative AI: A Survey](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey)

As a self-contained work, this survey starts with a brief introduction of how a basic diffusion model works for image synthesis, followed by how condition or guidance improves learning. Based on that, we present a review of state-of-the-art methods on text-conditioned image synthesis, i.e., text-to-image. We further summarize applications beyond text-to-image generation: text-guided creative generation and text-guided image editing. Beyond the progress made so far, we discuss existing challenges and promising future directions.

Moreover, we have also completed two survey works on generative AI (AIGC) [\[a survey\]](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need) and ChatGPT [\[a survey\]](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era), respectively. Interested readers may give it a look."
12,deeplearning,gpt-4,top,2023-11-15 10:30:36,"GPT-4 Turbo: Die Zukunft der Künstlichen Intelligenz, entwickelt von OpenAI",Webglobic_tech,False,0.86,15,17vqtlk,https://webglobic.com/magazine/,0,1700044236.0,
13,deeplearning,gpt-4,top,2022-12-23 14:35:17,How to change career trajectory to NLP engineer,Creative-Milk-8266,False,0.88,13,zth8rl,https://www.reddit.com/r/deeplearning/comments/zth8rl/how_to_change_career_trajectory_to_nlp_engineer/,3,1671806117.0," A little of my background - 5 years experience in data science. Mostly related to prototyping statistical models and optimization problems, bringing them into production. Some experience in building pipeline and orchestration flow with AWS services.

I have basic understanding on Transformers, BERT, GPT. Did my first NLP Kaggle competition the first time recently.

I'd like my next job to be a NLP engineer. How should I prepare myself for it?

Here's some of the items I'm thinking

&#x200B;

1. More hands on projects I can put on resume, including integration with cloud services. Any recommendations on what kinds of projects I should pick?  
 
2. Tryout techniques of speeding up models like distilled model, dynamic shape, quantization. Anything else that would be helpful?  
 
3. Understand lower level of GPU programming knowledges. Not sure if this is helpful for me finding a NLP job. If so, what kind of things I can do to go deeper on this subject. I'm currently taking [Intro to Parallel Programming](https://classroom.udacity.com/courses/cs344) CS344 course on Udemy (highly recommend btw).  
 
4. Grind leetcode :/  
 

Please point out other important directions I missed."
14,deeplearning,gpt-4,top,2023-06-29 19:49:38,"Open Orca, an open sourced replication of Microsofts Orca is in development! Heres the dataset!",Alignment-Lab-AI,False,1.0,12,14mejzk,https://www.reddit.com/r/deeplearning/comments/14mejzk/open_orca_an_open_sourced_replication_of/,2,1688068178.0,"Today we are releasing a dataset that lets open source models learn to think like GPT-4!

We call this Open Orca, as a tribute to the team who has released the Orca paper describing the data collection methods we have attempted to replicate in an open-source manner for the benefit of humanity.

With this data, we expect new open source models to be developed which are smaller, faster, and smarter than ever before because were going to be the ones doing the developing!

[https://huggingface.co/datasets/Open-Orca/OpenOrca](https://huggingface.co/datasets/Open-Orca/OpenOrca)

We'd like to give special recognition to the following contributors for their significant efforts and dedication:

caseus

Eric Hartford

NanoBit

Pankaj

winddude

Rohan

[http://alignmentlab.ai/:](http://alignmentlab.ai/:)

Entropi

neverendingtoast

AtlasUnified

AutoMeta

lightningRalf

NanoBit

caseus

The Orca paper has been replicated to as fine of a degree of precision as a motley crew of ML nerds toiling for weeks could pull off (a very high degree).

We will be releasing trained Orca models as the training currently in progress completes.

The dataset is still in final cleanup, and we will continue with further augmentations beyond the base Orca data in due time.

Right now, we are testing our fifth iteration of Orca on a subset of the final data, and are just about to jump into the final stages!

Many thanks to NanoBit and Caseus, makers of Axolotl \[[https://github.com/OpenAccess-AI-Collective/axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)\] for lending us their expertise on the platform that developed and trained manticore, minotaur, and many others!

If you want to follow along, meet the devs, ask us questions, get involved, or check out our other projects, such as:

Landmark Attention

[https://twitter.com/Yampeleg's](https://twitter.com/Yampeleg's) recently announced context extension method, which outperforms rope (were going to push this one later today)

EDIT: We've been made aware that Eric Hartford, a team member who chose to depart our team yesterday after some internal discussion of our grievances, has made claims to be the sole originator of the Open Orca project and to claim the work as his own. We wish to clarify that this was a team effort from the outset, and he was one of over a dozen data scientists, machine learning engineers, and other specialists who have been involved in this project from the outset.

Eric joined the team with the mutual understanding that we were all to be treated as equals and get our due credit for involvement, as well as say in group decisions.

He made snap decisions on behalf of the team contrary to long term plans, including announcing the project publicly on his blog, and implying that he was the sole originator and project lead.

We attempted to reconcile this internally, but he chose to depart from the team.

As such, we elected to release the data publicly in advance of original plans.

We have appropriately attributed he and all other contributors, as was originally planned.

We thank Eric for his contributions to the project and wish him well on his individual endeavors.

This repo is the original repo from which the entire team had agreed to work out of and publish out of from the outset.

Eric's repo represents his duplication and augmentation of the team's collective effort, initiated after he had chosen to depart the team."
15,deeplearning,gpt-4,top,2023-04-02 12:37:38,[N] Software 3.0 Blog Post Release 🔥,DragonLord9,False,0.76,11,129k24i,https://www.reddit.com/r/deeplearning/comments/129k24i/n_software_30_blog_post_release/,3,1680439058.0,"Hi all, excited to share my blog post on [**Software 3.0**](https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm_campaign=post&utm_medium=web)

https://preview.redd.it/9b4hjkkhugra1.png?width=1500&format=png&auto=webp&s=e341f3ab4c3c8abb206df8daa17428a297ff61e2

The blog post offers an insightful read on the new GPT-powered programming paradigm where the new programming language is simply ""*English*"", as well as recent developments in AI.

The post was originally written before GPT-4 release, and the predictions seem to have held surprisingly well. Knowledge cutoff date 28 Feb 2023.

Please read and share!! Happy to answer any follow-ups here or on DM 😊

Tweet: [https://twitter.com/DivGarg9/status/1642229948185280521?s=20](https://twitter.com/DivGarg9/status/1642229948185280521?s=20)

Blog: [https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm\_campaign=post&utm\_medium=web](https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm_campaign=post&utm_medium=web)"
16,deeplearning,gpt-4,top,2023-11-08 15:37:08,Start with Large Language Models (LLMs) in 2023,OnlyProggingForFun,False,0.71,10,17qo9lt,https://www.reddit.com/r/deeplearning/comments/17qo9lt/start_with_large_language_models_llms_in_2023/,11,1699457828.0,"This is a complete guide to start and improve your LLM skills in 2023 without an advanced background in the field and stay up-to-date with the latest news and state-of-the-art techniques!

The complete article: https://www.louisbouchard.ai/from-zero-to-hero-with-llms/

All the links on GitHub: https://github.com/louisfb01/start-llms 

Artificial is a fantastic field, and so are language models like GPT-4, Claude..., but it goes extremely fast. Don't miss out on the most important and exciting news by joining great communities, people, newsletters, and more you can all find in this guide!

This guide is intended for anyone with a small background in programming and machine learning. Simple python knowledge is enough to get you started. There is no specific order to follow, but a classic path would be from top to bottom. If you don't like reading books, skip it, if you don't want to follow an online course, you can skip it as well. There is not a single way to become a ""LLM expert"" and with motivation, you can absolutely achieve it."
17,deeplearning,gpt-4,top,2023-10-26 17:59:49,Long text summarization tool how-to (700+ pages),Old_Swan8945,False,0.92,10,17h2fbk,https://www.reddit.com/r/deeplearning/comments/17h2fbk/long_text_summarization_tool_howto_700_pages/,8,1698343189.0,"Hey all I've seen a bunch of posts about summarization of long texts and seems like there's been a lot of challenges, so wanted to spread some knowledge out there about some things I've discovered as I launched my tool here ([summarize-article.co](https://summarize-article.co)) (longest text was a psych book from one of my users at 700+ pages).

The most basic problem in the summarization process is the GPT context window length, so the basic strategy I follow is the following:

1. Chunk the text into chunks that fit inside the context window
2. Recursively summarize the summaries until it becomes manageable
3. Use a long context-window model to generate the final summary using a prompt that takes the recursively-generated summaries and re-restructures the output
4. Additional prompt magic to optimize the outputs (DM me for more details :D)

Anyway, would appreciate any feedback on the results or anything you think could be improved, otherwise feel free to check it out or msg me if you want to learn more about how it works!"
18,deeplearning,gpt-4,top,2023-04-07 10:28:52,"Series of Surveys on ChatGPT, Generative AI (AIGC), and Diffusion Models",Learningforeverrrrr,False,0.86,9,12egmab,https://www.reddit.com/r/deeplearning/comments/12egmab/series_of_surveys_on_chatgpt_generative_ai_aigc/,0,1680863332.0,"* **A survey on ChatGPT:** [**One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era**](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era)
* **A survey on Generative AI (AIGC):** [**A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?**](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need)
* **A survey on Text-to-image diffusion models:** [**Text-to-image Diffusion Models in Generative AI: A Survey**](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey)
* **A survey on Audio diffusion models:** [**A Survey on Audio Diffusion Models: Text To Speech Synthesis and Enhancement in Generative AI**](https://www.researchgate.net/publication/369477230_A_Survey_on_Audio_Diffusion_Models_Text_To_Speech_Synthesis_and_Enhancement_in_Generative_AI)
* **A survey on Graph diffusion models:** [**A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material**](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material)

**ChatGPT goes viral.** Launched by OpenAI on November 30, 2022, ChatGPT has attracted unprecedented attention due to its powerful abilities all over the world.  It took only 5 days \[1\] and 2 months \[2\] for ChatGPT to have 1 million users and 100 million monthly users after launch, making it the fastest-growing consumer application in history. ChatGPT can be seen as the milestone for the GPT family to go viral. In academia, ChatGPT has also inspired a large number of works discussing its applications in multiple fields, with **more than 500 papers within four months** after release and **the number is still increasing rapidly.**  This brings a huge challenge for a researcher who hopes to have an overview of ChatGPT applications or hopes to start his or her journey with ChatGPT in their own field.  **To help more people keep up with the latest progress of the GPT family,** we’re glad to share a self-contained survey that not only summarizes **the recent applications** of ChatGPT and other GPT variants like GPT-4, but also introduces the **underlying techniques** and **challenges.** Please refer to the following link for the paper: [One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era).

&#x200B;

**From ChatGPT to Generative AI.**  One highlighting ability of the GPT family is that it can generate natural languages, which falls into the area of Generative AI. Apart from text, Generative AI can also generate content in other modalities, such as image, audio, and graph. More excitingly, Generative AI is able to convert data from one modality to another one, such as the text-to-image task (generating images from text). **To help readers have a better overview of Generative AI,** we provide a complete survey on underlying **techniques,** summary and development of **typical tasks in academia**, and also **industrial applications.** Please refer to the following link for the paper.  [A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need)

&#x200B;

**From Generative AI to Diffusion Models.** The prosperity of a field is always driven by the development of technology, and so is Generative AI.  Different from ChatGPT which generates text based on the transformer, **diffuson models** have greatly accelerated the development of other fields in Generative AI, such as image synthesis.  Although we provide a summary of diffusion models and typical tasks in the Generative AI survey, we cannot include detailed discussions due to paper length limitations. **For those who are interested in the technical details of diffusion models and the recent progress of their applications in Generative AI,** we provide three self-contained surveys on **how diffusion models are applied in three typical areas: Text-to-image diffusion models** (also includes related tasks such as image editing)**, Audio diffusion models** (including text to speech synthesis and enhancement), and **Graph diffusion models** (including molecule, protein and material areas). Please refer to the following links for the paper.

* [Text-to-image Diffusion Models in Generative AI: A Survey](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey)
* [A Survey on Audio Diffusion Models: Text To Speech Synthesis and Enhancement in Generative AI](https://www.researchgate.net/publication/369477230_A_Survey_on_Audio_Diffusion_Models_Text_To_Speech_Synthesis_and_Enhancement_in_Generative_AI)
* [A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material)

We hope our survey series will help people for a better understanding of ChatGPT and Generative AI, and we will update the survey regularly to include the latest progress. Please refer to the personal pages of the authors for the latest updates on surveys. If you have any suggestions or problems, please feel free to contact us.

\[1\] Greg Brockman, co-founder of OpenAI, [https://twitter.com/gdb/status/1599683104142430208?lang=en](https://twitter.com/gdb/status/1599683104142430208?lang=en)

\[2\] Reuters, [https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/](https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/)"
19,deeplearning,gpt-4,top,2020-06-10 20:36:33,"GPT-3: The $4,600,000 Language model",mippie_moe,False,0.85,9,h0jm54,https://lambdalabs.com/blog/demystifying-gpt-3/,4,1591821393.0,
20,deeplearning,gpt-4,top,2023-03-11 00:38:10,Generate READMEs Using ChatGPT,tomd_96,False,0.91,8,11o5zyl,https://www.reddit.com/r/deeplearning/comments/11o5zyl/generate_readmes_using_chatgpt/,0,1678495090.0,"&#x200B;

https://i.redd.it/k375our2a0na1.gif

&#x200B;

You can use this program I wrote to generate readmes: [https://github.com/tom-doerr/codex-readme](https://github.com/tom-doerr/codex-readme)

&#x200B;

It's far from perfect, but I now added ChatGPT and it is surprisingly good at inferring what the project is about. It often generates interesting usage examples and explains the available command line options.

&#x200B;

You probably won't yet use this for larger projects, but I think this can make sense for small projects or single scripts. Many small scripts are very useful but might never be published because of the work that is required to document and explain it. Using this AI might assist you with that.

&#x200B;

Reportedly GPT-4 is coming out next week, which probably would make it even better.

&#x200B;

What do you think?"
21,deeplearning,gpt-4,top,2021-08-19 07:03:53,Dual 3090 vs A6000 + Intel vs AMD?,xKaiz3n,False,0.77,7,p79uhm,https://www.reddit.com/r/deeplearning/comments/p79uhm/dual_3090_vs_a6000_intel_vs_amd/,21,1629356633.0,"Hello,

I've been asked to spec out a machine for a range of DL tasks (inc. GPT-3/4 & classification etc.). Looking at prices here (AUS) it seems the price for 2x 3090s (AUD$3000 - 4000) is around the same price as 1x A6000 (AUD$7500 - 8500). 

I've gone into this with a fairly rudimentary understanding of both hardware at this level and deep learning (read: I'm a student & interning), so apologies if I've said something particularly silly.  I'm also looking to see if there are any recommendations for CPU's:

\- do DL packages have a preference for AMD vs Intel like they do with GPU's?

\- which CPU would you guys choose that won't bottleneck the GPUs?

&#x200B;

Thank you!"
22,deeplearning,gpt-4,top,2023-03-21 02:06:28,CoDev- A GPT 4.0 Virtual Developer To Generate Apps,aisaint,False,0.69,6,11x3p2u,https://www.reddit.com/r/deeplearning/comments/11x3p2u/codev_a_gpt_40_virtual_developer_to_generate_apps/,5,1679364388.0,"&#x200B;

&#x200B;

CoDev is a GPT 4.0 virtual developer prompt to help you create and refine boilerplates/apps. You can get the prompt from my GitHub link below, paste it in a new Chat session, and issue the commands (see How To Use CoDev). In this article, we will use CoDev to create a React/Typescript/MUI dashboard boiler plate

[https://medium.com/@etherlegend/codev-a-gpt-4-0-virtual-developer-to-build-app-boilerplates-34a431e779c7](https://medium.com/@etherlegend/codev-a-gpt-4-0-virtual-developer-to-build-app-boilerplates-34a431e779c7)"
23,deeplearning,gpt-4,top,2023-12-28 21:36:23,"The best current models (Dolphin, Mixtral, Solar, Noromaid) and where to try them",Horror_Echo6243,False,0.88,6,18t59yu,https://www.reddit.com/r/deeplearning/comments/18t59yu/the_best_current_models_dolphin_mixtral_solar/,5,1703799383.0," 

I just saw a lot of people talking about this models so if you want to test them i found this websites that have all of them

\- [infermatic.ai](https://infermatic.ai/) (all of them)

\- [https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0](https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0) (for solar)

\- [https://huggingface.co/chat](https://huggingface.co/chat) (for mixtral)

Let me know if you find more, I'd like to know

And heres a little resume if you don't know what each model is for

Dolphin : An uncensored model derived from an open-source dataset, it uses instructions from FLANv2 enhanced with GPT-4 and GPT-3.5 completions​​.

Mixtral : An advanced text generation model using a Mix of Experts architecture

Solar : domain specialization and optimization. It's recognized for its high performance and efficiency

Noromaid: Storywriting and roleplay"
24,deeplearning,gpt-4,top,2022-08-14 10:58:04,OneFlow v0.8.0 Came Out!,Just0by,False,1.0,5,wo3o9l,https://www.reddit.com/r/deeplearning/comments/wo3o9l/oneflow_v080_came_out/,1,1660474684.0,"Hi all,

We are thrilled to announce the new release of [**OneFlow**](https://github.com/Oneflow-Inc/oneflow)**, which is a deep learning framework designed to be user-friendly, scalable and efficient.** OneFlow v0.8.0 update contains 523 commits. For the full changlog, please check out: [**https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.8.0**](https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.8.0).  


**Paper:** [https://arxiv.org/abs/2110.15032](https://arxiv.org/abs/2110.15032);  
**Code:** [https://github.com/Oneflow-Inc/oneflow](https://github.com/Oneflow-Inc/oneflow)

Welcome to install OneFlow v0.8.0 for a new user experience. Your feedbacks will be much appreciated!

Highlights and optimizations in this release:

**1. PyTorch API compatibility**

OneFlow v0.8.0 provides more and better PyTorch compatible APIs. In v0.8.0, a series of new features and interfaces that are compatible with PyTorch 1.10.0 are in place, including 68 new APIs that are aligned with PyTorch; 84 bugs are fixed to ensure better compatibility between operators and interfaces, allowing users to transfer more PyTorch models to OneFlow with just one click.

&#x200B;

**2. Wider support of global operators**

All operators support Global Tensor more widely and efficiently. Fixed 28 bugs related to Global Tensor and added 180 Global operator unit tests, making the development of distributed models with Global Tensor faster and easier.

&#x200B;

**3. Better performance**

The advanced features of Graph have been improved for better performance:

In addition to the original ZeRO-DP, ZeRO can be used in parallel with MP, 2-D, and 3-D to further reduce memory overhead.

Added a new pipeline parallelism API for Graph to simplify the configuration for pipeline parallelism and accelerate training when using pipeline parallelism and 3-D parallelism.

Added debugging features in multiple dimensions, including logical graphs, light plan physical graphs, memory analysis, and Python stack information, to further improve efficiency of Graph.debug.

The combination of OneFlow v0.8.0 and LiBai v0.2.0 enables higher computation speeds of GPT and BERT under 3-D parallelism on multiple dimensions, surpassing those of Megatron-LM with the same configurations. (For more details, see: [https://libai.readthedocs.io/en/latest/tutorials/get\_started/Benchmark.html](https://libai.readthedocs.io/en/latest/tutorials/get_started/Benchmark.html)).

&#x200B;

**4. OneEmbedding component**

OneEmbedding is an extended component specifically designed for large-scale recommender systems. It boasts excellent performance, extensibility, and flexibility.

API Documentation: [https://docs.oneflow.org/en/master/cookies/one\_embedding.html](https://docs.oneflow.org/en/master/cookies/one_embedding.html)

&#x200B;

**5. Multi-Device adaptation**

OneFlow v0.8.0 provides a neat, efficient, and easily extensible hardware abstraction layer EP (Execution Provider) to adapt to different hardware. With the introduction of the hardware abstraction layer, no modifications are needed for any module of the framework to adapt to new hardware devices, regardless of the implementation details of any underlying hardware or framework.

To make the new hardware devices work, users only need to implement a series of interfaces based on the protocols of the hardware abstraction interfaces and the status quo of the hardware devices.

EP also defines a set of basic computing interface primitives, allowing the reimplementation of kernels. Primitives provide interfaces that are more flexible than the runtime interfaces provided by EP. Different interfaces are independent of each other, and each interface represents a kind of computing capability that can be provided by a certain hardware device.

**6. Debugging tool stack**

New debug tools: OneFlow-Profiler and AutoProf.

OneFlow-Profiler is a tool used to collect performance information during framework execution. It can keep records of the execution time of operators and system components, the allocation of memory, and the corresponding input and parameters of operators. All this information helps developers find out the main source of overhead in framework execution and thus implement targeted optimization.

AutoProf is a framework for testing the performance of OneFlow and PyTorch operators. It provides an elegant and efficient method to detect the alignment between OneFlow APIs and PyTorch APIs, allowing users to conveniently compare the performance of OneFlow APIs and PyTorch APIs.

**7. Error message**

Improved error message with more details. Refactored exception handling.

&#x200B;

**8. API documentation**

Made over 20 revisions to the OneFlow API documentation, restructured the documentation based on features, and added further elaboration of modules and environment variables including OneFlow oneflow.nn.graph, oneflow.embedding, and oneflow.autograd, in addition to the general operator APIs."
25,deeplearning,gpt-4,top,2023-07-25 13:44:39,Luca Beurer-Kellner on LMQL - Weaviate Podcast #59!,CShorten,False,1.0,6,1598yyk,https://www.reddit.com/r/deeplearning/comments/1598yyk/luca_beurerkellner_on_lmql_weaviate_podcast_59/,0,1690292679.0,"Hey everyone! I am beyond excited to publish our 59th Weaviate podcast with Luca Beurer-Kellner, the lead author and creator of LMQL!

LMQL is a *programming language* for LLMs, a really interesting and unique direction amongst the emerging development of LLM frameworks and tooling. I was really blown away by the elegance of the syntax, and I highly recommend checking out the LMQL playground. Not only is the LMQL playground a great way to learn LMQL particularly, it is one of the world's best visualizations of complex LLM execution, providing an interactive sandbox to explore!

We discussed many topics on the podcast from Luca's research background in Programming Languages and how that has shaped his perspectives on Constrained Sampling, the analog of LLM output nil pointer exceptions, and the effort to tame this chaos with LMQL! We also discussed how this fits into existing LLM frameworks such as our friends at LlamaIndex, LangChain, Haystack, MS Semantic Kernel, Jina AI, and others! We also discussed tool use with the Gorilla large language models and the general perspective of a master model such as GPT-4 that routes inferences to cheaper specialized models!

Finally we concluded with discussions on future directions! Luca really opened my eyes about the future of composable models and RETRO-style RAG architectures, can't wait to see that develop further!

I really hope you enjoy the podcast, as always I am more than happy to answer any questions or discuss any ideas you have related to the content in the podcast!  

https://www.youtube.com/watch?v=cuWLPHDAQ5g"
26,deeplearning,gpt-4,top,2023-05-31 13:38:15,New Weaviate Podcast - Kapa AI!,CShorten,False,0.72,3,13wmkpt,https://www.reddit.com/r/deeplearning/comments/13wmkpt/new_weaviate_podcast_kapa_ai/,0,1685540295.0,"Hey everyone, I am SUPER excited to publish our 50th Weaviate Podcast with Emil and Finn from Kapa AI!

Kapa AI is one of the leading companies in taking code documentation and community question answering data, for software companies such as Weaviate, and building these Retrieval-Augmented LLM systems. I can personally vouch for the high quality of Kapa, it is an insanely productive tool for Weaviate development!  

In the podcast, we cover the A-Z on how these systems are built: 

• How long does it take to get a companies' Docs etc. into Kapa? 

• How do companies think about ingesting their community support tickets into these systems? E.g. Slack / Discourse / Forum ""whitelisting"" and so on. 

• How do Emil and Finn think about text chunking and data cleaning? 

• What is the impact of the latest trends in LLMs - status of Hallucination, Long Input Lengths (e.g. GPT-4, MosaicML MPT, Anthropic Claude), Fine-Tuning LLMs with things like LoRA? 

I think Emil and Finn have some really interesting perspectives on this stuff. Always nice to get a mix of academic perspectives, as well as people like Emil and Finn who are really building these systems, selling them to companies, and managing the cost / performance tradeoffs.

https://www.youtube.com/watch?v=cjAhve\_DopY"
27,deeplearning,gpt-4,top,2023-12-06 21:16:44,Platform with algorithm that creates posts,gate-app,False,0.72,3,18cehg4,https://www.reddit.com/r/deeplearning/comments/18cehg4/platform_with_algorithm_that_creates_posts/,7,1701897404.0,"So i made this thing it'll keep growing and growing.

i published my [notes](https://ablaze-mine-be9.notion.site/Algorithm-566bcebb669f49c2aedb63ffd04df3bc?pvs=4) if someones interested im looking for more serious people who believe in this, also for opinions of credible people.

&#x200B;

&#x200B;

one if the ideas:

Tiktok has a huge algorithm but the only thing it does is recommends user created content to people.  what it has is millions of users metrics and how they interact with the content which is what makes its algorithms good.  there can be a platform that collects all that useful metrics too, but uses them not only for recommender model, but also for post creation.  you can take a llm (gpt) today and make it generate posts, then collect millions of peoples interactions and how they respond to them, all the metrics and train the post creator model with it. you can easily make an actual quality content creation bot thats better than any copywriter and understands the relevant details better than anyone.  the reason the other platforms do so well is because of the insane amounts of data they monitor.  the post creation is 2 parts:  one that finds relevant stuff on the internet, tracks events, and just figures out best content to post about.  the other one is llm model that takes any piece of information and converts it into a post with title and all the other fields  both can be trained with data from users.  i am working on this idea further theres a demo with a feed of posts and a chatbot [https://gate-app.com/](https://gate-app.com/) [https://gate-app.com/posts/170145283354301509](https://gate-app.com/posts/170145283354301509) "
28,deeplearning,gpt-4,top,2023-11-15 18:18:23,Exploring the Frontiers of AI with Taskade: Introducing AI Agents for Deep Learning Enthusiasts 🚀,taskade,False,0.76,4,17vzwl5,https://www.reddit.com/r/deeplearning/comments/17vzwl5/exploring_the_frontiers_of_ai_with_taskade/,4,1700072303.0," 
Hey r/deeplearning,

I'm John from [Taskade](https://taskade.com), and I'm thrilled to introduce you to our latest endeavor in the realm of AI: Taskade AI Agents. This feature is a blend of practicality and deep learning innovation, and we're eager to dive into discussions with enthusiasts like you.

**Taskade AI Agents - What's Under the Hood?**

- Taskade AI Agents is all about creating, training, and deploying custom AI agents to automate and enhance productivity tasks.
- Powered by GPT-4 Turbo, it's designed for those who appreciate the intricacies of AI and deep learning technologies.

**Why It Matters for Deep Learning:**

- Our AI Agents are more than just productivity tools; they're a testament to the advancements in neural networks and AI capabilities.
- We're pushing the boundaries of how AI can be utilized in everyday task management and collaboration environments.

**We're Keen on Your Insights:**

- As deep learning enthusiasts, your perspectives on AI implementation, performance, and potential improvements are invaluable.
- How do you see AI Agents like ours fitting into the broader landscape of AI and deep learning?
- We're especially interested in your thoughts on our use of GPT-4 Turbo and how it could evolve.

**Join the Conversation:**

- Learn more about Taskade AI Agents on our [Product Hunt page](https://www.producthunt.com/posts/taskade-ai-agents).
- Dive deeper into our feature on our [Blog](https://www.taskade.com/blog/custom-ai-agents-gpts/).
- Try it out and experiment with it [here](https://www.taskade.com/ai).

Your feedback, critiques, and ideas are not just welcomed, they're needed. Help us understand the impact of Taskade AI Agents from a deep learning perspective and how we can continue to innovate in this space.

Looking forward to some insightful discussions!

Cheers,
John & the /r/Taskade Team 🤖✨"
29,deeplearning,gpt-4,top,2023-04-05 15:23:45,Lifeline - Arxiv Conversational Search Assistant Demo (using ChatGPT),CommercialLynx7233,False,0.67,3,12cnu4c,https://www.reddit.com/r/deeplearning/comments/12cnu4c/lifeline_arxiv_conversational_search_assistant/,1,1680708225.0,"Hey guys,

I wanted to share a quick side project I built called [Lifeline](https://www.lifeline.dev/). [Lifeline](https://www.lifeline.dev/) is a search assistant on Arxiv Computer Science papers, leveraging ChatGPT. You can use it to find papers on specific topics, get summaries, ask questions about particular CS topics, find datasets or get similar papers. **Essentially, think of it as a conversational assistant that has knowledge about every CS paper published on Arxiv on or after 2022.**

Here are some sample questions: (Here's a [video](https://www.youtube.com/watch?v=VpFRkbKprLE) where I go through some examples)

* Are there any papers examining consciousness in recent AI systems, specifically large language models?
* What is the difference between chain of thought and augmenting language models with API calls?
* Summarize the new GPT-4 model
* Is GPT-4 better than lawyers on the bar exam? (lol...)
* What are some recent approaches for 3D object construction, from natural language?

If you want to contribute or have any questions, email me at: [rahul@lifeline.dev](mailto:rahul@lifeline.dev) .

Thank you!"
30,deeplearning,gpt-4,top,2023-09-28 13:34:24,First Impressions with GPT-4V(ision),zerojames_,False,0.75,4,16ug8gc,https://www.reddit.com/r/deeplearning/comments/16ug8gc/first_impressions_with_gpt4vision/,0,1695908064.0,"My colleague Piotr and I have been testing GPT-4V(ision) over the last day. We wrote up our findings, covering how GPT-4V performs on:

1. Visual question answering (VQA) across a range of domains (locations, movies, plants)
2. OCR
3. Math OCR
4. Object detection
5. And more

TL;DR: GPT-4V performed well for VQA and document OCR but struggled with OCR on real-world images and object detection (where we asked for bounding boxes).

[https://blog.roboflow.com/gpt-4-vision/](https://blog.roboflow.com/gpt-4-vision/)

I would love to hear what other people have found working with GPT-4V."
31,deeplearning,gpt-4,top,2020-06-30 19:19:50,"Training a GPT-2 from scratch in Greek-text, results in a low perplexity score of 7 after 15 epochs. Is it normal that score?",ni_klaras,False,0.83,4,hiu5eu,https://www.reddit.com/r/deeplearning/comments/hiu5eu/training_a_gpt2_from_scratch_in_greektext_results/,0,1593544790.0,"I try to train a GPT-2 from scratch in Greek with an older version of run\_language\_modeling.py ([https://github.com/huggingface/transformers/tree/master/examples/language-modeling](https://github.com/huggingface/transformers/tree/master/examples/language-modeling)) script from *HuggingFace* repo, but I get a low perplexity score of 7 after 15 epochs.

My data for train is about 4.6Gb and is constructed as 5 sentences per line. The data for the evaluation is about 450Mb constructed with the same way. Use of BPE for the encoding with a vocab of 22000 merges.

The loss and the evaluation loss seems to move normal . Even when i test it in the end for generation seems normal.

But the perplexity score is a question..."
32,deeplearning,gpt-4,top,2023-07-31 17:01:30,Where can I keep on top of LLM developments?,gonidphoe7,False,0.62,3,15elov0,https://www.reddit.com/r/deeplearning/comments/15elov0/where_can_i_keep_on_top_of_llm_developments/,3,1690822890.0,"I'm currently attempting to broaden my knowledge of AI and ML, particularly in relation to large language models. My understanding so far is that a significant limitation of these models is their restricted context window, which appears to hinder their ability to maintain continuity of information and reason effectively about complex topics. I see models like GPT-4, Anthropic's Claude, and Mosaic ML implementing larger windows (currently 32k, 100k and 82k tokens respectively).

Can anyone confirm whether my comprehension of the context window is accurate? If not, could you explain the primary challenges that impede the reasoning and problem-solving abilities of LLMs? Additionally, what are the proposed solutions currently being explored to overcome these challenges? Finally, could anyone recommend the best way to stay on top of developments in the LLM and AI agent space?"
33,deeplearning,gpt-4,top,2024-01-01 05:48:19,"VerificationGPT (open-source verification for GPT-4 using Brave Search, arXiv, and other APIs)",contextfund,False,1.0,2,18vq5vb,/r/contextfund/comments/18vp9hv/verificationgpt/,0,1704088099.0,
34,deeplearning,gpt-4,top,2023-12-06 02:31:58,best current form of text generation?,ythug,False,0.75,2,18btl0p,https://www.reddit.com/r/deeplearning/comments/18btl0p/best_current_form_of_text_generation/,2,1701829918.0,"I had a project back in 2021 where I trained an RNN on my own tweets and then had it generate tweets for me.

Haven't kept up to date with NN since and am wondering what is best form of text generation out there currently.

this account (https://twitter.com/DeepLeffen), intrigued me. Says it is trained on gpt-4. I was aware you could train with your own data but it didnt cross my mind."
35,deeplearning,gpt-4,top,2023-12-17 22:15:54,Any idea of GPT-4 Vision architecture?,AfraidAd4094,False,0.67,2,18kstjs,https://www.reddit.com/r/deeplearning/comments/18kstjs/any_idea_of_gpt4_vision_architecture/,1,1702851354.0,"Is it a big Vision Transformer, or maybe extra feature engineering step to adapt images as an input gpt-4? Like transforming an image to a vector embedding of same dimensions as text input  


 "
36,deeplearning,gpt-4,top,2023-03-18 10:40:15,"Need some advice for my idea of ""Sketch to design"" project",Haghiri75,False,1.0,2,11ukow0,https://www.reddit.com/r/deeplearning/comments/11ukow0/need_some_advice_for_my_idea_of_sketch_to_design/,1,1679136015.0,"*I originally asked this question* [*here on stackoverflow*](https://stackoverflow.com/questions/75775112/need-some-advice-for-my-idea-of-sketch-to-design-project)

I have an idea of a *sketch to design* program with deep learning and computer vision. I saw the very same concept before and I believe GPT-4 is capable of doing something similar. First, I have to say that I am familiar with the computer vision procedure. I did it [before](https://haghiri75.com/en/analyzing-components-of-an-electric-circuit-with-yolov5/) and I know using YOLO algorithms might be a good idea.

Also, I have no problems developing a ""Sketch to code"" program since I can pipe my results to another AI or code generator. But I also found [Uizard](http://uizard.io) which can turn your hand-drawn sketches into ""Design"".

It made some questions in my mind which are the following:

1. Is there any language for design? Or it's just XML, HTML or SVG coded file?
2. Is there any code/design generator which is capable of turning a simple design document (like *a page with a navbar*) to HTML or SVG? and **open source** of course!

I will be thankful for your helps and comments."
37,deeplearning,gpt-4,top,2023-10-11 12:38:04,Weird loss behaviour with higher learning rate - LLM training,thelibrarian101,False,1.0,2,175d148,https://www.reddit.com/r/deeplearning/comments/175d148/weird_loss_behaviour_with_higher_learning_rate/,0,1697027884.0,"I'm training a large language model right now with 360M parameters. Before committing to a full run, I am trying different learning rates (with higher / lower batch sizes respectively).

I am having a hard time understanding the pattern of the 1e-4 run (red). Do you guys know what's going on?  
My plan was to go with the largest batch size possible to find better gradient approximation and hopefully converge towards a ""better"" optimum? I know GPT-2 (about the same parameter count) used 6e-4.

Config:  
lr: 1e-6, batch size: 8  
lr: 1e-5: batch size: 80  
lr: 1e-4: batch size: 800

https://preview.redd.it/fyhguv4biktb1.png?width=601&format=png&auto=webp&s=feb55c7eedcb3129029d14d36b792475b58e7b7c"
38,deeplearning,gpt-4,top,2023-10-04 15:06:32,Custom LLM,Relative_Winner_4588,False,1.0,2,16zpnjz,https://www.reddit.com/r/deeplearning/comments/16zpnjz/custom_llm/,0,1696431992.0,"
I'm eager to develop a Large Language Model (LLM) that emulates ChatGPT, tailored precisely to my specific dataset. While I'm aware of existing models like Private-GPT and Gpt4all, my ultimate goal is to either create a custom LLM from scratch or fine-tune a pre-existing model like BERT or GPT-7B to meet my unique requirements.

I've been closely following Andrej Karpathy's instructive lecture on building GPT-like models. However, I've noticed that the model only generated text akin to Shakespearean prose in a continuous loop instead of answering questions. I'm striving to develop an LLM that excels at answering questions based on the data I provide.

The core objectives I'm pursuing encompass:
1. Effective data preparation tailored for question-answering tasks.
2. The strategic selection of a pre-trained model, such as BERT or GPT-7B.
3. Rigorous performance evaluation, employing pertinent metrics.
4. The creation of an efficient inference system that facilitates question input and response generation.

Please guide me for this objectives or provide me some resources for the same.

DM me if you want to talk in detail."
39,deeplearning,gpt-4,top,2023-04-05 13:21:51,"New Weaviate Podcast (#42) - ChatGPT Plugin Marketplace, Alpaca Models, Semantic Search on S3, and more!",CShorten,False,0.76,2,12ck7ae,https://www.reddit.com/r/deeplearning/comments/12ck7ae/new_weaviate_podcast_42_chatgpt_plugin/,0,1680700911.0," I am beyond excited to share our latest Weaviate Podcast with Ethan Steininger! Ethan is the founder of Mixpeek and creator of Collie.ai!

Ethan began by explaining how he came into search through integrating MongoDB with the Lucene inverted index. Ethan continued explaining how his background in Sales Engineering helped him to see the recurring problems businesses are facing when trying to utilize the latest LLM and Vector Database technologies to solve their problems.

We then continued to take a tour of all sorts of topics in the AI Landscape from the impact of the ChatGPT Plugin Marketplace / New App Store for AI to the Stanford Alpaca models, the impact of LLMs for coding productivity and many more, even ending with Ethan's advice on stress management by getting into nature and our thoughts on the existential fear technologies like GPT-4 inspire in many and the implications of it on society.

I hope you enjoy the podcast, please let us know what you think!

[https://www.youtube.com/watch?v=EDPk1umuge0](https://www.youtube.com/watch?v=EDPk1umuge0)"
40,deeplearning,gpt-4,top,2023-04-07 08:41:41,A survey on graph diffusion models,Learningforeverrrrr,False,1.0,2,12eejpe,https://www.reddit.com/r/deeplearning/comments/12eejpe/a_survey_on_graph_diffusion_models/,0,1680856901.0,"Diffusion models have become a SOTA generative modeling method for numerous content types, such as images, audio, graph, etc. As the number of articles on diffusion models has grown exponentially over the past few years, there is an increasing need for survey works to summarize them. Recognizing the existence of such works, our team has completed multiple field-specific surveys on diffusion models. We promote our works here and hope they can be helpful to researchers in relative fields: text-to-image diffusion models [\[a survey\]](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey), audio diffusion models [\[a survey\]](https://www.researchgate.net/publication/369477230_A_Survey_on_Audio_Diffusion_Models_Text_To_Speech_Synthesis_and_Enhancement_in_Generative_AI), and graph diffusion models [\[a survey\]](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material) .

In the following, we briefly summarize our survey work on graph diffusion models.

[https://www.researchgate.net/publication/369716257\_A\_Survey\_on\_Graph\_Diffusion\_Models\_Generative\_AI\_in\_Science\_for\_Molecule\_Protein\_and\_Material](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material)

We start with a summary of the progress of graph generation before diffusion models. The diffusion models are then concisely presented and graph generation is discussed in depth from a structural and application perspective. Moreover,  the currently popular evaluation datasets and metrics are covered. Finally, we summarize the challenges and research questions still facing the research community. This survey work might be a useful guidebook for researchers who are interested in exploring the potential of diffusion models for graph generation and related tasks.

Moreover, we have also completed two survey works on generative AI (AIGC) [\[a survey\]](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need) and ChatGPT [\[a survey\]](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era), respectively. Interested readers may give it a look."
41,deeplearning,gpt-4,top,2024-02-06 16:30:31,XMC.dspy with Karel D'Oosterlinck - Weaviate Podcast #87!,CShorten,False,1.0,2,1akdue4,https://www.reddit.com/r/deeplearning/comments/1akdue4/xmcdspy_with_karel_doosterlinck_weaviate_podcast/,0,1707237031.0,"Hey everyone! I am BEYOND EXCITED to publish our 87th Weaviate Podcast with Karel D’Oosterlinck from the University of Ghent and Stanford NLP!

This podcast was simply amazing, I can't thank Karel enough for how much he taught me about DSPy, how to use it for Extreme Multi-Label Classification (XMC), and the applications of XMC in Biomedical NLP, Recommendation, Job Listings, and more. I am beyond grateful to have the opportunity to share this knowledge in the Weaviate podcast!

The podcast begins with an overview of Extreme Multi-Label Classification. How in the world do we prompt LLMs to categorize inputs into thousands of classes?!

To solve this, Karel has developed a novel Infer-Retrieve-Rank (IReRa) DSPy program. Infer first takes the input and outputs coarse labels for it. These coarse labels are then mapped to the thousands of classes (typically managed in ontologies) with the retrieval system and... you guessed it, Vector Embeddings! The Rank LLM component then takes the classes from the vector search and sorts them by relevance to the query.

Karel then took me through the details of the DSPy compiler! There is just so much opportunity with this from understanding how we tweak the descriptions of tasks we give to our language models, to populating the prompt with in-context learning examples. We discussed all sorts of things from model compression (e.g. can we prompt Mistral or Llama 7b to rival the performance of GPT-4 or Gemini Ultra at a *particular* task in an LLM pipeline, such as re-ranking or query writing?), diving into the latest on Teacher-Student optimization, input-dependent prompting, and so much more! We then concluded the podcast by discussing IReRa's applications for Recommendation Systems and what lead Karel to Biomedical NLP! Thanks again Karel, I learned so much from this one!

YouTube: [https://www.youtube.com/watch?v=\_ye26\_8XPcs](https://www.youtube.com/watch?v=_ye26_8XPcs)

Spotify: [https://podcasters.spotify.com/pod/show/weaviate/episodes/XMC-dspy-with-Karel-DOosterlinck---Weaviate-Podcast-87-e2fehtk](https://podcasters.spotify.com/pod/show/weaviate/episodes/XMC-dspy-with-Karel-DOosterlinck---Weaviate-Podcast-87-e2fehtk)"
42,deeplearning,gpt-4,top,2023-05-28 17:56:31,Essentials of Multi-modal/Visual-Language models (A video),AvvYaa,False,0.67,1,13u6ptq,https://www.reddit.com/r/deeplearning/comments/13u6ptq/essentials_of_multimodalvisuallanguage_models_a/,0,1685296591.0,"Hello people! I just uploaded a video on my Youtube covering all the major techniques and challenges for training multi-modal models that can combine multiple input sources like images, text, audio, etc to perform amazing cross-modal tasks like text-image retrieval, multimodal vector arithmetic, visual question answering, and language modelling. 

I thought it was a good time to make a video about this topic since more and more recent LLMs are moving away from text-only into visual-language domains (GPT-4, PaLM-2, etc). So in the video I cover as much as I can to provide some intuition about this area - right from basics like contrastive learning (CLIP, ImageBind), all the way to Generative language models (like Flamingo).

&#x200B;

Here is a link to the video:  
 [https://youtu.be/-llkMpNH160](https://youtu.be/-llkMpNH160)

If the above doesn’t work, maybe try this:

[https://m.youtube.com/watch?v=-llkMpNH160&feature=youtu.be](https://m.youtube.com/watch?v=-llkMpNH160&feature=youtu.be)"
43,deeplearning,gpt-4,top,2023-08-03 23:38:39,What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?,Claud1ao,False,0.67,1,15hjv2y,https://www.reddit.com/r/deeplearning/comments/15hjv2y/what_would_be_the_initial_costs_of_developing_a/,4,1691105919.0,"I was wondering if this would be super expensive or not.

The cost to develop GPT-3 was about $4 millions according to some resources online. 

Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?

Any answer is appreciated.

Thanks in advance."
44,deeplearning,gpt-4,top,2023-08-21 16:48:23,Gorilla: Large Language Models Connected to Massive APIs [Paper Summary Video],CShorten,False,0.67,1,15xd14p,https://www.reddit.com/r/deeplearning/comments/15xd14p/gorilla_large_language_models_connected_to/,0,1692636503.0,"Hey everyone, I am SUPER excited to present a paper summary video of ""Gorilla: Large Language Models connected to Massive APIs"" by Patil et al. 2023!  LLMs have been supercharged by connecting them with external tools. An external tool could be a search engine, code executor, calculator, calendar, email, CRM, and many others! Although GPT-4 is fairly strong at formatting API requests zero-shot (without additional training), Gorilla shows that specialized training can outperform it significantly! In addition to the accuracy performance, this is also achievable with a much cheaper 7 billion parameter model, derived by fine-tuning the Meta AI LlaMA-2 7B checkpoint!!

There are all sorts of interesting details about this paper covered in the video, from the APIBench dataset to Self-Instruct training data generation, Retrieval-Aware Training, and the miscellaneous details of Gorilla! I hope you enjoy the paper summary video! As always I am more than happy to answer any questions or discuss any ideas you have related to the content in the video!

P.S. Please stay tuned for Weaviate Gorilla! 🦍 👀

https://www.youtube.com/watch?v=LkV5DTRNxAg"
45,deeplearning,gpt-4,top,2023-09-02 17:47:32,LLaVA: Bridging the Gap Between Visual and Language AI with GPT-4,OnlyProggingForFun,False,0.6,1,1688v3c,https://youtu.be/Pn1B_L_zAwI,1,1693676852.0,
46,deeplearning,gpt-4,top,2023-04-06 07:43:06,A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?,Learningforeverrrrr,False,0.56,1,12dcnrm,https://www.reddit.com/r/deeplearning/comments/12dcnrm/a_complete_survey_on_generative_ai_aigc_is/,0,1680766986.0,"We recently completed two surveys: one on generative AI and the other on ChatGPT. Generative AI and ChatGPT are two fast-evolving research fields, and we will update the content soon, for which your feedback is appreciated (you can reach out to us through emails on the paper).

The title of this post refers to the first one, however, we put both links below.

**Link to a survey on Generative AI (AIGC):** [**A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?**](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need)

**Link to a survey on ChatGPT:** [**One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era**](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era)

The following is the **abstract** of the **survey on generative AI** with a summary **figure**.

As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to analyze and create text, images, and beyond. With such overwhelming media coverage, it is almost impossible to miss the opportunity to glimpse AIGC from a certain angle.  In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks. Impressed by the capability of the ChatGPT, many people are wondering about its limits: can GPT-5 (or other future GPT variants) help ChatGPT unify all AIGC tasks for diversified content creation? To answer this question, a comprehensive review of existing AIGC tasks is needed. As such, our work comes to fill this gap promptly by offering a first look at AIGC, ranging from its **techniques** to **applications**. Modern generative AI relies on various technical foundations, ranging from **model architecture** and **self-supervised pretraining** to **generative modeling** methods (like GAN and diffusion models). After introducing the fundamental techniques, this work focuses on the technological development of various AIGC tasks based on their output type, including **text**, **images**, **videos**, **3D content**, **etc**., which depicts the full potential of ChatGPT's future. Moreover, we summarize their significant applications in some mainstream **industries**, such as **education** and **creativity** content. Finally, we discuss the **challenges** currently faced and present an **outlook** on how generative AI might evolve in the near future.

&#x200B;

https://preview.redd.it/scbpeabnx7sa1.png?width=1356&format=png&auto=webp&s=445da6a707ceb6af75e5305137ad30dcd06c32fe

**Link to a survey on Generative AI (AIGC):** [**A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?**](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need)

**Link to a survey on ChatGPT:** [**One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era**](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era)"
47,deeplearning,gpt-4,top,2023-07-24 17:54:54,AI Digests: GPT-4 generated Newsletter on ArXiv Deep Learning Papers,CommercialLynx7233,False,1.0,1,158hu6c,https://www.reddit.com/r/deeplearning/comments/158hu6c/ai_digests_gpt4_generated_newsletter_on_arxiv/,0,1690221294.0,"Hey y'all,

I built a quick site called [AI Digests](https://aidigest.dev/), that uses GPT-4 to generate a newsletter summarizing the key themes/concepts discussed, in ArXiv Deep Learning (cs.LG) papers, on a daily basis. Here is last Friday's Edition: [https://aidigest.dev/edition/2023-07-22](https://aidigest.dev/edition/2023-07-22)

If you are interested, please do subscribe by submitting your email! Let me know what you guys think!"
48,deeplearning,gpt-4,top,2024-02-17 08:34:08,Question about LLM's proficiency in advanced mathematics,WinExcellent381,False,0.6,1,1asxab6,https://www.reddit.com/r/deeplearning/comments/1asxab6/question_about_llms_proficiency_in_advanced/,21,1708158848.0,"The most cutting-edge LLMs like GPT 4 Turbo and Gemini Ultra 1.0 are great, but when it comes to mathematics, they are really limited. When will we start to have LLMs that will get a perfect score in IMO or the William Lowell Putnam Mathematical Competition every single time, and can solve master's or PhD questions about differential geometry or quantum field theory better and faster than any physicist or mathematician alive? Is AGI necessary for such capabilities or is it that researchers just haven't trained the models specifically on those tasks?"
49,deeplearning,gpt-4,top,2023-05-16 12:07:13,Keras GPT Copilot (New Python Package) - Integrating an LLM copilot within the Keras model development workflow!,CourseGlum5431,False,0.56,1,13j3c2c,https://www.reddit.com/r/deeplearning/comments/13j3c2c/keras_gpt_copilot_new_python_package_integrating/,0,1684238833.0," Integrating an LLM copilot within the Keras model development workflow!

[https://github.com/fabprezja/keras-gpt-copilot](https://github.com/fabprezja/keras-gpt-copilot)

Features

* Generates copilot feedback from gathering model configuration, optimizer details, and experiment results during model development
* Interacts with OpenAI's LLMs, such as GPT-4
* Can be used with non-OpenAI LLMs to generate suggestions
* Offers options to downsample and/or smoothen validation curves to accommodate large (and/or noisy) results within the copilot prompt
* Provides flexibility in customizing the copilot prompt, allowing for the addition of extra information.
* Supports follow-up questions for extended guidance, such as requesting specific code changes based on previous recommendations"
50,deeplearning,gpt-4,top,2023-04-10 17:02:54,Exploring the Potential and Pitfalls of Deep Learning and Machine Learning: A Reddit User's Quest for Knowledge,Large_Rush9013,False,1.0,1,12howrh,https://www.reddit.com/r/deeplearning/comments/12howrh/exploring_the_potential_and_pitfalls_of_deep/,0,1681146174.0,"As a fellow Reddit user, I couldn't help but be intrigued by some of the recent advancements and discussions surrounding deep learning and machine learning. It amazes me how much progress we've made in these fields, and the potential applications for them are seemingly endless. Although I love exploring the different areas where machine learning can have an impact, I also have some questions and would appreciate anyone's insights.

Conversely, a thought has crossed my mind regarding how these cutting-edge tools can also be used for disinformation or other negative purposes. It seems imperative that we, as a tech-savvy community, work together to ensure these tools remain positively focused and prevent them from being used to spread misinformation or other nefarious goals.

One particular area that has caught my eye is the powerful pipeline for background removal mentioned in a recent article. It utilizes the CUDA-accelerated MOG2 background segmentation algorithm and the Savant Video Analytics Framework, resulting in impressive processing speeds. I wonder, though, about the potential applications for this technology, both positive and negative.

Additionally, I came across an interesting topic on using machine learning to predict human preferences in assembly tasks. If we can successfully train robots to assist us, the implications for manufacturing, construction, and even everyday tasks could be significant. However, it begs the question of how much we should allow AI and robots to control our lives and the measures that need to be in place to ensure they remain our helpful assistants rather than our overlords.

In my quest to learn more, I stumbled upon a free deep learning course and was wondering if there are any other resources I could check out to expand my knowledge? It's crucial to comprehend the intricacies of these powerful tools to make informed decisions as a society regarding their applications and potential consequences.

I would love to hear your thoughts on the subjects and any recommendations for resources that will aid in deep learning and machine learning education. Let's work together to harness the potential of these technologies while maintaining a vigilant watch for the negative aspects that may arise.

This post was curated with the help of Moji AI, an innovative tool that utilizes GPT-4 to assist content writing. You can learn more about Moji AI by visiting their website at mojiai.io."
51,deeplearning,gpt-4,top,2023-11-06 02:57:04,"If a conversation is not deleted, can ChatGPT-4 continuously learn and maintain the conversation state?",Turbulent_Dot_5216,False,0.62,2,17ot4d4,https://www.reddit.com/r/deeplearning/comments/17ot4d4/if_a_conversation_is_not_deleted_can_chatgpt4/,6,1699239424.0," As a beginner, I have a question for everyone: Does ChatGPT-4 forget the context if the conversation is closed or left idle for a long period, meaning it can't maintain the state of the conversation? I want ChatGPT-4 to learn legal knowledge, and in one conversation, provide it with a vast amount of legal material over a long period. Can ChatGPT-4 remember the previous legal material every time I open it, i.e., maintain the conversation state? If not, how can I make ChatGPT-4 remember previous conversations? 

 Additionally, if I do not delete a conversation and continuously feed ChatGPT-4 a large amount of legal information within that same conversation, can ChatGPT-4 achieve self-learning? That is, can it become increasingly proficient in legal matters, or regardless of how much information I provide, will ChatGPT-4 not improve? "
52,deeplearning,gpt-4,top,2023-09-24 01:00:34,"Exploring ""Harm Filter for LLM"" as a Research in NLP",junkim100,False,1.0,1,16qkfjr,https://www.reddit.com/r/deeplearning/comments/16qkfjr/exploring_harm_filter_for_llm_as_a_research_in_nlp/,2,1695517234.0,"I'm currently considering a research topic for my combined masters/phd program in an NLP lab. I've been particularly intrigued by the challenges posed by Large Language Models (LLMs) when it comes to generating potentially harmful or inappropriate content. Given the recent ""jailbreaks"" on LLMs, where users have tried to bypass content filters, I believe there's a pressing need to delve deeper into this area.

For my research focus, I've been referring to it as ""Harm Filter for LLM."" However, I'm unsure if there's an established term for this specific area of study. It seems to encompass techniques to prevent models from generating harmful content and strategies to defend against adversarial attempts to bypass these filters.

I came across a few resources that shed light on this topic:

* [**GitHub Repository on LLM Prompt Injection Filtering**](https://github.com/derwiki/llm-prompt-injection-filtering/blob/main/README.md)
* [**Research Paper on Evaluating Large Language Models Trained on Code**](https://arxiv.org/pdf/2307.02483.pdf)
* [**Research Paper on ChatGPT: A Chatbot based on GPT-3.5**](https://arxiv.org/abs/2305.05027)

I have a few questions for the community:

1. Do you think ""Harm Filter for LLM"" (or whatever the established term might be) is a promising research area in NLP?
2. Is there a commonly used term for this field? Could it possibly fall under a broader category like ""Explainable AI""?
3. Any suggestions on where I can delve deeper into this topic?
4. Additionally, I'm also looking for resources to strengthen my foundational knowledge in NLP. Any recommendations would be greatly appreciated!"
53,deeplearning,gpt-4,top,2023-12-06 04:07:21,[D]Unlocking Insights: Harnessing Table Extraction and Advanced Data Querying with LlamaIndex’s Pandas Query Engine,Fit_Maintenance_2455,False,1.0,1,18bvfof,https://www.reddit.com/r/deeplearning/comments/18bvfof/dunlocking_insights_harnessing_table_extraction/,0,1701835641.0,"Introducing LlamaIndex, a transformative tool that facilitates seamless interaction between your data sources and powerful language models like GPT-4. This comprehensive guide unveils a groundbreaking approach: extracting data from URLs, converting it into PDFs, extracting tables from these PDFs, and ultimately converting these tables into CSV files. LlamaIndex serves as the linchpin, enabling effortless communication and utilization of data between diverse sources and language models, revolutionizing the landscape of intelligent applications.

&#x200B;

Link: [https://medium.com/ai-advances/unlocking-insights-harnessing-table-extraction-and-advanced-data-querying-with-llamaindexs-pandas-f7200ef07771](https://medium.com/ai-advances/unlocking-insights-harnessing-table-extraction-and-advanced-data-querying-with-llamaindexs-pandas-f7200ef07771) "
54,deeplearning,gpt-4,top,2023-12-22 21:52:34,NeuralFlash - a flashcard-making GPT specializing in AI to help you study.,MachineScholar,False,0.67,1,18opxcs,https://www.reddit.com/r/deeplearning/comments/18opxcs/neuralflash_a_flashcardmaking_gpt_specializing_in/,0,1703281954.0,"Hey everyone. I'm a computer science student and I've been searching for the most efficient way to study ML concepts via Quizlet flashcards so I came up with a ""pipeline"" by making this custom GPT and feeding it my Markdown notes. Here's a little guide:

1. Take lecture/book notes in Markdown (I use obsidian to do this since it's free, fast, and open source)
2. Open up NeuralFlash and choose the ""Generate flashcards from my AI notes"" action.
3. Copy your entire Markdown note, paste it into NeuralFlash.
4. Copy the csv it outputs and paste it into the ""import"" area of your Quizlet flashcard set (make sure you select comma instead of tab).
5. Learn and succeed.

**Here the link to the GPT:** [**https://chat.openai.com/g/g-m4nFBaKA8-neuralflash**](https://chat.openai.com/g/g-m4nFBaKA8-neuralflash)"
55,deeplearning,gpt-4,top,2020-10-30 01:48:31,Generating Snort Rules using GPT2,afoteygh,False,1.0,1,jkntfp,https://www.reddit.com/r/deeplearning/comments/jkntfp/generating_snort_rules_using_gpt2/,0,1604022511.0,"Hi I have been working on Generating Snort rules using the GPT2 Transformer.

This is my thinking

1. Snort rules for a particular family of malware are quite related. that is why these malware have been classified into that family so using text generation to generate new rules should be possible (i Feel)
2. Collect Snort rules for a particular malware family. (Also collect pcap which trigger these specific rules i have obtained)
3. Clean it up by removing commented/unused rules.
4. Feed the rules to GPT2 (124M) (I chose this because i read it performs quite well in text generation )
5. Trained GPT on the dataset
6. using it to generated new rules
7. clean up the rules (syntax etc)
8. Test newly generated rules in snort with sample pcap files.

So for i have been able to generate and clean up 1000's of rules and tested them without any success!

Can anyone give me some guidance on what i am doing wrong or if my whole hypothesis and experiment is flawed."
56,deeplearning,gpt-4,top,2023-03-29 14:07:24,New Weaviate Podcast with Mem Co-Founder Dennis Xu!,CShorten,False,0.67,1,125p56e,https://www.reddit.com/r/deeplearning/comments/125p56e/new_weaviate_podcast_with_mem_cofounder_dennis_xu/,0,1680098844.0," I'm super excited to publish our newest Weaviate Podcast with Mem Co-Founder Dennis Xu!! Dennis is at the cutting-edge of applying the latest advancements in AI to note taking or knowledge management software. In other words, shaping the future of knowledge work itself!

Dennis explained a ton of interesting topics such as personalized embeddings and organizing your digital footprint through the Me API, of course the trending topic of how GPT-4 and recent advances in LLMs are changing things, and many more topics in what it is powering these systems!

Please check it out and let us know what you think!

https://youtu.be/RujNYB5ZE2c"
57,deeplearning,gpt-4,top,2023-11-25 16:03:32,[D] Orca-2–13B vs LLAMA-2-Chat-13B,Fit_Maintenance_2455,False,0.5,0,183mvzk,https://www.reddit.com/r/deeplearning/comments/183mvzk/d_orca213b_vs_llama2chat13b/,1,1700928212.0,"In the evolving landscape of AI, Orca emerges as a pioneering force, poised to redefine reasoning in language models. This evolution resonates with the transformative potential seen in Large Language Models (LLMs) like GPT-4 and PaLM-2, unlocking unprecedented reasoning capabilities. However, the prevailing imitation learning approach poses limitations for smaller models, leading to the emergence of Orca 2. This iteration is designed to empower smaller language models with diverse reasoning techniques, tailored strategies, and an edge across diverse tasks. Orca 2’s initial evaluations reveal promising advancements, surpassing models of similar size and even larger counterparts in reasoning-centric tasks. Yet, akin to all models, Orca 2 encounters limitations rooted in its underlying pre-trained model, emphasizing the ongoing importance of safety considerations and potential extensions for enhanced safety alignment.

link in the comment "
58,deeplearning,gpt-4,top,2023-09-11 21:06:33,"Meta sets GPT-4 as the bar for its next AI model, says a new report",Nalix01,False,0.5,0,16g7dh3,https://www.reddit.com/r/deeplearning/comments/16g7dh3/meta_sets_gpt4_as_the_bar_for_its_next_ai_model/,2,1694466393.0,"Meta is reportedly planning to train a new model that it hopes will be as powerful as OpenAI’s GPT-4, by heavily investing in data centers and H100 chips. They hope the AI model will be way more powerful than Llama 2.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso).

**Meta's AI Ambitions**

* **New AI Development**: Meta is working on an AI model, which they hope to be several times more powerful than their recent model, Llama 2.
* **Accelerating Generative AI**: This initiative is spearheaded by a group established by Mark Zuckerberg earlier this year, focusing on AI tools that produce human-like expressions.
* **Expected Timeline**: Meta anticipates the commencement of training for this AI system in early 2024.

**Strategic Positioning in the AI Race**

* **Behind Rivals**: This new model is part of Zuckerberg's strategy to reposition Meta as a leading entity in the AI domain after falling behind competitors.
* **Infrastructure Development**: Meta is investing in data centers and acquiring advanced Nvidia chips (H100s) for AI training.
* **Shift from Microsoft**: While Meta's Llama 2 was integrated with Microsoft's cloud platform, Azure, the new model is intended to be trained on Meta's infrastructure.

**Open-source Approach and Implications**

* **Advocating Open-Source**: Zuckerberg's plan is to make the new AI model open-source, making it freely accessible for companies to build AI-driven tools.
* **Benefits and Risks**: Open-source AI models are favored due to their cost-effectiveness and flexibility. However, they also come with potential downsides, including legal risks and misuse for disseminating false information.
* **Concerns from Experts**: There are raised apprehensions about the unpredictability of the system and its potential vulnerabilities, emphasizing the need for transparency and control.

Sources [(WSJ](https://www.wsj.com/tech/ai/meta-is-developing-a-new-more-powerful-ai-system-as-technology-race-escalates-decf9451) and [TheVerge](https://www.theverge.com/2023/9/10/23867323/meta-new-ai-model-gpt-4-openai-chatbot-google-apple))

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,000+** **professionals** from **OpenAI, Google, Meta**…"
59,deeplearning,gpt-4,top,2023-09-30 12:23:31,[D] How to train a seq2seq model to rephrase input text following given rules.,3Ammar404,False,0.5,0,16w5g5p,https://www.reddit.com/r/deeplearning/comments/16w5g5p/d_how_to_train_a_seq2seq_model_to_rephrase_input/,2,1696076611.0,"Hi guys,

I want to train (fine-tune) a seq2seq model to perform the task of rephrasing input following these rules :

1- always follow the pattern ""Entity Verb Entity""

2- only use simple sentences : never combine sentences

3- Don't replace existing words

4- Don't lose the overall meaning of the text or any information in it.

For example:

text = ""Project Risk Management includes the processes of conducting risk management planning, identification, analysis, response planning, response implementation, and monitoring risk on a project""

Standardized Text = ""Project Risk Management conducts risk management planning. Project Risk Management conducts risk identification. Project Risk Management conducts risk analysis. Project Risk Management plans responses. Project Risk Management implements responses. Project Risk Management monitors risk on a project.""

Using ChatGPT the results were very good, but I want to know if I can fine tune a model (BERT, T5, any LM) locally, what should be the data format for training such a model, evaluation metrics ?"
60,deeplearning,gpt-4,top,2024-01-24 19:24:25,~2 minute explanation of RankZephyr!,CShorten,False,0.5,0,19eosj0,https://www.reddit.com/r/deeplearning/comments/19eosj0/2_minute_explanation_of_rankzephyr/,0,1706124265.0,RankZephyr is a really cool example of labeling training data with a larger model such as GPT-4 to then fine-tune into a cheaper model (Mistral 7B)! This is a nice explanation of some of the key ideas in 2 minutes - [https://twitter.com/ecardenas300/status/1750237408459706554](https://twitter.com/ecardenas300/status/1750237408459706554).
61,deeplearning,gpt-4,top,2023-12-12 12:10:06,[D] Crafting Visually Stunning Slides with Assistants API (GPT-4) and DALL·E-3,Fit_Maintenance_2455,False,0.5,0,18gkhbu,https://www.reddit.com/r/deeplearning/comments/18gkhbu/d_crafting_visually_stunning_slides_with/,0,1702383006.0,"In the realm of presentations, creating visually compelling slides that effectively communicate data insights is a skill coveted by professionals across diverse industries. However, the traditional process of manually constructing these slides can be a time-consuming endeavor. Enter the new Assistants API (GPT-4) and DALL·E-3, revolutionary tools that streamline the slide creation process, offering efficiency and visual finesse.

Crafting slides that capture the essence of complex data sets while maintaining audience engagement is a multifaceted challenge. It demands a blend of data interpretation, storytelling finesse, and an eye for design. Traditionally, this process involves laborious manual work, from structuring information to selecting images and formatting layouts.

&#x200B;

link: [https://medium.com/ai-advances/crafting-visually-stunning-slides-with-assistants-api-gpt-4-and-dall-e-3-f862368cec44](https://medium.com/ai-advances/crafting-visually-stunning-slides-with-assistants-api-gpt-4-and-dall-e-3-f862368cec44) "
62,deeplearning,gpt-4,top,2023-12-07 05:25:34,Gemini vs. GPT-4: Google's AI Takes the Lead in Benchmarks,Damanjain,False,0.4,0,18cofmx,https://thebuzz.news/article/gemini-vs-gpt-4-in-benchmarks/11594/,2,1701926734.0,
63,deeplearning,gpt-4,top,2023-09-26 18:24:05,"OpenAI’s GPT-4 with vision still has flaws, paper reveals",Nalix01,False,0.33,0,16svoeg,https://www.reddit.com/r/deeplearning/comments/16svoeg/openais_gpt4_with_vision_still_has_flaws_paper/,1,1695752645.0,"OpenAI initially promoted GPT-4's ability to analyze and interpret images alongside text, but has since limited these features due to concerns about misuse and privacy. A recent paper sheds light on the efforts to mitigate these issues and the ongoing challenges GPT-4 faces in interpreting images accurately and responsibly.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post).

**Image Analysis Concerns**

* **Abuse and Privacy Issues:** OpenAI limited GPT-4's image features due to potential misuse and privacy violations.
* **Mitigation Efforts:** The company is working on safeguards to prevent malicious use and bias in GPT-4’s image analysis.

**Performance Issues**

* **Inaccurate Inferences:** GPT-4V can make incorrect inferences, combining text strings wrongly and missing details.
* **Identification Issues:** Struggles with identifying dangerous substances or chemicals and gives wrong medical imaging responses.

**Discrimination and Bias**

* **Misunderstood Symbols:** GPT-4V doesn't grasp the nuances of certain hate symbols.
* **Discrimination:** Shows bias against certain sexes and body types, relating responses mainly to body weight and body positivity.

[Source (Tech Crunch)](https://techcrunch.com/2023/09/26/openais-gpt-4-with-vision-still-has-flaws-paper-reveals/#:~:text=The%20paper%20reveals%20that%20GPT,facts%20in%20an%20authoritative%20tone)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **7,000+** **professionals** from **OpenAI, Google, Meta**…"
64,deeplearning,gpt-4,top,2020-07-26 07:39:05,Crazy Numbers of GPT-3,alaap001,False,0.5,0,hy2vg1,https://www.reddit.com/r/deeplearning/comments/hy2vg1/crazy_numbers_of_gpt3/,2,1595749145.0,"Trained on over 285,000 CPU cores and 10,000 GPUs cluster, a lot of hype going around the latest GPT-3 model, those who are not into AI, it is the most advanced NLP algorithm to date. It learned the human-level language from over 400GB of data, costing crazy $12 million just to train it with \~175 Billion!! parameters. A typical high-end GPU would take over 350 years to train this model. As a Data Scientist, I thought why not look at how much data it took to learn human language. 

Well, here are the crazzyy numbers.

It used roughly 9 Million Hindi words,

3 Billion for German

and

4 Billion French words with 100 other languages. 

https://preview.redd.it/2b6aee0un5d51.png?width=937&format=png&auto=webp&s=3d4fa2e1b2621ae699ec1bb4a62d7cc85554c8d1

https://preview.redd.it/ec7tve0un5d51.png?width=871&format=png&auto=webp&s=9d8624d117ad4e1f41fff78f06bb30197abbd006

and all this fades away when English comes in with over 180 Billion words!! \[ For reference English has only 171,476 unique words with 20000 being used normally \]

It seems crazy how AI is being built so rapidly and now can talk like a human. Gets me excited thinking about what the future holds. 

***If you're the one who is getting started with Deep Learning then for you I created a website wherein I plan to do 100 Deep Learning Projects to help people understand the practicality of Deep Learning. You can visit*** [***https://www.aiunquote.com/***](https://www.aiunquote.com/) ***and learn deep learning by implementing,***

**#artificialintelligence** **#technology** **#AI** **#naturallanguageprocessing** **#gpt3** **#tableaupublic** **#computerscience** **#maths** **#innovation** **#datascience**"
65,deeplearning,gpt-4,top,2023-10-26 14:51:06,5 Game-Changing Applications of GPT-4: No Coding Skills Required!,OnlyProggingForFun,False,0.25,0,17gy9w8,https://youtu.be/lwNy4lgDpjY,0,1698331866.0,
66,deeplearning,gpt-4,top,2020-10-28 11:39:21,How did I get access to GPT-3 OpenAI's API? Tips are shared at 4:45 in the video! The rest of the videos explains what can GPT-3 really do and how it can help you or your company.,OnlyProggingForFun,False,0.43,0,jjm4ep,https://www.youtube.com/watch?v=Gm4AMjV8ErM,0,1603885161.0,
67,deeplearning,gpt-4,top,2023-03-16 12:48:36,Alpaca - Train Your GPT-4 for Less Than $100,deeplearningperson,False,0.38,0,11st80q,https://youtu.be/6qdzsDSduww,2,1678970916.0,
68,deeplearning,gpt-4,top,2023-12-13 10:06:50,Durchbruch in der KI mit Gemini: ChatGPT 4.0 in Benchmark-Tests übertroffen!,Webglobic_tech,False,0.25,0,18hdkrs,https://webglobic.com/2023/12/12/gemini-uebertrifft-chatgpt4-0-in-benchmark-tests-ein-neuer-meilenstein-in-der-ki-entwicklung/,0,1702462010.0,
69,deeplearning,gpt-4,top,2023-04-01 14:01:42,Revolutionizing Content Creation: Moji AI's Impact on Social Media and Beyond,Large_Rush9013,False,0.25,0,128nbfn,https://www.reddit.com/r/deeplearning/comments/128nbfn/revolutionizing_content_creation_moji_ais_impact/,0,1680357702.0,"Hey fellow Redditors, I recently stumbled upon a summary of an incredible new AI content tool called Moji AI, and I just had to share my thoughts about it. I think it has the potential to be a game-changer for content creators!

Moji AI is designed to make content creation easier by using the power of GPT-4 to generate text and Stable Diffusion Models to create eye-catching images. It offers icons and image assets that can significantly boost social media engagement. As a Reddit user, I'm always trying to find new ways to share content and start conversations, and I think the potential benefits of this tool are undeniable.

I've been aware of GPT-3 for a while now, and the thought of GPT-4 being a more powerful version gets me excited about what it could mean for the future of AI-generated content. The fact that Moji AI can not only generate text, but also customize images and icons, makes it seem like a must-have tool for anyone serious about making an impact on social media platforms.

The Stable Diffusion Models used by Moji AI allow it to create visually stunning images that are bound to catch the attention of users as they're scrolling through their feeds. It's not just about the text anymore - visuals are crucial in today's social media landscape, and Moji AI is tackling that aspect head-on.

I can already think of countless ways to apply Moji AI in both personal and professional projects. Imagine effortlessly creating engaging blog posts, social media posts, and digital marketing campaigns without the hassle of finding a graphic designer or a copywriter. This tool seems too good to be true!

For those of you who are interested in learning more about Moji AI and how it can elevate your content creation game, I urge you to check out their website at [mojiai.io](https://mojiai.io). I'm excited to see the applications of this tool, and I believe that it'll revolutionize how we create and share content moving forward.

Indeed, it's exciting to be part of a community that is always at the forefront of groundbreaking innovations like Moji AI! Feel free to share your thoughts and ideas about how you think Moji AI could impact the world of content creation. Let's start a conversation!"
70,deeplearning,gpt-4,top,2023-04-25 18:02:06,"Diverse Conversations: Mental Health, Sustainable Living, and Personal Finance in a Fast-Paced World",Large_Rush9013,False,0.25,0,12yqxxl,https://www.reddit.com/r/deeplearning/comments/12yqxxl/diverse_conversations_mental_health_sustainable/,3,1682445726.0,"Hey everyone, I wanted to share some thoughts I had recently after coming across various discussions on the platform. I realized how diverse and thought-provoking this community truly is.

One topic that caught my attention was the importance of mental health, especially in today's fast-paced world. The amount of information and the undeniable impact of social media on our lives can be both enlightening and suffocating. It has become more important than ever for us to take care of our well-being and find a balance between consuming content and living in the present moment.

Another area that has drawn my curiosity is the growing discussions on sustainable living and eco-friendliness. It's inspiring how we are collectively working to create a better world for future generations. Whether it's through reducing waste, discovering alternative energy sources, or just being more aware of our surroundings, every action makes a difference.

Lastly, I've noticed an increase in discussions surrounding personal finance and investment. We are living in unprecedented times, and it's fascinating to see how the financial landscape has transformed. Whether it's cryptocurrency, passive income ideas, or strategies to achieve financial freedom, these conversations are not only interesting but educational too.

All in all, the richness of this community lies in the plethora of topics discussed and the valuable insights shared by its members. I'm grateful to be part of this and always look forward to learning something new every day.

P.S. This post was curated with the help of Moji AI, a content-writing helper using GPT-4 technology. If you're interested in learning more, check out their website at mojiai.io."
71,deeplearning,gpt-4,top,2023-03-20 06:27:48,GPT-4,Genius_feed,False,0.41,0,11wat6c,https://i.redd.it/h1ov2l5p8uoa1.jpg,0,1679293668.0,
72,deeplearning,gpt-4,top,2023-03-16 00:03:09,OpenAI's GPT 4 is out and it's multimodal! What we know so far,gordicaleksa,False,0.38,0,11sdx6l,https://www.youtube.com/watch?v=FY9Nlkoq4GI&t=2s&ab_channel=AleksaGordi%C4%87-TheAIEpiphany,1,1678924989.0,
73,deeplearning,gpt-4,top,2023-08-30 17:58:05,"Bright Eye: free mobile AI app that generates art and different forms of text (code, math answers, essays, games, ideas, and more)!(GPT-4 POWERED)",EtelsonRecomputing,False,0.29,0,165lsy9,https://www.reddit.com/r/deeplearning/comments/165lsy9/bright_eye_free_mobile_ai_app_that_generates_art/,1,1693418285.0,"
Hi all. I’m the cofounder of a startup focused on developing the AI super app called “Bright Eye”, a multipurpose AI product that generates and analyzes content.

One of its interesting use cases is helping students study, people plan, and offering general advice. 

As the title puts it, it’s capable of generating almost anything, so the use-cases in terms of productivity isn’t confined to only those above, it can apply however you see fit. We run on GPT-4, stable diffusion, and Microsoft azure cognitive services.  

Check us out below, we’re looking for advice on the functionality and design of the app (and possibly some longtime users): 

https://apps.apple.com/us/app/bright-eye/id1593932475"
74,deeplearning,gpt-4,top,2023-11-06 05:28:48,"I want to create a continuously improving legal AI. My idea is to constantly feed ChatGPT-4 legal knowledge so that it keeps learning. Is this possible? If it can't be done with ChatGPT-4, is there another way to achieve this?",Turbulent_Dot_5216,False,0.3,0,17ovpmz,https://www.reddit.com/r/deeplearning/comments/17ovpmz/i_want_to_create_a_continuously_improving_legal/,3,1699248528.0," I want to create a continuously improving legal AI. My idea is to constantly feed ChatGPT-4 legal knowledge so that it keeps learning. Is this possible? If it can't be done with ChatGPT-4, is there another way to achieve this? "
75,deeplearning,gpt-4,top,2023-01-17 16:06:37,What nobody tells you about chatGPT and GPT-4,thomas999999,False,0.27,0,10efwno,https://www.reddit.com/r/deeplearning/comments/10efwno/what_nobody_tells_you_about_chatgpt_and_gpt4/,3,1673971597.0,i wanted to share a nice writeup my friend made about chatGPT [https://medium.com/@christian.bernhard97/what-nobody-tells-you-about-chatgpt-and-gpt-4-c8d97ae9f92d](https://medium.com/@christian.bernhard97/what-nobody-tells-you-about-chatgpt-and-gpt-4-c8d97ae9f92d)
76,deeplearning,gpt-4,top,2023-12-15 04:50:13,OpenAI's Next Move: ChatGPT 4.5 Upgrade in the Works? Sam Altman Clarifies,Damanjain,False,0.13,0,18is4sm,https://thebuzz.news/article/openai-chatgpt-4-5-leak/11787/,1,1702615813.0,
77,deeplearning,gpt-4,top,2023-03-15 01:53:32,How good is GPT-4 compared to ChatGPT?,OnlyProggingForFun,False,0.2,0,11rihli,https://youtu.be/GroMQETFXLc,1,1678845212.0,
78,deeplearning,gpt-4,top,2024-01-05 08:27:31,6 ways AI can make your life easier in 2024,PoetryOne4804,False,0.33,0,18z212l,https://www.reddit.com/r/deeplearning/comments/18z212l/6_ways_ai_can_make_your_life_easier_in_2024/,8,1704443251.0,"Artificial intelligence is developing every day. ChatGPT was a game changer for millions of people, but it is not the only one. Advances in AI are coming, and they're coming FAST. Very fast. There’re so many tasks AI can help with and make this year less stressful. Let me show you these ways:

**1) Chatbots for answering questions and brainstorming**

Except ChatGPT, you can use Google Bard, SpinBot, and YouChat.

**2) AI Essay writers**

Many people use [essay writing services](https://www.reddit.com/r/deeplearning/comments/16gnuwy/best_essay_writing_services_top_5/) but not all think that AI can also help in academic writing. AI essay writers like [Textero.ai](https://Textero.ai) can be faster and generate ideas or find sources for your topic.

**3) Daily life tools**

There’re AI planners to schedule meetings and integrate with your calendars. You can also keep track of finances using PocketGuard, Wally, or Cleo.

**4) Tools for social networks**

There’re various AI tools tailored for social networks, such as Postwise for Twitter posts and Steve.ai for YouTube.

**5) Tools to improve health and fitness goals**

AI tools like Apple Watches and Fitbits can monitor your fitness and health. They can even track your sleep and offer suggestions to improve sleep quality.

**6) Tools for academic needs**

Even though some professors are against using AI while studying, students look for ways to make academic life easier. Useful tools for school life you can find here:  [ai tools for students](https://www.reddit.com/r/artificial/comments/1716t0y/ai_tools_for_students_from_ai_essay_generators_to/)

Any other tools to share? Feel free to write about them, I’m ready to try more new services."
79,deeplearning,gpt-4,comments,2021-08-19 07:03:53,Dual 3090 vs A6000 + Intel vs AMD?,xKaiz3n,False,0.72,6,p79uhm,https://www.reddit.com/r/deeplearning/comments/p79uhm/dual_3090_vs_a6000_intel_vs_amd/,21,1629356633.0,"Hello,

I've been asked to spec out a machine for a range of DL tasks (inc. GPT-3/4 & classification etc.). Looking at prices here (AUS) it seems the price for 2x 3090s (AUD$3000 - 4000) is around the same price as 1x A6000 (AUD$7500 - 8500). 

I've gone into this with a fairly rudimentary understanding of both hardware at this level and deep learning (read: I'm a student & interning), so apologies if I've said something particularly silly.  I'm also looking to see if there are any recommendations for CPU's:

\- do DL packages have a preference for AMD vs Intel like they do with GPU's?

\- which CPU would you guys choose that won't bottleneck the GPUs?

&#x200B;

Thank you!"
80,deeplearning,gpt-4,comments,2024-02-17 08:34:08,Question about LLM's proficiency in advanced mathematics,WinExcellent381,False,0.6,1,1asxab6,https://www.reddit.com/r/deeplearning/comments/1asxab6/question_about_llms_proficiency_in_advanced/,21,1708158848.0,"The most cutting-edge LLMs like GPT 4 Turbo and Gemini Ultra 1.0 are great, but when it comes to mathematics, they are really limited. When will we start to have LLMs that will get a perfect score in IMO or the William Lowell Putnam Mathematical Competition every single time, and can solve master's or PhD questions about differential geometry or quantum field theory better and faster than any physicist or mathematician alive? Is AGI necessary for such capabilities or is it that researchers just haven't trained the models specifically on those tasks?"
81,deeplearning,gpt-4,comments,2023-04-05 01:36:40,Vicuna : an open source chatbot impresses GPT-4 with 90% of the quality of ChatGPT,Time_Key8052,False,0.95,87,12c43uu,https://www.reddit.com/r/deeplearning/comments/12c43uu/vicuna_an_open_source_chatbot_impresses_gpt4_with/,19,1680658600.0,"Vicuna : ChatGPT Alternative, Open-Source, High Quality and Low Cost 

&#x200B;

[ Relative Response Quality Assessed by GPT-4 ](https://preview.redd.it/oaj1s995zyra1.png?width=599&format=png&auto=webp&s=1fb01b017b3b8b4f9149d4b80f40c48d3a072b91)

Vicuna-13B has demonstrated competitive performance against other open-source models, such as Stanford Alpaca, by fine-tuning a LLaMA base model on user-shared conversations collected from ShareGPT.

Evaluation using GPT-4 as a judge shows that Vicuna-13B achieves more than 90% of the quality of OpenAI ChatGPT and Google Bard AI, while outperforming other models such as Meta LLaMA (Large Language Model Meta AI) and Stanford Alpaca in more than 90% of cases.

The cost of training Vicuna-13B is approximately $300.

The training and serving code, along with an online demo, are publicly available for non-commercial use.

&#x200B;

More Information : [https://gpt4chatgpt.tistory.com/entry/Vicuna-an-open-source-chatbot-impresses-GPT-4-with-90-of-the-quality-of-ChatGPT](https://gpt4chatgpt.tistory.com/entry/Vicuna-an-open-source-chatbot-impresses-GPT-4-with-90-of-the-quality-of-ChatGPT)

Discord Server : [https://discord.gg/h6kCZb72G7](https://discord.gg/h6kCZb72G7)

Twitter : [https://twitter.com/lmsysorg](https://twitter.com/lmsysorg)"
82,deeplearning,gpt-4,comments,2023-01-27 10:45:48,⭕ What People Are Missing About Microsoft’s $10B Investment In OpenAI,LesleyFair,False,0.95,116,10mhyek,https://www.reddit.com/r/deeplearning/comments/10mhyek/what_people_are_missing_about_microsofts_10b/,16,1674816348.0,"&#x200B;

[Sam Altman Might Have Just Pulled Off The Coup Of The Decade](https://preview.redd.it/sg24cw3zekea1.png?width=720&format=png&auto=webp&s=9eeae99b5e025a74a6cbe3aac7a842d2fff989a1)

Microsoft is investing $10B into OpenAI!

There is lots of frustration in the community about OpenAI not being all that open anymore. They appear to abandon their ethos of developing AI for everyone, [free](https://openai.com/blog/introducing-openai/) of economic pressures.

The fear is that OpenAI’s models are going to become fancy MS Office plugins. Gone would be the days of open research and innovation.

However, the specifics of the deal tell a different story.

To understand what is going on, we need to peek behind the curtain of the tough business of machine learning. We will find that Sam Altman might have just orchestrated the coup of the decade!

To appreciate better why there is some three-dimensional chess going on, let’s first look at Sam Altman’s backstory.

*Let’s go!*

# A Stellar Rise

Back in 2005, Sam Altman founded [Loopt](https://en.wikipedia.org/wiki/Loopt) and was part of the first-ever YC batch. He raised a total of $30M in funding, but the company failed to gain traction. Seven years into the business Loopt was basically dead in the water and had to be shut down.

Instead of caving, he managed to sell his startup for $[43M](https://golden.com/wiki/Sam_Altman-J5GKK5) to the finTech company [Green Dot](https://www.greendot.com/). Investors got their money back and he personally made $5M from the sale.

By YC standards, this was a pretty unimpressive outcome.

However, people took note that the fire between his ears was burning hotter than that of most people. So hot in fact that Paul Graham included him in his 2009 [essay](http://www.paulgraham.com/5founders.html?viewfullsite=1) about the five founders who influenced him the most.

He listed young Sam Altman next to Steve Jobs, Larry & Sergey from Google, and Paul Buchheit (creator of GMail and AdSense). He went on to describe him as a strategic mastermind whose sheer force of will was going to get him whatever he wanted.

And Sam Altman played his hand well!

He parleyed his new connections into raising $21M from Peter Thiel and others to start investing. Within four years he 10x-ed the money \[2\]. In addition, Paul Graham made him his successor as president of YC in 2014.

Within one decade of selling his first startup for $5M, he grew his net worth to a mind-bending $250M and rose to the circle of the most influential people in Silicon Valley.

Today, he is the CEO of OpenAI — one of the most exciting and impactful organizations in all of tech.

However, OpenAI — the rocket ship of AI innovation — is in dire straights.

# OpenAI is Bleeding Cash

Back in 2015, OpenAI was kickstarted with $1B in donations from famous donors such as Elon Musk.

That money is long gone.

In 2022 OpenAI is projecting a revenue of $36M. At the same time, they spent roughly $544M. Hence the company has lost >$500M over the last year alone.

This is probably not an outlier year. OpenAI is headquartered in San Francisco and has a stable of 375 employees of mostly machine learning rockstars. Hence, salaries alone probably come out to be roughly $200M p.a.

In addition to high salaries their compute costs are stupendous. Considering it cost them $4.6M to train GPT3 once, it is likely that their cloud bill is in a very healthy nine-figure range as well \[4\].

So, where does this leave them today?

Before the Microsoft investment of $10B, OpenAI had received a total of $4B over its lifetime. With $4B in funding, a burn rate of $0.5B, and eight years of company history it doesn’t take a genius to figure out that they are running low on cash.

It would be reasonable to think: OpenAI is sitting on ChatGPT and other great models. Can’t they just lease them and make a killing?

Yes and no. OpenAI is projecting a revenue of $1B for 2024. However, it is unlikely that they could pull this off without significantly increasing their costs as well.

*Here are some reasons why!*

# The Tough Business Of Machine Learning

Machine learning companies are distinct from regular software companies. On the outside they look and feel similar: people are creating products using code, but on the inside things can be very different.

To start off, machine learning companies are usually way less profitable. Their gross margins land in the 50%-60% range, much lower than those of SaaS businesses, which can be as high as 80% \[7\].

On the one hand, the massive compute requirements and thorny data management problems drive up costs.

On the other hand, the work itself can sometimes resemble consulting more than it resembles software engineering. Everyone who has worked in the field knows that training models requires deep domain knowledge and loads of manual work on data.

To illustrate the latter point, imagine the unspeakable complexity of performing content moderation on ChatGPT’s outputs. If OpenAI scales the usage of GPT in production, they will need large teams of moderators to filter and label hate speech, slurs, tutorials on killing people, you name it.

*Alright, alright, alright! Machine learning is hard.*

*OpenAI already has ChatGPT working. That’s gotta be worth something?*

# Foundation Models Might Become Commodities:

In order to monetize GPT or any of their other models, OpenAI can go two different routes.

First, they could pick one or more verticals and sell directly to consumers. They could for example become the ultimate copywriting tool and blow [Jasper](https://app.convertkit.com/campaigns/10748016/jasper.ai) or [copy.ai](https://app.convertkit.com/campaigns/10748016/copy.ai) out of the water.

This is not going to happen. Reasons for it include:

1. To support their mission of building competitive foundational AI tools, and their huge(!) burn rate, they would need to capture one or more very large verticals.
2. They fundamentally need to re-brand themselves and diverge from their original mission. This would likely scare most of the talent away.
3. They would need to build out sales and marketing teams. Such a step would fundamentally change their culture and would inevitably dilute their focus on research.

The second option OpenAI has is to keep doing what they are doing and monetize access to their models via API. Introducing a [pro version](https://www.searchenginejournal.com/openai-chatgpt-professional/476244/) of ChatGPT is a step in this direction.

This approach has its own challenges. Models like GPT do have a defensible moat. They are just large transformer models trained on very large open-source datasets.

As an example, last week Andrej Karpathy released a [video](https://www.youtube.com/watch?v=kCc8FmEb1nY) of him coding up a version of GPT in an afternoon. Nothing could stop e.g. Google, StabilityAI, or HuggingFace from open-sourcing their own GPT.

As a result GPT inference would become a common good. This would melt OpenAI’s profits down to a tiny bit of nothing.

In this scenario, they would also have a very hard time leveraging their branding to generate returns. Since companies that integrate with OpenAI’s API control the interface to the customer, they would likely end up capturing all of the value.

An argument can be made that this is a general problem of foundation models. Their high fixed costs and lack of differentiation could end up making them akin to the [steel industry](https://www.thediff.co/archive/is-the-business-of-ai-more-like-steel-or-vba/).

To sum it up:

* They don’t have a way to sustainably monetize their models.
* They do not want and probably should not build up internal sales and marketing teams to capture verticals
* They need a lot of money to keep funding their research without getting bogged down by details of specific product development

*So, what should they do?*

# The Microsoft Deal

OpenAI and Microsoft [announced](https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/) the extension of their partnership with a $10B investment, on Monday.

At this point, Microsoft will have invested a total of $13B in OpenAI. Moreover, new VCs are in on the deal by buying up shares of employees that want to take some chips off the table.

However, the astounding size is not the only extraordinary thing about this deal.

First off, the ownership will be split across three groups. Microsoft will hold 49%, VCs another 49%, and the OpenAI foundation will control the remaining 2% of shares.

If OpenAI starts making money, the profits are distributed differently across four stages:

1. First, early investors (probably Khosla Ventures and Reid Hoffman’s foundation) get their money back with interest.
2. After that Microsoft is entitled to 75% of profits until the $13B of funding is repaid
3. When the initial funding is repaid, Microsoft and the remaining VCs each get 49% of profits. This continues until another $92B and $150B are paid out to Microsoft and the VCs, respectively.
4. Once the aforementioned money is paid to investors, 100% of shares return to the foundation, which regains total control over the company. \[3\]

# What This Means

This is absolutely crazy!

OpenAI managed to solve all of its problems at once. They raised a boatload of money and have access to all the compute they need.

On top of that, they solved their distribution problem. They now have access to Microsoft’s sales teams and their models will be integrated into MS Office products.

Microsoft also benefits heavily. They can play at the forefront AI, brush up their tools, and have OpenAI as an exclusive partner to further compete in a [bitter cloud war](https://www.projectpro.io/article/aws-vs-azure-who-is-the-big-winner-in-the-cloud-war/401) against AWS.

The synergies do not stop there.

OpenAI as well as GitHub (aubsidiary of Microsoft) e. g. will likely benefit heavily from the partnership as they continue to develop[ GitHub Copilot](https://github.com/features/copilot).

The deal creates a beautiful win-win situation, but that is not even the best part.

Sam Altman and his team at OpenAI essentially managed to place a giant hedge. If OpenAI does not manage to create anything meaningful or we enter a new AI winter, Microsoft will have paid for the party.

However, if OpenAI creates something in the direction of AGI — whatever that looks like — the value of it will likely be huge.

In that case, OpenAI will quickly repay the dept to Microsoft and the foundation will control 100% of whatever was created.

*Wow!*

Whether you agree with the path OpenAI has chosen or would have preferred them to stay donation-based, you have to give it to them.

*This deal is an absolute power move!*

I look forward to the future. Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

*Thank you for reading!*

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] [https://golden.com/wiki/Sam\_Altman-J5GKK5](https://golden.com/wiki/Sam_Altman-J5GKK5)​

\[2\] [https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny](https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny)​

\[3\] [Article in Fortune magazine ](https://fortune.com/2023/01/11/structure-openai-investment-microsoft/?verification_code=DOVCVS8LIFQZOB&_ptid=%7Bkpdx%7DAAAA13NXUgHygQoKY2ZRajJmTTN6ahIQbGQ2NWZsMnMyd3loeGtvehoMRVhGQlkxN1QzMFZDIiUxODA3cnJvMGMwLTAwMDAzMWVsMzhrZzIxc2M4YjB0bmZ0Zmc0KhhzaG93T2ZmZXJXRDFSRzY0WjdXRTkxMDkwAToMT1RVVzUzRkE5UlA2Qg1PVFZLVlpGUkVaTVlNUhJ2LYIA8DIzZW55eGJhajZsWiYyYTAxOmMyMzo2NDE4OjkxMDA6NjBiYjo1NWYyOmUyMTU6NjMyZmIDZG1jaOPAtZ4GcBl4DA)​

\[4\] [https://arxiv.org/abs/2104.04473](https://arxiv.org/abs/2104.04473) Megatron NLG

\[5\] [https://www.crunchbase.com/organization/openai/company\_financials](https://www.crunchbase.com/organization/openai/company_financials)​

\[6\] Elon Musk donation [https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research](https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research)​

\[7\] [https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/](https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/)"
83,deeplearning,gpt-4,comments,2023-01-19 07:55:49,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.9,70,10fw22o,https://www.reddit.com/r/deeplearning/comments/10fw22o/gpt4_will_be_500x_smaller_than_people_think_here/,11,1674114949.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/xvpw1erngyca1.png?width=575&format=png&auto=webp&s=d7bea7c6132081f2df7c950a0989f398599d6cae)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you. At **TheDecoding** ⭕, I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
84,deeplearning,gpt-4,comments,2023-11-08 15:37:08,Start with Large Language Models (LLMs) in 2023,OnlyProggingForFun,False,0.72,11,17qo9lt,https://www.reddit.com/r/deeplearning/comments/17qo9lt/start_with_large_language_models_llms_in_2023/,11,1699457828.0,"This is a complete guide to start and improve your LLM skills in 2023 without an advanced background in the field and stay up-to-date with the latest news and state-of-the-art techniques!

The complete article: https://www.louisbouchard.ai/from-zero-to-hero-with-llms/

All the links on GitHub: https://github.com/louisfb01/start-llms 

Artificial is a fantastic field, and so are language models like GPT-4, Claude..., but it goes extremely fast. Don't miss out on the most important and exciting news by joining great communities, people, newsletters, and more you can all find in this guide!

This guide is intended for anyone with a small background in programming and machine learning. Simple python knowledge is enough to get you started. There is no specific order to follow, but a classic path would be from top to bottom. If you don't like reading books, skip it, if you don't want to follow an online course, you can skip it as well. There is not a single way to become a ""LLM expert"" and with motivation, you can absolutely achieve it."
85,deeplearning,gpt-4,comments,2023-10-26 17:59:49,Long text summarization tool how-to (700+ pages),Old_Swan8945,False,0.84,8,17h2fbk,https://www.reddit.com/r/deeplearning/comments/17h2fbk/long_text_summarization_tool_howto_700_pages/,8,1698343189.0,"Hey all I've seen a bunch of posts about summarization of long texts and seems like there's been a lot of challenges, so wanted to spread some knowledge out there about some things I've discovered as I launched my tool here ([summarize-article.co](https://summarize-article.co)) (longest text was a psych book from one of my users at 700+ pages).

The most basic problem in the summarization process is the GPT context window length, so the basic strategy I follow is the following:

1. Chunk the text into chunks that fit inside the context window
2. Recursively summarize the summaries until it becomes manageable
3. Use a long context-window model to generate the final summary using a prompt that takes the recursively-generated summaries and re-restructures the output
4. Additional prompt magic to optimize the outputs (DM me for more details :D)

Anyway, would appreciate any feedback on the results or anything you think could be improved, otherwise feel free to check it out or msg me if you want to learn more about how it works!"
86,deeplearning,gpt-4,comments,2024-01-05 08:27:31,6 ways AI can make your life easier in 2024,PoetryOne4804,False,0.33,0,18z212l,https://www.reddit.com/r/deeplearning/comments/18z212l/6_ways_ai_can_make_your_life_easier_in_2024/,8,1704443251.0,"Artificial intelligence is developing every day. ChatGPT was a game changer for millions of people, but it is not the only one. Advances in AI are coming, and they're coming FAST. Very fast. There’re so many tasks AI can help with and make this year less stressful. Let me show you these ways:

**1) Chatbots for answering questions and brainstorming**

Except ChatGPT, you can use Google Bard, SpinBot, and YouChat.

**2) AI Essay writers**

Many people use [essay writing services](https://www.reddit.com/r/deeplearning/comments/16gnuwy/best_essay_writing_services_top_5/) but not all think that AI can also help in academic writing. AI essay writers like [Textero.ai](https://Textero.ai) can be faster and generate ideas or find sources for your topic.

**3) Daily life tools**

There’re AI planners to schedule meetings and integrate with your calendars. You can also keep track of finances using PocketGuard, Wally, or Cleo.

**4) Tools for social networks**

There’re various AI tools tailored for social networks, such as Postwise for Twitter posts and Steve.ai for YouTube.

**5) Tools to improve health and fitness goals**

AI tools like Apple Watches and Fitbits can monitor your fitness and health. They can even track your sleep and offer suggestions to improve sleep quality.

**6) Tools for academic needs**

Even though some professors are against using AI while studying, students look for ways to make academic life easier. Useful tools for school life you can find here:  [ai tools for students](https://www.reddit.com/r/artificial/comments/1716t0y/ai_tools_for_students_from_ai_essay_generators_to/)

Any other tools to share? Feel free to write about them, I’m ready to try more new services."
87,deeplearning,gpt-4,comments,2023-03-05 11:10:56,LLaMA model parallelization and server configuration,ChristmasInOct,False,1.0,25,11ium8l,https://www.reddit.com/r/deeplearning/comments/11ium8l/llama_model_parallelization_and_server/,8,1678014656.0,"Hey everyone,

First of all, tldr at bottom, typed more than expected here.  

Please excuse the rather naive perspective I have here.  I've followed along with great interest, but this is not my industry.

Regardless, I have spent the past 3-4 days falling down a brutally obsessive rabbit hole, and I cannot seem to find this information.  I'm assuming it's just that I am missing context of course, and regardless of whether there is a clear answer, I'm trying to get a better understanding of this topic so that I could better appraise the situation myself.

Really I suppose I have two questions.  **The first** is regarding model parallelization.

I'm assuming this is not generic whatsoever.  What is the typical process engineers go about for designing such a pipeline?  Specifically in regards to these new LLaMA models, is something like ALPA relevant?  Deepspeed?

More importantly, what information should I be seeking to determine this myself?

This roughly segues to my **second inquiry**.

The reason I'm curious about splitting the model pipeline etc., is that I am potentially in interested in standing a server up for this.  Although I don't have much of a budget for this build (\~$30-40K is the rough top-end, but I'd be a lot happier around $20-25K), the money is there if I can genuinely satisfy my use-case.

I work at a small, but borderline manic startup working on enterprise software; 90% of the work we're doing based in the react/node ecosystem, some low-level work for backend services, and some very interesting database work that I have very little to do with.  I am a fullstack engineer that grew up playing with C++ => C#, and somehow ended up spending all of my time r/w'ing javascript.  Lol.  Anyways.

Part of our roadmap since GPT-3 and the playground were made publicly accessible, involves usage of these transformer models, and their ability to interpret natural language inputs, whether from user inputs, or scraped input values generated somewhere in a chain of requests / operations.

Seeing GPT-3 in action made me specifically realize that my estimations on this technology had been wildly off.  Seeing ChatGPT in action and uptick, the API's becoming available, has me further panicked.

Running our inference through their API has never really been an option for us.  I haven't even really looked that far into it, but bottom line the data running through our platform is all back-office, highly sensitive business information, and many have agreements explicitly restricting the movement of data to or from any cloud services, with Microsoft, Amazon, and Google all specifically mentioned.

Regardless of the reasoning for these contracts, the LLaMA release has had me obsessed over this topic in more detail than before, and whether or not I would be able to get this setup privately, for our use-case.

**To get to the actual second inquiry**:

Say I want to throw a budget rig together for this in a server cabinet.  Am I able to effectively parallelize the LLaMA model, well enough to justify going with 24GB VRAM 4090's in the rig?  Say I do so with DeepSpeed, or some of the standard model parallelization libraries.

Is the performance cost low enough to justify taking the extra compute here over 1/3 - 1/2 as many RTX6000 ADA's?

Or should I be grabbing the 48GB ADA's?

Like I said, I apologize for the naivety, I'm really looking for more information so that I can start to put this picture together better on my own.  It really isn't the easiest topic to research with how quickly things seem to move, and the giant gap between conversation depths (gamer || phd in a lot of the most interesting or niche discussions, little between).

Thank you very much for your time.

TL;DR - Any information on LLaMA model parallelization at the moment?  Will it be compatible with things like zero or alpa?  How about for throwing a rig together right now for fine-tuning and then running inference on the LLaMA models?  48GB 6000 ADA's, or 24GB 4090's?

Planning on putting it in a mostly empty 42U cabinet that also houses our primary web server and networking hardware, so if there is a sales pitch for 4090's across multiple nodes here, I do have a massive bias as the kind of nerd that finds that kind of hardware borderline erotic.

Hydro and cooling are not an issue, just usage of the budget and understanding the requirements / approach given memory limitations, and how to avoid communication bottlenecks or even balance them against raw compute.

Thanks again everyone!"
88,deeplearning,gpt-4,comments,2023-12-06 21:16:44,Platform with algorithm that creates posts,gate-app,False,0.83,4,18cehg4,https://www.reddit.com/r/deeplearning/comments/18cehg4/platform_with_algorithm_that_creates_posts/,7,1701897404.0,"So i made this thing it'll keep growing and growing.

i published my [notes](https://ablaze-mine-be9.notion.site/Algorithm-566bcebb669f49c2aedb63ffd04df3bc?pvs=4) if someones interested im looking for more serious people who believe in this, also for opinions of credible people.

&#x200B;

&#x200B;

one if the ideas:

Tiktok has a huge algorithm but the only thing it does is recommends user created content to people.  what it has is millions of users metrics and how they interact with the content which is what makes its algorithms good.  there can be a platform that collects all that useful metrics too, but uses them not only for recommender model, but also for post creation.  you can take a llm (gpt) today and make it generate posts, then collect millions of peoples interactions and how they respond to them, all the metrics and train the post creator model with it. you can easily make an actual quality content creation bot thats better than any copywriter and understands the relevant details better than anyone.  the reason the other platforms do so well is because of the insane amounts of data they monitor.  the post creation is 2 parts:  one that finds relevant stuff on the internet, tracks events, and just figures out best content to post about.  the other one is llm model that takes any piece of information and converts it into a post with title and all the other fields  both can be trained with data from users.  i am working on this idea further theres a demo with a feed of posts and a chatbot [https://gate-app.com/](https://gate-app.com/) [https://gate-app.com/posts/170145283354301509](https://gate-app.com/posts/170145283354301509) "
89,deeplearning,gpt-4,comments,2023-11-06 02:57:04,"If a conversation is not deleted, can ChatGPT-4 continuously learn and maintain the conversation state?",Turbulent_Dot_5216,False,0.62,2,17ot4d4,https://www.reddit.com/r/deeplearning/comments/17ot4d4/if_a_conversation_is_not_deleted_can_chatgpt4/,6,1699239424.0," As a beginner, I have a question for everyone: Does ChatGPT-4 forget the context if the conversation is closed or left idle for a long period, meaning it can't maintain the state of the conversation? I want ChatGPT-4 to learn legal knowledge, and in one conversation, provide it with a vast amount of legal material over a long period. Can ChatGPT-4 remember the previous legal material every time I open it, i.e., maintain the conversation state? If not, how can I make ChatGPT-4 remember previous conversations? 

 Additionally, if I do not delete a conversation and continuously feed ChatGPT-4 a large amount of legal information within that same conversation, can ChatGPT-4 achieve self-learning? That is, can it become increasingly proficient in legal matters, or regardless of how much information I provide, will ChatGPT-4 not improve? "
90,deeplearning,gpt-4,comments,2023-03-21 02:06:28,CoDev- A GPT 4.0 Virtual Developer To Generate Apps,aisaint,False,0.73,7,11x3p2u,https://www.reddit.com/r/deeplearning/comments/11x3p2u/codev_a_gpt_40_virtual_developer_to_generate_apps/,5,1679364388.0,"&#x200B;

&#x200B;

CoDev is a GPT 4.0 virtual developer prompt to help you create and refine boilerplates/apps. You can get the prompt from my GitHub link below, paste it in a new Chat session, and issue the commands (see How To Use CoDev). In this article, we will use CoDev to create a React/Typescript/MUI dashboard boiler plate

[https://medium.com/@etherlegend/codev-a-gpt-4-0-virtual-developer-to-build-app-boilerplates-34a431e779c7](https://medium.com/@etherlegend/codev-a-gpt-4-0-virtual-developer-to-build-app-boilerplates-34a431e779c7)"
91,deeplearning,gpt-4,comments,2023-12-28 21:36:23,"The best current models (Dolphin, Mixtral, Solar, Noromaid) and where to try them",Horror_Echo6243,False,0.78,5,18t59yu,https://www.reddit.com/r/deeplearning/comments/18t59yu/the_best_current_models_dolphin_mixtral_solar/,5,1703799383.0," 

I just saw a lot of people talking about this models so if you want to test them i found this websites that have all of them

\- [infermatic.ai](https://infermatic.ai/) (all of them)

\- [https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0](https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0) (for solar)

\- [https://huggingface.co/chat](https://huggingface.co/chat) (for mixtral)

Let me know if you find more, I'd like to know

And heres a little resume if you don't know what each model is for

Dolphin : An uncensored model derived from an open-source dataset, it uses instructions from FLANv2 enhanced with GPT-4 and GPT-3.5 completions​​.

Mixtral : An advanced text generation model using a Mix of Experts architecture

Solar : domain specialization and optimization. It's recognized for its high performance and efficiency

Noromaid: Storywriting and roleplay"
92,deeplearning,gpt-4,comments,2023-08-03 23:38:39,What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?,Claud1ao,False,0.67,1,15hjv2y,https://www.reddit.com/r/deeplearning/comments/15hjv2y/what_would_be_the_initial_costs_of_developing_a/,4,1691105919.0,"I was wondering if this would be super expensive or not.

The cost to develop GPT-3 was about $4 millions according to some resources online. 

Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?

Any answer is appreciated.

Thanks in advance."
93,deeplearning,gpt-4,comments,2020-06-10 20:36:33,"GPT-3: The $4,600,000 Language model",mippie_moe,False,0.76,6,h0jm54,https://lambdalabs.com/blog/demystifying-gpt-3/,4,1591821393.0,
94,deeplearning,gpt-4,comments,2023-11-06 05:28:48,"I want to create a continuously improving legal AI. My idea is to constantly feed ChatGPT-4 legal knowledge so that it keeps learning. Is this possible? If it can't be done with ChatGPT-4, is there another way to achieve this?",Turbulent_Dot_5216,False,0.36,0,17ovpmz,https://www.reddit.com/r/deeplearning/comments/17ovpmz/i_want_to_create_a_continuously_improving_legal/,3,1699248528.0," I want to create a continuously improving legal AI. My idea is to constantly feed ChatGPT-4 legal knowledge so that it keeps learning. Is this possible? If it can't be done with ChatGPT-4, is there another way to achieve this? "
95,deeplearning,gpt-4,comments,2023-11-15 18:18:23,Exploring the Frontiers of AI with Taskade: Introducing AI Agents for Deep Learning Enthusiasts 🚀,taskade,False,0.67,4,17vzwl5,https://www.reddit.com/r/deeplearning/comments/17vzwl5/exploring_the_frontiers_of_ai_with_taskade/,4,1700072303.0," 
Hey r/deeplearning,

I'm John from [Taskade](https://taskade.com), and I'm thrilled to introduce you to our latest endeavor in the realm of AI: Taskade AI Agents. This feature is a blend of practicality and deep learning innovation, and we're eager to dive into discussions with enthusiasts like you.

**Taskade AI Agents - What's Under the Hood?**

- Taskade AI Agents is all about creating, training, and deploying custom AI agents to automate and enhance productivity tasks.
- Powered by GPT-4 Turbo, it's designed for those who appreciate the intricacies of AI and deep learning technologies.

**Why It Matters for Deep Learning:**

- Our AI Agents are more than just productivity tools; they're a testament to the advancements in neural networks and AI capabilities.
- We're pushing the boundaries of how AI can be utilized in everyday task management and collaboration environments.

**We're Keen on Your Insights:**

- As deep learning enthusiasts, your perspectives on AI implementation, performance, and potential improvements are invaluable.
- How do you see AI Agents like ours fitting into the broader landscape of AI and deep learning?
- We're especially interested in your thoughts on our use of GPT-4 Turbo and how it could evolve.

**Join the Conversation:**

- Learn more about Taskade AI Agents on our [Product Hunt page](https://www.producthunt.com/posts/taskade-ai-agents).
- Dive deeper into our feature on our [Blog](https://www.taskade.com/blog/custom-ai-agents-gpts/).
- Try it out and experiment with it [here](https://www.taskade.com/ai).

Your feedback, critiques, and ideas are not just welcomed, they're needed. Help us understand the impact of Taskade AI Agents from a deep learning perspective and how we can continue to innovate in this space.

Looking forward to some insightful discussions!

Cheers,
John & the /r/Taskade Team 🤖✨"
96,deeplearning,gpt-4,comments,2023-04-02 12:37:38,[N] Software 3.0 Blog Post Release 🔥,DragonLord9,False,0.75,10,129k24i,https://www.reddit.com/r/deeplearning/comments/129k24i/n_software_30_blog_post_release/,3,1680439058.0,"Hi all, excited to share my blog post on [**Software 3.0**](https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm_campaign=post&utm_medium=web)

https://preview.redd.it/9b4hjkkhugra1.png?width=1500&format=png&auto=webp&s=e341f3ab4c3c8abb206df8daa17428a297ff61e2

The blog post offers an insightful read on the new GPT-powered programming paradigm where the new programming language is simply ""*English*"", as well as recent developments in AI.

The post was originally written before GPT-4 release, and the predictions seem to have held surprisingly well. Knowledge cutoff date 28 Feb 2023.

Please read and share!! Happy to answer any follow-ups here or on DM 😊

Tweet: [https://twitter.com/DivGarg9/status/1642229948185280521?s=20](https://twitter.com/DivGarg9/status/1642229948185280521?s=20)

Blog: [https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm\_campaign=post&utm\_medium=web](https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm_campaign=post&utm_medium=web)"
97,deeplearning,gpt-4,comments,2023-01-17 16:06:37,What nobody tells you about chatGPT and GPT-4,thomas999999,False,0.27,0,10efwno,https://www.reddit.com/r/deeplearning/comments/10efwno/what_nobody_tells_you_about_chatgpt_and_gpt4/,3,1673971597.0,i wanted to share a nice writeup my friend made about chatGPT [https://medium.com/@christian.bernhard97/what-nobody-tells-you-about-chatgpt-and-gpt-4-c8d97ae9f92d](https://medium.com/@christian.bernhard97/what-nobody-tells-you-about-chatgpt-and-gpt-4-c8d97ae9f92d)
98,deeplearning,gpt-4,comments,2023-07-31 17:01:30,Where can I keep on top of LLM developments?,gonidphoe7,False,0.67,4,15elov0,https://www.reddit.com/r/deeplearning/comments/15elov0/where_can_i_keep_on_top_of_llm_developments/,3,1690822890.0,"I'm currently attempting to broaden my knowledge of AI and ML, particularly in relation to large language models. My understanding so far is that a significant limitation of these models is their restricted context window, which appears to hinder their ability to maintain continuity of information and reason effectively about complex topics. I see models like GPT-4, Anthropic's Claude, and Mosaic ML implementing larger windows (currently 32k, 100k and 82k tokens respectively).

Can anyone confirm whether my comprehension of the context window is accurate? If not, could you explain the primary challenges that impede the reasoning and problem-solving abilities of LLMs? Additionally, what are the proposed solutions currently being explored to overcome these challenges? Finally, could anyone recommend the best way to stay on top of developments in the LLM and AI agent space?"
99,deeplearning,gpt-4,comments,2023-08-25 13:21:12,AI Meets AI: A Conversation Between GPT-4 and Google's Bard,Ubica123,False,0.82,37,160z5pp,https://www.youtube.com/watch?v=3H45IncZ7gs,3,1692969672.0,
100,deeplearning,gpt-4,comments,2023-04-25 18:02:06,"Diverse Conversations: Mental Health, Sustainable Living, and Personal Finance in a Fast-Paced World",Large_Rush9013,False,0.25,0,12yqxxl,https://www.reddit.com/r/deeplearning/comments/12yqxxl/diverse_conversations_mental_health_sustainable/,3,1682445726.0,"Hey everyone, I wanted to share some thoughts I had recently after coming across various discussions on the platform. I realized how diverse and thought-provoking this community truly is.

One topic that caught my attention was the importance of mental health, especially in today's fast-paced world. The amount of information and the undeniable impact of social media on our lives can be both enlightening and suffocating. It has become more important than ever for us to take care of our well-being and find a balance between consuming content and living in the present moment.

Another area that has drawn my curiosity is the growing discussions on sustainable living and eco-friendliness. It's inspiring how we are collectively working to create a better world for future generations. Whether it's through reducing waste, discovering alternative energy sources, or just being more aware of our surroundings, every action makes a difference.

Lastly, I've noticed an increase in discussions surrounding personal finance and investment. We are living in unprecedented times, and it's fascinating to see how the financial landscape has transformed. Whether it's cryptocurrency, passive income ideas, or strategies to achieve financial freedom, these conversations are not only interesting but educational too.

All in all, the richness of this community lies in the plethora of topics discussed and the valuable insights shared by its members. I'm grateful to be part of this and always look forward to learning something new every day.

P.S. This post was curated with the help of Moji AI, a content-writing helper using GPT-4 technology. If you're interested in learning more, check out their website at mojiai.io."
101,deeplearning,gpt-4,comments,2023-06-05 04:33:14,How Open Ai’s Andrej Karpathy Made One of the Best Tutorials in Deep Learning,0ssamaak0,False,0.92,63,141282u,https://www.reddit.com/r/deeplearning/comments/141282u/how_open_ais_andrej_karpathy_made_one_of_the_best/,3,1685939594.0,"I want you to check [my review](https://medium.com/@0ssamaak0/how-open-ais-andrej-karpathy-made-one-of-the-best-tutorials-in-deep-learning-e6b6445a2d05) on Andrej Karpathy amazing work on explaining how GPT is built

[GitHub Repo](https://github.com/0ssamaak0/Karpathy-Neural-Networks-Zero-to-Hero) for code & more details

&#x200B;

https://preview.redd.it/z204zwtzn44b1.png?width=720&format=png&auto=webp&s=095ea00991ebb295f48b70436456b1f283a50df1"
102,deeplearning,gpt-4,comments,2022-12-23 14:35:17,How to change career trajectory to NLP engineer,Creative-Milk-8266,False,0.85,13,zth8rl,https://www.reddit.com/r/deeplearning/comments/zth8rl/how_to_change_career_trajectory_to_nlp_engineer/,3,1671806117.0," A little of my background - 5 years experience in data science. Mostly related to prototyping statistical models and optimization problems, bringing them into production. Some experience in building pipeline and orchestration flow with AWS services.

I have basic understanding on Transformers, BERT, GPT. Did my first NLP Kaggle competition the first time recently.

I'd like my next job to be a NLP engineer. How should I prepare myself for it?

Here's some of the items I'm thinking

&#x200B;

1. More hands on projects I can put on resume, including integration with cloud services. Any recommendations on what kinds of projects I should pick?  
 
2. Tryout techniques of speeding up models like distilled model, dynamic shape, quantization. Anything else that would be helpful?  
 
3. Understand lower level of GPU programming knowledges. Not sure if this is helpful for me finding a NLP job. If so, what kind of things I can do to go deeper on this subject. I'm currently taking [Intro to Parallel Programming](https://classroom.udacity.com/courses/cs344) CS344 course on Udemy (highly recommend btw).  
 
4. Grind leetcode :/  
 

Please point out other important directions I missed."
103,deeplearning,gpt-4,comments,2023-09-24 01:00:34,"Exploring ""Harm Filter for LLM"" as a Research in NLP",junkim100,False,1.0,1,16qkfjr,https://www.reddit.com/r/deeplearning/comments/16qkfjr/exploring_harm_filter_for_llm_as_a_research_in_nlp/,2,1695517234.0,"I'm currently considering a research topic for my combined masters/phd program in an NLP lab. I've been particularly intrigued by the challenges posed by Large Language Models (LLMs) when it comes to generating potentially harmful or inappropriate content. Given the recent ""jailbreaks"" on LLMs, where users have tried to bypass content filters, I believe there's a pressing need to delve deeper into this area.

For my research focus, I've been referring to it as ""Harm Filter for LLM."" However, I'm unsure if there's an established term for this specific area of study. It seems to encompass techniques to prevent models from generating harmful content and strategies to defend against adversarial attempts to bypass these filters.

I came across a few resources that shed light on this topic:

* [**GitHub Repository on LLM Prompt Injection Filtering**](https://github.com/derwiki/llm-prompt-injection-filtering/blob/main/README.md)
* [**Research Paper on Evaluating Large Language Models Trained on Code**](https://arxiv.org/pdf/2307.02483.pdf)
* [**Research Paper on ChatGPT: A Chatbot based on GPT-3.5**](https://arxiv.org/abs/2305.05027)

I have a few questions for the community:

1. Do you think ""Harm Filter for LLM"" (or whatever the established term might be) is a promising research area in NLP?
2. Is there a commonly used term for this field? Could it possibly fall under a broader category like ""Explainable AI""?
3. Any suggestions on where I can delve deeper into this topic?
4. Additionally, I'm also looking for resources to strengthen my foundational knowledge in NLP. Any recommendations would be greatly appreciated!"
104,deeplearning,gpt-4,comments,2023-12-28 16:22:37,Do Large Vision-language Models Understand Charts? We found that the answer is NO!,steeveHuang,False,0.96,17,18sxs1r,https://www.reddit.com/r/deeplearning/comments/18sxs1r/do_large_visionlanguage_models_understand_charts/,2,1703780557.0,"We've just wrapped up a collaborative study with Columbia University and the University of Macau that probes into the capabilities of Large Vision-Language Models (LVLMs) when it comes to understanding and describing charts. The findings are quite startling.

Despite advancements in LVLMs, our research reveals that even the most advanced LVLMs like GPT-4V and Bard fall short. A striking 🚨**81.27%** (321/ 395) 🚨 of the captions they generated contained factual errors, misinterpreting data from charts. This suggests a significant gap in these models' ability to grasp the nuances and relationships between data points in visual representations.

🔍 Explore our findings in detail with the full paper on [Arxiv](https://arxiv.org/abs/2312.10160).

💻: Code and data are also available on [GitHub](https://github.com/khuangaf/CHOCOLATE)

&#x200B;

https://preview.redd.it/448ty01q929c1.png?width=1362&format=png&auto=webp&s=c6ce27262247ce6978ae7ff169f6fc844fda63de"
105,deeplearning,gpt-4,comments,2023-09-29 14:02:33,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.88,18,16vch0x,https://www.reddit.com/r/deeplearning/comments/16vch0x/this_week_in_ai_all_the_major_ai_developments_in/,2,1695996153.0,"1. **Meta AI** presents **Emu**, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal.
2. **Meta AI** researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks.
3. **Abacus AI** released a larger 70B version of **Giraffe**. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens\].
4. **Cerebras** and **Opentensor** released Bittensor Language Model, ‘**BTLM-3B-8K**’, a new 3 billion parameter open-source language model with an 8k context length trained on 627B tokens of SlimPajama. It outperforms models trained on hundreds of billions more tokens and achieves comparable performance to open 7B parameter models. The model needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models and is available with an Apache 2.0 license for commercial use.
5. **OpenAI** is rolling out, over the next two weeks, new voice and image capabilities in ChatGPT enabling ChatGPT to understand images, understand speech and speak. The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. .
6. **Mistral AI**, a French startup, released its first 7B-parameter model, **Mistral 7B**, which outperforms all currently available open models up to 13B parameters on all standard English and code benchmarks. Mistral 7B is released in Apache 2.0, making it usable without restrictions anywhere.
7. **Microsoft** has released **AutoGen** \- an open-source framework that enables development of LLM applications using multiple agents that can converse with each other to solve a task. Agents can operate in various modes that employ combinations of LLMs, human inputs and tools.
8. **LAION** released **LeoLM**, the first open and commercially available German foundation language model built on Llama-2
9. Researchers from **Google** and **Cornell University** present and release code for DynIBaR (Neural Dynamic Image-Based Rendering) - a novel approach that generates photorealistic renderings from complex, dynamic videos taken with mobile device cameras, overcoming fundamental limitations of prior methods and enabling new video effects.
10. **Cloudflare** launched **Workers AI** (an AI inference as a service platform), **Vectorize** (a vector Database) and **AI Gateway** with tools to cache, rate limit and observe AI deployments. Llama2 is available on Workers AI.
11. **Amazon** announced the general availability of **Bedrock**, its service that offers a choice of generative AI models from Amazon itself and third-party partners through an API.
12. **Spotify** has launched a pilot program for AI-powered voice translations of podcasts in other languages - in the podcaster’s voic. It uses OpenAI’s newly released voice generation model.
13. **Getty Images** has launched a generative AI image tool, ‘**Generative AI by Getty Images**’, that is ‘commercially‑safe’. It’s powered by Nvidia Picasso, a custom model trained exclusively using Getty’s images library.
14. **Optimus**, Tesla’s humanoid robot, can now sort objects autonomously and do yoga. Its neural network is trained fully end-to-end.
15. **Amazon** will invest up to $4 billion in Anthropic. Developers and engineers will be able to build on top of Anthropic’s models via Amazon Bedrock.
16. **Google Search** indexed shared Bard conversational links into its search results pages. Google says it is working on a fix.

&#x200B;

  
My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
106,deeplearning,gpt-4,comments,2023-12-07 05:25:34,Gemini vs. GPT-4: Google's AI Takes the Lead in Benchmarks,Damanjain,False,0.4,0,18cofmx,https://thebuzz.news/article/gemini-vs-gpt-4-in-benchmarks/11594/,2,1701926734.0,
107,deeplearning,gpt-4,comments,2023-03-16 12:48:36,Alpaca - Train Your GPT-4 for Less Than $100,deeplearningperson,False,0.43,0,11st80q,https://youtu.be/6qdzsDSduww,2,1678970916.0,
108,deeplearning,gpt-4,comments,2023-06-29 19:49:38,"Open Orca, an open sourced replication of Microsofts Orca is in development! Heres the dataset!",Alignment-Lab-AI,False,0.94,12,14mejzk,https://www.reddit.com/r/deeplearning/comments/14mejzk/open_orca_an_open_sourced_replication_of/,2,1688068178.0,"Today we are releasing a dataset that lets open source models learn to think like GPT-4!

We call this Open Orca, as a tribute to the team who has released the Orca paper describing the data collection methods we have attempted to replicate in an open-source manner for the benefit of humanity.

With this data, we expect new open source models to be developed which are smaller, faster, and smarter than ever before because were going to be the ones doing the developing!

[https://huggingface.co/datasets/Open-Orca/OpenOrca](https://huggingface.co/datasets/Open-Orca/OpenOrca)

We'd like to give special recognition to the following contributors for their significant efforts and dedication:

caseus

Eric Hartford

NanoBit

Pankaj

winddude

Rohan

[http://alignmentlab.ai/:](http://alignmentlab.ai/:)

Entropi

neverendingtoast

AtlasUnified

AutoMeta

lightningRalf

NanoBit

caseus

The Orca paper has been replicated to as fine of a degree of precision as a motley crew of ML nerds toiling for weeks could pull off (a very high degree).

We will be releasing trained Orca models as the training currently in progress completes.

The dataset is still in final cleanup, and we will continue with further augmentations beyond the base Orca data in due time.

Right now, we are testing our fifth iteration of Orca on a subset of the final data, and are just about to jump into the final stages!

Many thanks to NanoBit and Caseus, makers of Axolotl \[[https://github.com/OpenAccess-AI-Collective/axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)\] for lending us their expertise on the platform that developed and trained manticore, minotaur, and many others!

If you want to follow along, meet the devs, ask us questions, get involved, or check out our other projects, such as:

Landmark Attention

[https://twitter.com/Yampeleg's](https://twitter.com/Yampeleg's) recently announced context extension method, which outperforms rope (were going to push this one later today)

EDIT: We've been made aware that Eric Hartford, a team member who chose to depart our team yesterday after some internal discussion of our grievances, has made claims to be the sole originator of the Open Orca project and to claim the work as his own. We wish to clarify that this was a team effort from the outset, and he was one of over a dozen data scientists, machine learning engineers, and other specialists who have been involved in this project from the outset.

Eric joined the team with the mutual understanding that we were all to be treated as equals and get our due credit for involvement, as well as say in group decisions.

He made snap decisions on behalf of the team contrary to long term plans, including announcing the project publicly on his blog, and implying that he was the sole originator and project lead.

We attempted to reconcile this internally, but he chose to depart from the team.

As such, we elected to release the data publicly in advance of original plans.

We have appropriately attributed he and all other contributors, as was originally planned.

We thank Eric for his contributions to the project and wish him well on his individual endeavors.

This repo is the original repo from which the entire team had agreed to work out of and publish out of from the outset.

Eric's repo represents his duplication and augmentation of the team's collective effort, initiated after he had chosen to depart the team."
109,deeplearning,gpt-4,comments,2023-09-11 21:06:33,"Meta sets GPT-4 as the bar for its next AI model, says a new report",Nalix01,False,0.5,0,16g7dh3,https://www.reddit.com/r/deeplearning/comments/16g7dh3/meta_sets_gpt4_as_the_bar_for_its_next_ai_model/,2,1694466393.0,"Meta is reportedly planning to train a new model that it hopes will be as powerful as OpenAI’s GPT-4, by heavily investing in data centers and H100 chips. They hope the AI model will be way more powerful than Llama 2.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso).

**Meta's AI Ambitions**

* **New AI Development**: Meta is working on an AI model, which they hope to be several times more powerful than their recent model, Llama 2.
* **Accelerating Generative AI**: This initiative is spearheaded by a group established by Mark Zuckerberg earlier this year, focusing on AI tools that produce human-like expressions.
* **Expected Timeline**: Meta anticipates the commencement of training for this AI system in early 2024.

**Strategic Positioning in the AI Race**

* **Behind Rivals**: This new model is part of Zuckerberg's strategy to reposition Meta as a leading entity in the AI domain after falling behind competitors.
* **Infrastructure Development**: Meta is investing in data centers and acquiring advanced Nvidia chips (H100s) for AI training.
* **Shift from Microsoft**: While Meta's Llama 2 was integrated with Microsoft's cloud platform, Azure, the new model is intended to be trained on Meta's infrastructure.

**Open-source Approach and Implications**

* **Advocating Open-Source**: Zuckerberg's plan is to make the new AI model open-source, making it freely accessible for companies to build AI-driven tools.
* **Benefits and Risks**: Open-source AI models are favored due to their cost-effectiveness and flexibility. However, they also come with potential downsides, including legal risks and misuse for disseminating false information.
* **Concerns from Experts**: There are raised apprehensions about the unpredictability of the system and its potential vulnerabilities, emphasizing the need for transparency and control.

Sources [(WSJ](https://www.wsj.com/tech/ai/meta-is-developing-a-new-more-powerful-ai-system-as-technology-race-escalates-decf9451) and [TheVerge](https://www.theverge.com/2023/9/10/23867323/meta-new-ai-model-gpt-4-openai-chatbot-google-apple))

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,000+** **professionals** from **OpenAI, Google, Meta**…"
110,deeplearning,gpt-4,comments,2023-10-24 15:34:49,MemGPT Explained!,CShorten,False,0.96,21,17ffmuu,https://www.reddit.com/r/deeplearning/comments/17ffmuu/memgpt_explained/,2,1698161689.0,"Hey everyone! I am SUPER excited to publish a new paper summary video of MemGPT from Packer et al. at UC Berkeley!

MemGPT is a massive step forward in the evolution from naive Retrieval-Augmented Generation (RAG) to creating an OPERATING SYSTEM for LLM applications!

This works by telling the LLM about its limited input window and giving it new ""tools"" / APIs to manage its own memory. For example, the LLM processes the conversation history in a chatbot or the next paragraph in document processing and determines what is important to add to its working context.

The authors design a operating system around this concept complete with events, functions, and of a virtual context management algorithm inspired by operating system concepts such as page replacement. When the LLM determines it needs more context to answer a question, it searches into it's external context (could be recall storage (complete history of events such as dialogue in a chatbot across 4 months), or its archival storage (information such as Wikipedia entries stored in a Vector DB) -- it then parses the search results to determine what is worth adding to its working context.

The authors test MemGPT on chatbots and the experiments from Lost in the Middle, finding that this explicit memory management overcomes the problems of losing relevant information in the middle of search results!

I think there are tons of exciting implications of this work such as the intersection with the Gorilla LLMs (trying to allocate as few tokens as possible in describing a tool to an LLM), as well as this general phenomenon of connecting LLMs to Operating Systems!

Here is my review of the paper in more detail, I hope you find it useful!

[https://www.youtube.com/watch?v=nQmZmFERmrg](https://www.youtube.com/watch?v=nQmZmFERmrg)"
111,deeplearning,gpt-4,comments,2023-09-30 12:23:31,[D] How to train a seq2seq model to rephrase input text following given rules.,3Ammar404,False,0.5,0,16w5g5p,https://www.reddit.com/r/deeplearning/comments/16w5g5p/d_how_to_train_a_seq2seq_model_to_rephrase_input/,2,1696076611.0,"Hi guys,

I want to train (fine-tune) a seq2seq model to perform the task of rephrasing input following these rules :

1- always follow the pattern ""Entity Verb Entity""

2- only use simple sentences : never combine sentences

3- Don't replace existing words

4- Don't lose the overall meaning of the text or any information in it.

For example:

text = ""Project Risk Management includes the processes of conducting risk management planning, identification, analysis, response planning, response implementation, and monitoring risk on a project""

Standardized Text = ""Project Risk Management conducts risk management planning. Project Risk Management conducts risk identification. Project Risk Management conducts risk analysis. Project Risk Management plans responses. Project Risk Management implements responses. Project Risk Management monitors risk on a project.""

Using ChatGPT the results were very good, but I want to know if I can fine tune a model (BERT, T5, any LM) locally, what should be the data format for training such a model, evaluation metrics ?"
112,deeplearning,gpt-4,comments,2023-12-06 02:31:58,best current form of text generation?,ythug,False,0.75,2,18btl0p,https://www.reddit.com/r/deeplearning/comments/18btl0p/best_current_form_of_text_generation/,2,1701829918.0,"I had a project back in 2021 where I trained an RNN on my own tweets and then had it generate tweets for me.

Haven't kept up to date with NN since and am wondering what is best form of text generation out there currently.

this account (https://twitter.com/DeepLeffen), intrigued me. Says it is trained on gpt-4. I was aware you could train with your own data but it didnt cross my mind."
113,deeplearning,gpt-4,comments,2020-07-26 07:39:05,Crazy Numbers of GPT-3,alaap001,False,0.44,0,hy2vg1,https://www.reddit.com/r/deeplearning/comments/hy2vg1/crazy_numbers_of_gpt3/,2,1595749145.0,"Trained on over 285,000 CPU cores and 10,000 GPUs cluster, a lot of hype going around the latest GPT-3 model, those who are not into AI, it is the most advanced NLP algorithm to date. It learned the human-level language from over 400GB of data, costing crazy $12 million just to train it with \~175 Billion!! parameters. A typical high-end GPU would take over 350 years to train this model. As a Data Scientist, I thought why not look at how much data it took to learn human language. 

Well, here are the crazzyy numbers.

It used roughly 9 Million Hindi words,

3 Billion for German

and

4 Billion French words with 100 other languages. 

https://preview.redd.it/2b6aee0un5d51.png?width=937&format=png&auto=webp&s=3d4fa2e1b2621ae699ec1bb4a62d7cc85554c8d1

https://preview.redd.it/ec7tve0un5d51.png?width=871&format=png&auto=webp&s=9d8624d117ad4e1f41fff78f06bb30197abbd006

and all this fades away when English comes in with over 180 Billion words!! \[ For reference English has only 171,476 unique words with 20000 being used normally \]

It seems crazy how AI is being built so rapidly and now can talk like a human. Gets me excited thinking about what the future holds. 

***If you're the one who is getting started with Deep Learning then for you I created a website wherein I plan to do 100 Deep Learning Projects to help people understand the practicality of Deep Learning. You can visit*** [***https://www.aiunquote.com/***](https://www.aiunquote.com/) ***and learn deep learning by implementing,***

**#artificialintelligence** **#technology** **#AI** **#naturallanguageprocessing** **#gpt3** **#tableaupublic** **#computerscience** **#maths** **#innovation** **#datascience**"
114,deeplearning,gpt-4,comments,2023-04-12 05:21:13,Is OpenAI’s Study On The Labor Market Impacts Of AI Flawed?,LesleyFair,False,0.96,26,12jb4xz,https://www.reddit.com/r/deeplearning/comments/12jb4xz/is_openais_study_on_the_labor_market_impacts_of/,1,1681276873.0,"[Example img\_name](https://preview.redd.it/f3hrmeet1eta1.png?width=1451&format=png&auto=webp&s=20e20b142a2f88c3d495177e540f34bc8ea4312b)

We all have heard an uncountable amount of predictions about how AI will ***terk err jerbs!***

However, here we have a proper study on the topic from OpenAI and the University of Pennsylvania. They investigate how Generative Pre-trained Transformers (GPTs) could automate tasks across different occupations \[1\].

Although I’m going to discuss how the study comes with a set of “imperfections”, the findings still make me really excited. The findings suggest that machine learning is going to deliver some serious productivity gains.

People in the data science world fought tooth and nail for years to squeeze some value out of incomplete data sets from scattered sources while hand-holding people on their way toward a data-driven organization. At the same time, the media was flooded with predictions of omniscient AI right around the corner.

*Let’s dive in and take an* exciting glimpse into the future of labor markets\*!\*

# What They Did

The study looks at all US occupations. It breaks them down into tasks and assesses the possible level of for each task. They use that to estimate how much automation is possible for a given occupation.

The researchers used the [O\*NET database,](https://www.onetcenter.org/database.html) which is an occupation database specifically for the U.S. market. It lists 1,016 occupations along with its standardized descriptions of tasks.

The researchers annotated each task once manually and once using GPT-4. Thereby, each task was labeled as either somewhat (<50%) or significantly (>50%) automatable through LLMs. In their judgment, they considered both the direct “exposure” of a task to GPT as well as to a secondary GPT-powered system, e.g. LLMs integrated with image generation systems.

To reiterate, a higher “exposure” means that an occupation is more likely to get automated.

Lastly, they enriched the occupation data with wages and demographic information. This was used to determine whether e. g. high or low-paying jobs are at higher risk to be automated.

So far so good. This all sounds pretty decent. Sure, there is a lot of qualitative judgment going into their data acquisition process. However, we gotta cut them some slag. These kinds of studies always struggle to get any hard data and so far they did a good job.

However, there are a few obvious things to criticize. But before we get to that let’s look at their results.

# Key Findings

The study finds that 80% of the US workforce, across all industries, could have at least some tasks affected. Even more significantly, 19% of occupations are expected to have at least half of their tasks significantly automated!

Furthermore, they find that higher levels of automation exposure are associated with:

* Programming and writing skills
* Higher wages (contrary to previous research!)
* Higher levels of education (Bachelor’s and up)

Lower levels of exposure are associated with:

* Science and critical thinking skills
* Manual work and tasks that might potentially be done using physical robots

This is somewhat unsurprising. We of course know that LLMs will likely not increase productivity in the plumbing business. However, their findings underline again how different this wave is. In the past, simple and repetitive tasks fell prey to automation.

*This time it’s the suits!*

If we took this study at face value, many of us could start thinking about life as full-time pensioners.

But not so fast! This, like all the other studies on the topic, has a number of flaws.

# Necessary Criticism

First, let’s address the elephant in the room!

OpenAI co-authored the study. They have a vested interest in the hype around AI, both for commercial and regulatory reasons. Even if the external researchers performed their work with the utmost thoroughness and integrity, which I am sure they did, the involvement of OpenAI could have introduced an unconscious bias.

*But there’s more!*

The occupation database contains over 1000 occupations broken down into tasks. Neither GPT-4 nor the human labelers can possibly have a complete understanding of all the tasks across all occupations. Hence, their judgment about how much a certain task can be automated has to be rather hand-wavy in many cases.

Flaws in the data also arise from the GPT-based labeling itself.

The internet is flooded with countless sensationalist articles about how AI will replace jobs. It is hard to gauge whether this actually causes GPT models to be more optimistic when it comes to their own impact on society. However, it is possible and should not be neglected.

The authors do also not really distinguish between labor-augmenting and labor-displacing effects and it is hard to know what “affected by” or “exposed to LLMs” actually means. Will people be replaced or will they just be able to do more?

Last but not least, lists of tasks most likely do not capture all requirements in a given occupation. For instance ""making someone feel cared for"" can be an essential part of a job but might be neglected in such a list.

# Take-Away And Implications

GPT models have the world in a frenzy - rightfully so.

Nobody knows whether 19% of knowledge work gets heavily automated or if it is only 10%.

As the dust settles, we will begin to see how the ecosystem develops and how productivity in different industries can be increased. Time will tell whether foundational LLMs, specialized smaller models, or vertical tools built on top of APIs will be having the biggest impact.

In any case, these technologies have the potential to create unimaginable value for the world. At the same time, change rarely happens without pain. I strongly believe in human ingenuity and our ability to adapt to change. All in all, the study - flaws aside - represents an honest attempt at gauging the future.

Efforts like this and their scrutiny are our best shot at navigating the future. Well, or we all get chased out of the city by pitchforks.

Jokes aside!

What an exciting time for science and humanity!

As always, I really enjoyed making this for you and I sincerely hope you found value in it!

If you are not subscribed to the newsletter yet, [click here to sign up](https://thedecoding.net/)! I send out a thoughtful 5-minute email every week to keep you in the loop about machine learning research and the data economy.

*Thank you for reading and I see you next week ⭕!*

**References:**

\[1\] [https://arxiv.org/abs/2303.10130](https://arxiv.org/abs/2303.10130)"
115,deeplearning,gpt-4,comments,2023-11-25 16:03:32,[D] Orca-2–13B vs LLAMA-2-Chat-13B,Fit_Maintenance_2455,False,0.5,0,183mvzk,https://www.reddit.com/r/deeplearning/comments/183mvzk/d_orca213b_vs_llama2chat13b/,1,1700928212.0,"In the evolving landscape of AI, Orca emerges as a pioneering force, poised to redefine reasoning in language models. This evolution resonates with the transformative potential seen in Large Language Models (LLMs) like GPT-4 and PaLM-2, unlocking unprecedented reasoning capabilities. However, the prevailing imitation learning approach poses limitations for smaller models, leading to the emergence of Orca 2. This iteration is designed to empower smaller language models with diverse reasoning techniques, tailored strategies, and an edge across diverse tasks. Orca 2’s initial evaluations reveal promising advancements, surpassing models of similar size and even larger counterparts in reasoning-centric tasks. Yet, akin to all models, Orca 2 encounters limitations rooted in its underlying pre-trained model, emphasizing the ongoing importance of safety considerations and potential extensions for enhanced safety alignment.

link in the comment "
116,deeplearning,gpt-4,comments,2023-12-15 04:50:13,OpenAI's Next Move: ChatGPT 4.5 Upgrade in the Works? Sam Altman Clarifies,Damanjain,False,0.22,0,18is4sm,https://thebuzz.news/article/openai-chatgpt-4-5-leak/11787/,1,1702615813.0,
117,deeplearning,gpt-4,comments,2023-09-02 17:47:32,LLaVA: Bridging the Gap Between Visual and Language AI with GPT-4,OnlyProggingForFun,False,0.6,1,1688v3c,https://youtu.be/Pn1B_L_zAwI,1,1693676852.0,
118,deeplearning,gpt-4,comments,2023-03-16 00:03:09,OpenAI's GPT 4 is out and it's multimodal! What we know so far,gordicaleksa,False,0.25,0,11sdx6l,https://www.youtube.com/watch?v=FY9Nlkoq4GI&t=2s&ab_channel=AleksaGordi%C4%87-TheAIEpiphany,1,1678924989.0,
119,deeplearning,gpt-4,comments,2023-08-30 17:58:05,"Bright Eye: free mobile AI app that generates art and different forms of text (code, math answers, essays, games, ideas, and more)!(GPT-4 POWERED)",EtelsonRecomputing,False,0.29,0,165lsy9,https://www.reddit.com/r/deeplearning/comments/165lsy9/bright_eye_free_mobile_ai_app_that_generates_art/,1,1693418285.0,"
Hi all. I’m the cofounder of a startup focused on developing the AI super app called “Bright Eye”, a multipurpose AI product that generates and analyzes content.

One of its interesting use cases is helping students study, people plan, and offering general advice. 

As the title puts it, it’s capable of generating almost anything, so the use-cases in terms of productivity isn’t confined to only those above, it can apply however you see fit. We run on GPT-4, stable diffusion, and Microsoft azure cognitive services.  

Check us out below, we’re looking for advice on the functionality and design of the app (and possibly some longtime users): 

https://apps.apple.com/us/app/bright-eye/id1593932475"
120,deeplearning,gpt-4,comments,2023-04-05 15:23:45,Lifeline - Arxiv Conversational Search Assistant Demo (using ChatGPT),CommercialLynx7233,False,0.71,3,12cnu4c,https://www.reddit.com/r/deeplearning/comments/12cnu4c/lifeline_arxiv_conversational_search_assistant/,1,1680708225.0,"Hey guys,

I wanted to share a quick side project I built called [Lifeline](https://www.lifeline.dev/). [Lifeline](https://www.lifeline.dev/) is a search assistant on Arxiv Computer Science papers, leveraging ChatGPT. You can use it to find papers on specific topics, get summaries, ask questions about particular CS topics, find datasets or get similar papers. **Essentially, think of it as a conversational assistant that has knowledge about every CS paper published on Arxiv on or after 2022.**

Here are some sample questions: (Here's a [video](https://www.youtube.com/watch?v=VpFRkbKprLE) where I go through some examples)

* Are there any papers examining consciousness in recent AI systems, specifically large language models?
* What is the difference between chain of thought and augmenting language models with API calls?
* Summarize the new GPT-4 model
* Is GPT-4 better than lawyers on the bar exam? (lol...)
* What are some recent approaches for 3D object construction, from natural language?

If you want to contribute or have any questions, email me at: [rahul@lifeline.dev](mailto:rahul@lifeline.dev) .

Thank you!"
121,deeplearning,gpt-4,comments,2023-09-26 18:24:05,"OpenAI’s GPT-4 with vision still has flaws, paper reveals",Nalix01,False,0.33,0,16svoeg,https://www.reddit.com/r/deeplearning/comments/16svoeg/openais_gpt4_with_vision_still_has_flaws_paper/,1,1695752645.0,"OpenAI initially promoted GPT-4's ability to analyze and interpret images alongside text, but has since limited these features due to concerns about misuse and privacy. A recent paper sheds light on the efforts to mitigate these issues and the ongoing challenges GPT-4 faces in interpreting images accurately and responsibly.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post).

**Image Analysis Concerns**

* **Abuse and Privacy Issues:** OpenAI limited GPT-4's image features due to potential misuse and privacy violations.
* **Mitigation Efforts:** The company is working on safeguards to prevent malicious use and bias in GPT-4’s image analysis.

**Performance Issues**

* **Inaccurate Inferences:** GPT-4V can make incorrect inferences, combining text strings wrongly and missing details.
* **Identification Issues:** Struggles with identifying dangerous substances or chemicals and gives wrong medical imaging responses.

**Discrimination and Bias**

* **Misunderstood Symbols:** GPT-4V doesn't grasp the nuances of certain hate symbols.
* **Discrimination:** Shows bias against certain sexes and body types, relating responses mainly to body weight and body positivity.

[Source (Tech Crunch)](https://techcrunch.com/2023/09/26/openais-gpt-4-with-vision-still-has-flaws-paper-reveals/#:~:text=The%20paper%20reveals%20that%20GPT,facts%20in%20an%20authoritative%20tone)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **7,000+** **professionals** from **OpenAI, Google, Meta**…"
122,deeplearning,gpt-4,comments,2023-03-18 10:40:15,"Need some advice for my idea of ""Sketch to design"" project",Haghiri75,False,1.0,2,11ukow0,https://www.reddit.com/r/deeplearning/comments/11ukow0/need_some_advice_for_my_idea_of_sketch_to_design/,1,1679136015.0,"*I originally asked this question* [*here on stackoverflow*](https://stackoverflow.com/questions/75775112/need-some-advice-for-my-idea-of-sketch-to-design-project)

I have an idea of a *sketch to design* program with deep learning and computer vision. I saw the very same concept before and I believe GPT-4 is capable of doing something similar. First, I have to say that I am familiar with the computer vision procedure. I did it [before](https://haghiri75.com/en/analyzing-components-of-an-electric-circuit-with-yolov5/) and I know using YOLO algorithms might be a good idea.

Also, I have no problems developing a ""Sketch to code"" program since I can pipe my results to another AI or code generator. But I also found [Uizard](http://uizard.io) which can turn your hand-drawn sketches into ""Design"".

It made some questions in my mind which are the following:

1. Is there any language for design? Or it's just XML, HTML or SVG coded file?
2. Is there any code/design generator which is capable of turning a simple design document (like *a page with a navbar*) to HTML or SVG? and **open source** of course!

I will be thankful for your helps and comments."
123,deeplearning,gpt-4,comments,2022-08-14 10:58:04,OneFlow v0.8.0 Came Out!,Just0by,False,1.0,6,wo3o9l,https://www.reddit.com/r/deeplearning/comments/wo3o9l/oneflow_v080_came_out/,1,1660474684.0,"Hi all,

We are thrilled to announce the new release of [**OneFlow**](https://github.com/Oneflow-Inc/oneflow)**, which is a deep learning framework designed to be user-friendly, scalable and efficient.** OneFlow v0.8.0 update contains 523 commits. For the full changlog, please check out: [**https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.8.0**](https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.8.0).  


**Paper:** [https://arxiv.org/abs/2110.15032](https://arxiv.org/abs/2110.15032);  
**Code:** [https://github.com/Oneflow-Inc/oneflow](https://github.com/Oneflow-Inc/oneflow)

Welcome to install OneFlow v0.8.0 for a new user experience. Your feedbacks will be much appreciated!

Highlights and optimizations in this release:

**1. PyTorch API compatibility**

OneFlow v0.8.0 provides more and better PyTorch compatible APIs. In v0.8.0, a series of new features and interfaces that are compatible with PyTorch 1.10.0 are in place, including 68 new APIs that are aligned with PyTorch; 84 bugs are fixed to ensure better compatibility between operators and interfaces, allowing users to transfer more PyTorch models to OneFlow with just one click.

&#x200B;

**2. Wider support of global operators**

All operators support Global Tensor more widely and efficiently. Fixed 28 bugs related to Global Tensor and added 180 Global operator unit tests, making the development of distributed models with Global Tensor faster and easier.

&#x200B;

**3. Better performance**

The advanced features of Graph have been improved for better performance:

In addition to the original ZeRO-DP, ZeRO can be used in parallel with MP, 2-D, and 3-D to further reduce memory overhead.

Added a new pipeline parallelism API for Graph to simplify the configuration for pipeline parallelism and accelerate training when using pipeline parallelism and 3-D parallelism.

Added debugging features in multiple dimensions, including logical graphs, light plan physical graphs, memory analysis, and Python stack information, to further improve efficiency of Graph.debug.

The combination of OneFlow v0.8.0 and LiBai v0.2.0 enables higher computation speeds of GPT and BERT under 3-D parallelism on multiple dimensions, surpassing those of Megatron-LM with the same configurations. (For more details, see: [https://libai.readthedocs.io/en/latest/tutorials/get\_started/Benchmark.html](https://libai.readthedocs.io/en/latest/tutorials/get_started/Benchmark.html)).

&#x200B;

**4. OneEmbedding component**

OneEmbedding is an extended component specifically designed for large-scale recommender systems. It boasts excellent performance, extensibility, and flexibility.

API Documentation: [https://docs.oneflow.org/en/master/cookies/one\_embedding.html](https://docs.oneflow.org/en/master/cookies/one_embedding.html)

&#x200B;

**5. Multi-Device adaptation**

OneFlow v0.8.0 provides a neat, efficient, and easily extensible hardware abstraction layer EP (Execution Provider) to adapt to different hardware. With the introduction of the hardware abstraction layer, no modifications are needed for any module of the framework to adapt to new hardware devices, regardless of the implementation details of any underlying hardware or framework.

To make the new hardware devices work, users only need to implement a series of interfaces based on the protocols of the hardware abstraction interfaces and the status quo of the hardware devices.

EP also defines a set of basic computing interface primitives, allowing the reimplementation of kernels. Primitives provide interfaces that are more flexible than the runtime interfaces provided by EP. Different interfaces are independent of each other, and each interface represents a kind of computing capability that can be provided by a certain hardware device.

**6. Debugging tool stack**

New debug tools: OneFlow-Profiler and AutoProf.

OneFlow-Profiler is a tool used to collect performance information during framework execution. It can keep records of the execution time of operators and system components, the allocation of memory, and the corresponding input and parameters of operators. All this information helps developers find out the main source of overhead in framework execution and thus implement targeted optimization.

AutoProf is a framework for testing the performance of OneFlow and PyTorch operators. It provides an elegant and efficient method to detect the alignment between OneFlow APIs and PyTorch APIs, allowing users to conveniently compare the performance of OneFlow APIs and PyTorch APIs.

**7. Error message**

Improved error message with more details. Refactored exception handling.

&#x200B;

**8. API documentation**

Made over 20 revisions to the OneFlow API documentation, restructured the documentation based on features, and added further elaboration of modules and environment variables including OneFlow oneflow.nn.graph, oneflow.embedding, and oneflow.autograd, in addition to the general operator APIs."
124,deeplearning,gpt-4,comments,2023-12-17 22:15:54,Any idea of GPT-4 Vision architecture?,AfraidAd4094,False,0.57,1,18kstjs,https://www.reddit.com/r/deeplearning/comments/18kstjs/any_idea_of_gpt4_vision_architecture/,1,1702851354.0,"Is it a big Vision Transformer, or maybe extra feature engineering step to adapt images as an input gpt-4? Like transforming an image to a vector embedding of same dimensions as text input  


 "
125,deeplearning,gpt-4,comments,2023-03-15 01:53:32,How good is GPT-4 compared to ChatGPT?,OnlyProggingForFun,False,0.27,0,11rihli,https://youtu.be/GroMQETFXLc,1,1678845212.0,
126,deeplearning,gpt-4,comments,2023-12-06 04:07:21,[D]Unlocking Insights: Harnessing Table Extraction and Advanced Data Querying with LlamaIndex’s Pandas Query Engine,Fit_Maintenance_2455,False,1.0,1,18bvfof,https://www.reddit.com/r/deeplearning/comments/18bvfof/dunlocking_insights_harnessing_table_extraction/,0,1701835641.0,"Introducing LlamaIndex, a transformative tool that facilitates seamless interaction between your data sources and powerful language models like GPT-4. This comprehensive guide unveils a groundbreaking approach: extracting data from URLs, converting it into PDFs, extracting tables from these PDFs, and ultimately converting these tables into CSV files. LlamaIndex serves as the linchpin, enabling effortless communication and utilization of data between diverse sources and language models, revolutionizing the landscape of intelligent applications.

&#x200B;

Link: [https://medium.com/ai-advances/unlocking-insights-harnessing-table-extraction-and-advanced-data-querying-with-llamaindexs-pandas-f7200ef07771](https://medium.com/ai-advances/unlocking-insights-harnessing-table-extraction-and-advanced-data-querying-with-llamaindexs-pandas-f7200ef07771) "
127,deeplearning,gpt-4,comments,2023-10-26 14:51:06,5 Game-Changing Applications of GPT-4: No Coding Skills Required!,OnlyProggingForFun,False,0.25,0,17gy9w8,https://youtu.be/lwNy4lgDpjY,0,1698331866.0,
128,deeplearning,gpt-4,comments,2020-10-28 11:39:21,How did I get access to GPT-3 OpenAI's API? Tips are shared at 4:45 in the video! The rest of the videos explains what can GPT-3 really do and how it can help you or your company.,OnlyProggingForFun,False,0.42,0,jjm4ep,https://www.youtube.com/watch?v=Gm4AMjV8ErM,0,1603885161.0,
129,deeplearning,gpt-4,comments,2024-01-01 05:48:19,"VerificationGPT (open-source verification for GPT-4 using Brave Search, arXiv, and other APIs)",contextfund,False,1.0,2,18vq5vb,/r/contextfund/comments/18vp9hv/verificationgpt/,0,1704088099.0,
130,deeplearning,gpt-4,comments,2023-08-21 16:48:23,Gorilla: Large Language Models Connected to Massive APIs [Paper Summary Video],CShorten,False,0.67,1,15xd14p,https://www.reddit.com/r/deeplearning/comments/15xd14p/gorilla_large_language_models_connected_to/,0,1692636503.0,"Hey everyone, I am SUPER excited to present a paper summary video of ""Gorilla: Large Language Models connected to Massive APIs"" by Patil et al. 2023!  LLMs have been supercharged by connecting them with external tools. An external tool could be a search engine, code executor, calculator, calendar, email, CRM, and many others! Although GPT-4 is fairly strong at formatting API requests zero-shot (without additional training), Gorilla shows that specialized training can outperform it significantly! In addition to the accuracy performance, this is also achievable with a much cheaper 7 billion parameter model, derived by fine-tuning the Meta AI LlaMA-2 7B checkpoint!!

There are all sorts of interesting details about this paper covered in the video, from the APIBench dataset to Self-Instruct training data generation, Retrieval-Aware Training, and the miscellaneous details of Gorilla! I hope you enjoy the paper summary video! As always I am more than happy to answer any questions or discuss any ideas you have related to the content in the video!

P.S. Please stay tuned for Weaviate Gorilla! 🦍 👀

https://www.youtube.com/watch?v=LkV5DTRNxAg"
131,deeplearning,gpt-4,comments,2023-05-28 17:56:31,Essentials of Multi-modal/Visual-Language models (A video),AvvYaa,False,0.67,1,13u6ptq,https://www.reddit.com/r/deeplearning/comments/13u6ptq/essentials_of_multimodalvisuallanguage_models_a/,0,1685296591.0,"Hello people! I just uploaded a video on my Youtube covering all the major techniques and challenges for training multi-modal models that can combine multiple input sources like images, text, audio, etc to perform amazing cross-modal tasks like text-image retrieval, multimodal vector arithmetic, visual question answering, and language modelling. 

I thought it was a good time to make a video about this topic since more and more recent LLMs are moving away from text-only into visual-language domains (GPT-4, PaLM-2, etc). So in the video I cover as much as I can to provide some intuition about this area - right from basics like contrastive learning (CLIP, ImageBind), all the way to Generative language models (like Flamingo).

&#x200B;

Here is a link to the video:  
 [https://youtu.be/-llkMpNH160](https://youtu.be/-llkMpNH160)

If the above doesn’t work, maybe try this:

[https://m.youtube.com/watch?v=-llkMpNH160&feature=youtu.be](https://m.youtube.com/watch?v=-llkMpNH160&feature=youtu.be)"
132,deeplearning,gpt-4,comments,2023-03-20 06:27:48,GPT-4,Genius_feed,False,0.4,0,11wat6c,https://i.redd.it/h1ov2l5p8uoa1.jpg,0,1679293668.0,
133,deeplearning,gpt-4,comments,2023-04-07 10:58:54,Text-to-image Diffusion Models in Generative AI: A Survey,Learningforeverrrrr,False,0.91,15,12ehc2m,https://www.reddit.com/r/deeplearning/comments/12ehc2m/texttoimage_diffusion_models_in_generative_ai_a/,0,1680865134.0,"Diffusion models have become a SOTA generative modeling method for numerous content types, such as images, audio, graph, etc. As the number of articles on diffusion models has grown exponentially over the past few years, there is an increasing need for survey works to summarize them. Recognizing the existence of such works, our team has completed multiple field-specific surveys on diffusion models. We promote our works here and hope they can be helpful to researchers in relative fields: text-to-image diffusion models [\[a survey\]](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey), audio diffusion models [\[a survey\]](https://www.researchgate.net/publication/369477230_A_Survey_on_Audio_Diffusion_Models_Text_To_Speech_Synthesis_and_Enhancement_in_Generative_AI), and graph diffusion models [\[a survey\]](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material) .

In the following, we briefly summarize our survey on text-to-image diffusion models.

[Text-to-image Diffusion Models in Generative AI: A Survey](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey)

As a self-contained work, this survey starts with a brief introduction of how a basic diffusion model works for image synthesis, followed by how condition or guidance improves learning. Based on that, we present a review of state-of-the-art methods on text-conditioned image synthesis, i.e., text-to-image. We further summarize applications beyond text-to-image generation: text-guided creative generation and text-guided image editing. Beyond the progress made so far, we discuss existing challenges and promising future directions.

Moreover, we have also completed two survey works on generative AI (AIGC) [\[a survey\]](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need) and ChatGPT [\[a survey\]](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era), respectively. Interested readers may give it a look."
134,deeplearning,gpt-4,comments,2023-03-11 00:38:10,Generate READMEs Using ChatGPT,tomd_96,False,0.76,6,11o5zyl,https://www.reddit.com/r/deeplearning/comments/11o5zyl/generate_readmes_using_chatgpt/,0,1678495090.0,"&#x200B;

https://i.redd.it/k375our2a0na1.gif

&#x200B;

You can use this program I wrote to generate readmes: [https://github.com/tom-doerr/codex-readme](https://github.com/tom-doerr/codex-readme)

&#x200B;

It's far from perfect, but I now added ChatGPT and it is surprisingly good at inferring what the project is about. It often generates interesting usage examples and explains the available command line options.

&#x200B;

You probably won't yet use this for larger projects, but I think this can make sense for small projects or single scripts. Many small scripts are very useful but might never be published because of the work that is required to document and explain it. Using this AI might assist you with that.

&#x200B;

Reportedly GPT-4 is coming out next week, which probably would make it even better.

&#x200B;

What do you think?"
135,deeplearning,gpt-4,comments,2023-03-29 14:07:24,New Weaviate Podcast with Mem Co-Founder Dennis Xu!,CShorten,False,0.67,1,125p56e,https://www.reddit.com/r/deeplearning/comments/125p56e/new_weaviate_podcast_with_mem_cofounder_dennis_xu/,0,1680098844.0," I'm super excited to publish our newest Weaviate Podcast with Mem Co-Founder Dennis Xu!! Dennis is at the cutting-edge of applying the latest advancements in AI to note taking or knowledge management software. In other words, shaping the future of knowledge work itself!

Dennis explained a ton of interesting topics such as personalized embeddings and organizing your digital footprint through the Me API, of course the trending topic of how GPT-4 and recent advances in LLMs are changing things, and many more topics in what it is powering these systems!

Please check it out and let us know what you think!

https://youtu.be/RujNYB5ZE2c"
136,deeplearning,gpt-4,comments,2023-10-11 12:38:04,Weird loss behaviour with higher learning rate - LLM training,thelibrarian101,False,1.0,2,175d148,https://www.reddit.com/r/deeplearning/comments/175d148/weird_loss_behaviour_with_higher_learning_rate/,0,1697027884.0,"I'm training a large language model right now with 360M parameters. Before committing to a full run, I am trying different learning rates (with higher / lower batch sizes respectively).

I am having a hard time understanding the pattern of the 1e-4 run (red). Do you guys know what's going on?  
My plan was to go with the largest batch size possible to find better gradient approximation and hopefully converge towards a ""better"" optimum? I know GPT-2 (about the same parameter count) used 6e-4.

Config:  
lr: 1e-6, batch size: 8  
lr: 1e-5: batch size: 80  
lr: 1e-4: batch size: 800

https://preview.redd.it/fyhguv4biktb1.png?width=601&format=png&auto=webp&s=feb55c7eedcb3129029d14d36b792475b58e7b7c"
137,deeplearning,gpt-4,comments,2023-11-15 10:30:36,"GPT-4 Turbo: Die Zukunft der Künstlichen Intelligenz, entwickelt von OpenAI",Webglobic_tech,False,0.86,15,17vqtlk,https://webglobic.com/magazine/,0,1700044236.0,
138,deeplearning,gpt-4,comments,2023-05-16 12:07:13,Keras GPT Copilot (New Python Package) - Integrating an LLM copilot within the Keras model development workflow!,CourseGlum5431,False,0.56,1,13j3c2c,https://www.reddit.com/r/deeplearning/comments/13j3c2c/keras_gpt_copilot_new_python_package_integrating/,0,1684238833.0," Integrating an LLM copilot within the Keras model development workflow!

[https://github.com/fabprezja/keras-gpt-copilot](https://github.com/fabprezja/keras-gpt-copilot)

Features

* Generates copilot feedback from gathering model configuration, optimizer details, and experiment results during model development
* Interacts with OpenAI's LLMs, such as GPT-4
* Can be used with non-OpenAI LLMs to generate suggestions
* Offers options to downsample and/or smoothen validation curves to accommodate large (and/or noisy) results within the copilot prompt
* Provides flexibility in customizing the copilot prompt, allowing for the addition of extra information.
* Supports follow-up questions for extended guidance, such as requesting specific code changes based on previous recommendations"
139,deeplearning,gpt-4,comments,2023-10-04 15:06:32,Custom LLM,Relative_Winner_4588,False,1.0,2,16zpnjz,https://www.reddit.com/r/deeplearning/comments/16zpnjz/custom_llm/,0,1696431992.0,"
I'm eager to develop a Large Language Model (LLM) that emulates ChatGPT, tailored precisely to my specific dataset. While I'm aware of existing models like Private-GPT and Gpt4all, my ultimate goal is to either create a custom LLM from scratch or fine-tune a pre-existing model like BERT or GPT-7B to meet my unique requirements.

I've been closely following Andrej Karpathy's instructive lecture on building GPT-like models. However, I've noticed that the model only generated text akin to Shakespearean prose in a continuous loop instead of answering questions. I'm striving to develop an LLM that excels at answering questions based on the data I provide.

The core objectives I'm pursuing encompass:
1. Effective data preparation tailored for question-answering tasks.
2. The strategic selection of a pre-trained model, such as BERT or GPT-7B.
3. Rigorous performance evaluation, employing pertinent metrics.
4. The creation of an efficient inference system that facilitates question input and response generation.

Please guide me for this objectives or provide me some resources for the same.

DM me if you want to talk in detail."
140,deeplearning,gpt-4,comments,2023-09-28 13:34:24,First Impressions with GPT-4V(ision),zerojames_,False,0.63,2,16ug8gc,https://www.reddit.com/r/deeplearning/comments/16ug8gc/first_impressions_with_gpt4vision/,0,1695908064.0,"My colleague Piotr and I have been testing GPT-4V(ision) over the last day. We wrote up our findings, covering how GPT-4V performs on:

1. Visual question answering (VQA) across a range of domains (locations, movies, plants)
2. OCR
3. Math OCR
4. Object detection
5. And more

TL;DR: GPT-4V performed well for VQA and document OCR but struggled with OCR on real-world images and object detection (where we asked for bounding boxes).

[https://blog.roboflow.com/gpt-4-vision/](https://blog.roboflow.com/gpt-4-vision/)

I would love to hear what other people have found working with GPT-4V."
141,deeplearning,gpt-4,comments,2023-04-05 13:21:51,"New Weaviate Podcast (#42) - ChatGPT Plugin Marketplace, Alpaca Models, Semantic Search on S3, and more!",CShorten,False,0.76,2,12ck7ae,https://www.reddit.com/r/deeplearning/comments/12ck7ae/new_weaviate_podcast_42_chatgpt_plugin/,0,1680700911.0," I am beyond excited to share our latest Weaviate Podcast with Ethan Steininger! Ethan is the founder of Mixpeek and creator of Collie.ai!

Ethan began by explaining how he came into search through integrating MongoDB with the Lucene inverted index. Ethan continued explaining how his background in Sales Engineering helped him to see the recurring problems businesses are facing when trying to utilize the latest LLM and Vector Database technologies to solve their problems.

We then continued to take a tour of all sorts of topics in the AI Landscape from the impact of the ChatGPT Plugin Marketplace / New App Store for AI to the Stanford Alpaca models, the impact of LLMs for coding productivity and many more, even ending with Ethan's advice on stress management by getting into nature and our thoughts on the existential fear technologies like GPT-4 inspire in many and the implications of it on society.

I hope you enjoy the podcast, please let us know what you think!

[https://www.youtube.com/watch?v=EDPk1umuge0](https://www.youtube.com/watch?v=EDPk1umuge0)"
142,deeplearning,gpt-4,comments,2023-04-01 14:01:42,Revolutionizing Content Creation: Moji AI's Impact on Social Media and Beyond,Large_Rush9013,False,0.25,0,128nbfn,https://www.reddit.com/r/deeplearning/comments/128nbfn/revolutionizing_content_creation_moji_ais_impact/,0,1680357702.0,"Hey fellow Redditors, I recently stumbled upon a summary of an incredible new AI content tool called Moji AI, and I just had to share my thoughts about it. I think it has the potential to be a game-changer for content creators!

Moji AI is designed to make content creation easier by using the power of GPT-4 to generate text and Stable Diffusion Models to create eye-catching images. It offers icons and image assets that can significantly boost social media engagement. As a Reddit user, I'm always trying to find new ways to share content and start conversations, and I think the potential benefits of this tool are undeniable.

I've been aware of GPT-3 for a while now, and the thought of GPT-4 being a more powerful version gets me excited about what it could mean for the future of AI-generated content. The fact that Moji AI can not only generate text, but also customize images and icons, makes it seem like a must-have tool for anyone serious about making an impact on social media platforms.

The Stable Diffusion Models used by Moji AI allow it to create visually stunning images that are bound to catch the attention of users as they're scrolling through their feeds. It's not just about the text anymore - visuals are crucial in today's social media landscape, and Moji AI is tackling that aspect head-on.

I can already think of countless ways to apply Moji AI in both personal and professional projects. Imagine effortlessly creating engaging blog posts, social media posts, and digital marketing campaigns without the hassle of finding a graphic designer or a copywriter. This tool seems too good to be true!

For those of you who are interested in learning more about Moji AI and how it can elevate your content creation game, I urge you to check out their website at [mojiai.io](https://mojiai.io). I'm excited to see the applications of this tool, and I believe that it'll revolutionize how we create and share content moving forward.

Indeed, it's exciting to be part of a community that is always at the forefront of groundbreaking innovations like Moji AI! Feel free to share your thoughts and ideas about how you think Moji AI could impact the world of content creation. Let's start a conversation!"
143,deeplearning,gpt-4,comments,2023-07-25 13:44:39,Luca Beurer-Kellner on LMQL - Weaviate Podcast #59!,CShorten,False,0.84,4,1598yyk,https://www.reddit.com/r/deeplearning/comments/1598yyk/luca_beurerkellner_on_lmql_weaviate_podcast_59/,0,1690292679.0,"Hey everyone! I am beyond excited to publish our 59th Weaviate podcast with Luca Beurer-Kellner, the lead author and creator of LMQL!

LMQL is a *programming language* for LLMs, a really interesting and unique direction amongst the emerging development of LLM frameworks and tooling. I was really blown away by the elegance of the syntax, and I highly recommend checking out the LMQL playground. Not only is the LMQL playground a great way to learn LMQL particularly, it is one of the world's best visualizations of complex LLM execution, providing an interactive sandbox to explore!

We discussed many topics on the podcast from Luca's research background in Programming Languages and how that has shaped his perspectives on Constrained Sampling, the analog of LLM output nil pointer exceptions, and the effort to tame this chaos with LMQL! We also discussed how this fits into existing LLM frameworks such as our friends at LlamaIndex, LangChain, Haystack, MS Semantic Kernel, Jina AI, and others! We also discussed tool use with the Gorilla large language models and the general perspective of a master model such as GPT-4 that routes inferences to cheaper specialized models!

Finally we concluded with discussions on future directions! Luca really opened my eyes about the future of composable models and RETRO-style RAG architectures, can't wait to see that develop further!

I really hope you enjoy the podcast, as always I am more than happy to answer any questions or discuss any ideas you have related to the content in the podcast!  

https://www.youtube.com/watch?v=cuWLPHDAQ5g"
144,deeplearning,gpt-4,comments,2023-04-07 10:28:52,"Series of Surveys on ChatGPT, Generative AI (AIGC), and Diffusion Models",Learningforeverrrrr,False,0.82,9,12egmab,https://www.reddit.com/r/deeplearning/comments/12egmab/series_of_surveys_on_chatgpt_generative_ai_aigc/,0,1680863332.0,"* **A survey on ChatGPT:** [**One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era**](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era)
* **A survey on Generative AI (AIGC):** [**A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?**](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need)
* **A survey on Text-to-image diffusion models:** [**Text-to-image Diffusion Models in Generative AI: A Survey**](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey)
* **A survey on Audio diffusion models:** [**A Survey on Audio Diffusion Models: Text To Speech Synthesis and Enhancement in Generative AI**](https://www.researchgate.net/publication/369477230_A_Survey_on_Audio_Diffusion_Models_Text_To_Speech_Synthesis_and_Enhancement_in_Generative_AI)
* **A survey on Graph diffusion models:** [**A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material**](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material)

**ChatGPT goes viral.** Launched by OpenAI on November 30, 2022, ChatGPT has attracted unprecedented attention due to its powerful abilities all over the world.  It took only 5 days \[1\] and 2 months \[2\] for ChatGPT to have 1 million users and 100 million monthly users after launch, making it the fastest-growing consumer application in history. ChatGPT can be seen as the milestone for the GPT family to go viral. In academia, ChatGPT has also inspired a large number of works discussing its applications in multiple fields, with **more than 500 papers within four months** after release and **the number is still increasing rapidly.**  This brings a huge challenge for a researcher who hopes to have an overview of ChatGPT applications or hopes to start his or her journey with ChatGPT in their own field.  **To help more people keep up with the latest progress of the GPT family,** we’re glad to share a self-contained survey that not only summarizes **the recent applications** of ChatGPT and other GPT variants like GPT-4, but also introduces the **underlying techniques** and **challenges.** Please refer to the following link for the paper: [One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era).

&#x200B;

**From ChatGPT to Generative AI.**  One highlighting ability of the GPT family is that it can generate natural languages, which falls into the area of Generative AI. Apart from text, Generative AI can also generate content in other modalities, such as image, audio, and graph. More excitingly, Generative AI is able to convert data from one modality to another one, such as the text-to-image task (generating images from text). **To help readers have a better overview of Generative AI,** we provide a complete survey on underlying **techniques,** summary and development of **typical tasks in academia**, and also **industrial applications.** Please refer to the following link for the paper.  [A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need)

&#x200B;

**From Generative AI to Diffusion Models.** The prosperity of a field is always driven by the development of technology, and so is Generative AI.  Different from ChatGPT which generates text based on the transformer, **diffuson models** have greatly accelerated the development of other fields in Generative AI, such as image synthesis.  Although we provide a summary of diffusion models and typical tasks in the Generative AI survey, we cannot include detailed discussions due to paper length limitations. **For those who are interested in the technical details of diffusion models and the recent progress of their applications in Generative AI,** we provide three self-contained surveys on **how diffusion models are applied in three typical areas: Text-to-image diffusion models** (also includes related tasks such as image editing)**, Audio diffusion models** (including text to speech synthesis and enhancement), and **Graph diffusion models** (including molecule, protein and material areas). Please refer to the following links for the paper.

* [Text-to-image Diffusion Models in Generative AI: A Survey](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey)
* [A Survey on Audio Diffusion Models: Text To Speech Synthesis and Enhancement in Generative AI](https://www.researchgate.net/publication/369477230_A_Survey_on_Audio_Diffusion_Models_Text_To_Speech_Synthesis_and_Enhancement_in_Generative_AI)
* [A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material)

We hope our survey series will help people for a better understanding of ChatGPT and Generative AI, and we will update the survey regularly to include the latest progress. Please refer to the personal pages of the authors for the latest updates on surveys. If you have any suggestions or problems, please feel free to contact us.

\[1\] Greg Brockman, co-founder of OpenAI, [https://twitter.com/gdb/status/1599683104142430208?lang=en](https://twitter.com/gdb/status/1599683104142430208?lang=en)

\[2\] Reuters, [https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/](https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/)"
145,deeplearning,gpt-4,comments,2023-12-13 10:06:50,Durchbruch in der KI mit Gemini: ChatGPT 4.0 in Benchmark-Tests übertroffen!,Webglobic_tech,False,0.25,0,18hdkrs,https://webglobic.com/2023/12/12/gemini-uebertrifft-chatgpt4-0-in-benchmark-tests-ein-neuer-meilenstein-in-der-ki-entwicklung/,0,1702462010.0,
146,deeplearning,gpt-4,comments,2023-07-24 17:54:54,AI Digests: GPT-4 generated Newsletter on ArXiv Deep Learning Papers,CommercialLynx7233,False,1.0,1,158hu6c,https://www.reddit.com/r/deeplearning/comments/158hu6c/ai_digests_gpt4_generated_newsletter_on_arxiv/,0,1690221294.0,"Hey y'all,

I built a quick site called [AI Digests](https://aidigest.dev/), that uses GPT-4 to generate a newsletter summarizing the key themes/concepts discussed, in ArXiv Deep Learning (cs.LG) papers, on a daily basis. Here is last Friday's Edition: [https://aidigest.dev/edition/2023-07-22](https://aidigest.dev/edition/2023-07-22)

If you are interested, please do subscribe by submitting your email! Let me know what you guys think!"
147,deeplearning,gpt-4,comments,2023-04-25 17:53:47,"Microsoft releases SynapseMl v0.11 with support for ChatGPT, GPT-4, causal learning, and more",mhamilton723,False,0.88,24,12yqpnp,https://www.reddit.com/r/deeplearning/comments/12yqpnp/microsoft_releases_synapseml_v011_with_support/,0,1682445227.0,"Today Microsoft launched SynapseML v0.11 with support for ChatGPT, GPT-4, distributed training of huggingface and torchvision models, an ONNX Model hub integration, Causal Learning with EconML, 10x memory reductions for LightGBM, and a newly refactored integration with Vowpal Wabbit. To learn more check out our release notes and please feel give us a star if you enjoy the project!

Release Notes: [https://github.com/microsoft/SynapseML/releases/tag/v0.11.0](https://github.com/microsoft/SynapseML/releases/tag/v0.11.0)

Blog: [https://techcommunity.microsoft.com/t5/azure-synapse-analytics-blog/what-s-new-in-synapseml-v0-11/ba-p/3804919](https://techcommunity.microsoft.com/t5/azure-synapse-analytics-blog/what-s-new-in-synapseml-v0-11/ba-p/3804919)

Thank you to all the contributors in the community who made the release possible!

&#x200B;

[What's new in SynapseML v0.11](https://preview.redd.it/9pqj1mowj2wa1.png?width=4125&format=png&auto=webp&s=a358e73760c847a09cc76f2ed17dc58e15aed5ed)"
148,deeplearning,gpt-4,comments,2023-12-22 21:52:34,NeuralFlash - a flashcard-making GPT specializing in AI to help you study.,MachineScholar,False,0.67,1,18opxcs,https://www.reddit.com/r/deeplearning/comments/18opxcs/neuralflash_a_flashcardmaking_gpt_specializing_in/,0,1703281954.0,"Hey everyone. I'm a computer science student and I've been searching for the most efficient way to study ML concepts via Quizlet flashcards so I came up with a ""pipeline"" by making this custom GPT and feeding it my Markdown notes. Here's a little guide:

1. Take lecture/book notes in Markdown (I use obsidian to do this since it's free, fast, and open source)
2. Open up NeuralFlash and choose the ""Generate flashcards from my AI notes"" action.
3. Copy your entire Markdown note, paste it into NeuralFlash.
4. Copy the csv it outputs and paste it into the ""import"" area of your Quizlet flashcard set (make sure you select comma instead of tab).
5. Learn and succeed.

**Here the link to the GPT:** [**https://chat.openai.com/g/g-m4nFBaKA8-neuralflash**](https://chat.openai.com/g/g-m4nFBaKA8-neuralflash)"
149,deeplearning,gpt-4,comments,2023-04-06 07:43:06,A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?,Learningforeverrrrr,False,0.56,1,12dcnrm,https://www.reddit.com/r/deeplearning/comments/12dcnrm/a_complete_survey_on_generative_ai_aigc_is/,0,1680766986.0,"We recently completed two surveys: one on generative AI and the other on ChatGPT. Generative AI and ChatGPT are two fast-evolving research fields, and we will update the content soon, for which your feedback is appreciated (you can reach out to us through emails on the paper).

The title of this post refers to the first one, however, we put both links below.

**Link to a survey on Generative AI (AIGC):** [**A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?**](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need)

**Link to a survey on ChatGPT:** [**One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era**](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era)

The following is the **abstract** of the **survey on generative AI** with a summary **figure**.

As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to analyze and create text, images, and beyond. With such overwhelming media coverage, it is almost impossible to miss the opportunity to glimpse AIGC from a certain angle.  In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks. Impressed by the capability of the ChatGPT, many people are wondering about its limits: can GPT-5 (or other future GPT variants) help ChatGPT unify all AIGC tasks for diversified content creation? To answer this question, a comprehensive review of existing AIGC tasks is needed. As such, our work comes to fill this gap promptly by offering a first look at AIGC, ranging from its **techniques** to **applications**. Modern generative AI relies on various technical foundations, ranging from **model architecture** and **self-supervised pretraining** to **generative modeling** methods (like GAN and diffusion models). After introducing the fundamental techniques, this work focuses on the technological development of various AIGC tasks based on their output type, including **text**, **images**, **videos**, **3D content**, **etc**., which depicts the full potential of ChatGPT's future. Moreover, we summarize their significant applications in some mainstream **industries**, such as **education** and **creativity** content. Finally, we discuss the **challenges** currently faced and present an **outlook** on how generative AI might evolve in the near future.

&#x200B;

https://preview.redd.it/scbpeabnx7sa1.png?width=1356&format=png&auto=webp&s=445da6a707ceb6af75e5305137ad30dcd06c32fe

**Link to a survey on Generative AI (AIGC):** [**A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?**](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need)

**Link to a survey on ChatGPT:** [**One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era**](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era)"
150,deeplearning,gpt-4,comments,2020-06-30 19:19:50,"Training a GPT-2 from scratch in Greek-text, results in a low perplexity score of 7 after 15 epochs. Is it normal that score?",ni_klaras,False,0.67,2,hiu5eu,https://www.reddit.com/r/deeplearning/comments/hiu5eu/training_a_gpt2_from_scratch_in_greektext_results/,0,1593544790.0,"I try to train a GPT-2 from scratch in Greek with an older version of run\_language\_modeling.py ([https://github.com/huggingface/transformers/tree/master/examples/language-modeling](https://github.com/huggingface/transformers/tree/master/examples/language-modeling)) script from *HuggingFace* repo, but I get a low perplexity score of 7 after 15 epochs.

My data for train is about 4.6Gb and is constructed as 5 sentences per line. The data for the evaluation is about 450Mb constructed with the same way. Use of BPE for the encoding with a vocab of 22000 merges.

The loss and the evaluation loss seems to move normal . Even when i test it in the end for generation seems normal.

But the perplexity score is a question..."
151,deeplearning,gpt-4,comments,2024-01-24 19:24:25,~2 minute explanation of RankZephyr!,CShorten,False,0.5,0,19eosj0,https://www.reddit.com/r/deeplearning/comments/19eosj0/2_minute_explanation_of_rankzephyr/,0,1706124265.0,RankZephyr is a really cool example of labeling training data with a larger model such as GPT-4 to then fine-tune into a cheaper model (Mistral 7B)! This is a nice explanation of some of the key ideas in 2 minutes - [https://twitter.com/ecardenas300/status/1750237408459706554](https://twitter.com/ecardenas300/status/1750237408459706554).
152,deeplearning,gpt-4,comments,2023-04-10 17:02:54,Exploring the Potential and Pitfalls of Deep Learning and Machine Learning: A Reddit User's Quest for Knowledge,Large_Rush9013,False,1.0,1,12howrh,https://www.reddit.com/r/deeplearning/comments/12howrh/exploring_the_potential_and_pitfalls_of_deep/,0,1681146174.0,"As a fellow Reddit user, I couldn't help but be intrigued by some of the recent advancements and discussions surrounding deep learning and machine learning. It amazes me how much progress we've made in these fields, and the potential applications for them are seemingly endless. Although I love exploring the different areas where machine learning can have an impact, I also have some questions and would appreciate anyone's insights.

Conversely, a thought has crossed my mind regarding how these cutting-edge tools can also be used for disinformation or other negative purposes. It seems imperative that we, as a tech-savvy community, work together to ensure these tools remain positively focused and prevent them from being used to spread misinformation or other nefarious goals.

One particular area that has caught my eye is the powerful pipeline for background removal mentioned in a recent article. It utilizes the CUDA-accelerated MOG2 background segmentation algorithm and the Savant Video Analytics Framework, resulting in impressive processing speeds. I wonder, though, about the potential applications for this technology, both positive and negative.

Additionally, I came across an interesting topic on using machine learning to predict human preferences in assembly tasks. If we can successfully train robots to assist us, the implications for manufacturing, construction, and even everyday tasks could be significant. However, it begs the question of how much we should allow AI and robots to control our lives and the measures that need to be in place to ensure they remain our helpful assistants rather than our overlords.

In my quest to learn more, I stumbled upon a free deep learning course and was wondering if there are any other resources I could check out to expand my knowledge? It's crucial to comprehend the intricacies of these powerful tools to make informed decisions as a society regarding their applications and potential consequences.

I would love to hear your thoughts on the subjects and any recommendations for resources that will aid in deep learning and machine learning education. Let's work together to harness the potential of these technologies while maintaining a vigilant watch for the negative aspects that may arise.

This post was curated with the help of Moji AI, an innovative tool that utilizes GPT-4 to assist content writing. You can learn more about Moji AI by visiting their website at mojiai.io."
153,deeplearning,gpt-4,comments,2023-05-31 13:38:15,New Weaviate Podcast - Kapa AI!,CShorten,False,0.86,5,13wmkpt,https://www.reddit.com/r/deeplearning/comments/13wmkpt/new_weaviate_podcast_kapa_ai/,0,1685540295.0,"Hey everyone, I am SUPER excited to publish our 50th Weaviate Podcast with Emil and Finn from Kapa AI!

Kapa AI is one of the leading companies in taking code documentation and community question answering data, for software companies such as Weaviate, and building these Retrieval-Augmented LLM systems. I can personally vouch for the high quality of Kapa, it is an insanely productive tool for Weaviate development!  

In the podcast, we cover the A-Z on how these systems are built: 

• How long does it take to get a companies' Docs etc. into Kapa? 

• How do companies think about ingesting their community support tickets into these systems? E.g. Slack / Discourse / Forum ""whitelisting"" and so on. 

• How do Emil and Finn think about text chunking and data cleaning? 

• What is the impact of the latest trends in LLMs - status of Hallucination, Long Input Lengths (e.g. GPT-4, MosaicML MPT, Anthropic Claude), Fine-Tuning LLMs with things like LoRA? 

I think Emil and Finn have some really interesting perspectives on this stuff. Always nice to get a mix of academic perspectives, as well as people like Emil and Finn who are really building these systems, selling them to companies, and managing the cost / performance tradeoffs.

https://www.youtube.com/watch?v=cjAhve\_DopY"
154,deeplearning,gpt-4,comments,2023-04-07 08:41:41,A survey on graph diffusion models,Learningforeverrrrr,False,1.0,2,12eejpe,https://www.reddit.com/r/deeplearning/comments/12eejpe/a_survey_on_graph_diffusion_models/,0,1680856901.0,"Diffusion models have become a SOTA generative modeling method for numerous content types, such as images, audio, graph, etc. As the number of articles on diffusion models has grown exponentially over the past few years, there is an increasing need for survey works to summarize them. Recognizing the existence of such works, our team has completed multiple field-specific surveys on diffusion models. We promote our works here and hope they can be helpful to researchers in relative fields: text-to-image diffusion models [\[a survey\]](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey), audio diffusion models [\[a survey\]](https://www.researchgate.net/publication/369477230_A_Survey_on_Audio_Diffusion_Models_Text_To_Speech_Synthesis_and_Enhancement_in_Generative_AI), and graph diffusion models [\[a survey\]](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material) .

In the following, we briefly summarize our survey work on graph diffusion models.

[https://www.researchgate.net/publication/369716257\_A\_Survey\_on\_Graph\_Diffusion\_Models\_Generative\_AI\_in\_Science\_for\_Molecule\_Protein\_and\_Material](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material)

We start with a summary of the progress of graph generation before diffusion models. The diffusion models are then concisely presented and graph generation is discussed in depth from a structural and application perspective. Moreover,  the currently popular evaluation datasets and metrics are covered. Finally, we summarize the challenges and research questions still facing the research community. This survey work might be a useful guidebook for researchers who are interested in exploring the potential of diffusion models for graph generation and related tasks.

Moreover, we have also completed two survey works on generative AI (AIGC) [\[a survey\]](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need) and ChatGPT [\[a survey\]](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era), respectively. Interested readers may give it a look."
155,deeplearning,gpt-4,comments,2020-10-30 01:48:31,Generating Snort Rules using GPT2,afoteygh,False,1.0,1,jkntfp,https://www.reddit.com/r/deeplearning/comments/jkntfp/generating_snort_rules_using_gpt2/,0,1604022511.0,"Hi I have been working on Generating Snort rules using the GPT2 Transformer.

This is my thinking

1. Snort rules for a particular family of malware are quite related. that is why these malware have been classified into that family so using text generation to generate new rules should be possible (i Feel)
2. Collect Snort rules for a particular malware family. (Also collect pcap which trigger these specific rules i have obtained)
3. Clean it up by removing commented/unused rules.
4. Feed the rules to GPT2 (124M) (I chose this because i read it performs quite well in text generation )
5. Trained GPT on the dataset
6. using it to generated new rules
7. clean up the rules (syntax etc)
8. Test newly generated rules in snort with sample pcap files.

So for i have been able to generate and clean up 1000's of rules and tested them without any success!

Can anyone give me some guidance on what i am doing wrong or if my whole hypothesis and experiment is flawed."
156,deeplearning,gpt-4,comments,2023-12-12 12:10:06,[D] Crafting Visually Stunning Slides with Assistants API (GPT-4) and DALL·E-3,Fit_Maintenance_2455,False,0.5,0,18gkhbu,https://www.reddit.com/r/deeplearning/comments/18gkhbu/d_crafting_visually_stunning_slides_with/,0,1702383006.0,"In the realm of presentations, creating visually compelling slides that effectively communicate data insights is a skill coveted by professionals across diverse industries. However, the traditional process of manually constructing these slides can be a time-consuming endeavor. Enter the new Assistants API (GPT-4) and DALL·E-3, revolutionary tools that streamline the slide creation process, offering efficiency and visual finesse.

Crafting slides that capture the essence of complex data sets while maintaining audience engagement is a multifaceted challenge. It demands a blend of data interpretation, storytelling finesse, and an eye for design. Traditionally, this process involves laborious manual work, from structuring information to selecting images and formatting layouts.

&#x200B;

link: [https://medium.com/ai-advances/crafting-visually-stunning-slides-with-assistants-api-gpt-4-and-dall-e-3-f862368cec44](https://medium.com/ai-advances/crafting-visually-stunning-slides-with-assistants-api-gpt-4-and-dall-e-3-f862368cec44) "
157,deeplearning,gpt-4,comments,2024-02-06 16:30:31,XMC.dspy with Karel D'Oosterlinck - Weaviate Podcast #87!,CShorten,False,1.0,2,1akdue4,https://www.reddit.com/r/deeplearning/comments/1akdue4/xmcdspy_with_karel_doosterlinck_weaviate_podcast/,0,1707237031.0,"Hey everyone! I am BEYOND EXCITED to publish our 87th Weaviate Podcast with Karel D’Oosterlinck from the University of Ghent and Stanford NLP!

This podcast was simply amazing, I can't thank Karel enough for how much he taught me about DSPy, how to use it for Extreme Multi-Label Classification (XMC), and the applications of XMC in Biomedical NLP, Recommendation, Job Listings, and more. I am beyond grateful to have the opportunity to share this knowledge in the Weaviate podcast!

The podcast begins with an overview of Extreme Multi-Label Classification. How in the world do we prompt LLMs to categorize inputs into thousands of classes?!

To solve this, Karel has developed a novel Infer-Retrieve-Rank (IReRa) DSPy program. Infer first takes the input and outputs coarse labels for it. These coarse labels are then mapped to the thousands of classes (typically managed in ontologies) with the retrieval system and... you guessed it, Vector Embeddings! The Rank LLM component then takes the classes from the vector search and sorts them by relevance to the query.

Karel then took me through the details of the DSPy compiler! There is just so much opportunity with this from understanding how we tweak the descriptions of tasks we give to our language models, to populating the prompt with in-context learning examples. We discussed all sorts of things from model compression (e.g. can we prompt Mistral or Llama 7b to rival the performance of GPT-4 or Gemini Ultra at a *particular* task in an LLM pipeline, such as re-ranking or query writing?), diving into the latest on Teacher-Student optimization, input-dependent prompting, and so much more! We then concluded the podcast by discussing IReRa's applications for Recommendation Systems and what lead Karel to Biomedical NLP! Thanks again Karel, I learned so much from this one!

YouTube: [https://www.youtube.com/watch?v=\_ye26\_8XPcs](https://www.youtube.com/watch?v=_ye26_8XPcs)

Spotify: [https://podcasters.spotify.com/pod/show/weaviate/episodes/XMC-dspy-with-Karel-DOosterlinck---Weaviate-Podcast-87-e2fehtk](https://podcasters.spotify.com/pod/show/weaviate/episodes/XMC-dspy-with-Karel-DOosterlinck---Weaviate-Podcast-87-e2fehtk)"
158,deeplearning,gpt-4,relevance,2023-12-17 22:15:54,Any idea of GPT-4 Vision architecture?,AfraidAd4094,False,0.63,2,18kstjs,https://www.reddit.com/r/deeplearning/comments/18kstjs/any_idea_of_gpt4_vision_architecture/,1,1702851354.0,"Is it a big Vision Transformer, or maybe extra feature engineering step to adapt images as an input gpt-4? Like transforming an image to a vector embedding of same dimensions as text input  


 "
159,deeplearning,gpt-4,relevance,2023-03-20 06:27:48,GPT-4,Genius_feed,False,0.4,0,11wat6c,https://i.redd.it/h1ov2l5p8uoa1.jpg,0,1679293668.0,
160,deeplearning,gpt-4,relevance,2024-01-01 05:48:19,"VerificationGPT (open-source verification for GPT-4 using Brave Search, arXiv, and other APIs)",contextfund,False,1.0,2,18vq5vb,/r/contextfund/comments/18vp9hv/verificationgpt/,0,1704088099.0,
161,deeplearning,gpt-4,relevance,2023-04-05 01:36:40,Vicuna : an open source chatbot impresses GPT-4 with 90% of the quality of ChatGPT,Time_Key8052,False,0.95,84,12c43uu,https://www.reddit.com/r/deeplearning/comments/12c43uu/vicuna_an_open_source_chatbot_impresses_gpt4_with/,19,1680658600.0,"Vicuna : ChatGPT Alternative, Open-Source, High Quality and Low Cost 

&#x200B;

[ Relative Response Quality Assessed by GPT-4 ](https://preview.redd.it/oaj1s995zyra1.png?width=599&format=png&auto=webp&s=1fb01b017b3b8b4f9149d4b80f40c48d3a072b91)

Vicuna-13B has demonstrated competitive performance against other open-source models, such as Stanford Alpaca, by fine-tuning a LLaMA base model on user-shared conversations collected from ShareGPT.

Evaluation using GPT-4 as a judge shows that Vicuna-13B achieves more than 90% of the quality of OpenAI ChatGPT and Google Bard AI, while outperforming other models such as Meta LLaMA (Large Language Model Meta AI) and Stanford Alpaca in more than 90% of cases.

The cost of training Vicuna-13B is approximately $300.

The training and serving code, along with an online demo, are publicly available for non-commercial use.

&#x200B;

More Information : [https://gpt4chatgpt.tistory.com/entry/Vicuna-an-open-source-chatbot-impresses-GPT-4-with-90-of-the-quality-of-ChatGPT](https://gpt4chatgpt.tistory.com/entry/Vicuna-an-open-source-chatbot-impresses-GPT-4-with-90-of-the-quality-of-ChatGPT)

Discord Server : [https://discord.gg/h6kCZb72G7](https://discord.gg/h6kCZb72G7)

Twitter : [https://twitter.com/lmsysorg](https://twitter.com/lmsysorg)"
162,deeplearning,gpt-4,relevance,2023-11-15 10:30:36,"GPT-4 Turbo: Die Zukunft der Künstlichen Intelligenz, entwickelt von OpenAI",Webglobic_tech,False,0.86,15,17vqtlk,https://webglobic.com/magazine/,0,1700044236.0,
163,deeplearning,gpt-4,relevance,2023-08-25 13:21:12,AI Meets AI: A Conversation Between GPT-4 and Google's Bard,Ubica123,False,0.82,35,160z5pp,https://www.youtube.com/watch?v=3H45IncZ7gs,3,1692969672.0,
164,deeplearning,gpt-4,relevance,2023-03-15 01:53:32,How good is GPT-4 compared to ChatGPT?,OnlyProggingForFun,False,0.27,0,11rihli,https://youtu.be/GroMQETFXLc,1,1678845212.0,
165,deeplearning,gpt-4,relevance,2023-09-26 18:24:05,"OpenAI’s GPT-4 with vision still has flaws, paper reveals",Nalix01,False,0.33,0,16svoeg,https://www.reddit.com/r/deeplearning/comments/16svoeg/openais_gpt4_with_vision_still_has_flaws_paper/,1,1695752645.0,"OpenAI initially promoted GPT-4's ability to analyze and interpret images alongside text, but has since limited these features due to concerns about misuse and privacy. A recent paper sheds light on the efforts to mitigate these issues and the ongoing challenges GPT-4 faces in interpreting images accurately and responsibly.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post).

**Image Analysis Concerns**

* **Abuse and Privacy Issues:** OpenAI limited GPT-4's image features due to potential misuse and privacy violations.
* **Mitigation Efforts:** The company is working on safeguards to prevent malicious use and bias in GPT-4’s image analysis.

**Performance Issues**

* **Inaccurate Inferences:** GPT-4V can make incorrect inferences, combining text strings wrongly and missing details.
* **Identification Issues:** Struggles with identifying dangerous substances or chemicals and gives wrong medical imaging responses.

**Discrimination and Bias**

* **Misunderstood Symbols:** GPT-4V doesn't grasp the nuances of certain hate symbols.
* **Discrimination:** Shows bias against certain sexes and body types, relating responses mainly to body weight and body positivity.

[Source (Tech Crunch)](https://techcrunch.com/2023/09/26/openais-gpt-4-with-vision-still-has-flaws-paper-reveals/#:~:text=The%20paper%20reveals%20that%20GPT,facts%20in%20an%20authoritative%20tone)

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso?utm_source=reddit&utm_medium=social&utm_campaign=post) that summarizes the best AI/tech news from 50+ media. It’s already being read by **7,000+** **professionals** from **OpenAI, Google, Meta**…"
166,deeplearning,gpt-4,relevance,2023-01-17 16:06:37,What nobody tells you about chatGPT and GPT-4,thomas999999,False,0.25,0,10efwno,https://www.reddit.com/r/deeplearning/comments/10efwno/what_nobody_tells_you_about_chatgpt_and_gpt4/,3,1673971597.0,i wanted to share a nice writeup my friend made about chatGPT [https://medium.com/@christian.bernhard97/what-nobody-tells-you-about-chatgpt-and-gpt-4-c8d97ae9f92d](https://medium.com/@christian.bernhard97/what-nobody-tells-you-about-chatgpt-and-gpt-4-c8d97ae9f92d)
167,deeplearning,gpt-4,relevance,2023-09-02 17:47:32,LLaVA: Bridging the Gap Between Visual and Language AI with GPT-4,OnlyProggingForFun,False,0.6,1,1688v3c,https://youtu.be/Pn1B_L_zAwI,1,1693676852.0,
168,deeplearning,gpt-4,relevance,2023-01-19 07:55:49,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.89,69,10fw22o,https://www.reddit.com/r/deeplearning/comments/10fw22o/gpt4_will_be_500x_smaller_than_people_think_here/,11,1674114949.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/xvpw1erngyca1.png?width=575&format=png&auto=webp&s=d7bea7c6132081f2df7c950a0989f398599d6cae)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you. At **TheDecoding** ⭕, I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
169,deeplearning,gpt-4,relevance,2023-07-24 17:54:54,AI Digests: GPT-4 generated Newsletter on ArXiv Deep Learning Papers,CommercialLynx7233,False,1.0,1,158hu6c,https://www.reddit.com/r/deeplearning/comments/158hu6c/ai_digests_gpt4_generated_newsletter_on_arxiv/,0,1690221294.0,"Hey y'all,

I built a quick site called [AI Digests](https://aidigest.dev/), that uses GPT-4 to generate a newsletter summarizing the key themes/concepts discussed, in ArXiv Deep Learning (cs.LG) papers, on a daily basis. Here is last Friday's Edition: [https://aidigest.dev/edition/2023-07-22](https://aidigest.dev/edition/2023-07-22)

If you are interested, please do subscribe by submitting your email! Let me know what you guys think!"
170,deeplearning,gpt-4,relevance,2023-09-11 21:06:33,"Meta sets GPT-4 as the bar for its next AI model, says a new report",Nalix01,False,0.5,0,16g7dh3,https://www.reddit.com/r/deeplearning/comments/16g7dh3/meta_sets_gpt4_as_the_bar_for_its_next_ai_model/,2,1694466393.0,"Meta is reportedly planning to train a new model that it hopes will be as powerful as OpenAI’s GPT-4, by heavily investing in data centers and H100 chips. They hope the AI model will be way more powerful than Llama 2.

If you want to stay ahead of the curve in AI and tech, [look here first](https://dupple.com/techpresso).

**Meta's AI Ambitions**

* **New AI Development**: Meta is working on an AI model, which they hope to be several times more powerful than their recent model, Llama 2.
* **Accelerating Generative AI**: This initiative is spearheaded by a group established by Mark Zuckerberg earlier this year, focusing on AI tools that produce human-like expressions.
* **Expected Timeline**: Meta anticipates the commencement of training for this AI system in early 2024.

**Strategic Positioning in the AI Race**

* **Behind Rivals**: This new model is part of Zuckerberg's strategy to reposition Meta as a leading entity in the AI domain after falling behind competitors.
* **Infrastructure Development**: Meta is investing in data centers and acquiring advanced Nvidia chips (H100s) for AI training.
* **Shift from Microsoft**: While Meta's Llama 2 was integrated with Microsoft's cloud platform, Azure, the new model is intended to be trained on Meta's infrastructure.

**Open-source Approach and Implications**

* **Advocating Open-Source**: Zuckerberg's plan is to make the new AI model open-source, making it freely accessible for companies to build AI-driven tools.
* **Benefits and Risks**: Open-source AI models are favored due to their cost-effectiveness and flexibility. However, they also come with potential downsides, including legal risks and misuse for disseminating false information.
* **Concerns from Experts**: There are raised apprehensions about the unpredictability of the system and its potential vulnerabilities, emphasizing the need for transparency and control.

Sources [(WSJ](https://www.wsj.com/tech/ai/meta-is-developing-a-new-more-powerful-ai-system-as-technology-race-escalates-decf9451) and [TheVerge](https://www.theverge.com/2023/9/10/23867323/meta-new-ai-model-gpt-4-openai-chatbot-google-apple))

**PS:** **If you enjoyed this post**, you’ll love my [ML-powered newsletter](https://dupple.com/techpresso) that summarizes the best AI/tech news from 50+ media. It’s already being read by **6,000+** **professionals** from **OpenAI, Google, Meta**…"
171,deeplearning,gpt-4,relevance,2023-03-16 12:48:36,Alpaca - Train Your GPT-4 for Less Than $100,deeplearningperson,False,0.4,0,11st80q,https://youtu.be/6qdzsDSduww,2,1678970916.0,
172,deeplearning,gpt-4,relevance,2023-04-06 07:43:06,A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?,Learningforeverrrrr,False,0.5,0,12dcnrm,https://www.reddit.com/r/deeplearning/comments/12dcnrm/a_complete_survey_on_generative_ai_aigc_is/,0,1680766986.0,"We recently completed two surveys: one on generative AI and the other on ChatGPT. Generative AI and ChatGPT are two fast-evolving research fields, and we will update the content soon, for which your feedback is appreciated (you can reach out to us through emails on the paper).

The title of this post refers to the first one, however, we put both links below.

**Link to a survey on Generative AI (AIGC):** [**A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?**](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need)

**Link to a survey on ChatGPT:** [**One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era**](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era)

The following is the **abstract** of the **survey on generative AI** with a summary **figure**.

As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to analyze and create text, images, and beyond. With such overwhelming media coverage, it is almost impossible to miss the opportunity to glimpse AIGC from a certain angle.  In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks. Impressed by the capability of the ChatGPT, many people are wondering about its limits: can GPT-5 (or other future GPT variants) help ChatGPT unify all AIGC tasks for diversified content creation? To answer this question, a comprehensive review of existing AIGC tasks is needed. As such, our work comes to fill this gap promptly by offering a first look at AIGC, ranging from its **techniques** to **applications**. Modern generative AI relies on various technical foundations, ranging from **model architecture** and **self-supervised pretraining** to **generative modeling** methods (like GAN and diffusion models). After introducing the fundamental techniques, this work focuses on the technological development of various AIGC tasks based on their output type, including **text**, **images**, **videos**, **3D content**, **etc**., which depicts the full potential of ChatGPT's future. Moreover, we summarize their significant applications in some mainstream **industries**, such as **education** and **creativity** content. Finally, we discuss the **challenges** currently faced and present an **outlook** on how generative AI might evolve in the near future.

&#x200B;

https://preview.redd.it/scbpeabnx7sa1.png?width=1356&format=png&auto=webp&s=445da6a707ceb6af75e5305137ad30dcd06c32fe

**Link to a survey on Generative AI (AIGC):** [**A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?**](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need)

**Link to a survey on ChatGPT:** [**One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era**](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era)"
173,deeplearning,gpt-4,relevance,2023-12-07 05:25:34,Gemini vs. GPT-4: Google's AI Takes the Lead in Benchmarks,Damanjain,False,0.44,0,18cofmx,https://thebuzz.news/article/gemini-vs-gpt-4-in-benchmarks/11594/,2,1701926734.0,
174,deeplearning,gpt-4,relevance,2023-10-26 14:51:06,5 Game-Changing Applications of GPT-4: No Coding Skills Required!,OnlyProggingForFun,False,0.25,0,17gy9w8,https://youtu.be/lwNy4lgDpjY,0,1698331866.0,
175,deeplearning,gpt-4,relevance,2023-12-13 10:06:50,Durchbruch in der KI mit Gemini: ChatGPT 4.0 in Benchmark-Tests übertroffen!,Webglobic_tech,False,0.25,0,18hdkrs,https://webglobic.com/2023/12/12/gemini-uebertrifft-chatgpt4-0-in-benchmark-tests-ein-neuer-meilenstein-in-der-ki-entwicklung/,0,1702462010.0,
176,deeplearning,gpt-4,relevance,2023-12-12 12:10:06,[D] Crafting Visually Stunning Slides with Assistants API (GPT-4) and DALL·E-3,Fit_Maintenance_2455,False,0.5,0,18gkhbu,https://www.reddit.com/r/deeplearning/comments/18gkhbu/d_crafting_visually_stunning_slides_with/,0,1702383006.0,"In the realm of presentations, creating visually compelling slides that effectively communicate data insights is a skill coveted by professionals across diverse industries. However, the traditional process of manually constructing these slides can be a time-consuming endeavor. Enter the new Assistants API (GPT-4) and DALL·E-3, revolutionary tools that streamline the slide creation process, offering efficiency and visual finesse.

Crafting slides that capture the essence of complex data sets while maintaining audience engagement is a multifaceted challenge. It demands a blend of data interpretation, storytelling finesse, and an eye for design. Traditionally, this process involves laborious manual work, from structuring information to selecting images and formatting layouts.

&#x200B;

link: [https://medium.com/ai-advances/crafting-visually-stunning-slides-with-assistants-api-gpt-4-and-dall-e-3-f862368cec44](https://medium.com/ai-advances/crafting-visually-stunning-slides-with-assistants-api-gpt-4-and-dall-e-3-f862368cec44) "
177,deeplearning,gpt-4,relevance,2024-01-24 19:24:25,~2 minute explanation of RankZephyr!,CShorten,False,0.5,0,19eosj0,https://www.reddit.com/r/deeplearning/comments/19eosj0/2_minute_explanation_of_rankzephyr/,0,1706124265.0,RankZephyr is a really cool example of labeling training data with a larger model such as GPT-4 to then fine-tune into a cheaper model (Mistral 7B)! This is a nice explanation of some of the key ideas in 2 minutes - [https://twitter.com/ecardenas300/status/1750237408459706554](https://twitter.com/ecardenas300/status/1750237408459706554).
178,deeplearning,gpt-4,relevance,2023-12-15 04:50:13,OpenAI's Next Move: ChatGPT 4.5 Upgrade in the Works? Sam Altman Clarifies,Damanjain,False,0.13,0,18is4sm,https://thebuzz.news/article/openai-chatgpt-4-5-leak/11787/,1,1702615813.0,
179,deeplearning,gpt-4,relevance,2023-04-25 17:53:47,"Microsoft releases SynapseMl v0.11 with support for ChatGPT, GPT-4, causal learning, and more",mhamilton723,False,0.9,24,12yqpnp,https://www.reddit.com/r/deeplearning/comments/12yqpnp/microsoft_releases_synapseml_v011_with_support/,0,1682445227.0,"Today Microsoft launched SynapseML v0.11 with support for ChatGPT, GPT-4, distributed training of huggingface and torchvision models, an ONNX Model hub integration, Causal Learning with EconML, 10x memory reductions for LightGBM, and a newly refactored integration with Vowpal Wabbit. To learn more check out our release notes and please feel give us a star if you enjoy the project!

Release Notes: [https://github.com/microsoft/SynapseML/releases/tag/v0.11.0](https://github.com/microsoft/SynapseML/releases/tag/v0.11.0)

Blog: [https://techcommunity.microsoft.com/t5/azure-synapse-analytics-blog/what-s-new-in-synapseml-v0-11/ba-p/3804919](https://techcommunity.microsoft.com/t5/azure-synapse-analytics-blog/what-s-new-in-synapseml-v0-11/ba-p/3804919)

Thank you to all the contributors in the community who made the release possible!

&#x200B;

[What's new in SynapseML v0.11](https://preview.redd.it/9pqj1mowj2wa1.png?width=4125&format=png&auto=webp&s=a358e73760c847a09cc76f2ed17dc58e15aed5ed)"
180,deeplearning,gpt-4,relevance,2023-11-06 02:57:04,"If a conversation is not deleted, can ChatGPT-4 continuously learn and maintain the conversation state?",Turbulent_Dot_5216,False,0.57,1,17ot4d4,https://www.reddit.com/r/deeplearning/comments/17ot4d4/if_a_conversation_is_not_deleted_can_chatgpt4/,6,1699239424.0," As a beginner, I have a question for everyone: Does ChatGPT-4 forget the context if the conversation is closed or left idle for a long period, meaning it can't maintain the state of the conversation? I want ChatGPT-4 to learn legal knowledge, and in one conversation, provide it with a vast amount of legal material over a long period. Can ChatGPT-4 remember the previous legal material every time I open it, i.e., maintain the conversation state? If not, how can I make ChatGPT-4 remember previous conversations? 

 Additionally, if I do not delete a conversation and continuously feed ChatGPT-4 a large amount of legal information within that same conversation, can ChatGPT-4 achieve self-learning? That is, can it become increasingly proficient in legal matters, or regardless of how much information I provide, will ChatGPT-4 not improve? "
181,deeplearning,gpt-4,relevance,2023-11-06 05:28:48,"I want to create a continuously improving legal AI. My idea is to constantly feed ChatGPT-4 legal knowledge so that it keeps learning. Is this possible? If it can't be done with ChatGPT-4, is there another way to achieve this?",Turbulent_Dot_5216,False,0.27,0,17ovpmz,https://www.reddit.com/r/deeplearning/comments/17ovpmz/i_want_to_create_a_continuously_improving_legal/,3,1699248528.0," I want to create a continuously improving legal AI. My idea is to constantly feed ChatGPT-4 legal knowledge so that it keeps learning. Is this possible? If it can't be done with ChatGPT-4, is there another way to achieve this? "
182,deeplearning,gpt-4,relevance,2023-11-15 18:18:23,Exploring the Frontiers of AI with Taskade: Introducing AI Agents for Deep Learning Enthusiasts 🚀,taskade,False,0.76,4,17vzwl5,https://www.reddit.com/r/deeplearning/comments/17vzwl5/exploring_the_frontiers_of_ai_with_taskade/,4,1700072303.0," 
Hey r/deeplearning,

I'm John from [Taskade](https://taskade.com), and I'm thrilled to introduce you to our latest endeavor in the realm of AI: Taskade AI Agents. This feature is a blend of practicality and deep learning innovation, and we're eager to dive into discussions with enthusiasts like you.

**Taskade AI Agents - What's Under the Hood?**

- Taskade AI Agents is all about creating, training, and deploying custom AI agents to automate and enhance productivity tasks.
- Powered by GPT-4 Turbo, it's designed for those who appreciate the intricacies of AI and deep learning technologies.

**Why It Matters for Deep Learning:**

- Our AI Agents are more than just productivity tools; they're a testament to the advancements in neural networks and AI capabilities.
- We're pushing the boundaries of how AI can be utilized in everyday task management and collaboration environments.

**We're Keen on Your Insights:**

- As deep learning enthusiasts, your perspectives on AI implementation, performance, and potential improvements are invaluable.
- How do you see AI Agents like ours fitting into the broader landscape of AI and deep learning?
- We're especially interested in your thoughts on our use of GPT-4 Turbo and how it could evolve.

**Join the Conversation:**

- Learn more about Taskade AI Agents on our [Product Hunt page](https://www.producthunt.com/posts/taskade-ai-agents).
- Dive deeper into our feature on our [Blog](https://www.taskade.com/blog/custom-ai-agents-gpts/).
- Try it out and experiment with it [here](https://www.taskade.com/ai).

Your feedback, critiques, and ideas are not just welcomed, they're needed. Help us understand the impact of Taskade AI Agents from a deep learning perspective and how we can continue to innovate in this space.

Looking forward to some insightful discussions!

Cheers,
John & the /r/Taskade Team 🤖✨"
183,deeplearning,gpt-4,relevance,2023-12-28 21:36:23,"The best current models (Dolphin, Mixtral, Solar, Noromaid) and where to try them",Horror_Echo6243,False,0.88,6,18t59yu,https://www.reddit.com/r/deeplearning/comments/18t59yu/the_best_current_models_dolphin_mixtral_solar/,5,1703799383.0," 

I just saw a lot of people talking about this models so if you want to test them i found this websites that have all of them

\- [infermatic.ai](https://infermatic.ai/) (all of them)

\- [https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0](https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0) (for solar)

\- [https://huggingface.co/chat](https://huggingface.co/chat) (for mixtral)

Let me know if you find more, I'd like to know

And heres a little resume if you don't know what each model is for

Dolphin : An uncensored model derived from an open-source dataset, it uses instructions from FLANv2 enhanced with GPT-4 and GPT-3.5 completions​​.

Mixtral : An advanced text generation model using a Mix of Experts architecture

Solar : domain specialization and optimization. It's recognized for its high performance and efficiency

Noromaid: Storywriting and roleplay"
184,deeplearning,gpt-4,relevance,2023-03-21 02:06:28,CoDev- A GPT 4.0 Virtual Developer To Generate Apps,aisaint,False,0.73,7,11x3p2u,https://www.reddit.com/r/deeplearning/comments/11x3p2u/codev_a_gpt_40_virtual_developer_to_generate_apps/,5,1679364388.0,"&#x200B;

&#x200B;

CoDev is a GPT 4.0 virtual developer prompt to help you create and refine boilerplates/apps. You can get the prompt from my GitHub link below, paste it in a new Chat session, and issue the commands (see How To Use CoDev). In this article, we will use CoDev to create a React/Typescript/MUI dashboard boiler plate

[https://medium.com/@etherlegend/codev-a-gpt-4-0-virtual-developer-to-build-app-boilerplates-34a431e779c7](https://medium.com/@etherlegend/codev-a-gpt-4-0-virtual-developer-to-build-app-boilerplates-34a431e779c7)"
185,deeplearning,gpt-4,relevance,2023-04-05 15:23:45,Lifeline - Arxiv Conversational Search Assistant Demo (using ChatGPT),CommercialLynx7233,False,0.75,4,12cnu4c,https://www.reddit.com/r/deeplearning/comments/12cnu4c/lifeline_arxiv_conversational_search_assistant/,1,1680708225.0,"Hey guys,

I wanted to share a quick side project I built called [Lifeline](https://www.lifeline.dev/). [Lifeline](https://www.lifeline.dev/) is a search assistant on Arxiv Computer Science papers, leveraging ChatGPT. You can use it to find papers on specific topics, get summaries, ask questions about particular CS topics, find datasets or get similar papers. **Essentially, think of it as a conversational assistant that has knowledge about every CS paper published on Arxiv on or after 2022.**

Here are some sample questions: (Here's a [video](https://www.youtube.com/watch?v=VpFRkbKprLE) where I go through some examples)

* Are there any papers examining consciousness in recent AI systems, specifically large language models?
* What is the difference between chain of thought and augmenting language models with API calls?
* Summarize the new GPT-4 model
* Is GPT-4 better than lawyers on the bar exam? (lol...)
* What are some recent approaches for 3D object construction, from natural language?

If you want to contribute or have any questions, email me at: [rahul@lifeline.dev](mailto:rahul@lifeline.dev) .

Thank you!"
186,deeplearning,gpt-4,relevance,2023-03-16 00:03:09,OpenAI's GPT 4 is out and it's multimodal! What we know so far,gordicaleksa,False,0.29,0,11sdx6l,https://www.youtube.com/watch?v=FY9Nlkoq4GI&t=2s&ab_channel=AleksaGordi%C4%87-TheAIEpiphany,1,1678924989.0,
187,deeplearning,gpt-4,relevance,2023-11-25 16:03:32,[D] Orca-2–13B vs LLAMA-2-Chat-13B,Fit_Maintenance_2455,False,0.5,0,183mvzk,https://www.reddit.com/r/deeplearning/comments/183mvzk/d_orca213b_vs_llama2chat13b/,1,1700928212.0,"In the evolving landscape of AI, Orca emerges as a pioneering force, poised to redefine reasoning in language models. This evolution resonates with the transformative potential seen in Large Language Models (LLMs) like GPT-4 and PaLM-2, unlocking unprecedented reasoning capabilities. However, the prevailing imitation learning approach poses limitations for smaller models, leading to the emergence of Orca 2. This iteration is designed to empower smaller language models with diverse reasoning techniques, tailored strategies, and an edge across diverse tasks. Orca 2’s initial evaluations reveal promising advancements, surpassing models of similar size and even larger counterparts in reasoning-centric tasks. Yet, akin to all models, Orca 2 encounters limitations rooted in its underlying pre-trained model, emphasizing the ongoing importance of safety considerations and potential extensions for enhanced safety alignment.

link in the comment "
188,deeplearning,gpt-4,relevance,2023-05-16 12:07:13,Keras GPT Copilot (New Python Package) - Integrating an LLM copilot within the Keras model development workflow!,CourseGlum5431,False,0.62,2,13j3c2c,https://www.reddit.com/r/deeplearning/comments/13j3c2c/keras_gpt_copilot_new_python_package_integrating/,0,1684238833.0," Integrating an LLM copilot within the Keras model development workflow!

[https://github.com/fabprezja/keras-gpt-copilot](https://github.com/fabprezja/keras-gpt-copilot)

Features

* Generates copilot feedback from gathering model configuration, optimizer details, and experiment results during model development
* Interacts with OpenAI's LLMs, such as GPT-4
* Can be used with non-OpenAI LLMs to generate suggestions
* Offers options to downsample and/or smoothen validation curves to accommodate large (and/or noisy) results within the copilot prompt
* Provides flexibility in customizing the copilot prompt, allowing for the addition of extra information.
* Supports follow-up questions for extended guidance, such as requesting specific code changes based on previous recommendations"
189,deeplearning,gpt-4,relevance,2023-08-30 17:58:05,"Bright Eye: free mobile AI app that generates art and different forms of text (code, math answers, essays, games, ideas, and more)!(GPT-4 POWERED)",EtelsonRecomputing,False,0.33,0,165lsy9,https://www.reddit.com/r/deeplearning/comments/165lsy9/bright_eye_free_mobile_ai_app_that_generates_art/,1,1693418285.0,"
Hi all. I’m the cofounder of a startup focused on developing the AI super app called “Bright Eye”, a multipurpose AI product that generates and analyzes content.

One of its interesting use cases is helping students study, people plan, and offering general advice. 

As the title puts it, it’s capable of generating almost anything, so the use-cases in terms of productivity isn’t confined to only those above, it can apply however you see fit. We run on GPT-4, stable diffusion, and Microsoft azure cognitive services.  

Check us out below, we’re looking for advice on the functionality and design of the app (and possibly some longtime users): 

https://apps.apple.com/us/app/bright-eye/id1593932475"
190,deeplearning,gpt-4,relevance,2023-04-02 12:37:38,[N] Software 3.0 Blog Post Release 🔥,DragonLord9,False,0.73,10,129k24i,https://www.reddit.com/r/deeplearning/comments/129k24i/n_software_30_blog_post_release/,3,1680439058.0,"Hi all, excited to share my blog post on [**Software 3.0**](https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm_campaign=post&utm_medium=web)

https://preview.redd.it/9b4hjkkhugra1.png?width=1500&format=png&auto=webp&s=e341f3ab4c3c8abb206df8daa17428a297ff61e2

The blog post offers an insightful read on the new GPT-powered programming paradigm where the new programming language is simply ""*English*"", as well as recent developments in AI.

The post was originally written before GPT-4 release, and the predictions seem to have held surprisingly well. Knowledge cutoff date 28 Feb 2023.

Please read and share!! Happy to answer any follow-ups here or on DM 😊

Tweet: [https://twitter.com/DivGarg9/status/1642229948185280521?s=20](https://twitter.com/DivGarg9/status/1642229948185280521?s=20)

Blog: [https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm\_campaign=post&utm\_medium=web](https://open.substack.com/pub/divgarg/p/software-3?r=ccbhq&utm_campaign=post&utm_medium=web)"
191,deeplearning,gpt-4,relevance,2023-04-01 14:01:42,Revolutionizing Content Creation: Moji AI's Impact on Social Media and Beyond,Large_Rush9013,False,0.25,0,128nbfn,https://www.reddit.com/r/deeplearning/comments/128nbfn/revolutionizing_content_creation_moji_ais_impact/,0,1680357702.0,"Hey fellow Redditors, I recently stumbled upon a summary of an incredible new AI content tool called Moji AI, and I just had to share my thoughts about it. I think it has the potential to be a game-changer for content creators!

Moji AI is designed to make content creation easier by using the power of GPT-4 to generate text and Stable Diffusion Models to create eye-catching images. It offers icons and image assets that can significantly boost social media engagement. As a Reddit user, I'm always trying to find new ways to share content and start conversations, and I think the potential benefits of this tool are undeniable.

I've been aware of GPT-3 for a while now, and the thought of GPT-4 being a more powerful version gets me excited about what it could mean for the future of AI-generated content. The fact that Moji AI can not only generate text, but also customize images and icons, makes it seem like a must-have tool for anyone serious about making an impact on social media platforms.

The Stable Diffusion Models used by Moji AI allow it to create visually stunning images that are bound to catch the attention of users as they're scrolling through their feeds. It's not just about the text anymore - visuals are crucial in today's social media landscape, and Moji AI is tackling that aspect head-on.

I can already think of countless ways to apply Moji AI in both personal and professional projects. Imagine effortlessly creating engaging blog posts, social media posts, and digital marketing campaigns without the hassle of finding a graphic designer or a copywriter. This tool seems too good to be true!

For those of you who are interested in learning more about Moji AI and how it can elevate your content creation game, I urge you to check out their website at [mojiai.io](https://mojiai.io). I'm excited to see the applications of this tool, and I believe that it'll revolutionize how we create and share content moving forward.

Indeed, it's exciting to be part of a community that is always at the forefront of groundbreaking innovations like Moji AI! Feel free to share your thoughts and ideas about how you think Moji AI could impact the world of content creation. Let's start a conversation!"
192,deeplearning,gpt-4,relevance,2023-03-11 00:38:10,Generate READMEs Using ChatGPT,tomd_96,False,0.91,8,11o5zyl,https://www.reddit.com/r/deeplearning/comments/11o5zyl/generate_readmes_using_chatgpt/,0,1678495090.0,"&#x200B;

https://i.redd.it/k375our2a0na1.gif

&#x200B;

You can use this program I wrote to generate readmes: [https://github.com/tom-doerr/codex-readme](https://github.com/tom-doerr/codex-readme)

&#x200B;

It's far from perfect, but I now added ChatGPT and it is surprisingly good at inferring what the project is about. It often generates interesting usage examples and explains the available command line options.

&#x200B;

You probably won't yet use this for larger projects, but I think this can make sense for small projects or single scripts. Many small scripts are very useful but might never be published because of the work that is required to document and explain it. Using this AI might assist you with that.

&#x200B;

Reportedly GPT-4 is coming out next week, which probably would make it even better.

&#x200B;

What do you think?"
193,deeplearning,gpt-4,relevance,2023-04-07 10:28:52,"Series of Surveys on ChatGPT, Generative AI (AIGC), and Diffusion Models",Learningforeverrrrr,False,0.93,11,12egmab,https://www.reddit.com/r/deeplearning/comments/12egmab/series_of_surveys_on_chatgpt_generative_ai_aigc/,0,1680863332.0,"* **A survey on ChatGPT:** [**One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era**](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era)
* **A survey on Generative AI (AIGC):** [**A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?**](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need)
* **A survey on Text-to-image diffusion models:** [**Text-to-image Diffusion Models in Generative AI: A Survey**](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey)
* **A survey on Audio diffusion models:** [**A Survey on Audio Diffusion Models: Text To Speech Synthesis and Enhancement in Generative AI**](https://www.researchgate.net/publication/369477230_A_Survey_on_Audio_Diffusion_Models_Text_To_Speech_Synthesis_and_Enhancement_in_Generative_AI)
* **A survey on Graph diffusion models:** [**A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material**](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material)

**ChatGPT goes viral.** Launched by OpenAI on November 30, 2022, ChatGPT has attracted unprecedented attention due to its powerful abilities all over the world.  It took only 5 days \[1\] and 2 months \[2\] for ChatGPT to have 1 million users and 100 million monthly users after launch, making it the fastest-growing consumer application in history. ChatGPT can be seen as the milestone for the GPT family to go viral. In academia, ChatGPT has also inspired a large number of works discussing its applications in multiple fields, with **more than 500 papers within four months** after release and **the number is still increasing rapidly.**  This brings a huge challenge for a researcher who hopes to have an overview of ChatGPT applications or hopes to start his or her journey with ChatGPT in their own field.  **To help more people keep up with the latest progress of the GPT family,** we’re glad to share a self-contained survey that not only summarizes **the recent applications** of ChatGPT and other GPT variants like GPT-4, but also introduces the **underlying techniques** and **challenges.** Please refer to the following link for the paper: [One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era).

&#x200B;

**From ChatGPT to Generative AI.**  One highlighting ability of the GPT family is that it can generate natural languages, which falls into the area of Generative AI. Apart from text, Generative AI can also generate content in other modalities, such as image, audio, and graph. More excitingly, Generative AI is able to convert data from one modality to another one, such as the text-to-image task (generating images from text). **To help readers have a better overview of Generative AI,** we provide a complete survey on underlying **techniques,** summary and development of **typical tasks in academia**, and also **industrial applications.** Please refer to the following link for the paper.  [A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need)

&#x200B;

**From Generative AI to Diffusion Models.** The prosperity of a field is always driven by the development of technology, and so is Generative AI.  Different from ChatGPT which generates text based on the transformer, **diffuson models** have greatly accelerated the development of other fields in Generative AI, such as image synthesis.  Although we provide a summary of diffusion models and typical tasks in the Generative AI survey, we cannot include detailed discussions due to paper length limitations. **For those who are interested in the technical details of diffusion models and the recent progress of their applications in Generative AI,** we provide three self-contained surveys on **how diffusion models are applied in three typical areas: Text-to-image diffusion models** (also includes related tasks such as image editing)**, Audio diffusion models** (including text to speech synthesis and enhancement), and **Graph diffusion models** (including molecule, protein and material areas). Please refer to the following links for the paper.

* [Text-to-image Diffusion Models in Generative AI: A Survey](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey)
* [A Survey on Audio Diffusion Models: Text To Speech Synthesis and Enhancement in Generative AI](https://www.researchgate.net/publication/369477230_A_Survey_on_Audio_Diffusion_Models_Text_To_Speech_Synthesis_and_Enhancement_in_Generative_AI)
* [A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material)

We hope our survey series will help people for a better understanding of ChatGPT and Generative AI, and we will update the survey regularly to include the latest progress. Please refer to the personal pages of the authors for the latest updates on surveys. If you have any suggestions or problems, please feel free to contact us.

\[1\] Greg Brockman, co-founder of OpenAI, [https://twitter.com/gdb/status/1599683104142430208?lang=en](https://twitter.com/gdb/status/1599683104142430208?lang=en)

\[2\] Reuters, [https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/](https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/)"
194,deeplearning,gpt-4,relevance,2023-03-29 14:07:24,New Weaviate Podcast with Mem Co-Founder Dennis Xu!,CShorten,False,0.67,1,125p56e,https://www.reddit.com/r/deeplearning/comments/125p56e/new_weaviate_podcast_with_mem_cofounder_dennis_xu/,0,1680098844.0," I'm super excited to publish our newest Weaviate Podcast with Mem Co-Founder Dennis Xu!! Dennis is at the cutting-edge of applying the latest advancements in AI to note taking or knowledge management software. In other words, shaping the future of knowledge work itself!

Dennis explained a ton of interesting topics such as personalized embeddings and organizing your digital footprint through the Me API, of course the trending topic of how GPT-4 and recent advances in LLMs are changing things, and many more topics in what it is powering these systems!

Please check it out and let us know what you think!

https://youtu.be/RujNYB5ZE2c"
195,deeplearning,gpt-4,relevance,2023-04-05 13:21:51,"New Weaviate Podcast (#42) - ChatGPT Plugin Marketplace, Alpaca Models, Semantic Search on S3, and more!",CShorten,False,0.76,2,12ck7ae,https://www.reddit.com/r/deeplearning/comments/12ck7ae/new_weaviate_podcast_42_chatgpt_plugin/,0,1680700911.0," I am beyond excited to share our latest Weaviate Podcast with Ethan Steininger! Ethan is the founder of Mixpeek and creator of Collie.ai!

Ethan began by explaining how he came into search through integrating MongoDB with the Lucene inverted index. Ethan continued explaining how his background in Sales Engineering helped him to see the recurring problems businesses are facing when trying to utilize the latest LLM and Vector Database technologies to solve their problems.

We then continued to take a tour of all sorts of topics in the AI Landscape from the impact of the ChatGPT Plugin Marketplace / New App Store for AI to the Stanford Alpaca models, the impact of LLMs for coding productivity and many more, even ending with Ethan's advice on stress management by getting into nature and our thoughts on the existential fear technologies like GPT-4 inspire in many and the implications of it on society.

I hope you enjoy the podcast, please let us know what you think!

[https://www.youtube.com/watch?v=EDPk1umuge0](https://www.youtube.com/watch?v=EDPk1umuge0)"
196,deeplearning,gpt-4,relevance,2023-08-21 16:48:23,Gorilla: Large Language Models Connected to Massive APIs [Paper Summary Video],CShorten,False,0.67,1,15xd14p,https://www.reddit.com/r/deeplearning/comments/15xd14p/gorilla_large_language_models_connected_to/,0,1692636503.0,"Hey everyone, I am SUPER excited to present a paper summary video of ""Gorilla: Large Language Models connected to Massive APIs"" by Patil et al. 2023!  LLMs have been supercharged by connecting them with external tools. An external tool could be a search engine, code executor, calculator, calendar, email, CRM, and many others! Although GPT-4 is fairly strong at formatting API requests zero-shot (without additional training), Gorilla shows that specialized training can outperform it significantly! In addition to the accuracy performance, this is also achievable with a much cheaper 7 billion parameter model, derived by fine-tuning the Meta AI LlaMA-2 7B checkpoint!!

There are all sorts of interesting details about this paper covered in the video, from the APIBench dataset to Self-Instruct training data generation, Retrieval-Aware Training, and the miscellaneous details of Gorilla! I hope you enjoy the paper summary video! As always I am more than happy to answer any questions or discuss any ideas you have related to the content in the video!

P.S. Please stay tuned for Weaviate Gorilla! 🦍 👀

https://www.youtube.com/watch?v=LkV5DTRNxAg"
197,deeplearning,gpt-4,relevance,2024-02-06 16:30:31,XMC.dspy with Karel D'Oosterlinck - Weaviate Podcast #87!,CShorten,False,1.0,2,1akdue4,https://www.reddit.com/r/deeplearning/comments/1akdue4/xmcdspy_with_karel_doosterlinck_weaviate_podcast/,0,1707237031.0,"Hey everyone! I am BEYOND EXCITED to publish our 87th Weaviate Podcast with Karel D’Oosterlinck from the University of Ghent and Stanford NLP!

This podcast was simply amazing, I can't thank Karel enough for how much he taught me about DSPy, how to use it for Extreme Multi-Label Classification (XMC), and the applications of XMC in Biomedical NLP, Recommendation, Job Listings, and more. I am beyond grateful to have the opportunity to share this knowledge in the Weaviate podcast!

The podcast begins with an overview of Extreme Multi-Label Classification. How in the world do we prompt LLMs to categorize inputs into thousands of classes?!

To solve this, Karel has developed a novel Infer-Retrieve-Rank (IReRa) DSPy program. Infer first takes the input and outputs coarse labels for it. These coarse labels are then mapped to the thousands of classes (typically managed in ontologies) with the retrieval system and... you guessed it, Vector Embeddings! The Rank LLM component then takes the classes from the vector search and sorts them by relevance to the query.

Karel then took me through the details of the DSPy compiler! There is just so much opportunity with this from understanding how we tweak the descriptions of tasks we give to our language models, to populating the prompt with in-context learning examples. We discussed all sorts of things from model compression (e.g. can we prompt Mistral or Llama 7b to rival the performance of GPT-4 or Gemini Ultra at a *particular* task in an LLM pipeline, such as re-ranking or query writing?), diving into the latest on Teacher-Student optimization, input-dependent prompting, and so much more! We then concluded the podcast by discussing IReRa's applications for Recommendation Systems and what lead Karel to Biomedical NLP! Thanks again Karel, I learned so much from this one!

YouTube: [https://www.youtube.com/watch?v=\_ye26\_8XPcs](https://www.youtube.com/watch?v=_ye26_8XPcs)

Spotify: [https://podcasters.spotify.com/pod/show/weaviate/episodes/XMC-dspy-with-Karel-DOosterlinck---Weaviate-Podcast-87-e2fehtk](https://podcasters.spotify.com/pod/show/weaviate/episodes/XMC-dspy-with-Karel-DOosterlinck---Weaviate-Podcast-87-e2fehtk)"
198,deeplearning,gpt-4,relevance,2023-03-18 10:40:15,"Need some advice for my idea of ""Sketch to design"" project",Haghiri75,False,1.0,2,11ukow0,https://www.reddit.com/r/deeplearning/comments/11ukow0/need_some_advice_for_my_idea_of_sketch_to_design/,1,1679136015.0,"*I originally asked this question* [*here on stackoverflow*](https://stackoverflow.com/questions/75775112/need-some-advice-for-my-idea-of-sketch-to-design-project)

I have an idea of a *sketch to design* program with deep learning and computer vision. I saw the very same concept before and I believe GPT-4 is capable of doing something similar. First, I have to say that I am familiar with the computer vision procedure. I did it [before](https://haghiri75.com/en/analyzing-components-of-an-electric-circuit-with-yolov5/) and I know using YOLO algorithms might be a good idea.

Also, I have no problems developing a ""Sketch to code"" program since I can pipe my results to another AI or code generator. But I also found [Uizard](http://uizard.io) which can turn your hand-drawn sketches into ""Design"".

It made some questions in my mind which are the following:

1. Is there any language for design? Or it's just XML, HTML or SVG coded file?
2. Is there any code/design generator which is capable of turning a simple design document (like *a page with a navbar*) to HTML or SVG? and **open source** of course!

I will be thankful for your helps and comments."
199,deeplearning,gpt-4,relevance,2023-07-25 13:44:39,Luca Beurer-Kellner on LMQL - Weaviate Podcast #59!,CShorten,False,1.0,6,1598yyk,https://www.reddit.com/r/deeplearning/comments/1598yyk/luca_beurerkellner_on_lmql_weaviate_podcast_59/,0,1690292679.0,"Hey everyone! I am beyond excited to publish our 59th Weaviate podcast with Luca Beurer-Kellner, the lead author and creator of LMQL!

LMQL is a *programming language* for LLMs, a really interesting and unique direction amongst the emerging development of LLM frameworks and tooling. I was really blown away by the elegance of the syntax, and I highly recommend checking out the LMQL playground. Not only is the LMQL playground a great way to learn LMQL particularly, it is one of the world's best visualizations of complex LLM execution, providing an interactive sandbox to explore!

We discussed many topics on the podcast from Luca's research background in Programming Languages and how that has shaped his perspectives on Constrained Sampling, the analog of LLM output nil pointer exceptions, and the effort to tame this chaos with LMQL! We also discussed how this fits into existing LLM frameworks such as our friends at LlamaIndex, LangChain, Haystack, MS Semantic Kernel, Jina AI, and others! We also discussed tool use with the Gorilla large language models and the general perspective of a master model such as GPT-4 that routes inferences to cheaper specialized models!

Finally we concluded with discussions on future directions! Luca really opened my eyes about the future of composable models and RETRO-style RAG architectures, can't wait to see that develop further!

I really hope you enjoy the podcast, as always I am more than happy to answer any questions or discuss any ideas you have related to the content in the podcast!  

https://www.youtube.com/watch?v=cuWLPHDAQ5g"
200,deeplearning,gpt-4,relevance,2023-04-25 18:02:06,"Diverse Conversations: Mental Health, Sustainable Living, and Personal Finance in a Fast-Paced World",Large_Rush9013,False,0.25,0,12yqxxl,https://www.reddit.com/r/deeplearning/comments/12yqxxl/diverse_conversations_mental_health_sustainable/,3,1682445726.0,"Hey everyone, I wanted to share some thoughts I had recently after coming across various discussions on the platform. I realized how diverse and thought-provoking this community truly is.

One topic that caught my attention was the importance of mental health, especially in today's fast-paced world. The amount of information and the undeniable impact of social media on our lives can be both enlightening and suffocating. It has become more important than ever for us to take care of our well-being and find a balance between consuming content and living in the present moment.

Another area that has drawn my curiosity is the growing discussions on sustainable living and eco-friendliness. It's inspiring how we are collectively working to create a better world for future generations. Whether it's through reducing waste, discovering alternative energy sources, or just being more aware of our surroundings, every action makes a difference.

Lastly, I've noticed an increase in discussions surrounding personal finance and investment. We are living in unprecedented times, and it's fascinating to see how the financial landscape has transformed. Whether it's cryptocurrency, passive income ideas, or strategies to achieve financial freedom, these conversations are not only interesting but educational too.

All in all, the richness of this community lies in the plethora of topics discussed and the valuable insights shared by its members. I'm grateful to be part of this and always look forward to learning something new every day.

P.S. This post was curated with the help of Moji AI, a content-writing helper using GPT-4 technology. If you're interested in learning more, check out their website at mojiai.io."
201,deeplearning,gpt-4,relevance,2023-09-28 13:34:24,First Impressions with GPT-4V(ision),zerojames_,False,0.71,3,16ug8gc,https://www.reddit.com/r/deeplearning/comments/16ug8gc/first_impressions_with_gpt4vision/,0,1695908064.0,"My colleague Piotr and I have been testing GPT-4V(ision) over the last day. We wrote up our findings, covering how GPT-4V performs on:

1. Visual question answering (VQA) across a range of domains (locations, movies, plants)
2. OCR
3. Math OCR
4. Object detection
5. And more

TL;DR: GPT-4V performed well for VQA and document OCR but struggled with OCR on real-world images and object detection (where we asked for bounding boxes).

[https://blog.roboflow.com/gpt-4-vision/](https://blog.roboflow.com/gpt-4-vision/)

I would love to hear what other people have found working with GPT-4V."
202,deeplearning,gpt-4,relevance,2020-06-10 20:36:33,"GPT-3: The $4,600,000 Language model",mippie_moe,False,0.76,6,h0jm54,https://lambdalabs.com/blog/demystifying-gpt-3/,4,1591821393.0,
203,deeplearning,gpt-4,relevance,2023-12-28 16:22:37,Do Large Vision-language Models Understand Charts? We found that the answer is NO!,steeveHuang,False,0.96,17,18sxs1r,https://www.reddit.com/r/deeplearning/comments/18sxs1r/do_large_visionlanguage_models_understand_charts/,2,1703780557.0,"We've just wrapped up a collaborative study with Columbia University and the University of Macau that probes into the capabilities of Large Vision-Language Models (LVLMs) when it comes to understanding and describing charts. The findings are quite startling.

Despite advancements in LVLMs, our research reveals that even the most advanced LVLMs like GPT-4V and Bard fall short. A striking 🚨**81.27%** (321/ 395) 🚨 of the captions they generated contained factual errors, misinterpreting data from charts. This suggests a significant gap in these models' ability to grasp the nuances and relationships between data points in visual representations.

🔍 Explore our findings in detail with the full paper on [Arxiv](https://arxiv.org/abs/2312.10160).

💻: Code and data are also available on [GitHub](https://github.com/khuangaf/CHOCOLATE)

&#x200B;

https://preview.redd.it/448ty01q929c1.png?width=1362&format=png&auto=webp&s=c6ce27262247ce6978ae7ff169f6fc844fda63de"
204,deeplearning,gpt-4,relevance,2023-04-10 17:02:54,Exploring the Potential and Pitfalls of Deep Learning and Machine Learning: A Reddit User's Quest for Knowledge,Large_Rush9013,False,1.0,1,12howrh,https://www.reddit.com/r/deeplearning/comments/12howrh/exploring_the_potential_and_pitfalls_of_deep/,0,1681146174.0,"As a fellow Reddit user, I couldn't help but be intrigued by some of the recent advancements and discussions surrounding deep learning and machine learning. It amazes me how much progress we've made in these fields, and the potential applications for them are seemingly endless. Although I love exploring the different areas where machine learning can have an impact, I also have some questions and would appreciate anyone's insights.

Conversely, a thought has crossed my mind regarding how these cutting-edge tools can also be used for disinformation or other negative purposes. It seems imperative that we, as a tech-savvy community, work together to ensure these tools remain positively focused and prevent them from being used to spread misinformation or other nefarious goals.

One particular area that has caught my eye is the powerful pipeline for background removal mentioned in a recent article. It utilizes the CUDA-accelerated MOG2 background segmentation algorithm and the Savant Video Analytics Framework, resulting in impressive processing speeds. I wonder, though, about the potential applications for this technology, both positive and negative.

Additionally, I came across an interesting topic on using machine learning to predict human preferences in assembly tasks. If we can successfully train robots to assist us, the implications for manufacturing, construction, and even everyday tasks could be significant. However, it begs the question of how much we should allow AI and robots to control our lives and the measures that need to be in place to ensure they remain our helpful assistants rather than our overlords.

In my quest to learn more, I stumbled upon a free deep learning course and was wondering if there are any other resources I could check out to expand my knowledge? It's crucial to comprehend the intricacies of these powerful tools to make informed decisions as a society regarding their applications and potential consequences.

I would love to hear your thoughts on the subjects and any recommendations for resources that will aid in deep learning and machine learning education. Let's work together to harness the potential of these technologies while maintaining a vigilant watch for the negative aspects that may arise.

This post was curated with the help of Moji AI, an innovative tool that utilizes GPT-4 to assist content writing. You can learn more about Moji AI by visiting their website at mojiai.io."
205,deeplearning,gpt-4,relevance,2024-02-17 08:34:08,Question about LLM's proficiency in advanced mathematics,WinExcellent381,False,0.6,1,1asxab6,https://www.reddit.com/r/deeplearning/comments/1asxab6/question_about_llms_proficiency_in_advanced/,21,1708158848.0,"The most cutting-edge LLMs like GPT 4 Turbo and Gemini Ultra 1.0 are great, but when it comes to mathematics, they are really limited. When will we start to have LLMs that will get a perfect score in IMO or the William Lowell Putnam Mathematical Competition every single time, and can solve master's or PhD questions about differential geometry or quantum field theory better and faster than any physicist or mathematician alive? Is AGI necessary for such capabilities or is it that researchers just haven't trained the models specifically on those tasks?"
206,deeplearning,gpt-4,relevance,2023-04-12 05:21:13,Is OpenAI’s Study On The Labor Market Impacts Of AI Flawed?,LesleyFair,False,0.94,26,12jb4xz,https://www.reddit.com/r/deeplearning/comments/12jb4xz/is_openais_study_on_the_labor_market_impacts_of/,1,1681276873.0,"[Example img\_name](https://preview.redd.it/f3hrmeet1eta1.png?width=1451&format=png&auto=webp&s=20e20b142a2f88c3d495177e540f34bc8ea4312b)

We all have heard an uncountable amount of predictions about how AI will ***terk err jerbs!***

However, here we have a proper study on the topic from OpenAI and the University of Pennsylvania. They investigate how Generative Pre-trained Transformers (GPTs) could automate tasks across different occupations \[1\].

Although I’m going to discuss how the study comes with a set of “imperfections”, the findings still make me really excited. The findings suggest that machine learning is going to deliver some serious productivity gains.

People in the data science world fought tooth and nail for years to squeeze some value out of incomplete data sets from scattered sources while hand-holding people on their way toward a data-driven organization. At the same time, the media was flooded with predictions of omniscient AI right around the corner.

*Let’s dive in and take an* exciting glimpse into the future of labor markets\*!\*

# What They Did

The study looks at all US occupations. It breaks them down into tasks and assesses the possible level of for each task. They use that to estimate how much automation is possible for a given occupation.

The researchers used the [O\*NET database,](https://www.onetcenter.org/database.html) which is an occupation database specifically for the U.S. market. It lists 1,016 occupations along with its standardized descriptions of tasks.

The researchers annotated each task once manually and once using GPT-4. Thereby, each task was labeled as either somewhat (<50%) or significantly (>50%) automatable through LLMs. In their judgment, they considered both the direct “exposure” of a task to GPT as well as to a secondary GPT-powered system, e.g. LLMs integrated with image generation systems.

To reiterate, a higher “exposure” means that an occupation is more likely to get automated.

Lastly, they enriched the occupation data with wages and demographic information. This was used to determine whether e. g. high or low-paying jobs are at higher risk to be automated.

So far so good. This all sounds pretty decent. Sure, there is a lot of qualitative judgment going into their data acquisition process. However, we gotta cut them some slag. These kinds of studies always struggle to get any hard data and so far they did a good job.

However, there are a few obvious things to criticize. But before we get to that let’s look at their results.

# Key Findings

The study finds that 80% of the US workforce, across all industries, could have at least some tasks affected. Even more significantly, 19% of occupations are expected to have at least half of their tasks significantly automated!

Furthermore, they find that higher levels of automation exposure are associated with:

* Programming and writing skills
* Higher wages (contrary to previous research!)
* Higher levels of education (Bachelor’s and up)

Lower levels of exposure are associated with:

* Science and critical thinking skills
* Manual work and tasks that might potentially be done using physical robots

This is somewhat unsurprising. We of course know that LLMs will likely not increase productivity in the plumbing business. However, their findings underline again how different this wave is. In the past, simple and repetitive tasks fell prey to automation.

*This time it’s the suits!*

If we took this study at face value, many of us could start thinking about life as full-time pensioners.

But not so fast! This, like all the other studies on the topic, has a number of flaws.

# Necessary Criticism

First, let’s address the elephant in the room!

OpenAI co-authored the study. They have a vested interest in the hype around AI, both for commercial and regulatory reasons. Even if the external researchers performed their work with the utmost thoroughness and integrity, which I am sure they did, the involvement of OpenAI could have introduced an unconscious bias.

*But there’s more!*

The occupation database contains over 1000 occupations broken down into tasks. Neither GPT-4 nor the human labelers can possibly have a complete understanding of all the tasks across all occupations. Hence, their judgment about how much a certain task can be automated has to be rather hand-wavy in many cases.

Flaws in the data also arise from the GPT-based labeling itself.

The internet is flooded with countless sensationalist articles about how AI will replace jobs. It is hard to gauge whether this actually causes GPT models to be more optimistic when it comes to their own impact on society. However, it is possible and should not be neglected.

The authors do also not really distinguish between labor-augmenting and labor-displacing effects and it is hard to know what “affected by” or “exposed to LLMs” actually means. Will people be replaced or will they just be able to do more?

Last but not least, lists of tasks most likely do not capture all requirements in a given occupation. For instance ""making someone feel cared for"" can be an essential part of a job but might be neglected in such a list.

# Take-Away And Implications

GPT models have the world in a frenzy - rightfully so.

Nobody knows whether 19% of knowledge work gets heavily automated or if it is only 10%.

As the dust settles, we will begin to see how the ecosystem develops and how productivity in different industries can be increased. Time will tell whether foundational LLMs, specialized smaller models, or vertical tools built on top of APIs will be having the biggest impact.

In any case, these technologies have the potential to create unimaginable value for the world. At the same time, change rarely happens without pain. I strongly believe in human ingenuity and our ability to adapt to change. All in all, the study - flaws aside - represents an honest attempt at gauging the future.

Efforts like this and their scrutiny are our best shot at navigating the future. Well, or we all get chased out of the city by pitchforks.

Jokes aside!

What an exciting time for science and humanity!

As always, I really enjoyed making this for you and I sincerely hope you found value in it!

If you are not subscribed to the newsletter yet, [click here to sign up](https://thedecoding.net/)! I send out a thoughtful 5-minute email every week to keep you in the loop about machine learning research and the data economy.

*Thank you for reading and I see you next week ⭕!*

**References:**

\[1\] [https://arxiv.org/abs/2303.10130](https://arxiv.org/abs/2303.10130)"
207,deeplearning,gpt-4,relevance,2023-12-06 02:31:58,best current form of text generation?,ythug,False,0.75,2,18btl0p,https://www.reddit.com/r/deeplearning/comments/18btl0p/best_current_form_of_text_generation/,2,1701829918.0,"I had a project back in 2021 where I trained an RNN on my own tweets and then had it generate tweets for me.

Haven't kept up to date with NN since and am wondering what is best form of text generation out there currently.

this account (https://twitter.com/DeepLeffen), intrigued me. Says it is trained on gpt-4. I was aware you could train with your own data but it didnt cross my mind."
208,deeplearning,gpt-4,relevance,2020-10-28 11:39:21,How did I get access to GPT-3 OpenAI's API? Tips are shared at 4:45 in the video! The rest of the videos explains what can GPT-3 really do and how it can help you or your company.,OnlyProggingForFun,False,0.43,0,jjm4ep,https://www.youtube.com/watch?v=Gm4AMjV8ErM,0,1603885161.0,
209,deeplearning,gpt-4,relevance,2023-12-06 04:07:21,[D]Unlocking Insights: Harnessing Table Extraction and Advanced Data Querying with LlamaIndex’s Pandas Query Engine,Fit_Maintenance_2455,False,1.0,1,18bvfof,https://www.reddit.com/r/deeplearning/comments/18bvfof/dunlocking_insights_harnessing_table_extraction/,0,1701835641.0,"Introducing LlamaIndex, a transformative tool that facilitates seamless interaction between your data sources and powerful language models like GPT-4. This comprehensive guide unveils a groundbreaking approach: extracting data from URLs, converting it into PDFs, extracting tables from these PDFs, and ultimately converting these tables into CSV files. LlamaIndex serves as the linchpin, enabling effortless communication and utilization of data between diverse sources and language models, revolutionizing the landscape of intelligent applications.

&#x200B;

Link: [https://medium.com/ai-advances/unlocking-insights-harnessing-table-extraction-and-advanced-data-querying-with-llamaindexs-pandas-f7200ef07771](https://medium.com/ai-advances/unlocking-insights-harnessing-table-extraction-and-advanced-data-querying-with-llamaindexs-pandas-f7200ef07771) "
210,deeplearning,gpt-4,relevance,2023-10-04 15:06:32,Custom LLM,Relative_Winner_4588,False,1.0,2,16zpnjz,https://www.reddit.com/r/deeplearning/comments/16zpnjz/custom_llm/,0,1696431992.0,"
I'm eager to develop a Large Language Model (LLM) that emulates ChatGPT, tailored precisely to my specific dataset. While I'm aware of existing models like Private-GPT and Gpt4all, my ultimate goal is to either create a custom LLM from scratch or fine-tune a pre-existing model like BERT or GPT-7B to meet my unique requirements.

I've been closely following Andrej Karpathy's instructive lecture on building GPT-like models. However, I've noticed that the model only generated text akin to Shakespearean prose in a continuous loop instead of answering questions. I'm striving to develop an LLM that excels at answering questions based on the data I provide.

The core objectives I'm pursuing encompass:
1. Effective data preparation tailored for question-answering tasks.
2. The strategic selection of a pre-trained model, such as BERT or GPT-7B.
3. Rigorous performance evaluation, employing pertinent metrics.
4. The creation of an efficient inference system that facilitates question input and response generation.

Please guide me for this objectives or provide me some resources for the same.

DM me if you want to talk in detail."
211,deeplearning,gpt-4,relevance,2023-11-08 15:37:08,Start with Large Language Models (LLMs) in 2023,OnlyProggingForFun,False,0.71,10,17qo9lt,https://www.reddit.com/r/deeplearning/comments/17qo9lt/start_with_large_language_models_llms_in_2023/,11,1699457828.0,"This is a complete guide to start and improve your LLM skills in 2023 without an advanced background in the field and stay up-to-date with the latest news and state-of-the-art techniques!

The complete article: https://www.louisbouchard.ai/from-zero-to-hero-with-llms/

All the links on GitHub: https://github.com/louisfb01/start-llms 

Artificial is a fantastic field, and so are language models like GPT-4, Claude..., but it goes extremely fast. Don't miss out on the most important and exciting news by joining great communities, people, newsletters, and more you can all find in this guide!

This guide is intended for anyone with a small background in programming and machine learning. Simple python knowledge is enough to get you started. There is no specific order to follow, but a classic path would be from top to bottom. If you don't like reading books, skip it, if you don't want to follow an online course, you can skip it as well. There is not a single way to become a ""LLM expert"" and with motivation, you can absolutely achieve it."
212,deeplearning,gpt-4,relevance,2023-04-07 10:58:54,Text-to-image Diffusion Models in Generative AI: A Survey,Learningforeverrrrr,False,0.84,14,12ehc2m,https://www.reddit.com/r/deeplearning/comments/12ehc2m/texttoimage_diffusion_models_in_generative_ai_a/,0,1680865134.0,"Diffusion models have become a SOTA generative modeling method for numerous content types, such as images, audio, graph, etc. As the number of articles on diffusion models has grown exponentially over the past few years, there is an increasing need for survey works to summarize them. Recognizing the existence of such works, our team has completed multiple field-specific surveys on diffusion models. We promote our works here and hope they can be helpful to researchers in relative fields: text-to-image diffusion models [\[a survey\]](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey), audio diffusion models [\[a survey\]](https://www.researchgate.net/publication/369477230_A_Survey_on_Audio_Diffusion_Models_Text_To_Speech_Synthesis_and_Enhancement_in_Generative_AI), and graph diffusion models [\[a survey\]](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material) .

In the following, we briefly summarize our survey on text-to-image diffusion models.

[Text-to-image Diffusion Models in Generative AI: A Survey](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey)

As a self-contained work, this survey starts with a brief introduction of how a basic diffusion model works for image synthesis, followed by how condition or guidance improves learning. Based on that, we present a review of state-of-the-art methods on text-conditioned image synthesis, i.e., text-to-image. We further summarize applications beyond text-to-image generation: text-guided creative generation and text-guided image editing. Beyond the progress made so far, we discuss existing challenges and promising future directions.

Moreover, we have also completed two survey works on generative AI (AIGC) [\[a survey\]](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need) and ChatGPT [\[a survey\]](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era), respectively. Interested readers may give it a look."
213,deeplearning,gpt-4,relevance,2023-04-07 08:41:41,A survey on graph diffusion models,Learningforeverrrrr,False,1.0,2,12eejpe,https://www.reddit.com/r/deeplearning/comments/12eejpe/a_survey_on_graph_diffusion_models/,0,1680856901.0,"Diffusion models have become a SOTA generative modeling method for numerous content types, such as images, audio, graph, etc. As the number of articles on diffusion models has grown exponentially over the past few years, there is an increasing need for survey works to summarize them. Recognizing the existence of such works, our team has completed multiple field-specific surveys on diffusion models. We promote our works here and hope they can be helpful to researchers in relative fields: text-to-image diffusion models [\[a survey\]](https://www.researchgate.net/publication/369662720_Text-to-image_Diffusion_Models_in_Generative_AI_A_Survey), audio diffusion models [\[a survey\]](https://www.researchgate.net/publication/369477230_A_Survey_on_Audio_Diffusion_Models_Text_To_Speech_Synthesis_and_Enhancement_in_Generative_AI), and graph diffusion models [\[a survey\]](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material) .

In the following, we briefly summarize our survey work on graph diffusion models.

[https://www.researchgate.net/publication/369716257\_A\_Survey\_on\_Graph\_Diffusion\_Models\_Generative\_AI\_in\_Science\_for\_Molecule\_Protein\_and\_Material](https://www.researchgate.net/publication/369716257_A_Survey_on_Graph_Diffusion_Models_Generative_AI_in_Science_for_Molecule_Protein_and_Material)

We start with a summary of the progress of graph generation before diffusion models. The diffusion models are then concisely presented and graph generation is discussed in depth from a structural and application perspective. Moreover,  the currently popular evaluation datasets and metrics are covered. Finally, we summarize the challenges and research questions still facing the research community. This survey work might be a useful guidebook for researchers who are interested in exploring the potential of diffusion models for graph generation and related tasks.

Moreover, we have also completed two survey works on generative AI (AIGC) [\[a survey\]](https://www.researchgate.net/publication/369385153_A_Complete_Survey_on_Generative_AI_AIGC_Is_ChatGPT_from_GPT-4_to_GPT-5_All_You_Need) and ChatGPT [\[a survey\]](https://www.researchgate.net/publication/369618942_One_Small_Step_for_Generative_AI_One_Giant_Leap_for_AGI_A_Complete_Survey_on_ChatGPT_in_AIGC_Era), respectively. Interested readers may give it a look."
214,deeplearning,gpt-4,relevance,2023-12-22 21:52:34,NeuralFlash - a flashcard-making GPT specializing in AI to help you study.,MachineScholar,False,0.67,1,18opxcs,https://www.reddit.com/r/deeplearning/comments/18opxcs/neuralflash_a_flashcardmaking_gpt_specializing_in/,0,1703281954.0,"Hey everyone. I'm a computer science student and I've been searching for the most efficient way to study ML concepts via Quizlet flashcards so I came up with a ""pipeline"" by making this custom GPT and feeding it my Markdown notes. Here's a little guide:

1. Take lecture/book notes in Markdown (I use obsidian to do this since it's free, fast, and open source)
2. Open up NeuralFlash and choose the ""Generate flashcards from my AI notes"" action.
3. Copy your entire Markdown note, paste it into NeuralFlash.
4. Copy the csv it outputs and paste it into the ""import"" area of your Quizlet flashcard set (make sure you select comma instead of tab).
5. Learn and succeed.

**Here the link to the GPT:** [**https://chat.openai.com/g/g-m4nFBaKA8-neuralflash**](https://chat.openai.com/g/g-m4nFBaKA8-neuralflash)"
215,deeplearning,gpt-4,relevance,2023-07-31 17:01:30,Where can I keep on top of LLM developments?,gonidphoe7,False,0.5,0,15elov0,https://www.reddit.com/r/deeplearning/comments/15elov0/where_can_i_keep_on_top_of_llm_developments/,3,1690822890.0,"I'm currently attempting to broaden my knowledge of AI and ML, particularly in relation to large language models. My understanding so far is that a significant limitation of these models is their restricted context window, which appears to hinder their ability to maintain continuity of information and reason effectively about complex topics. I see models like GPT-4, Anthropic's Claude, and Mosaic ML implementing larger windows (currently 32k, 100k and 82k tokens respectively).

Can anyone confirm whether my comprehension of the context window is accurate? If not, could you explain the primary challenges that impede the reasoning and problem-solving abilities of LLMs? Additionally, what are the proposed solutions currently being explored to overcome these challenges? Finally, could anyone recommend the best way to stay on top of developments in the LLM and AI agent space?"
216,deeplearning,gpt-4,relevance,2023-10-24 15:34:49,MemGPT Explained!,CShorten,False,0.96,21,17ffmuu,https://www.reddit.com/r/deeplearning/comments/17ffmuu/memgpt_explained/,2,1698161689.0,"Hey everyone! I am SUPER excited to publish a new paper summary video of MemGPT from Packer et al. at UC Berkeley!

MemGPT is a massive step forward in the evolution from naive Retrieval-Augmented Generation (RAG) to creating an OPERATING SYSTEM for LLM applications!

This works by telling the LLM about its limited input window and giving it new ""tools"" / APIs to manage its own memory. For example, the LLM processes the conversation history in a chatbot or the next paragraph in document processing and determines what is important to add to its working context.

The authors design a operating system around this concept complete with events, functions, and of a virtual context management algorithm inspired by operating system concepts such as page replacement. When the LLM determines it needs more context to answer a question, it searches into it's external context (could be recall storage (complete history of events such as dialogue in a chatbot across 4 months), or its archival storage (information such as Wikipedia entries stored in a Vector DB) -- it then parses the search results to determine what is worth adding to its working context.

The authors test MemGPT on chatbots and the experiments from Lost in the Middle, finding that this explicit memory management overcomes the problems of losing relevant information in the middle of search results!

I think there are tons of exciting implications of this work such as the intersection with the Gorilla LLMs (trying to allocate as few tokens as possible in describing a tool to an LLM), as well as this general phenomenon of connecting LLMs to Operating Systems!

Here is my review of the paper in more detail, I hope you find it useful!

[https://www.youtube.com/watch?v=nQmZmFERmrg](https://www.youtube.com/watch?v=nQmZmFERmrg)"
217,deeplearning,gpt-4,relevance,2024-01-05 08:27:31,6 ways AI can make your life easier in 2024,PoetryOne4804,False,0.33,0,18z212l,https://www.reddit.com/r/deeplearning/comments/18z212l/6_ways_ai_can_make_your_life_easier_in_2024/,8,1704443251.0,"Artificial intelligence is developing every day. ChatGPT was a game changer for millions of people, but it is not the only one. Advances in AI are coming, and they're coming FAST. Very fast. There’re so many tasks AI can help with and make this year less stressful. Let me show you these ways:

**1) Chatbots for answering questions and brainstorming**

Except ChatGPT, you can use Google Bard, SpinBot, and YouChat.

**2) AI Essay writers**

Many people use [essay writing services](https://www.reddit.com/r/deeplearning/comments/16gnuwy/best_essay_writing_services_top_5/) but not all think that AI can also help in academic writing. AI essay writers like [Textero.ai](https://Textero.ai) can be faster and generate ideas or find sources for your topic.

**3) Daily life tools**

There’re AI planners to schedule meetings and integrate with your calendars. You can also keep track of finances using PocketGuard, Wally, or Cleo.

**4) Tools for social networks**

There’re various AI tools tailored for social networks, such as Postwise for Twitter posts and Steve.ai for YouTube.

**5) Tools to improve health and fitness goals**

AI tools like Apple Watches and Fitbits can monitor your fitness and health. They can even track your sleep and offer suggestions to improve sleep quality.

**6) Tools for academic needs**

Even though some professors are against using AI while studying, students look for ways to make academic life easier. Useful tools for school life you can find here:  [ai tools for students](https://www.reddit.com/r/artificial/comments/1716t0y/ai_tools_for_students_from_ai_essay_generators_to/)

Any other tools to share? Feel free to write about them, I’m ready to try more new services."
218,deeplearning,gpt-4,relevance,2023-10-11 12:38:04,Weird loss behaviour with higher learning rate - LLM training,thelibrarian101,False,1.0,2,175d148,https://www.reddit.com/r/deeplearning/comments/175d148/weird_loss_behaviour_with_higher_learning_rate/,0,1697027884.0,"I'm training a large language model right now with 360M parameters. Before committing to a full run, I am trying different learning rates (with higher / lower batch sizes respectively).

I am having a hard time understanding the pattern of the 1e-4 run (red). Do you guys know what's going on?  
My plan was to go with the largest batch size possible to find better gradient approximation and hopefully converge towards a ""better"" optimum? I know GPT-2 (about the same parameter count) used 6e-4.

Config:  
lr: 1e-6, batch size: 8  
lr: 1e-5: batch size: 80  
lr: 1e-4: batch size: 800

https://preview.redd.it/fyhguv4biktb1.png?width=601&format=png&auto=webp&s=feb55c7eedcb3129029d14d36b792475b58e7b7c"
219,deeplearning,gpt-4,relevance,2023-05-28 17:56:31,Essentials of Multi-modal/Visual-Language models (A video),AvvYaa,False,0.67,1,13u6ptq,https://www.reddit.com/r/deeplearning/comments/13u6ptq/essentials_of_multimodalvisuallanguage_models_a/,0,1685296591.0,"Hello people! I just uploaded a video on my Youtube covering all the major techniques and challenges for training multi-modal models that can combine multiple input sources like images, text, audio, etc to perform amazing cross-modal tasks like text-image retrieval, multimodal vector arithmetic, visual question answering, and language modelling. 

I thought it was a good time to make a video about this topic since more and more recent LLMs are moving away from text-only into visual-language domains (GPT-4, PaLM-2, etc). So in the video I cover as much as I can to provide some intuition about this area - right from basics like contrastive learning (CLIP, ImageBind), all the way to Generative language models (like Flamingo).

&#x200B;

Here is a link to the video:  
 [https://youtu.be/-llkMpNH160](https://youtu.be/-llkMpNH160)

If the above doesn’t work, maybe try this:

[https://m.youtube.com/watch?v=-llkMpNH160&feature=youtu.be](https://m.youtube.com/watch?v=-llkMpNH160&feature=youtu.be)"
220,deeplearning,gpt-4,relevance,2023-08-03 23:38:39,What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?,Claud1ao,False,0.67,1,15hjv2y,https://www.reddit.com/r/deeplearning/comments/15hjv2y/what_would_be_the_initial_costs_of_developing_a/,4,1691105919.0,"I was wondering if this would be super expensive or not.

The cost to develop GPT-3 was about $4 millions according to some resources online. 

Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?

Any answer is appreciated.

Thanks in advance."
221,deeplearning,gpt-4,relevance,2023-09-29 14:02:33,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.88,18,16vch0x,https://www.reddit.com/r/deeplearning/comments/16vch0x/this_week_in_ai_all_the_major_ai_developments_in/,2,1695996153.0,"1. **Meta AI** presents **Emu**, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal.
2. **Meta AI** researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks.
3. **Abacus AI** released a larger 70B version of **Giraffe**. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens\].
4. **Cerebras** and **Opentensor** released Bittensor Language Model, ‘**BTLM-3B-8K**’, a new 3 billion parameter open-source language model with an 8k context length trained on 627B tokens of SlimPajama. It outperforms models trained on hundreds of billions more tokens and achieves comparable performance to open 7B parameter models. The model needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models and is available with an Apache 2.0 license for commercial use.
5. **OpenAI** is rolling out, over the next two weeks, new voice and image capabilities in ChatGPT enabling ChatGPT to understand images, understand speech and speak. The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. .
6. **Mistral AI**, a French startup, released its first 7B-parameter model, **Mistral 7B**, which outperforms all currently available open models up to 13B parameters on all standard English and code benchmarks. Mistral 7B is released in Apache 2.0, making it usable without restrictions anywhere.
7. **Microsoft** has released **AutoGen** \- an open-source framework that enables development of LLM applications using multiple agents that can converse with each other to solve a task. Agents can operate in various modes that employ combinations of LLMs, human inputs and tools.
8. **LAION** released **LeoLM**, the first open and commercially available German foundation language model built on Llama-2
9. Researchers from **Google** and **Cornell University** present and release code for DynIBaR (Neural Dynamic Image-Based Rendering) - a novel approach that generates photorealistic renderings from complex, dynamic videos taken with mobile device cameras, overcoming fundamental limitations of prior methods and enabling new video effects.
10. **Cloudflare** launched **Workers AI** (an AI inference as a service platform), **Vectorize** (a vector Database) and **AI Gateway** with tools to cache, rate limit and observe AI deployments. Llama2 is available on Workers AI.
11. **Amazon** announced the general availability of **Bedrock**, its service that offers a choice of generative AI models from Amazon itself and third-party partners through an API.
12. **Spotify** has launched a pilot program for AI-powered voice translations of podcasts in other languages - in the podcaster’s voic. It uses OpenAI’s newly released voice generation model.
13. **Getty Images** has launched a generative AI image tool, ‘**Generative AI by Getty Images**’, that is ‘commercially‑safe’. It’s powered by Nvidia Picasso, a custom model trained exclusively using Getty’s images library.
14. **Optimus**, Tesla’s humanoid robot, can now sort objects autonomously and do yoga. Its neural network is trained fully end-to-end.
15. **Amazon** will invest up to $4 billion in Anthropic. Developers and engineers will be able to build on top of Anthropic’s models via Amazon Bedrock.
16. **Google Search** indexed shared Bard conversational links into its search results pages. Google says it is working on a fix.

&#x200B;

  
My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
222,deeplearning,gpt-4,relevance,2023-09-24 01:00:34,"Exploring ""Harm Filter for LLM"" as a Research in NLP",junkim100,False,1.0,1,16qkfjr,https://www.reddit.com/r/deeplearning/comments/16qkfjr/exploring_harm_filter_for_llm_as_a_research_in_nlp/,2,1695517234.0,"I'm currently considering a research topic for my combined masters/phd program in an NLP lab. I've been particularly intrigued by the challenges posed by Large Language Models (LLMs) when it comes to generating potentially harmful or inappropriate content. Given the recent ""jailbreaks"" on LLMs, where users have tried to bypass content filters, I believe there's a pressing need to delve deeper into this area.

For my research focus, I've been referring to it as ""Harm Filter for LLM."" However, I'm unsure if there's an established term for this specific area of study. It seems to encompass techniques to prevent models from generating harmful content and strategies to defend against adversarial attempts to bypass these filters.

I came across a few resources that shed light on this topic:

* [**GitHub Repository on LLM Prompt Injection Filtering**](https://github.com/derwiki/llm-prompt-injection-filtering/blob/main/README.md)
* [**Research Paper on Evaluating Large Language Models Trained on Code**](https://arxiv.org/pdf/2307.02483.pdf)
* [**Research Paper on ChatGPT: A Chatbot based on GPT-3.5**](https://arxiv.org/abs/2305.05027)

I have a few questions for the community:

1. Do you think ""Harm Filter for LLM"" (or whatever the established term might be) is a promising research area in NLP?
2. Is there a commonly used term for this field? Could it possibly fall under a broader category like ""Explainable AI""?
3. Any suggestions on where I can delve deeper into this topic?
4. Additionally, I'm also looking for resources to strengthen my foundational knowledge in NLP. Any recommendations would be greatly appreciated!"
223,deeplearning,gpt-4,relevance,2023-01-27 10:45:48,⭕ What People Are Missing About Microsoft’s $10B Investment In OpenAI,LesleyFair,False,0.95,117,10mhyek,https://www.reddit.com/r/deeplearning/comments/10mhyek/what_people_are_missing_about_microsofts_10b/,16,1674816348.0,"&#x200B;

[Sam Altman Might Have Just Pulled Off The Coup Of The Decade](https://preview.redd.it/sg24cw3zekea1.png?width=720&format=png&auto=webp&s=9eeae99b5e025a74a6cbe3aac7a842d2fff989a1)

Microsoft is investing $10B into OpenAI!

There is lots of frustration in the community about OpenAI not being all that open anymore. They appear to abandon their ethos of developing AI for everyone, [free](https://openai.com/blog/introducing-openai/) of economic pressures.

The fear is that OpenAI’s models are going to become fancy MS Office plugins. Gone would be the days of open research and innovation.

However, the specifics of the deal tell a different story.

To understand what is going on, we need to peek behind the curtain of the tough business of machine learning. We will find that Sam Altman might have just orchestrated the coup of the decade!

To appreciate better why there is some three-dimensional chess going on, let’s first look at Sam Altman’s backstory.

*Let’s go!*

# A Stellar Rise

Back in 2005, Sam Altman founded [Loopt](https://en.wikipedia.org/wiki/Loopt) and was part of the first-ever YC batch. He raised a total of $30M in funding, but the company failed to gain traction. Seven years into the business Loopt was basically dead in the water and had to be shut down.

Instead of caving, he managed to sell his startup for $[43M](https://golden.com/wiki/Sam_Altman-J5GKK5) to the finTech company [Green Dot](https://www.greendot.com/). Investors got their money back and he personally made $5M from the sale.

By YC standards, this was a pretty unimpressive outcome.

However, people took note that the fire between his ears was burning hotter than that of most people. So hot in fact that Paul Graham included him in his 2009 [essay](http://www.paulgraham.com/5founders.html?viewfullsite=1) about the five founders who influenced him the most.

He listed young Sam Altman next to Steve Jobs, Larry & Sergey from Google, and Paul Buchheit (creator of GMail and AdSense). He went on to describe him as a strategic mastermind whose sheer force of will was going to get him whatever he wanted.

And Sam Altman played his hand well!

He parleyed his new connections into raising $21M from Peter Thiel and others to start investing. Within four years he 10x-ed the money \[2\]. In addition, Paul Graham made him his successor as president of YC in 2014.

Within one decade of selling his first startup for $5M, he grew his net worth to a mind-bending $250M and rose to the circle of the most influential people in Silicon Valley.

Today, he is the CEO of OpenAI — one of the most exciting and impactful organizations in all of tech.

However, OpenAI — the rocket ship of AI innovation — is in dire straights.

# OpenAI is Bleeding Cash

Back in 2015, OpenAI was kickstarted with $1B in donations from famous donors such as Elon Musk.

That money is long gone.

In 2022 OpenAI is projecting a revenue of $36M. At the same time, they spent roughly $544M. Hence the company has lost >$500M over the last year alone.

This is probably not an outlier year. OpenAI is headquartered in San Francisco and has a stable of 375 employees of mostly machine learning rockstars. Hence, salaries alone probably come out to be roughly $200M p.a.

In addition to high salaries their compute costs are stupendous. Considering it cost them $4.6M to train GPT3 once, it is likely that their cloud bill is in a very healthy nine-figure range as well \[4\].

So, where does this leave them today?

Before the Microsoft investment of $10B, OpenAI had received a total of $4B over its lifetime. With $4B in funding, a burn rate of $0.5B, and eight years of company history it doesn’t take a genius to figure out that they are running low on cash.

It would be reasonable to think: OpenAI is sitting on ChatGPT and other great models. Can’t they just lease them and make a killing?

Yes and no. OpenAI is projecting a revenue of $1B for 2024. However, it is unlikely that they could pull this off without significantly increasing their costs as well.

*Here are some reasons why!*

# The Tough Business Of Machine Learning

Machine learning companies are distinct from regular software companies. On the outside they look and feel similar: people are creating products using code, but on the inside things can be very different.

To start off, machine learning companies are usually way less profitable. Their gross margins land in the 50%-60% range, much lower than those of SaaS businesses, which can be as high as 80% \[7\].

On the one hand, the massive compute requirements and thorny data management problems drive up costs.

On the other hand, the work itself can sometimes resemble consulting more than it resembles software engineering. Everyone who has worked in the field knows that training models requires deep domain knowledge and loads of manual work on data.

To illustrate the latter point, imagine the unspeakable complexity of performing content moderation on ChatGPT’s outputs. If OpenAI scales the usage of GPT in production, they will need large teams of moderators to filter and label hate speech, slurs, tutorials on killing people, you name it.

*Alright, alright, alright! Machine learning is hard.*

*OpenAI already has ChatGPT working. That’s gotta be worth something?*

# Foundation Models Might Become Commodities:

In order to monetize GPT or any of their other models, OpenAI can go two different routes.

First, they could pick one or more verticals and sell directly to consumers. They could for example become the ultimate copywriting tool and blow [Jasper](https://app.convertkit.com/campaigns/10748016/jasper.ai) or [copy.ai](https://app.convertkit.com/campaigns/10748016/copy.ai) out of the water.

This is not going to happen. Reasons for it include:

1. To support their mission of building competitive foundational AI tools, and their huge(!) burn rate, they would need to capture one or more very large verticals.
2. They fundamentally need to re-brand themselves and diverge from their original mission. This would likely scare most of the talent away.
3. They would need to build out sales and marketing teams. Such a step would fundamentally change their culture and would inevitably dilute their focus on research.

The second option OpenAI has is to keep doing what they are doing and monetize access to their models via API. Introducing a [pro version](https://www.searchenginejournal.com/openai-chatgpt-professional/476244/) of ChatGPT is a step in this direction.

This approach has its own challenges. Models like GPT do have a defensible moat. They are just large transformer models trained on very large open-source datasets.

As an example, last week Andrej Karpathy released a [video](https://www.youtube.com/watch?v=kCc8FmEb1nY) of him coding up a version of GPT in an afternoon. Nothing could stop e.g. Google, StabilityAI, or HuggingFace from open-sourcing their own GPT.

As a result GPT inference would become a common good. This would melt OpenAI’s profits down to a tiny bit of nothing.

In this scenario, they would also have a very hard time leveraging their branding to generate returns. Since companies that integrate with OpenAI’s API control the interface to the customer, they would likely end up capturing all of the value.

An argument can be made that this is a general problem of foundation models. Their high fixed costs and lack of differentiation could end up making them akin to the [steel industry](https://www.thediff.co/archive/is-the-business-of-ai-more-like-steel-or-vba/).

To sum it up:

* They don’t have a way to sustainably monetize their models.
* They do not want and probably should not build up internal sales and marketing teams to capture verticals
* They need a lot of money to keep funding their research without getting bogged down by details of specific product development

*So, what should they do?*

# The Microsoft Deal

OpenAI and Microsoft [announced](https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/) the extension of their partnership with a $10B investment, on Monday.

At this point, Microsoft will have invested a total of $13B in OpenAI. Moreover, new VCs are in on the deal by buying up shares of employees that want to take some chips off the table.

However, the astounding size is not the only extraordinary thing about this deal.

First off, the ownership will be split across three groups. Microsoft will hold 49%, VCs another 49%, and the OpenAI foundation will control the remaining 2% of shares.

If OpenAI starts making money, the profits are distributed differently across four stages:

1. First, early investors (probably Khosla Ventures and Reid Hoffman’s foundation) get their money back with interest.
2. After that Microsoft is entitled to 75% of profits until the $13B of funding is repaid
3. When the initial funding is repaid, Microsoft and the remaining VCs each get 49% of profits. This continues until another $92B and $150B are paid out to Microsoft and the VCs, respectively.
4. Once the aforementioned money is paid to investors, 100% of shares return to the foundation, which regains total control over the company. \[3\]

# What This Means

This is absolutely crazy!

OpenAI managed to solve all of its problems at once. They raised a boatload of money and have access to all the compute they need.

On top of that, they solved their distribution problem. They now have access to Microsoft’s sales teams and their models will be integrated into MS Office products.

Microsoft also benefits heavily. They can play at the forefront AI, brush up their tools, and have OpenAI as an exclusive partner to further compete in a [bitter cloud war](https://www.projectpro.io/article/aws-vs-azure-who-is-the-big-winner-in-the-cloud-war/401) against AWS.

The synergies do not stop there.

OpenAI as well as GitHub (aubsidiary of Microsoft) e. g. will likely benefit heavily from the partnership as they continue to develop[ GitHub Copilot](https://github.com/features/copilot).

The deal creates a beautiful win-win situation, but that is not even the best part.

Sam Altman and his team at OpenAI essentially managed to place a giant hedge. If OpenAI does not manage to create anything meaningful or we enter a new AI winter, Microsoft will have paid for the party.

However, if OpenAI creates something in the direction of AGI — whatever that looks like — the value of it will likely be huge.

In that case, OpenAI will quickly repay the dept to Microsoft and the foundation will control 100% of whatever was created.

*Wow!*

Whether you agree with the path OpenAI has chosen or would have preferred them to stay donation-based, you have to give it to them.

*This deal is an absolute power move!*

I look forward to the future. Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

*Thank you for reading!*

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] [https://golden.com/wiki/Sam\_Altman-J5GKK5](https://golden.com/wiki/Sam_Altman-J5GKK5)​

\[2\] [https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny](https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny)​

\[3\] [Article in Fortune magazine ](https://fortune.com/2023/01/11/structure-openai-investment-microsoft/?verification_code=DOVCVS8LIFQZOB&_ptid=%7Bkpdx%7DAAAA13NXUgHygQoKY2ZRajJmTTN6ahIQbGQ2NWZsMnMyd3loeGtvehoMRVhGQlkxN1QzMFZDIiUxODA3cnJvMGMwLTAwMDAzMWVsMzhrZzIxc2M4YjB0bmZ0Zmc0KhhzaG93T2ZmZXJXRDFSRzY0WjdXRTkxMDkwAToMT1RVVzUzRkE5UlA2Qg1PVFZLVlpGUkVaTVlNUhJ2LYIA8DIzZW55eGJhajZsWiYyYTAxOmMyMzo2NDE4OjkxMDA6NjBiYjo1NWYyOmUyMTU6NjMyZmIDZG1jaOPAtZ4GcBl4DA)​

\[4\] [https://arxiv.org/abs/2104.04473](https://arxiv.org/abs/2104.04473) Megatron NLG

\[5\] [https://www.crunchbase.com/organization/openai/company\_financials](https://www.crunchbase.com/organization/openai/company_financials)​

\[6\] Elon Musk donation [https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research](https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research)​

\[7\] [https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/](https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/)"
224,deeplearning,gpt-4,relevance,2023-05-31 13:38:15,New Weaviate Podcast - Kapa AI!,CShorten,False,0.83,4,13wmkpt,https://www.reddit.com/r/deeplearning/comments/13wmkpt/new_weaviate_podcast_kapa_ai/,0,1685540295.0,"Hey everyone, I am SUPER excited to publish our 50th Weaviate Podcast with Emil and Finn from Kapa AI!

Kapa AI is one of the leading companies in taking code documentation and community question answering data, for software companies such as Weaviate, and building these Retrieval-Augmented LLM systems. I can personally vouch for the high quality of Kapa, it is an insanely productive tool for Weaviate development!  

In the podcast, we cover the A-Z on how these systems are built: 

• How long does it take to get a companies' Docs etc. into Kapa? 

• How do companies think about ingesting their community support tickets into these systems? E.g. Slack / Discourse / Forum ""whitelisting"" and so on. 

• How do Emil and Finn think about text chunking and data cleaning? 

• What is the impact of the latest trends in LLMs - status of Hallucination, Long Input Lengths (e.g. GPT-4, MosaicML MPT, Anthropic Claude), Fine-Tuning LLMs with things like LoRA? 

I think Emil and Finn have some really interesting perspectives on this stuff. Always nice to get a mix of academic perspectives, as well as people like Emil and Finn who are really building these systems, selling them to companies, and managing the cost / performance tradeoffs.

https://www.youtube.com/watch?v=cjAhve\_DopY"
225,deeplearning,gpt-4,relevance,2023-10-26 17:59:49,Long text summarization tool how-to (700+ pages),Old_Swan8945,False,0.84,8,17h2fbk,https://www.reddit.com/r/deeplearning/comments/17h2fbk/long_text_summarization_tool_howto_700_pages/,8,1698343189.0,"Hey all I've seen a bunch of posts about summarization of long texts and seems like there's been a lot of challenges, so wanted to spread some knowledge out there about some things I've discovered as I launched my tool here ([summarize-article.co](https://summarize-article.co)) (longest text was a psych book from one of my users at 700+ pages).

The most basic problem in the summarization process is the GPT context window length, so the basic strategy I follow is the following:

1. Chunk the text into chunks that fit inside the context window
2. Recursively summarize the summaries until it becomes manageable
3. Use a long context-window model to generate the final summary using a prompt that takes the recursively-generated summaries and re-restructures the output
4. Additional prompt magic to optimize the outputs (DM me for more details :D)

Anyway, would appreciate any feedback on the results or anything you think could be improved, otherwise feel free to check it out or msg me if you want to learn more about how it works!"
226,deeplearning,gpt-4,relevance,2023-09-30 12:23:31,[D] How to train a seq2seq model to rephrase input text following given rules.,3Ammar404,False,0.5,0,16w5g5p,https://www.reddit.com/r/deeplearning/comments/16w5g5p/d_how_to_train_a_seq2seq_model_to_rephrase_input/,2,1696076611.0,"Hi guys,

I want to train (fine-tune) a seq2seq model to perform the task of rephrasing input following these rules :

1- always follow the pattern ""Entity Verb Entity""

2- only use simple sentences : never combine sentences

3- Don't replace existing words

4- Don't lose the overall meaning of the text or any information in it.

For example:

text = ""Project Risk Management includes the processes of conducting risk management planning, identification, analysis, response planning, response implementation, and monitoring risk on a project""

Standardized Text = ""Project Risk Management conducts risk management planning. Project Risk Management conducts risk identification. Project Risk Management conducts risk analysis. Project Risk Management plans responses. Project Risk Management implements responses. Project Risk Management monitors risk on a project.""

Using ChatGPT the results were very good, but I want to know if I can fine tune a model (BERT, T5, any LM) locally, what should be the data format for training such a model, evaluation metrics ?"
227,deeplearning,gpt-4,relevance,2023-12-06 21:16:44,Platform with algorithm that creates posts,gate-app,False,0.75,4,18cehg4,https://www.reddit.com/r/deeplearning/comments/18cehg4/platform_with_algorithm_that_creates_posts/,7,1701897404.0,"So i made this thing it'll keep growing and growing.

i published my [notes](https://ablaze-mine-be9.notion.site/Algorithm-566bcebb669f49c2aedb63ffd04df3bc?pvs=4) if someones interested im looking for more serious people who believe in this, also for opinions of credible people.

&#x200B;

&#x200B;

one if the ideas:

Tiktok has a huge algorithm but the only thing it does is recommends user created content to people.  what it has is millions of users metrics and how they interact with the content which is what makes its algorithms good.  there can be a platform that collects all that useful metrics too, but uses them not only for recommender model, but also for post creation.  you can take a llm (gpt) today and make it generate posts, then collect millions of peoples interactions and how they respond to them, all the metrics and train the post creator model with it. you can easily make an actual quality content creation bot thats better than any copywriter and understands the relevant details better than anyone.  the reason the other platforms do so well is because of the insane amounts of data they monitor.  the post creation is 2 parts:  one that finds relevant stuff on the internet, tracks events, and just figures out best content to post about.  the other one is llm model that takes any piece of information and converts it into a post with title and all the other fields  both can be trained with data from users.  i am working on this idea further theres a demo with a feed of posts and a chatbot [https://gate-app.com/](https://gate-app.com/) [https://gate-app.com/posts/170145283354301509](https://gate-app.com/posts/170145283354301509) "
228,deeplearning,gpt-4,relevance,2021-08-19 07:03:53,Dual 3090 vs A6000 + Intel vs AMD?,xKaiz3n,False,0.77,7,p79uhm,https://www.reddit.com/r/deeplearning/comments/p79uhm/dual_3090_vs_a6000_intel_vs_amd/,21,1629356633.0,"Hello,

I've been asked to spec out a machine for a range of DL tasks (inc. GPT-3/4 & classification etc.). Looking at prices here (AUS) it seems the price for 2x 3090s (AUD$3000 - 4000) is around the same price as 1x A6000 (AUD$7500 - 8500). 

I've gone into this with a fairly rudimentary understanding of both hardware at this level and deep learning (read: I'm a student & interning), so apologies if I've said something particularly silly.  I'm also looking to see if there are any recommendations for CPU's:

\- do DL packages have a preference for AMD vs Intel like they do with GPU's?

\- which CPU would you guys choose that won't bottleneck the GPUs?

&#x200B;

Thank you!"
229,deeplearning,gpt-4,relevance,2023-06-05 04:33:14,How Open Ai’s Andrej Karpathy Made One of the Best Tutorials in Deep Learning,0ssamaak0,False,0.92,63,141282u,https://www.reddit.com/r/deeplearning/comments/141282u/how_open_ais_andrej_karpathy_made_one_of_the_best/,3,1685939594.0,"I want you to check [my review](https://medium.com/@0ssamaak0/how-open-ais-andrej-karpathy-made-one-of-the-best-tutorials-in-deep-learning-e6b6445a2d05) on Andrej Karpathy amazing work on explaining how GPT is built

[GitHub Repo](https://github.com/0ssamaak0/Karpathy-Neural-Networks-Zero-to-Hero) for code & more details

&#x200B;

https://preview.redd.it/z204zwtzn44b1.png?width=720&format=png&auto=webp&s=095ea00991ebb295f48b70436456b1f283a50df1"
230,deeplearning,gpt-4,relevance,2023-03-05 11:10:56,LLaMA model parallelization and server configuration,ChristmasInOct,False,0.97,24,11ium8l,https://www.reddit.com/r/deeplearning/comments/11ium8l/llama_model_parallelization_and_server/,8,1678014656.0,"Hey everyone,

First of all, tldr at bottom, typed more than expected here.  

Please excuse the rather naive perspective I have here.  I've followed along with great interest, but this is not my industry.

Regardless, I have spent the past 3-4 days falling down a brutally obsessive rabbit hole, and I cannot seem to find this information.  I'm assuming it's just that I am missing context of course, and regardless of whether there is a clear answer, I'm trying to get a better understanding of this topic so that I could better appraise the situation myself.

Really I suppose I have two questions.  **The first** is regarding model parallelization.

I'm assuming this is not generic whatsoever.  What is the typical process engineers go about for designing such a pipeline?  Specifically in regards to these new LLaMA models, is something like ALPA relevant?  Deepspeed?

More importantly, what information should I be seeking to determine this myself?

This roughly segues to my **second inquiry**.

The reason I'm curious about splitting the model pipeline etc., is that I am potentially in interested in standing a server up for this.  Although I don't have much of a budget for this build (\~$30-40K is the rough top-end, but I'd be a lot happier around $20-25K), the money is there if I can genuinely satisfy my use-case.

I work at a small, but borderline manic startup working on enterprise software; 90% of the work we're doing based in the react/node ecosystem, some low-level work for backend services, and some very interesting database work that I have very little to do with.  I am a fullstack engineer that grew up playing with C++ => C#, and somehow ended up spending all of my time r/w'ing javascript.  Lol.  Anyways.

Part of our roadmap since GPT-3 and the playground were made publicly accessible, involves usage of these transformer models, and their ability to interpret natural language inputs, whether from user inputs, or scraped input values generated somewhere in a chain of requests / operations.

Seeing GPT-3 in action made me specifically realize that my estimations on this technology had been wildly off.  Seeing ChatGPT in action and uptick, the API's becoming available, has me further panicked.

Running our inference through their API has never really been an option for us.  I haven't even really looked that far into it, but bottom line the data running through our platform is all back-office, highly sensitive business information, and many have agreements explicitly restricting the movement of data to or from any cloud services, with Microsoft, Amazon, and Google all specifically mentioned.

Regardless of the reasoning for these contracts, the LLaMA release has had me obsessed over this topic in more detail than before, and whether or not I would be able to get this setup privately, for our use-case.

**To get to the actual second inquiry**:

Say I want to throw a budget rig together for this in a server cabinet.  Am I able to effectively parallelize the LLaMA model, well enough to justify going with 24GB VRAM 4090's in the rig?  Say I do so with DeepSpeed, or some of the standard model parallelization libraries.

Is the performance cost low enough to justify taking the extra compute here over 1/3 - 1/2 as many RTX6000 ADA's?

Or should I be grabbing the 48GB ADA's?

Like I said, I apologize for the naivety, I'm really looking for more information so that I can start to put this picture together better on my own.  It really isn't the easiest topic to research with how quickly things seem to move, and the giant gap between conversation depths (gamer || phd in a lot of the most interesting or niche discussions, little between).

Thank you very much for your time.

TL;DR - Any information on LLaMA model parallelization at the moment?  Will it be compatible with things like zero or alpa?  How about for throwing a rig together right now for fine-tuning and then running inference on the LLaMA models?  48GB 6000 ADA's, or 24GB 4090's?

Planning on putting it in a mostly empty 42U cabinet that also houses our primary web server and networking hardware, so if there is a sales pitch for 4090's across multiple nodes here, I do have a massive bias as the kind of nerd that finds that kind of hardware borderline erotic.

Hydro and cooling are not an issue, just usage of the budget and understanding the requirements / approach given memory limitations, and how to avoid communication bottlenecks or even balance them against raw compute.

Thanks again everyone!"
231,deeplearning,gpt-4,relevance,2022-12-23 14:35:17,How to change career trajectory to NLP engineer,Creative-Milk-8266,False,0.85,13,zth8rl,https://www.reddit.com/r/deeplearning/comments/zth8rl/how_to_change_career_trajectory_to_nlp_engineer/,3,1671806117.0," A little of my background - 5 years experience in data science. Mostly related to prototyping statistical models and optimization problems, bringing them into production. Some experience in building pipeline and orchestration flow with AWS services.

I have basic understanding on Transformers, BERT, GPT. Did my first NLP Kaggle competition the first time recently.

I'd like my next job to be a NLP engineer. How should I prepare myself for it?

Here's some of the items I'm thinking

&#x200B;

1. More hands on projects I can put on resume, including integration with cloud services. Any recommendations on what kinds of projects I should pick?  
 
2. Tryout techniques of speeding up models like distilled model, dynamic shape, quantization. Anything else that would be helpful?  
 
3. Understand lower level of GPU programming knowledges. Not sure if this is helpful for me finding a NLP job. If so, what kind of things I can do to go deeper on this subject. I'm currently taking [Intro to Parallel Programming](https://classroom.udacity.com/courses/cs344) CS344 course on Udemy (highly recommend btw).  
 
4. Grind leetcode :/  
 

Please point out other important directions I missed."
232,deeplearning,gpt-4,relevance,2023-06-29 19:49:38,"Open Orca, an open sourced replication of Microsofts Orca is in development! Heres the dataset!",Alignment-Lab-AI,False,0.93,11,14mejzk,https://www.reddit.com/r/deeplearning/comments/14mejzk/open_orca_an_open_sourced_replication_of/,2,1688068178.0,"Today we are releasing a dataset that lets open source models learn to think like GPT-4!

We call this Open Orca, as a tribute to the team who has released the Orca paper describing the data collection methods we have attempted to replicate in an open-source manner for the benefit of humanity.

With this data, we expect new open source models to be developed which are smaller, faster, and smarter than ever before because were going to be the ones doing the developing!

[https://huggingface.co/datasets/Open-Orca/OpenOrca](https://huggingface.co/datasets/Open-Orca/OpenOrca)

We'd like to give special recognition to the following contributors for their significant efforts and dedication:

caseus

Eric Hartford

NanoBit

Pankaj

winddude

Rohan

[http://alignmentlab.ai/:](http://alignmentlab.ai/:)

Entropi

neverendingtoast

AtlasUnified

AutoMeta

lightningRalf

NanoBit

caseus

The Orca paper has been replicated to as fine of a degree of precision as a motley crew of ML nerds toiling for weeks could pull off (a very high degree).

We will be releasing trained Orca models as the training currently in progress completes.

The dataset is still in final cleanup, and we will continue with further augmentations beyond the base Orca data in due time.

Right now, we are testing our fifth iteration of Orca on a subset of the final data, and are just about to jump into the final stages!

Many thanks to NanoBit and Caseus, makers of Axolotl \[[https://github.com/OpenAccess-AI-Collective/axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)\] for lending us their expertise on the platform that developed and trained manticore, minotaur, and many others!

If you want to follow along, meet the devs, ask us questions, get involved, or check out our other projects, such as:

Landmark Attention

[https://twitter.com/Yampeleg's](https://twitter.com/Yampeleg's) recently announced context extension method, which outperforms rope (were going to push this one later today)

EDIT: We've been made aware that Eric Hartford, a team member who chose to depart our team yesterday after some internal discussion of our grievances, has made claims to be the sole originator of the Open Orca project and to claim the work as his own. We wish to clarify that this was a team effort from the outset, and he was one of over a dozen data scientists, machine learning engineers, and other specialists who have been involved in this project from the outset.

Eric joined the team with the mutual understanding that we were all to be treated as equals and get our due credit for involvement, as well as say in group decisions.

He made snap decisions on behalf of the team contrary to long term plans, including announcing the project publicly on his blog, and implying that he was the sole originator and project lead.

We attempted to reconcile this internally, but he chose to depart from the team.

As such, we elected to release the data publicly in advance of original plans.

We have appropriately attributed he and all other contributors, as was originally planned.

We thank Eric for his contributions to the project and wish him well on his individual endeavors.

This repo is the original repo from which the entire team had agreed to work out of and publish out of from the outset.

Eric's repo represents his duplication and augmentation of the team's collective effort, initiated after he had chosen to depart the team."
233,deeplearning,gpt-4,relevance,2020-06-30 19:19:50,"Training a GPT-2 from scratch in Greek-text, results in a low perplexity score of 7 after 15 epochs. Is it normal that score?",ni_klaras,False,0.8,3,hiu5eu,https://www.reddit.com/r/deeplearning/comments/hiu5eu/training_a_gpt2_from_scratch_in_greektext_results/,0,1593544790.0,"I try to train a GPT-2 from scratch in Greek with an older version of run\_language\_modeling.py ([https://github.com/huggingface/transformers/tree/master/examples/language-modeling](https://github.com/huggingface/transformers/tree/master/examples/language-modeling)) script from *HuggingFace* repo, but I get a low perplexity score of 7 after 15 epochs.

My data for train is about 4.6Gb and is constructed as 5 sentences per line. The data for the evaluation is about 450Mb constructed with the same way. Use of BPE for the encoding with a vocab of 22000 merges.

The loss and the evaluation loss seems to move normal . Even when i test it in the end for generation seems normal.

But the perplexity score is a question..."
234,deeplearning,gpt-4,relevance,2020-10-30 01:48:31,Generating Snort Rules using GPT2,afoteygh,False,1.0,1,jkntfp,https://www.reddit.com/r/deeplearning/comments/jkntfp/generating_snort_rules_using_gpt2/,0,1604022511.0,"Hi I have been working on Generating Snort rules using the GPT2 Transformer.

This is my thinking

1. Snort rules for a particular family of malware are quite related. that is why these malware have been classified into that family so using text generation to generate new rules should be possible (i Feel)
2. Collect Snort rules for a particular malware family. (Also collect pcap which trigger these specific rules i have obtained)
3. Clean it up by removing commented/unused rules.
4. Feed the rules to GPT2 (124M) (I chose this because i read it performs quite well in text generation )
5. Trained GPT on the dataset
6. using it to generated new rules
7. clean up the rules (syntax etc)
8. Test newly generated rules in snort with sample pcap files.

So for i have been able to generate and clean up 1000's of rules and tested them without any success!

Can anyone give me some guidance on what i am doing wrong or if my whole hypothesis and experiment is flawed."
235,deeplearning,gpt-4,relevance,2020-07-26 07:39:05,Crazy Numbers of GPT-3,alaap001,False,0.5,0,hy2vg1,https://www.reddit.com/r/deeplearning/comments/hy2vg1/crazy_numbers_of_gpt3/,2,1595749145.0,"Trained on over 285,000 CPU cores and 10,000 GPUs cluster, a lot of hype going around the latest GPT-3 model, those who are not into AI, it is the most advanced NLP algorithm to date. It learned the human-level language from over 400GB of data, costing crazy $12 million just to train it with \~175 Billion!! parameters. A typical high-end GPU would take over 350 years to train this model. As a Data Scientist, I thought why not look at how much data it took to learn human language. 

Well, here are the crazzyy numbers.

It used roughly 9 Million Hindi words,

3 Billion for German

and

4 Billion French words with 100 other languages. 

https://preview.redd.it/2b6aee0un5d51.png?width=937&format=png&auto=webp&s=3d4fa2e1b2621ae699ec1bb4a62d7cc85554c8d1

https://preview.redd.it/ec7tve0un5d51.png?width=871&format=png&auto=webp&s=9d8624d117ad4e1f41fff78f06bb30197abbd006

and all this fades away when English comes in with over 180 Billion words!! \[ For reference English has only 171,476 unique words with 20000 being used normally \]

It seems crazy how AI is being built so rapidly and now can talk like a human. Gets me excited thinking about what the future holds. 

***If you're the one who is getting started with Deep Learning then for you I created a website wherein I plan to do 100 Deep Learning Projects to help people understand the practicality of Deep Learning. You can visit*** [***https://www.aiunquote.com/***](https://www.aiunquote.com/) ***and learn deep learning by implementing,***

**#artificialintelligence** **#technology** **#AI** **#naturallanguageprocessing** **#gpt3** **#tableaupublic** **#computerscience** **#maths** **#innovation** **#datascience**"
236,deeplearning,gpt-4,relevance,2022-08-14 10:58:04,OneFlow v0.8.0 Came Out!,Just0by,False,1.0,6,wo3o9l,https://www.reddit.com/r/deeplearning/comments/wo3o9l/oneflow_v080_came_out/,1,1660474684.0,"Hi all,

We are thrilled to announce the new release of [**OneFlow**](https://github.com/Oneflow-Inc/oneflow)**, which is a deep learning framework designed to be user-friendly, scalable and efficient.** OneFlow v0.8.0 update contains 523 commits. For the full changlog, please check out: [**https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.8.0**](https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.8.0).  


**Paper:** [https://arxiv.org/abs/2110.15032](https://arxiv.org/abs/2110.15032);  
**Code:** [https://github.com/Oneflow-Inc/oneflow](https://github.com/Oneflow-Inc/oneflow)

Welcome to install OneFlow v0.8.0 for a new user experience. Your feedbacks will be much appreciated!

Highlights and optimizations in this release:

**1. PyTorch API compatibility**

OneFlow v0.8.0 provides more and better PyTorch compatible APIs. In v0.8.0, a series of new features and interfaces that are compatible with PyTorch 1.10.0 are in place, including 68 new APIs that are aligned with PyTorch; 84 bugs are fixed to ensure better compatibility between operators and interfaces, allowing users to transfer more PyTorch models to OneFlow with just one click.

&#x200B;

**2. Wider support of global operators**

All operators support Global Tensor more widely and efficiently. Fixed 28 bugs related to Global Tensor and added 180 Global operator unit tests, making the development of distributed models with Global Tensor faster and easier.

&#x200B;

**3. Better performance**

The advanced features of Graph have been improved for better performance:

In addition to the original ZeRO-DP, ZeRO can be used in parallel with MP, 2-D, and 3-D to further reduce memory overhead.

Added a new pipeline parallelism API for Graph to simplify the configuration for pipeline parallelism and accelerate training when using pipeline parallelism and 3-D parallelism.

Added debugging features in multiple dimensions, including logical graphs, light plan physical graphs, memory analysis, and Python stack information, to further improve efficiency of Graph.debug.

The combination of OneFlow v0.8.0 and LiBai v0.2.0 enables higher computation speeds of GPT and BERT under 3-D parallelism on multiple dimensions, surpassing those of Megatron-LM with the same configurations. (For more details, see: [https://libai.readthedocs.io/en/latest/tutorials/get\_started/Benchmark.html](https://libai.readthedocs.io/en/latest/tutorials/get_started/Benchmark.html)).

&#x200B;

**4. OneEmbedding component**

OneEmbedding is an extended component specifically designed for large-scale recommender systems. It boasts excellent performance, extensibility, and flexibility.

API Documentation: [https://docs.oneflow.org/en/master/cookies/one\_embedding.html](https://docs.oneflow.org/en/master/cookies/one_embedding.html)

&#x200B;

**5. Multi-Device adaptation**

OneFlow v0.8.0 provides a neat, efficient, and easily extensible hardware abstraction layer EP (Execution Provider) to adapt to different hardware. With the introduction of the hardware abstraction layer, no modifications are needed for any module of the framework to adapt to new hardware devices, regardless of the implementation details of any underlying hardware or framework.

To make the new hardware devices work, users only need to implement a series of interfaces based on the protocols of the hardware abstraction interfaces and the status quo of the hardware devices.

EP also defines a set of basic computing interface primitives, allowing the reimplementation of kernels. Primitives provide interfaces that are more flexible than the runtime interfaces provided by EP. Different interfaces are independent of each other, and each interface represents a kind of computing capability that can be provided by a certain hardware device.

**6. Debugging tool stack**

New debug tools: OneFlow-Profiler and AutoProf.

OneFlow-Profiler is a tool used to collect performance information during framework execution. It can keep records of the execution time of operators and system components, the allocation of memory, and the corresponding input and parameters of operators. All this information helps developers find out the main source of overhead in framework execution and thus implement targeted optimization.

AutoProf is a framework for testing the performance of OneFlow and PyTorch operators. It provides an elegant and efficient method to detect the alignment between OneFlow APIs and PyTorch APIs, allowing users to conveniently compare the performance of OneFlow APIs and PyTorch APIs.

**7. Error message**

Improved error message with more details. Refactored exception handling.

&#x200B;

**8. API documentation**

Made over 20 revisions to the OneFlow API documentation, restructured the documentation based on features, and added further elaboration of modules and environment variables including OneFlow oneflow.nn.graph, oneflow.embedding, and oneflow.autograd, in addition to the general operator APIs."
237,deeplearning,gpt-4,relevance,2023-02-01 15:20:25,Launching my first-ever open-source project and it might make your ChatGPT answers better,Vegetable-Skill-9700,False,0.75,2,10qx9po,https://www.reddit.com/r/deeplearning/comments/10qx9po/launching_my_firstever_opensource_project_and_it/,6,1675264825.0,"I am building UpTrain - an open-source ML diagnostic toolkit that recently got investment from YCombinator.

As you know no ML model is 100% accurate, and, further, their accuracy deteriorates over time 😣. Additionally, due to the black boxiness ⬛ nature of Large Language models, it's challenging to identify and fix their problems.

The tool helps ML practitioners to:
1. Understand how their models are performing in production
2. Catch edge cases and outliers to help them refine their models
3. Allow them to define custom monitors to catch under-performing data-points
4. Retrain the model on them to improve its accuracy

You can check out the project here: https://github.com/uptrain-ai/uptrain. Would love to hear feedback from the community!"
238,deeplearning,gpt-4,relevance,2023-04-08 07:55:07,need help. GPT-3.5 can't solve it.,ryanultralifeio,False,0.25,0,12ff87f,https://www.reddit.com/r/deeplearning/comments/12ff87f/need_help_gpt35_cant_solve_it/,8,1680940507.0,"Trying to make a schedule for the league, here are the constraints.  I think it should be tailormade for AI.


Schedule May 2023 Games.

￼￼

I need you to schedule games between 7 teams, on 4 fields, beginning on Monday May 1st for the whole month of May 2023. 

The 4 fields are; Quincy, Portola, Chester and Loyalton. Fields in Quincy, Portola and Loyalton are available beginning May 1st. The field in Chester is available beginning May 8th.

 Saturdays can have 3 games per day at either 10am, 1pm, or 4 pm. 

No games on Sunday. 

Monday, Tuesday, Wednesday, Thursday, and Friday games are at 5:00. 

Mondays, Tuesdays, Wednesdays, Thursdays, and Fridays can have games played on 3 different fields at the same time. 

There are 7 teams. Quincy Red, Quincy Blue, Quincy Grey, Portola Padres, Portola Dodgers, Chester Giants and Loyalton. 

All teams can only play each other 2 times in May with the exceptions of Quincy Grey and Quincy Red, Quincy Grey and Quincy Blue, and Quincy Grey and Chester Giants, who can only play each other 1 time in May. 

Only Loyalton cannot play on May 3,4, or 5 for Sierra Nevada Journeys. 

All teams are unavailable to play May 26,27,29 for Memorial Day Weekend. 

All teams are unavailable to play May 17,18,19 for 6th grade field trip. 

Each team will play one home game against each other, except for the teams only playing one game. 

Quincy Blue only plays home games on Quincy field on Mondays, and Thursdays. 

Quincy Grey only plays home games on Quincy field on Wednesdays, and Fridays. 

Quincy Red only plays home games on Quincy Field on Tuesdays, Thursdays, and Fridays. 

Loyalton only plays home games on Loyalton field. 

Chester Giants only play Home Games on Chester field. 

Portola Padres only play home games on Portola field. 

Portola Dodgers only play home games on Portola field. 

Each team can play a maximum of two games per week. 

A team cannot play without two calenders days between games. 

A team cannot play two games on consecutive days.

A team cannot play two games on the same day. 

Teams must have at least 9 games.

Put the total number of games played per team at the bottom of the whole months schedule.

2+ hours a no good results........."
