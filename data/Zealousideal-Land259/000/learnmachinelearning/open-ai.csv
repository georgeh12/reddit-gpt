,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,id,url,num_comments,created,body
0,learnmachinelearning,open-ai,top,2020-09-26 13:10:55,Trying to keep my Jump Rope and AI Skills on point! Made this application using OpenPose. Link to the Medium tutorial and the GitHub Repo in the thread.,jumper_oj,False,0.99,1179,j05rte,https://v.redd.it/jh5n48ghrhp51,29,1601125855.0,
1,learnmachinelearning,open-ai,top,2020-08-05 10:58:02,image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model,OnlyProggingForFun,False,0.97,641,i437om,https://www.youtube.com/watch?v=FwXQ568_io0,46,1596625082.0,
2,learnmachinelearning,open-ai,top,2023-04-03 16:39:55,"If you are looking for courses about Artificial Intelligence, I created the repository with links to resources that I found super high quality and helpful. The link is in the comment.",RandomForests92,False,0.99,598,12apw9o,https://i.redd.it/jczyjswj6pra1.png,62,1680539995.0,
3,learnmachinelearning,open-ai,top,2021-04-17 14:35:34,*Semantic* Video Search with OpenAI’s CLIP Neural Network (link in comments),designer1one,False,1.0,492,msruz1,https://i.redd.it/dlw52klsvqt61.gif,53,1618670134.0,
4,learnmachinelearning,open-ai,top,2023-01-10 11:12:01,Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI,BackgroundResult,False,0.97,449,1087ady,https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion,102,1673349121.0,
5,learnmachinelearning,open-ai,top,2019-10-23 23:58:05,OpenAI plays hide and seek and breaks the game. (Reinforcement Learning),UnintelligibleThing,False,0.97,342,dm86ay,https://www.youtube.com/watch?v=Lu56xVlZ40M,19,1571875085.0,
6,learnmachinelearning,open-ai,top,2023-01-19 07:56:20,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.96,334,10fw2df,https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/,47,1674114980.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
7,learnmachinelearning,open-ai,top,2020-12-22 22:31:24,Study Plan for Learning Data Science Over the Next 12 Months [D],daniel-data,False,0.98,306,kifqtc,https://www.reddit.com/r/learnmachinelearning/comments/kifqtc/study_plan_for_learning_data_science_over_the/,58,1608676284.0,"In this thread, I address a study plan for 2021.

In case you're interested, I wrote a whole article about this topic: [Study Plan for Learning Data Science Over the Next 12 Months](https://www.datasource.ai/en/data-science-articles/study-plan-for-learning-data-science-over-the-next-12-months)

Let me know your thoughts on this.

&#x200B;

https://preview.redd.it/emg20nzhet661.png?width=1170&format=png&auto=webp&s=cf09e4dc5e82ba2fd7b57c706ba2873be57fe8de

We are ending 2020 and it is time to make plans for next year, and one of the most important plans and questions we must ask is what do we want to study?, what do we want to enhance?, what changes do we want to make?, and what is the direction we are going to take (or continue) in our professional careers?.

Many of you will be starting on the road to becoming a data scientist, in fact you may be evaluating it, since you have heard a lot about it, but you have some doubts, for example about the amount of job offers that may exist in this area, doubts about the technology itself, and about the path you should follow, considering the wide range of options to learn.

I’m a believer that we should learn from various sources, from various mentors, and from various formats. By sources I mean the various virtual platforms and face-to-face options that exist to study. By mentors I mean that it is always a good idea to learn from different points of view and learning from different teachers/mentors, and by formats I mean the choices between books, videos, classes, and other formats where the information is contained.

When we extract information from all these sources we reinforce the knowledge learned, but we always need a guide, and this post aims to give you some practical insights and strategies in this regard.

To decide on sources, mentors and formats it is up to you to choose. It depends on your preferences and ease of learning: for example, some people are better at learning from books, while others prefer to learn from videos. Some prefer to study on platforms that are practical (following online code), and others prefer traditional platforms: like those at universities (Master’s Degree, PHDs or MOOCs). Others prefer to pay for quality content, while others prefer to look only for free material. That’s why I won’t give a specific recommendation in this post, but I’ll give you the whole picture: **a study plan**.

To start you should consider the time you’ll spend studying and the depth of learning you want to achieve, because if you find yourself without a job you could be available full time to study, which is a huge advantage. On the other hand, if you are working, you’ll have less time and you’ll have to discipline yourself to be able to have the time available in the evenings, mornings or weekends. Ultimately, the important thing is to meet the goal of learning and perhaps dedicating your career to this exciting area!

We will divide the year into quarters as follows

* **First Quarter**: Learning the Basics
* **Second Quarter**: Upgrading the Level: Intermediate Knowledge
* **Third Quarter**: A Real World Project — A Full-stack Project
* **Fourth Quarter**: Seeking Opportunities While Maintaining Practice

# First Quarter: Learning the Basics

&#x200B;

https://preview.redd.it/u7t9bthket661.png?width=998&format=png&auto=webp&s=4ad29cb43618e7acf793259243aa5a60a8535f0a

If you want to be more rigorous you can have start and end dates for this period of study of the bases. It could be something like: From January 1 to March 30, 2021 as deadline. During this period you will study the following:

## A programming language that you can apply to data science: Python or R.

We recommend Python due to the simple fact that approximately 80% of data science job offers ask for knowledge in Python. That same percentage is maintained with respect to the real projects you will find implemented in production. And we add the fact that Python is multipurpose, so you won’t “waste” your time if at some point you decide to focus on web development, for example, or desktop development. This would be the first topic to study in the first months of the year.

## Familiarize yourself with statistics and mathematics.

There is a big debate in the data science community about whether we need this foundation or not. I will write a post later on about this, but the reality is that you **DO** need it, but **ONLY** the basics (at least in the beginning). And I want to clarify this point before continuing.

We could say that data science is divided in two big fields: Research on one side and putting Machine Learning algorithms into production on the other side. If you later decide to focus on Research then you are going to need mathematics and statistics in depth (very in depth). If you are going to go for the practical part, the libraries will help you deal with most of it, under the hood. It should be noted that most job offers are in the practical part.

For both cases, and in this first stage you will only need the basics of:

* **Statistics (with Python and NumPy)**

1. Descriptive statistics
2. Inferential Statistics
3. Hypothesis testing
4. Probability

* **Mathematics (with Python and NumPy)**

1. Linear Algebra (For example: SVD)
2. Multivariate Calculus
3. Calculus (For example: gradient descent)

**Note**: We recommend that you study Python first before seeing statistics and mathematics, because the challenge is to implement these statistical and mathematical bases with Python. Don’t look for theoretical tutorials that show only slides or statistical and/or mathematical examples in Excel/Matlab/Octave/SAS and other different to Python or R, it gets very boring and impractical! You should choose a course, program or book that teaches these concepts in a practical way and using Python. Remember that Python is what we finally use, so you need to choose well. **This advice is key so you don’t give up on this part, as it will be the most dense and difficult**.

If you have these basics in the first three months, you will be ready to make a leap in your learning for the next three months.

# Second Quarter: Upgrading the Level: Intermediate Knowledge

&#x200B;

https://preview.redd.it/y1y55vynet661.png?width=669&format=png&auto=webp&s=bd3e12bb112943025c39a8975faf4d64514df275

If you want to be more rigorous you can have start and end dates for this period of study at the intermediate level. It could be something like: From April 1 to June 30, 2021 as deadline.

Now that you have a good foundation in programming, statistics and mathematics, it is time to move forward and learn about the great advantages that Python has for applying data analysis. For this stage you will be focused on:

## Data science Python stack

Python has the following libraries that you should study, know and practice at this stage

* **Pandas**: for working with tabular data and make in-depth analysis
* **Matplotlib and Seaborn**: for data visualization

Pandas is the in-facto library for data analysis, it is one of the most important (if not the most important) and powerful tools you should know and master during your career as a data scientist. Pandas will make it much easier for you to manipulate, cleanse and organize your data.

## Feature Engineering

Many times people don’t go deep into Feature Engineering, but if you want to have Machine Learning models that make good predictions and improve your scores, spending some time on this subject is invaluable!

Feature engineering is the process of using domain knowledge to extract features from raw data using data mining techniques. These features can be used to improve the performance of machine learning algorithms. Feature engineering can be considered as applied machine learning itself. To achieve the goal of good feature engineering you must know the different techniques that exist, so it is a good idea to at least study the main ones.

## Basic Models of Machine Learning

At the end of this stage you will start with the study of Machine Learning. This is perhaps the most awaited moment! This is where you start to learn about the different algorithms you can use, which particular problems you can solve and how you can apply them in real life.

The Python library we recommend you to start experimenting with ML is: scikit-learn. *However it is a good idea that you can find tutorials where they explain the implementation of the algorithms (at least the simplest ones) from scratch with Python, since the library could be a “****Black Box****” and you might not understand what is happening under the hood. If you learn how to implement them with Python, you can have a more solid foundation*.

If you implement the algorithms with Python (without a library), you will put into practice everything seen in the statistics, mathematics and Pandas part.

These are some recommendations of the algorithms that you should at least know in this initial stage

* **Supervised learning**
   * Simple Linear Regression
   * Multiple Linear Regression
   * K-nearest neighbors (KNN)
   * Logistic Regression
   * Decision Trees
   * Random Forest
* **Unsupervised Learning**
   * K-Means
   * PCA

**Bonus**: if you have the time and you are within the time ranges, you can study these others

* **Gradient Boosting Algorithms**
   * GBM
   * XGBoost
   * LightGBM
   * CatBoost

**Note**: do not spend more than the 3 months stipulated for this stage. Because you will be falling behind and not complying with the study plan. We all have shortcomings at this stage, it is normal, go ahead and then you can resume some concepts that did not understand in detail. The important thing is to have the basic knowledge and move forward!

*If at least you succeed to study the mentioned algorithms of supervised and unsupervised learning, you will have a very clear idea of what you will be able to do in the future*. So don’t worry about covering everything, remember that it is a process, and ideally you should have some clearly established times so that you don’t get frustrated and feel you are advancing.

So far, here comes your “theoretical” study of the basics of data science. Now we’ll continue with the practical part!

# Third Quarter: A Real World Project — A Full-stack Project

&#x200B;

https://preview.redd.it/vrn783vqet661.png?width=678&format=png&auto=webp&s=664061b3d33b34979b74b10b9f8a3d0f7b8b99ee

If you want to be more rigorous you can have start and end dates for this period of study at the intermediate level. It could be something like: From July 1 to September 30, 2021 as deadline.

Now that you have a good foundation in programming, statistics, mathematics, data analysis and machine learning algorithms, it is time to move forward and put into practice all this knowledge.

Many of these suggestions may sound out of the box, but believe me they will make a big difference in your career as a data scientist.

## The first thing is to create your web presence:

* *Create a Github (or GitLab) account, and learn Git*. Being able to manage different versions of your code is important, you should have version control over them, not to mention that having an active Github account is very valuable in demonstrating your true skills. On Github, you can also set up your Jupyter Notebooks and make them public, so you can show off your skills as well. This is mine for example: [https://github.com/danielmoralesp](https://github.com/danielmoralesp)
* *Learn the basics of web programming*. The advantage is that you already have Python as a skill, so you can learn Flask to create a simple web page. Or you can use a template engine like Github Pages, Ghost or Wordpress itself and create your online portfolio.
* *Buy a domain with your name*. Something like myname.com, myname.co, myname.dev, etc. This is invaluable so you can have your CV online and update it with your projects. There you can make a big difference, showing your projects, your Jupyter Notebooks and showing that you have the practical skills to execute projects in this area. There are many front-end templates for you to purchase for free or for payment, and give it a more personalized and pleasant look. Don’t use free sub-domains of Wordpress, Github or Wix, it looks very unprofessional, make your own. Here is mine for example: [https://www.danielmorales.dev/](https://www.danielmorales.dev/)

## Choose a project you are passionate about and create a Machine Learning model around it.

The final goal of this third quarter is to create **ONE** project, that you are passionate about, and that is **UNIQUE** among others. It turns out that there are many typical projects in the community, such as predicting the Titanic Survivors, or predicting the price of Houses in Boston. Those kinds of projects are good for learning, but not for showing off as your **UNIQUE** projects.

If you are passionate about sports, try predicting the soccer results of your local league. If you are passionate about finance, try predicting your country’s stock market prices. If you are passionate about marketing, try to find someone who has an e-commerce and implement a product recommendation algorithm and upload it to production. If you are passionate about business: make a predictor of the best business ideas for 2021 :)

As you can see, you are limited by your passions and your imagination. ***In fact,*** ***those are the two keys for you to do this project: Passion and Imagination***.

However don’t expect to make money from it, you are in a learning stage, you need that algorithm to be deployed in production, make an API in Flask with it, and explain in your website how you did it and how people can access it. This is the moment to shine, and at the same time it’s the moment of the greatest learning.

You will most likely face obstacles, if your algorithm gives 60% of Accuracy after a huge optimization effort, it doesn’t matter, finish the whole process, deploy it to production, try to get a friend or family member to use it, and that will be the goal achieved for this stage: **Make a Full-stack Machine Learning project.**

By full-stack I mean that you did all the following steps:

* You got the data from somewhere (scrapping, open data or API)
* You did a data analysis
* You cleaned and transformed the data
* You created Machine Learning Models
* You deployed the best model to production for other people to use.

This does not mean that this whole process is what you will always do in your daily job, but it does mean that you will know every part of the pipeline that is needed for a data science project for a company. You will have a unique perspective!

# Fourth Quarter: Seeking Opportunities While Maintaining Practice

&#x200B;

https://preview.redd.it/qd0osystet661.png?width=1056&format=png&auto=webp&s=2da456b15985b2793041256f5e45bca99a23b51a

If you want to be more rigorous you can have start and end dates for this period of study at the final level. It could be something like: From October 1 to December 31, 2021 as deadline.

Now you have theoretical and practical knowledge. You have implemented a model in production. The next step depends on you and your personality. Let’s say you are an entrepreneur, and you have the vision to create something new from something you discovered or saw an opportunity to do business with this discipline, so it’s time to start planning how to do it. If that’s the case, obviously this post won’t cover that process, but you should know what the steps might be (or start figuring them out).

But if you are one of those who want to get a job as a data scientist, here is my advice.

## Getting a job as a data scientist

>*“You’re not going to get a job as fast as you think, if you keep thinking the same way”.Author*

It turns out that all people who start out as data scientists imagine themselves working for the big companies in their country or region. Or even remote. It turns out that if you aspire to work for a large company like data scientist you will be frustrated by the years of experience they ask for (3 or more years) and the skills they request.

Large companies don’t hire Juniors (or very few do), precisely because they are already large companies. They have the financial muscle to demand experience and skills and can pay a commensurate salary (although this is not always the case). The point is that if you focus there you’re going to get frustrated!

Here we must return to the following advise: ***“You need creativity to get a job in data science”***.

Like everything else in life we have to start at different steps, in this case, from the beginning. Here are the scenarios

* *If you are working in a company and in a non-engineering role you must demonstrate your new skills to the company you are working for*. If you are working in the customer service area, you should apply it to your work, and do for example, detailed analysis of your calls, conversion rates, store data and make predictions about it! If you can have data from your colleagues, you could try to predict their sales! This may sound funny, but it’s about how creatively you can apply data science to your current work and how to show your bosses how valuable it is and **EVANGELIZE** them about the benefits of implementation. You’ll be noticed and they could certainly create a new data related department or job. And you already have the knowledge and experience. The key word here is **Evangelize**. Many companies and entrepreneurs are just beginning to see the power of this discipline, and it is your task to nurture that reality.
* *If you are working in an area related to engineering, but that is not data science*. Here the same applies as the previous example, but you have some advantages, and that is that you could access the company’s data, and you could use it for the benefit of the company, making analyses and/or predictions about it, and again **EVANGELIZING** your bosses your new skills and the benefits of data science.
* *If you are unemployed (or do not want, or do not feel comfortable following the two examples above)*, you can start looking outside, and what I recommend is that you look for technology companies and / or startups where they are just forming the first teams and are paying some salary, or even have options shares of the company. Obviously here the salaries will not be exorbitant, and the working hours could be longer, but remember that you are in the learning and practice stage (just in the first step), so you can not demand too much, you must land your expectations and fit that reality, and stop pretending to be paid $ 10,000 a month at this stage. But, depending of your country $1.000 USD could be something very interesting to start this new career. Remember, you are a Junior at this stage.

***The conclusion is: don’t waste your time looking at and/or applying to offers from big companies, because you will get frustrated. Be creative, and look for opportunities in smaller or newly created companies***.

## Learning never stops

While you are in that process of looking for a job or an opportunity, which could take half of your time (50% looking for opportunities, 50% staying in practice), you have to keep learning, you should advance to concepts such as Deep Learning, Data Engineer or other topics that you feel were left loose from the past stages or focus on the topics that you are passionate about within this group of disciplines in data science.

At the same time you can choose a second project, and spend some time running it from end-to-end, and thus increase your portfolio and your experience. If this is the case, try to find a completely different project: if the first one was done with Machine Learning, let this second one be done with Deep learning. If the first one was deployed to a web page, that this second one is deployed to a mobile platform. Remember, creativity is the key!

# Conclusion

We are at an ideal time to plan for 2021, and if this is the path you want to take, start looking for the platforms and media you want to study on. Get to work and don’t miss this opportunity to become a data scientist in 2021!

Note: we are building a private community in Slack of data scientist, if you want to join us write to the email: [support@datasource.ai](mailto:support@datasource.ai)

I hope you enjoyed this reading! you can follow me on [twitter](https://twitter.com/daniel_moralesp) or [linkedin](https://www.linkedin.com/in/danielmorales1/)

Thank you for reading!"
8,learnmachinelearning,open-ai,top,2020-08-23 17:50:14,Hi team! I want to share with you a simple Convolutional Neural Network I implemented in vanilla C++ for handwritten digit recognition using the MNIST dataset. I made this some time ago just for learning purposes. I also used OpenGL to visualize how layers and tensors evolves during the training.,anadalg,False,0.97,280,if7n2p,https://www.reddit.com/r/learnmachinelearning/comments/if7n2p/hi_team_i_want_to_share_with_you_a_simple/,9,1598205014.0,"You can download or review the source code at [https://github.com/albertnadal/Tensar](https://github.com/albertnadal/Tensar)

Here is attached a video/demo of the application during the training. 

[CNN implemented in C++\/OpenGL trained with the MNIST dataset](https://reddit.com/link/if7n2p/video/33k3qwhhesi51/player)

You can find the original video in my youtube channel ([https://youtu.be/oCElhUzadaA](https://youtu.be/oCElhUzadaA)), so I encourage you to subscribe to the channel if you are interested in future implementations related to ML and AI. I hope you find it useful to better understand how CNN's works. Thank you!

&#x200B;

Albert,"
9,learnmachinelearning,open-ai,top,2022-02-22 09:16:23,Almost no one knows how easily you can optimize your AI models,emilec___,False,0.9,271,syj7vx,https://www.reddit.com/r/learnmachinelearning/comments/syj7vx/almost_no_one_knows_how_easily_you_can_optimize/,38,1645521383.0,"The situation is fairly simple. **Your model could run 10 times faster** by adding a few lines to your code, but you weren't aware of it. Let me expand on that.

1. AI applications are multiplying like mushrooms, which is awesome
2. As a result, more and more people are turning to the dark side, joining the AI world, as I did
3. The problem? Developers focus only on AI, cleaning up datasets and training their models. Almost no one has a background in hardware, compilers, computing, cloud, etc
4. The result? Developers spend a lot of hours improving the accuracy and performance of their software, and all their hard work risks being undone by the wrong choice of hardware-software coupling

This problem bothered me for a long time, so with a couple of buddies at [Nebuly](https://nebuly.ai/) (all ex MIT, ETH and EPFL), we put a lot of energy into an **open-source library** called **nebullvm** to make DL compiler technology accessible to any developer, even for those who know nothing about hardware, as I did.

How does it work? It **speeds up your DL models by \~5-20x** by testing the best DL compilers out there and selecting the optimal one to best couple your AI model with your machine (GPU, CPU, etc.). All this in just a few lines of code.

The library is open source and you can find it here [https://github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/nebullvm).

Please leave a star on GitHub for the hard work in building the library :) It's a simple act for you, a big smile for us. Thank you, and don't hesitate to contribute to the library!"
10,learnmachinelearning,open-ai,top,2020-05-16 08:13:15,Free zoom lecture about advances in deep learning and 3D modeling for reddit community,pinter69,False,0.97,272,gkr44a,https://www.reddit.com/r/learnmachinelearning/comments/gkr44a/free_zoom_lecture_about_advances_in_deep_learning/,147,1589616795.0,"Hi all,

I work with machine learning and 3D modeling (you can checkout my profile info). I have a cool lecture about the advances in Academia in automatic 3D modeling, the lecture is called ""From 2D to 3D with AI"". I usually teach it at conferences and machine learning courses. Now because of Corona, there is less teaching, so I thought of offering it to the community here :) If there will be 20+ redditors who are interested in the lecture we will make it happen. Feel free to DM me, or leave your info here and we will take it from there.

&#x200B;

\[Edited\]

Hey all, since I see there is a lot of interest already, please fill-out the form so that I would know how to prepare the lecture and at what time: [https://forms.gle/wSXexXSBj5e5267G8](https://forms.gle/wSXexXSBj5e5267G8)

There is no need to comment anymore or dm me, it is just filling out my inbox lol

&#x200B;

\[Edited 2\]

Well, this is kind of amazing, I was expecting for 20-50 people maximum, there are currently 232 people registered from literally all over the world. I will probably need to start a group somewhere to manage this. There might be several lectures for different technical backgrounds and time zones. I am still thinking of the best approach. Will send updates via email once the plan is set.

In the meantime, still accepting registration, so fill free to fill the form with your details to stay in the loop.

&#x200B;

\[Edited 3\]

So, following this amazing and unexpected turn, 329 people registered (!!!) from all over the world. This is too many people for one zoom event :P

I have opened a sub-reddit manage all event details and share all the information. In this sub everyone can also discuss about anything regarding image processing, 3D modelling and AI:

[https://www.reddit.com/r/2D3DAI/](https://www.reddit.com/r/2D3DAI/)

Currently there are two events scheduled, one for the eastern hemisphere and one for the western - they are stickied so you can easily find them. I will do the same lecture twice so that people from different timezones could participate, since we truly have people from all over the world :) This lecture will not require technical background in the field.

For the more technically advanced people (almost half the registered have DL background) - we will probably have another set of 2 lectures. I just want to start this first round, see how it goes and take it from there.

Seeing this amazing interest from people, I have started putting into plan more free lectures in deep learning on other subjects from other guest lecturers. We will take it a step at a time. All info will be shared in /r/2D3DAI and probably also in this subreddit.

Regarding recording the event and putting it on youtube - It will definitely be recorded, if I see that the quality is good, I will also publish it online. Will update in the new subreddit (and via email to those who registered).

Let's do this 🚀🚀

&#x200B;

\[Edited 4\]

Since there is more growing interest and people who might be interested in other talks, feel free to leave your info the the google form above ([https://forms.gle/wSXexXSBj5e5267G8](https://forms.gle/wSXexXSBj5e5267G8)) and I will send out an update via email when more free lectures in similar topics are scheduled."
11,learnmachinelearning,open-ai,top,2022-01-22 13:55:19,"Consolidated Video lectures for Machine Learning(including DL, CV, NLP, etc)",slim_but_not_shady,False,0.99,256,sa30oc,https://www.reddit.com/r/learnmachinelearning/comments/sa30oc/consolidated_video_lectures_for_machine/,23,1642859719.0,"**Video Lectures for Machine Learning(Theory):**

**Machine Learning:**

Cornell CS4780: [https://www.youtube.com/playlist?list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS](https://www.youtube.com/playlist?list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS)

Stanford CS 229:

[https://www.youtube.com/playlist?list=PLoROMvodv4rNH7qL6-efu\_q2\_bPuy0adh](https://www.youtube.com/playlist?list=PLoROMvodv4rNH7qL6-efu_q2_bPuy0adh)

IIT Madras:

[https://www.youtube.com/playlist?list=PL1xHD4vteKYVpaIiy295pg6\_SY5qznc77](https://www.youtube.com/playlist?list=PL1xHD4vteKYVpaIiy295pg6_SY5qznc77)

IISc Bangalore(Rigorous Math):

[https://www.youtube.com/playlist?list=PLbMVogVj5nJSlpmy0ni\_5-RgbseafOViy](https://www.youtube.com/playlist?list=PLbMVogVj5nJSlpmy0ni_5-RgbseafOViy)

Applied Machine Learning Cornell CS5787:

[https://www.youtube.com/playlist?list=PL2UML\_KCiC0UlY7iCQDSiGDMovaupqc83](https://www.youtube.com/playlist?list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83)

Caltech's Machine Learning Course - CS 156 by Professor Yaser Abu-Mostafa:

[https://www.youtube.com/playlist?list=PL41qI9AD63BMXtmes0upOcPA5psKqVkgS](https://www.youtube.com/playlist?list=PL41qI9AD63BMXtmes0upOcPA5psKqVkgS)

StatQuest(Best resource for revision and visualization):

[https://www.youtube.com/user/joshstarmer?app=desktop](https://www.youtube.com/user/joshstarmer?app=desktop)

&#x200B;

**Deep Learning:**

IIT Madras(No prerequisites and great prof):

Part 1: [https://youtube.com/playlist?list=PLyqSpQzTE6M9gCgajvQbc68Hk\_JKGBAYT](https://youtube.com/playlist?list=PLyqSpQzTE6M9gCgajvQbc68Hk_JKGBAYT)

Part 2: [https://www.youtube.com/playlist?list=PLyqSpQzTE6M-\_1jAqrFCsgCcuTYm\_2urp](https://www.youtube.com/playlist?list=PLyqSpQzTE6M-_1jAqrFCsgCcuTYm_2urp)

Course link for slides and references: [http://www.cse.iitm.ac.in/\~miteshk/CS7015\_2018.html](http://www.cse.iitm.ac.in/~miteshk/CS7015_2018.html)

Neural Networks by Hinton:

[https://www.youtube.com/playlist?list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0](https://www.youtube.com/playlist?list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

 NYU DL (Taught by Prof Alfredo Canziani and Prof Yann Lecun):

[https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI](https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI) 

**Computer Vision(Deep Learning):**

Michigan University:

[https://youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r](https://youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r)

(This Michigan university course is the updated version of Stanford’s CS231n CV course and includes all the content covered by that as well)

Advanced Deep Learning for Computer Vision by TU Munich:

[https://www.youtube.com/playlist?list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39](https://www.youtube.com/playlist?list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39)

**Natural Language Processing(Deep Learning):**

Stanford CS 224n:

[https://youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z](https://youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)

Natural Language Understanding Stanford CS 224u:

[https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20](https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20)

Deep Learning for NLP at Oxford with Deep Mind 2017:

[https://www.youtube.com/playlist?list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm](https://www.youtube.com/playlist?list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm)

NLP CMU 11-411/11-611:

[https://www.youtube.com/playlist?list=PL4YhK0pT0ZhXteJ2OTzg4vgySjxTU\_QUs](https://www.youtube.com/playlist?list=PL4YhK0pT0ZhXteJ2OTzg4vgySjxTU_QUs)

CMU CS11-737 Multilingual Natural Language Processing:

[https://www.youtube.com/playlist?list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5](https://www.youtube.com/playlist?list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5)

**Reinforcement Learning:**

IIT Madras:

[https://youtube.com/playlist?list=PLEAYkSg4uSQ0Hkv\_1LHlJtC\_wqwVu6RQX](https://youtube.com/playlist?list=PLEAYkSg4uSQ0Hkv_1LHlJtC_wqwVu6RQX)

Stanford CS234:

[https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)

**Deep Reinforcement Learning:**

UC Berkeley CS 285:

[https://youtube.com/playlist?list=PL\_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc](https://youtube.com/playlist?list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc)

**Other:**

CS224W: Machine Learning with Graphs

[https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn](https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn)

Stanford CS330: Multi-Task and Meta-Learning

[https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5](https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5)

Explainable AI:

[https://www.youtube.com/playlist?list=PLV8yxwGOxvvovp-j6ztxhF3QcKXT6vORU](https://www.youtube.com/playlist?list=PLV8yxwGOxvvovp-j6ztxhF3QcKXT6vORU)

Explainable AI in Industry:

[https://www.youtube.com/playlist?list=PL9ekywqME2Aj8OmKoBUaYEH7Xzi-YCRBy](https://www.youtube.com/playlist?list=PL9ekywqME2Aj8OmKoBUaYEH7Xzi-YCRBy)

**Some Math lectures(refresher):**

Linear algebra(MIT):

[https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8](https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8)

Optimization(IIT Kanpur):

[https://www.youtube.com/playlist?list=PLbMVogVj5nJRRbofh3Qm3P6\_NVyevDGD\_](https://www.youtube.com/playlist?list=PLbMVogVj5nJRRbofh3Qm3P6_NVyevDGD_)

Multivariable Calculus(MIT):

[https://www.youtube.com/playlist?list=PL4C4C8A7D06566F38](https://www.youtube.com/playlist?list=PL4C4C8A7D06566F38)

Probability and Statistics(Harvard):

[https://www.youtube.com/playlist?list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo](https://www.youtube.com/playlist?list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo)

&#x200B;

If you are applying for a job, ML and DL is sufficient for a DS/ML Engineer role initially(Given that you know programming and have completed some projects). But depending on the JD and the work that the company does, Computer vision and Natural Language Processing questions can be expected.

Disclaimer: The video list includes some advanced topics(Meta-learning, Graph ML, etc) which might not be relevant for a person who is applying for a ML Engineer job(unless your job involves work or research related to those topics)

**Some basic Python libraries that you need to be familiar with:**

ML: Sckit-learn, xgboost, catboost, lightgbm, hyperopt etc

DL: Tensorflow, PyTorch, Keras, etc

NLP and transformers: HuggingFace

RL: OpenAI Gym, etc

Production: MLFlow, Apache Airflow, Kubeflow, etc (This is not a hardcore requirement but some companies ask questions on production tools)

Explainable AI: SHAP, LIME, ELI5, tf-explain, captum, etc( Not a hardcore requirement for interviews)"
12,learnmachinelearning,open-ai,top,2023-05-11 20:15:46,Top 20 Large Language Models based on the Elo rating system.,kingabzpro,False,0.96,248,13eympz,https://i.redd.it/7xfqr5crf9za1.png,43,1683836146.0,
13,learnmachinelearning,open-ai,top,2019-05-16 23:01:12,Learning Machine Learning Resources,rhklite,False,0.99,246,bpjh2a,https://www.reddit.com/r/learnmachinelearning/comments/bpjh2a/learning_machine_learning_resources/,14,1558047672.0,"I collected a bunch of machine learning resources for my self studying, thought I'd share it here, could be of use to other people.

&#x200B;

* ★ are resources that were highly recommended by others
* **tags:**    `course` ,   `book` ,   `git-repo` ,   `blog-post` ,   `video` ,   `cheat-sheet` ,   `list`

## Machine Learning

* [Coursera Machine Learning, Andrew Ng](https://www.coursera.org/learn/machine-learning)   `introductory course`  ★
* [Introduction to Computational Thinking and Data Science](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/)   `introductory course`
* [Machine Learning MIT Open Courseware](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/)   `course`
* [Amazon AWS Machine Learning Course](https://aws.amazon.com/training/learning-paths/machine-learning/)   `course`
* [Virgilio - Mentor for Data Science E-Learning](https://github.com/virgili0/Virgilio)   `course`

&#x200B;

* [Machine Learning Yearning - Andrew Ng](https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf)   `book`   ★
* [Mathmatics for Machine Learning, Marc Peter Deisenroth](https://mml-book.github.io/)   `book`
* [The Hundred-page Machine Learning Book, Andriy Burkov](http://themlbook.com/wiki/doku.php)   `book`
* [Model Based Machine Learning](http://mbmlbook.com/toc.html)  `book`
* [Coursera Machine Learning - Python Code, JWarmenhoven](https://github.com/JWarmenhoven/Coursera-Machine-Learning)   `git-repo`
* [Coursera Machine Learning - Python Code, kaleko](https://github.com/kaleko/CourseraML)   `git-repo`
* [Coursera Machine Learning - Python Code, dibgerge](https://github.com/dibgerge/ml-coursera-python-assignments)   `git-repo`
* [Machine Learning Git Codebook](https://www.reddit.com/r/learnmachinelearning/comments/ax6ep5/machine_learning_git_codebook_case_study_of/?utm_medium=android_app&utm_source=share)  `git-repo`

&#x200B;

* [A Complete Machine Learning Project Walk-Through in Python](https://morioh.com/p/b56ae6b04ffc/a-complete-machine-learning-project-walk-through-in-python)  `blog-post`
* [What's the best ML Paper you read in 2018?](https://www.reddit.com/r/MachineLearning/comments/a6cbzm/d_what_is_the_best_ml_paper_you_read_in_2018_and/)   `blog-post`
* [Seeing Theory](https://seeing-theory.brown.edu/basic-probability/index.html)   `blog-post`
* [The most complete chart of Neural Networks, explained](https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464)   `blog-post`
* [The Machine Learning cheat-sheet](https://github.com/remicnrd/ml_cheatsheet)   `cheatsheet`

## Deep Learning

* [Fast.ai Online Course](https://www.fast.ai/)  `course`  ★
* [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/2017/)   `course` ★
* [CS230: Deep Learning](https://cs230.stanford.edu/)   `course`
* [Google Machine Learning Crash Course with TensorFlow APIs](https://developers.google.com/machine-learning/crash-course/)   `course`
* [MIT Deep Learning](https://www.youtube.com/watch?v=O5xeyoRL95U&list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf)   `course`
* [Deep Learning - An MIT Press Book, Ian Goodfellow](http://www.deeplearningbook.org/)   `book` ★

&#x200B;

* [TensorFlow.js - Real-Time Objection Detection in 10 Lines of Code](https://hackernoon.com/tensorflow-js-real-time-object-detection-in-10-lines-of-code-baf15dfb95b2)  `blog-post`

&#x200B;

* [Build a TensorFlow Image Classifier in 5 Min](https://www.youtube.com/watch?v=QfNvhPx5Px8)   `video`

&#x200B;

* [Deep Learning cheat-sheets covering Stanford's CS 230 Class](https://stanford.edu/~shervine/teaching/cs-230/)   `cheat-sheet`
* [cheat-sheets for AI, Neural Nets, ML, Deep Learning & Data Science](https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-science-pdf-f22dc900d2d7)   `cheat-sheet`
* [Tensorflow-Cookbook](https://github.com/taki0112/Tensorflow-Cookbook)   `cheat-sheet`

&#x200B;

* [Deep Learning Papers Reading Roadmap](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap)   `list`  ★
* [Papers with Code](https://paperswithcode.com/sota)  `list`  ★

## Reinforcement Learning

* [CS294-112 Deep Reinforcement Learning](http://rail.eecs.berkeley.edu/deeprlcourse/)   `course`
* [CMPUT 609 Reinforcement Learning - Rich Sutton](https://drive.google.com/drive/folders/0B-WvrETGtkesN29sV1g3aXZ1Z0U)   `course`
* [Deep RL Bootcamp](https://www.youtube.com/watch?v=qaMdN6LS9rA&list=PLPfj7W0fIrmy3MfjPFbpy7jFGDmvspgHE)   `course`
* [Reinforcement Learning Crash Course](https://www.youtube.com/watch?v=sOiNMW8k4T0)   `course`

&#x200B;

* [Reinforcement Learning: An Introduction Richard, S.Sutton 2ndED 2018](http://incompleteideas.net/book/the-book-2nd.html)   `book`  ★

&#x200B;

* [Open AI Spinning Up](https://spinningup.openai.com/en/latest/index.html)   `github repo` ★
* [OpenAI - Gym](https://github.com/openai/gym/wiki)  `git-repo`
* [Stable Baseline: a Fork of OpenAI Baselines - Reinforcement Learning Made Easy](https://stable-baselines.readthedocs.io/en/master/)   `git-repo`
* [PyGame Learning Environment](https://pygame-learning-environment.readthedocs.io/en/latest/)   `git-repo`
* [S-RL Toolbox](https://s-rl-toolbox.readthedocs.io/en/latest/guide/rl.html)   `git-repo`

&#x200B;

* [Google AI Blog](https://ai.googleblog.com/2019/02/long-range-robotic-navigation-via.html?fbclid=IwAR2p5UBtLyXG1Dru5-zW_lnnZF3u3T03U3XF7_2jqBZY6h3ijeIzqmYuEpI)   `blog-post`  ★
* [An introduction to Q-Learning: Reinforcement Learning](https://medium.freecodecamp.org/an-introduction-to-q-learning-reinforcement-learning-14ac0b4493cc)   `blog-post`
* [Introduction: Reinforcement Learning with Open AI Gym](https://towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2)   `blog-post`
* [An intro to Advantage Actor Critic methods](https://medium.freecodecamp.org/an-intro-to-advantage-actor-critic-methods-lets-play-sonic-the-hedgehog-86d6240171d)   `blog-post`
* [Double Q-Learning, the Easy Way](https://towardsdatascience.com/double-q-learning-the-easy-way-a924c4085ec3?fbclid=IwAR17Ht_oyJL4_1AHTqcwf1EU1RziGgRrwTskKY1xRlpLLd3T7_NKMK_V6-g)   `blog-post`
* [A Beginner's Guide to Reinforcement Learning](https://skymind.ai/wiki/deep-reinforcement-learning)   `blog-post`
* [Papaers that criticize Deep Reinforcement Learning](https://www.reddit.com/r/MachineLearning/comments/bdgxin/d_any_papers_that_criticize_deep_reinforcement/)   `blog-post`

## Artificial Intelligence

* [Techniques in Artificial Intelligence (SMA 5504) MIT Open Courseware](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-825-techniques-in-artificial-intelligence-sma-5504-fall-2002/index.htm)  `course`
* [CS 188 - Introduction to Artificial Intelligence - UC Berkeley](https://inst.eecs.berkeley.edu/~cs188/fa18/)  `course`
* [Artifical Intelligence: Foundataions of Computational Agents, 2ndED 2017](https://artint.info/2e/html/ArtInt2e.html)   `book`

## Others

* [Awesome public datasets](https://github.com/awesomedata/awesome-public-datasets)   `list`
* [100+ Basic Machine Learning Interview Questions and Answers](http://theprofessionalspoint.blogspot.com/2019/01/100-basic-machine-learning-interview.html)   `blog-post`"
14,learnmachinelearning,open-ai,top,2023-02-25 11:19:05,Any MLOps platform you use?,squalidaesthetics20,False,0.98,239,11biozs,https://www.reddit.com/r/learnmachinelearning/comments/11biozs/any_mlops_platform_you_use/,31,1677323945.0,"I've been searching for some MLOps platforms for my some projects that I’m working on. I am creating a list that will hopefully help out with productivity and help mr build better apps and services. Also hopefully faster.

I've looked at some of the more popular ones out there and here’s my top 4 so far. Let me know what you guys think about these:

* [Vertex AI](https://cloud.google.com/vertex-ai) \- An ML platform by Google Cloud. They have AI-powered tools to ingest, analyze, and store video data. Good for image classification, NLP, recommendation systems etc.
* [Jina AI](https://jina.ai/) \-They offer a neural search solution that can help build smarter, more efficient search engines. They also have a list of [cool github repos](https://github.com/jina-ai/jina) that you can check out. Similar to Vertex AI, they have image classification tools, NLPs, fine tuners etc.
* [MLflow](https://mlflow.org/) \- an open-source platform for managing your ML lifecycle. What’s great is that they also support popular Python libraries like TensorFlow, PyTorch, scikit-learn, and R.
* Neptune.ai, which promises to streamline your workflows and make collaboration a breeze.

Have you guys tried any of these platforms? I know a lot of AI tools and platforms have been popping up lately especially with the rise of AI tools but what are your thoughts?"
15,learnmachinelearning,open-ai,top,2019-08-27 14:19:56,[D] What do you use to keep you update on ML/DL?,pirate7777777,False,0.99,218,cw542g,https://www.reddit.com/r/learnmachinelearning/comments/cw542g/d_what_do_you_use_to_keep_you_update_on_mldl/,11,1566915596.0,"Hi everyone! What do you use to navigate-in-the-noise and keep you update in this field? *Excluding this subreddit* which type of resources do you recommend to check regularly?

&#x200B;

Here's my list:

***Newsletters (weekly)***:

\- [ImportAI (@JackClark)](https://jack-clark.net/)

\- [The batch (@Deeplearning.ai)](https://www.deeplearning.ai/thebatch/)

&#x200B;

**Podcast & Video (weekly/monthly)**

\- [Artificial Intelligence Podcast (@Lex Fridman)](https://lexfridman.com/ai/)

\- [Two Minute papers](https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg)

&#x200B;

**Blogs (RSS newsfeed)**

\- [DeepMind](https://deepmind.com/blog)

\- [OpenAI](https://openai.com/blog/)

\- [BAIR](https://bair.berkeley.edu/blog/)

\- [Google AI](https://ai.googleblog.com/)

\- [FAIR](https://research.fb.com/category/facebook-ai-research/)

&#x200B;

**MOOCs (once per year)**

\- [Deep learning for coders p1 & p2 (@fast.ai)](https://course.fast.ai/)

\- [CS231n: DL for CV](http://cs231n.stanford.edu/)

\- [CS224d: DL for NLP](https://cs224d.stanford.edu/)

&#x200B;

**Social (once per day/week)**

\- Twitter & LinkedIn are good quite good sometimes, but too noisy.

\- Facebook groups (such as [AIDL](https://www.facebook.com/groups/DeepNetGroup/)) but most of the time, the articles shared are not really good or particularly useful.

&#x200B;

**Conferences / Events (once per year)**

\- [NIPS](https://nips.cc/)

\- [PyTorch Dev Conference](https://pytorch.fbreg.com/)

\- [TF Dev Summit](https://www.tensorflow.org/dev-summit)"
16,learnmachinelearning,open-ai,top,2023-02-16 10:29:31,OpenAI Has Purchased AI.Com For ChatGPT For $11M,vadhavaniyafaijan,False,0.93,211,113nizs,https://www.theinsaneapp.com/2023/02/openai-purchased-ai-com-domain.html,23,1676543371.0,
17,learnmachinelearning,open-ai,top,2019-02-28 12:22:34,Coursera: AI For Everyone (with Andrew Ng) is finally open.,sercosan,False,0.98,208,avqim1,https://www.coursera.org/learn/ai-for-everyone,34,1551356554.0,
18,learnmachinelearning,open-ai,top,2023-06-18 15:56:44,"I made FableForge: Text Prompt to an Illustrated Children’s Book using OpenAI Function Calls, Stable Diffusion, LangChain, & DeepLake",AverageKanyeStan,False,0.96,200,14cnuz4,https://v.redd.it/5p2apjnsts6b1,6,1687103804.0,
19,learnmachinelearning,open-ai,top,2023-10-23 12:07:34,"I created the repository with links to top AI, LLMs, CV, or NLP resources | The link is in the comment",RandomForests92,False,0.97,196,17eisx4,https://i.redd.it/lyxdc9cg0yvb1.png,22,1698062854.0,
20,learnmachinelearning,open-ai,top,2023-01-16 12:28:25,I benchmarked OpenAI's GPT API vs other proprietary APIs on different NLP tasks,AImSamy,False,0.9,192,10ddc1f,https://www.reddit.com/gallery/10ddc1f,37,1673872105.0,
21,learnmachinelearning,open-ai,top,2022-04-08 15:20:26,OpenAI 's new model DALL·E 2 is amazing!,OnlyProggingForFun,False,0.94,194,tz5x2f,https://youtu.be/rdGVbPI42sA,8,1649431226.0,
22,learnmachinelearning,open-ai,top,2023-09-23 13:42:22,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.96,183,16q4ve6,https://www.reddit.com/r/learnmachinelearning/comments/16q4ve6/this_week_in_ai_all_the_major_ai_developments_in/,16,1695476542.0,"1. **Genmo** releases a new text-to-video model: **Genmo Replay** v0.1, which generates high-quality videos from text without the need for advanced prompt engineering. *Genmo is available for free to create AI videos* \[[*Details*](https://blog.genmo.ai/log/replay-ai-video) | [Genmo *Replay*](https://www.genmo.ai/)\] .
2. **OpenAI** unveils **DALL·E 3** \- a major update to the text-to-image model, which will be integrated in ChatGPT. It will be available to ChatGPT Plus and Enterprise users in October, via the API and in Labs later this fall. Creators can now also opt their images out from future training.
3. **Toyota Research Institute** has developed a technique, powered by generative AI, that enables teaching robots new manipulation abilities in a single afternoon. Using the same robot, same code, and same setup, TRI taught over 60 different dexterous behaviors like peeling vegetables, using hand mixers, preparing snacks, and flipping pancakes.
4. **Microsoft** announced:
   1. Availability of AI Copilot for Windows from September 26th. Copilot will incorporate the context and intelligence of the web, your work data and what you are doing in the moment on your PC to provide better assistance. It will be integrated in Windows 11, Microsoft 365, Edge and Bing.
   2. Bing will add support for DALL.E 3 and deliver more personalized answers based on search history.
   3. New AI powered experiences in Paint, Photos and Clipchamp.
   4. New AI-powered shopping experience
5. **ElevenLabs** released **Projects** \- a tool that lets you generate an entire audiobook at the click of a button. Projects now supports .epub, .pdf, and .txt file imports, as well as initializing a project from a URL.
6. **Deci** presents **DeciDiffusion 1.0** \- an open-source text-to-image latent diffusion model which is 3x faster than Stable Diffusion v1.5 with the same quality.
7. **Google researchers** present a new approach that produces photo-realistic animations from a single picture. The model is trained on automatically extracted motion trajectories from a large collection of real video sequences.
8. **Google** has updated Bard\*\]\*:
9. **Bard Extensions:** With extensions, Bard can now connect to your Google apps and services like Gmail, Docs, Drive, Google Maps, YouTube, and Google Flights and hotels.
10. Users can use Bard’s “Google it” button to more easily double-check its answers and evaluate whether there is content across the web to substantiate it.
11. Bard can now let you continue chat via **shared public links**
12. **YouTube** announces new AI tools for creators. **Dream Screen** will let users create an AI-generated video or image background from text. Automatic AI-dubbing tool called **Aloud**, which will be integrated into YouTube Studio. **AI-powered insights** to generate video ideas and draft outlines. **Assistive Search in Creator Music** where AI will suggest the right music based on your description of your content.
13. **Amazon** announced that its voice assistant Alexa is being upgraded with a new, custom-built large language model.
14. **IBM** open-sources **MoLM** \- a collection of ModuleFormer-based language models ranging in scale from 4 billion to 8 billion parameters. ModuleFormer is a new neural network architecture based on the Sparse Mixture of Experts (SMoE) by IBM researchers. .
15. **Neuralink**, Elon Musk's brain implant startup, set to begin human trials.
16. **Lexica** has released **Aperture v3.5** \- their latest next-gen image model that can create photorealistic images and follows your prompt with precision.
17. **OpenAI** has invited domain experts to collaborate in evaluating and improving the safety of OpenAI's models by joining the new **OpenAI Red Teaming Network**.
18. \*\*GitHub Copilot Chat (\*\*beta) is now available for all individuals.
19. **Replit** announced a virtual hackathon for projects built using **Replit ModelFarm**
20. **Oracle** brings voice-activated AI to healthcare with Clinical Digital Assistant.
21. **Google** and the Department of Defense are building an AI-powered microscope to help doctors spot cancer.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
23,learnmachinelearning,open-ai,top,2023-02-20 05:19:31,"Voice.AI Stole Open-Source Code, Banned The Developer Who Informed Them About This, From Discord Server",TheInsaneApp,False,0.98,169,116yj78,https://www.theinsaneapp.com/2023/02/voice-ai-stole-open-source-code.html,7,1676870371.0,
24,learnmachinelearning,open-ai,top,2023-06-28 12:29:48,"Intern tasked to make a ""local"" version of chatGPT for my work",Assasinshock,False,0.97,153,14l887h,https://www.reddit.com/r/learnmachinelearning/comments/14l887h/intern_tasked_to_make_a_local_version_of_chatgpt/,104,1687955388.0,"Hi everyone,

I'm currently an intern at a company, and my mission is to make a proof of concept of an conversational AI for the company.They told me that the AI needs to be trained already but still able to get trained on the documents of the company, the AI needs to be open-source and needs to run locally so no cloud solution.

The AI should be able to answers questions related to the company, and tell the user which documents are pertained to their question, and also tell them which departement to contact to access those files.

For this they have a PC with an I7 8700K, 128Gb of DDR4 RAM and an Nvidia A2.

I already did some research and found some solution like localGPT and local LLM like vicuna etc, which could be usefull, but i'm really lost on how i should proceed with this task. (especially on how to train those model)

That's why i hope you guys can help me figure it out. If you have more questions or need other details don't hesitate to ask.

Thank you.  


Edit : They don't want me to make something like chatGPT, they know that it's impossible. They want a prototype that can answer question about their past project. "
25,learnmachinelearning,open-ai,top,2023-05-11 00:54:18,What do actual ML engineers think of ChatGPT?,PhillConners,False,0.96,152,13e8of2,https://www.reddit.com/r/learnmachinelearning/comments/13e8of2/what_do_actual_ml_engineers_think_of_chatgpt/,106,1683766458.0,"You have been doing this for awhile, now the world is obsessed with OpenAI and suddenly all full of AI “experts”."
26,learnmachinelearning,open-ai,top,2021-01-18 15:30:22,Reinforcement Learning Crash Course (Free),rroocckk,False,0.95,137,kzwso5,https://www.reddit.com/r/learnmachinelearning/comments/kzwso5/reinforcement_learning_crash_course_free/,18,1610983822.0,"I wanted to announce the new and free [Reinforcement Learning Crash Course](https://rlcourse.com).

This course takes a _unique hands-on approach_ to teaching Reinforcement Learning.

- Reinforcement Learning concepts are communicated primarily via code examples (Python, Gym and Keras). 

- Mathematical equations are kept to a minimum. 

Therefore, the course should appeal to you if you like a practical approach to learning, devoid of mathematical pedantry. Plus, you can be an absolute beginner. You don't need any prior machine learning knowledge to understand the content. Machine Learning and Deep Learning concepts are introduced and explained within the course when needed.

This is my attempt at creating a Reinforcement Learning course that **programmers** can love. I am hoping that this further democratizes the amazing capabilities of RL. I have tried to maintain the high standards found in David Silver's course or The Deep RL Bootcamp at Berkeley, but replacing mathematics with code as the main learning UI. I am also inspired by François Chollet's intuitive and code-first approach in his book Deep Learning with Python.

I make the course in my free time, and that allows me to upload 1 video on a new topic per week. The first chapter is already published at the time of this announcement and the rest will come in the next months according to a planned schedule. I have decided that if you enroll now (while the course is being made), it will be **free and you keep all the content forever**. 

In the already published chapter, you will be introduced to Reinforcement Learning basics. This way, you can already take the course for a test drive and see if you like my code-first approach. 

Take a look at the detailed syllabus to find what to expect from later chapters. Briefly speaking, we will take a code-oriented approach to learning classical Reinforcement Learning algorithms like GLIE Monte Carlo, SARSA etc. and Deep RL algorithms like PPO and DQN. We will pay special attention to the following topics: 

- Writing modular and extensible code
- How to make results reproducible
- Logging
- Monitoring
- Best practices for running RL experiments. 

There will also be plenty of practice problems where you will be able to test out your new skills. At the end of the course, you will have solved 5 interesting OpenAI Gym environments, covering everything from classic problems, bipedal walking to playing games. After doing the course, you will be able to confidently apply RL to other problems that catch your fancy.

Thank you for taking the time to read all of this.  The [course page](https://rlcourse.com) has more details."
27,learnmachinelearning,open-ai,top,2023-09-16 13:22:41,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.95,134,16k7heb,https://www.reddit.com/r/learnmachinelearning/comments/16k7heb/this_week_in_ai_all_the_major_ai_developments_in/,17,1694870561.0,"1. **Stability AI** launched Stable Audio, a generative AI tool for music & sound generation from text. The underlying latent diffusion model architecture uses audio conditioned on text metadata as well as audio file duration and start time.
2. **Coqui** released **XTTS** \- a new voice generation model that lets you clone voices in 13 different languages by using just a quick 3-second audio clip.
3. **Microsoft Research** released and open-sourced **Phi-1.5** \- a 1.3 billion parameter transformer-based model with performance on natural language tasks comparable to models 5x larger.
4. **Project Gutenberg**, Microsoft and MIT have worked together to use neural text-to-speech to create and release thousands of **human-quality free and open audiobooks**.
5. Researchers present **NExT-GPT -** an any-to-any multimodal LLM that accepts inputs and generate outputs in arbitrary combinations of text, images, videos, and audio.
6. **Chain of Density (CoD):** a new prompt introduced by researchers from Salesforce, MIT and Colombia University that generates more dense and human-preferable summaries compared to vanilla GPT-4.
7. **Adept** open-sources **Persimmon-8B**, releasing it under an Apache license. The model has been trained from scratch using a context size of 16K.
8. **Adobe's** **Firefly** generative AI models, after 176 days in beta, are now commercially available in Creative Cloud, Adobe Express, and Adobe Experience Cloud. Adobe is also launching Firefly as a standalone web app.
9. **Deci** released **DeciLM 6B**, a permissively licensed, open-source foundation LLM that is 15 times faster than Llama 2 while having comparable quality.
10. Researchers release **Scenimefy** \- a model transforming real-life photos into Shinkai-animation-style images.
11. **Microsoft** open sources **EvoDiff**, a novel protein-generating AI that could be used to create enzymes for new therapeutics and drug delivery methods as well as new enzymes for industrial chemical reactions.
12. Several companies including Adobe, IBM, Nvidia, Cohere, Palantir, Salesforce, Scale AI, and Stability AI have pledged to the White House to develop safe and trustworthy AI, in a voluntary agreement similar to an earlier one signed by Meta, Google, and OpenAI.
13. **Microsoft** will provide legal protection for customers who are sued for copyright infringement over content generated using Copilot, Bing Chat, and other AI services as long as they use built-in guardrails.
14. **NVIDIA** beta released **TensorRT** \- an open-source library that accelerates and optimizes inference performance on the latest LLMs on NVIDIA Tensor Core GPUs.
15. Pulitzer Prize winning novelist Michael Chabon and several other writers sue OpenAI of copyright infringement..
16. **NVIDIA** partners with two of India’s largest conglomerates, Reliance Industries Limited and Tata Group, to create an AI computing infrastructure and platforms for developing AI solutions.
17. **Roblox** announced a new conversational AI assistant that let creators build virtual assets and write code with the help of generative AI.
18. **Google** researchers introduced **MADLAD-400** \- a 3T token multilingual, general web-domain, document-level text dataset spanning 419 Languages.
19. A recent survey by **Salesforce** show that 65% of generative AI users are Millennials or Gen Z, and 72% are employed.  The survey included 4,000+ people across the United States, UK, Australia, and India.
20. **Meta** is reportedly working on an AI model designed to compete with GPT-4.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
28,learnmachinelearning,open-ai,top,2022-06-26 11:59:58,"TMT: A KISS library to keep track of experiments, results and code",levnikmyskin,False,0.98,133,vl36ro,https://www.reddit.com/r/learnmachinelearning/comments/vl36ro/tmt_a_kiss_library_to_keep_track_of_experiments/,13,1656244798.0,"Hi everyone!

This past week I had a bit of free time and decided to work on this library I've had in mind for some time now. I'm doing a PhD in Computer Science (mainly working with text classification) and too many times I've seen research projects losing track of the experiments ran, their metrics, their results and the code used to produce them.

While there are available libraries at the moment to do this, such as [Weights & Biases](https://wandb.ai/site) or [Modelchimp](https://github.com/ModelChimp/modelchimp), I wanted a library which could be as simple as possible, both for the user and the developer, and completely free...a library based on the [KISS](https://en.wikipedia.org/wiki/KISS_principle) principle. My idea is that the researcher/user of the library should also be able to easily adjust and modify the source code of the library, should they feel the need.

This project was done both for fun and for satisfying a real need, creating a library which does the bare minimum but hopefully right (do one thing, do it right).

That's why I've just published [That Metric Timeline (TMT)](https://github.com/levnikmyskin/that_metric_timeline) as an open-source project on Github.

TMT is available on the PyPI index and can be installed with

    pip install ThatMetricTimeline

`tmt` also provides an old-fashioned terminal user interface (TUI), which should be available as `tmt_tui` in your python path once you installed it.

Using `tmt` should be pretty straightforward. Once you installed the library, you can do:

    from tmt import tmt_recorder
    
    @tmt_recorder(name=""some_experiment"")
    def train_and_predict(x_tr, y_tr, x_te, y_te):
        lr = LogisticRegression()
        lr.fit(x_tr, y_tr)
        preds = lr.predict(x_te)
        return {'f1': f1_score(y_te, preds), 'accuracy': accuracy_score(y_te, preds)}  

The `tmt_recorder` decorator will save this experiment with the name you provided, also saving the metrics associated with it (the dictionary returned by your function) and taking a snapshot backup of your code. You may also save results at any time with the `tmt.tmt_save` function:

    from tmt import tmt_recorder, tmt_save
    
    @tmt_recorder(name=""some_experiment_with_data"")
    def train_and_predict(...):
        ...
        preds = lr.predict(x_te)
        tmt_save(preds, name='lr_predictions')
        return {'f1': f1_score(y_te, preds), 'accuracy': accuracy_score(y_te, preds)}  

You can look for the experiments saved using the `tmt` TUI (have a look at the [Github readme](https://github.com/levnikmyskin/that_metric_timeline#tui) for more information, if you're interested). You can then use the `tmt.TmtManager` helper to load results and more:

    from tmt import TmtManager
    
    # Let's say we know there is an experiment with id ""example""
    
    
    # An Entry is a row in the database, i.e. an experiment that was tracked.
    manager = TmtManager()
    manager.set_entry_by_id('example') 
    
    # load the results and unpickle them
    for name, path in manager.results_paths():
        with open(path, 'rb') as f:
            # do stuff with your results. If it's a pickle it's 
            # more convenient to use the code block below this one
            res = pickle.load(f)
    
    # load the unpickled results
    for name, res in manager.load_results():
        # do something with your results.
        # if res is a numpy array...
        print(res.mean())
    
    
    for name, val in manager.get_metrics():
        print(f""{name}: {val}"")  

That's basically it, but I recommend reading the Github readme for a more complete explanation. Also, notice this library was born pretty quickly in around one week, documentation is basically lacking everywhere (but I plan to serve it on readthedocs at some point). I would love to hear feedback (positive and negative) on this if you have any :)

Cheers!"
29,learnmachinelearning,open-ai,top,2019-08-24 09:50:31,A Notebook to create your own beautiful style transfer pictures with Google Colab,Zenol,False,0.94,125,curhf6,https://www.reddit.com/r/learnmachinelearning/comments/curhf6/a_notebook_to_create_your_own_beautiful_style/,3,1566640231.0,"&#x200B;

[A successful style transfer :\)](https://preview.redd.it/3dgrjfafuji31.png?width=256&format=png&auto=webp&s=f9ba4a4141676206e4b3939f7bf7e3520917f1fd)

Hello ML community,

I had a look at pytorch and tensorflow tutorial on style transfer, and I found the result of their code very deceiving ; pytorch result is pretty ugly, dark, miss colors and is... let's be honest, its like a bad photoshop filter. 😂

So I had a look at what different peoples does on combining two images, and the original paper, and made my own teaching support based on it. I am planing to use it as a basis for mainstream conferences in order to make peoples interested into ML. I think it provide some explanation and interpretation on how it works and why it works. (I am basically summarizing diverses ideas I have encounter on the web, and a little bit of my math knowledge.)

This code can be used in two way:

1. You don't know a shit about ML, or don't care, are note a developer, whatever. You just want to play with AI painting, and you can do it. You basically just have to set the URLs of the content image and the style image (You have to open the notebook with Google Colab. It should work out of the box, just by pressing run.). This way, you can just focus on getting beautiful images and express your creativity.
2. You are into ML and you want to understand the inner working of style transfer. I think this is a really good starting point for you. You get explanation and working code, you can play with it by removing different part ; Set the content loss to 0, you make abstract art. Set the style loss to 0, you recover more or less the content image. Play with the layers of VGG you are using or not. Replace VGG by an other model, what happens ?

Let me know if something is un clean / need more details / rephrasing. I'd be happy to improve it from your feedback :)

&#x200B;

[https://github.com/jeremycochoy/style-transfer/blob/master/Pytorch\_Style\_Transfer.ipynb](https://github.com/jeremycochoy/style-transfer/blob/master/Pytorch_Style_Transfer.ipynb)"
30,learnmachinelearning,open-ai,top,2022-05-08 15:54:23,I’ve been trying to learn the limits of some of the available machine learning models out there. Built an app that lets you try a mix of CLIP from Open AI + Apple’s version of MobileNet directly on your phone's camera roll.,Playgroundai,False,0.99,125,ul4oag,https://v.redd.it/2fs4i7nnx9y81,3,1652025263.0,
31,learnmachinelearning,open-ai,top,2022-11-10 14:29:23,[P] Transcribe any podcast episode in just 1 minute with optimized OpenAI/whisper,thundergolfer,False,0.97,120,yrgnuq,https://v.redd.it/wnt66ghfody91,6,1668090563.0,
32,learnmachinelearning,open-ai,top,2023-06-03 14:33:38,This week in AI - all the Major AI development in a nutshell,wyem,False,0.98,119,13zeoi3,https://www.reddit.com/r/learnmachinelearning/comments/13zeoi3/this_week_in_ai_all_the_major_ai_development_in_a/,13,1685802818.0,"1. The recently released open-source large language model **Falcon LLM**, by UAE’s Technology Innovation Institute, is now royalty-free for both commercial and research usage. **Falcon 40B,** the 40 billion parameters model trained on one trillion tokens, is ranked #1 on **Open LLM Leaderboard by Hugging Face**.
2. **Neuralangelo**, a new AI model from Nvidia turns 2D video from any device - cell phone to drone capture - into 3D structures with intricate details using neural networks..
3. In three months, JPMorgan has advertised **3,651 AI jobs** and sought a trademark for **IndexGPT**, a securities analysis AI product.
4. **Google** presents **DIDACT** (​​Dynamic Integrated Developer ACTivity), the first code LLM trained to model real software developers editing code, fixing builds, and doing code review. DIDACT uses the software development process as training data and not just the final code, leading to a more realistic understanding of the development task.
5. Researchers from **Deepmind** have presented ‘**LLMs As Tool Makers (LATM)**’ - a framework that allows Large Language Models (LLMs) to create and use their own tools, enhancing problem-solving abilities and cost efficiency. With this approach, a sophisticated model (like GPT-4) can make tools (where a tool is implemented as a Python utility function), while a less demanding one (like GPT-3.5) uses them.
6. **Japan's government** won't enforce copyrights on data used for AI training regardless of whether it is for non-profit or commercial purposes.
7. *‘Mitigating the* ***risk of extinction from AI*** *should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.’ -* One sentence statement signed by leading AI Scientists as well as many industry experts including CEOs of OpenAI, DeepMind and Anthropic.*.*
8. Nvidia launched ‘**Nvidia Avatar Cloud Engine (ACE) for Games**’ - a custom AI model foundry service to build non-playable characters (NPCs) that not only engage in dynamic and unscripted conversations, but also possess evolving, persistent personalities and have precise facial animations and expressions.
9. **OpenAI** has launched a trust/security portal for OpenAI’s compliance documentation, security practices etc..
10. **Nvidia** announced a new AI supercomputer, the **DGX GH200,** for giant models powering Generative AI, Recommender Systems and Data Processing. It has 500 times more memory than its predecessor, the DGX A100 from 2020.
11. Researchers from Nvidia presented **Voyager**, the first ‘LLM-powered embodied lifelong learning agent’ that can explore, learn new skills, and make new discoveries continually without human intervention in the game Minecraft.
12. The a16z-backed chatbot startup **Character.AI** launched its mobile AI chatbot app on May 23 for iOS and Android, and succeeded in gaining over **1.7 million new installs** within a week.
13. Microsoft Research presents **Gorilla**, a fine-tuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls.
14. **OpenAI** has trained a model using process supervision - rewarding the thought process rather than the outcome - to improve mathematical reasoning. Also released the full dataset used.
15. **WPP**, the world's largest advertising agency, and Nvidia have teamed up to use generative AI for creating ads. The new platform allows WPP to tailor ads for different locations and digital channels, eliminating the need for costly on-site production.
16. **PerplexityAI’s** android app is available now, letting users search with voice input, learn with follow-up questions, and build a library of threads.

**If you like this news format**, you might find my  [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with **bite-sized news, learning resources and selected tools**. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
33,learnmachinelearning,open-ai,top,2023-02-11 06:58:18,[N] New Open-Source Version Of ChatGPT ⭕,LesleyFair,False,0.98,115,10zep6u,https://www.reddit.com/r/learnmachinelearning/comments/10zep6u/n_new_opensource_version_of_chatgpt/,8,1676098698.0,"GPT is getting competition from open-source.

A group of researchers, around the YouTuber [Yannic Kilcher](https://www.ykilcher.com/), have announced that they are working on [Open Assistant](https://github.com/LAION-AI/Open-Assistant). The goal is to produce a chat-based language model that is much smaller than GPT-3 while maintaining similar performance.

If you want to support them, they are crowd-sourcing training data [here](https://open-assistant.io/).

**What Does This Mean?**

Current language models are too big.

They require millions of dollars of hardware to train and use. Hence, access to this technology is limited to big organizations. Smaller firms and universities are effectively shut out from the developments.

Shrinking and open-sourcing models will facilitate academic research and niche applications.

Projects such as Open Assistant will help to make language models a commodity. Lowering the barrier to entry will increase access and accelerate innovation.

What an exciting time to be alive! 

Thank you for reading! I really enjoyed making this for you!  
The Decoding ⭕ is a thoughtful weekly 5-minute email that keeps you in the loop about machine research and the data economy. [Click here to sign up](https://thedecoding.net/)!"
34,learnmachinelearning,open-ai,top,2019-04-18 05:06:37,Face Recognition: An Introduction for Beginners,spmallick,False,0.96,104,behp9l,https://www.reddit.com/r/learnmachinelearning/comments/behp9l/face_recognition_an_introduction_for_beginners/,5,1555563997.0,"Face Recognition has been one of the most researched Computer Vision areas till date. So, it is natural to have too much information overload around the same.   
In our latest article, we have tried to simplify the topic and hope that it serves as a beginners' guide on Face Recognition.  
Feel free to comment if you think we have missed out on anything important.

[https://www.learnopencv.com/face-recognition-an-introduction-for-beginners/](https://www.learnopencv.com/face-recognition-an-introduction-for-beginners/) 

Mention reviews and what you want us to work next, in the comments!

P.S : More articles ( with code ) to come.  
[\#LearnOpenCV](https://www.facebook.com/hashtag/learnopencv?source=feed_text&epa=HASHTAG&__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&__tn__=%2ANK-R) [\#OpenCV](https://www.facebook.com/hashtag/opencv?source=feed_text&epa=HASHTAG&__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&__tn__=%2ANK-R) [\#MachineLearning](https://www.facebook.com/hashtag/machinelearning?source=feed_text&epa=HASHTAG&__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&__tn__=%2ANK-R) [\#DeepLearning](https://www.facebook.com/hashtag/deeplearning?source=feed_text&epa=HASHTAG&__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&__tn__=%2ANK-R) [\#AI](https://www.facebook.com/hashtag/ai?source=feed_text&epa=HASHTAG&__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&__tn__=%2ANK-R)[\#ComputerVision](https://www.facebook.com/hashtag/computervision?source=feed_text&epa=HASHTAG&__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&__tn__=%2ANK-R) [\#FaceRecognition](https://www.facebook.com/hashtag/facerecognition?source=feed_text&epa=HASHTAG&__xts__%5B0%5D=68.ARA-mqImCdcmNoesLTLnq1cHNx1qybEcB2vWv0U-LCVooLDVbt6twgiEf_1ZdH1eFnuxGrlk-qovZie_GKHbK9JuHS7gwOzoQlew_P-o3By52IF6bkino3DlFiv1hW6__v-RJ83fIE3I4z6rmAlqKS7J5zP2ZG__d1RAql-eqhVXFtX7VUWedJ7uwZTMLaykIT2Ickd_8UC5VfMo5xc6HT5nOG3OIaht8E_lQnjxIG4LcGyYA4W2Vmm9FEPdvEyEW_JXGb_bsi33Jv0TCRtHyQT0EvR_DOIyo51B6ykXO3DkAHtMplZAjpPE3XW6dU2hPSsDuWWhqBMQ78GQuEwY3OE&__tn__=%2ANK-R)

https://preview.redd.it/h75e0n3wgys21.jpg?width=960&format=pjpg&auto=webp&s=8a085a6be83a1096e49d08ce5f8b077fdce5775a"
35,learnmachinelearning,open-ai,top,2023-02-22 16:59:33,MIT Introduction to Data-Centric AI,anishathalye,False,0.97,99,1194vsn,https://www.reddit.com/r/learnmachinelearning/comments/1194vsn/mit_introduction_to_datacentric_ai/,4,1677085173.0,"Announcing the [first-ever course on Data-Centric AI](https://dcai.csail.mit.edu/). Learn how to train better ML models by improving the data.

[Course homepage](https://dcai.csail.mit.edu/) | [Lecture videos on YouTube](https://www.youtube.com/watch?v=ayzOzZGHZy4&list=PLnSYPjg2dHQKdig0vVbN-ZnEU0yNJ1mo5) | [Lab Assignments](https://github.com/dcai-course/dcai-lab)

The course covers:

* [Data-Centric AI vs. Model-Centric AI](https://dcai.csail.mit.edu/lectures/data-centric-model-centric/)
* [Label Errors](https://dcai.csail.mit.edu/lectures/label-errors/)
* [Dataset Creation and Curation](https://dcai.csail.mit.edu/lectures/dataset-creation-curation/)
* [Data-centric Evaluation of ML Models](https://dcai.csail.mit.edu/lectures/data-centric-evaluation/)
* [Class Imbalance, Outliers, and Distribution Shift](https://dcai.csail.mit.edu/lectures/imbalance-outliers-shift/)
* [Growing or Compressing Datasets](https://dcai.csail.mit.edu/lectures/growing-compressing-datasets/)
* [Interpretability in Data-Centric ML](https://dcai.csail.mit.edu/lectures/interpretable-features/)
* [Encoding Human Priors: Data Augmentation and Prompt Engineering](https://dcai.csail.mit.edu/lectures/human-priors/)
* [Data Privacy and Security](https://dcai.csail.mit.edu/lectures/data-privacy-security/)

MIT, like most universities, has many courses on machine learning (6.036, 6.867, and many others). Those classes teach techniques to produce effective models for a given dataset, and the classes focus heavily on the mathematical details of models rather than practical applications. However, in real-world applications of ML, the dataset is not fixed, and focusing on improving the data often gives better results than improving the model. We’ve personally seen this time and time again in our applied ML work as well as our research.

Data-Centric AI (DCAI) is an emerging science that studies techniques to improve datasets in a systematic/algorithmic way — given that this topic wasn’t covered in the standard curriculum, we (a group of PhD candidates and grads) thought that we should put together a new class! We taught this intensive 2-week course in January over MIT’s IAP term, and we’ve just published all the course material, including lecture videos, lecture notes, hands-on lab assignments, and lab solutions, in hopes that people outside the MIT community would find these resources useful.

We’d be happy to answer any questions related to the class or DCAI in general, and we’d love to hear any feedback on how we can improve the course material. Introduction to Data-Centric AI is open-source opencourseware, so feel free to make improvements directly: [https://github.com/dcai-course/dcai-course](https://github.com/dcai-course/dcai-course)."
36,learnmachinelearning,open-ai,top,2023-11-24 15:06:53,Talk to Taipy - an app that uses natural language to manipulate and visualize data,quicklyalienated76,False,0.99,97,182u4c8,https://www.reddit.com/r/learnmachinelearning/comments/182u4c8/talk_to_taipy_an_app_that_uses_natural_language/,4,1700838413.0,"Hi! My team has been working on an LLM application called Talk to Taipy.

[https://talk-to-taipy.taipy.cloud/](https://talk-to-taipy.taipy.cloud/)

https://i.redd.it/vrdd3zsa9b2c1.gif

Talk to Taipy was created as an end-user application to manipulate and visualize your data using natural language.  You can add your CSV file and ask the prompt to show/filter/plot... the data. You can also get the Taipy and Panda code of the plot/query.

It was built with Taipy, an open-source Python library that turns your Data and ML applications into full applications, from the front-end to the back-end. ([https://github.com/Avaiga/taipy](https://github.com/Avaiga/taipy)). For the AI part, Talk to Taipy was created using Hugging's face starcoder.

We are open to constructive feedback to make it the best application possible, so don't hesitate!"
37,learnmachinelearning,open-ai,top,2023-02-08 01:39:15,Master's Degree in ML/AI worth it in 2023?,TheOnlyAuthority,False,0.93,96,10wjo7e,https://www.reddit.com/r/learnmachinelearning/comments/10wjo7e/masters_degree_in_mlai_worth_it_in_2023/,172,1675820355.0,"I know there are similar/exact questions all over Reddit, but they all seem to be a little dated and the ones with the most activity seems to be from at least a few years ago. I was wondering if a Master's in ML/AI still worth it in 2023.

Also, what other CS related masters degrees do you think would be valubale or considered as highly preferred for a candidate to have to work in a certain field?

Sorry, the second part is more of a broad question for this subreddit!

Edit: Just adding that I'm currently working as Software Engineer and my company would bear part of the tuition cost. But I still want it to be worth my time and effort as well. If there is a better engineering master's choice, I'd like to pursue that. Strong bias for something within engineering, but open to other also."
38,learnmachinelearning,open-ai,top,2023-11-21 20:58:14,Does your company let your engineers use AI tools like Copilot or ChatGPT?,Psychological_March2,False,0.93,94,180r9tx,https://www.reddit.com/r/learnmachinelearning/comments/180r9tx/does_your_company_let_your_engineers_use_ai_tools/,75,1700600294.0,"In light of what's been happening with Open AI, this blog we wrote is still relevant:

A few weeks ago, I was with a group of CTOs when someone asked: *does your company let your engineers use AI tools like Copilot or ChatGPT?*

I thought the question was strange. What do you mean *let*? They're going to use it no matter what you say. AI code generation tools offer engineers a huge productivity boost. The ability to autocomplete code in seconds or work through a problem with AI isn’t an opportunity developers will pass up.

When we drilled into why this group was reluctant to allow their engineers to use AI, it became apparent that their reservations centered primarily on one concern: the absence of a robust testing framework to give them confidence in the code generated by AI.

But this is still flawed reasoning. If you’re not confident in using AI, how can you be confident in hiring new grads? If you don’t have the tools to have confidence in your code, it doesn’t matter where that code comes from–you’ll always struggle with quality.

Read more [here](https://trunk.io/blog/enhancing-code-quality-and-security-in-the-ai-era?utm=reddit)."
39,learnmachinelearning,open-ai,top,2023-05-25 17:23:19,"Are people still coding stuff on their own like chatbots, image AIs, etc., or is everyone just using pretrained models and APIs now?",TrackLabs,False,0.91,93,13rnopr,https://www.reddit.com/r/learnmachinelearning/comments/13rnopr/are_people_still_coding_stuff_on_their_own_like/,35,1685035399.0,"I feel like everyone is just downloading models from huggingface at this point, or using GPT APIs and so on.

I also feel like there are not really tutorials anymore on YT and the web about how to code stuff like there used to be 5 to 2 years ago. Every video now is just ""how to use OpenAIs API"" or ""how to use llama model from huggingface"". 

I have a big problem with staying up to date on the stuff, I never really bothered using huggingface, and I dont really like the idea to just use other peoples pretrained models for everything, what actual contribution am I doing in my own projects then lol.

Would be cool if some people could give me some reality check on whats going on."
40,learnmachinelearning,open-ai,top,2019-01-12 22:50:09,"Newer people, anyone interested in a beginner friendly group project (subreddit group project) with a bit of guidance/mentorship?",BatmantoshReturns,False,0.98,93,afcqgb,https://www.reddit.com/r/learnmachinelearning/comments/afcqgb/newer_people_anyone_interested_in_a_beginner/,83,1547333409.0,"I posted earlier ( https://redd.it/aa64p0 ) for anyone interested in a project with a bit of mentorship/guidance. I got a lot of responses from people who were very new who weren't ready for the stuff I had in mind, so I came up with an idea for a project for those with very little experience. Also, multiple people can work on it together, pretty much we can work on it as a subreddit. 

The idea for the project is retraining word vectors for a specific domain, in this case, a research paper dataset. 

The motivation is that in different contexts, words will take on slightly different properties. For example, word vectors trained on a wikipedia data set will show different properties than vectors trained on a google news dataset. 

Anyone can participate, follow along, and show others their progress on a Google colab notebook. 

It'll be a pretty casual arrangement, anyone can pop in and out at anytime. 

And we can start right now! If you're interested comment below. No need for PMs on this one, this is pretty much open source, just comment below.

Edit:

Here are first steps

-Get familiar with Google Colaboratory

https://colab.research.google.com

-Go over word2vec 

Some suggested info, but keep going finding stuff on your own until you're comfortable with it.
https://www.youtube.com/watch?v=xMwx2A_o5r4
https://www.youtube.com/watch?v=BD8wPsr_DAI

-Go over a Word2vec implementation in your ML library of choice

Suggested resources, please look for stuff on your own as well

Keras Functional API for Tensorflow

https://adventuresinmachinelearning.com/word2vec-keras-tutorial/
https://github.com/adventuresinML/adventures-in-ml-code/blob/master/keras_word2vec.py

Tensorflow Graph/Session 

https://www.tensorflow.org/tutorials/representation/word2vec

Pytorch

https://towardsdatascience.com/implementing-word2vec-in-pytorch-skip-gram-model-e6bae040d2fb
https://adoni.github.io/2017/11/08/word2vec-pytorch/

Let me know if you're already familiar with colab, word2vec, and your ML library of choice, I'll post next steps. 

If you like, comment with your colab notebook so everyone can see, learn from, and give feedback on your work. 

Pretty excited about this. If this works well, we can do more intermediate group projects. 

Next Steps Part 2:

The next steps would be to figure out how to wrangle data from databases. Here are the databases we have to work with

Here's a corpus of research papers

https://labs.semanticscholar.org/corpus/

Another research papers database

https://aminer.org/open-academic-graph

This is also a great database for text data based on research papers, which I don't think people have done any real ml projects on, the arxiv database

https://arxiv.org/help/bulk_data

I recommend just focusing on a few areas, for example arxiv-sanity just extracts cs.[CV|CL|LG|AI|NE]/stat.ML papers.

This will be more tricky, so post your colab notebooks often so people can learn from you or help you whenever you get stuck. "
41,learnmachinelearning,open-ai,top,2023-10-09 11:54:03,Where Do You Get Your AI News?,Altruistic_Gift4997,False,0.97,88,173pvsv,https://www.reddit.com/r/learnmachinelearning/comments/173pvsv/where_do_you_get_your_ai_news/,45,1696852443.0,"Guys, I'm looking for the best spots to get the latest updates and news in the field. What websites, blogs, or other sources do you guys follow to stay on top of the AI game?  
Give me your go-to sources, whether it's some cool YouTube channel, a Twitter(X xd) account, or just a blog that's always dropping fresh AI knowledge. I'm open to anything – the more diverse, the better!

Thanks a lot! 😍"
42,learnmachinelearning,open-ai,top,2023-06-14 09:08:23,"Introducing, OpenLLM 🎉",AaZasDass,False,0.96,87,149302y,https://www.reddit.com/r/learnmachinelearning/comments/149302y/introducing_openllm/,15,1686733703.0,"OpenLLM allows you to run inferences with any open-source LLMs, deploy to the cloud or on-premises, and build powerful AI apps. It includes simple and familiar APIs, enabling easy integration with tools such as LangChain, and BentoML! Discover more at [https://github.com/bentoml/OpenLLM](https://github.com/bentoml/OpenLLM)

To get started, install it with pip: `pip install -U openllm`  Currently, it has support for all major SOTA LLMs, including Falcon, ChatGLM, Dolly V2, StableLM, and more to come!

Some of the feature that is currently wip:

\- Fine-tuning API with `LLM.tuning()`

\- LangChain integration [https://github.com/hwchase17/langchain/pull/6064](https://github.com/hwchase17/langchain/pull/6064)

\- OpenAI Compatible API

    import openai
    
    openai.api_base = ""http://localhost:3000"" # Running with OpenLLM
    
    completion = openai.Completion.create(...)

We are currently actively developing the library, so we would love to hear your thoughts and feedback. Feel free also to join our [discord](https://l.bentoml.com/join-openllm-discord) to meet other fellows, AI application builders, and enthusiasts."
43,learnmachinelearning,open-ai,top,2023-01-27 14:51:14,Fine-tuning open source models to emulate ChatGPT for code explanation.,awesomequantity,False,0.88,87,10mmofg,https://www.reddit.com/r/learnmachinelearning/comments/10mmofg/finetuning_open_source_models_to_emulate_chatgpt/,13,1674831074.0,"I'm looking to step up my game and emulate ChatGPT for specific use-cases like explaining code. I'm thinking about using open source models like GPT-J, or OPT to get beyond the limitations of the closed-source nature of ChatGPT, like the amount of text it can read or respond with.

I got the funding for training, hardware, etc, and I want the end product to be on-premises, so no worries there. The inference doesn't have to be super fast either. I know there are projects like OpenAssistant and petals.ml but haven’t made enough research just yet.

One option I’m considering is using fine tuners like the one from [HuggingFace](https://github.com/subhasisj/HuggingFace-Transformers-FineTuning) or [Jina AI](https://github.com/jina-ai/finetuner) to fine-tune open source models like GPT-J or OPT to improve specific use-cases like code explanation. With the funding that we have, I wouldn’t want to cheap out on fine-tuning and expect something good.

So, can anyone help out and point me in the right direction? Which model is the best to fine-tune and how do I fine-tune to improve specific use cases? Any help would be appreciated. Thanks!"
44,learnmachinelearning,open-ai,top,2021-11-23 09:50:15,I've been working on a DIY Batmobile™ kit that will teach kids STEM for over a year now,Albert_Gajsak,False,0.85,85,r09tja,https://www.reddit.com/r/learnmachinelearning/comments/r09tja/ive_been_working_on_a_diy_batmobile_kit_that_will/,1,1637661015.0," Hi everyone,  
My name is Albert, and I’m a 22-year-old tech-lover creating fun and educational electronic devices 😄  
I wanted to share my latest project with the rest of the group - it’s named CircuitMess Batmobile™️ 🦇🚗  
CircuitMess is a small business that I’m trying to build based on the idea of bringing excitement and joy via fun electronic kits to people all around the world. 🌎  
CircuitMess Batmobile™️ is an AI-powered DIY Batmobile kit made in cooperation with Warner Bros.

I’ve been negotiating with WB and working on this product for the past year and a half. Being a huge Batman fan myself, getting to work with the people behind Batman as a brand was a dream come true! ✨  


I’ve designed this kit to teach everyone about cutting-edge technologies, such as machine learning, computer vision, AI, IoT, and much more, while feeling like the Caped Crusader. 🦇

Everything I do is also open source, Arduino compatible, and hackable. 💻  
I would appreciate your honest feedback on the product! 😄

You can send me an inbox, drop a comment here or directly on my Kickstarter listing for Batmobile: [https://www.kickstarter.com/projects/albertgajsak/circuitmess-batmobile?ref=535kx4](https://www.kickstarter.com/projects/albertgajsak/circuitmess-batmobile?ref=535kx4) 

You can also join my discord channel for updates and discussions: [https://discord.gg/UZkp89eN4y](https://discord.gg/UZkp89eN4y)   
Thank you for your time 👋 

https://preview.redd.it/e7uzqr6ghb181.png?width=628&format=png&auto=webp&s=6c6faebcb74083007bc586775e6f13e96d3d6b1f"
45,learnmachinelearning,open-ai,top,2023-09-30 15:01:31,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.97,80,16w93bx,https://www.reddit.com/r/learnmachinelearning/comments/16w93bx/this_week_in_ai_all_the_major_ai_developments_in/,4,1696086091.0,"1. **Meta AI** presents **Emu**, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal.
2. **Meta AI** researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks.
3. **Abacus AI** released a larger 70B version of **Giraffe**. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens\].
4. **Meta** announced:  

   1. **Meta AI** \- a new AI assistant users can interact with on WhatsApp, Messenger and Instagram. Will also be available on Ray-Ban Meta smart glasses and Quest 3, Meta’s mixed reality headset.
   2. **AI stickers** that enable users to generate customized stickers for chats and stories using text. Powered by Llama 2 and the new foundational model for image generation, Emu.
   3. **28 AI characters**, each with a unique personality that users can message on WhatsApp, Messenger, and Instagram.
   4. New AI editing tools, **restyle** and **backdrop** in Instagram.
   5. **AI Studio** \- a platform that supports the creation of custom AIs by coders and non-coders alike.
5. **Cerebras** and **Opentensor** released Bittensor Language Model, ‘**BTLM-3B-8K**’, a new 3 billion parameter open-source language model with an 8k context length trained on 627B tokens of SlimPajama. It outperforms models trained on hundreds of billions more tokens and achieves comparable performance to open 7B parameter models. The model needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models and is available with an Apache 2.0 license for commercial use.
6. **OpenAI** is rolling out, over the next two weeks, new voice and image capabilities in ChatGPT enabling ChatGPT to understand images, understand speech and speak. The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. .
7. **Mistral AI**, a French startup, released its first 7B-parameter model, **Mistral 7B**, which outperforms all currently available open models up to 13B parameters on all standard English and code benchmarks. Mistral 7B is released in Apache 2.0, making it usable without restrictions anywhere.
8. **OpenAI** has returned the ChatGPT browsing feature for Plus subscribers, enabling ChatGPT to access internet for current information. It was disabled earlier as users were able to deploy it to bypass the paywalls of leading news publishers.
9. **Microsoft** has released **AutoGen** \- an open-source framework that enables development of LLM applications using multiple agents that can converse with each other to solve a task. Agents can operate in various modes that employ combinations of LLMs, human inputs and tools.
10. **LAION** released **LeoLM**, the first open and commercially available German foundation language model built on Llama-2
11. Researchers from **Google** and **Cornell University** present and release code for DynIBaR (Neural Dynamic Image-Based Rendering) - a novel approach that generates photorealistic renderings from complex, dynamic videos taken with mobile device cameras, overcoming fundamental limitations of prior methods and enabling new video effects.
12. **Cloudflare** launched **Workers AI** (an AI inference as a service platform), **Vectorize** (a vector Database) and **AI Gateway** with tools to cache, rate limit and observe AI deployments. Llama2 is available on Workers AI.
13. **Amazon** announced the general availability of **Bedrock**, its service that offers a choice of generative AI models from Amazon itself and third-party partners through an API.
14. **Google** announced it’s giving website publishers a way to opt out of having their data used to train the company’s AI models while remaining accessible through Google Search.
15. **Spotify** has launched a pilot program for AI-powered voice translations of podcasts in other languages - in the podcaster’s voic. It uses OpenAI’s newly released voice generation model.
16. **Getty Images** has launched a generative AI image tool, ‘**Generative AI by Getty Images**’, that is ‘commercially‑safe’. It’s powered by Nvidia Picasso, a custom model trained exclusively using Getty’s images library.
17. **Optimus**, Tesla’s humanoid robot, can now sort objects autonomously and do yoga. Its neural network is trained fully end-to-end.
18. **Amazon** will invest up to $4 billion in Anthropic. Developers and engineers will be able to build on top of Anthropic’s models via Amazon Bedrock.
19. **Google Search** indexed shared Bard conversational links into its search results pages. Google says it is working on a fix.
20. **Pika** Labs' text-to-video tool now lets users encrypt a message in a video\].

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
46,learnmachinelearning,open-ai,top,2022-10-19 09:27:38,Fixing YouTube Search with OpenAI's Whisper,jamescalam,False,0.95,82,y7xxri,https://www.reddit.com/r/learnmachinelearning/comments/y7xxri/fixing_youtube_search_with_openais_whisper/,13,1666171658.0,"Hi all, I wanted to [build a ""YouTube search"" app](https://www.pinecone.io/learn/openai-whisper/) for some time. Not the typical YouTube search where you return videos, but a YouTube search that returns the specific part of a video that answers your question. With text-based data this is pretty easy, but video/audio is less so.

That was until OpenAI (open sourced?) Whisper, a new SotA for speech-to-text. So I went ahead and built [""Ask YouTube""](https://huggingface.co/spaces/jamescalam/ask-youtube). A little search bar where you can ask technical questions and get the exact most relevant part from a set of videos (for now, the video scope is limited, I'll add more soon).

I explained everything I did to build it in [the linked article](https://pinecone.io/learn/openai-whisper/) and [video](https://youtu.be/vpU_6x3jowg). You could also just grab the app code and replicate it, I don't think it would take long. At a high level it is:

* Download YouTube audio with `pytube`
* Transcribe with OpenAI's Whisper
* Do some data prep
* Encode using Hugging Face / sentence-transformers
* Index and query with Pinecone vector DB

Then I wrapped all of this into a quick Streamlit web app and hosted it all for free on Hugging Face Spaces. One somewhat surprising thing here is absolutely everything was either open source or free, I didn't pay a dime!

Anyway, I hope this is interesting. Let me know what you think!"
47,learnmachinelearning,open-ai,top,2020-05-26 02:46:48,Artificial intelligence grad program comparison,kookookachoo17,False,0.96,77,gqostb,https://www.reddit.com/r/learnmachinelearning/comments/gqostb/artificial_intelligence_grad_program_comparison/,17,1590461208.0,"Hello all!

This is a career/education-oriented post, so if it's in the wrong spot I apologize and will be happy to move it.

TLDR: recent CS grad, trying to figure out a better grad program. One is more general and has a wider focus but isn't entirely AI-focused, and the other is more narrowly focused on NLP. Thoughts?


I am a recent undergrad computer science graduate, and I'm currently looking at two (and possibly more, I'm open to online programs as well but would prefer one of these) AI-focused graduate programs in NJ. 

One is the MSCS at Monmouth University, with a focus in Database and Intelligent Systems. Here is the program:

https://catalog.monmouth.edu/graduate-catalog/science/computer-science-software-engineering/computer-science-ms-databases-intelligent-information-systems-non-thesis-track/

I'm also considering the MS in Computational Linguistics from Montclair State University: 

https://www.montclair.edu/graduate/programs-of-study/computational-linguistics-ms/

I've already been accepted to the Monmouth University program, but my concern is that it doesn't contain enough in depth theory. The program offers additional AI courses aside from the required ones, but I'm not sure it will be enough to gain a competitive amount of knowledge. Conversely, the Computational Linguistics program at Montclair is very in depth, but narrowly focused on NLP.

 I AM very interested in NLP, but also find computer vision fascinating and worry about pigeonholing myself into a niche field, vs having a more general master's w/ an AI track. If it matters, I don't have current plans to pursue a PhD. Does anyone have any recommendations/experience with this sort of choice, should I look at other programs instead of these, etc.? Sorry for the wall of text and thanks in advance!"
48,learnmachinelearning,open-ai,top,2023-03-25 06:14:22,Does it make sense to specialize in NLP now?,Aromatic_Eye_6268,False,0.92,80,121cvgi,https://www.reddit.com/r/learnmachinelearning/comments/121cvgi/does_it_make_sense_to_specialize_in_nlp_now/,20,1679724862.0,"With the explosion of Large Language Models, it is clear that most of the cutting edge work is being done in a handful of companies around the world. Does it make sense to specialize in NLP? Will someone be able to do novel research work in NLP without being a part of places like OpenAI?"
49,learnmachinelearning,open-ai,top,2019-04-14 05:14:01,Humans Call GG! OpenAI Five Bots Beat Top Pros OG in Dota 2,gwen0927,False,0.92,78,bczjd5,https://medium.com/syncedreview/humans-call-gg-openai-five-bots-beat-top-pros-og-in-dota-2-8508e59b8fd5,7,1555218841.0,
50,learnmachinelearning,open-ai,top,2019-04-25 04:55:07,"Took too long to research and write about DeepMind's AlphaStar. After OpenAI's Dota 2 bot, I finally wrote a technical summary.",jshek,False,0.94,72,bh4odw,https://www.reddit.com/r/learnmachinelearning/comments/bh4odw/took_too_long_to_research_and_write_about/,3,1556168107.0,"I've been researching and reading about AlphaStar for months, but I was never able to put pen to paper and write. After OpenAI's Dota 2 events the last two weeks, I forced myself to summarize all the research I had read into deep reinforcement learning onto an article. 

[https://www.senrigan.io/blog/takeaways-from-openai-5](https://www.senrigan.io/blog/takeaways-from-openai-5)

Love to know your thoughts! I compare both bots (OpenAI's Dota 2 vs. AlphaStar)."
51,learnmachinelearning,open-ai,top,2022-09-23 13:46:55,Created a GUI for OpenAI's Whisper Using Gradio,ImplodingCoding,False,0.96,70,xly2gp,https://v.redd.it/6djgfjpp4mp91,9,1663940815.0,
52,learnmachinelearning,open-ai,top,2023-07-10 14:36:34,🤖🔎 Excited to introduce 'GPT-Researcher'!,Legal-Dragonfruit845,False,0.81,69,14vvtqf,https://www.reddit.com/r/learnmachinelearning/comments/14vvtqf/excited_to_introduce_gptresearcher/,35,1688999794.0,"The idea is simple - Specify what you want to research, and the AI will autonomously research it for you in minutes!

▸ One prompt generates an unbiased, factual and in depth research report

▸ Generate research, outlines, resource and lessons reports

▸ Aggregates over 20 web sources per research

▸ Includes an easy to use web interface

▸ Open source: [https://github.com/assafelovic/gpt-researcher](https://github.com/assafelovic/gpt-researcher)

▸ Scrapes web sources with javascript support

▸ Keeps track and context of visited and used web sources

https://reddit.com/link/14vvtqf/video/zce4347lf5bb1/player"
53,learnmachinelearning,open-ai,top,2023-01-15 00:08:37,Is it still worth learning NLP in the age of API-accessibles LLM like GPT?,CrimsonPilgrim,False,0.94,63,10c509n,https://www.reddit.com/r/learnmachinelearning/comments/10c509n/is_it_still_worth_learning_nlp_in_the_age_of/,24,1673741317.0,"A question that, I hope, you will find legitimate from a data science student.

I am speaking from the point of view of a data scientist not working in research.

Until now, learning NLP could be used to meet occasional business needs like sentiment analysis, text classification, topic modeling....

With the opening of GPT-3 to the public, the rise of ChatGPT, and the huge wave of applications, sites, plug-ins and extensions based on this technology that are accessible with a simple API request, it's impossible not to wonder if spending dozens of hours diving into this field if ML wouldn't be as useful today as learning the source code of the Pandas library. 

In some specialized cases, it could be useful, but GPT-3, and the models that will follow, seem to offer more than sufficient results for the immensity of the cases and for almost all classical NLP tasks. Not only that, but there is a good chance that the models trained by giants like Open-AI (Microsoft) or Google can never be replicated outside these companies anyway.  With ChatGPT and its incomparable mastery of language, its ability to code, summarize, extract topics, understand... why would I bother to use BERT or a TF-IDF vectorizer when an API will be released? Not only it would be easily accessible, but it also would be much better at the task, faster and cheaper.

In fact, it's a concern regarding all the machine learning field in general with the arrival of powerful ""no-code"" applications, which abstract a large part of the inherent complexity of the field. There will always be a need for experts, for safeguards, but in the end, won't the Data Scientist who masters the features of GPT-3 or 4 and knows a bit of NLP be more efficient than the one who has spent hours reading Google papers and practicing on Gensim, NLTK, spacy... It is the purpose of an API to make things simpler eventually... At what point is there no more reason to be interested in the behind-the-scenes of these tools and to become simple users rather than trying to develop our own techniques?"
54,learnmachinelearning,open-ai,top,2021-08-08 01:51:11,"This week in AI: VoxPopuli, Cool Generative Models, Perceiver IO, New platform for Medical Imaging",feather-ai,False,0.96,62,p05xl3,https://www.reddit.com/r/learnmachinelearning/comments/p05xl3/this_week_in_ai_voxpopuli_cool_generative_models/,1,1628387471.0,"1) Facebook release VoxPopuli, a dataset with over 400,000 hours of speech data (labelled and unlabelled): [https://ai.facebook.com/blog/voxpopuli-the-largest-open-multilingual-speech-corpus-for-ai-translation-and-more/](https://ai.facebook.com/blog/voxpopuli-the-largest-open-multilingual-speech-corpus-for-ai-translation-and-more/)   

2) Sheng-Yu Wang et al. create an algorithm that allows re-writing a GAN to produce in-domain images by only providing a handful of sketch samples: [https://arxiv.org/abs/2108.02774](https://arxiv.org/abs/2108.02774)   

3) DeepMind announce and open source Perceiver IO - an addition to the Perceiver which allows it to output and model all modalities: [https://deepmind.com/blog/article/building-architectures-that-can-handle-the-worlds-data](https://deepmind.com/blog/article/building-architectures-that-can-handle-the-worlds-data)   

4) Meng et al. use Stochastic Differential Equations to create an algorithm that allows synthesising images from strokes, and also editing images using strokes: [https://arxiv.org/abs/2108.01073](https://arxiv.org/abs/2108.01073)   

5) Stanford’s Center for Artificial Intelligence in Medicine and Imaging (AIMI) team with Microsoft's AI for Health program to create an open source repository of medical imaging data: https://hai.stanford.edu/news/open-source-movement-comes-medical-datasets [https://stanfordaimi.azurewebsites.net/](https://stanfordaimi.azurewebsites.net/)   

&#x200B;

Watch the video for more info: [https://www.youtube.com/watch?v=Q3YPO6Yfo78](https://www.youtube.com/watch?v=Q3YPO6Yfo78) 

&#x200B;

https://reddit.com/link/p05xl3/video/pvkr20x8i1g71/player"
55,learnmachinelearning,open-ai,top,2018-11-09 03:14:53,"Spinning Up in Deep RL - ""...an educational resource produced by OpenAI that makes it easier to learn about deep reinforcement learning (deep RL).""",ClydeMachine,False,0.93,62,9vgwch,https://blog.openai.com/spinning-up-in-deep-rl/,3,1541733293.0,
56,learnmachinelearning,open-ai,top,2022-10-27 14:51:50,CROWDLAB: open-source tools for data labeled by multiple annotators,cmauck10,False,0.94,57,yeu074,https://www.reddit.com/r/learnmachinelearning/comments/yeu074/crowdlab_opensource_tools_for_data_labeled_by/,12,1666882310.0,"Hi Redditors! Many of us in machine learning use multiple annotations to get higher quality labels for our data — yet AFAIK there is no open-source python package for **data labeled by multiple annotators** — so we [built one](https://docs.cleanlab.ai/stable/tutorials/multiannotator.html), [benchmarked it](https://cleanlab.ai/blog/multiannotator/), and released [the CROWDLAB paper](https://cleanlab.github.io/multiannotator-benchmarks/paper.pdf).

[CROWDLAB produces a consensus label, confidence, and annotator score for data labeled by multiple annotators.](https://preview.redd.it/oo5351711dw91.png?width=1630&format=png&auto=webp&s=8e7824276093577e81719de7dfd69fced8505b40)

After many long nights, I'm psyched to share the new easy-to-use and effective CROWDLAB algorithm that can use **any classifier** to estimate:

1 - A **consensus label** for each example that aggregates the individual annotations.

* more accurate than aggregation via majority-vote and common crowd-sourcing algorithms

2 - A **quality score for each consensus label** which measures the confidence that the consensus is correct.

* uses well-calibrated estimates that account for the: number of annotations for each example and their agreement, prediction-confidence from a trained classifier, and trustworthiness of each annotator vs. the classifier

3 - A **quality score for each annotator** which estimates the overall correctness of their labels.

**Surprise!** All 3 tasks are estimated in one line of open-source code via [cleanlab.multiannotator.get\_label\_quality\_multiannotator](https://docs.cleanlab.ai/stable/tutorials/multiannotator.html) .

    from cleanlab.multiannotator import get_label_quality_multiannotator  
    
    get_label_quality_multiannotator(multiannotator_labels, pred_probs)  
    # multiannotator_labels: matrix with rows = examples, columns = annotator labels, NA = missing label 
    # pred_probs: predicted class probabilities from any trained classifier

Extensive benchmarks on real-world multi-annotator data show that CROWDLAB produces significantly better estimates for all three tasks than algorithms from crowdsourcing like: majority-vote, GLAD, Dawid-Skene, etc.

Using simple weighted ensembles rather than complex generative models makes CROWDLAB results easy to understand, efficient, and reproducible. An added benefit — CROWDLAB also works well for datasets that include examples with a single annotation (useful for folks who have a tight data labeling budget 😉).

* Blog post: [https://cleanlab.ai/blog/multiannotator/](https://cleanlab.ai/blog/cleanlab-v2.1)
* Paper: [https://cleanlab.github.io/multiannotator-benchmarks/paper.pdf](https://cleanlab.github.io/multiannotator-benchmarks/paper.pdf)
* Tutorial: [https://docs.cleanlab.ai/stable/tutorials/multiannotator.html](https://docs.cleanlab.ai/stable/tutorials/multiannotator.html)
* Benchmarks: [https://github.com/cleanlab/multiannotator-benchmarks](https://github.com/cleanlab/multiannotator-benchmarks)
* Code: [https://github.com/cleanlab/cleanlab](https://github.com/cleanlab/cleanlab)

Have fun using CROWDLAB!"
57,learnmachinelearning,open-ai,top,2023-03-25 16:23:09,What's the current state of actually free and open source LLMs?,maquinary,False,0.97,58,121qvqn,https://www.reddit.com/r/learnmachinelearning/comments/121qvqn/whats_the_current_state_of_actually_free_and_open/,25,1679761389.0,"*People, take easy on me, I just a newbie that tests stuff made by A.I. in a very amateur manner.*

---------------------

Yesterday a played a bit with [Alpaca.cpp](https://github.com/antimatter15/alpaca.cpp), but despite the fact that the software itself is in the MIT license, it has serious limitations because of licensing factors, as you can see [here](https://crfm.stanford.edu/2023/03/13/alpaca.html):

>[...]

>

> We emphasize that Alpaca is intended only for academic research and any commercial use is prohibited. There are three factors in this decision: First, Alpaca is based on LLaMA, which has a non-commercial license, so we necessarily inherit this decision. Second, the instruction data is based on OpenAI’s text-davinci-003, whose terms of use prohibit developing models that compete with OpenAI. Finally, we have not designed adequate safety measures, so Alpaca is not ready to be deployed for general use.

>

> [...]

So, do we have anything that is **completely free** that reaches at least the level of GTP-3?

And what about the data that people use to train the models? Those big companies can ""scan"" the entire web to get insane amounts of data, but can free software developers use these already harvested data to train their own models? Or, in order to have a completely free LLM, people will have to collect data again from the Internet?

-------------

*When I say ""free"", I mean free from licensing limitations, in a sense that I can implement the A.I. in my software without the need of being forced to apply a limited range of licenses, or without the need to pay.*"
58,learnmachinelearning,open-ai,top,2021-11-04 01:18:35,Jupyter Ascending - open-source tool to run notebooks from your favorite code editor,ai_ellie,False,0.99,61,qm9ecu,https://www.reddit.com/r/learnmachinelearning/comments/qm9ecu/jupyter_ascending_opensource_tool_to_run/,7,1635988715.0,"Hi all, 

I've seen a bunch of posts here debating the relative merits of developing in a Jupyter notebook vs. in a powerful IDE/code editor. There are pros and cons to each; notebooks are amazing tools for visualization and interactivity, but they lack the full support (e.g. autocomplete, keybindings, refactoring tools) of your favorite code editor. 

We at Generally Intelligent had the same dilemma, so we decided to build and open-source a tool that lets you edit and run cells in a notebook from your code editor (e.g. PyCharm) so you can have the best of both worlds:

[https://generallyintelligent.ai/open-source/2021-10-14-jupyter-ascending/](https://generallyintelligent.ai/open-source/2021-10-14-jupyter-ascending/)"
59,learnmachinelearning,open-ai,top,2018-11-24 16:19:37,Has anyone previously applied/interned at OpenAI? What was your experience like?,ZER_0_NE,False,0.9,52,9zzpzl,https://www.reddit.com/r/learnmachinelearning/comments/9zzpzl/has_anyone_previously_appliedinterned_at_openai/,19,1543076377.0,
60,learnmachinelearning,open-ai,top,2018-06-25 17:11:58,OpenAI Five,j_orshman,False,0.97,55,8ts9a7,https://blog.openai.com/openai-five/,2,1529946718.0,
61,learnmachinelearning,open-ai,top,2017-02-27 10:17:07,[Short Post] Eyes Open: My first 4 months in an ML product team,thundergolfer,False,0.97,56,5wfzz3,https://www.reddit.com/r/learnmachinelearning/comments/5wfzz3/short_post_eyes_open_my_first_4_months_in_an_ml/,7,1488190627.0,"Hey r/learnmachinelearning

I'm writing this short post in response to [this infographic post](https://www.reddit.com/r/learnmachinelearning/comments/5w8lsf/the_4_stages_in_machine_learning_source_udacity/), *The 4 Stages of Machine Learning*. I basically [replied to it](https://www.reddit.com/r/learnmachinelearning/comments/5w8lsf/the_4_stages_in_machine_learning_source_udacity/de8c4g7/) saying that it encapsulates reasonably well ML in a research context, but not so much the greater problem of production ML systems. People asked me to expand on that so here it is. 

What's my experience with production ML? Pretty limited, but my very short time in it has been eye-opening. I started a year long data engineering internship with Zendesk's ML product team in November 2016. It's the team that posted [*Serving Tensorflow in Production at Zendesk*](https://www.reddit.com/r/MachineLearning/comments/5w64uo/p_serving_tensorflow_in_production_at_zendesk/) recently. Our product is [*Automatic Answers*](https://www.zendesk.com/automatic-answers/). 

#### Getting XX.XX% on a dataset vs. creating a product for users

Perhaps the most important difference between the ML most people here know and production ML at Zendesk is that Zendesk's ML must have *business value*, which means it must offer *value to customers*. Zendesk has a product model, and Automatic Answers must fit into that and drive the companie's growth. Sure ML and AI are really cool, but if you can't get it to be useful to a user then you have nothing. Before Zendesk, I saw ML as ""how can I get this damn network to train and perform on this dataset? The pros have achieved 9X.XX% accuracy."" Now 'doing ML' for the team includes: 

* Managing customer expectations
* Debugging problems end-users face with how the model behaves
* Serving 1000s of models and their predictions on demand to thousands of people
* So. much. UX.

I can't tell you how influential UX seems to be to the success of real-software systems. Your model can be awesome, but your ML system (in a production context) really includes everything the *product* relies on, from the data ingestion system to the end-user UX. If those fail you your model is pointless and your ML system is crippled.


#### more about ML in the real world (again, from what *I've* seen)

Just as it's known that Data Science is really around 20% research and 80% data stewardship, being an ML engineer in production means that your responsibilities extend beyond training models on ready-to-go datasets. You're going to be using them, so capabilities with AWS/GCP, Hadoop/Spark, Tensorflow Serving, Pachyderm, Docker, Data Visualisation, SQL are all very handy. Also, all of a sudden your work becomes part of a wider team, product, and company so it must actually be *reproducible*, *implementable*, *bug-free*, *documented*.  Those four things don't really constrain researchers and at-home ML hobbyists. 

#### Eyes Open 

Realistically, the world of 'open-source and MOOC' ML consists *mostly* of 3 kinds of ML work:

1. Tutorials
2. Implementing ML research papers
3. Personal Projects

Of these, the first two are basically 'follow the steps'. It's certainly not easy but it's not like what's done in industry. The third may or may not involve real end-users and production-ready ML engineering, most don't. You can go along and learn a bunch about ML through doing the above things and still be wholly unsuccessful at production ML engineering, which really does require you put on different hats (product management, data engineer, reliability engineer, OPS, Tester, etc). 

#### What's heartening to me

I should remind that I am not an *ML* Engineering Intern, I'm a Data Engineering intern. Though part of my work is solving problems peculiarly associated with and created by ML systems, and it's pretty awesome. Though I'm not sitting there with IPython and Tensorboard open, my work falls within what I would call *ML Engineering*. It's a much broader problem than the already massive problem that is Machine Learning research, and it stands on its own as a pretty great (under-exposed) area of software engineering. I likely could not have gained an internship in ML research as an undergrad, but being a data engineer in an ML team is pretty much the next best thing. Further, it seems the norm amongst ML teams to encourage cross-fertilisation of skills so if you're in the ML team you're bound to be up-skilling in ML. **If you don't have/want-to-get a PHD, but love ML, seriously consider shaping yourself as a Data/ML engineer. You'll be in high-demand.**

#### Learn more about real-world ML

There really isn't enough material out there on 'real-world ML'. The field is still quite new, and people are still finding their feet. Most of the good ML engineering stuff comes, unsurprisingly, out of Google. They've been doing ML in production for a long time now and on a massive scale, so they've come face to face with it's unique challenges. 

Properly explaining how big the problem of production ML is would take more than a few books, and so far no one's even written one book on it. Nevertheless, here are some things I've read which give at least some insight into production ML and its teams.

* [Google's M. Zinkevich's ""Rules of Machine Learning""](https://github.com/thundergolfer/google-rules-of-machine-learning)
* [Hidden Technical Debt in Machine Learning - Google](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)
* [Google's hybrid approach to research - P. Norvig](http://norvig.com/cacm-hybrid.html)
* [Detecting Adversarial Advertisements in the Wild - Google](https://www.eecs.tufts.edu/~dsculley/papers/adversarial-ads.pdf)
* [Scaling Big Data Infrastructure: The Twitter Experience](http://www.datascienceassn.org/sites/default/files/Scaling%20Big%20Data%20Mining%20Infrastructure%20-%20The%20Twitter%20Experience.pdf)
"
62,learnmachinelearning,open-ai,top,2023-05-19 07:08:51,OpenAI Launches ChatGPT App For iOS Users,vadhavaniyafaijan,False,0.88,54,13lnv1e,https://www.theinsaneapp.com/2023/05/chatgpt-app-for-iphone-and-ipad.html,10,1684480131.0,
63,learnmachinelearning,open-ai,top,2022-07-15 11:15:58,"Beside OpenAI, Google and Midjourney; what are the companies/start-ups working on text to image generation?",matxi182,False,0.93,53,vzm5rb,https://www.reddit.com/r/learnmachinelearning/comments/vzm5rb/beside_openai_google_and_midjourney_what_are_the/,32,1657883758.0,
64,learnmachinelearning,open-ai,top,2023-01-29 21:14:13,Create a Serverless Search Engine using the OpenAI Embeddings API,sopmac21379,False,0.94,52,10oitli,https://medium.com/sopmac-ai/create-a-serverless-search-engine-using-the-openai-embeddings-api-50e5ac8ca6e3,1,1675026853.0,
65,learnmachinelearning,open-ai,top,2021-09-21 19:13:07,Need some advice for starting out in this field,AlreadyOwnMyself,False,0.91,51,pspq0f,https://www.reddit.com/r/learnmachinelearning/comments/pspq0f/need_some_advice_for_starting_out_in_this_field/,12,1632251587.0,"Hello, long time lurker here who has been dabbling on and off with ML (watched some courses and tried my take at some projects).

But I can't help feeling that I've yet to grasp a lot of the essential concepts. I've not followed any study plan and feel like even though I majored in CS my math skills are kind of rusty.

Thus, I tried my best at creating a small study guide.

1. Prerequisites
   1. [3Blue1Brown - Essence of Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)
   2. [3Blue1Brown - Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)
   3. Stats and Python libs -> [Think stats 2nd ed.](https://greenteapress.com/wp/think-stats-2e/)
2. Basics Machine Learning
   1. [Machine Learning Course by Andrew Ng](https://www.coursera.org/learn/machine-learning)
3. Deep learning
   1. [fast.ai - Free Courses (Practical Deep Learning for Coders)](https://course.fast.ai/)

However I'm not sure how good it actually is :)

Do you think it's a good way to approach this? Is this a good enough basis to start building upon? (I'm thinking of going more in-depth with the understanding after finishing this)

I was thinking to also include [Mathematics for machine learning](https://mml-book.github.io/) and [OpenIntro stats](https://www.openintro.org/book/os/) for prereqs as well as Stanford courses for DL but I don't want to over-do it (and end up with a huge list that just feels demotivating).

Or maybe I'm having the wrong expectations and I should expect things to take a lot of time?

Any help is more than appreciated :D"
66,learnmachinelearning,open-ai,top,2023-08-16 11:26:18,OpenAI Notebooks which are really helpful,vishank97,False,0.92,50,15sn6ti,https://www.reddit.com/r/learnmachinelearning/comments/15sn6ti/openai_notebooks_which_are_really_helpful/,2,1692185178.0,"The OpenAI cookbook is one of the most underrated and underused developer resources available today. Here are 7 notebooks you should know about:

1. Improve LLM reliability:  
[https://github.com/openai/openai-cookbook/blob/main/techniques\_to\_improve\_reliability.md](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)
2. Embedding long text inputs:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Embedding\_long\_inputs.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Embedding_long_inputs.ipynb)
3. Dynamic masks with DALLE:  
[https://github.com/openai/openai-cookbook/blob/main/examples/dalle/How\_to\_create\_dynamic\_masks\_with\_DALL-E\_and\_Segment\_Anything.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/dalle/How_to_create_dynamic_masks_with_DALL-E_and_Segment_Anything.ipynb)
4. Function calling to find places nearby:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Function\_calling\_finding\_nearby\_places.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Function_calling_finding_nearby_places.ipynb)
5. Visualize embeddings in 3D:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Visualizing\_embeddings\_in\_3D.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Visualizing_embeddings_in_3D.ipynb)
6. Pre and post-processing of Whisper transcripts:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Whisper\_processing\_guide.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Whisper_processing_guide.ipynb)
7. Search, Retrieval, and Chat:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Question\_answering\_using\_a\_search\_API.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_a_search_API.ipynb)

Big thanks to the creators of these notebooks!"
67,learnmachinelearning,open-ai,top,2023-04-29 09:21:53,Prompt Engineering Free Course For Beginners By OpenAI And Deep Learning AI,vadhavaniyafaijan,False,0.78,53,132o8tt,https://www.theinsaneapp.com/2023/04/free-prompt-engineering-course-for-beginners.html,7,1682760113.0,
68,learnmachinelearning,open-ai,top,2022-03-02 07:36:55,NiceScaler 1.1.0 - Lossless image upscaler app based on OpenCV SuperResolution deeplearning models,jangystudio,False,0.91,51,t4uupo,https://www.reddit.com/r/learnmachinelearning/comments/t4uupo/nicescaler_110_lossless_image_upscaler_app_based/,11,1646206615.0," 

[Gui interface](https://preview.redd.it/van8gewubxk81.png?width=2048&format=png&auto=webp&s=74b087b5cfd8023cd981bad42cf2bcd979a289d4)

I just released the first major update, the version 1.1.0, which includes:

1. Multiple photos upscaling (batch upscaling)
2. More images dropped shows in a list with image counter
3. Complete UI / UX overhaul (using a dark color palette)
4. Stop button to stop upscaling process
5. Speed up image conversion to png
6. Added Paypal button to support the project (and now it's free)
7. Automatically remove duplicates in dropped images
8. General code cleaning, bugfix and improvements

All project is Python based, libraries used are:

1. Tkinter
2. OpenCV
3. PyInstaller

Github here  
\-> [https://github.com/Djdefrag/NiceScaler](https://github.com/Djdefrag/NiceScaler)

Installation.  
NiceScaler does not require any installation, it's a single portable exe usable on any Windows PC

Supported IA backends.  
Actually NiceScaler utilize only CPU to upscale to be compatible with any PC

Features.  
\- Different IA models selection  
\- Drag and drop single image or multiple images  
\- Auto-convert images to .png  
\- Factor x2 upscaling   
\- Simple and clean GUI  
\- Compatible with PNG, JPEG, BMP, WEBP, TIF images  
\- Portable everywhere without installation

Next steps.  
\- Video upscaling  
\- More AI backends (CUDA / OpenCL / Vulkan)  
\- Pre-processing (image/videos downscaling before upscaling)

Feedback.  
Please, give me feedback about the product, i will listen all feedback.

Thank you for your support :)"
69,learnmachinelearning,open-ai,top,2022-02-28 10:15:28,TinyML Monitoring Air Quality an 8-bit Microcontroller,literallair,False,0.91,51,t3ce5j,https://www.reddit.com/r/learnmachinelearning/comments/t3ce5j/tinyml_monitoring_air_quality_an_8bit/,4,1646043328.0,"I’d like to share my experiment on how to easily create your own tiny machine learning model and run inferences on a microcontroller to detect the concentration of various gases. I will illustrate the whole process with my example of detecting the concentration of benzene (С6H6(GT)) based on the concentration of other recorded compounds.

Things I used in this project: Arduino Mega 2560, Neuton Tiny ML software

To my mind, such simple solutions may contribute to improving the air pollution problem which now causes serious concerns. In fact, the World Health Organization estimates that over seven million people die prematurely each year from diseases caused by air pollution. Can you imagine that?

As such, more and more organizations, responsible for monitoring emissions, need to have effective tools at their disposal to monitor the air quality in a timely way, and TinyML solutions seem to be the best technology for that. They are quite low-energy and cheap to produce, as well as they don’t require a permanent Internet connection. I believe these factors will promote the mass implementation of TinyML as a great opportunity to create AI-based devices and successfully solve various challenges.

Therefore, in my experiment, I take the most primitive 8-bit MCU to show that even such a device today can have ML models in it.

Dataset description:

My dataset contained 5875 rows of hourly averaged responses from an array of oxide chemical sensors that were located on the field in a polluted area in Italy, at road level. Hourly averaged concentrations for CO, Non-Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx), and Nitrogen Dioxide (NO2) were provided.

It is a regression problem.

Target metric – MAE (Mean Absolute Error). Target - C6H6(GT).

Attribute Information:RH - Relative Humidity

AH - Absolute Humidity

T - Temperature in °C;

PT08.S3(NOx) - Tungsten oxide. Hourly averaged sensor response (nominally NOx targeted);

PT08.S4(NO2) - Tungsten oxide. Hourly averaged sensor response (nominally NO2 targeted);

PT08.S5(O3) - Indium oxide. Hourly averaged sensor response (nominally O3 targeted);

PT08.S1(CO) - (Tin oxide) hourly averaged sensor response (nominally CO targeted);

CO(GT) - True hourly averaged concentration CO in mg/m\^3 (reference analyzer);

PT08.S2(NMHC) - Titania. hourly averaged sensor response (nominally NMHC targeted);

You can see more details and download the dataset here: ​​[https://archive.ics.uci.edu/ml/datasets/air+qualityProcedure](https://archive.ics.uci.edu/ml/datasets/air+qualityProcedure):

Step 1: Model Training

The model was created and trained with a free tool, Neuton TinyML, as I needed a super compact model that would fit into a tiny microcontroller with 8-bit precision. I tried to make such a model with the help of TensorFlow before, but it was too large to run operations on 8 bit.

To train the model, I converted the dataset into a CSV file, uploaded it to the platform, and selected the column that should be trained to make predictions.  


&#x200B;

https://preview.redd.it/1gwa81l1ujk81.png?width=1899&format=png&auto=webp&s=9c20805a91494e17e08e48d8a70139b9ab9698dd

&#x200B;

https://preview.redd.it/t1qncrl3ujk81.png?width=1901&format=png&auto=webp&s=4e53fbab4da74b033e4e7a7374861be93a3ea76b

The trained model had the following characteristics:  
The model turned out to be super compact, having only 38 coefficients and 0.234 KB in size!  


&#x200B;

https://preview.redd.it/uu35fal7ujk81.png?width=1900&format=png&auto=webp&s=dd08a6b3e4a3dc9c7ee998b92243673af331fd66

Additionally, I created models with TF and TF Lite and measured metrics on the same dataset. The comparison speaks louder than words. Also, as I said above, TF models still cannot run operations on 8 bits, but it was interesting for me to use just such a primitive device.  


&#x200B;

https://preview.redd.it/6h0zlqi9ujk81.png?width=1497&format=png&auto=webp&s=e2b74048f8a5a9159d6c87d0a8b44efa710cc8ca

Step 2: Embedding into a Microcontroller

Upon completion of training, I downloaded the archive which contained all the necessary files, including meta-information about the model in two formats (binary, and HEX), calculator, Neuton library, and the implementation file.  


&#x200B;

https://preview.redd.it/dypc560eujk81.png?width=1900&format=png&auto=webp&s=9901e1f89ed0dade6173cd167e584139e58758b2

Since I couldn’t run the experiment in field conditions with real gases, I developed a simple protocol to stream data from a computer.

Step 3: Running Inference on the Microcontroller

I connected a microcontroller on which the prediction was performed to a computer via a serial port, so signals were received in a binary format.

The microcontroller was programmed to turn on the red LED if the concentration of benzene was exceeded, and the green LED - if the concentration was within permitted limits. Check out the videos below to see how it worked.  


&#x200B;

https://reddit.com/link/t3ce5j/video/ll5m97vttjk81/player

In this case, the concentration of benzene is within reasonable bounds (<15 mg/m3).  


&#x200B;

https://reddit.com/link/t3ce5j/video/vm5c5grutjk81/player

In this case, the concentration of benzene exceeds the limits (>15 mg/m3).

Conclusion

My example vividly illustrates how everyone can easily use the TinyML approach to create compact but smart devices, even with 8-bit precision. I’m convinced that the low production costs and high efficiency of TinyML open up enormous opportunities for its worldwide implementation.

Due to the absence of the need to involve technical specialists, in this particular case, even non-data scientists can rapidly build super compact models and locate smart AI-driven devices throughout the area to monitor air quality in real-time. To my mind, it’s really inspiring that such small solutions can help us improve the environmental situation on a global scale!"
70,learnmachinelearning,open-ai,top,2023-12-03 14:38:25,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.93,50,189ustx,https://www.reddit.com/r/learnmachinelearning/comments/189ustx/this_week_in_ai_all_the_major_ai_developments_in/,1,1701614305.0,"1. **Meta AI** introduced a suite of AI language translation models that preserve expression and improve streaming \[[*Details*](https://ai.meta.com/blog/seamless-communication) *|* [*GitHub*](https://github.com/facebookresearch/seamless_communication)\]:
   1. ***SeamlessExpressive*** enables the transfer of tones, emotional expression and vocal styles in speech translation. You can try a demo of SeamlessExpressive using your own voice as an input [***here***](https://seamless.metademolab.com/expressive)***.***
   2. ***SeamlessStreaming***, a new model that enables streaming speech-to-speech and speech-to-text translations with <2 seconds of latency and nearly the same accuracy as an offline model. In contrast to conventional systems which translate when the speaker has finished their sentence, SeamlessStreaming translates while the speaker is still talking. t intelligently decides when it has enough context to output the next translated segment.
   3. ***SeamlessM4T v2***, a foundational multilingual & multitask model for both speech & text. It's the successor to SeamlessM4T, demonstrating performance improvements across ASR, speech-to-speech, speech-to-text & text-to-speech tasks.
   4. ***Seamless***, a model that merges capabilities from SeamlessExpressive, SeamlessStreaming and SeamlessM4T v2 into one.
2. **Stability AI** released ***SDXL Turbo***: a real-time Text-to-Image generation model. SDXL Turbo is based on a a new distillation technology, which enables the model to synthesize image outputs in a single step and generate real-time text-to-image outputs while maintaining high sampling fidelity.
3. **Mozilla’s** innovation group and Justine Tunney released ***llamafile*** that lets you distribute and run LLMs with a single file. llamafiles can run on six OSes (macOS, Windows, Linux, FreeBSD, OpenBSD, and NetBSD) and on multiple CPU architectures.
4. **Perplexity** released two new PPLX models: ***pplx-7b-online and pplx-70b-online***. These *online LLMs* can leverage the most up-to-date information using the internet when forming a response..
5. **Google DeepMind** presented ***GNoME*** (Graph Networks for Materials Exploration): an AI tool that discovered *2.2 million new crystal structures*, with 380,000 being highly stable and promising for breakthroughs in superconductors, supercomputers, and advanced batteries for electric vehicles.
6. **Amazon** introduced two new Amazon Titan multimodal foundation models (FMs): ***Amazon Titan Image Generator*** (preview) and ***Amazon Titan Multimodal Embeddings***. All images generated by Amazon Titan contain an invisible watermark.
7. Researchers present ***Animatable Gaussians***, a new avatar representation method that can create lifelike human avatars from multi-view RGB videos.
8. **Pika Labs** released a major product upgrade of their generative AI video tool, ***Pika 1.0***, which includes a new AI model capable of generating and editing videos in diverse styles such as 3D animation, anime, cartoon and cinematic using text, image or existing video.
9. **Eleven Labs** announced a ***grant*** program offering 11M text characters of content per month for the first 3 months to solo-preneurs and startups.
10. Researchers from **UC Berkeley** introduced ***Starling-7B***, an open large language model trained using Reinforcement Learning from AI Feedback (RLAIF). It utilizes the GPT-4 labeled ranking dataset, Nectar, and a new reward training pipeline. Starling-7B outperforms every model to date on MT-Bench except for OpenAI’s GPT-4 and GPT-4 Turbo .
11. **XTX Markets** is launching a new $10mn challenge fund, the **Artificial Intelligence Mathematical Olympiad Prize** (AI-MO Prize) The grand prize of $5mn will be awarded to the first publicly-shared AI model to enter an AI-MO approved competition and perform at a standard equivalent to a gold medal in the in the International Mathematical Olympiad (IMO) .
12. **Microsoft Research** evaluated GPT-4 for processing ***radiology reports***, focusing on tasks like disease classification and findings summarization. The study found GPT-4 has a sufficient level of radiology knowledge with only occasional errors in complex context that require nuanced domain knowledge. The radiology report summaries generated by GPT-4 were found to be comparable and, in some cases, even *preferred* over those written by experienced radiologists.
13. **AWS** announced ***Amazon Q***, a new generative AI–powered assistant for businesses. It enables employees to query and obtain answers from various content repositories, summarize reports, write articles, perform tasks, and more, all within their company's integrated content systems. Amazon Q offers over 40 built-in connectors to popular enterprise systems.
14. 18 countries including the US, Britain signed a detailed international agreement on how to keep artificial intelligence safe from rogue actors, pushing for companies to create AI systems that are ‘secure by design’ .

**Source**: AI Brews - you can subscribe [here](https://aibrews.com/). it's free to join, sent only once a week with ***bite-sized news, learning resources and selected tools.*** I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks."
71,learnmachinelearning,open-ai,top,2024-01-04 21:15:12,Natural Language Processing (NLP) Learning Path - In depth,millhouse056,False,0.98,47,18yo5kp,https://www.reddit.com/r/learnmachinelearning/comments/18yo5kp/natural_language_processing_nlp_learning_path_in/,9,1704402912.0,"Hi friends, i'm currently engaged in NLP and created an pretty extense roadmap or learning path so begginers don't feel lost, it covers from the basics to advanced cutting-edge concepts.

Feedback is appreciated.

&#x200B;

\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-

&#x200B;

NLP Learning Roadmap

1. Prerequisites:

&#x200B;

* Mathematics:

&#x200B;

* Linear algebra
* Probability and statistics

&#x200B;

* Programming:

&#x200B;

* Proficiency in a programming language (e.g., Python)

**2. Introduction to NLP:**

&#x200B;

* Definition      and scope of NLP
* Historical      development of NLP
* Key challenges      and applications

**3. Text Analysis:**

&#x200B;

* **Lexical Analysis:**

&#x200B;

* Word meaning and structure

· Morphology (word formation)

· lemmatization (base form identification)

&#x200B;

* **Syntactic Analysis:**

· Parts-of-speech tagging

· Dependency parsing

· Constituency parsing

&#x200B;

* **Semantic Analysis:**

· Extracting meaning

· Encompassing word embedding models like Word2Vec and GloVe

· Topic modeling

&#x200B;

* **Semantic Analysis:**

· Coreference resolution

· Discourse analysis

&#x200B;

**3. Text Processing:**

&#x200B;

* **Tokenization:**

&#x200B;

* Sentence tokenization
* Word tokenization
* Subword tokenization (Byte Pair Encoding, SentencePiece)

&#x200B;

* **Stop Words Removal:**

&#x200B;

* Importance and impact on NLP tasks
* Customizing stop word lists

&#x200B;

* **Stemming and Lemmatization:**

&#x200B;

* Porter stemming algorithm
* Snowball stemming algorithm
* Lemmatization techniques and challenges

&#x200B;

* **Part-of-Speech Tagging:**

 

* POS tagging algorithms (HMM-based, rule-based, and neural-based)
* Fine-grained POS tagging

**4. Text Representation:**

&#x200B;

* **Bag of Words (BoW):**

 

* Term Frequency (TF) and Inverse Document Frequency (IDF)
* Bag of N-grams

&#x200B;

* **TF-IDF:**

 

* Calculating TF-IDF scores
* Applications in information retrieval

&#x200B;

* **Word Embeddings:**

 

* Word2Vec:

&#x200B;

* Continuous Bag of Words (CBOW) model
* Skip-gram model
* GloVe (Global Vectors for Word Representation)

&#x200B;

* **Contextual Embeddings:**

 

* ELMo (Embeddings from Language Models)
* ULMFiT (Universal Language Model Fine-tuning)
* OpenAI GPT (Generative Pre-trained Transformer)

**5. NLP Libraries and Tools:**

&#x200B;

* NLTK      (Natural Language Toolkit)
* SpaCy
* scikit-learn
* Transformers      library (Hugging Face)

**6. Statistical Language Models:**

&#x200B;

* **N-grams:**

 

* Unigrams, bigrams, and trigrams
* N-gram language models

&#x200B;

* **Hidden Markov Models (HMM):**

 

* Basics of HMMs
* Applications in part-of-speech tagging

**7. Machine Learning for NLP:**

&#x200B;

* **Supervised Learning:**

 

* Text classification algorithms (Naive Bayes, Support Vector       Machines)
* Evaluation metrics (precision, recall, F1-score)

&#x200B;

* **Named Entity Recognition (NER):**

 

* Rule-based NER
* Machine learning-based NER
* Evaluation metrics for NER

&#x200B;

* **Sentiment Analysis:**

 

* Sentiment lexicons
* Machine learning approaches for sentiment analysis

**8. Sequence-to-Sequence Models:**

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Vanishing and exploding gradient problems
* Bidirectional RNNs

&#x200B;

* **Long Short-Term Memory (LSTM):**

 

* Architecture and key components
* Gating mechanisms

&#x200B;

* **Gated Recurrent Unit (GRU):**

 

* Simplified gating compared to LSTM
* Applications and advantages

**9. Deep Learning Architectures for NLP:**

&#x200B;

* **Convolutional Neural Networks (CNN) for Text:**

 

* Text classification with CNNs
* Hierarchical and multi-channel CNNs

&#x200B;

* **Transfer Learning in NLP:**

 

* Fine-tuning pre-trained models
* Universal Sentence Encoder

&#x200B;

* **Transformer Architecture:**

 

* Self-attention mechanism
* Multi-head attention
* Positional encoding

**10. Transduction and Recurrency:**

&#x200B;

* **Transduction in NLP:**

 

* Definition and applications
* Challenges in sequence-to-sequence transduction

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Applications beyond sequence-to-sequence tasks
* Challenges in training RNNs

**11. Advanced Topics in Sequence Modeling:**

&#x200B;

* **Attention Mechanism:**

 

* Scaled Dot-Product Attention
* Position-wise Feedforward Networks

&#x200B;

* **Self-Attention Mechanism:**

 

* The concept of self-attention
* Layer normalization in self-attention

&#x200B;

* **Multi-Head Attention:**

 

* Motivation and benefits
* Combining multiple attention heads

**12. Syntax and Parsing:**

&#x200B;

* **Dependency Parsing:**

 

* Dependency tree representation
* Transition-based and graph-based parsing

&#x200B;

* **Constituency Parsing:**

 

* Treebank representation
* Earley parsing algorithm

&#x200B;

* **Parsing Techniques:**

 

* Chart parsing (CYK parser)
* Shift-Reduce parsing

**13. Semantic Role Labeling (SRL) and Coreference Resolution:**

&#x200B;

* **Semantic Role Labeling:**

&#x200B;

* PropBank and FrameNet
* Neural approaches to SRL

&#x200B;

* **Coreference Resolution:**

&#x200B;

* Mention detection
* End-to-end coreference resolution models

**14. Evaluation Metrics:**

&#x200B;

* Precision,      Recall, F1-score
* BLEU      score for machine translation
* Perplexity      for language models

**15. NLP in Industry and Research:**

&#x200B;

* Case      studies and applications in various domains (healthcare, finance, legal,      etc.)
* Emerging      research trends in NLP

**16. Ethical Considerations and Bias in NLP:**

&#x200B;

* **Addressing Bias in NLP Models:**

&#x200B;

* Identifying and mitigating biases in training data
* Fairness-aware machine learning

&#x200B;

* **Ethical Considerations in NLP Research and      Deployment:**

&#x200B;

* Privacy concerns in NLP
* Responsible AI practices in NLP

**17. Continuous Learning and Keeping Updated:**

&#x200B;

* Follow      conferences (ACL, NAACL, EMNLP)
* Engage      with the NLP community
* Explore      recent research papers and advancements (Arxiv, NeurIPS)

**18. Projects and Hands-on Practice:**

&#x200B;

* Apply      knowledge through practical projects
* Contribute      to open-source NLP projects
* Participate      in Kaggle competitions

==============================="
72,learnmachinelearning,open-ai,top,2023-05-16 07:40:00,EU AI Act: Shaping Or Destroying The Future Of US Open Source Softwares?,vadhavaniyafaijan,False,0.79,43,13iybuc,https://www.theinsaneapp.com/2023/05/eu-ai-act.html,48,1684222800.0,
73,learnmachinelearning,open-ai,top,2023-09-12 13:42:02,This is why LLMs have flooded the NLP market in the past 1 year 👇 (A Brief History of NLP),japkeerat,False,0.82,44,16grq5y,https://www.reddit.com/r/learnmachinelearning/comments/16grq5y/this_is_why_llms_have_flooded_the_nlp_market_in/,15,1694526122.0,"Text Generation has been the hottest topic in Natural Language Processing. Recurrent Neural Networks (RNNs) were among the Algorithms to generate text. How RNNs generated text is by essentially predicting the next word given the previous few words. At one-stage RNNs were the hottest commodity one could have. But researchers were worried about 1 problem.

RNNs had a context-length problem. To understand what is context-length, consider an analogy. You started reading a book, it’s 100 pages long and when you read each page, details of previous pages start to get a little hazy. Haziness keeps on increasing to the point that when you reach page 50, you don’t remember anything from the first 5 pages. That is exactly what the problem is with RNNs.

To solve this, researchers developed another algorithm called the Long-Short Term Memory (LSTM) and another variant called Bidirectional Long-Short Term Memory (Bi-LSTM) which had a larger context-length than RNNs. Let’s get back to the book analogy. This time while reading, you are making notes. When you go ahead to a new page and your previous pages information start to get hazy, you look back at these notes to refresh your memory. It’s oversimplified, but that’s basically how an LSTM works.

LSTMs were not perfect. There were a number of new issues that came up in order to resolve the previous one. Meanwhile, other areas of research and technological advancements were heating up. Hardware was getting more and more prominent and with cloud getting popular, it was easily accessible. And on the research side, a new kind of Algorithm came up that shaped the entire NLP domain from here on - Attention Mechanism.

Attention Mechanism, as you might have guessed, is all about telling the more sophisticated algorithms where to “focus”. It’s the same way how we focus more on certain parts of the meeting we attend than the entire meeting itself. In context of NLP, the Mechanism became the core part for better algorithms. These better algorithms could keep larger context-lengths and at the time of predicting the next word, ask the Attention Mechanism about what to focus on while predicting the next word. This was an era-defining discovery in NLP as the algorithms that came up after this were the Transformers.

Consider jigsaw puzzles. You start by looking at all the pieces at once and join the pieces together. Initially, it is random. You join a couple of pieces at the top left corner, a few in the centre and a couple more defining the right edge. You are doing it all at once. Transformers basically work the same way. They could look at longer context-lengths, all at once, courtesy of Attention Mechanism. This means, they can not only work with a sentence, they can work with an entire paragraph.  With time, these Transformers started becoming more and more sophisticated. It eventually reached to a point that the only thing that was keeping these algorithms in handcuffs was the lack of data.

Until recently, these algorithms were trained on a specific data but when algorithms became too powerful, researchers started throwing every kind of data they could find on the internet easily. It could be articles like this, your social media posts, exam papers and solutions, and ebooks in any language they could find and hoped the algorithms learnt it all. And they were right. Algorithms started learning all of it to the point that you could ask models to explain concepts of LLMs in how Shakespeare would write and it would give a real-sounding responsive. These algorithms were Large! And hence, became known as Large Language Models (LLMs).

There we are now. With LLMs. OpenAI, technically, won the race for LLM development. They brought everybody’s attention to LLMs first with GPT-2, but GPT-3 was where shit hit the roof and every company that had deep pockets started investing in LLMs.  The result? We now have a new LLM getting released EVERY. SINGLE. DAY.

*I post articles like these every few days on X. If you like this post, please* [follow me on X!](https://twitter.com/JapkeeratS/)

*NOTE: To make it simple for anybody, even without a tech background, to understand, a few things were oversimplified. I will be sharing soon on* [my X handle](https://twitter.com/JapkeeratS) *a technical version.*"
74,learnmachinelearning,open-ai,top,2018-04-27 07:22:52,"Karpathy says NNs should avoid regression problems (in favor of classification). Yet in Q-Learning, the function approximator is often an NN, even when the action space is discrete (and Q-Learning could be converted to a classification problem). Is CS231n correct?",Frozen_Turtle,False,1.0,43,8f9tes,https://www.reddit.com/r/learnmachinelearning/comments/8f9tes/karpathy_says_nns_should_avoid_regression/,16,1524813772.0,"From https://cs231n.github.io/neural-networks-2/ (emphasis mine):

>It is important to note that the L2 loss is much harder to optimize than a more stable loss such as Softmax. Intuitively, it requires a very fragile and specific property from the network to output exactly one correct value for each input (and its augmentations). Notice that this is not the case with Softmax, where the precise value of each score is less important: It only matters that their magnitudes are appropriate. Additionally, the L2 loss is less robust because outliers can introduce huge gradients. ***When faced with a regression problem, first consider if it is absolutely inadequate to quantize the output into bins.*** For example, if you are predicting star rating for a product, it might work much better to use 5 independent classifiers for ratings of 1-5 stars instead of a regression loss. Classification has the additional benefit that it can give you a distribution over the regression outputs, not just a single output with no indication of its confidence. If you’re certain that classification is not appropriate, use the L2 but be careful: For example, the L2 is more fragile and applying dropout in the network (especially in the layer right before the L2 loss) is not a great idea.

Outliers are not an issue in RL, which leaves only this:

>L2 loss is much harder to optimize than a more stable loss such as Softmax. Intuitively, it requires a very fragile and specific property from the network to output exactly one correct value for each input (and its augmentations).

I don't know what what the above means: What is a property? Why is it fragile? What is an augmentation? If you have any answers or know any links that discuss this issue, please let me know.

The typical Q-learning function approximator predicts (continuous) q-values, on which the agent acts ε greedy. In RL problems with discrete action spaces, is it wise to modify the Q-learning algorithm to directly predict actions instead of Q-values? Or should I stick with ε-maxing over ""unstable"" q-values? 

Anyway, even though regression may be less stable than classification, it seems to work anyway if we throw enough episodes at it :)

---

Post nap realization:

David Silver discusses 3 types of value function approximators [here](https://youtu.be/UoPei5o4fps?t=522):

1) Input is the state, output is the value function.

2) Input is the state and action, output is a q value.

3) Input is the state, output is the q value for every action.

All types could be interpreted as regression NNs. However, through a certain lens and also by using loose definitions, type 3 is a classification NN. When I speak about classification and regression NNs, here's what I have in mind:

* classification NNs typically have an output node for each class. The last layer's activation function is typically a softmax.

* regression NNs typically have one output node with no activation function, aka the linear activation function.

Value function approximators type 1 and 2 look like regression NNs. Type 3 looks kiiiiiinda like a classification NN. It has an output node for each action, and predicts q-values, which technically makes it a regression. But since the next step in the Q-learning algorithm is a ε greedy action, the *system* of the NN+ε greedy is choosing an action, this effectively makes it a classification style NN. It is classifying which action to take given the state.

Anyway, Silver says their DQNs use type 3 in solving the Atari problems, so I'll probably use that in my attempts to solve OpenAI's gyms. If anyone wants to criticize my realization here, please do so! I hardly consider this a closed issue.

---
---
---

# Links I've found discussing NN and regression problems

Many links seem to ignore or fail to mention the above advice from CS231n:

* https://www.reddit.com/r/learnmachinelearning/comments/7j2l4o/what_do_i_have_to_change_for_a_neural_network_to/

* https://www.quora.com/Can-Deep-Learning-and-Neural-Networks-be-useful-for-regression-problems-where-the-output-variable-has-an-unknown-or-varying-in-real-time-upper-bound

* https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/

* https://www.reddit.com/r/learnmachinelearning/comments/65sh1x/creating_a_deep_neural_network_regression_model/

* https://www.quora.com/Can-Deep-Learning-and-Neural-Networks-be-useful-for-regression-problems-where-the-output-variable-has-an-unknown-or-varying-in-real-time-upper-bound

In particular, the DQN implementations I've seen all predict Q-values and not actions (even if the action space is discrete), such as:

* https://jaromiru.com/2016/10/03/lets-make-a-dqn-implementation/

* https://github.com/dennybritz/reinforcement-learning/blob/master/DQN/Deep%20Q%20Learning%20Solution.ipynb"
75,learnmachinelearning,open-ai,top,2023-05-16 17:56:49,Datalab: A Linter for ML Datasets,jonas__m,False,0.92,40,13jc9v5,https://www.reddit.com/r/learnmachinelearning/comments/13jc9v5/datalab_a_linter_for_ml_datasets/,4,1684259809.0,"Hello Redditors!

I'm excited to share **Datalab** — a *linter* for datasets.

&#x200B;

[These real-world issues are automatically found by Datalab.](https://preview.redd.it/czbh8jfuc80b1.png?width=637&format=png&auto=webp&s=be8e27abdde9482d28a43b510707bed89cd4f998)

I recently published a [blog](https://cleanlab.ai/blog/datalab/) introducing **Datalab** and an [open-source](https://github.com/cleanlab/cleanlab) Python implementation that is easy-to-use for all data types (image, text, tabular, audio, etc). For data scientists, I’ve made a quick [Jupyter tutorial](https://docs.cleanlab.ai/stable/tutorials/datalab/datalab_quickstart.html) to run **Datalab** on your own data.

All of us that have dealt with real-world data know it’s full of various issues like label errors, outliers, (near) duplicates, drift, etc. One line of open-source code `datalab.find_issues()` automatically detects all of these issues.

In Software 2.0, data is the new code, models are the new compiler, and manually-defined data validation is the new unit test. **Datalab** combines any ML model with novel data quality algorithms to provide a *linter* for this Software 2.0 stack that automatically analyzes a dataset for “bugs”. Unlike *data validation*, which runs checks that you manually define via domain knowledge, Datalab adaptively checks for the issues that most commonly occur in real-world ML datasets without you having to specify their potential form. Whereas traditional dataset checks are based on simple statistics/histograms, Datalab’s checks consider all the pertinent information learned by your trained ML model.

Hope Datalab helps you automatically check your dataset for issues that may negatively impact subsequent modeling --- it's so easy to use you have no excuse not to 😛

Let me know your thoughts!"
76,learnmachinelearning,open-ai,top,2022-11-29 17:39:16,How To: Automatically Detect Annotation Errors in Image/Text Tagging Datasets,cmauck10,False,0.97,42,z80iww,https://www.reddit.com/r/learnmachinelearning/comments/z80iww/how_to_automatically_detect_annotation_errors_in/,0,1669743556.0,"Hey guys! Many of us in ML work with **multi-label data**, where the image or text is tagged with multiple labels. Often these datasets contain **frequent label errors** and/or **missing tags** (check what we found below in the CelebA dataset) that make it hard to train highly accurate ML models. Support for multi-label data was one of the top features requested — so we [added it](https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html), [benchmarked it](https://cleanlab.ai/blog/multilabel/), and published all of the [research](https://cleanlab.ai/blog/multilabel/).

[Find errors and missing labels in multi-label datasets.](https://preview.redd.it/av14p6ko7x2a1.png?width=1250&format=png&auto=webp&s=63f63bd93e4195e070e08a088cbc5c630c333430)

We are excited to share this newest research on algorithms to automatically find label errors in multi-label classification datasets.  Image/document tagging represents important instances of **multi-label classification** tasks, where each example can belong to multiple (or none) of K possible classes.  Because annotating such data requires many decisions for each example, often multi-label classification datasets contain tons of label errors, which harm the performance of ML models.

We’ve open-sourced our algorithms in the [recent release of cleanlab v2.2](https://github.com/cleanlab/cleanlab/releases/tag/v2.2.0). All you need to do to use them is write one line of open-source code via [cleanlab.filter.find\_label\_issues](https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html).

    from cleanlab.filter import find_label_issues
    
    ranked_label_issues = find_label_issues(
        labels=labels,
        pred_probs=pred_probs,
        multi_label=True,
        return_indices_ranked_by=""self_confidence"",
    )
    # labels: list of lists of (multiple) labels of each example
    # pred_probs: predicted class probabilities from any trained classifier

Running the new `find_label_issues()` function on the [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) image tagging dataset reveals around **30,000 mislabeled images**! Check out a few of them in the blog post!

Resources:

* Blog post: [https://cleanlab.ai/blog/multilabel/](https://cleanlab.ai/blog/multilabel/)
* Paper: [https://arxiv.org/abs/2211.13895](https://arxiv.org/abs/2211.13895)
* Tutorial: [https://docs.cleanlab.ai/stable/tutorials/multilabel\_classification.html](https://docs.cleanlab.ai/stable/tutorials/multilabel_classification.html)
* Benchmarks: [https://github.com/cleanlab/multilabel-error-detection-benchmarks](https://github.com/cleanlab/multilabel-error-detection-benchmarks)
* Code: [https://github.com/cleanlab/cleanlab](https://github.com/cleanlab/cleanlab)

Hope you find these practical tools useful in your real-world ML applications!"
77,learnmachinelearning,open-ai,top,2020-01-13 14:53:09,Reviews on top AI free courses that I've taken,alinrauta,False,0.97,42,eo53wd,https://www.reddit.com/r/learnmachinelearning/comments/eo53wd/reviews_on_top_ai_free_courses_that_ive_taken/,11,1578927189.0,"Last year I've decided to get past the artificial intelligence buzzwords from the media articles and really have a clue about the subject.

The more research I made the more I got intrigued and interested in AI. It baffled me how much AI will impact our lives and I realised this is the field I want to be in.

So, I began searching for learning resources and immersed myself into all kinds of AI related material. This was a normal thing to do since I taught myself how to code and I figured that I can also teach myself at least the basic of AI.

After a few months of taking courses, I will give you my opinion on the most useful free courses I have taken, the ones I'm in progress of finishing and as a bonus the ones I intend to take in the future.

## Courses I've taken

[Intro to Artificial Intelligence](https://classroom.udacity.com/courses/cs271) 

**About the course**   
It's a classic on AI and it happened to be the first course I've ever taken on the subject. It's a comprehensive course that gives you just the right amount of information about all the branches and sub-branches that AI is made of.

**About the teachers**   
The course is taught by two of the greatest advocates of AI:

* Sebastian Thrun: a former associate professor at Stanford University, co-founder of Udacity, led the team that won the 2005 DARPA Grand Challenge and co-developed Street View at Google.
* Peter Norvig: a director of research at Google and co-author of the leading college text in the field - Artificial Intelligence: A modern Approach

**Conclusion**   
I can't recommend it enough. It's definitely a must.

[Elements of AI](https://course.elementsofai.com/)   
**About the course**   
This is a text based course and the aspect I loved the most about it was the fact that it makes you ponder about the role artificial intelligence is going to have in your life. I like the structure of the course and how quickly you can check if you really understood something by taking a quiz.

**About the teachers**   
It's created by Reaktor and the University of Helsinki. It's part of an initiative that wants to encourage as broad a group of people as possible to learn about AI. The goal is to make the course available in all EU languages.

**Conclusion**   
It's a quick and engaging course to take to get the very basics on AI.

[Neural Networks and Deep Learning](https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning)   
**About the course**   
This one is a bit more advanced in terms of knowledge you gain after its completion and it's part of a series of courses on deep learning. I like the fact that it's not getting too technical and you can easily get to understand more advanced nuances tools that are being used in AI, more exactly - deep learning.

**About the teachers**   
The course is taught by the one and only Andrew Ng: co-founder of Coursera, Adjunct Professor at Stanford University and an outspoken AI advocate.

**Conclusion**   
It's the kind of course you need to take if you're serious about learning AI.

[Improving Deep Neural Networks](https://www.coursera.org/learn/deep-neural-network?specialization=deep-learning)   
**About the course**   
This is more of a sequel of the previous course and the purpose is to get your knowledge of deep learning one step further. This is where the magic happens in deep learning because it's more of an empirical process (trial and error) and you need to get a deeper (yeah, that's a pun) understanding before you know what parameters to tweak.

**About the teachers**   
The course is taught by the one and only Andrew Ng: co-founder of Coursera, Adjunct Professor at Stanford University and an outspoken AI advocate.

**Conclusion**   
You really need to take this course if you already had taken the previous one.

[Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning](https://www.coursera.org/learn/introduction-tensorflow)   
**About the course**   
TensorFlow is an open source platform for machine learning and this course is about teaching you how to use TensorFlow in your AI applications. As a coder I really enjoyed this course because it has less theory and more practice into it.

**About the teachers**   
The course is taught by Laurence Moroney who is an AI advocate at Google and also part of the TensorFlow team. For me, he is one of the best teachers I've ever seen.

**Conclusion**   
It's a friendly course for beginners and with lots of hands-on activities.

## In Progress

[Convolutional Neural Networks](https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning)   
**About the course**   
This course touches the concept of computer vision and builds on the knowledge acquired in the previous two courses from the [series](https://www.coursera.org/specializations/deep-learning). I can't wait to finish it and get more understanding of the computer vision field.

**About the teachers**   
The course is taught by the one and only Andrew Ng: co-founder of Coursera, Adjunct Professor at Stanford University and an outspoken AI advocate.

[Convolutional Neural Networks in TensorFlow](https://www.coursera.org/learn/convolutional-neural-networks-tensorflow)   
**About the course**   
This is a sequel of Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning course that I've already taken and things get even more practical in terms of coding which makes it highly appealing for coders.

**About the teachers**   
The course is taught by Laurence Moroney who is an AI advocate at Google and also part of the TensorFlow team. For me, he is one of the best teachers I've ever seen.

[Machine Learning](https://www.coursera.org/learn/machine-learning)   
**About the course**   
This is probably the reference course on Machine Learning. It's by far the longest and the most technical one from all the courses I've taken. I believe it's worth the effort of finishing the course if you are serious about getting a job in AI.

**About the teachers**   
The course is taught by the one and only Andrew Ng: co-founder of Coursera, Adjunct Professor at Stanford University and an outspoken AI advocate.

## Courses I intend to take (BONUS)

[Learn AI With An AI](https://korbit.ai/machinelearning)   
This seems really interesting and it's the next one on my list.

[Introduction to Computer Vision](https://classroom.udacity.com/courses/ud810)   
This course is a great companion for the Intro to Artificial Intelligence course and I hope it will broaden my knowledge on computer vision.

[Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/)   
This one puts more emphasis on the technical side and it's a good fit after you dabbled with TensorFlow.

[Intro to Data Science](https://www.udacity.com/course/intro-to-data-science--ud359)   
One of the most host jobs in the world right now is the Data Scientist, so I think it's really useful to have an idea about the field, which intersects with AI.

I hope these reviews will be useful for you and I can't wait to hear your feedback or the experiences you had with other AI courses.

If you liked this article and want to see more of these, then follow me on [twitter](https://twitter.com/RautaAlin)"
78,learnmachinelearning,open-ai,top,2023-11-23 10:24:00,"Nonfiction authors sue OpenAI, Microsoft for copyright infringement",anujtomar_17,False,0.84,40,181y9sl,https://newyorkverified.com/4324297-nonfiction-authors-sue-openai-microsoft-copyright-infringement/,34,1700735040.0,
79,learnmachinelearning,open-ai,top,2022-09-22 16:14:37,"Whisper, a general-purpose speech recognition model by OpenAI with Gradio Demo",Illustrious_Row_9971,False,0.91,36,xl5pky,https://i.redd.it/uc18wju5qfp91.png,3,1663863277.0,
80,learnmachinelearning,open-ai,top,2023-08-17 12:50:37,I'm trying to create a comprehensive table of the best AI tools to Increase Your Productivity + Automate Your Work- feel free to give some recs so I can add it to the list.,paulflythe,False,0.79,38,15tmnit,https://i.redd.it/sgcuo4o13oib1.png,19,1692276637.0,
81,learnmachinelearning,open-ai,top,2023-12-27 16:57:27,Staff Software Engineer in Bay with 10+ YOE. What’s the best way to learn AI/ML to maintain relevance?,SalamiJack,False,0.88,38,18s59ra,https://www.reddit.com/r/learnmachinelearning/comments/18s59ra/staff_software_engineer_in_bay_with_10_yoe_whats/,17,1703696247.0,"As the title stated, I am a staff software engineer at a large tech company in the Bay Area. My predominant expertise is backend distributed systems.

I work closely with ML and DS engineers, and I always feel out of my depth whenever specifics of our ML models are discussed. Given this and how the technological landscape is shifting so rapidly with AI, I want to do what I can to ensure I maintain relevance in my engineering career.

I don’t necessarily want to transition *now* away from a general backend focus to a ML or AI related role, but I want to set myself up with a deep foundational understanding so that I could easily transition if the need arises.

What is this community’s opinion on structured vs. unstructured learning? I am open to courses, certifications, or post-graduate degrees. I currently have a bachelor’s in CS from 10+ years ago, but my GPA was admittedly terrible, so I worry about my marketability for master’s programs.

Given my current job security, my primary focus is maximizing expertise, with a secondary focus on securing future job prospects."
82,learnmachinelearning,open-ai,top,2023-03-28 12:51:54,I am creating a tool that uses OpenAI models and an OCR to translate screenshots,K-RT-DEV,False,0.87,37,124nsy8,https://www.reddit.com/r/learnmachinelearning/comments/124nsy8/i_am_creating_a_tool_that_uses_openai_models_and/,15,1680007914.0,"Currently, the OCR is specifically for translating from Japanese, but I plan to add a range of OCRs and different translators to the system to accommodate the user's needs.  


https://i.redd.it/8ymk99uf8hqa1.gif

My idea is to have a system that leverages OpenAI models for *bagging*. This way, I can combine the output of multiple OCRs  to increase the accuracy of the recognized characters. Similarly, I can combine the output of multiple translators for the same phrase to improve the final result . Chat models can be particularly useful in providing **context** and a translation history to help the system understand how to conjugate phrases for translation.   


You can find the source code and an executable version on the [project's GitHub](https://github.com/K-RT-Dev/VGT)"
83,learnmachinelearning,open-ai,top,2022-02-03 18:39:05,[Project] Refining the Natural language processing course - Feedback v2 and thank you,sb2nov,False,0.91,37,sjqogi,https://www.reddit.com/r/learnmachinelearning/comments/sjqogi/project_refining_the_natural_language_processing/,2,1643913545.0,"I’m Sourabh, I lead one of the core Tensorflow teams at Google Brain and worked on data products at Coursera with Andrew Ng. Kaushik Rangadurai, ML Engineer at Facebook and I are leading a live, cohort based course on NLP starting March 14th. [https://corise.com/course/natural-language-processing](https://corise.com/course/natural-language-processing).

This is the second run of the class and we learned a lot from the feedback of the reddit community from the first run in November. Some of the changes we're making from the previous iteration:

1/ More focus on transformers and less on RNN/LSTM as hugging face is becoming the defacto for any nlp.

2/ Pytorch lightning has some really easy to use interfaces so better organizing the boiler plate code.

3/ OpenAI has opened the GPT-3 API so a deeper dive into current possibilities.

Would love to continue getting feedback and build this to be a great resource. The plan is to open the content after we refine it to a degree we're happy with. You can join the course (capped at about 30 students) at the link above. If you’re open to giving feedback on the class on how we can do better, happy to give a discount."
84,learnmachinelearning,open-ai,top,2023-06-02 17:41:02,Unlocking the availability and access to generative AI technologies with ubiquitous hardware and open software,ramyaravi19,False,0.91,36,13yjaa4,https://venturebeat.com/ai/unlocking-generative-ai-with-ubiquitous-hardware-and-open-software/,3,1685727662.0,
85,learnmachinelearning,open-ai,top,2023-03-31 06:20:23,LAION Launches Petition to Establish an International Publicly Funded Supercomputing Facility for Open Source Large-scale AI Research and its Safety,stringShuffle,False,1.0,36,127c7sb,https://www.reddit.com/r/learnmachinelearning/comments/127c7sb/laion_launches_petition_to_establish_an/,0,1680243623.0,"[https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety](https://www.openpetition.eu/petition/online/securing-our-digital-future-a-cern-for-open-source-large-scale-ai-research-and-its-safety)

>Join us in our urgent mission to democratize AI research by establishing an international, publicly funded supercomputing facility equipped with 100,000 state-of-the-art AI accelerators to train open source foundation models. This monumental initiative will secure our  technological independence, empower global innovation, and ensure safety, while safeguarding our democratic principles for generations to come."
86,learnmachinelearning,open-ai,top,2022-08-16 14:51:07,Hey learners! I am launching a new website to help people learn data science and machine learning,Tamock,False,0.91,35,wpwbgw,https://www.reddit.com/r/learnmachinelearning/comments/wpwbgw/hey_learners_i_am_launching_a_new_website_to_help/,6,1660661467.0,"Hey Reddit,

Here is [www.opencurricul.ai](www.opencurricul.ai), an opinionated, constantly evolving, organized curation of top resources in the form of a curriculum and a resource hub, for people whose goal is to become a data scientist. 

It not only covers all core aspects of data science, but also includes content on how to learn effectively, how to think about your career, mentions of influencers to follow, links to important books, articles, Youtube channels, etc. 

In addition, there is a roadmap in the curriculum page to show you what a path might look like.

We have a [Discord channel](https://discord.gg/cfgtzBwDXR) to encourage you to find study groups and partners to learn and collaborate together. Come join and introduce yourself. I talk and reply to everyone.

The website is fully open source and open to contributions. If you know of great resources and want to share them, just [create an issue](https://github.com/opencurriculai/data_science_curriculum/issues) on Github with a description of the content so I can audit it. I'd love to hear your suggestions.
  
I'll be working on a few projects to improve the website over the course of the next few months. Check the __/about__ section for more details. I am also going to lead a study group around math fundamentals with anyone interested in joining. 

If you're interested about helping or joining either, let me know, let's chat.

Here is the link to the curriculum: [www.opencurricul.ai/curriculum](http://www.opencurricul.ai/curriculum)

If you like the content, it would really help if you starred the repo on Github! 

Thanks!"
87,learnmachinelearning,open-ai,top,2022-02-22 11:53:19,"A guide on how to optimize your AI models before deploying them (a must!! → open-source, 5-10x faster inference)",emilec___,False,0.79,36,sylrvc,https://www.reddit.com/r/learnmachinelearning/comments/sylrvc/a_guide_on_how_to_optimize_your_ai_models_before/,8,1645530799.0,"Many people like me, and probably like you too, are getting better at building AI models. We spend tons of time creating and cleaning datasets and training models trying to improve performance by a tiny bit 😅 And at times, something good comes out of it. Cheers **🥳**🥂

But... the work is far from complete.

In fact, **model performance can be improved a lot (!!!) with the right coupling hardware-software**. Not in accuracy, but in computation time, which also means better AI services, less computation cost. Yet, many people like me, and maybe you too, know little about CPUs, GPUs, FPGAs, etc. and AI compilers and all that stuff.

This problem bothered me for a long time, so with a couple of buddies at [Nebuly](https://nebuly.ai/) (all ex MIT, ETH and EPFL), we put a lot of energy into an **open-source library** called **nebullvm** to make DL compiler technology accessible to any developer, even for those who know nothing about hardware, as I did.

How does it work? It **speeds up your DL models by \~5-20x** by testing the best DL compilers out there and selecting the optimal one to best couple your AI model with your machine (GPU, CPU, etc.). All this in just a few lines of code.

The library is open source and you can find it here [https://github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/nebullvm). You can find all the documentation there.

Please leave a star on GitHub for the hard work in building the library :) It's a simple act for you, a big smile for us. Thank you, and don't hesitate to contribute to the library!"
88,learnmachinelearning,open-ai,top,2022-06-08 09:37:52,"Just launched - nebulgym, a new open-source that accelerates AI training (~1.5-2x as of now) in a few lines of code without requiring you to change your training setup",emilec___,False,0.91,34,v7ll3p,https://www.reddit.com/r/learnmachinelearning/comments/v7ll3p/just_launched_nebulgym_a_new_opensource_that/,4,1654681072.0,"Training always takes too long. If it takes an hour, it would be better if it took 30 minutes, or maybe 15 minutes... or just 1 minute, why not? And if you want to speed up training, the techs available usually require to increase the complexity of the training process, whether it's making trade-off in terms of accuracy or time for the developer to learn a new framework. Often times it's trial and error, playing with parameters, training recipes, or switching framework/model. That's definitely not ideal.

“Fast & easy-to-use” These were keywords that motivated me to work on a new way of doing training, the library `nebulgym`, which now is open-source ([github link](https://github.com/nebuly-ai/nebulgym)).

**Fast**

Training should be fast, period. Wouldn't it be great if in the near future you could train a GPT3 from scratch on your laptop? Or a large EfficientNet in a fraction of a minute? Nebulgym was built to try to bring developers closer to that future. This open-source optimizes the full training computation stack, from efficient data loading to faster forward and backward passes and earlier convergence. For example, by saving data samples in the cache on the first data read, it speeds up the full data loading process and eliminates what can become the bottleneck for the training process. Nebulgym also leverages techniques such as partial compilation of some calculations and smart sparse gradients to speed up forward and backward gradient propagations. And many more features will be implemented soon. And please let me know / open issues if you have ideas for making nebulgym even faster :)

**Easy-to-use**

""Not another framework, please, there're already 1000"". That's a call for help from many developers, so nebulgym has been developed with this in mind. Nebulgym let you use the training setup you've always used, and works ""on top"". This is made possible with the use of class decorators (like Java's annotations). In short, you can just add these decorators before defining the model classes, and nebulgym will make sure that you use your computing resources to the fullest.

Here's a snippet of training with nebulgym decorators (`@accelerate_dataset` and `@accelerate_model`)

```
import torch
from nebulgym.decorators.torch_decorators import accelerate_model, accelerate_dataset

@accelerate_dataset()
class MyDataset(torch.utils.data.Dataset):
   # Your Dataset definition

@accelerate_model()
class MyModel(torch.nn.Module):
   # Your model definition

# Train your model as you usually do
```

And that's it. Give it a try, and leave a star ⭐, it's a little contribution to show some love for open-source projects :) Also feedback would be super appreciated!

[https://github.com/nebuly-ai/nebulgym](https://github.com/nebuly-ai/nebulgym)"
89,learnmachinelearning,open-ai,top,2022-06-29 03:57:49,Open source that takes as input a deep learning model and outputs a version that runs faster in inference. Now faster and easier to use (New release),emilec___,False,0.92,34,vn6chm,https://www.reddit.com/r/learnmachinelearning/comments/vn6chm/open_source_that_takes_as_input_a_deep_learning/,10,1656475069.0,"nebullvm is an open-source library that takes an AI model as input and outputs an optimized version that runs much faster on your hardware, **usually achieving 2 to 5 times faster inference** **without losing accuracy** (benchmarks below for Option A), or even more if you specify that you are willing to sacrifice some accuracy for a lighter model with even lower latency, using compression techniques (Option B, leveraging multiple quantization methods \[1\], soon also pruning \[2\] and more)

[https://github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/nebullvm)

nebullvm now supports also PyTorch and TensorFlow backends that, together with the already supported deep learning compilers (including ONNX runtime \[3\], TensorRT \[4\], OpenVINO \[5\], Apache TVM \[6\]), will **optimize how your model is mapped to your hardware**. Together these techniques will allow nebullvm to explore more paths and find the best way to make the most of your hardware's computing capabilities, making inference as fast as it can run.

**You can run nebullvm in just a few lines of code**, and after many requests from users, I simplified the installation of these deep learning compilers. In addition to the option of installing all compilers with a single command, it is now possible to **skip the installation to pull Docker images with compilers already preinstalled**. Discover more [here](https://github.com/nebuly-ai/nebullvm#download-docker-images-with-preinstalled-compilers).

Many more releases are on the way. And if you have questions, ideas and product suggestions, I'm more than happy to discuss them here! And don't forget to leave a small star for all the open-source work to make DL optimization techniques more accessible :)

https://preview.redd.it/pz70l50ahh891.png?width=1480&format=png&auto=webp&s=14c21bfb2a06372451ddce2cc1b1b72226d8b795

\[[1](https://github.com/nebuly-ai/learning-AI-optimization/blob/main/Quantization.md)\] Quantization. Techniques and Concept Map. \[[2](https://github.com/nebuly-ai/learning-AI-optimization/blob/main/Pruning.md)\] Pruning. Techniques and Concept Map. \[[3](https://onnxruntime.ai/)\] ONNX Runtime \[[4](https://developer.nvidia.com/tensorrt#:~:text=TensorRT%2C%20built%20on%20the%20NVIDIA,high%20performance%20computing%2C%20and%20graphics.)\] Nvidia TensorRT \[[5](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)\] Intel OpenVINO \[[6](https://tvm.apache.org/)\] Apache TVM"
90,learnmachinelearning,open-ai,top,2023-02-12 03:54:05,[N] All of this you need to know happening in ML/AI.,Opening-Ad-8849,False,0.78,32,1106e9p,https://www.reddit.com/r/learnmachinelearning/comments/1106e9p/n_all_of_this_you_need_to_know_happening_in_mlai/,0,1676174045.0,"Hello humans - This is AI Daily by Ovetted, helping you stay updated on AI in less than 5 minutes.

Originally published on [https://www.ovetted.com/ai](https://www.ovetted.com/ai).

### What’s happening in AI -

[**The AI doctor will see you now: ChatGPT passes the gold-standard US medical exam.**](https://www.dailymail.co.uk/health/article-11732687/The-AI-doctor-ChatGPT-passes-gold-standard-medical-exam.html)

ChatGPT has passed the gold-standard exam required to practice medicine in the US

The artificial intelligence program scored 52.4 and 75 percent across the three-part Medical Licensing Exam (USMLE).

[**Google and Microsoft announced plans to incorporate AI into search engines.**](https://youtu.be/EBDJ9MGSV6k)

Google and Microsoft plan to incorporate AI into their search engines to change how people use the internet. Microsoft has announced that AI will soon allow conversations with its software and search engine Bing, while Google has announced similar plans.

As the most profitable software business is searching both companies are trying to take advantage of AI to rule the search engine market. 

[**Integrating the generative AI means a fivefold increase in Computing power & carbon emission.**](https://www.wired.com/story/the-generative-ai-search-race-has-a-dirty-secret/)

The integration of artificial intelligence (AI) into search engines could lead to a significant increase in the amount of energy that tech companies require and the amount of carbon they emit.

Training these models takes a huge amount of computational power, but only big tech companies can do so because they have the resources.

### Snippets -

**Human & AI:** How Will [Humans and A.I](https://www.nytimes.com/2023/02/10/opinion/letters/artificial-intelligence.html?smid=url-share). Get Along?

**OpenAI in office apps:** Microsoft Has Plans to Shove Its Bing AI Into [Word, PowerPoint, and More](https://gizmodo.com/microsoft-bing-ai-powerpoint-word-prometheus-1850098510). 

**WTF:** This AI Image Fooled Judges and [Won](https://petapixel.com/2023/02/10/ai-image-fools-judges-and-wins-photography-contest/) a Photography Contest.

**Hype:** Why the ChatGPT AI Chatbot Is [Blowing](https://www.cnet.com/tech/computing/why-the-chatgpt-ai-chatbot-is-blowing-everybodys-mind/) Everybody's Mind.

**Oops:** New AI voice-cloning tools 'add fuel' to [misinformation](https://abcnews.go.com/US/wireStory/new-ai-voice-cloning-tools-add-fuel-misinformation-97046760) fire.

**Oh no:** [Microsoft](https://www.businessinsider.com/microsoft-layoffs-cloud-ai-artificial-intelligence-2023-2?IR=T) is even cutting cloud and AI workers in its plan to lay off 10,000 employees.

**Wow:** AI In 2023 And [Beyond](https://www.forbes.com/sites/forbestechcouncil/2023/02/10/ai-in-2023-and-beyond-the-top-research-and-development-trends-to-keep-an-eye-on/?sh=5e2a45a7deae): The Top Research And Development Trends To Keep An Eye On.

**Realistic** newscasts feature AI-generated [anchors](https://edition.cnn.com/videos/business/2023/02/11/deepfake-newscast-ai-chinese-messaging-wang-pkg-ac360-vpx.cnn) disparaging the US.

**Google** cautions against '[hallucinating](https://www.reuters.com/technology/google-cautions-against-hallucinating-chatbots-report-2023-02-11/)' chatbots.

### Things to try -

* Someone made a **Discord bot** that can **write** **poems, descriptions, and titles on the image you provide**. Using GPT3 & CLIP. - [Try now](https://discord.gg/m4taXd6AB3)
* **Lalal AI** can **extract vocal accompaniment and other instruments** from any audio or video. - [Try now](https://www.lalal.ai/)
* What if you can create your own ChatGPT? well, you can make your own chatbot with your own data by using **customGPT**. - [Try now](https://customgpt.ai/)
* Do you create content for websites or any kind of digital content? Well, **metagenie** can help you to create **metadata like Titles, Descriptions, Tags, and Thumbnail Ideas.** \- [Try now](https://www.metagenieai.com/)
* **Snape** is here to help you write your custom job description generator. - [Try now](https://snape.springworks.in/)
* Give a try to this AI food robot that gives you **food pictures and recipes generated by AI. -** [Try now](https://aifoodrobot.com/)
* Need a **coding assistant** try spell box. That uses artificial intelligence to create the code you need from simple prompts. - [Try now](https://spellbox.app/)"
91,learnmachinelearning,open-ai,top,2017-08-19 21:47:27,Building Your First Neural Network Tutorial,ejmejm1,False,0.98,33,6urtd3,https://www.reddit.com/r/learnmachinelearning/comments/6urtd3/building_your_first_neural_network_tutorial/,1,1503179247.0,"I've been working on a [series teaching deep learning](https://youtu.be/g5n4BVNdxK8?list=PL_49VD9KwQ_NFnA6egEPs4UiM6P3pp0hS), particularly how neural networks work and how to create one on Youtube that can be found [here](https://youtu.be/g5n4BVNdxK8?list=PL_49VD9KwQ_NFnA6egEPs4UiM6P3pp0hS)

I've finished going over some basics and I can't decide on where to go next. I was thinking of going into a project, like making a Go bot, Open AI Gym projects, a StarCraft II bot or something of the sort. I could also do general concepts like reinforcement learning, ect.

Any thoughts on what would be most helpful or what you would like to see?"
92,learnmachinelearning,open-ai,top,2023-10-09 21:43:30,How feasible is it to train AI on an existing game? Or is there a basis for training AI on an existing game?,Ok-Instruction-8624,False,0.92,30,1743xhj,https://www.reddit.com/r/learnmachinelearning/comments/1743xhj/how_feasible_is_it_to_train_ai_on_an_existing/,16,1696887810.0,"I'm an undergrad student but have very little experience with machine learning. I'm fond of online fighting games, but noticed that many smaller games do not have AI/singleplayer modes. Some are open source, so I was wondering if I could mod one to set up an environment to try training AI. It's more for fun than something realistic. A long time ago, I set one up with an AI that would only do random moves, but did not get much farther before life made me take a break. I still have the code and my notes about getting specific data/triggering moves/how the game works. It would be the ideal one to start with, and is a smaller 2d fighting game with very simple graphics. However, I want to make sure its even feasible before attempting to create a machine learning environment.

My main worry is that using an existing game to train would be too resource intensive or would take too much time due to game code generally being complicated compared to other tasks. While I know it varies based on game specs/computer specs, I was curious if there was any basis for people using a game to train AI without building the game from the ground up. Are there any good guidelines I could check to see if a game is simple enough for training, or am I almost always better off recreating a game from the ground up to reduce resource use? "
93,learnmachinelearning,open-ai,top,2022-07-04 23:32:55,Trying to get my computer set up for ML,LoveLaika237,False,1.0,30,vrkdhh,https://www.reddit.com/r/learnmachinelearning/comments/vrkdhh/trying_to_get_my_computer_set_up_for_ml/,12,1656977575.0,"Hi, sorry, I'm not sure if this question is totally appropriate here, but since it is related to machine learning, I thought to ask here. I don't really have anywhere else to turn to. As a beginner to machine learning, I'm trying to get my environment set up for [TensorFlow](https://docs.microsoft.com/en-us/windows/ai/directml/gpu-tensorflow-wsl) and [PyTorch](https://docs.microsoft.com/en-us/windows/ai/directml/gpu-pytorch-wsl) following these sets of instructions. For this, I'm running a WSL2 Ubuntu distribution using Intel graphics (not an external GPU), but I'm having trouble getting it set up. Following the instructions got me the results shown below when trying to verify each installation.

* Tensorflow Verification Code

&#8203;

    import tensorflow.compat.v1 as tf
    tf.enable_eager_execution(tf.ConfigProto(log_device_placement=True))
    print(tf.add([1.0, 2.0], [3.0, 4.0]))

* Tensorflow Results

&#8203;

    I tensorflow/stream_executor/platform/default/dso_loader.cc:97] Successfully opened dynamic library libdirectml.0de2b4431c6572ee74152a7ee0cd3fb1534e4a95.so
    
    I tensorflow/stream_executor/platform/default/dso_loader.cc:97] Successfully opened dynamic library libdxcore.so
    
    I tensorflow/core/common_runtime/dml/dml_device_cache.cc:250] DirectML device enumeration: found 0 compatible adapters.
    
    I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
    2022-07-04 16:55:36.133454: I tensorflow/core/common_runtime/eager/execute.cc:571] 
    
    Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0
    tf.Tensor([4. 6.], shape=(2,), dtype=float32)

* PyTorch Verification Code

&#8203;

    import torch
    tensor1 = torch.tensor([1]).to(""dml"")
    tensor2 = torch.tensor([2]).to(""dml"")
    dml_algebra = tensor1 + tensor2
    dml_algebra.item()

* PyTorch Results

&#8203;

    Segmentation Fault at tensor1 = torch.tensor([1]).to(""dml"")

It seems that with TensorFlow, maybe my computer isn't suitable for it given the results. Is this correct? With PyTorch, it's odd that it seg faulted on such a simple verification run. Could there be something strange about running PyTorch on WSL2? Would it be better to run this on Windows instead?"
94,learnmachinelearning,open-ai,top,2018-06-13 15:25:24,Learning how to implement Q-Learning in Python and training with OpenAi Gym,brendanmartin,False,0.96,29,8qta4p,https://www.reddit.com/r/learnmachinelearning/comments/8qta4p/learning_how_to_implement_qlearning_in_python_and/,5,1528903524.0,"/u/satwik_ and I wrote an article about Reinforcement Q-Learning in Python and would love to answer any questions for anyone that's interested in learning how to apply Q-Learning to a project.

Article: https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/"
95,learnmachinelearning,open-ai,top,2022-04-08 12:07:15,I made a list of Data Science blogs/communities/influencers to stay updated on the latest trends,bornot2b,False,0.94,30,tz21v1,https://www.reddit.com/r/learnmachinelearning/comments/tz21v1/i_made_a_list_of_data_science/,6,1649419635.0,"I made a list of popular blogs, communities, and influencers that periodically publish posts with the latest trends about Data Science. I hope it can be useful to someone!

# Medium Publications

* [Towards Data Science](https://towardsdatascience.com/)
* [Analytics Vidhya](https://medium.com/analytics-vidhya)
* [SyncedReview](https://medium.com/syncedreview)
* [Inside Machine learning](https://medium.com/inside-machine-learning)
* [ML Review](https://blog.mlreview.com/)
* [TensorFlow](https://medium.com/tensorflow)
* [Emergent // Future](https://medium.com/emergent-future)
* [learn data science](https://blog.exploratory.io/)
* [Dunder Data](https://medium.com/dunder-data)
* [MLearning.ai](https://medium.com/mlearning-ai)
* [NanoNets](https://medium.com/nanonets)
* [DataThings](https://medium.com/datathings)
* [ActiveWizards — AI & ML for startups](https://medium.com/activewizards-machine-learning-company)
* [Data Notes](https://data-notes.co/)
* [Sicara's blog](https://medium.com/sicara)
* [Data Visualization Weekly](https://medium.com/data-visualization-weekly)
* [Data & Society: Points](https://points.datasociety.net/)
* [AR & VR in the classroom](https://blog.cospaces.io/)
* [Quick Code](https://medium.com/quick-code)

# Medium Authors

* [Susan Li](https://medium.com/@actsusanli)
* [ODSC - Open Data Science](https://medium.com/@odsc)
* [Favio Vázquez](https://medium.com/@faviovazquez)
* [Igor Bobriakov](https://medium.com/@ibobriakov)
* [Matthew Stewart, PhD Researcher](https://medium.com/@matthew_stewart)
* [Lily Chen](https://medium.com/@lilychencodes)
* [TensorFlow](https://medium.com/@tensorflow)
* [Will Koehrsen](https://medium.com/@williamkoehrsen)
* [Ben Rogojan](https://medium.com/@SeattleDataGuy)
* [Parul Pandey](https://medium.com/@pandeyparul)
* [plotly](https://medium.com/@plotlygraphs)
* [Dimitris Poulopoulos](https://medium.com/@dpoulopoulos)
* [Adam Geitgey](https://medium.com/@ageitgey)
* [Michael Galarnyk](https://medium.com/@GalarnykMichael)
* [Khuyen Tran](https://medium.com/@khuyentran1476)
* [Devin Soni](https://medium.com/@devins)
* [David Venturi](https://medium.com/@davidventuri)

# Subreddits

* [r/datascience](https://www.reddit.com/r/datascience/)
* [r/learnmachinelearning](https://www.reddit.com/r/learnmachinelearning/)
* [r/algorithms](https://www.reddit.com/r/algorithms/)
* [r/analytics](https://www.reddit.com/r/analytics/)

# Discord Servers

* [Learn AI Together](https://discord.gg/learnaitogether)
* [MLSpace: The Machine Learning Community](https://discord.com/invite/4RMwz64gdH)
* [Data Science/ML/AI](https://discord.com/invite/EdP8QVz)
* [Code Bullet and Co](https://discord.gg/codebullet)
* [AI Multiverse](https://discord.com/invite/puRyrw869h)

# Twitter Accounts

* [Kirk Borne](https://twitter.com/KirkDBorne)
* [Machine Learning](https://twitter.com/machinelearnflx)
* [Data Science Dojo](https://twitter.com/DataScienceDojo)
* [Mike Tamir, PhD](https://twitter.com/MikeTamir)
* [scikit-learn](https://twitter.com/scikit_learn)
* [KDnuggets](https://twitter.com/kdnuggets)
* [MIT CSAIL](https://twitter.com/MIT_CSAIL)
* [Kosta Derpanis](https://twitter.com/CSProfKGD)
* [Dr. Ganapathi Pulipaka](https://twitter.com/gp_pulipaka)
* [AI](https://twitter.com/DeepLearn007)
* [Sreenivas Bhattiprolu](https://twitter.com/digitalsreeni)

# YouTube

* [DigitalSreeni](https://www.youtube.com/c/digitalsreeni)

I've also collected the number of followers of all of these blogs/communities/influencers, along with their descriptions and latest posts so that you can get an idea of ​​their contents with a quick glance, which you can find in this [blog post](https://blog.bloghound.social/popular-communities-and-influencers-about-data-science-april-2022/)."
96,learnmachinelearning,open-ai,top,2022-09-26 06:48:01,Is CUDA / NVIDIA still required for modern day machine learning?,nxtfari,False,0.93,27,xobnhm,https://www.reddit.com/r/learnmachinelearning/comments/xobnhm/is_cuda_nvidia_still_required_for_modern_day/,14,1664174881.0,"Hey all!

I was up to date with SOTA ML/AI up until maybe about 2019, when I switched tracks into embedded CS for a while. I'm now trying to get back into ML and looking for a Linux machine to learn and do small-time training on.

Even back in 2019, I know Colab / Paperspace was an option, but I really just personally learn better when my code is running on my machine and I can debug problems then and there. The only thing is: back then, I had a machine with an AMD GPU, and remember being so frustrated that it seemed like half of all ML tools required CUDA to even work, with no option for OpenGL or even CPU based calculation. So I was wondering: is that still true? I'm primarily interested in computer vision depth estimation, localization, mapping, and reinforcement learning. How is it out there if you don't have an NVIDIA GPU?

All input is appreciated!"
97,learnmachinelearning,open-ai,top,2022-10-03 22:32:08,"Hi everyone! I'm Piotr and for several years I have been developing a small open-source project for labeling photos - makesense.ai. Now, you can use YOLOv5 models to automatically annotate photos. Take a look!",RandomForests92,False,0.94,27,xuxkqg,https://v.redd.it/l03d6sne3or91,7,1664836328.0,
98,learnmachinelearning,open-ai,top,2023-05-29 17:37:32,"GPT Weekly - 29th May Edition: Facebook's massive STT and TTS Release, AI in Windows, Paralegal jobs are here to stay and more.",level6-killjoy,False,0.82,25,13v1asb,https://www.reddit.com/r/learnmachinelearning/comments/13v1asb/gpt_weekly_29th_may_edition_facebooks_massive_stt/,2,1685381852.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 AI news in the past week
* 🗞️10 AI news highlights and interesting reads
* 🧑‍🎓3 Learning Resources

# 🔥Top 3 AI news in the past week

## 1. Expanding Language Horizons

Facebook has [released an open source model called MMS (Massively Multilingual Search)](https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/) for STT (speech to text), TTS (text to speech) and language identification. 

This is a big breakthrough. Currently, STT and TTS models recognize only 100 languages. With this the technology has been expanded to 1100 languages. That is 10x the current best. 

Additionally, these models can recognize 4000+ languages. 

As per Facebook, they also have half the error rate of OpenAI’s Whisper.

These guys are on a roll.

## 2. Bing Chat Enters the OS

After [Google’s announcement](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin), it was time for Microsoft to announce AI products. Here’s a rundown of what was announced during Microsoft Build:

1. **Windows Copilot**  \- Microsoft is integrating AI directly into the OS. Now you can do everything you could do with Bing Chat but now on the OS. You can do the usual stuff - summarize emails, documents, re-write etc. But it goes beyond that by integrating into the installed applications.

Microsoft is also adopting OpenAI's plugin model. So, **you can use ChatGPT and Bing plugins to interact with the integrated AI.** 

The great thing about it is the direct integration into the OS. Eat your heart out, Mac users – at least for now 😀. Until Apple announces something similar. And someone will come up with an alternative solution. Especially, because of the privacy concerns with Microsoft telemetry. 

The bad thing is - [the security aspect of the plugins](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). It can open a whole new attack vector on the OS and antivirus softwares might struggle with it. 

It also might be the second nail in the coffin for all the summarize, “talk to your document” apps. Once, this feature is integrated with [Google Docs](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and Microsoft Office - why will you want to pay for extra apps?

1. **Search comes to ChatGPT**  \- Looks like OpenAI had enough of the testing and new features are being rolled out [left](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and [right](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). 

No prizes for guessing the search engine behind it. Ding, Ding, Ding..It’s Bing!

1. **Co-Pilot in PowerPages** \- Microsoft is now adding AI to their [PowerPages platform](https://powerpages.microsoft.com/en-in/), their low-code tool to build websites. It’ll help users to generate text, forms etc.
2. **Microsoft Fabric** \- A new data analytics platform built on top of Azure Data lake but can get data from S3, Google cloud etc. It can help users build pipelines, write code, and build ML models.

## 3. From Trusted Advisor to Nightmare: The Hazards of Depending on AI

Here’s a [fun story which is breaking out on Legal twitter](https://www.nytimes.com/2023/05/27/nyregion/avianca-airline-lawsuit-chatgpt.html). 

A man filed a personal injury lawsuit against Avianca airlines. Avianca's lawyers wasted no time and requested the judge to dismiss the case. The man's lawyer had a different plan in mind. He submitted a document citing half a dozen cases that bolstered his client's claims.

Here's the twist—the judge and Avianca's lawyer couldn't locate any of the referenced cases. Quite a conundrum, right? The lawyer was then asked to provide copies of these elusive cases. The lawyer submitted screenshots as evidence, taking extra precautions to ensure their authenticity. 

You already know the direction this story is taking. 

The lawyer had used ChatGPT to compose his brief. But little did he know that ChatGPT had supplied him with fake cases.

When asked to file tangible copies of these cases, the lawyer turned to ChatGPT once again. ChatGPT had reassured him that the cases were genuine. Feeling emboldened, the lawyer used ChatGPT to provide the requested copies. He even went as far as incorporating chat screenshots into a legal document.

The lawyer maintains that it was never his intention to deceive the court. He expressed regret for relying on ChatGPT for their research. Unfortunately, the judge isn't pleased with this turn of events. The judge has threatened sanctions against both the lawyer and his firm.

It serves as a stark reminder of how ChatGPT has fooled many people. There is a clear warning stating that ChatGPT may produce inaccurate information. But many tend to overlook these warnings. Even legal professionals!!

This story carries significant importance for those who fear job insecurity. The lawyer and his firm could have prevented the entire debacle. They should've used paralegal services. They instead relied on ChatGPT's. It's a hard lesson learned the hard way.

My sincere hope is that this story serves as a valuable lesson. It helps people avoid making similar mistakes. The legal community might become apprehensive about ChatGPT's use moving forward.

# 🗞️10 AI news highlights and interesting reads

1. [OpenAI says in 10 years AI could be as productive as one of today’s large corporations](https://openai.com/blog/governance-of-superintelligence). This poses an existential risk and they suggest some regulations to manage it. This poses an existential risk and they suggest some regulations to manage it. To achieve this, countries need to form something like the [IAEA](https://en.wikipedia.org/wiki/International_Atomic_Energy_Agency). The IAEA is an intergovernmental agency under the UN to oversee nuclear energy. This “AI agency” will monitor the AI systems and conduct inspections. Just like nuclear energy is tracked through signatures, they suggest using compute and energy usage to track systems.
2. In the meantime, [Google is working on voluntary rules](https://techcrunch.com/2023/05/24/eu-google-ai-pact/) until there are some real regulations in place. 
3. [As per Pew Research, 58% of Americans have heard of ChatGPT. Even less - 14% have tried ChatGPT. ](https://www.pewresearch.org/short-reads/2023/05/24/a-majority-of-americans-have-heard-of-chatgpt-but-few-have-tried-it-themselves/)
4. Sharing prompts and results has been a pain. Taking screenshots is one way. But then everyone has to type in the prompts manually. Or you can share as plain text. But ChatGPT results are non-deterministic. So, the results might not be the same. Even the lawyer above would’ve loved this feature. Now you will be able to [share your ChatGPT conversations publicly](https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq).
5. LLM Agents and plugins need to connect to tools to perform the tasks outside the LLM environment. So, it is important for the LLM to know which API to call and pass correct arguments. [Gorilla is a fine-tuned Llama-model which can generate the correct call and arguments](https://gorilla.cs.berkeley.edu/). 
6. If you are trying to build something beyond a document summarizer or a wrapper around GPT4 API, [things can be hard](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm). Finding the correct context window, dealing with slow responses (I am looking at you GPT-4) etc are some of the problems. 
7. [The AI boom could expose investors’ natural stupidity](https://www.reuters.com/breakingviews/ai-boom-could-expose-investors-natural-stupidity-2023-05-19/). 
8. [Chatbot leaderboard for the week](https://lmsys.org/blog/2023-05-25-leaderboard/). GPT-4 is still ahead.
9. [Google’s flood warning system is now available in 80 countries. ](https://blog.google/outreach-initiatives/sustainability/flood-hub-ai-flood-forecasting-more-countries/)
10. [GPT detectors are biased against non-native English writers](https://arxiv.org/abs/2304.02819)

# 🧑‍🎓3 Learning Resources

1. [Build a product using Replit+AI](https://www.priyaa.me/blog/building-with-ai-replit). The author is a non-technical person who won a hackathon competing with engineers. 
2. [LangChain 101](https://replit.com/@MckayWrigley). 
3. [NLP Course from HuggingFace](https://huggingface.co/learn/nlp-course/chapter0/1)

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
99,learnmachinelearning,open-ai,top,2023-08-02 18:21:44,A Brief History of Natural Language Generation [Timeline] —Thoughts? Corrections? Suggestions? Thanks!,Britney-Ramona,False,0.85,27,15ggib0,https://i.redd.it/meslnx7moqfb1.png,8,1691000504.0,
100,learnmachinelearning,open-ai,comments,2023-02-08 01:39:15,Master's Degree in ML/AI worth it in 2023?,TheOnlyAuthority,False,0.93,97,10wjo7e,https://www.reddit.com/r/learnmachinelearning/comments/10wjo7e/masters_degree_in_mlai_worth_it_in_2023/,172,1675820355.0,"I know there are similar/exact questions all over Reddit, but they all seem to be a little dated and the ones with the most activity seems to be from at least a few years ago. I was wondering if a Master's in ML/AI still worth it in 2023.

Also, what other CS related masters degrees do you think would be valubale or considered as highly preferred for a candidate to have to work in a certain field?

Sorry, the second part is more of a broad question for this subreddit!

Edit: Just adding that I'm currently working as Software Engineer and my company would bear part of the tuition cost. But I still want it to be worth my time and effort as well. If there is a better engineering master's choice, I'd like to pursue that. Strong bias for something within engineering, but open to other also."
101,learnmachinelearning,open-ai,comments,2020-05-16 08:13:15,Free zoom lecture about advances in deep learning and 3D modeling for reddit community,pinter69,False,0.97,272,gkr44a,https://www.reddit.com/r/learnmachinelearning/comments/gkr44a/free_zoom_lecture_about_advances_in_deep_learning/,147,1589616795.0,"Hi all,

I work with machine learning and 3D modeling (you can checkout my profile info). I have a cool lecture about the advances in Academia in automatic 3D modeling, the lecture is called ""From 2D to 3D with AI"". I usually teach it at conferences and machine learning courses. Now because of Corona, there is less teaching, so I thought of offering it to the community here :) If there will be 20+ redditors who are interested in the lecture we will make it happen. Feel free to DM me, or leave your info here and we will take it from there.

&#x200B;

\[Edited\]

Hey all, since I see there is a lot of interest already, please fill-out the form so that I would know how to prepare the lecture and at what time: [https://forms.gle/wSXexXSBj5e5267G8](https://forms.gle/wSXexXSBj5e5267G8)

There is no need to comment anymore or dm me, it is just filling out my inbox lol

&#x200B;

\[Edited 2\]

Well, this is kind of amazing, I was expecting for 20-50 people maximum, there are currently 232 people registered from literally all over the world. I will probably need to start a group somewhere to manage this. There might be several lectures for different technical backgrounds and time zones. I am still thinking of the best approach. Will send updates via email once the plan is set.

In the meantime, still accepting registration, so fill free to fill the form with your details to stay in the loop.

&#x200B;

\[Edited 3\]

So, following this amazing and unexpected turn, 329 people registered (!!!) from all over the world. This is too many people for one zoom event :P

I have opened a sub-reddit manage all event details and share all the information. In this sub everyone can also discuss about anything regarding image processing, 3D modelling and AI:

[https://www.reddit.com/r/2D3DAI/](https://www.reddit.com/r/2D3DAI/)

Currently there are two events scheduled, one for the eastern hemisphere and one for the western - they are stickied so you can easily find them. I will do the same lecture twice so that people from different timezones could participate, since we truly have people from all over the world :) This lecture will not require technical background in the field.

For the more technically advanced people (almost half the registered have DL background) - we will probably have another set of 2 lectures. I just want to start this first round, see how it goes and take it from there.

Seeing this amazing interest from people, I have started putting into plan more free lectures in deep learning on other subjects from other guest lecturers. We will take it a step at a time. All info will be shared in /r/2D3DAI and probably also in this subreddit.

Regarding recording the event and putting it on youtube - It will definitely be recorded, if I see that the quality is good, I will also publish it online. Will update in the new subreddit (and via email to those who registered).

Let's do this 🚀🚀

&#x200B;

\[Edited 4\]

Since there is more growing interest and people who might be interested in other talks, feel free to leave your info the the google form above ([https://forms.gle/wSXexXSBj5e5267G8](https://forms.gle/wSXexXSBj5e5267G8)) and I will send out an update via email when more free lectures in similar topics are scheduled."
102,learnmachinelearning,open-ai,comments,2023-05-11 00:54:18,What do actual ML engineers think of ChatGPT?,PhillConners,False,0.96,152,13e8of2,https://www.reddit.com/r/learnmachinelearning/comments/13e8of2/what_do_actual_ml_engineers_think_of_chatgpt/,106,1683766458.0,"You have been doing this for awhile, now the world is obsessed with OpenAI and suddenly all full of AI “experts”."
103,learnmachinelearning,open-ai,comments,2023-06-28 12:29:48,"Intern tasked to make a ""local"" version of chatGPT for my work",Assasinshock,False,0.97,152,14l887h,https://www.reddit.com/r/learnmachinelearning/comments/14l887h/intern_tasked_to_make_a_local_version_of_chatgpt/,104,1687955388.0,"Hi everyone,

I'm currently an intern at a company, and my mission is to make a proof of concept of an conversational AI for the company.They told me that the AI needs to be trained already but still able to get trained on the documents of the company, the AI needs to be open-source and needs to run locally so no cloud solution.

The AI should be able to answers questions related to the company, and tell the user which documents are pertained to their question, and also tell them which departement to contact to access those files.

For this they have a PC with an I7 8700K, 128Gb of DDR4 RAM and an Nvidia A2.

I already did some research and found some solution like localGPT and local LLM like vicuna etc, which could be usefull, but i'm really lost on how i should proceed with this task. (especially on how to train those model)

That's why i hope you guys can help me figure it out. If you have more questions or need other details don't hesitate to ask.

Thank you.  


Edit : They don't want me to make something like chatGPT, they know that it's impossible. They want a prototype that can answer question about their past project. "
104,learnmachinelearning,open-ai,comments,2023-01-10 11:12:01,Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI,BackgroundResult,False,0.97,447,1087ady,https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion,102,1673349121.0,
105,learnmachinelearning,open-ai,comments,2019-01-12 22:50:09,"Newer people, anyone interested in a beginner friendly group project (subreddit group project) with a bit of guidance/mentorship?",BatmantoshReturns,False,0.98,90,afcqgb,https://www.reddit.com/r/learnmachinelearning/comments/afcqgb/newer_people_anyone_interested_in_a_beginner/,83,1547333409.0,"I posted earlier ( https://redd.it/aa64p0 ) for anyone interested in a project with a bit of mentorship/guidance. I got a lot of responses from people who were very new who weren't ready for the stuff I had in mind, so I came up with an idea for a project for those with very little experience. Also, multiple people can work on it together, pretty much we can work on it as a subreddit. 

The idea for the project is retraining word vectors for a specific domain, in this case, a research paper dataset. 

The motivation is that in different contexts, words will take on slightly different properties. For example, word vectors trained on a wikipedia data set will show different properties than vectors trained on a google news dataset. 

Anyone can participate, follow along, and show others their progress on a Google colab notebook. 

It'll be a pretty casual arrangement, anyone can pop in and out at anytime. 

And we can start right now! If you're interested comment below. No need for PMs on this one, this is pretty much open source, just comment below.

Edit:

Here are first steps

-Get familiar with Google Colaboratory

https://colab.research.google.com

-Go over word2vec 

Some suggested info, but keep going finding stuff on your own until you're comfortable with it.
https://www.youtube.com/watch?v=xMwx2A_o5r4
https://www.youtube.com/watch?v=BD8wPsr_DAI

-Go over a Word2vec implementation in your ML library of choice

Suggested resources, please look for stuff on your own as well

Keras Functional API for Tensorflow

https://adventuresinmachinelearning.com/word2vec-keras-tutorial/
https://github.com/adventuresinML/adventures-in-ml-code/blob/master/keras_word2vec.py

Tensorflow Graph/Session 

https://www.tensorflow.org/tutorials/representation/word2vec

Pytorch

https://towardsdatascience.com/implementing-word2vec-in-pytorch-skip-gram-model-e6bae040d2fb
https://adoni.github.io/2017/11/08/word2vec-pytorch/

Let me know if you're already familiar with colab, word2vec, and your ML library of choice, I'll post next steps. 

If you like, comment with your colab notebook so everyone can see, learn from, and give feedback on your work. 

Pretty excited about this. If this works well, we can do more intermediate group projects. 

Next Steps Part 2:

The next steps would be to figure out how to wrangle data from databases. Here are the databases we have to work with

Here's a corpus of research papers

https://labs.semanticscholar.org/corpus/

Another research papers database

https://aminer.org/open-academic-graph

This is also a great database for text data based on research papers, which I don't think people have done any real ml projects on, the arxiv database

https://arxiv.org/help/bulk_data

I recommend just focusing on a few areas, for example arxiv-sanity just extracts cs.[CV|CL|LG|AI|NE]/stat.ML papers.

This will be more tricky, so post your colab notebooks often so people can learn from you or help you whenever you get stuck. "
106,learnmachinelearning,open-ai,comments,2023-11-21 20:58:14,Does your company let your engineers use AI tools like Copilot or ChatGPT?,Psychological_March2,False,0.93,95,180r9tx,https://www.reddit.com/r/learnmachinelearning/comments/180r9tx/does_your_company_let_your_engineers_use_ai_tools/,75,1700600294.0,"In light of what's been happening with Open AI, this blog we wrote is still relevant:

A few weeks ago, I was with a group of CTOs when someone asked: *does your company let your engineers use AI tools like Copilot or ChatGPT?*

I thought the question was strange. What do you mean *let*? They're going to use it no matter what you say. AI code generation tools offer engineers a huge productivity boost. The ability to autocomplete code in seconds or work through a problem with AI isn’t an opportunity developers will pass up.

When we drilled into why this group was reluctant to allow their engineers to use AI, it became apparent that their reservations centered primarily on one concern: the absence of a robust testing framework to give them confidence in the code generated by AI.

But this is still flawed reasoning. If you’re not confident in using AI, how can you be confident in hiring new grads? If you don’t have the tools to have confidence in your code, it doesn’t matter where that code comes from–you’ll always struggle with quality.

Read more [here](https://trunk.io/blog/enhancing-code-quality-and-security-in-the-ai-era?utm=reddit)."
107,learnmachinelearning,open-ai,comments,2023-04-03 16:39:55,"If you are looking for courses about Artificial Intelligence, I created the repository with links to resources that I found super high quality and helpful. The link is in the comment.",RandomForests92,False,0.99,598,12apw9o,https://i.redd.it/jczyjswj6pra1.png,62,1680539995.0,
108,learnmachinelearning,open-ai,comments,2020-12-22 22:31:24,Study Plan for Learning Data Science Over the Next 12 Months [D],daniel-data,False,0.98,302,kifqtc,https://www.reddit.com/r/learnmachinelearning/comments/kifqtc/study_plan_for_learning_data_science_over_the/,58,1608676284.0,"In this thread, I address a study plan for 2021.

In case you're interested, I wrote a whole article about this topic: [Study Plan for Learning Data Science Over the Next 12 Months](https://www.datasource.ai/en/data-science-articles/study-plan-for-learning-data-science-over-the-next-12-months)

Let me know your thoughts on this.

&#x200B;

https://preview.redd.it/emg20nzhet661.png?width=1170&format=png&auto=webp&s=cf09e4dc5e82ba2fd7b57c706ba2873be57fe8de

We are ending 2020 and it is time to make plans for next year, and one of the most important plans and questions we must ask is what do we want to study?, what do we want to enhance?, what changes do we want to make?, and what is the direction we are going to take (or continue) in our professional careers?.

Many of you will be starting on the road to becoming a data scientist, in fact you may be evaluating it, since you have heard a lot about it, but you have some doubts, for example about the amount of job offers that may exist in this area, doubts about the technology itself, and about the path you should follow, considering the wide range of options to learn.

I’m a believer that we should learn from various sources, from various mentors, and from various formats. By sources I mean the various virtual platforms and face-to-face options that exist to study. By mentors I mean that it is always a good idea to learn from different points of view and learning from different teachers/mentors, and by formats I mean the choices between books, videos, classes, and other formats where the information is contained.

When we extract information from all these sources we reinforce the knowledge learned, but we always need a guide, and this post aims to give you some practical insights and strategies in this regard.

To decide on sources, mentors and formats it is up to you to choose. It depends on your preferences and ease of learning: for example, some people are better at learning from books, while others prefer to learn from videos. Some prefer to study on platforms that are practical (following online code), and others prefer traditional platforms: like those at universities (Master’s Degree, PHDs or MOOCs). Others prefer to pay for quality content, while others prefer to look only for free material. That’s why I won’t give a specific recommendation in this post, but I’ll give you the whole picture: **a study plan**.

To start you should consider the time you’ll spend studying and the depth of learning you want to achieve, because if you find yourself without a job you could be available full time to study, which is a huge advantage. On the other hand, if you are working, you’ll have less time and you’ll have to discipline yourself to be able to have the time available in the evenings, mornings or weekends. Ultimately, the important thing is to meet the goal of learning and perhaps dedicating your career to this exciting area!

We will divide the year into quarters as follows

* **First Quarter**: Learning the Basics
* **Second Quarter**: Upgrading the Level: Intermediate Knowledge
* **Third Quarter**: A Real World Project — A Full-stack Project
* **Fourth Quarter**: Seeking Opportunities While Maintaining Practice

# First Quarter: Learning the Basics

&#x200B;

https://preview.redd.it/u7t9bthket661.png?width=998&format=png&auto=webp&s=4ad29cb43618e7acf793259243aa5a60a8535f0a

If you want to be more rigorous you can have start and end dates for this period of study of the bases. It could be something like: From January 1 to March 30, 2021 as deadline. During this period you will study the following:

## A programming language that you can apply to data science: Python or R.

We recommend Python due to the simple fact that approximately 80% of data science job offers ask for knowledge in Python. That same percentage is maintained with respect to the real projects you will find implemented in production. And we add the fact that Python is multipurpose, so you won’t “waste” your time if at some point you decide to focus on web development, for example, or desktop development. This would be the first topic to study in the first months of the year.

## Familiarize yourself with statistics and mathematics.

There is a big debate in the data science community about whether we need this foundation or not. I will write a post later on about this, but the reality is that you **DO** need it, but **ONLY** the basics (at least in the beginning). And I want to clarify this point before continuing.

We could say that data science is divided in two big fields: Research on one side and putting Machine Learning algorithms into production on the other side. If you later decide to focus on Research then you are going to need mathematics and statistics in depth (very in depth). If you are going to go for the practical part, the libraries will help you deal with most of it, under the hood. It should be noted that most job offers are in the practical part.

For both cases, and in this first stage you will only need the basics of:

* **Statistics (with Python and NumPy)**

1. Descriptive statistics
2. Inferential Statistics
3. Hypothesis testing
4. Probability

* **Mathematics (with Python and NumPy)**

1. Linear Algebra (For example: SVD)
2. Multivariate Calculus
3. Calculus (For example: gradient descent)

**Note**: We recommend that you study Python first before seeing statistics and mathematics, because the challenge is to implement these statistical and mathematical bases with Python. Don’t look for theoretical tutorials that show only slides or statistical and/or mathematical examples in Excel/Matlab/Octave/SAS and other different to Python or R, it gets very boring and impractical! You should choose a course, program or book that teaches these concepts in a practical way and using Python. Remember that Python is what we finally use, so you need to choose well. **This advice is key so you don’t give up on this part, as it will be the most dense and difficult**.

If you have these basics in the first three months, you will be ready to make a leap in your learning for the next three months.

# Second Quarter: Upgrading the Level: Intermediate Knowledge

&#x200B;

https://preview.redd.it/y1y55vynet661.png?width=669&format=png&auto=webp&s=bd3e12bb112943025c39a8975faf4d64514df275

If you want to be more rigorous you can have start and end dates for this period of study at the intermediate level. It could be something like: From April 1 to June 30, 2021 as deadline.

Now that you have a good foundation in programming, statistics and mathematics, it is time to move forward and learn about the great advantages that Python has for applying data analysis. For this stage you will be focused on:

## Data science Python stack

Python has the following libraries that you should study, know and practice at this stage

* **Pandas**: for working with tabular data and make in-depth analysis
* **Matplotlib and Seaborn**: for data visualization

Pandas is the in-facto library for data analysis, it is one of the most important (if not the most important) and powerful tools you should know and master during your career as a data scientist. Pandas will make it much easier for you to manipulate, cleanse and organize your data.

## Feature Engineering

Many times people don’t go deep into Feature Engineering, but if you want to have Machine Learning models that make good predictions and improve your scores, spending some time on this subject is invaluable!

Feature engineering is the process of using domain knowledge to extract features from raw data using data mining techniques. These features can be used to improve the performance of machine learning algorithms. Feature engineering can be considered as applied machine learning itself. To achieve the goal of good feature engineering you must know the different techniques that exist, so it is a good idea to at least study the main ones.

## Basic Models of Machine Learning

At the end of this stage you will start with the study of Machine Learning. This is perhaps the most awaited moment! This is where you start to learn about the different algorithms you can use, which particular problems you can solve and how you can apply them in real life.

The Python library we recommend you to start experimenting with ML is: scikit-learn. *However it is a good idea that you can find tutorials where they explain the implementation of the algorithms (at least the simplest ones) from scratch with Python, since the library could be a “****Black Box****” and you might not understand what is happening under the hood. If you learn how to implement them with Python, you can have a more solid foundation*.

If you implement the algorithms with Python (without a library), you will put into practice everything seen in the statistics, mathematics and Pandas part.

These are some recommendations of the algorithms that you should at least know in this initial stage

* **Supervised learning**
   * Simple Linear Regression
   * Multiple Linear Regression
   * K-nearest neighbors (KNN)
   * Logistic Regression
   * Decision Trees
   * Random Forest
* **Unsupervised Learning**
   * K-Means
   * PCA

**Bonus**: if you have the time and you are within the time ranges, you can study these others

* **Gradient Boosting Algorithms**
   * GBM
   * XGBoost
   * LightGBM
   * CatBoost

**Note**: do not spend more than the 3 months stipulated for this stage. Because you will be falling behind and not complying with the study plan. We all have shortcomings at this stage, it is normal, go ahead and then you can resume some concepts that did not understand in detail. The important thing is to have the basic knowledge and move forward!

*If at least you succeed to study the mentioned algorithms of supervised and unsupervised learning, you will have a very clear idea of what you will be able to do in the future*. So don’t worry about covering everything, remember that it is a process, and ideally you should have some clearly established times so that you don’t get frustrated and feel you are advancing.

So far, here comes your “theoretical” study of the basics of data science. Now we’ll continue with the practical part!

# Third Quarter: A Real World Project — A Full-stack Project

&#x200B;

https://preview.redd.it/vrn783vqet661.png?width=678&format=png&auto=webp&s=664061b3d33b34979b74b10b9f8a3d0f7b8b99ee

If you want to be more rigorous you can have start and end dates for this period of study at the intermediate level. It could be something like: From July 1 to September 30, 2021 as deadline.

Now that you have a good foundation in programming, statistics, mathematics, data analysis and machine learning algorithms, it is time to move forward and put into practice all this knowledge.

Many of these suggestions may sound out of the box, but believe me they will make a big difference in your career as a data scientist.

## The first thing is to create your web presence:

* *Create a Github (or GitLab) account, and learn Git*. Being able to manage different versions of your code is important, you should have version control over them, not to mention that having an active Github account is very valuable in demonstrating your true skills. On Github, you can also set up your Jupyter Notebooks and make them public, so you can show off your skills as well. This is mine for example: [https://github.com/danielmoralesp](https://github.com/danielmoralesp)
* *Learn the basics of web programming*. The advantage is that you already have Python as a skill, so you can learn Flask to create a simple web page. Or you can use a template engine like Github Pages, Ghost or Wordpress itself and create your online portfolio.
* *Buy a domain with your name*. Something like myname.com, myname.co, myname.dev, etc. This is invaluable so you can have your CV online and update it with your projects. There you can make a big difference, showing your projects, your Jupyter Notebooks and showing that you have the practical skills to execute projects in this area. There are many front-end templates for you to purchase for free or for payment, and give it a more personalized and pleasant look. Don’t use free sub-domains of Wordpress, Github or Wix, it looks very unprofessional, make your own. Here is mine for example: [https://www.danielmorales.dev/](https://www.danielmorales.dev/)

## Choose a project you are passionate about and create a Machine Learning model around it.

The final goal of this third quarter is to create **ONE** project, that you are passionate about, and that is **UNIQUE** among others. It turns out that there are many typical projects in the community, such as predicting the Titanic Survivors, or predicting the price of Houses in Boston. Those kinds of projects are good for learning, but not for showing off as your **UNIQUE** projects.

If you are passionate about sports, try predicting the soccer results of your local league. If you are passionate about finance, try predicting your country’s stock market prices. If you are passionate about marketing, try to find someone who has an e-commerce and implement a product recommendation algorithm and upload it to production. If you are passionate about business: make a predictor of the best business ideas for 2021 :)

As you can see, you are limited by your passions and your imagination. ***In fact,*** ***those are the two keys for you to do this project: Passion and Imagination***.

However don’t expect to make money from it, you are in a learning stage, you need that algorithm to be deployed in production, make an API in Flask with it, and explain in your website how you did it and how people can access it. This is the moment to shine, and at the same time it’s the moment of the greatest learning.

You will most likely face obstacles, if your algorithm gives 60% of Accuracy after a huge optimization effort, it doesn’t matter, finish the whole process, deploy it to production, try to get a friend or family member to use it, and that will be the goal achieved for this stage: **Make a Full-stack Machine Learning project.**

By full-stack I mean that you did all the following steps:

* You got the data from somewhere (scrapping, open data or API)
* You did a data analysis
* You cleaned and transformed the data
* You created Machine Learning Models
* You deployed the best model to production for other people to use.

This does not mean that this whole process is what you will always do in your daily job, but it does mean that you will know every part of the pipeline that is needed for a data science project for a company. You will have a unique perspective!

# Fourth Quarter: Seeking Opportunities While Maintaining Practice

&#x200B;

https://preview.redd.it/qd0osystet661.png?width=1056&format=png&auto=webp&s=2da456b15985b2793041256f5e45bca99a23b51a

If you want to be more rigorous you can have start and end dates for this period of study at the final level. It could be something like: From October 1 to December 31, 2021 as deadline.

Now you have theoretical and practical knowledge. You have implemented a model in production. The next step depends on you and your personality. Let’s say you are an entrepreneur, and you have the vision to create something new from something you discovered or saw an opportunity to do business with this discipline, so it’s time to start planning how to do it. If that’s the case, obviously this post won’t cover that process, but you should know what the steps might be (or start figuring them out).

But if you are one of those who want to get a job as a data scientist, here is my advice.

## Getting a job as a data scientist

>*“You’re not going to get a job as fast as you think, if you keep thinking the same way”.Author*

It turns out that all people who start out as data scientists imagine themselves working for the big companies in their country or region. Or even remote. It turns out that if you aspire to work for a large company like data scientist you will be frustrated by the years of experience they ask for (3 or more years) and the skills they request.

Large companies don’t hire Juniors (or very few do), precisely because they are already large companies. They have the financial muscle to demand experience and skills and can pay a commensurate salary (although this is not always the case). The point is that if you focus there you’re going to get frustrated!

Here we must return to the following advise: ***“You need creativity to get a job in data science”***.

Like everything else in life we have to start at different steps, in this case, from the beginning. Here are the scenarios

* *If you are working in a company and in a non-engineering role you must demonstrate your new skills to the company you are working for*. If you are working in the customer service area, you should apply it to your work, and do for example, detailed analysis of your calls, conversion rates, store data and make predictions about it! If you can have data from your colleagues, you could try to predict their sales! This may sound funny, but it’s about how creatively you can apply data science to your current work and how to show your bosses how valuable it is and **EVANGELIZE** them about the benefits of implementation. You’ll be noticed and they could certainly create a new data related department or job. And you already have the knowledge and experience. The key word here is **Evangelize**. Many companies and entrepreneurs are just beginning to see the power of this discipline, and it is your task to nurture that reality.
* *If you are working in an area related to engineering, but that is not data science*. Here the same applies as the previous example, but you have some advantages, and that is that you could access the company’s data, and you could use it for the benefit of the company, making analyses and/or predictions about it, and again **EVANGELIZING** your bosses your new skills and the benefits of data science.
* *If you are unemployed (or do not want, or do not feel comfortable following the two examples above)*, you can start looking outside, and what I recommend is that you look for technology companies and / or startups where they are just forming the first teams and are paying some salary, or even have options shares of the company. Obviously here the salaries will not be exorbitant, and the working hours could be longer, but remember that you are in the learning and practice stage (just in the first step), so you can not demand too much, you must land your expectations and fit that reality, and stop pretending to be paid $ 10,000 a month at this stage. But, depending of your country $1.000 USD could be something very interesting to start this new career. Remember, you are a Junior at this stage.

***The conclusion is: don’t waste your time looking at and/or applying to offers from big companies, because you will get frustrated. Be creative, and look for opportunities in smaller or newly created companies***.

## Learning never stops

While you are in that process of looking for a job or an opportunity, which could take half of your time (50% looking for opportunities, 50% staying in practice), you have to keep learning, you should advance to concepts such as Deep Learning, Data Engineer or other topics that you feel were left loose from the past stages or focus on the topics that you are passionate about within this group of disciplines in data science.

At the same time you can choose a second project, and spend some time running it from end-to-end, and thus increase your portfolio and your experience. If this is the case, try to find a completely different project: if the first one was done with Machine Learning, let this second one be done with Deep learning. If the first one was deployed to a web page, that this second one is deployed to a mobile platform. Remember, creativity is the key!

# Conclusion

We are at an ideal time to plan for 2021, and if this is the path you want to take, start looking for the platforms and media you want to study on. Get to work and don’t miss this opportunity to become a data scientist in 2021!

Note: we are building a private community in Slack of data scientist, if you want to join us write to the email: [support@datasource.ai](mailto:support@datasource.ai)

I hope you enjoyed this reading! you can follow me on [twitter](https://twitter.com/daniel_moralesp) or [linkedin](https://www.linkedin.com/in/danielmorales1/)

Thank you for reading!"
109,learnmachinelearning,open-ai,comments,2021-04-17 14:35:34,*Semantic* Video Search with OpenAI’s CLIP Neural Network (link in comments),designer1one,False,1.0,494,msruz1,https://i.redd.it/dlw52klsvqt61.gif,53,1618670134.0,
110,learnmachinelearning,open-ai,comments,2023-05-16 07:40:00,EU AI Act: Shaping Or Destroying The Future Of US Open Source Softwares?,vadhavaniyafaijan,False,0.8,45,13iybuc,https://www.theinsaneapp.com/2023/05/eu-ai-act.html,48,1684222800.0,
111,learnmachinelearning,open-ai,comments,2023-01-19 07:56:20,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.96,331,10fw2df,https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/,47,1674114980.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
112,learnmachinelearning,open-ai,comments,2020-08-05 10:58:02,image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model,OnlyProggingForFun,False,0.97,636,i437om,https://www.youtube.com/watch?v=FwXQ568_io0,46,1596625082.0,
113,learnmachinelearning,open-ai,comments,2023-10-09 11:54:03,Where Do You Get Your AI News?,Altruistic_Gift4997,False,0.97,89,173pvsv,https://www.reddit.com/r/learnmachinelearning/comments/173pvsv/where_do_you_get_your_ai_news/,45,1696852443.0,"Guys, I'm looking for the best spots to get the latest updates and news in the field. What websites, blogs, or other sources do you guys follow to stay on top of the AI game?  
Give me your go-to sources, whether it's some cool YouTube channel, a Twitter(X xd) account, or just a blog that's always dropping fresh AI knowledge. I'm open to anything – the more diverse, the better!

Thanks a lot! 😍"
114,learnmachinelearning,open-ai,comments,2023-05-11 20:15:46,Top 20 Large Language Models based on the Elo rating system.,kingabzpro,False,0.96,251,13eympz,https://i.redd.it/7xfqr5crf9za1.png,43,1683836146.0,
115,learnmachinelearning,open-ai,comments,2018-09-08 23:24:14,Do you guys buy Elon Musks fatalistic view on ML?,alpha_53g43,False,0.65,6,9e8inn,https://www.reddit.com/r/learnmachinelearning/comments/9e8inn/do_you_guys_buy_elon_musks_fatalistic_view_on_ml/,40,1536449054.0,"I was watching Elon Musks interview with Joe Rogan here: https://www.youtube.com/watch?v=ycPr5-27vSI.

I have done some amount of ML myself, and have listened to a fair amount of discussion of ML papers. Do you guys think that this fatalistic view is real? Currently, is there any indication that with the kind of ML architectures available you can actually build something to replace the human brain? 

To me, this actually seems like marketing, and Elon is amazing at marketing. To expand on that a little bit, if everybody is hyping about the potential of AI, and Elon starts talking about how AI is going to destroy the earth, people will start thinking that Elon knows something that nobody really knows about. This in turn will lead to the best AI engineers joining Tesla/OpenAI. It's actually very similar to the `Don't be evil` campaign by Google to attract the best engineers. The best engineers do see the potential that technology can have but also have this altruistic view that they don't want to create destructive effects (well a few do)."
116,learnmachinelearning,open-ai,comments,2022-02-22 09:16:23,Almost no one knows how easily you can optimize your AI models,emilec___,False,0.9,273,syj7vx,https://www.reddit.com/r/learnmachinelearning/comments/syj7vx/almost_no_one_knows_how_easily_you_can_optimize/,38,1645521383.0,"The situation is fairly simple. **Your model could run 10 times faster** by adding a few lines to your code, but you weren't aware of it. Let me expand on that.

1. AI applications are multiplying like mushrooms, which is awesome
2. As a result, more and more people are turning to the dark side, joining the AI world, as I did
3. The problem? Developers focus only on AI, cleaning up datasets and training their models. Almost no one has a background in hardware, compilers, computing, cloud, etc
4. The result? Developers spend a lot of hours improving the accuracy and performance of their software, and all their hard work risks being undone by the wrong choice of hardware-software coupling

This problem bothered me for a long time, so with a couple of buddies at [Nebuly](https://nebuly.ai/) (all ex MIT, ETH and EPFL), we put a lot of energy into an **open-source library** called **nebullvm** to make DL compiler technology accessible to any developer, even for those who know nothing about hardware, as I did.

How does it work? It **speeds up your DL models by \~5-20x** by testing the best DL compilers out there and selecting the optimal one to best couple your AI model with your machine (GPU, CPU, etc.). All this in just a few lines of code.

The library is open source and you can find it here [https://github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/nebullvm).

Please leave a star on GitHub for the hard work in building the library :) It's a simple act for you, a big smile for us. Thank you, and don't hesitate to contribute to the library!"
117,learnmachinelearning,open-ai,comments,2023-01-16 12:28:25,I benchmarked OpenAI's GPT API vs other proprietary APIs on different NLP tasks,AImSamy,False,0.9,197,10ddc1f,https://www.reddit.com/gallery/10ddc1f,37,1673872105.0,
118,learnmachinelearning,open-ai,comments,2023-05-25 17:23:19,"Are people still coding stuff on their own like chatbots, image AIs, etc., or is everyone just using pretrained models and APIs now?",TrackLabs,False,0.91,93,13rnopr,https://www.reddit.com/r/learnmachinelearning/comments/13rnopr/are_people_still_coding_stuff_on_their_own_like/,35,1685035399.0,"I feel like everyone is just downloading models from huggingface at this point, or using GPT APIs and so on.

I also feel like there are not really tutorials anymore on YT and the web about how to code stuff like there used to be 5 to 2 years ago. Every video now is just ""how to use OpenAIs API"" or ""how to use llama model from huggingface"". 

I have a big problem with staying up to date on the stuff, I never really bothered using huggingface, and I dont really like the idea to just use other peoples pretrained models for everything, what actual contribution am I doing in my own projects then lol.

Would be cool if some people could give me some reality check on whats going on."
119,learnmachinelearning,open-ai,comments,2023-07-10 14:36:34,🤖🔎 Excited to introduce 'GPT-Researcher'!,Legal-Dragonfruit845,False,0.8,70,14vvtqf,https://www.reddit.com/r/learnmachinelearning/comments/14vvtqf/excited_to_introduce_gptresearcher/,35,1688999794.0,"The idea is simple - Specify what you want to research, and the AI will autonomously research it for you in minutes!

▸ One prompt generates an unbiased, factual and in depth research report

▸ Generate research, outlines, resource and lessons reports

▸ Aggregates over 20 web sources per research

▸ Includes an easy to use web interface

▸ Open source: [https://github.com/assafelovic/gpt-researcher](https://github.com/assafelovic/gpt-researcher)

▸ Scrapes web sources with javascript support

▸ Keeps track and context of visited and used web sources

https://reddit.com/link/14vvtqf/video/zce4347lf5bb1/player"
120,learnmachinelearning,open-ai,comments,2023-11-23 10:24:00,"Nonfiction authors sue OpenAI, Microsoft for copyright infringement",anujtomar_17,False,0.84,40,181y9sl,https://newyorkverified.com/4324297-nonfiction-authors-sue-openai-microsoft-copyright-infringement/,34,1700735040.0,
121,learnmachinelearning,open-ai,comments,2019-02-28 12:22:34,Coursera: AI For Everyone (with Andrew Ng) is finally open.,sercosan,False,0.98,206,avqim1,https://www.coursera.org/learn/ai-for-everyone,34,1551356554.0,
122,learnmachinelearning,open-ai,comments,2022-07-15 11:15:58,"Beside OpenAI, Google and Midjourney; what are the companies/start-ups working on text to image generation?",matxi182,False,0.92,51,vzm5rb,https://www.reddit.com/r/learnmachinelearning/comments/vzm5rb/beside_openai_google_and_midjourney_what_are_the/,32,1657883758.0,
123,learnmachinelearning,open-ai,comments,2023-02-25 11:19:05,Any MLOps platform you use?,squalidaesthetics20,False,0.98,239,11biozs,https://www.reddit.com/r/learnmachinelearning/comments/11biozs/any_mlops_platform_you_use/,31,1677323945.0,"I've been searching for some MLOps platforms for my some projects that I’m working on. I am creating a list that will hopefully help out with productivity and help mr build better apps and services. Also hopefully faster.

I've looked at some of the more popular ones out there and here’s my top 4 so far. Let me know what you guys think about these:

* [Vertex AI](https://cloud.google.com/vertex-ai) \- An ML platform by Google Cloud. They have AI-powered tools to ingest, analyze, and store video data. Good for image classification, NLP, recommendation systems etc.
* [Jina AI](https://jina.ai/) \-They offer a neural search solution that can help build smarter, more efficient search engines. They also have a list of [cool github repos](https://github.com/jina-ai/jina) that you can check out. Similar to Vertex AI, they have image classification tools, NLPs, fine tuners etc.
* [MLflow](https://mlflow.org/) \- an open-source platform for managing your ML lifecycle. What’s great is that they also support popular Python libraries like TensorFlow, PyTorch, scikit-learn, and R.
* Neptune.ai, which promises to streamline your workflows and make collaboration a breeze.

Have you guys tried any of these platforms? I know a lot of AI tools and platforms have been popping up lately especially with the rise of AI tools but what are your thoughts?"
124,learnmachinelearning,open-ai,comments,2020-09-26 13:10:55,Trying to keep my Jump Rope and AI Skills on point! Made this application using OpenPose. Link to the Medium tutorial and the GitHub Repo in the thread.,jumper_oj,False,0.99,1180,j05rte,https://v.redd.it/jh5n48ghrhp51,29,1601125855.0,
125,learnmachinelearning,open-ai,comments,2023-12-22 00:15:37,"I'm torn between RL and CV, which one is better for finding research position at big companies?",Trevorego,False,0.85,14,18o1kix,https://www.reddit.com/r/learnmachinelearning/comments/18o1kix/im_torn_between_rl_and_cv_which_one_is_better_for/,26,1703204137.0,"I'm learning ML/DL and now I need to choose a path to follow and specialize in. I like both RL & CV, and luckily I have the opportunity to work with both subjects with my professors. However, I'm just clueless which one to learn, or maybe I should say learn first because very likely I'll also learn and required to work with the other one in future, but for now I can't decide. They both look very interesting, both looks challenging, both looks fun. Thus, now I consider which one would be a better choice for finding a research position at a big company like OpenAI, Google, etc. I'm open to any advise and really need one."
126,learnmachinelearning,open-ai,comments,2023-03-25 16:23:09,What's the current state of actually free and open source LLMs?,maquinary,False,0.96,59,121qvqn,https://www.reddit.com/r/learnmachinelearning/comments/121qvqn/whats_the_current_state_of_actually_free_and_open/,25,1679761389.0,"*People, take easy on me, I just a newbie that tests stuff made by A.I. in a very amateur manner.*

---------------------

Yesterday a played a bit with [Alpaca.cpp](https://github.com/antimatter15/alpaca.cpp), but despite the fact that the software itself is in the MIT license, it has serious limitations because of licensing factors, as you can see [here](https://crfm.stanford.edu/2023/03/13/alpaca.html):

>[...]

>

> We emphasize that Alpaca is intended only for academic research and any commercial use is prohibited. There are three factors in this decision: First, Alpaca is based on LLaMA, which has a non-commercial license, so we necessarily inherit this decision. Second, the instruction data is based on OpenAI’s text-davinci-003, whose terms of use prohibit developing models that compete with OpenAI. Finally, we have not designed adequate safety measures, so Alpaca is not ready to be deployed for general use.

>

> [...]

So, do we have anything that is **completely free** that reaches at least the level of GTP-3?

And what about the data that people use to train the models? Those big companies can ""scan"" the entire web to get insane amounts of data, but can free software developers use these already harvested data to train their own models? Or, in order to have a completely free LLM, people will have to collect data again from the Internet?

-------------

*When I say ""free"", I mean free from licensing limitations, in a sense that I can implement the A.I. in my software without the need of being forced to apply a limited range of licenses, or without the need to pay.*"
127,learnmachinelearning,open-ai,comments,2023-01-15 00:08:37,Is it still worth learning NLP in the age of API-accessibles LLM like GPT?,CrimsonPilgrim,False,0.94,64,10c509n,https://www.reddit.com/r/learnmachinelearning/comments/10c509n/is_it_still_worth_learning_nlp_in_the_age_of/,24,1673741317.0,"A question that, I hope, you will find legitimate from a data science student.

I am speaking from the point of view of a data scientist not working in research.

Until now, learning NLP could be used to meet occasional business needs like sentiment analysis, text classification, topic modeling....

With the opening of GPT-3 to the public, the rise of ChatGPT, and the huge wave of applications, sites, plug-ins and extensions based on this technology that are accessible with a simple API request, it's impossible not to wonder if spending dozens of hours diving into this field if ML wouldn't be as useful today as learning the source code of the Pandas library. 

In some specialized cases, it could be useful, but GPT-3, and the models that will follow, seem to offer more than sufficient results for the immensity of the cases and for almost all classical NLP tasks. Not only that, but there is a good chance that the models trained by giants like Open-AI (Microsoft) or Google can never be replicated outside these companies anyway.  With ChatGPT and its incomparable mastery of language, its ability to code, summarize, extract topics, understand... why would I bother to use BERT or a TF-IDF vectorizer when an API will be released? Not only it would be easily accessible, but it also would be much better at the task, faster and cheaper.

In fact, it's a concern regarding all the machine learning field in general with the arrival of powerful ""no-code"" applications, which abstract a large part of the inherent complexity of the field. There will always be a need for experts, for safeguards, but in the end, won't the Data Scientist who masters the features of GPT-3 or 4 and knows a bit of NLP be more efficient than the one who has spent hours reading Google papers and practicing on Gensim, NLTK, spacy... It is the purpose of an API to make things simpler eventually... At what point is there no more reason to be interested in the behind-the-scenes of these tools and to become simple users rather than trying to develop our own techniques?"
128,learnmachinelearning,open-ai,comments,2023-02-16 10:29:31,OpenAI Has Purchased AI.Com For ChatGPT For $11M,vadhavaniyafaijan,False,0.93,207,113nizs,https://www.theinsaneapp.com/2023/02/openai-purchased-ai-com-domain.html,23,1676543371.0,
129,learnmachinelearning,open-ai,comments,2022-01-22 13:55:19,"Consolidated Video lectures for Machine Learning(including DL, CV, NLP, etc)",slim_but_not_shady,False,0.99,261,sa30oc,https://www.reddit.com/r/learnmachinelearning/comments/sa30oc/consolidated_video_lectures_for_machine/,23,1642859719.0,"**Video Lectures for Machine Learning(Theory):**

**Machine Learning:**

Cornell CS4780: [https://www.youtube.com/playlist?list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS](https://www.youtube.com/playlist?list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS)

Stanford CS 229:

[https://www.youtube.com/playlist?list=PLoROMvodv4rNH7qL6-efu\_q2\_bPuy0adh](https://www.youtube.com/playlist?list=PLoROMvodv4rNH7qL6-efu_q2_bPuy0adh)

IIT Madras:

[https://www.youtube.com/playlist?list=PL1xHD4vteKYVpaIiy295pg6\_SY5qznc77](https://www.youtube.com/playlist?list=PL1xHD4vteKYVpaIiy295pg6_SY5qznc77)

IISc Bangalore(Rigorous Math):

[https://www.youtube.com/playlist?list=PLbMVogVj5nJSlpmy0ni\_5-RgbseafOViy](https://www.youtube.com/playlist?list=PLbMVogVj5nJSlpmy0ni_5-RgbseafOViy)

Applied Machine Learning Cornell CS5787:

[https://www.youtube.com/playlist?list=PL2UML\_KCiC0UlY7iCQDSiGDMovaupqc83](https://www.youtube.com/playlist?list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83)

Caltech's Machine Learning Course - CS 156 by Professor Yaser Abu-Mostafa:

[https://www.youtube.com/playlist?list=PL41qI9AD63BMXtmes0upOcPA5psKqVkgS](https://www.youtube.com/playlist?list=PL41qI9AD63BMXtmes0upOcPA5psKqVkgS)

StatQuest(Best resource for revision and visualization):

[https://www.youtube.com/user/joshstarmer?app=desktop](https://www.youtube.com/user/joshstarmer?app=desktop)

&#x200B;

**Deep Learning:**

IIT Madras(No prerequisites and great prof):

Part 1: [https://youtube.com/playlist?list=PLyqSpQzTE6M9gCgajvQbc68Hk\_JKGBAYT](https://youtube.com/playlist?list=PLyqSpQzTE6M9gCgajvQbc68Hk_JKGBAYT)

Part 2: [https://www.youtube.com/playlist?list=PLyqSpQzTE6M-\_1jAqrFCsgCcuTYm\_2urp](https://www.youtube.com/playlist?list=PLyqSpQzTE6M-_1jAqrFCsgCcuTYm_2urp)

Course link for slides and references: [http://www.cse.iitm.ac.in/\~miteshk/CS7015\_2018.html](http://www.cse.iitm.ac.in/~miteshk/CS7015_2018.html)

Neural Networks by Hinton:

[https://www.youtube.com/playlist?list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0](https://www.youtube.com/playlist?list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

 NYU DL (Taught by Prof Alfredo Canziani and Prof Yann Lecun):

[https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI](https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI) 

**Computer Vision(Deep Learning):**

Michigan University:

[https://youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r](https://youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r)

(This Michigan university course is the updated version of Stanford’s CS231n CV course and includes all the content covered by that as well)

Advanced Deep Learning for Computer Vision by TU Munich:

[https://www.youtube.com/playlist?list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39](https://www.youtube.com/playlist?list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39)

**Natural Language Processing(Deep Learning):**

Stanford CS 224n:

[https://youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z](https://youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)

Natural Language Understanding Stanford CS 224u:

[https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20](https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20)

Deep Learning for NLP at Oxford with Deep Mind 2017:

[https://www.youtube.com/playlist?list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm](https://www.youtube.com/playlist?list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm)

NLP CMU 11-411/11-611:

[https://www.youtube.com/playlist?list=PL4YhK0pT0ZhXteJ2OTzg4vgySjxTU\_QUs](https://www.youtube.com/playlist?list=PL4YhK0pT0ZhXteJ2OTzg4vgySjxTU_QUs)

CMU CS11-737 Multilingual Natural Language Processing:

[https://www.youtube.com/playlist?list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5](https://www.youtube.com/playlist?list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5)

**Reinforcement Learning:**

IIT Madras:

[https://youtube.com/playlist?list=PLEAYkSg4uSQ0Hkv\_1LHlJtC\_wqwVu6RQX](https://youtube.com/playlist?list=PLEAYkSg4uSQ0Hkv_1LHlJtC_wqwVu6RQX)

Stanford CS234:

[https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)

**Deep Reinforcement Learning:**

UC Berkeley CS 285:

[https://youtube.com/playlist?list=PL\_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc](https://youtube.com/playlist?list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc)

**Other:**

CS224W: Machine Learning with Graphs

[https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn](https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn)

Stanford CS330: Multi-Task and Meta-Learning

[https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5](https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5)

Explainable AI:

[https://www.youtube.com/playlist?list=PLV8yxwGOxvvovp-j6ztxhF3QcKXT6vORU](https://www.youtube.com/playlist?list=PLV8yxwGOxvvovp-j6ztxhF3QcKXT6vORU)

Explainable AI in Industry:

[https://www.youtube.com/playlist?list=PL9ekywqME2Aj8OmKoBUaYEH7Xzi-YCRBy](https://www.youtube.com/playlist?list=PL9ekywqME2Aj8OmKoBUaYEH7Xzi-YCRBy)

**Some Math lectures(refresher):**

Linear algebra(MIT):

[https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8](https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8)

Optimization(IIT Kanpur):

[https://www.youtube.com/playlist?list=PLbMVogVj5nJRRbofh3Qm3P6\_NVyevDGD\_](https://www.youtube.com/playlist?list=PLbMVogVj5nJRRbofh3Qm3P6_NVyevDGD_)

Multivariable Calculus(MIT):

[https://www.youtube.com/playlist?list=PL4C4C8A7D06566F38](https://www.youtube.com/playlist?list=PL4C4C8A7D06566F38)

Probability and Statistics(Harvard):

[https://www.youtube.com/playlist?list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo](https://www.youtube.com/playlist?list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo)

&#x200B;

If you are applying for a job, ML and DL is sufficient for a DS/ML Engineer role initially(Given that you know programming and have completed some projects). But depending on the JD and the work that the company does, Computer vision and Natural Language Processing questions can be expected.

Disclaimer: The video list includes some advanced topics(Meta-learning, Graph ML, etc) which might not be relevant for a person who is applying for a ML Engineer job(unless your job involves work or research related to those topics)

**Some basic Python libraries that you need to be familiar with:**

ML: Sckit-learn, xgboost, catboost, lightgbm, hyperopt etc

DL: Tensorflow, PyTorch, Keras, etc

NLP and transformers: HuggingFace

RL: OpenAI Gym, etc

Production: MLFlow, Apache Airflow, Kubeflow, etc (This is not a hardcore requirement but some companies ask questions on production tools)

Explainable AI: SHAP, LIME, ELI5, tf-explain, captum, etc( Not a hardcore requirement for interviews)"
130,learnmachinelearning,open-ai,comments,2021-04-12 23:04:57,"I'm currently self studying machine learning using the book ""Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow"" (2nd Edition) by Aurélien Géron. Is anybody else studying this book and interested in being part of a remote study group to complete it?",Letuku,False,0.86,15,mppp1r,https://www.reddit.com/r/learnmachinelearning/comments/mppp1r/im_currently_self_studying_machine_learning_using/,22,1618268697.0,"I find that the problem with self studying is that unlike studying through a university or online bootcamp there is nobody to ask for help when you're stuck and thus studying becomes slower because a lot of time is wasted when you're not able to get quick and effective help online which can also result in feeling demotivated at times.

I'm currently at the beginning of this book and I'd like to complete it as quick as possible with a few study partners if I can find any. I also got my hands on [""Mastering OpenCV 4 with Python""](https://www.amazon.com/Mastering-OpenCV-Python-practical-processing/dp/1789344913/ref=sr_1_1?dchild=1&keywords=mastering+opencv+with+python&qid=1618269386&s=books&sr=1-1) if anyone is doing that. I think it would help to find other people who'd be interested to be part of a remote machine learning study group and maybe at the end build two or so projects (outside of the book) or MVP's together to be able to have competitive portfolios of work when trying to establish our careers in the AI industry. I think that working on projects together at the end of studying this book can also show potential employers that we can work well in remote and collaborative environments or maybe if we're lucky and build something that can get a good number of users we could even get funded for a startup for one of the products we build together.

So far the group has two people (including myself) and we're at the beginning of our first ML project in chapter 2. Please feel free to send me a DM if you'd be interested to complete this book (or any other similar book) with me as quickly and efficiently as we can so that we can find our feet in this very exciting industry!

If you see this late also feel free to contact me. I may be able to help if I have any success. I'm looking forward to hearing from you. : )

https://preview.redd.it/r9kfcb8aeqs61.jpg?width=1951&format=pjpg&auto=webp&s=db7447eeb748dbf28e25aa6ee06458681a9e965b"
131,learnmachinelearning,open-ai,comments,2023-10-23 12:07:34,"I created the repository with links to top AI, LLMs, CV, or NLP resources | The link is in the comment",RandomForests92,False,0.97,196,17eisx4,https://i.redd.it/lyxdc9cg0yvb1.png,22,1698062854.0,
132,learnmachinelearning,open-ai,comments,2023-08-17 12:50:37,I'm trying to create a comprehensive table of the best AI tools to Increase Your Productivity + Automate Your Work- feel free to give some recs so I can add it to the list.,paulflythe,False,0.8,39,15tmnit,https://i.redd.it/sgcuo4o13oib1.png,19,1692276637.0,
133,learnmachinelearning,open-ai,comments,2023-04-06 22:52:56,What OS is widely used in the ML community?,AjSpeed22,False,0.57,1,12e0zbu,https://www.reddit.com/r/learnmachinelearning/comments/12e0zbu/what_os_is_widely_used_in_the_ml_community/,16,1680821576.0,I am in the market for a new laptop and was wondering if a certain system works best for general ML code / software. Recently tried to access the open ai gym on windows and learned it doesn't fully support windows. So now I am wondering which system I should go for if I make a purchase.
134,learnmachinelearning,open-ai,comments,2023-03-25 06:14:22,Does it make sense to specialize in NLP now?,Aromatic_Eye_6268,False,0.91,76,121cvgi,https://www.reddit.com/r/learnmachinelearning/comments/121cvgi/does_it_make_sense_to_specialize_in_nlp_now/,20,1679724862.0,"With the explosion of Large Language Models, it is clear that most of the cutting edge work is being done in a handful of companies around the world. Does it make sense to specialize in NLP? Will someone be able to do novel research work in NLP without being a part of places like OpenAI?"
135,learnmachinelearning,open-ai,comments,2018-11-24 16:19:37,Has anyone previously applied/interned at OpenAI? What was your experience like?,ZER_0_NE,False,0.93,59,9zzpzl,https://www.reddit.com/r/learnmachinelearning/comments/9zzpzl/has_anyone_previously_appliedinterned_at_openai/,19,1543076377.0,
136,learnmachinelearning,open-ai,comments,2019-10-23 23:58:05,OpenAI plays hide and seek and breaks the game. (Reinforcement Learning),UnintelligibleThing,False,0.97,343,dm86ay,https://www.youtube.com/watch?v=Lu56xVlZ40M,19,1571875085.0,
137,learnmachinelearning,open-ai,comments,2022-12-27 18:05:30,Am I Too Late?,stupidSTEMquestions,False,0.5,0,zwltk8,https://www.reddit.com/r/learnmachinelearning/comments/zwltk8/am_i_too_late/,19,1672164330.0,"I am a college student studying math and computer science. I know how to program with high level languages, C, and a bit of C++ and Scheme. I can build basic web apps and scripts, and am focusing on machine learning with python. 

With the release of ChatGPT and articles like [this](https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext#comments) though, I can't help but ask — am I too late?

Is it simply too late for a beginner to make any contributions to the field at this point when OpenAI, Deepmind, and the like are iterating at such a rapid pace? I really love AI and machine learning so far, but I also don't want to waste my time and energy if there won't be any meaningful work for me once I finish my education in 4 or more years."
138,learnmachinelearning,open-ai,comments,2024-02-19 01:44:52,GPU vs CPU for inference,AI-Brain,False,0.67,3,1aubc4u,https://www.reddit.com/r/learnmachinelearning/comments/1aubc4u/gpu_vs_cpu_for_inference/,18,1708307092.0,"I read through some comments on the sub and understood that GPUs are mainly used for training and CPUs for inference. Had some follow ups: 
1. Is there a scenario where GPUs are better suited for inference? 
2. Would you say that if you are handling billions of inference requests then you should use GPUs? 
3. What makes GPUs inefficient for inference? (If any) 
4. When we use chatGPT, is OpenAI using CPUs for inference? 

Any insights would be helpful."
139,learnmachinelearning,open-ai,comments,2023-10-06 12:17:41,Wrap my own API library in a GPT-like based chatbot,motorollo,False,0.62,2,171ati0,https://www.reddit.com/r/learnmachinelearning/comments/171ati0/wrap_my_own_api_library_in_a_gptlike_based_chatbot/,18,1696594661.0,"Hi everyone!
I am working on a project whose ultimate goal is to be able to chat with a chatbot that after a natural language request returns specific calls to library functions that implement calls to a tool's API.

A bit more into details: I have a tool that can be used by calling its HTTP API. In order to make these calls, I have built a library on top of the API, so as to simplify the calls and make them easier to use. I would like to have a chatbot whose model is trained on the library itself, so that, given a natural language request as input, it returns its translation into the library language. 

My first idea was to use OpenAI API service as a wrapper and eventually try other models in the future if I find a better and/or cheaper custom way to implement the chatbot.

My doubts are mainly 2:
1. Fine-tuning: which is the best way to fine-tune the OpenAI model for this use case?

2. Well formatted calls: how to avoid the chatbot from returning non-existing method calls or classes and stick with what is available in the library?

Any other suggestion outside the scope of the doubts are more than welcome.
Thank you very much in advance for every guy that will read the post."
140,learnmachinelearning,open-ai,comments,2021-01-18 15:30:22,Reinforcement Learning Crash Course (Free),rroocckk,False,0.95,136,kzwso5,https://www.reddit.com/r/learnmachinelearning/comments/kzwso5/reinforcement_learning_crash_course_free/,18,1610983822.0,"I wanted to announce the new and free [Reinforcement Learning Crash Course](https://rlcourse.com).

This course takes a _unique hands-on approach_ to teaching Reinforcement Learning.

- Reinforcement Learning concepts are communicated primarily via code examples (Python, Gym and Keras). 

- Mathematical equations are kept to a minimum. 

Therefore, the course should appeal to you if you like a practical approach to learning, devoid of mathematical pedantry. Plus, you can be an absolute beginner. You don't need any prior machine learning knowledge to understand the content. Machine Learning and Deep Learning concepts are introduced and explained within the course when needed.

This is my attempt at creating a Reinforcement Learning course that **programmers** can love. I am hoping that this further democratizes the amazing capabilities of RL. I have tried to maintain the high standards found in David Silver's course or The Deep RL Bootcamp at Berkeley, but replacing mathematics with code as the main learning UI. I am also inspired by François Chollet's intuitive and code-first approach in his book Deep Learning with Python.

I make the course in my free time, and that allows me to upload 1 video on a new topic per week. The first chapter is already published at the time of this announcement and the rest will come in the next months according to a planned schedule. I have decided that if you enroll now (while the course is being made), it will be **free and you keep all the content forever**. 

In the already published chapter, you will be introduced to Reinforcement Learning basics. This way, you can already take the course for a test drive and see if you like my code-first approach. 

Take a look at the detailed syllabus to find what to expect from later chapters. Briefly speaking, we will take a code-oriented approach to learning classical Reinforcement Learning algorithms like GLIE Monte Carlo, SARSA etc. and Deep RL algorithms like PPO and DQN. We will pay special attention to the following topics: 

- Writing modular and extensible code
- How to make results reproducible
- Logging
- Monitoring
- Best practices for running RL experiments. 

There will also be plenty of practice problems where you will be able to test out your new skills. At the end of the course, you will have solved 5 interesting OpenAI Gym environments, covering everything from classic problems, bipedal walking to playing games. After doing the course, you will be able to confidently apply RL to other problems that catch your fancy.

Thank you for taking the time to read all of this.  The [course page](https://rlcourse.com) has more details."
141,learnmachinelearning,open-ai,comments,2023-04-19 11:39:45,How to Auto-Generate a Summary from Long Youtube Videos Using AI,anabildea,False,0.93,25,12rqb4z,https://www.reddit.com/r/learnmachinelearning/comments/12rqb4z/how_to_autogenerate_a_summary_from_long_youtube/,18,1681904385.0,"**Struggling to find time to watch all those interesting YouTube podcasts and talks?**  
I've found a solution that combines the power of AI and open-source models like Whisper (for transcription) and BART (for summarization) to auto-generate summaries for you.

I've created a step-by-step guide to transcribe and summarize long videos, like Stephen Wolfram's talks, right on your local PC.  
 Check it out and share your thoughts! 

[https://medium.com/towards-data-science/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d](https://medium.com/towards-data-science/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d)"
142,learnmachinelearning,open-ai,comments,2023-11-20 06:33:59,Understanding which laptop will be suitable for my ML needs,abillionasians,False,0.44,0,17ziams,https://www.reddit.com/r/learnmachinelearning/comments/17ziams/understanding_which_laptop_will_be_suitable_for/,17,1700462039.0,"I have to buy a macbook for machine learning. My budget is $2k. It has to be a mac.

My requirements:

I want to run and train ML and AI models. Maybe run open source LLMs like LLAMA. I guess im okay if the training and all is a bit slow, I care more about the results ( and laptop shouldn't be slow during other tasks )

Side question : will cloud services be a better option than training and running LLMs and other models on my mac ? If yes then please guide me."
143,learnmachinelearning,open-ai,comments,2023-12-27 16:57:27,Staff Software Engineer in Bay with 10+ YOE. What’s the best way to learn AI/ML to maintain relevance?,SalamiJack,False,0.89,41,18s59ra,https://www.reddit.com/r/learnmachinelearning/comments/18s59ra/staff_software_engineer_in_bay_with_10_yoe_whats/,17,1703696247.0,"As the title stated, I am a staff software engineer at a large tech company in the Bay Area. My predominant expertise is backend distributed systems.

I work closely with ML and DS engineers, and I always feel out of my depth whenever specifics of our ML models are discussed. Given this and how the technological landscape is shifting so rapidly with AI, I want to do what I can to ensure I maintain relevance in my engineering career.

I don’t necessarily want to transition *now* away from a general backend focus to a ML or AI related role, but I want to set myself up with a deep foundational understanding so that I could easily transition if the need arises.

What is this community’s opinion on structured vs. unstructured learning? I am open to courses, certifications, or post-graduate degrees. I currently have a bachelor’s in CS from 10+ years ago, but my GPA was admittedly terrible, so I worry about my marketability for master’s programs.

Given my current job security, my primary focus is maximizing expertise, with a secondary focus on securing future job prospects."
144,learnmachinelearning,open-ai,comments,2023-12-28 22:20:51,"Why does Google look so dominant in search, but seems to admit that they have no moat with GenAI?",PsychoWorld,False,0.44,0,18t6ced,https://www.reddit.com/r/learnmachinelearning/comments/18t6ced/why_does_google_look_so_dominant_in_search_but/,17,1703802051.0,"Hey everyone.

Background: I studied Cognitive Science, which included some Calculus and data structures in Computer Science. I'm not the MOST technical person there is, but I can comprehend concepts that tap into advanced computer science domains.

1. Google is dominant in online searching. Despite sustained efforts by companies with platform advantages, including Microsoft and Apple (Bing and Siri) attempting to make their search engines better, Google seems far and away the most preferred search engine worldwide.

2. Meanwhile... They seem to admit internally that GenAI isn't a race that they can sustainably win (https://www.semianalysis.com/p/google-we-have-no-moat-and-neither). The have no moat in this.

What is the technical cause of this?

I'm unfamiliar with the technical reasons for why they're so much better in search, but ChatGPT seems to think it's due to their data advantage and focus on user experience. But I'm still not sure why that cannot be overcome. Is search technology much more reliant on one aspect of tech infrastructure that cannot be overcome by other companies, whereas LLMs are dependent on open-source tech and data, and thus can be improved upon easily?

Is deep learning why they're so much better?"
145,learnmachinelearning,open-ai,comments,2023-06-14 09:08:23,"Introducing, OpenLLM 🎉",AaZasDass,False,0.96,87,149302y,https://www.reddit.com/r/learnmachinelearning/comments/149302y/introducing_openllm/,15,1686733703.0,"OpenLLM allows you to run inferences with any open-source LLMs, deploy to the cloud or on-premises, and build powerful AI apps. It includes simple and familiar APIs, enabling easy integration with tools such as LangChain, and BentoML! Discover more at [https://github.com/bentoml/OpenLLM](https://github.com/bentoml/OpenLLM)

To get started, install it with pip: `pip install -U openllm`  Currently, it has support for all major SOTA LLMs, including Falcon, ChatGLM, Dolly V2, StableLM, and more to come!

Some of the feature that is currently wip:

\- Fine-tuning API with `LLM.tuning()`

\- LangChain integration [https://github.com/hwchase17/langchain/pull/6064](https://github.com/hwchase17/langchain/pull/6064)

\- OpenAI Compatible API

    import openai
    
    openai.api_base = ""http://localhost:3000"" # Running with OpenLLM
    
    completion = openai.Completion.create(...)

We are currently actively developing the library, so we would love to hear your thoughts and feedback. Feel free also to join our [discord](https://l.bentoml.com/join-openllm-discord) to meet other fellows, AI application builders, and enthusiasts."
146,learnmachinelearning,open-ai,comments,2020-05-26 02:46:48,Artificial intelligence grad program comparison,kookookachoo17,False,0.96,80,gqostb,https://www.reddit.com/r/learnmachinelearning/comments/gqostb/artificial_intelligence_grad_program_comparison/,17,1590461208.0,"Hello all!

This is a career/education-oriented post, so if it's in the wrong spot I apologize and will be happy to move it.

TLDR: recent CS grad, trying to figure out a better grad program. One is more general and has a wider focus but isn't entirely AI-focused, and the other is more narrowly focused on NLP. Thoughts?


I am a recent undergrad computer science graduate, and I'm currently looking at two (and possibly more, I'm open to online programs as well but would prefer one of these) AI-focused graduate programs in NJ. 

One is the MSCS at Monmouth University, with a focus in Database and Intelligent Systems. Here is the program:

https://catalog.monmouth.edu/graduate-catalog/science/computer-science-software-engineering/computer-science-ms-databases-intelligent-information-systems-non-thesis-track/

I'm also considering the MS in Computational Linguistics from Montclair State University: 

https://www.montclair.edu/graduate/programs-of-study/computational-linguistics-ms/

I've already been accepted to the Monmouth University program, but my concern is that it doesn't contain enough in depth theory. The program offers additional AI courses aside from the required ones, but I'm not sure it will be enough to gain a competitive amount of knowledge. Conversely, the Computational Linguistics program at Montclair is very in depth, but narrowly focused on NLP.

 I AM very interested in NLP, but also find computer vision fascinating and worry about pigeonholing myself into a niche field, vs having a more general master's w/ an AI track. If it matters, I don't have current plans to pursue a PhD. Does anyone have any recommendations/experience with this sort of choice, should I look at other programs instead of these, etc.? Sorry for the wall of text and thanks in advance!"
147,learnmachinelearning,open-ai,comments,2023-09-16 13:22:41,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.95,133,16k7heb,https://www.reddit.com/r/learnmachinelearning/comments/16k7heb/this_week_in_ai_all_the_major_ai_developments_in/,17,1694870561.0,"1. **Stability AI** launched Stable Audio, a generative AI tool for music & sound generation from text. The underlying latent diffusion model architecture uses audio conditioned on text metadata as well as audio file duration and start time.
2. **Coqui** released **XTTS** \- a new voice generation model that lets you clone voices in 13 different languages by using just a quick 3-second audio clip.
3. **Microsoft Research** released and open-sourced **Phi-1.5** \- a 1.3 billion parameter transformer-based model with performance on natural language tasks comparable to models 5x larger.
4. **Project Gutenberg**, Microsoft and MIT have worked together to use neural text-to-speech to create and release thousands of **human-quality free and open audiobooks**.
5. Researchers present **NExT-GPT -** an any-to-any multimodal LLM that accepts inputs and generate outputs in arbitrary combinations of text, images, videos, and audio.
6. **Chain of Density (CoD):** a new prompt introduced by researchers from Salesforce, MIT and Colombia University that generates more dense and human-preferable summaries compared to vanilla GPT-4.
7. **Adept** open-sources **Persimmon-8B**, releasing it under an Apache license. The model has been trained from scratch using a context size of 16K.
8. **Adobe's** **Firefly** generative AI models, after 176 days in beta, are now commercially available in Creative Cloud, Adobe Express, and Adobe Experience Cloud. Adobe is also launching Firefly as a standalone web app.
9. **Deci** released **DeciLM 6B**, a permissively licensed, open-source foundation LLM that is 15 times faster than Llama 2 while having comparable quality.
10. Researchers release **Scenimefy** \- a model transforming real-life photos into Shinkai-animation-style images.
11. **Microsoft** open sources **EvoDiff**, a novel protein-generating AI that could be used to create enzymes for new therapeutics and drug delivery methods as well as new enzymes for industrial chemical reactions.
12. Several companies including Adobe, IBM, Nvidia, Cohere, Palantir, Salesforce, Scale AI, and Stability AI have pledged to the White House to develop safe and trustworthy AI, in a voluntary agreement similar to an earlier one signed by Meta, Google, and OpenAI.
13. **Microsoft** will provide legal protection for customers who are sued for copyright infringement over content generated using Copilot, Bing Chat, and other AI services as long as they use built-in guardrails.
14. **NVIDIA** beta released **TensorRT** \- an open-source library that accelerates and optimizes inference performance on the latest LLMs on NVIDIA Tensor Core GPUs.
15. Pulitzer Prize winning novelist Michael Chabon and several other writers sue OpenAI of copyright infringement..
16. **NVIDIA** partners with two of India’s largest conglomerates, Reliance Industries Limited and Tata Group, to create an AI computing infrastructure and platforms for developing AI solutions.
17. **Roblox** announced a new conversational AI assistant that let creators build virtual assets and write code with the help of generative AI.
18. **Google** researchers introduced **MADLAD-400** \- a 3T token multilingual, general web-domain, document-level text dataset spanning 419 Languages.
19. A recent survey by **Salesforce** show that 65% of generative AI users are Millennials or Gen Z, and 72% are employed.  The survey included 4,000+ people across the United States, UK, Australia, and India.
20. **Meta** is reportedly working on an AI model designed to compete with GPT-4.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
148,learnmachinelearning,open-ai,comments,2023-10-13 21:02:42,ChatBase Backend: How Does it Work?,Nice-Ad1199,False,1.0,2,1778n3l,https://www.reddit.com/r/learnmachinelearning/comments/1778n3l/chatbase_backend_how_does_it_work/,17,1697230962.0,"Hey all,

I've been building my own ""personal assistant"" using the GPT API and Eleven Labs, and I am finally getting to the fine-tuning portion of everything. That being said, I have been primarily working with fine-tuning GPT directly through the OpenAI documentation, finding some success, but nothing too amazing quite yet.

&#x200B;

That being said, I was pointed to [ChatBase](https://www.chatbase.co/), a website that trains GPT on your data. I am assuming many of you have seen it, but the point is you can put documents, text, Q&A's, and web data which it will then train GPT on. The results are quite good with proper data, but it really doesn't require much to produce results.  


I imagine that they are using the same fine tuning techniques, but I question how they are able to produce such fantastic results with such little information. Perhaps there is something I am missing in the documentation? Does anybody know how one might be able to achieve similar results to a custom ChatBase model through their own GPT fine-tuning data set?"
149,learnmachinelearning,open-ai,comments,2020-06-22 16:11:03,Generating Fake News with OpenAI’s GPT-2 Language Model,dxjustice,False,0.89,13,hdv7mk,https://towardsdatascience.com/creating-fake-news-with-openais-language-models-368e01a698a3#f7e4-509ea6e7d52d,16,1592842263.0,
150,learnmachinelearning,open-ai,comments,2018-04-27 07:22:52,"Karpathy says NNs should avoid regression problems (in favor of classification). Yet in Q-Learning, the function approximator is often an NN, even when the action space is discrete (and Q-Learning could be converted to a classification problem). Is CS231n correct?",Frozen_Turtle,False,0.99,42,8f9tes,https://www.reddit.com/r/learnmachinelearning/comments/8f9tes/karpathy_says_nns_should_avoid_regression/,16,1524813772.0,"From https://cs231n.github.io/neural-networks-2/ (emphasis mine):

>It is important to note that the L2 loss is much harder to optimize than a more stable loss such as Softmax. Intuitively, it requires a very fragile and specific property from the network to output exactly one correct value for each input (and its augmentations). Notice that this is not the case with Softmax, where the precise value of each score is less important: It only matters that their magnitudes are appropriate. Additionally, the L2 loss is less robust because outliers can introduce huge gradients. ***When faced with a regression problem, first consider if it is absolutely inadequate to quantize the output into bins.*** For example, if you are predicting star rating for a product, it might work much better to use 5 independent classifiers for ratings of 1-5 stars instead of a regression loss. Classification has the additional benefit that it can give you a distribution over the regression outputs, not just a single output with no indication of its confidence. If you’re certain that classification is not appropriate, use the L2 but be careful: For example, the L2 is more fragile and applying dropout in the network (especially in the layer right before the L2 loss) is not a great idea.

Outliers are not an issue in RL, which leaves only this:

>L2 loss is much harder to optimize than a more stable loss such as Softmax. Intuitively, it requires a very fragile and specific property from the network to output exactly one correct value for each input (and its augmentations).

I don't know what what the above means: What is a property? Why is it fragile? What is an augmentation? If you have any answers or know any links that discuss this issue, please let me know.

The typical Q-learning function approximator predicts (continuous) q-values, on which the agent acts ε greedy. In RL problems with discrete action spaces, is it wise to modify the Q-learning algorithm to directly predict actions instead of Q-values? Or should I stick with ε-maxing over ""unstable"" q-values? 

Anyway, even though regression may be less stable than classification, it seems to work anyway if we throw enough episodes at it :)

---

Post nap realization:

David Silver discusses 3 types of value function approximators [here](https://youtu.be/UoPei5o4fps?t=522):

1) Input is the state, output is the value function.

2) Input is the state and action, output is a q value.

3) Input is the state, output is the q value for every action.

All types could be interpreted as regression NNs. However, through a certain lens and also by using loose definitions, type 3 is a classification NN. When I speak about classification and regression NNs, here's what I have in mind:

* classification NNs typically have an output node for each class. The last layer's activation function is typically a softmax.

* regression NNs typically have one output node with no activation function, aka the linear activation function.

Value function approximators type 1 and 2 look like regression NNs. Type 3 looks kiiiiiinda like a classification NN. It has an output node for each action, and predicts q-values, which technically makes it a regression. But since the next step in the Q-learning algorithm is a ε greedy action, the *system* of the NN+ε greedy is choosing an action, this effectively makes it a classification style NN. It is classifying which action to take given the state.

Anyway, Silver says their DQNs use type 3 in solving the Atari problems, so I'll probably use that in my attempts to solve OpenAI's gyms. If anyone wants to criticize my realization here, please do so! I hardly consider this a closed issue.

---
---
---

# Links I've found discussing NN and regression problems

Many links seem to ignore or fail to mention the above advice from CS231n:

* https://www.reddit.com/r/learnmachinelearning/comments/7j2l4o/what_do_i_have_to_change_for_a_neural_network_to/

* https://www.quora.com/Can-Deep-Learning-and-Neural-Networks-be-useful-for-regression-problems-where-the-output-variable-has-an-unknown-or-varying-in-real-time-upper-bound

* https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/

* https://www.reddit.com/r/learnmachinelearning/comments/65sh1x/creating_a_deep_neural_network_regression_model/

* https://www.quora.com/Can-Deep-Learning-and-Neural-Networks-be-useful-for-regression-problems-where-the-output-variable-has-an-unknown-or-varying-in-real-time-upper-bound

In particular, the DQN implementations I've seen all predict Q-values and not actions (even if the action space is discrete), such as:

* https://jaromiru.com/2016/10/03/lets-make-a-dqn-implementation/

* https://github.com/dennybritz/reinforcement-learning/blob/master/DQN/Deep%20Q%20Learning%20Solution.ipynb"
151,learnmachinelearning,open-ai,comments,2024-01-03 01:17:54,What libraries should I become proficient in as a machine learning engineer?,Bbpowrr,False,0.89,15,18x6eu9,https://www.reddit.com/r/learnmachinelearning/comments/18x6eu9/what_libraries_should_i_become_proficient_in_as_a/,16,1704244674.0,"I do MLE / DS at a big 4 firm, and have been doing so for about 2 years. I have experience with implementing some pretty cool solutions using the following libs:
- open AI (gpt & embedding models)
- huggingface
- faiss
- scikit-learn

I also have a 1st class CS degree from a Russell group uni and have done some ML projects during my degree.

But I have never had to / been taught how to use libraries such as TensorFlow or PyTorch or Keras in any ML project that I have implemented. Usually I use the scikit-learn library for model development.

However, I see a lot of jobs specifically asking for TensorFlow or PyTorch or Keras.

Therefore, I was wondering whether it is necessary to start upskilling in one or all of these libraries/frameworks to become a well established MLE? And if so, what is the best way to learn them?



Also, with my current skill set, how do I fair in the job market for MLE / DS roles? Ik it's not much to go off but any guesses would be appreciated.

For context, I have experience with using the following types of models:
- GPT / embedding
- ensemble (Random Forest, XGBoost, AdaBoost)
- computer vision (OCR)
- Clustering (cus Weka)
- SVM
- Naive Bayes
- Logistic regression 
- decision trees 

I think an obvious gap is a lack of neural networks / CNNs - does this matter much?

Many thanks for any advice!"
152,learnmachinelearning,open-ai,comments,2023-09-23 13:42:22,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.96,184,16q4ve6,https://www.reddit.com/r/learnmachinelearning/comments/16q4ve6/this_week_in_ai_all_the_major_ai_developments_in/,16,1695476542.0,"1. **Genmo** releases a new text-to-video model: **Genmo Replay** v0.1, which generates high-quality videos from text without the need for advanced prompt engineering. *Genmo is available for free to create AI videos* \[[*Details*](https://blog.genmo.ai/log/replay-ai-video) | [Genmo *Replay*](https://www.genmo.ai/)\] .
2. **OpenAI** unveils **DALL·E 3** \- a major update to the text-to-image model, which will be integrated in ChatGPT. It will be available to ChatGPT Plus and Enterprise users in October, via the API and in Labs later this fall. Creators can now also opt their images out from future training.
3. **Toyota Research Institute** has developed a technique, powered by generative AI, that enables teaching robots new manipulation abilities in a single afternoon. Using the same robot, same code, and same setup, TRI taught over 60 different dexterous behaviors like peeling vegetables, using hand mixers, preparing snacks, and flipping pancakes.
4. **Microsoft** announced:
   1. Availability of AI Copilot for Windows from September 26th. Copilot will incorporate the context and intelligence of the web, your work data and what you are doing in the moment on your PC to provide better assistance. It will be integrated in Windows 11, Microsoft 365, Edge and Bing.
   2. Bing will add support for DALL.E 3 and deliver more personalized answers based on search history.
   3. New AI powered experiences in Paint, Photos and Clipchamp.
   4. New AI-powered shopping experience
5. **ElevenLabs** released **Projects** \- a tool that lets you generate an entire audiobook at the click of a button. Projects now supports .epub, .pdf, and .txt file imports, as well as initializing a project from a URL.
6. **Deci** presents **DeciDiffusion 1.0** \- an open-source text-to-image latent diffusion model which is 3x faster than Stable Diffusion v1.5 with the same quality.
7. **Google researchers** present a new approach that produces photo-realistic animations from a single picture. The model is trained on automatically extracted motion trajectories from a large collection of real video sequences.
8. **Google** has updated Bard\*\]\*:
9. **Bard Extensions:** With extensions, Bard can now connect to your Google apps and services like Gmail, Docs, Drive, Google Maps, YouTube, and Google Flights and hotels.
10. Users can use Bard’s “Google it” button to more easily double-check its answers and evaluate whether there is content across the web to substantiate it.
11. Bard can now let you continue chat via **shared public links**
12. **YouTube** announces new AI tools for creators. **Dream Screen** will let users create an AI-generated video or image background from text. Automatic AI-dubbing tool called **Aloud**, which will be integrated into YouTube Studio. **AI-powered insights** to generate video ideas and draft outlines. **Assistive Search in Creator Music** where AI will suggest the right music based on your description of your content.
13. **Amazon** announced that its voice assistant Alexa is being upgraded with a new, custom-built large language model.
14. **IBM** open-sources **MoLM** \- a collection of ModuleFormer-based language models ranging in scale from 4 billion to 8 billion parameters. ModuleFormer is a new neural network architecture based on the Sparse Mixture of Experts (SMoE) by IBM researchers. .
15. **Neuralink**, Elon Musk's brain implant startup, set to begin human trials.
16. **Lexica** has released **Aperture v3.5** \- their latest next-gen image model that can create photorealistic images and follows your prompt with precision.
17. **OpenAI** has invited domain experts to collaborate in evaluating and improving the safety of OpenAI's models by joining the new **OpenAI Red Teaming Network**.
18. \*\*GitHub Copilot Chat (\*\*beta) is now available for all individuals.
19. **Replit** announced a virtual hackathon for projects built using **Replit ModelFarm**
20. **Oracle** brings voice-activated AI to healthcare with Clinical Digital Assistant.
21. **Google** and the Department of Defense are building an AI-powered microscope to help doctors spot cancer.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
153,learnmachinelearning,open-ai,comments,2023-10-09 21:43:30,How feasible is it to train AI on an existing game? Or is there a basis for training AI on an existing game?,Ok-Instruction-8624,False,0.9,28,1743xhj,https://www.reddit.com/r/learnmachinelearning/comments/1743xhj/how_feasible_is_it_to_train_ai_on_an_existing/,16,1696887810.0,"I'm an undergrad student but have very little experience with machine learning. I'm fond of online fighting games, but noticed that many smaller games do not have AI/singleplayer modes. Some are open source, so I was wondering if I could mod one to set up an environment to try training AI. It's more for fun than something realistic. A long time ago, I set one up with an AI that would only do random moves, but did not get much farther before life made me take a break. I still have the code and my notes about getting specific data/triggering moves/how the game works. It would be the ideal one to start with, and is a smaller 2d fighting game with very simple graphics. However, I want to make sure its even feasible before attempting to create a machine learning environment.

My main worry is that using an existing game to train would be too resource intensive or would take too much time due to game code generally being complicated compared to other tasks. While I know it varies based on game specs/computer specs, I was curious if there was any basis for people using a game to train AI without building the game from the ground up. Are there any good guidelines I could check to see if a game is simple enough for training, or am I almost always better off recreating a game from the ground up to reduce resource use? "
154,learnmachinelearning,open-ai,comments,2023-03-20 18:42:54,[D] How do OpenAI and other companies manage to have real-time inference on model with billions of parameters over an API?,RaunchyAppleSauce,False,0.84,4,11wrdse,https://www.reddit.com/r/learnmachinelearning/comments/11wrdse/d_how_do_openai_and_other_companies_manage_to/,16,1679337774.0,"Hi, guys

I have been using OpenAI’s chatgpt through the app Poe and I find it very confusing how a model with billions of parameters is responding in real-time over an API.

How does one go about making inference fast, say 15-20ms, over an API for large models?

Thanks!"
155,learnmachinelearning,open-ai,comments,2019-08-11 14:32:04,`gpt2-client`: A New Wrapper for GPT-2,rish-16,False,0.84,4,coxeko,https://www.reddit.com/r/learnmachinelearning/comments/coxeko/gpt2client_a_new_wrapper_for_gpt2/,16,1565533924.0,"Hey everyone 👋🏻

I recently built a wrapper for OpenAI's \`gpt-2\` model called \`gpt2-client\`. Currently, the \`gpt-2\` repo is archived and the code is messy and riddled with bugs. My wrapper simplifies the entire process by enabling anyone to get started with text generation models without the fuss.

&#x200B;

[This is how it looks like](https://preview.redd.it/ookaj95lytf31.png?width=1584&format=png&auto=webp&s=efaea7da8edc03136c627223a2d71ff6a4ef0c73)

Please do go check it out here:

[https://github.com/rish-16/gpt2client](https://github.com/rish-16/gpt2client)

If you like it, a ⭐️ on GitHub would be highly appreciated! It's my first ever Python module I've released and am really excited about it.

If you run into any bugs, please do file an issue and if you have any suggestions or enhancements, please do file a PR with a short description of your awesome improvement.

Cheers!"
156,learnmachinelearning,open-ai,comments,2023-01-05 02:06:03,Would it be realistic to be able to write an A.I. with Python and Tensorflow that can write unique stories using certain inputs within the span of 1-3 months starting as a beginner in A.I. programming?,learningmoreandmore,False,0.5,0,103mfri,https://www.reddit.com/r/learnmachinelearning/comments/103mfri/would_it_be_realistic_to_be_able_to_write_an_ai/,15,1672884363.0,"For context, I have over three years of experience as a programmer. This doesn't just include studying but also in a work environment.

I've been looking into how to approach and what datasets I can use to train it but I'm honestly going in blind. I'm considering using Python and Tensorflow. Is it realistic for me to be able to do something like this in 1-3 months?

I was initially planning on using the Open AI API but it's way to costly and honestly I already wrote the code for it generally and don't feel like I'll improve much as a programmer if I continue by using the API. I'm considering pivoting as a programmer anyways and figured I might as well tackle this head on while using it for my business."
157,learnmachinelearning,open-ai,comments,2023-03-28 12:51:54,I am creating a tool that uses OpenAI models and an OCR to translate screenshots,K-RT-DEV,False,0.86,36,124nsy8,https://www.reddit.com/r/learnmachinelearning/comments/124nsy8/i_am_creating_a_tool_that_uses_openai_models_and/,15,1680007914.0,"Currently, the OCR is specifically for translating from Japanese, but I plan to add a range of OCRs and different translators to the system to accommodate the user's needs.  


https://i.redd.it/8ymk99uf8hqa1.gif

My idea is to have a system that leverages OpenAI models for *bagging*. This way, I can combine the output of multiple OCRs  to increase the accuracy of the recognized characters. Similarly, I can combine the output of multiple translators for the same phrase to improve the final result . Chat models can be particularly useful in providing **context** and a translation history to help the system understand how to conjugate phrases for translation.   


You can find the source code and an executable version on the [project's GitHub](https://github.com/K-RT-Dev/VGT)"
158,learnmachinelearning,open-ai,comments,2023-09-12 13:42:02,This is why LLMs have flooded the NLP market in the past 1 year 👇 (A Brief History of NLP),japkeerat,False,0.82,43,16grq5y,https://www.reddit.com/r/learnmachinelearning/comments/16grq5y/this_is_why_llms_have_flooded_the_nlp_market_in/,15,1694526122.0,"Text Generation has been the hottest topic in Natural Language Processing. Recurrent Neural Networks (RNNs) were among the Algorithms to generate text. How RNNs generated text is by essentially predicting the next word given the previous few words. At one-stage RNNs were the hottest commodity one could have. But researchers were worried about 1 problem.

RNNs had a context-length problem. To understand what is context-length, consider an analogy. You started reading a book, it’s 100 pages long and when you read each page, details of previous pages start to get a little hazy. Haziness keeps on increasing to the point that when you reach page 50, you don’t remember anything from the first 5 pages. That is exactly what the problem is with RNNs.

To solve this, researchers developed another algorithm called the Long-Short Term Memory (LSTM) and another variant called Bidirectional Long-Short Term Memory (Bi-LSTM) which had a larger context-length than RNNs. Let’s get back to the book analogy. This time while reading, you are making notes. When you go ahead to a new page and your previous pages information start to get hazy, you look back at these notes to refresh your memory. It’s oversimplified, but that’s basically how an LSTM works.

LSTMs were not perfect. There were a number of new issues that came up in order to resolve the previous one. Meanwhile, other areas of research and technological advancements were heating up. Hardware was getting more and more prominent and with cloud getting popular, it was easily accessible. And on the research side, a new kind of Algorithm came up that shaped the entire NLP domain from here on - Attention Mechanism.

Attention Mechanism, as you might have guessed, is all about telling the more sophisticated algorithms where to “focus”. It’s the same way how we focus more on certain parts of the meeting we attend than the entire meeting itself. In context of NLP, the Mechanism became the core part for better algorithms. These better algorithms could keep larger context-lengths and at the time of predicting the next word, ask the Attention Mechanism about what to focus on while predicting the next word. This was an era-defining discovery in NLP as the algorithms that came up after this were the Transformers.

Consider jigsaw puzzles. You start by looking at all the pieces at once and join the pieces together. Initially, it is random. You join a couple of pieces at the top left corner, a few in the centre and a couple more defining the right edge. You are doing it all at once. Transformers basically work the same way. They could look at longer context-lengths, all at once, courtesy of Attention Mechanism. This means, they can not only work with a sentence, they can work with an entire paragraph.  With time, these Transformers started becoming more and more sophisticated. It eventually reached to a point that the only thing that was keeping these algorithms in handcuffs was the lack of data.

Until recently, these algorithms were trained on a specific data but when algorithms became too powerful, researchers started throwing every kind of data they could find on the internet easily. It could be articles like this, your social media posts, exam papers and solutions, and ebooks in any language they could find and hoped the algorithms learnt it all. And they were right. Algorithms started learning all of it to the point that you could ask models to explain concepts of LLMs in how Shakespeare would write and it would give a real-sounding responsive. These algorithms were Large! And hence, became known as Large Language Models (LLMs).

There we are now. With LLMs. OpenAI, technically, won the race for LLM development. They brought everybody’s attention to LLMs first with GPT-2, but GPT-3 was where shit hit the roof and every company that had deep pockets started investing in LLMs.  The result? We now have a new LLM getting released EVERY. SINGLE. DAY.

*I post articles like these every few days on X. If you like this post, please* [follow me on X!](https://twitter.com/JapkeeratS/)

*NOTE: To make it simple for anybody, even without a tech background, to understand, a few things were oversimplified. I will be sharing soon on* [my X handle](https://twitter.com/JapkeeratS) *a technical version.*"
159,learnmachinelearning,open-ai,comments,2019-05-16 23:01:12,Learning Machine Learning Resources,rhklite,False,0.99,248,bpjh2a,https://www.reddit.com/r/learnmachinelearning/comments/bpjh2a/learning_machine_learning_resources/,14,1558047672.0,"I collected a bunch of machine learning resources for my self studying, thought I'd share it here, could be of use to other people.

&#x200B;

* ★ are resources that were highly recommended by others
* **tags:**    `course` ,   `book` ,   `git-repo` ,   `blog-post` ,   `video` ,   `cheat-sheet` ,   `list`

## Machine Learning

* [Coursera Machine Learning, Andrew Ng](https://www.coursera.org/learn/machine-learning)   `introductory course`  ★
* [Introduction to Computational Thinking and Data Science](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/)   `introductory course`
* [Machine Learning MIT Open Courseware](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/)   `course`
* [Amazon AWS Machine Learning Course](https://aws.amazon.com/training/learning-paths/machine-learning/)   `course`
* [Virgilio - Mentor for Data Science E-Learning](https://github.com/virgili0/Virgilio)   `course`

&#x200B;

* [Machine Learning Yearning - Andrew Ng](https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf)   `book`   ★
* [Mathmatics for Machine Learning, Marc Peter Deisenroth](https://mml-book.github.io/)   `book`
* [The Hundred-page Machine Learning Book, Andriy Burkov](http://themlbook.com/wiki/doku.php)   `book`
* [Model Based Machine Learning](http://mbmlbook.com/toc.html)  `book`
* [Coursera Machine Learning - Python Code, JWarmenhoven](https://github.com/JWarmenhoven/Coursera-Machine-Learning)   `git-repo`
* [Coursera Machine Learning - Python Code, kaleko](https://github.com/kaleko/CourseraML)   `git-repo`
* [Coursera Machine Learning - Python Code, dibgerge](https://github.com/dibgerge/ml-coursera-python-assignments)   `git-repo`
* [Machine Learning Git Codebook](https://www.reddit.com/r/learnmachinelearning/comments/ax6ep5/machine_learning_git_codebook_case_study_of/?utm_medium=android_app&utm_source=share)  `git-repo`

&#x200B;

* [A Complete Machine Learning Project Walk-Through in Python](https://morioh.com/p/b56ae6b04ffc/a-complete-machine-learning-project-walk-through-in-python)  `blog-post`
* [What's the best ML Paper you read in 2018?](https://www.reddit.com/r/MachineLearning/comments/a6cbzm/d_what_is_the_best_ml_paper_you_read_in_2018_and/)   `blog-post`
* [Seeing Theory](https://seeing-theory.brown.edu/basic-probability/index.html)   `blog-post`
* [The most complete chart of Neural Networks, explained](https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464)   `blog-post`
* [The Machine Learning cheat-sheet](https://github.com/remicnrd/ml_cheatsheet)   `cheatsheet`

## Deep Learning

* [Fast.ai Online Course](https://www.fast.ai/)  `course`  ★
* [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/2017/)   `course` ★
* [CS230: Deep Learning](https://cs230.stanford.edu/)   `course`
* [Google Machine Learning Crash Course with TensorFlow APIs](https://developers.google.com/machine-learning/crash-course/)   `course`
* [MIT Deep Learning](https://www.youtube.com/watch?v=O5xeyoRL95U&list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf)   `course`
* [Deep Learning - An MIT Press Book, Ian Goodfellow](http://www.deeplearningbook.org/)   `book` ★

&#x200B;

* [TensorFlow.js - Real-Time Objection Detection in 10 Lines of Code](https://hackernoon.com/tensorflow-js-real-time-object-detection-in-10-lines-of-code-baf15dfb95b2)  `blog-post`

&#x200B;

* [Build a TensorFlow Image Classifier in 5 Min](https://www.youtube.com/watch?v=QfNvhPx5Px8)   `video`

&#x200B;

* [Deep Learning cheat-sheets covering Stanford's CS 230 Class](https://stanford.edu/~shervine/teaching/cs-230/)   `cheat-sheet`
* [cheat-sheets for AI, Neural Nets, ML, Deep Learning & Data Science](https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-science-pdf-f22dc900d2d7)   `cheat-sheet`
* [Tensorflow-Cookbook](https://github.com/taki0112/Tensorflow-Cookbook)   `cheat-sheet`

&#x200B;

* [Deep Learning Papers Reading Roadmap](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap)   `list`  ★
* [Papers with Code](https://paperswithcode.com/sota)  `list`  ★

## Reinforcement Learning

* [CS294-112 Deep Reinforcement Learning](http://rail.eecs.berkeley.edu/deeprlcourse/)   `course`
* [CMPUT 609 Reinforcement Learning - Rich Sutton](https://drive.google.com/drive/folders/0B-WvrETGtkesN29sV1g3aXZ1Z0U)   `course`
* [Deep RL Bootcamp](https://www.youtube.com/watch?v=qaMdN6LS9rA&list=PLPfj7W0fIrmy3MfjPFbpy7jFGDmvspgHE)   `course`
* [Reinforcement Learning Crash Course](https://www.youtube.com/watch?v=sOiNMW8k4T0)   `course`

&#x200B;

* [Reinforcement Learning: An Introduction Richard, S.Sutton 2ndED 2018](http://incompleteideas.net/book/the-book-2nd.html)   `book`  ★

&#x200B;

* [Open AI Spinning Up](https://spinningup.openai.com/en/latest/index.html)   `github repo` ★
* [OpenAI - Gym](https://github.com/openai/gym/wiki)  `git-repo`
* [Stable Baseline: a Fork of OpenAI Baselines - Reinforcement Learning Made Easy](https://stable-baselines.readthedocs.io/en/master/)   `git-repo`
* [PyGame Learning Environment](https://pygame-learning-environment.readthedocs.io/en/latest/)   `git-repo`
* [S-RL Toolbox](https://s-rl-toolbox.readthedocs.io/en/latest/guide/rl.html)   `git-repo`

&#x200B;

* [Google AI Blog](https://ai.googleblog.com/2019/02/long-range-robotic-navigation-via.html?fbclid=IwAR2p5UBtLyXG1Dru5-zW_lnnZF3u3T03U3XF7_2jqBZY6h3ijeIzqmYuEpI)   `blog-post`  ★
* [An introduction to Q-Learning: Reinforcement Learning](https://medium.freecodecamp.org/an-introduction-to-q-learning-reinforcement-learning-14ac0b4493cc)   `blog-post`
* [Introduction: Reinforcement Learning with Open AI Gym](https://towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2)   `blog-post`
* [An intro to Advantage Actor Critic methods](https://medium.freecodecamp.org/an-intro-to-advantage-actor-critic-methods-lets-play-sonic-the-hedgehog-86d6240171d)   `blog-post`
* [Double Q-Learning, the Easy Way](https://towardsdatascience.com/double-q-learning-the-easy-way-a924c4085ec3?fbclid=IwAR17Ht_oyJL4_1AHTqcwf1EU1RziGgRrwTskKY1xRlpLLd3T7_NKMK_V6-g)   `blog-post`
* [A Beginner's Guide to Reinforcement Learning](https://skymind.ai/wiki/deep-reinforcement-learning)   `blog-post`
* [Papaers that criticize Deep Reinforcement Learning](https://www.reddit.com/r/MachineLearning/comments/bdgxin/d_any_papers_that_criticize_deep_reinforcement/)   `blog-post`

## Artificial Intelligence

* [Techniques in Artificial Intelligence (SMA 5504) MIT Open Courseware](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-825-techniques-in-artificial-intelligence-sma-5504-fall-2002/index.htm)  `course`
* [CS 188 - Introduction to Artificial Intelligence - UC Berkeley](https://inst.eecs.berkeley.edu/~cs188/fa18/)  `course`
* [Artifical Intelligence: Foundataions of Computational Agents, 2ndED 2017](https://artint.info/2e/html/ArtInt2e.html)   `book`

## Others

* [Awesome public datasets](https://github.com/awesomedata/awesome-public-datasets)   `list`
* [100+ Basic Machine Learning Interview Questions and Answers](http://theprofessionalspoint.blogspot.com/2019/01/100-basic-machine-learning-interview.html)   `blog-post`"
160,learnmachinelearning,open-ai,comments,2022-09-26 06:48:01,Is CUDA / NVIDIA still required for modern day machine learning?,nxtfari,False,0.96,30,xobnhm,https://www.reddit.com/r/learnmachinelearning/comments/xobnhm/is_cuda_nvidia_still_required_for_modern_day/,14,1664174881.0,"Hey all!

I was up to date with SOTA ML/AI up until maybe about 2019, when I switched tracks into embedded CS for a while. I'm now trying to get back into ML and looking for a Linux machine to learn and do small-time training on.

Even back in 2019, I know Colab / Paperspace was an option, but I really just personally learn better when my code is running on my machine and I can debug problems then and there. The only thing is: back then, I had a machine with an AMD GPU, and remember being so frustrated that it seemed like half of all ML tools required CUDA to even work, with no option for OpenGL or even CPU based calculation. So I was wondering: is that still true? I'm primarily interested in computer vision depth estimation, localization, mapping, and reinforcement learning. How is it out there if you don't have an NVIDIA GPU?

All input is appreciated!"
161,learnmachinelearning,open-ai,comments,2023-06-26 12:23:07,"Best way to cost effectively ""upload"" a large PDF to a language model so that you can ask questions about it?",RepresentativeNet509,False,1.0,8,14jfvq8,https://www.reddit.com/r/learnmachinelearning/comments/14jfvq8/best_way_to_cost_effectively_upload_a_large_pdf/,13,1687782187.0," I have a 400 page PDF and need to get it into a language model (cost effectively) and then be able to ask the model questions about the document like ""on what page does the scope summary begin"" or ""are there any prohibitions to participate in this solicitation due to the size of respondent's business"".

I have been able to use ""Ask My PDF"" to upload part of the PDF to ChatGPT and this basically gives the outcome I want for the pages that are uploaded, but it invariably crashes every time and there is no way to pick up where the uploading of pages left off.

I am fairly technical; would NanoGPT be a better solution for this? I am also looking at fine-tuning a model on OpenAI's API, but that seems cumbersome and expensive for my use case.

Any thoughts are appreciated!"
162,learnmachinelearning,open-ai,comments,2023-12-28 19:48:58,Where do you find people you can constantly bother about technical issues.,uforanch,False,0.93,24,18t2qe0,https://www.reddit.com/r/learnmachinelearning/comments/18t2qe0/where_do_you_find_people_you_can_constantly/,13,1703792938.0,"Alright. I'm a former math academic. I've taken courses online for Deep Learning and NLP. I get the gist of it, generally. I know the math, I know what's happening, etc. I am currently trying to get to something original by making models from books and keras's site and then adapting them to other things. 

I'm running into a lot of weird issues.  Too many to get into here. Like my model will get the opposite results of the book, or won't predict on input it's supposed to, there's warnings being raised every command, etc. 

I've been to code meetups and have some software oriented friends. I generally don't find a lot of people into AI who aren't super busy and have time to just answer questions of ""How am I getting this error"". Most people don't even really want to do much besides send prompts to an openAI API, whereas I want to showcase I can build and use these models. 

Where do you find someone who can actually help or answer questions. Is there a notable discord or some space where I'm more likely to meet someone who can answer questions? 

&#x200B;"
163,learnmachinelearning,open-ai,comments,2023-08-21 07:54:44,Steps to get into AI Development,_Powski_,False,0.5,0,15x0vti,https://www.reddit.com/r/learnmachinelearning/comments/15x0vti/steps_to_get_into_ai_development/,13,1692604484.0,"Hello.  
In my free time i want to dive a little into ai development. I have not much time, but a few hours during the week and few more on the weekend to learn. I am pretty good with c#, know some dart, java and scala.  
I have an idea for an app that is in my mind for a long time now. And now with the raise of AI it could be possible to build. I know that it will take me a long time but as a hobby project i would like to tackle that.   
*A similar question could have been already asked here but because i am new in this field i don't really know how the answer to my problem would look like.*

&#x200B;

Problem? I don't know where to start with learning AI Development. I could just google and start with some courses or tutorials but i dont want to spend weeks on learning something that wasn't even needed for the thing i want to do, but i wasn't understanding it so i didn't know.  


Can someone tell me what would be the best way to start and what exact thing i need to learn. ( I know how to build apps, just the ai part is missing for me)  


What i want to achieve:   
1. Users can upload short texts in the app(1000 words).  
2. Other users can choose texts and then ask questions about the text.  
3. Only information related to the chosen text is given. No need for the app to know anything else.   


Now i know that it would be possible to somehow work with the openAI API and somehow solve the problem with that. But would that be the best solution? Would it be possible even somehow without an internet connection just on the users device? Let the app learn the text and answer questions about that with a local LLM? 

So please can you give me a small guide where to start learning. Please also keep in mind that its only a hobby project for me and that i only want to learn the things i actually need for that."
164,learnmachinelearning,open-ai,comments,2022-04-13 16:27:40,Is there a way for neural network to mimic the way the brain stores memory?,x_m_n,False,1.0,2,u2u8l5,https://www.reddit.com/r/learnmachinelearning/comments/u2u8l5/is_there_a_way_for_neural_network_to_mimic_the/,13,1649867260.0,"Dislaimer: I'm a novice at both brain anatomy and neural network so please pardon any misunderstandings I have.

&#x200B;

From what I understand, the brain stores memory via connections between neurons. All the types of memory (scent, touch, feel, taste, vision, etc...) are just a certain set of neurons firing together. The more the memory is repeated/reinforced, the stronger the connections between those neurons, and they're more likely to be recalled (in tact). The more something is done, the more strengthen its neural pathways and eventually it becomes the equivalent of hardware accelerated process where you don't need to ""process"" and just do it.

Versus a computer/neural network stores memory in ... dedicated memory units. Variables, with data types. The connections between the neurons are for processing, not for storing memory.

Is there a way/neural network model that mimics the way the brain stores memory?

Also, just like how the brain have different regions that does different tasks, like the hippocampus stores memory, the left/right side of the brain does rationale/artistic, the frontal lobe does impulse control/decision making, the brain stem controls the limbs, olfactory recognizes smell, etc... is there certain neural network models that specialize in those tasks specifically? Or it just depends on which data set the neural network is trained on?

Are most of the neural network in use/research at the moment just a really expansive bunch of nodes with a bunch of inputs without any specialized areas? Or the specialized areas are activated based on which input is fed in? There's that neural network by OpenAI that does a bunch of things because it has tons of input nodes (again, can't remember the name. my hippocampus needs a jolt).

Just need some help conceptualize them all.

Thank you."
165,learnmachinelearning,open-ai,comments,2022-06-26 11:59:58,"TMT: A KISS library to keep track of experiments, results and code",levnikmyskin,False,0.98,131,vl36ro,https://www.reddit.com/r/learnmachinelearning/comments/vl36ro/tmt_a_kiss_library_to_keep_track_of_experiments/,13,1656244798.0,"Hi everyone!

This past week I had a bit of free time and decided to work on this library I've had in mind for some time now. I'm doing a PhD in Computer Science (mainly working with text classification) and too many times I've seen research projects losing track of the experiments ran, their metrics, their results and the code used to produce them.

While there are available libraries at the moment to do this, such as [Weights & Biases](https://wandb.ai/site) or [Modelchimp](https://github.com/ModelChimp/modelchimp), I wanted a library which could be as simple as possible, both for the user and the developer, and completely free...a library based on the [KISS](https://en.wikipedia.org/wiki/KISS_principle) principle. My idea is that the researcher/user of the library should also be able to easily adjust and modify the source code of the library, should they feel the need.

This project was done both for fun and for satisfying a real need, creating a library which does the bare minimum but hopefully right (do one thing, do it right).

That's why I've just published [That Metric Timeline (TMT)](https://github.com/levnikmyskin/that_metric_timeline) as an open-source project on Github.

TMT is available on the PyPI index and can be installed with

    pip install ThatMetricTimeline

`tmt` also provides an old-fashioned terminal user interface (TUI), which should be available as `tmt_tui` in your python path once you installed it.

Using `tmt` should be pretty straightforward. Once you installed the library, you can do:

    from tmt import tmt_recorder
    
    @tmt_recorder(name=""some_experiment"")
    def train_and_predict(x_tr, y_tr, x_te, y_te):
        lr = LogisticRegression()
        lr.fit(x_tr, y_tr)
        preds = lr.predict(x_te)
        return {'f1': f1_score(y_te, preds), 'accuracy': accuracy_score(y_te, preds)}  

The `tmt_recorder` decorator will save this experiment with the name you provided, also saving the metrics associated with it (the dictionary returned by your function) and taking a snapshot backup of your code. You may also save results at any time with the `tmt.tmt_save` function:

    from tmt import tmt_recorder, tmt_save
    
    @tmt_recorder(name=""some_experiment_with_data"")
    def train_and_predict(...):
        ...
        preds = lr.predict(x_te)
        tmt_save(preds, name='lr_predictions')
        return {'f1': f1_score(y_te, preds), 'accuracy': accuracy_score(y_te, preds)}  

You can look for the experiments saved using the `tmt` TUI (have a look at the [Github readme](https://github.com/levnikmyskin/that_metric_timeline#tui) for more information, if you're interested). You can then use the `tmt.TmtManager` helper to load results and more:

    from tmt import TmtManager
    
    # Let's say we know there is an experiment with id ""example""
    
    
    # An Entry is a row in the database, i.e. an experiment that was tracked.
    manager = TmtManager()
    manager.set_entry_by_id('example') 
    
    # load the results and unpickle them
    for name, path in manager.results_paths():
        with open(path, 'rb') as f:
            # do stuff with your results. If it's a pickle it's 
            # more convenient to use the code block below this one
            res = pickle.load(f)
    
    # load the unpickled results
    for name, res in manager.load_results():
        # do something with your results.
        # if res is a numpy array...
        print(res.mean())
    
    
    for name, val in manager.get_metrics():
        print(f""{name}: {val}"")  

That's basically it, but I recommend reading the Github readme for a more complete explanation. Also, notice this library was born pretty quickly in around one week, documentation is basically lacking everywhere (but I plan to serve it on readthedocs at some point). I would love to hear feedback (positive and negative) on this if you have any :)

Cheers!"
166,learnmachinelearning,open-ai,comments,2022-10-19 09:27:38,Fixing YouTube Search with OpenAI's Whisper,jamescalam,False,0.95,78,y7xxri,https://www.reddit.com/r/learnmachinelearning/comments/y7xxri/fixing_youtube_search_with_openais_whisper/,13,1666171658.0,"Hi all, I wanted to [build a ""YouTube search"" app](https://www.pinecone.io/learn/openai-whisper/) for some time. Not the typical YouTube search where you return videos, but a YouTube search that returns the specific part of a video that answers your question. With text-based data this is pretty easy, but video/audio is less so.

That was until OpenAI (open sourced?) Whisper, a new SotA for speech-to-text. So I went ahead and built [""Ask YouTube""](https://huggingface.co/spaces/jamescalam/ask-youtube). A little search bar where you can ask technical questions and get the exact most relevant part from a set of videos (for now, the video scope is limited, I'll add more soon).

I explained everything I did to build it in [the linked article](https://pinecone.io/learn/openai-whisper/) and [video](https://youtu.be/vpU_6x3jowg). You could also just grab the app code and replicate it, I don't think it would take long. At a high level it is:

* Download YouTube audio with `pytube`
* Transcribe with OpenAI's Whisper
* Do some data prep
* Encode using Hugging Face / sentence-transformers
* Index and query with Pinecone vector DB

Then I wrapped all of this into a quick Streamlit web app and hosted it all for free on Hugging Face Spaces. One somewhat surprising thing here is absolutely everything was either open source or free, I didn't pay a dime!

Anyway, I hope this is interesting. Let me know what you think!"
167,learnmachinelearning,open-ai,comments,2023-05-18 13:36:49,Few shot learning to make gpt4 dumb,mr_dark_matter,False,0.43,0,13kzfxk,https://www.reddit.com/r/learnmachinelearning/comments/13kzfxk/few_shot_learning_to_make_gpt4_dumb/,13,1684417009.0,"If  gpt4 can be made to learn things by zero/few shot learning, is it not  vulnerable to exploits to make it dumb? Few shot learning to make it do  incorrect things. Done this at scale over distributed accounts, gpt4  will become dumb.

Is this really possible? If true, what is OpenAI doing to mitigate this?"
168,learnmachinelearning,open-ai,comments,2023-01-27 14:51:14,Fine-tuning open source models to emulate ChatGPT for code explanation.,awesomequantity,False,0.88,85,10mmofg,https://www.reddit.com/r/learnmachinelearning/comments/10mmofg/finetuning_open_source_models_to_emulate_chatgpt/,13,1674831074.0,"I'm looking to step up my game and emulate ChatGPT for specific use-cases like explaining code. I'm thinking about using open source models like GPT-J, or OPT to get beyond the limitations of the closed-source nature of ChatGPT, like the amount of text it can read or respond with.

I got the funding for training, hardware, etc, and I want the end product to be on-premises, so no worries there. The inference doesn't have to be super fast either. I know there are projects like OpenAssistant and petals.ml but haven’t made enough research just yet.

One option I’m considering is using fine tuners like the one from [HuggingFace](https://github.com/subhasisj/HuggingFace-Transformers-FineTuning) or [Jina AI](https://github.com/jina-ai/finetuner) to fine-tune open source models like GPT-J or OPT to improve specific use-cases like code explanation. With the funding that we have, I wouldn’t want to cheap out on fine-tuning and expect something good.

So, can anyone help out and point me in the right direction? Which model is the best to fine-tune and how do I fine-tune to improve specific use cases? Any help would be appreciated. Thanks!"
169,learnmachinelearning,open-ai,comments,2023-06-03 14:33:38,This week in AI - all the Major AI development in a nutshell,wyem,False,0.98,117,13zeoi3,https://www.reddit.com/r/learnmachinelearning/comments/13zeoi3/this_week_in_ai_all_the_major_ai_development_in_a/,13,1685802818.0,"1. The recently released open-source large language model **Falcon LLM**, by UAE’s Technology Innovation Institute, is now royalty-free for both commercial and research usage. **Falcon 40B,** the 40 billion parameters model trained on one trillion tokens, is ranked #1 on **Open LLM Leaderboard by Hugging Face**.
2. **Neuralangelo**, a new AI model from Nvidia turns 2D video from any device - cell phone to drone capture - into 3D structures with intricate details using neural networks..
3. In three months, JPMorgan has advertised **3,651 AI jobs** and sought a trademark for **IndexGPT**, a securities analysis AI product.
4. **Google** presents **DIDACT** (​​Dynamic Integrated Developer ACTivity), the first code LLM trained to model real software developers editing code, fixing builds, and doing code review. DIDACT uses the software development process as training data and not just the final code, leading to a more realistic understanding of the development task.
5. Researchers from **Deepmind** have presented ‘**LLMs As Tool Makers (LATM)**’ - a framework that allows Large Language Models (LLMs) to create and use their own tools, enhancing problem-solving abilities and cost efficiency. With this approach, a sophisticated model (like GPT-4) can make tools (where a tool is implemented as a Python utility function), while a less demanding one (like GPT-3.5) uses them.
6. **Japan's government** won't enforce copyrights on data used for AI training regardless of whether it is for non-profit or commercial purposes.
7. *‘Mitigating the* ***risk of extinction from AI*** *should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.’ -* One sentence statement signed by leading AI Scientists as well as many industry experts including CEOs of OpenAI, DeepMind and Anthropic.*.*
8. Nvidia launched ‘**Nvidia Avatar Cloud Engine (ACE) for Games**’ - a custom AI model foundry service to build non-playable characters (NPCs) that not only engage in dynamic and unscripted conversations, but also possess evolving, persistent personalities and have precise facial animations and expressions.
9. **OpenAI** has launched a trust/security portal for OpenAI’s compliance documentation, security practices etc..
10. **Nvidia** announced a new AI supercomputer, the **DGX GH200,** for giant models powering Generative AI, Recommender Systems and Data Processing. It has 500 times more memory than its predecessor, the DGX A100 from 2020.
11. Researchers from Nvidia presented **Voyager**, the first ‘LLM-powered embodied lifelong learning agent’ that can explore, learn new skills, and make new discoveries continually without human intervention in the game Minecraft.
12. The a16z-backed chatbot startup **Character.AI** launched its mobile AI chatbot app on May 23 for iOS and Android, and succeeded in gaining over **1.7 million new installs** within a week.
13. Microsoft Research presents **Gorilla**, a fine-tuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls.
14. **OpenAI** has trained a model using process supervision - rewarding the thought process rather than the outcome - to improve mathematical reasoning. Also released the full dataset used.
15. **WPP**, the world's largest advertising agency, and Nvidia have teamed up to use generative AI for creating ads. The new platform allows WPP to tailor ads for different locations and digital channels, eliminating the need for costly on-site production.
16. **PerplexityAI’s** android app is available now, letting users search with voice input, learn with follow-up questions, and build a library of threads.

**If you like this news format**, you might find my  [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with **bite-sized news, learning resources and selected tools**. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
170,learnmachinelearning,open-ai,comments,2022-10-27 14:51:50,CROWDLAB: open-source tools for data labeled by multiple annotators,cmauck10,False,0.95,55,yeu074,https://www.reddit.com/r/learnmachinelearning/comments/yeu074/crowdlab_opensource_tools_for_data_labeled_by/,12,1666882310.0,"Hi Redditors! Many of us in machine learning use multiple annotations to get higher quality labels for our data — yet AFAIK there is no open-source python package for **data labeled by multiple annotators** — so we [built one](https://docs.cleanlab.ai/stable/tutorials/multiannotator.html), [benchmarked it](https://cleanlab.ai/blog/multiannotator/), and released [the CROWDLAB paper](https://cleanlab.github.io/multiannotator-benchmarks/paper.pdf).

[CROWDLAB produces a consensus label, confidence, and annotator score for data labeled by multiple annotators.](https://preview.redd.it/oo5351711dw91.png?width=1630&format=png&auto=webp&s=8e7824276093577e81719de7dfd69fced8505b40)

After many long nights, I'm psyched to share the new easy-to-use and effective CROWDLAB algorithm that can use **any classifier** to estimate:

1 - A **consensus label** for each example that aggregates the individual annotations.

* more accurate than aggregation via majority-vote and common crowd-sourcing algorithms

2 - A **quality score for each consensus label** which measures the confidence that the consensus is correct.

* uses well-calibrated estimates that account for the: number of annotations for each example and their agreement, prediction-confidence from a trained classifier, and trustworthiness of each annotator vs. the classifier

3 - A **quality score for each annotator** which estimates the overall correctness of their labels.

**Surprise!** All 3 tasks are estimated in one line of open-source code via [cleanlab.multiannotator.get\_label\_quality\_multiannotator](https://docs.cleanlab.ai/stable/tutorials/multiannotator.html) .

    from cleanlab.multiannotator import get_label_quality_multiannotator  
    
    get_label_quality_multiannotator(multiannotator_labels, pred_probs)  
    # multiannotator_labels: matrix with rows = examples, columns = annotator labels, NA = missing label 
    # pred_probs: predicted class probabilities from any trained classifier

Extensive benchmarks on real-world multi-annotator data show that CROWDLAB produces significantly better estimates for all three tasks than algorithms from crowdsourcing like: majority-vote, GLAD, Dawid-Skene, etc.

Using simple weighted ensembles rather than complex generative models makes CROWDLAB results easy to understand, efficient, and reproducible. An added benefit — CROWDLAB also works well for datasets that include examples with a single annotation (useful for folks who have a tight data labeling budget 😉).

* Blog post: [https://cleanlab.ai/blog/multiannotator/](https://cleanlab.ai/blog/cleanlab-v2.1)
* Paper: [https://cleanlab.github.io/multiannotator-benchmarks/paper.pdf](https://cleanlab.github.io/multiannotator-benchmarks/paper.pdf)
* Tutorial: [https://docs.cleanlab.ai/stable/tutorials/multiannotator.html](https://docs.cleanlab.ai/stable/tutorials/multiannotator.html)
* Benchmarks: [https://github.com/cleanlab/multiannotator-benchmarks](https://github.com/cleanlab/multiannotator-benchmarks)
* Code: [https://github.com/cleanlab/cleanlab](https://github.com/cleanlab/cleanlab)

Have fun using CROWDLAB!"
171,learnmachinelearning,open-ai,comments,2018-07-21 10:52:01,Advice and Suggestions needed on my Roadmap to Machine Learning/AI Pro,aka_ab31,False,0.93,14,90ohlm,https://www.reddit.com/r/learnmachinelearning/comments/90ohlm/advice_and_suggestions_needed_on_my_roadmap_to/,12,1532170321.0,"I found out recently that ML and AI has interested me so much. I have decided to take up a career in it. Before we begin, I would like to tell a few things about myself that might help you in assisting me better.  I am guy who loves to learn stuff but the bad part is I don't put enough time to learn them  fundamentally. I get bored with watching lengthy videos online and jump into the project directly without learning the basics properly and learn what's only necessary or most times just google up the problem/error and get it done. I have always expected quick results and gave up easily when they don't happen. I have understood that it won't be of any use in ML/AI learning. So I have decided to create a  roadmap and follow it to become a ML/AI pro. I am really bad at Math.. I was good at programming but stopped practising it.. So it is better to call myself a noob in both programming and Math.  I am including the links to the courses if anybody would like to follow. The  ' | ' means that I will work on it simultaneously.

1. [Python for Everybody from Coursera](https://www.coursera.org/specializations/python) | [Code Academy Python Tutorials](https://www.codecademy.com/learn/learn-python) | [Sentdex Python Tutorials](https://www.pythonprogramming.net)
2. [Trignometry from Khan Academy](https://www.khanacademy.org/math/trigonometry) | [Pre Calculus from UCI Open](http://ocw.uci.edu/courses/math_1a1b_precalculus.html)
3. [Calculus from Khan Academy](https://www.khanacademy.org/math/calculus-home) | [Single Variable Calculus from MIT](https://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010/index.htm)
4. [Multi Variable Calculus from Khan Academy](https://www.khanacademy.org/math/multivariable-calculus) | [Multi Variable Calculus from MIT](https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/)
5. [Linear Algebra from Khan Academy](https://www.khanacademy.org/math/linear-algebra) | [Linear Algebra from MIT](https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/)
6. [Mathematics for Machine Learning from Coursera](https://www.coursera.org/specializations/mathematics-machine-learning)
7. [Statistics from Khan Academy](https://www.khanacademy.org/math/statistics-probability) | [Introduction to Probablity and Statistics from MIT](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/) | [Statistics from Udacity](https://in.udacity.com/course/statistics--st095) | [Introduction to Probablity and Data](https://www.coursera.org/learn/probability-intro)
8. [Data Structures from Coursera](https://www.coursera.org/learn/data-structures) | [Intro to Algorithms from Udacity](https://in.udacity.com/course/intro-to-algorithms--cs215) | [Algorithms from Coursera](https://www.coursera.org/specializations/algorithms)
9. [Machine Learning from Coursera](https://www.coursera.org/learn/machine-learning) | [Intro to Machine Learning from Udacity](https://in.udacity.com/course/intro-to-machine-learning--ud120-india) | [Foundations of Machine Learning by Bloomberg](https://bloomberg.github.io/foml/#home) 
10. [Learning from Data from Caltech](https://work.caltech.edu/lectures.html#lectures)
11. Kaggle Competitions | Hacker Rank | Other ML applications and Projects
12. [Intro to AI from Udacity](https://in.udacity.com/course/intro-to-artificial-intelligence--cs271) | [Deep Learning from Coursera](https://www.coursera.org/specializations/deep-learning) | [Fast AI](https://www.fast.ai)
13. [Advanced Machine Learning from Coursera](https://www.coursera.org/specializations/aml) | [Machine Learning from Tensorflow on GCP](https://www.coursera.org/specializations/machine-learning-tensorflow-gcp)

I am planning do it this time without giving up. I am taking the courses of same level from different platforms to get better exposure and understanding. I will skip the parts that are the same. What do you guys think? Do you think it is a overkill?  Are the courses in the right order? Will it help me get good knowledge on ML/AI? Feel free to leave your advice or suggestions.

I will be able to dedicate 30-35 hours per week towards this. Assuming me to be a slow learner, how long would it take for me to have good command in ML/AI?

 Apart from these I also wish to learn MatLab, LabView, Tableau and R.  Thank you for taking the time to read this post. "
172,learnmachinelearning,open-ai,comments,2022-12-12 19:17:50,"A web application tool for improving your written communication features paraphrasing, grammar checking, and text summarizing tool built with OpenAI API.",Austin_Nguyen_2k,False,0.93,28,zk8gr7,https://v.redd.it/95jm43veoi5a1,12,1670872670.0,
173,learnmachinelearning,open-ai,comments,2023-12-16 15:26:30,Is there any alternative for OpenAI API?,CrazyProgramm,False,0.84,9,18jti72,https://www.reddit.com/r/learnmachinelearning/comments/18jti72/is_there_any_alternative_for_openai_api/,12,1702740390.0, So I am from Sri Lanka and our university is going to organize a competition and we need OpenAI API for it but we don't have money to afford it. Is there any alternative API you guys know 
174,learnmachinelearning,open-ai,comments,2021-09-21 19:13:07,Need some advice for starting out in this field,AlreadyOwnMyself,False,0.9,49,pspq0f,https://www.reddit.com/r/learnmachinelearning/comments/pspq0f/need_some_advice_for_starting_out_in_this_field/,12,1632251587.0,"Hello, long time lurker here who has been dabbling on and off with ML (watched some courses and tried my take at some projects).

But I can't help feeling that I've yet to grasp a lot of the essential concepts. I've not followed any study plan and feel like even though I majored in CS my math skills are kind of rusty.

Thus, I tried my best at creating a small study guide.

1. Prerequisites
   1. [3Blue1Brown - Essence of Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)
   2. [3Blue1Brown - Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)
   3. Stats and Python libs -> [Think stats 2nd ed.](https://greenteapress.com/wp/think-stats-2e/)
2. Basics Machine Learning
   1. [Machine Learning Course by Andrew Ng](https://www.coursera.org/learn/machine-learning)
3. Deep learning
   1. [fast.ai - Free Courses (Practical Deep Learning for Coders)](https://course.fast.ai/)

However I'm not sure how good it actually is :)

Do you think it's a good way to approach this? Is this a good enough basis to start building upon? (I'm thinking of going more in-depth with the understanding after finishing this)

I was thinking to also include [Mathematics for machine learning](https://mml-book.github.io/) and [OpenIntro stats](https://www.openintro.org/book/os/) for prereqs as well as Stanford courses for DL but I don't want to over-do it (and end up with a huge list that just feels demotivating).

Or maybe I'm having the wrong expectations and I should expect things to take a lot of time?

Any help is more than appreciated :D"
175,learnmachinelearning,open-ai,comments,2022-07-04 23:32:55,Trying to get my computer set up for ML,LoveLaika237,False,1.0,30,vrkdhh,https://www.reddit.com/r/learnmachinelearning/comments/vrkdhh/trying_to_get_my_computer_set_up_for_ml/,12,1656977575.0,"Hi, sorry, I'm not sure if this question is totally appropriate here, but since it is related to machine learning, I thought to ask here. I don't really have anywhere else to turn to. As a beginner to machine learning, I'm trying to get my environment set up for [TensorFlow](https://docs.microsoft.com/en-us/windows/ai/directml/gpu-tensorflow-wsl) and [PyTorch](https://docs.microsoft.com/en-us/windows/ai/directml/gpu-pytorch-wsl) following these sets of instructions. For this, I'm running a WSL2 Ubuntu distribution using Intel graphics (not an external GPU), but I'm having trouble getting it set up. Following the instructions got me the results shown below when trying to verify each installation.

* Tensorflow Verification Code

&#8203;

    import tensorflow.compat.v1 as tf
    tf.enable_eager_execution(tf.ConfigProto(log_device_placement=True))
    print(tf.add([1.0, 2.0], [3.0, 4.0]))

* Tensorflow Results

&#8203;

    I tensorflow/stream_executor/platform/default/dso_loader.cc:97] Successfully opened dynamic library libdirectml.0de2b4431c6572ee74152a7ee0cd3fb1534e4a95.so
    
    I tensorflow/stream_executor/platform/default/dso_loader.cc:97] Successfully opened dynamic library libdxcore.so
    
    I tensorflow/core/common_runtime/dml/dml_device_cache.cc:250] DirectML device enumeration: found 0 compatible adapters.
    
    I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
    2022-07-04 16:55:36.133454: I tensorflow/core/common_runtime/eager/execute.cc:571] 
    
    Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0
    tf.Tensor([4. 6.], shape=(2,), dtype=float32)

* PyTorch Verification Code

&#8203;

    import torch
    tensor1 = torch.tensor([1]).to(""dml"")
    tensor2 = torch.tensor([2]).to(""dml"")
    dml_algebra = tensor1 + tensor2
    dml_algebra.item()

* PyTorch Results

&#8203;

    Segmentation Fault at tensor1 = torch.tensor([1]).to(""dml"")

It seems that with TensorFlow, maybe my computer isn't suitable for it given the results. Is this correct? With PyTorch, it's odd that it seg faulted on such a simple verification run. Could there be something strange about running PyTorch on WSL2? Would it be better to run this on Windows instead?"
176,learnmachinelearning,open-ai,comments,2024-01-13 22:36:40,Book suggestion: AI: A Modern Approach vs Pattern Recognition and Machine Learning,neural-learner,False,0.76,6,1960885,https://www.reddit.com/r/learnmachinelearning/comments/1960885/book_suggestion_ai_a_modern_approach_vs_pattern/,11,1705185400.0,"Hi there, I am an undergraduate student who has been interning in the area for the past 2 years. Though I can build projects, I lack a lot of the theory and I want to go all in the theory, possibly pursue an academic career -a research-related career at the very least. I am mainly interested in computer vision. I want to get a book that will largely provide the theory. People suggested the famous ""Artificial Intelligence: A Modern Approach"" by Stuart Russel and ""Pattern Recognition and Machine Learning"" by Christopher M. Bishop. Which one would be a better pick? I am also open to other book suggestions.

PS: I know that the question is largely about AI and CV and might be outside of the topic of this subreddit but this is the best subreddit for learning in the field."
177,learnmachinelearning,open-ai,comments,2023-09-28 15:50:53,Work asked me to tell them which PC to buy for me - Suggestions? plshelp,sim0of,False,0.92,19,16ujluo,https://www.reddit.com/r/learnmachinelearning/comments/16ujluo/work_asked_me_to_tell_them_which_pc_to_buy_for_me/,11,1695916253.0,"Hello everyone,

I have been working as a junior developer in this company for some months now

I have been using my own Acer Nitro 5 17"" (i7 11800h, RTX 3060 Laptop 6GB, 16GB Ram)

So far I've been involved in projects with computer vision, audio and nlp

This is an entirely new branch for the company and I'm still a student at the beginning of my journey, therefore there is no ""standard modus operandi"" for doing things and basically I'm the one responsible for telling them what piece of hardware is best for my needs

Anything that involves training we just rent GPUs from the major providers so I'm definitely not worrying about that

Things I will definitely be working on

\- OpenAI API integration  
\- NVIDIA NeMo framework  
\- YOLO  
\- Langchain, elastic and similars

&#x200B;

Since I've been busy studying and learning stuff I've never really bothered looking into hardware requirements for any of the things I've done/will do

Does the hardware choice matter in this case?  


They proposed me a laptop with i7 12th gen, 16GB Ram, and RTX4050 which costs 1k euros

I told them to hold off and that I would have done some further research because that doesn't look like a solid investment in my opinion

&#x200B;

**What (I think) I know:**

Budget I assume is something in the 1k - 2k range but they really just care about giving me something that allows me to provide good results

\- Pretty much when running models locally for testing and developing, they will run on a GPU, which I assume has to be powerful. But how powerful is powerful enough? 4060? 4080? 4090? Do mobile CPUs even make sense?  
\- I notices some dockerized services take up a fair bit of my current CPU, so is it coherent to assume that a more recent CPU with more cores and pretty much more power would be beneficial for my work?  
\- 16GB Ram nowadays is barely enough for google chrome with a few extensions so I don't really have any doubts that going for 32GB is a reasonable enough upgrade  
\- I work both at home, at the office and around the world when I'm in WFH mode, so a laptop would seem a better option than a Desktop PC, but is that actually the case?  


**What I don't know**

Aside from the fact that this section worringly overlaps with the ""what I know section""..  
I've only considered Windows laptops onto which I would at the very least make dual boot with linux if not exclusively linux because the NVIDIA NeMo framework can't run on windows

Given what I will do, should I even consider Apple? Like a Macbook Pro M1 or something like that?

  
I already have high end desktop pc at home and my current laptop is already something I'm comfortable bringing around, but one big limitation is that I always need to be plugged into a power source or the battery drains withing one hour of work  
AFAIK a macbook pro would kinda allow me to work anywhere so that'd be a cool quality of life upgrade but I doubt it's practically worth anything other than a ""cool!"" reaction

&#x200B;

As you can see there's a lot of stuff I don't know and I don't really know what I actually need

Thank you so much for any help and suggestion towards the right direction!  
"
178,learnmachinelearning,open-ai,comments,2023-02-18 09:15:07,Useful programming stuff for ML practitioners that aren't ML based,FallUpJV,False,0.94,15,115bbqq,https://www.reddit.com/r/learnmachinelearning/comments/115bbqq/useful_programming_stuff_for_ml_practitioners/,11,1676711707.0,"Hi, sorry for that title but I find it difficult to explain in one sentence.

I just passed my final exams for my AI/ML master's degree (in Europe) and I have a  2 week gap between that and the start of my ML internship.

Not that I got fed up with ML but with all the exams related stress I'd like to use my time for programming stuff that is not necessarily ML based for those 2 weeks but is still useful for an ML engineer.

Most likely what kind of stuff is useful to know in Python for an ML engineer that most don't know or just learn on the go ? DevOps skills ? Functional programming ? C(++) usage for Python ML libraries ?

This is a totally open-ended question, I just want to get my brain a little off all the math I've been learning this year for my degree."
179,learnmachinelearning,open-ai,comments,2019-08-27 14:19:56,[D] What do you use to keep you update on ML/DL?,pirate7777777,False,0.99,215,cw542g,https://www.reddit.com/r/learnmachinelearning/comments/cw542g/d_what_do_you_use_to_keep_you_update_on_mldl/,11,1566915596.0,"Hi everyone! What do you use to navigate-in-the-noise and keep you update in this field? *Excluding this subreddit* which type of resources do you recommend to check regularly?

&#x200B;

Here's my list:

***Newsletters (weekly)***:

\- [ImportAI (@JackClark)](https://jack-clark.net/)

\- [The batch (@Deeplearning.ai)](https://www.deeplearning.ai/thebatch/)

&#x200B;

**Podcast & Video (weekly/monthly)**

\- [Artificial Intelligence Podcast (@Lex Fridman)](https://lexfridman.com/ai/)

\- [Two Minute papers](https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg)

&#x200B;

**Blogs (RSS newsfeed)**

\- [DeepMind](https://deepmind.com/blog)

\- [OpenAI](https://openai.com/blog/)

\- [BAIR](https://bair.berkeley.edu/blog/)

\- [Google AI](https://ai.googleblog.com/)

\- [FAIR](https://research.fb.com/category/facebook-ai-research/)

&#x200B;

**MOOCs (once per year)**

\- [Deep learning for coders p1 & p2 (@fast.ai)](https://course.fast.ai/)

\- [CS231n: DL for CV](http://cs231n.stanford.edu/)

\- [CS224d: DL for NLP](https://cs224d.stanford.edu/)

&#x200B;

**Social (once per day/week)**

\- Twitter & LinkedIn are good quite good sometimes, but too noisy.

\- Facebook groups (such as [AIDL](https://www.facebook.com/groups/DeepNetGroup/)) but most of the time, the articles shared are not really good or particularly useful.

&#x200B;

**Conferences / Events (once per year)**

\- [NIPS](https://nips.cc/)

\- [PyTorch Dev Conference](https://pytorch.fbreg.com/)

\- [TF Dev Summit](https://www.tensorflow.org/dev-summit)"
180,learnmachinelearning,open-ai,comments,2022-03-02 07:36:55,NiceScaler 1.1.0 - Lossless image upscaler app based on OpenCV SuperResolution deeplearning models,jangystudio,False,0.92,52,t4uupo,https://www.reddit.com/r/learnmachinelearning/comments/t4uupo/nicescaler_110_lossless_image_upscaler_app_based/,11,1646206615.0," 

[Gui interface](https://preview.redd.it/van8gewubxk81.png?width=2048&format=png&auto=webp&s=74b087b5cfd8023cd981bad42cf2bcd979a289d4)

I just released the first major update, the version 1.1.0, which includes:

1. Multiple photos upscaling (batch upscaling)
2. More images dropped shows in a list with image counter
3. Complete UI / UX overhaul (using a dark color palette)
4. Stop button to stop upscaling process
5. Speed up image conversion to png
6. Added Paypal button to support the project (and now it's free)
7. Automatically remove duplicates in dropped images
8. General code cleaning, bugfix and improvements

All project is Python based, libraries used are:

1. Tkinter
2. OpenCV
3. PyInstaller

Github here  
\-> [https://github.com/Djdefrag/NiceScaler](https://github.com/Djdefrag/NiceScaler)

Installation.  
NiceScaler does not require any installation, it's a single portable exe usable on any Windows PC

Supported IA backends.  
Actually NiceScaler utilize only CPU to upscale to be compatible with any PC

Features.  
\- Different IA models selection  
\- Drag and drop single image or multiple images  
\- Auto-convert images to .png  
\- Factor x2 upscaling   
\- Simple and clean GUI  
\- Compatible with PNG, JPEG, BMP, WEBP, TIF images  
\- Portable everywhere without installation

Next steps.  
\- Video upscaling  
\- More AI backends (CUDA / OpenCL / Vulkan)  
\- Pre-processing (image/videos downscaling before upscaling)

Feedback.  
Please, give me feedback about the product, i will listen all feedback.

Thank you for your support :)"
181,learnmachinelearning,open-ai,comments,2023-11-22 19:05:16,Made some promises. Now I'm desperately trying to figure out how to conduct very large scale pdf doc analysis.,-rampant,False,0.94,15,181gxg0,https://www.reddit.com/r/learnmachinelearning/comments/181gxg0/made_some_promises_now_im_desperately_trying_to/,11,1700679916.0,"I have about a half million pdfs I need to summarize. Very wide range of types: invoices, diagrams, contracts, emails, letters, pictures, schedules, notices, data sheets, manuals, more. 

Which is... woof. Something else. I've been trying for many hours now to figure out a service/combination thereof that can get me there, but I'm seriously struggling. The *ideal* solution would be to throw the pdfs in and have it return a csv with dates and summaries, maybe parsed out email heading info.

I'm currently running these pdfs through Acrobat OCR now, which its own special hell.

I've tried myriad local and webhosted solutions. The BEST results in what is almost the perfect system for this I found on https://docalysis.com/. Good text results, works in batches, BUT I can only upload a single document at a time. They have a service to do batch processing and so I'm waiting to hear from them now. I imagine at the scale I need it's expensive.

I also got this solution working: https://github.com/mayooear/gpt4-pdf-chatbot-langchain. Seemed solid, I was able to upload a thousand pdfs in a single go, but it would keep returning information from only 2-3 documents. Upload 5? Results for 2-3. Upload a thousand? Results for 2-3. My uneducated guess is that it's hitting the OpenAI API token limit, but maybe not?

I know it's possible, just not whether it's feasible for an end user. Does anyone know a solution to accomplish this?"
182,learnmachinelearning,open-ai,comments,2023-02-15 17:39:58,Why am I learning C++ ?,MeezyintheMountains,False,0.38,0,1133r6o,https://www.reddit.com/r/learnmachinelearning/comments/1133r6o/why_am_i_learning_c/,11,1676482798.0,"Can someone give me a good reason? 

I know Python and it seems like that’s the primary language used for machine learning. But I’m taking an OOP course and it’s taught in C++. I’m always open to learning new things and don’t want to limit myself, so I’m going with it, but I’m finding it to be a somewhat frustrating language to get set up on my computer, let alone learn. I’d love to know more about how it can be helpful for ML/AI so I can focus my learning a bit more."
183,learnmachinelearning,open-ai,comments,2018-07-17 14:58:18,Ready to start a project...now what?,elihusmails,False,0.93,26,8zlttu,https://www.reddit.com/r/learnmachinelearning/comments/8zlttu/ready_to_start_a_projectnow_what/,11,1531839498.0,"I've been through dozens of YouTube videos, online courses, kaggle examples..etc.  I want to start ""stretching my legs"" but I can't find anything that's really interesting.  How do people get going with AI/ML projects once they start building their own systems?  I assume you find some cool data and just start crunching on it.  I'm interested in sports, specifically hockey, but there's not a ton of data and even if there was what would I use it to do?  I thought a ChatBot might be interesting for hockey-related info, but I'm not sure it would keep my interest.

Has anyone else run into this problem?  What did you do to get over it?  Are there open source projects to contribute to?"
184,learnmachinelearning,open-ai,comments,2020-01-13 14:53:09,Reviews on top AI free courses that I've taken,alinrauta,False,0.94,37,eo53wd,https://www.reddit.com/r/learnmachinelearning/comments/eo53wd/reviews_on_top_ai_free_courses_that_ive_taken/,11,1578927189.0,"Last year I've decided to get past the artificial intelligence buzzwords from the media articles and really have a clue about the subject.

The more research I made the more I got intrigued and interested in AI. It baffled me how much AI will impact our lives and I realised this is the field I want to be in.

So, I began searching for learning resources and immersed myself into all kinds of AI related material. This was a normal thing to do since I taught myself how to code and I figured that I can also teach myself at least the basic of AI.

After a few months of taking courses, I will give you my opinion on the most useful free courses I have taken, the ones I'm in progress of finishing and as a bonus the ones I intend to take in the future.

## Courses I've taken

[Intro to Artificial Intelligence](https://classroom.udacity.com/courses/cs271) 

**About the course**   
It's a classic on AI and it happened to be the first course I've ever taken on the subject. It's a comprehensive course that gives you just the right amount of information about all the branches and sub-branches that AI is made of.

**About the teachers**   
The course is taught by two of the greatest advocates of AI:

* Sebastian Thrun: a former associate professor at Stanford University, co-founder of Udacity, led the team that won the 2005 DARPA Grand Challenge and co-developed Street View at Google.
* Peter Norvig: a director of research at Google and co-author of the leading college text in the field - Artificial Intelligence: A modern Approach

**Conclusion**   
I can't recommend it enough. It's definitely a must.

[Elements of AI](https://course.elementsofai.com/)   
**About the course**   
This is a text based course and the aspect I loved the most about it was the fact that it makes you ponder about the role artificial intelligence is going to have in your life. I like the structure of the course and how quickly you can check if you really understood something by taking a quiz.

**About the teachers**   
It's created by Reaktor and the University of Helsinki. It's part of an initiative that wants to encourage as broad a group of people as possible to learn about AI. The goal is to make the course available in all EU languages.

**Conclusion**   
It's a quick and engaging course to take to get the very basics on AI.

[Neural Networks and Deep Learning](https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning)   
**About the course**   
This one is a bit more advanced in terms of knowledge you gain after its completion and it's part of a series of courses on deep learning. I like the fact that it's not getting too technical and you can easily get to understand more advanced nuances tools that are being used in AI, more exactly - deep learning.

**About the teachers**   
The course is taught by the one and only Andrew Ng: co-founder of Coursera, Adjunct Professor at Stanford University and an outspoken AI advocate.

**Conclusion**   
It's the kind of course you need to take if you're serious about learning AI.

[Improving Deep Neural Networks](https://www.coursera.org/learn/deep-neural-network?specialization=deep-learning)   
**About the course**   
This is more of a sequel of the previous course and the purpose is to get your knowledge of deep learning one step further. This is where the magic happens in deep learning because it's more of an empirical process (trial and error) and you need to get a deeper (yeah, that's a pun) understanding before you know what parameters to tweak.

**About the teachers**   
The course is taught by the one and only Andrew Ng: co-founder of Coursera, Adjunct Professor at Stanford University and an outspoken AI advocate.

**Conclusion**   
You really need to take this course if you already had taken the previous one.

[Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning](https://www.coursera.org/learn/introduction-tensorflow)   
**About the course**   
TensorFlow is an open source platform for machine learning and this course is about teaching you how to use TensorFlow in your AI applications. As a coder I really enjoyed this course because it has less theory and more practice into it.

**About the teachers**   
The course is taught by Laurence Moroney who is an AI advocate at Google and also part of the TensorFlow team. For me, he is one of the best teachers I've ever seen.

**Conclusion**   
It's a friendly course for beginners and with lots of hands-on activities.

## In Progress

[Convolutional Neural Networks](https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning)   
**About the course**   
This course touches the concept of computer vision and builds on the knowledge acquired in the previous two courses from the [series](https://www.coursera.org/specializations/deep-learning). I can't wait to finish it and get more understanding of the computer vision field.

**About the teachers**   
The course is taught by the one and only Andrew Ng: co-founder of Coursera, Adjunct Professor at Stanford University and an outspoken AI advocate.

[Convolutional Neural Networks in TensorFlow](https://www.coursera.org/learn/convolutional-neural-networks-tensorflow)   
**About the course**   
This is a sequel of Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning course that I've already taken and things get even more practical in terms of coding which makes it highly appealing for coders.

**About the teachers**   
The course is taught by Laurence Moroney who is an AI advocate at Google and also part of the TensorFlow team. For me, he is one of the best teachers I've ever seen.

[Machine Learning](https://www.coursera.org/learn/machine-learning)   
**About the course**   
This is probably the reference course on Machine Learning. It's by far the longest and the most technical one from all the courses I've taken. I believe it's worth the effort of finishing the course if you are serious about getting a job in AI.

**About the teachers**   
The course is taught by the one and only Andrew Ng: co-founder of Coursera, Adjunct Professor at Stanford University and an outspoken AI advocate.

## Courses I intend to take (BONUS)

[Learn AI With An AI](https://korbit.ai/machinelearning)   
This seems really interesting and it's the next one on my list.

[Introduction to Computer Vision](https://classroom.udacity.com/courses/ud810)   
This course is a great companion for the Intro to Artificial Intelligence course and I hope it will broaden my knowledge on computer vision.

[Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/)   
This one puts more emphasis on the technical side and it's a good fit after you dabbled with TensorFlow.

[Intro to Data Science](https://www.udacity.com/course/intro-to-data-science--ud359)   
One of the most host jobs in the world right now is the Data Scientist, so I think it's really useful to have an idea about the field, which intersects with AI.

I hope these reviews will be useful for you and I can't wait to hear your feedback or the experiences you had with other AI courses.

If you liked this article and want to see more of these, then follow me on [twitter](https://twitter.com/RautaAlin)"
185,learnmachinelearning,open-ai,comments,2022-12-13 17:25:09,Open Source PokerAI based on Pluribus.,Professional-Luck-64,False,0.86,5,zl1aic,https://www.reddit.com/r/learnmachinelearning/comments/zl1aic/open_source_pokerai_based_on_pluribus/,11,1670952309.0," 

As the title states, we are looking to create an open source successor to Pluribus

I myself am a beginner to AI and ML, this isnt a super easy thing i understand but much of the research is done, we know the concept works and it was cheap and fast to train Pluribus (equiv $144 and 8 days on AWS)

Ive made a little discord to act as an organisation hub and place to share info for the project, please let me know if you're interested and ill invite you! :)"
186,learnmachinelearning,open-ai,comments,2023-04-28 16:17:58,ChatGPT Prompt Engineering for Developers free on deeplearning.ai,sunkenwaaaaaa,False,0.85,17,131zare,https://www.reddit.com/r/learnmachinelearning/comments/131zare/chatgpt_prompt_engineering_for_developers_free_on/,10,1682698678.0,Andrew Ng just released a short course on how to use the Open AI api. It is free for now.
187,learnmachinelearning,open-ai,comments,2022-06-29 03:57:49,Open source that takes as input a deep learning model and outputs a version that runs faster in inference. Now faster and easier to use (New release),emilec___,False,0.89,30,vn6chm,https://www.reddit.com/r/learnmachinelearning/comments/vn6chm/open_source_that_takes_as_input_a_deep_learning/,10,1656475069.0,"nebullvm is an open-source library that takes an AI model as input and outputs an optimized version that runs much faster on your hardware, **usually achieving 2 to 5 times faster inference** **without losing accuracy** (benchmarks below for Option A), or even more if you specify that you are willing to sacrifice some accuracy for a lighter model with even lower latency, using compression techniques (Option B, leveraging multiple quantization methods \[1\], soon also pruning \[2\] and more)

[https://github.com/nebuly-ai/nebullvm](https://github.com/nebuly-ai/nebullvm)

nebullvm now supports also PyTorch and TensorFlow backends that, together with the already supported deep learning compilers (including ONNX runtime \[3\], TensorRT \[4\], OpenVINO \[5\], Apache TVM \[6\]), will **optimize how your model is mapped to your hardware**. Together these techniques will allow nebullvm to explore more paths and find the best way to make the most of your hardware's computing capabilities, making inference as fast as it can run.

**You can run nebullvm in just a few lines of code**, and after many requests from users, I simplified the installation of these deep learning compilers. In addition to the option of installing all compilers with a single command, it is now possible to **skip the installation to pull Docker images with compilers already preinstalled**. Discover more [here](https://github.com/nebuly-ai/nebullvm#download-docker-images-with-preinstalled-compilers).

Many more releases are on the way. And if you have questions, ideas and product suggestions, I'm more than happy to discuss them here! And don't forget to leave a small star for all the open-source work to make DL optimization techniques more accessible :)

https://preview.redd.it/pz70l50ahh891.png?width=1480&format=png&auto=webp&s=14c21bfb2a06372451ddce2cc1b1b72226d8b795

\[[1](https://github.com/nebuly-ai/learning-AI-optimization/blob/main/Quantization.md)\] Quantization. Techniques and Concept Map. \[[2](https://github.com/nebuly-ai/learning-AI-optimization/blob/main/Pruning.md)\] Pruning. Techniques and Concept Map. \[[3](https://onnxruntime.ai/)\] ONNX Runtime \[[4](https://developer.nvidia.com/tensorrt#:~:text=TensorRT%2C%20built%20on%20the%20NVIDIA,high%20performance%20computing%2C%20and%20graphics.)\] Nvidia TensorRT \[[5](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)\] Intel OpenVINO \[[6](https://tvm.apache.org/)\] Apache TVM"
188,learnmachinelearning,open-ai,comments,2023-04-01 19:01:32,"How to start in AI: PyTorch, Tensor flow? Or something else?",Magenta_Axolotl,False,0.87,11,128vdnm,https://www.reddit.com/r/learnmachinelearning/comments/128vdnm/how_to_start_in_ai_pytorch_tensor_flow_or/,10,1680375692.0,"Hello everyone, I’m currently studying Mechatronics and Robotics in my third year. I have learned the basic principle of AI and learned how to use Matlab to train Neural Networks, create genetic algorithms and Fuzzy controllers. I have also used openCV. I have a decent programming background in Python. I’m really interested in AI and robotics and would love to peruse it as a career. Can someone point me on the right path to learn ML and DL. I’m thinking of learning how to use Tensor Flow 2 or PyTorch. Is this the right way to start? And what should be the end goal I’m working towards? In other words, what should I learn to be competent."
189,learnmachinelearning,open-ai,comments,2023-05-19 07:08:51,OpenAI Launches ChatGPT App For iOS Users,vadhavaniyafaijan,False,0.88,55,13lnv1e,https://www.theinsaneapp.com/2023/05/chatgpt-app-for-iphone-and-ipad.html,10,1684480131.0,
190,learnmachinelearning,open-ai,comments,2020-08-23 17:50:14,Hi team! I want to share with you a simple Convolutional Neural Network I implemented in vanilla C++ for handwritten digit recognition using the MNIST dataset. I made this some time ago just for learning purposes. I also used OpenGL to visualize how layers and tensors evolves during the training.,anadalg,False,0.97,282,if7n2p,https://www.reddit.com/r/learnmachinelearning/comments/if7n2p/hi_team_i_want_to_share_with_you_a_simple/,9,1598205014.0,"You can download or review the source code at [https://github.com/albertnadal/Tensar](https://github.com/albertnadal/Tensar)

Here is attached a video/demo of the application during the training. 

[CNN implemented in C++\/OpenGL trained with the MNIST dataset](https://reddit.com/link/if7n2p/video/33k3qwhhesi51/player)

You can find the original video in my youtube channel ([https://youtu.be/oCElhUzadaA](https://youtu.be/oCElhUzadaA)), so I encourage you to subscribe to the channel if you are interested in future implementations related to ML and AI. I hope you find it useful to better understand how CNN's works. Thank you!

&#x200B;

Albert,"
191,learnmachinelearning,open-ai,comments,2023-06-19 16:38:37,I wanted to use OpenAI API but it's a paid service. What are alternatives for this?,Beginning-Scholar105,False,0.64,4,14djjsj,https://www.reddit.com/r/learnmachinelearning/comments/14djjsj/i_wanted_to_use_openai_api_but_its_a_paid_service/,10,1687192717.0,I have tried some Open Source Hugging Face LLMs but they are very large in size and also need heavy machine to run those LLMs.  If you know any other alternatives then please let me know.
192,learnmachinelearning,open-ai,comments,2019-10-28 19:54:31,ML Study partner wanted - Are you also bad at self motivating?,Vettriano16,False,0.87,6,doe97p,https://www.reddit.com/r/learnmachinelearning/comments/doe97p/ml_study_partner_wanted_are_you_also_bad_at_self/,10,1572292471.0,"I'm quite new to ML (3/4 months), I'm currently self-teaching Python, Calculus and AI fundamentals from Coursera, Open MIT and various books. I enjoy it and i'm looking forward to the day that I know enough to pivot my career into it.

However...

I'm getting lazy with it more and more frequently as I get to the point where i'm learning enough that the mystery of it is fading. I could definitely use some motivation to keep pushing through and climbing the hill, is anyone at a similar level to me finding the same thing? I think i'd work faster if I was in contact with someone working towards the same goal who could bully me into learning, and i'd be able to offer the same back. Would be cool to collaborate on projects down the road too. Get in touch!"
193,learnmachinelearning,open-ai,comments,2018-05-17 21:23:05,I'm lost - too many resources out there,ReeMann,False,0.92,20,8k7vr4,https://www.reddit.com/r/learnmachinelearning/comments/8k7vr4/im_lost_too_many_resources_out_there/,10,1526592185.0,"Hi friends!
I'm front-end developer with 3y exp, currently also developing in Node. It's been like 2 years since I wanted to learn ML. But there are too many good resources. I really can't decide what to choose, and I don't want to miss anything. Today I saw google crash course, like 2 weeks ago there was microsoft open ai school. fast.ai also introduced new version of their course. There are plenty resources out there and I don't know where to start. Could anybody show me the way? I read https://howicodestuff.github.io/machine_learning/2018/01/12/a-roadmap-to-machine-learning.html and I think it is cool, but I'm afraid I will spent my time on something unnecessary :(
Is there something like big roadmap?"
194,learnmachinelearning,open-ai,comments,2023-10-10 13:31:04,Explained Simply: OpenAI's breakthrough paper about defeating Dota2 world champions!,mngrwl,False,0.33,0,174lahd,https://mngrwl.medium.com/explained-simply-how-a-i-defeated-world-champions-in-the-game-of-dota-2-f3df90d38a70,9,1696944664.0,
195,learnmachinelearning,open-ai,comments,2019-02-23 10:25:23,Best way to label data for object detection,Carvalho96,False,1.0,7,atu3s1,https://www.reddit.com/r/learnmachinelearning/comments/atu3s1/best_way_to_label_data_for_object_detection/,9,1550917523.0,"Good day,

  
So I've got roughly 5k images (4k train, 1k test) for an object detection problem I'm working with, and was wondering if hand drawing bounding boxes for each of the objects for each of the images is really the only way to go about labeling the data? Is this really the way folks at Google, Facebook, Deepmind and OpenAI go about training their models?  


If there is any better way, or a standard ""best practice"" tool to be used for this task, please let me know?

&#x200B;

Thanks!"
196,learnmachinelearning,open-ai,comments,2023-07-07 01:56:23,ML for DIY House Design,No-Dare-7624,False,0.88,17,14st4q5,https://www.reddit.com/r/learnmachinelearning/comments/14st4q5/ml_for_diy_house_design/,9,1688694983.0,"https://reddit.com/link/14st4q5/video/afhad8qnagab1/player

As an architect and computational designer, I've recently ventured into the exciting world of Machine Learning (ML) to bring an innovative touch to DIY house designs. My project, based in Grasshopper, integrates ML in the architectural process to predict the optimal wall/window configurations for desired temperature settings in diverse scenarios.

Starting with a modest dataset (2000 rooms), I developed a stacked ML model, part of a larger project, aiming to democratize house design by aiding DIY enthusiasts. My workflow was all about getting the model running first, even with limited data, and refining it as I gained more understanding and expanded the dataset, which is self-supervised. I'm using Ladybug a grasshopper plugin that it is the way to go for enviromental analysis, so I can generate new data on demand but it takes time to compute.

The most challenging part was predicting optimal configurations when all wall options were not available. I addressed this by merging outputs from the second (predict optimal configuration) and third neural (predict best configuration with aviable walls) networks, assigning more weight to the latter.

With the assistance of OpenAI's GPT-4, especially for Python, I am now focused on generating five times more data and scrutinizing model performance through metrics such as R-squared (0.8144), MSE(0.003), and MAE(0.0454). The best model so far is using Backpropagation and Sigmoid.

As an architect turned ML enthusiast, there's been a steep learning curve, but the journey has been rewarding. I'm keen to hear suggestions, particularly any rules of thumb from seasoned data scientists that could be missing from my toolkit. Looking forward to enriching this exciting intersection of architecture and ML!

Here is a small video of the first attempt of the first neural network that its just predict the solar radation.

[https://www.instagram.com/reel/CuPwUVNArTv/?utm\_source=ig\_web\_copy\_link&igshid=MzRlODBiNWFlZA==](https://www.instagram.com/reel/CuPwUVNArTv/?utm_source=ig_web_copy_link&igshid=MzRlODBiNWFlZA==)"
197,learnmachinelearning,open-ai,comments,2023-05-01 18:53:50,AI model / Open source tool that can read company docs and can answer related questions,x3n0n547,False,0.5,0,134xv5a,https://www.reddit.com/r/learnmachinelearning/comments/134xv5a/ai_model_open_source_tool_that_can_read_company/,9,1682967230.0,"Hi, I am a programmer but have no idea on AI/ML. 

I am doing a research of tools in open source to read internal company wiki and can answer questions related to the information. For example:

* Which team manages the <any project name>?
* Who is the team lead for <team name>?
* What are all the authentication systems used in <project name>?

Is there an open source tool that can do this? I can extract the data from wiki and can arrange it in any necessary format required for the tool/model. Any guidance would be great."
198,learnmachinelearning,open-ai,comments,2022-09-23 13:46:55,Created a GUI for OpenAI's Whisper Using Gradio,ImplodingCoding,False,0.96,70,xly2gp,https://v.redd.it/6djgfjpp4mp91,9,1663940815.0,
199,learnmachinelearning,open-ai,comments,2018-05-29 22:07:52,Summer project ideas focusing on impact,depretechybubble,False,0.78,7,8n36yd,https://www.reddit.com/r/learnmachinelearning/comments/8n36yd/summer_project_ideas_focusing_on_impact/,9,1527631672.0,"I'm an undergraduate 3rd\-year studying ML and I have an upcoming research internship for the summer at a large and respected tech company. I am looking for side project ideas to pursue on the side \(outside of work\). My goal is to finish an impactful project, maybe like a blog post or open source contribution that demonstrates my coding expertise, and then in the fall, apply to AI residency programs and graduate programs. How should I choose an independent summer ML project that focuses on impact, evaluated by something like number of website views or number of stars on github? I guess my question is, what does it take for a blog post to be impactful for the community and meaningful enough for lots of people to be interested? "
200,learnmachinelearning,open-ai,relevance,2023-01-10 11:12:01,Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI,BackgroundResult,False,0.97,451,1087ady,https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion,102,1673349121.0,
201,learnmachinelearning,open-ai,relevance,2024-02-16 09:14:37,Video Generated By OpenAI Sora! New OpenAI Text-To-Video Model,st1275857,False,0.67,2,1as4dzx,https://www.youtube.com/watch?v=KiP05mehXFQ,0,1708074877.0,This entire video is generated by OpenAI sora. It incredible how good it is. RIP to videographer. What do you guys think? 
202,learnmachinelearning,open-ai,relevance,2023-11-23 10:24:00,"Nonfiction authors sue OpenAI, Microsoft for copyright infringement",anujtomar_17,False,0.83,40,181y9sl,https://newyorkverified.com/4324297-nonfiction-authors-sue-openai-microsoft-copyright-infringement/,34,1700735040.0,
203,learnmachinelearning,open-ai,relevance,2023-02-16 10:29:31,OpenAI Has Purchased AI.Com For ChatGPT For $11M,vadhavaniyafaijan,False,0.93,209,113nizs,https://www.theinsaneapp.com/2023/02/openai-purchased-ai-com-domain.html,23,1676543371.0,
204,learnmachinelearning,open-ai,relevance,2023-12-16 15:26:30,Is there any alternative for OpenAI API?,CrazyProgramm,False,0.84,9,18jti72,https://www.reddit.com/r/learnmachinelearning/comments/18jti72/is_there_any_alternative_for_openai_api/,12,1702740390.0, So I am from Sri Lanka and our university is going to organize a competition and we need OpenAI API for it but we don't have money to afford it. Is there any alternative API you guys know 
205,learnmachinelearning,open-ai,relevance,2024-02-17 16:14:04,"OpenAI's NEW AI Model ""SORA"" Just SHOCKED EVERYONE| Text To Video Generator",UseCreative4765,False,0.33,0,1at5hzf,https://youtu.be/CgYfgm7kzJo?si=QkwBGklzUuTNxnzG,0,1708186444.0,
206,learnmachinelearning,open-ai,relevance,2023-07-07 02:38:18,Open AI baiters,Enough_Wishbone7175,False,0.78,8,14su39l,https://www.reddit.com/r/learnmachinelearning/comments/14su39l/open_ai_baiters/,5,1688697498.0,"I really respect the quality work that comes out of Open AI but they get on my nerves a little. Like they are talking about super intelligence being created within a decade??? We literally have no idea what that looks like. I feel like they are just constantly fishing for regulations. Again, I know there are brilliant people there but I can’t help but feel this is an angle play."
207,learnmachinelearning,open-ai,relevance,2023-11-23 01:18:18,[P] An Open Source version of OpenAI Assistants API,louis3195,False,0.8,3,181pbow,https://twitter.com/louis030195/status/1727495156918861836,0,1700702298.0,
208,learnmachinelearning,open-ai,relevance,2023-11-17 01:24:48,OpenAI completions api timeout help,Artistic_Slip_8679,False,1.0,1,17x3d20,https://www.reddit.com/r/learnmachinelearning/comments/17x3d20/openai_completions_api_timeout_help/,0,1700184288.0,"I’ve got an angular/.NET website that is utilizing OpenAI’s completions API and I’m running into a timeout issue. My site has various limitations that basically cause my endpoint to timeout after 60 seconds. Is anyone aware of a way I can store the id of my request and check in on it rather than waiting for it? I’m slightly new to C# and am not sure how I can prevent this timeout without streaming client-side, which I don’t want to do since it’ll expose my API key. Any links, information, tutorials appreciated!"
209,learnmachinelearning,open-ai,relevance,2021-04-17 14:35:34,*Semantic* Video Search with OpenAI’s CLIP Neural Network (link in comments),designer1one,False,1.0,491,msruz1,https://i.redd.it/dlw52klsvqt61.gif,53,1618670134.0,
210,learnmachinelearning,open-ai,relevance,2024-01-19 22:03:14,"Fine Tuning OpenAI CLIP, where am I missing out?",MaintenanceNo5993,False,1.0,1,19av4eh,https://www.reddit.com/r/learnmachinelearning/comments/19av4eh/fine_tuning_openai_clip_where_am_i_missing_out/,0,1705701794.0,"Since past 2 weeks I have been trying to **fine tune CLIP, train CLIP from scratch** on another dataset (MS COCO Captions). But the model is not able to learn anything it gets stuck at `0.1% TOP 1 acc. and 0.5% TOP 5 acc.` on ImageNetV2 dataset zero shot classification from the very first epoch. On looking the output from the very first epoch it starts to give image and text features such that the `image_features @ text_features.T` is full of `-1`

I am using the training code available at `https://github.com/mlfoundations/open_clip/tree/main/src/training`. I have read the paper and was able to make sense of their implementation.

I have searched in the literature, blogs, GitHub issues but haven't found the solution yet. What I have I done:

[x] Read the official paper and set the hyper params as they have mentioned.

[x] Asked on [`r/MachineLearing`](https://www.reddit.com/r/MachineLearning/comments/193gug2/d_fine_tuning_open_clip_model_causes_it_zero_shot/?utm_source=share&utm_medium=web2x&context=3) they advised for using gradient accumulation. I used it keeping batch size as 160, accumulating after step of 1, 200, 300, 400,..., at the end 1 epoch also but same thing was happening even after waiting till the 30th epoch.

[x] Used about 6 GPU days in running various experiments to fix this, 2 V100's 16 GB.

Most of the experiments were done on ViT-B-32 (scratch, pretrained on laion2b_s34b_b79k) and some on ConvNext-Base. 

Code at: https://codepad.site/edit/08t37xxp

Thank You <3!"
211,learnmachinelearning,open-ai,relevance,2023-08-31 15:54:43,OpenAI Function Calling Tutorial,kingabzpro,False,1.0,2,166exjp,https://www.reddit.com/r/learnmachinelearning/comments/166exjp/openai_function_calling_tutorial/,0,1693497283.0,"Learn how OpenAI's new Function Calling capability enables GPT models to generate structured JSON output, resolving common dev issues caused by irregular outputs.

https://www.datacamp.com/tutorial/open-ai-function-calling-tutorial"
212,learnmachinelearning,open-ai,relevance,2023-08-16 11:26:18,OpenAI Notebooks which are really helpful,vishank97,False,0.93,51,15sn6ti,https://www.reddit.com/r/learnmachinelearning/comments/15sn6ti/openai_notebooks_which_are_really_helpful/,2,1692185178.0,"The OpenAI cookbook is one of the most underrated and underused developer resources available today. Here are 7 notebooks you should know about:

1. Improve LLM reliability:  
[https://github.com/openai/openai-cookbook/blob/main/techniques\_to\_improve\_reliability.md](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)
2. Embedding long text inputs:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Embedding\_long\_inputs.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Embedding_long_inputs.ipynb)
3. Dynamic masks with DALLE:  
[https://github.com/openai/openai-cookbook/blob/main/examples/dalle/How\_to\_create\_dynamic\_masks\_with\_DALL-E\_and\_Segment\_Anything.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/dalle/How_to_create_dynamic_masks_with_DALL-E_and_Segment_Anything.ipynb)
4. Function calling to find places nearby:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Function\_calling\_finding\_nearby\_places.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Function_calling_finding_nearby_places.ipynb)
5. Visualize embeddings in 3D:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Visualizing\_embeddings\_in\_3D.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Visualizing_embeddings_in_3D.ipynb)
6. Pre and post-processing of Whisper transcripts:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Whisper\_processing\_guide.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Whisper_processing_guide.ipynb)
7. Search, Retrieval, and Chat:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Question\_answering\_using\_a\_search\_API.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_a_search_API.ipynb)

Big thanks to the creators of these notebooks!"
213,learnmachinelearning,open-ai,relevance,2023-11-08 23:09:05,OpenAI api remember conversation context in Angular,Shacrak4,False,1.0,4,17qyjet,https://www.reddit.com/r/learnmachinelearning/comments/17qyjet/openai_api_remember_conversation_context_in/,1,1699484945.0,"I'm doing an Angular app which uses the chatgpt api to generate interactive stories based on a character and setting which are chosen by the user. I made an intermediary API(with node) to manage the different methods(post/get) and a service to inject my API where it's needed. The story is generated by chunks and in between them, the AI should also generate 3 options, the user chooses one and it would be sent back as a prompt so that the story can continue. I want the AI to remember the whole conversation, as it's really important that it knows how to behave, generate the story and the chunks it already sent. This last bit is where the problem lies, since this is a college project and my budget is really tight(due to national economic problems), I can't afford to make a conversation history and send it back as part of the new prompt because the usage cost would be too high. Is there a way to make the AI remember the conversation without having to always send it back with the new prompt(chosen option)?

Sorry if this is not the place to make this request but at this point I'm kinda desperate"
214,learnmachinelearning,open-ai,relevance,2023-11-08 16:56:45,[P] Top 5 AI Announcements (and Implications) from the 1st OpenAI DevDay,vykthur,False,0.86,5,17qq0z9,https://www.reddit.com/r/learnmachinelearning/comments/17qq0z9/p_top_5_ai_announcements_and_implications_from/,0,1699462605.0,"OpenAI recently had the first   developer day, featuring several new announcements

https://preview.redd.it/ep1scxynm5zb1.png?width=1456&format=png&auto=webp&s=4be58601b9a0fb9bcc1ff17d25560257f895dca2

&#x200B;

Full post here: [https://newsletter.victordibia.com/p/top-5-ai-announcements-and-implications](https://newsletter.victordibia.com/p/top-5-ai-announcements-and-implications) 

TLDR.

* **💰📉 Cost Reduction**: The new GPT-4 and GPT-3.5 Turbo models are more capable yet cost less. 🤯🤯.
* **📈🧠 Improved Model Capabilities**: GPT-4 now includes a 128K token version (300 pages of text), features an updated knowledge cutoff (previously April 2021, now April 2023), and offers improved function calling.
* **🎛️🔧 Improved Model Control**: The new model series can generate valid JSON-formatted responses using a \`response\_format\` parameter and supports reproducible results through a seed parameter. Additionally, there is upcoming support for accessing log probabilities of generated tokens.
* **🤖🔗Agents: The Assistant API**: This API supports the **creation of agents** that can utilize external knowledge (RAG), **act** via tools (e.g., code execution and function calling), and maintain infinitely long conversations through Threads. All of this in a unified api for building agents.
* **🤖🛍️Agents: GPTAgents and Agent Store**: OpenAI will create a store where developers can bundle and share GPT agents with some revenue sharing. An Agent here is an LLM+Knowledge+Tools. 

&#x200B;

**High Level Implications** 

\- Cost reductions could make these models more practical to use (cost competitive with running smaller models at scale). 

&#x200B;

[Pricing of OpenAI models show cost reductions in successive GPT models from March - Nov 2023 . Davinci Source https:\/\/openai.com\/pricing](https://preview.redd.it/hfvytscem5zb1.png?width=1456&format=png&auto=webp&s=516a263a9b98165043c7b41946b70cce791cc861)

&#x200B;

&#x200B;

https://preview.redd.it/skio4eohm5zb1.png?width=1196&format=png&auto=webp&s=57299651d05a9469a90506e0b4724649c834b6ed

\- The Assistant API facilitates prototyping complex agent workflows, eliminating the extensive infrastructure work that was previously burdensome, such as implementing a RAG workflow, managing long conversation contexts, and executing code.

\- The capability to generate output constrained to a valid JSON format, the option to set a seed for reproducibility, and access to log probabilities are significant steps toward addressing **reliability issues** with large language models (LLMs).

While some of the ideas introduced may not be entirely new, they certainly represent significant quality-of-life improvements for engineers attempting to build Generative AI apps."
215,learnmachinelearning,open-ai,relevance,2024-01-04 12:35:54,Epstein Documents 2024: Full Search with OpenAI and Embeddings,vanlifecoder,False,0.67,1,18yc5pg,https://collie.ai/epstein2024,0,1704371754.0,
216,learnmachinelearning,open-ai,relevance,2023-01-16 12:28:25,I benchmarked OpenAI's GPT API vs other proprietary APIs on different NLP tasks,AImSamy,False,0.9,198,10ddc1f,https://www.reddit.com/gallery/10ddc1f,37,1673872105.0,
217,learnmachinelearning,open-ai,relevance,2023-06-29 00:28:52,OpenAI Function Calling Examples,sopmac21379,False,1.0,3,14lq1eg,https://medium.com/sopmac-ai/openai-function-calling-examples-a438268e0a77,3,1687998532.0,
218,learnmachinelearning,open-ai,relevance,2023-05-09 18:05:05,"Building with LLMs, ChatGPT, and Working at OpenAI With Logan Kilpatrick (Dev Rel @OpenAI) - What's AI episode 11",OnlyProggingForFun,False,1.0,1,13d13os,https://youtu.be/zz4U3X3PD4s,0,1683655505.0,
219,learnmachinelearning,open-ai,relevance,2024-02-06 00:51:48,OpenAI's GPTs Ranks (Daily Update) - according to the official categories,SanBirth,False,0.5,0,1ajwxfm,https://www.reddit.com/r/learnmachinelearning/comments/1ajwxfm/openais_gpts_ranks_daily_update_according_to_the/,2,1707180708.0," It took 2 days to put all together, hope this helps, all data  official data sourced from Openai.

**Top Picks,**

[gptsapp.io/trending-gpts/top-1000-gpts-ranked](https://gptsapp.io/trending-gpts/top-1000-gpts-ranked)

**DALL·E**

[gptsapp.io/trending-gpts/dall-e-gpts](https://gptsapp.io/trending-gpts/dall-e-gpts)

**Writing**

[gptsapp.io/trending-gpts/writing-gpts](https://ptsapp.io/trending-gpts/writing-gpts)

**Productivity**

[gptsapp.io/trending-gpts/productivity-gpts](https://gptsapp.io/trending-gpts/productivity-gpts)

**Research & Analysis**

[gptsapp.io/trending-gpts/research-analysis-gpts](https://gptsapp.io/trending-gpts/research-analysis-gpts)

**Programming**

[gptsapp.io/trending-gpts/programming-gpts](https://gptsapp.io/trending-gpts/programming-gpts)

**Education**

[gptsapp.io/trending-gpts/education-gpts](https://gptsapp.io/trending-gpts/education-gpts)

**Lifestyle**

[gptsapp.io/trending-gpts/lifestyle-gpts](https://gptsapp.io/trending-gpts/lifestyle-gpts)

**Other**

[gptsapp.io/trending-gpts/other-gpts](https://gptsapp.io/trending-gpts/other-gpts)"
220,learnmachinelearning,open-ai,relevance,2023-04-29 09:21:53,Prompt Engineering Free Course For Beginners By OpenAI And Deep Learning AI,vadhavaniyafaijan,False,0.77,49,132o8tt,https://www.theinsaneapp.com/2023/04/free-prompt-engineering-course-for-beginners.html,7,1682760113.0,
221,learnmachinelearning,open-ai,relevance,2023-11-29 14:18:51,PowerPoint-Präsentation - Finxter_Prompting_OpenAI-2.pdf,CheapBison1861,False,1.0,1,186qg2u,https://blog.finxter.com/wp-content/uploads/2023/03/Finxter_Prompting_OpenAI-2.pdf?utm_source=www.neatprompts.com,0,1701267531.0,
222,learnmachinelearning,open-ai,relevance,2023-10-19 08:38:07,"Stanford Study On Transparency Of AI Models Of Google, Meta, OpenAI, And Other Big Companies",vadhavaniyafaijan,False,1.0,7,17beeki,https://www.theinsaneapp.com/2023/10/stanford-foundational-model-transparency-report.html,0,1697704687.0,
223,learnmachinelearning,open-ai,relevance,2023-09-10 20:05:36,Two models of OpenAI demonstrated separate personalities,Reasonable_Leg_7405,False,0.67,1,16fa5m0,https://i.redd.it/7uerqe0kihnb1.jpg,0,1694376336.0,
224,learnmachinelearning,open-ai,relevance,2023-10-10 13:31:04,Explained Simply: OpenAI's breakthrough paper about defeating Dota2 world champions!,mngrwl,False,0.35,0,174lahd,https://mngrwl.medium.com/explained-simply-how-a-i-defeated-world-champions-in-the-game-of-dota-2-f3df90d38a70,9,1696944664.0,
225,learnmachinelearning,open-ai,relevance,2023-07-20 08:43:25,Help with selecting hardware for Open AI whisper,shai_das,False,0.87,6,154l9b9,https://www.reddit.com/r/learnmachinelearning/comments/154l9b9/help_with_selecting_hardware_for_open_ai_whisper/,3,1689842605.0,"Looking at integrating whisper into our transcription software..struggling to find the right balance to use as a staging Ubuntu server till the solution is ready for release. Do not want to exceed AUD 5000 and need to process roughly 16 hours of audio a day, once transcribed and stored in the db the audio file is destroyed.  Prebuilt or custom, GPU ..looks like RTX 4090 is the go (happy to be corrected), Older gen Intel xeon with DDR 4 or newer i7/9 or Ryzen 9 with DDR5 , Storage NVME 2 ssd , Memory 64Gb , storage 2 Tb . When we go live to OpenAI cloud, I need the staging to act as a fall back to the cloud "
226,learnmachinelearning,open-ai,relevance,2023-05-19 07:08:51,OpenAI Launches ChatGPT App For iOS Users,vadhavaniyafaijan,False,0.86,51,13lnv1e,https://www.theinsaneapp.com/2023/05/chatgpt-app-for-iphone-and-ipad.html,10,1684480131.0,
227,learnmachinelearning,open-ai,relevance,2023-07-27 05:19:20,OpenAI’s Andrej Karpathy Launches Baby Llama 2,vadhavaniyafaijan,False,0.96,26,15asqwd,https://www.theinsaneapp.com/2023/07/openai-karpathy-launches-baby-llama-2.html,3,1690435160.0,
228,learnmachinelearning,open-ai,relevance,2023-09-29 14:00:56,Question about using OpenAI embeddings to cluster my users,ihaveajob79,False,1.0,1,16vcfdj,https://www.reddit.com/r/learnmachinelearning/comments/16vcfdj/question_about_using_openai_embeddings_to_cluster/,2,1695996056.0,"Hi everyone. I'm a curious machine learning aficionado, but I learn as I go and have not a lot of formal training beyond college a while back. I'm working on a process to cluster my users by job title and industry, with the idea of showing them customized training and onboarding material for my app. So the process I follow, at a high level, is:

1. Compute embeddings for the set of (job-title, industry) pairs; I gave about 5000 total. Note that many job-title entries are set to 'unknown'.
2. Cluster the embeddings using k-means (Sklearn library). I tried with various numbers of clusters, between 20 and 200.
3. In the future, when new users arrive, I'd compute their embedding and find the nearest cluster for classification.

However, the clustering feels poor, with lots of outliers such as **<helpline accountibility officer | nonprofit or charitable organization>** in the same cluster as **<regional manager | automotive repair and maintenance>**, and in the same cluster there are lots of medical device manufacturing folks.

So I'm wondering what to try next, and I have some ideas but I have no intuition as to what might work best:

1. Throwing more data for each user, such as their email's domain name, in the hope that the embeddings can extract more meaning
2. Clustering job titles and industries separately, and then using both indexes to classify new users
3. Somehow processing the embeddings to reduce the dimmensionality (how?) so there's less overfitting

What would you do in my shoes? And thanks!"
229,learnmachinelearning,open-ai,relevance,2023-11-06 18:23:17,OpenAI Whisper new model Large V3 just released and amazing,CeFurkan,False,1.0,3,17p9a5s,/r/OpenAI/comments/17p93sp/openai_whisper_new_model_large_v3_just_released/,0,1699294997.0,
230,learnmachinelearning,open-ai,relevance,2023-10-01 20:37:56,LLM Firewall - Guardrail Tutorial and Quickstart with OpenAI and Colab,Educational_Grass_38,False,1.0,13,16xc53k,https://m.youtube.com/watch?v=EnwVnz07h1I&pp=ygUSR3VhcmRyYWlsIEZpcmV3YWxs,5,1696192676.0,"Been working on a Firewall for devs to use in a few lines of code, to implement a protective layer around LLMs like OpenAI. Firewall has over 20+ detectors out-of-the-box including prompt injections, harmful content, toxicity and common security vulnerabilities.

Google Colab QuickStart: https://github.com/guardrail-ml/guardrail

Developer Docs: https://docs.useguardrail.com

Would appreciate if you could give a star and provide feedback, thanks!"
231,learnmachinelearning,open-ai,relevance,2023-12-21 18:13:30,Langchain vs. LlamaIndex vs. OpenAI GPTs: Which one should you use?,OnlyProggingForFun,False,0.67,1,18ntbp9,https://youtu.be/g84uWgVXVYg,0,1703182410.0,
232,learnmachinelearning,open-ai,relevance,2023-08-22 22:55:04,OpenAI Python Colab to Summarize and Chat with PDF,starlineventures,False,1.0,7,15yljxz,https://youtu.be/bypGr-Q8RB0,3,1692744904.0,
233,learnmachinelearning,open-ai,relevance,2023-08-29 03:52:11,"Open-Source CodeLlama Server: Streaming, Caching, Model Fallbacks (OpenAI + Anthropic), Prompt-tracking",VideoTo,False,1.0,8,1647o7n,https://www.reddit.com/r/learnmachinelearning/comments/1647o7n/opensource_codellama_server_streaming_caching/,0,1693281131.0,"**TLDR;** We're open-sourcing our CodeLlama server. It handles streaming, caching, model fallbacks, and tracks prompts + token usage - [https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server](https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server)

\~\~

Hello r/learnmachinelearning,

I’m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, TogetherAI, Cohere, Anthropic, Baseten, Hugging face API Endpoints: [https://github.com/BerriAI/litellm/](https://github.com/BerriAI/litellm/)

We're open sourcing our CodeLlama server:

What can our server do? - It uses Together AI's CodeLlama to answer coding questions, with GPT-4 + Claude-2 as backups (you can easily switch this to any model from Huggingface, Replicate, Cohere, AI21, Azure, OpenAI, etc.)

Consistent Input/Output Format - Call all models using the OpenAI format: completion(model, messages) - Text responses will always be available at \['choices'\]\[0\]\['message'\]\['content'\]

* Streaming & Async Support - Return generators to stream text responses
* Error Handling Using Model Fallbacks (if Phind-CodeLlama fails, use Claude-2, fine-tuned GPT-3.5 etc.)
* Logging - It's integrated with promptlayer, so you can automatically track your prompt + model changes there.
* Token Usage & Spend - Track Input + Completion tokens used + Spend/model
* Caching - In-memory + Redis Cache solutions provided (works for streaming too!).

You can deploy liteLLM to your own infrastructure using Railway, GCP, AWS, Azure

Happy completion() !"
234,learnmachinelearning,open-ai,relevance,2023-08-28 15:51:49,Longer Responses from OpenAI's ChatCompletion object?,CartographerSuper506,False,0.5,0,163pqu6,https://www.reddit.com/r/learnmachinelearning/comments/163pqu6/longer_responses_from_openais_chatcompletion/,0,1693237909.0,"Hi all! Was just wondering if there's a way to encourage longer responses from the ChatCompletion object's create method? I know there's a max\_tokens parameter, but it wouldn't seem that would explain the short responses when its default value is set to inf. "
235,learnmachinelearning,open-ai,relevance,2023-06-14 15:56:31,"Vercel AI Accelerator: $850k in API credits from OpenAI, Anthropic, and more",Nutlope,False,0.81,3,149bhgz,https://vercel.com/ai-accelerator,0,1686758191.0,
236,learnmachinelearning,open-ai,relevance,2023-12-22 19:43:21,Unlocking Intelligent Applications: A Guide to Deploying Azure OpenAI Models with Team GPT,LongjmpingShower,False,0.67,2,18on66a,https://www.reddit.com/r/learnmachinelearning/comments/18on66a/unlocking_intelligent_applications_a_guide_to/,0,1703274201.0,"Unlock the potential of Azure OpenAI models with this concise guide. Learn to seamlessly deploy your own model, enhanced by collaborative efforts within Team GPT, and revolutionize your applications with cutting-edge AI capabilities.  
**Learn more>>>**[https://team-gpt.com/learn/chatgpt-for-work-course/](https://team-gpt.com/learn/chatgpt-for-work-course/)  


https://preview.redd.it/h2lh3edogw7c1.png?width=699&format=png&auto=webp&s=aedb958abc90a58337b11b4e389e1ca896b4dd01

 "
237,learnmachinelearning,open-ai,relevance,2024-01-12 12:52:39,"Contribute to open-source AI gateway, written in TS",EscapedLaughter,False,0.75,2,194ucaw,https://www.reddit.com/r/learnmachinelearning/comments/194ucaw/contribute_to_opensource_ai_gateway_written_in_ts/,0,1705063959.0,"[https://github.com/portkey-ai/gateway](https://github.com/portkey-ai/gateway)  
 We've been developing this open-source AI gateway that routes to hundred+ LLMs using the OpenAI SDK.

It is a one-line executable that starts a local proxy server - you can just put that url in the baseURL of the OpenAI SDK and call providers like Google, Azure, AWS, Anthropic, Anyscale, Together, Perplexity, Mistral, and more.

It's designed to be highly performant — we have been using it to route billions of tokens daily for our customers.

Would love to hear the community's views/feedback 🙏"
238,learnmachinelearning,open-ai,relevance,2023-04-17 18:43:11,OpenAI Demo Code Isn't Working?,Bodesterine555,False,1.0,1,12psbuy,https://www.reddit.com/r/learnmachinelearning/comments/12psbuy/openai_demo_code_isnt_working/,1,1681756991.0,"Hi there, I've used OpenAI's demo code (for GPT models) a number of times before, never had issues. Today I wanted to remind myself how everything works for a new project, and an unedited version (I added my API key, that's it) isn't working. I'm getting the error, ""Unexpected token '<', ""<!DOCTYPE ""... is not valid JSON""

&#x200B;

Any advice or ideas? I'm not a good programmer, I must be making a simple mistake here

https://preview.redd.it/82uzzm9ephua1.png?width=914&format=png&auto=webp&s=80bb05aa5b4e517fa20c280e045bfbca803b070e"
239,learnmachinelearning,open-ai,relevance,2022-10-19 09:27:38,Fixing YouTube Search with OpenAI's Whisper,jamescalam,False,0.95,77,y7xxri,https://www.reddit.com/r/learnmachinelearning/comments/y7xxri/fixing_youtube_search_with_openais_whisper/,13,1666171658.0,"Hi all, I wanted to [build a ""YouTube search"" app](https://www.pinecone.io/learn/openai-whisper/) for some time. Not the typical YouTube search where you return videos, but a YouTube search that returns the specific part of a video that answers your question. With text-based data this is pretty easy, but video/audio is less so.

That was until OpenAI (open sourced?) Whisper, a new SotA for speech-to-text. So I went ahead and built [""Ask YouTube""](https://huggingface.co/spaces/jamescalam/ask-youtube). A little search bar where you can ask technical questions and get the exact most relevant part from a set of videos (for now, the video scope is limited, I'll add more soon).

I explained everything I did to build it in [the linked article](https://pinecone.io/learn/openai-whisper/) and [video](https://youtu.be/vpU_6x3jowg). You could also just grab the app code and replicate it, I don't think it would take long. At a high level it is:

* Download YouTube audio with `pytube`
* Transcribe with OpenAI's Whisper
* Do some data prep
* Encode using Hugging Face / sentence-transformers
* Index and query with Pinecone vector DB

Then I wrapped all of this into a quick Streamlit web app and hosted it all for free on Hugging Face Spaces. One somewhat surprising thing here is absolutely everything was either open source or free, I didn't pay a dime!

Anyway, I hope this is interesting. Let me know what you think!"
240,learnmachinelearning,open-ai,relevance,2023-07-01 00:43:36,Semantic Video Search using OpenAI's CLIP,vanlifecoder,False,0.86,5,14nh6nm,https://learn.mixpeek.com/what-is-semantic-video-search/,0,1688172216.0,
241,learnmachinelearning,open-ai,relevance,2023-10-04 23:08:19,Can I use open ai api to handle multiple requests at once,Informal-Beyond-5584,False,0.75,2,1701s8f,https://www.reddit.com/r/learnmachinelearning/comments/1701s8f/can_i_use_open_ai_api_to_handle_multiple_requests/,2,1696460899.0,"Hey I wanted to put in news articles for a website I’m building as part of a stock portfolio

It takes into account different articles and I want to read it in all at once if I say like 50 articles can it handle that amount ?"
242,learnmachinelearning,open-ai,relevance,2020-08-05 10:58:02,image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model,OnlyProggingForFun,False,0.97,637,i437om,https://www.youtube.com/watch?v=FwXQ568_io0,46,1596625082.0,
243,learnmachinelearning,open-ai,relevance,2023-01-25 22:03:50,OpenAI's breakthrough,bradasm,False,0.13,0,10lb504,https://www.reddit.com/r/learnmachinelearning/comments/10lb504/openais_breakthrough/,0,1674684230.0,[https://twitter.com/make\_mhe/status/1618255363580755968](https://twitter.com/make_mhe/status/1618255363580755968)
244,learnmachinelearning,open-ai,relevance,2023-04-22 05:51:13,Integrating Google search into OpenAI models like GPT-4,Ghost25,False,0.95,15,12uwd8p,https://www.reddit.com/r/learnmachinelearning/comments/12uwd8p/integrating_google_search_into_openai_models_like/,8,1682142673.0,"Thought I'd share an explanation of how I implemented Google search into my GPT-4 based chatbot.

Github here: https://github.com/sgreenb/pico_assistant

One extremally simple modification that dramatically improves the ability of a GPT to answer questions: letting it Google stuff.

Here’s a demo:

https://imgur.com/ZR6hvLg 1

The implementation works like this.

1. A user enters an input.
2. An agent called “Executive” looks at the input and decides if an API like Spotify, Twillio, or Gmail is needed or if it can be answered by the chatbot alone.
3. If the chatbot is needed the input is first sent to a Google agent. The Google agent’s system message looks like this:

```
{""role"":""system"", ""content"": ""You analyze a user's input to a large language model with \
training data that cuts off at September 2021. The current year is 2023. You decide how \
likely it is that a user's request will benefit from a Google search to help address the\
question. Respond with a number in the range 1-10, where 1 is very unlikely that a \
Google search would be beneficial, and 10 meaning a Google search is highly necessary.""}
```

This is quite fast, since it only needs to generate one or two tokens.

If the output is above some threshold (say 7), then we call another agent, the query agent, otherwise we return False and default to the normal chat agent.

```
    google_probability = int(completion.choices[0].message.content)
    if google_probability >= cutoff:
        search_results = trim_text(search_and_scrape(prompt))
        query_with_context = prompt + str(search_results)
        print(""\nPico: "", end='', flush=True)
        response = query_agent_stream(query_with_context)
        return response
    else:
        return False
```

When we call the query agent, we feed it the first part of a Google search we get from searching the input. We get that from the very simple trim_text and search_and_scrape functions that look like this:

```

def search_and_scrape(query):
    try:
        headers = {
            ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3""
        }
        url = f""https://www.google.com/search?q={query}""
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text()
            cleaned_text = ' '.join(text.split())
            return cleaned_text
        else:
            print(f""Failed to fetch search results for query: {query}, status code: {response.status_code}"")
            return None

    except Exception as e:
        print(f""Error fetching search results for query: {query}, error: {e}"")
        return None

def trim_text(text, start_index = 450, length=1500):
    return text[start_index:start_index + length]
```

The query agent has this system message:

```
{""role"":""system"", ""content"": ""You answer a user's question, given some text as context to help\
answer the question. The user request will be followed by the context. The context given is\
from the user's Google search results, it is current and up to date.\
Do not contradict the contents of the given text in your answer.""}
```

And that’s it. You can change the cutoff threshold or get more sophisticated with fetching web results. I hope you find this useful."
245,learnmachinelearning,open-ai,relevance,2024-01-17 05:25:46,The Future of AI is Open-Source,swodtke,False,0.72,13,198oxi9,https://www.reddit.com/r/learnmachinelearning/comments/198oxi9/the_future_of_ai_is_opensource/,5,1705469146.0,"Imagine a future where AI isn't locked away in corporate vaults, but built in the open, brick by brick, by a global community of innovators. Where collaboration, not competition, fuels advancements, and ethical considerations hold equal weight with raw performance. This isn't science fiction, it's the open-source revolution brewing in the heart of AI development. But Big Tech has its own agenda, masking restricted models as open source while attempting to reap the benefits of a truly open community. Let's peel back the layers of code and unveil the truth behind these efforts. This exploration of the future of open-source AI will dissect the “pretenders” and champion the “real ones” in AI development to uncover the innovation engine that is open-source software humming beneath it all. The bottom line is that open-source AI will beget an open-source data stack.

[https://blog.min.io/the-future-of-ai-is-open-source/?utm\_source=reddit&utm\_medium=organic-social+&utm\_campaign=future\_ai\_open\_source](https://blog.min.io/the-future-of-ai-is-open-source/?utm_source=reddit&utm_medium=organic-social+&utm_campaign=future_ai_open_source)"
246,learnmachinelearning,open-ai,relevance,2023-12-08 13:20:50,Open Source Pretrained AI models?,Odd_Acanthisitta_853,False,0.67,2,18dmomf,https://www.reddit.com/r/learnmachinelearning/comments/18dmomf/open_source_pretrained_ai_models/,3,1702041650.0,So I'm interested in getting into AI models but I have no idea where to start. Could you guys tell me about some open source models you're using and what you're doing with them?
247,learnmachinelearning,open-ai,relevance,2023-04-12 05:19:38,Is OpenAI’s Study On The Labor Market Impacts Of AI Flawed?,LesleyFair,False,1.0,3,12jb3hy,https://www.reddit.com/r/learnmachinelearning/comments/12jb3hy/is_openais_study_on_the_labor_market_impacts_of/,0,1681276778.0,"[Example img\_name](https://preview.redd.it/u4m50gaj1eta1.png?width=1451&format=png&auto=webp&s=8c9eda5aebd66ad1c6514ba8fe14bca7dc0e381a)

We all have heard an uncountable amount of predictions about how AI will ***terk err jerbs!***

However, here we have a proper study on the topic from OpenAI and the University of Pennsylvania. They investigate how Generative Pre-trained Transformers (GPTs) could automate tasks across different occupations \[1\].

Although I’m going to discuss how the study comes with a set of “imperfections”, the findings still make me really excited. The findings suggest that machine learning is going to deliver some serious productivity gains.

People in the data science world fought tooth and nail for years to squeeze some value out of incomplete data sets from scattered sources while hand-holding people on their way toward a data-driven organization. At the same time, the media was flooded with predictions of omniscient AI right around the corner.

*Let’s dive in and take an* exciting glimpse into the future of labor markets\*!\*

# What They Did

The study looks at all US occupations. It breaks them down into tasks and assesses the possible level of for each task. They use that to estimate how much automation is possible for a given occupation.

The researchers used the [O\*NET database,](https://www.onetcenter.org/database.html) which is an occupation database specifically for the U.S. market. It lists 1,016 occupations along with its standardized descriptions of tasks.

The researchers annotated each task once manually and once using GPT-4. Thereby, each task was labeled as either somewhat (<50%) or significantly (>50%) automatable through LLMs. In their judgment, they considered both the direct “exposure” of a task to GPT as well as to a secondary GPT-powered system, e.g. LLMs integrated with image generation systems.

To reiterate, a higher “exposure” means that an occupation is more likely to get automated.

Lastly, they enriched the occupation data with wages and demographic information. This was used to determine whether e. g. high or low-paying jobs are at higher risk to be automated.

So far so good. This all sounds pretty decent. Sure, there is a lot of qualitative judgment going into their data acquisition process. However, we gotta cut them some slag. These kinds of studies always struggle to get any hard data and so far they did a good job.

However, there are a few obvious things to criticize. But before we get to that let’s look at their results.

# Key Findings

The study finds that 80% of the US workforce, across all industries, could have at least some tasks affected. Even more significantly, 19% of occupations are expected to have at least half of their tasks significantly automated!

Furthermore, they find that higher levels of automation exposure are associated with:

* Programming and writing skills
* Higher wages (contrary to previous research!)
* Higher levels of education (Bachelor’s and up)

Lower levels of exposure are associated with:

* Science and critical thinking skills
* Manual work and tasks that might potentially be done using physical robots

This is somewhat unsurprising. We of course know that LLMs will likely not increase productivity in the plumbing business. However, their findings underline again how different this wave is. In the past, simple and repetitive tasks fell prey to automation.

*This time it’s the suits!*

If we took this study at face value, many of us could start thinking about life as full-time pensioners.

But not so fast! This, like all the other studies on the topic, has a number of flaws.

# Necessary Criticism

First, let’s address the elephant in the room!

OpenAI co-authored the study. They have a vested interest in the hype around AI, both for commercial and regulatory reasons. Even if the external researchers performed their work with the utmost thoroughness and integrity, which I am sure they did, the involvement of OpenAI could have introduced an unconscious bias.

*But there’s more!*

The occupation database contains over 1000 occupations broken down into tasks. Neither GPT-4 nor the human labelers can possibly have a complete understanding of all the tasks across all occupations. Hence, their judgment about how much a certain task can be automated has to be rather hand-wavy in many cases.

Flaws in the data also arise from the GPT-based labeling itself.

The internet is flooded with countless sensationalist articles about how AI will replace jobs. It is hard to gauge whether this actually causes GPT models to be more optimistic when it comes to their own impact on society. However, it is possible and should not be neglected.

The authors do also not really distinguish between labor-augmenting and labor-displacing effects and it is hard to know what “affected by” or “exposed to LLMs” actually means. Will people be replaced or will they just be able to do more?

Last but not least, lists of tasks most likely do not capture all requirements in a given occupation. For instance ""making someone feel cared for"" can be an essential part of a job but might be neglected in such a list.

# Take-Away And Implications

GPT models have the world in a frenzy - rightfully so.

Nobody knows whether 19% of knowledge work gets heavily automated or if it is only 10%.

As the dust settles, we will begin to see how the ecosystem develops and how productivity in different industries can be increased. Time will tell whether foundational LLMs, specialized smaller models, or vertical tools built on top of APIs will be having the biggest impact.

In any case, these technologies have the potential to create unimaginable value for the world. At the same time, change rarely happens without pain. I strongly believe in human ingenuity and our ability to adapt to change. All in all, the study - flaws aside - represents an honest attempt at gauging the future.

Efforts like this and their scrutiny are our best shot at navigating the future. Well, or we all get chased out of the city by pitchforks.

Jokes aside!

What an exciting time for science and humanity!

As always, I really enjoyed making this for you and I sincerely hope you found value in it!

If you are not subscribed to the newsletter yet, [click here to sign up](https://thedecoding.net/)! I send out a thoughtful 5-minute email every week to keep you in the loop about machine learning research and the data economy.

*Thank you for reading and I see you next week ⭕!*

**References:**

\[1\] [https://arxiv.org/abs/2303.10130](https://arxiv.org/abs/2303.10130)"
248,learnmachinelearning,open-ai,relevance,2023-05-11 02:01:17,OpenAI & GPT Dictionary of Vocabulary. Generative AI Terms To Know In 2023,OnlyProggingForFun,False,0.67,1,13ea36c,https://youtu.be/q4G6X09NEu4,0,1683770477.0,
249,learnmachinelearning,open-ai,relevance,2023-05-06 15:50:19,Exploring text embeddings with OpenAI and Seinfeld,AlphaX,False,1.0,1,139tm0j,https://medium.com/@alex.pusch/exploring-text-embeddings-with-openai-and-seinfeld-68753f2bfd9e,0,1683388219.0,
250,learnmachinelearning,open-ai,relevance,2022-04-08 15:20:26,OpenAI 's new model DALL·E 2 is amazing!,OnlyProggingForFun,False,0.94,198,tz5x2f,https://youtu.be/rdGVbPI42sA,8,1649431226.0,
251,learnmachinelearning,open-ai,relevance,2023-11-09 19:16:20,Overcame the OpenAI Assistant API Learning Curve Post-DevDay – Our Detailed Guide Inside,davorrunje,False,0.94,12,17rkmfw,https://www.reddit.com/r/learnmachinelearning/comments/17rkmfw/overcame_the_openai_assistant_api_learning_curve/,1,1699557380.0,"Hello AI enthusiasts,

Navigating the new Assistant API after the recent OpenAI DevDay? We know the official docs aren't quite there yet, and it can be a bit like finding your way in the dark.

To help out, we've put together a detailed walkthrough of our own experience – the missteps, the breakthroughs, and everything in between.

We believe this resource can save you some time and frustration. If you're planning to work with the Assistant API, give our guide a read and get a head start: [Our Guide to the Assistant API](https://airt.hashnode.dev/function-calling-and-code-interpretation-with-openais-assistant-api-a-quick-and-simple-tutorial)

Looking forward to your feedback and hope it helps!"
252,learnmachinelearning,open-ai,relevance,2023-07-16 16:12:50,Semantic Video Search using OpenAI’s CLIP (demo and tutorial in comments),vanlifecoder,False,0.91,25,151a6hu,https://v.redd.it/hmam3vr1qccb1,3,1689523970.0,
253,learnmachinelearning,open-ai,relevance,2023-04-27 09:35:29,"Semantic Search with LangChain, OpenAI, and Elasticsearch",dcastm,False,1.0,5,130ffl5,https://dylancastillo.co/semantic-search-elasticsearch-openai-langchain/,0,1682588129.0,
254,learnmachinelearning,open-ai,relevance,2022-09-23 13:46:55,Created a GUI for OpenAI's Whisper Using Gradio,ImplodingCoding,False,0.96,71,xly2gp,https://v.redd.it/6djgfjpp4mp91,9,1663940815.0,
255,learnmachinelearning,open-ai,relevance,2023-11-08 16:15:30,Function Calling and Code Interpretation with OpenAI's Assistant API: A Quick and Simple Tutorial,davorrunje,False,1.0,4,17qp4ni,https://airt.hashnode.dev/function-calling-and-code-interpretation-with-openais-assistant-api-a-quick-and-simple-tutorial,0,1699460130.0,
256,learnmachinelearning,open-ai,relevance,2023-02-17 08:26:18,"The Latest On OpenAI, Google AI, and What it Means For Data Science",kingabzpro,False,0.67,2,114eg71,https://www.datacamp.com/blog/openai-google-ai-data-science,0,1676622378.0,
257,learnmachinelearning,open-ai,relevance,2022-12-08 20:35:20,Daath AI Parser is an open-source application that uses OpenAI to parse visible text of HTML elements.,softcrater,False,0.8,3,zgaqhe,https://github.com/kagermanov27/daath-ai-parser,0,1670531720.0,
258,learnmachinelearning,open-ai,relevance,2022-12-03 22:04:53,Open AI chatgpt mind blowing 🚀🚀,DataSynapse82,False,0.2,0,zbs4tg,https://www.reddit.com/r/learnmachinelearning/comments/zbs4tg/open_ai_chatgpt_mind_blowing/,0,1670105093.0,
259,learnmachinelearning,open-ai,relevance,2023-03-28 12:51:54,I am creating a tool that uses OpenAI models and an OCR to translate screenshots,K-RT-DEV,False,0.86,36,124nsy8,https://www.reddit.com/r/learnmachinelearning/comments/124nsy8/i_am_creating_a_tool_that_uses_openai_models_and/,15,1680007914.0,"Currently, the OCR is specifically for translating from Japanese, but I plan to add a range of OCRs and different translators to the system to accommodate the user's needs.  


https://i.redd.it/8ymk99uf8hqa1.gif

My idea is to have a system that leverages OpenAI models for *bagging*. This way, I can combine the output of multiple OCRs  to increase the accuracy of the recognized characters. Similarly, I can combine the output of multiple translators for the same phrase to improve the final result . Chat models can be particularly useful in providing **context** and a translation history to help the system understand how to conjugate phrases for translation.   


You can find the source code and an executable version on the [project's GitHub](https://github.com/K-RT-Dev/VGT)"
260,learnmachinelearning,open-ai,relevance,2023-05-16 07:40:00,EU AI Act: Shaping Or Destroying The Future Of US Open Source Softwares?,vadhavaniyafaijan,False,0.8,45,13iybuc,https://www.theinsaneapp.com/2023/05/eu-ai-act.html,48,1684222800.0,
261,learnmachinelearning,open-ai,relevance,2023-05-30 05:43:47,How to overcome OpenAI fine-tuning training data token limit?,Professor-Pumpkin,False,0.57,1,13vhs97,https://www.reddit.com/r/learnmachinelearning/comments/13vhs97/how_to_overcome_openai_finetuning_training_data/,0,1685425427.0,"I am using curie model to fine-tune in Python. Basically, I am passing the training data of form `{""prompt"":""completion""}`and I have 736 prompt-example pairs. My example completions are pretty long - I aim at generating a JSON file based on a description of fixed form. The fine-tune reports to be created, however, when retrieving the fine-tune model key via

    retrieve_response = openai.FineTune.retrieve(id=""fine_tune_model_id"") print(retrieve_response)  

I get the following messsage:

    {
      ""created_at"": 1685346828,
      ""events"": [
        {
          ""created_at"": 1685346828,
          ""level"": ""info"",
          ""message"": ""Created fine-tune: fine_tune_model_id"",
          ""object"": ""fine-tune-event""
        },
        {
          ""created_at"": 1685346879,
          ""level"": ""info"",
          ""message"": ""Error: The training file does not contain enough examples that fit within the 2048 tokens allowed for this model."",
          ""object"": ""fine-tune-event""
        }
    ...
    
    Cross-posted on https://stackoverflow.com/questions/76355721/openai-fine-tuning-training-data-exceeds-the-token-limit 

and thus the status failed, but for the ""training files"" object the status is proceeded (pretty obvious).

Is there a way to overcome the error above?

I do have an OpenAI subscription."
262,learnmachinelearning,open-ai,relevance,2023-05-30 13:11:21,Set Up OpenAI's CLIP on Amazon SageMaker for Inference,vanlifecoder,False,0.86,9,13vpxzn,https://rise.climb.dev/clip-on-sagemaker/,2,1685452281.0,
263,learnmachinelearning,open-ai,relevance,2023-11-16 21:34:20,AI/LLM starter kit in open source repo,linamagr,False,0.75,6,17wy4aw,https://www.reddit.com/r/learnmachinelearning/comments/17wy4aw/aillm_starter_kit_in_open_source_repo/,6,1700170460.0,"Share a Github repository to quickly build and start a local application to chat with private documents. The stack used is python,  [\#LangChainAI](https://www.linkedin.com/feed/hashtag/?keywords=langchainai&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7130952995793489920) , [\#qdrant\_engine](https://www.linkedin.com/feed/hashtag/?keywords=qdrant_engine&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7130952995793489920) [\#Ollama\_ai](https://www.linkedin.com/feed/hashtag/?keywords=ollama_ai&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7130952995793489920) and [\#FastAPI](https://www.linkedin.com/feed/hashtag/?keywords=fastapi&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7130952995793489920)  
)  
[https://github.com/mallahyari/ai-starter-kit](https://github.com/mallahyari/ai-starter-kit)   
"
264,learnmachinelearning,open-ai,relevance,2023-10-17 06:20:21,Open Source AI FOMO Saver,HorrorNo8851,False,1.0,1,179rt7j,https://www.reddit.com/r/learnmachinelearning/comments/179rt7j/open_source_ai_fomo_saver/,0,1697523621.0,[https://github.com/premAI-io/state-of-open-source-ai](https://github.com/premAI-io/state-of-open-source-ai)
265,learnmachinelearning,open-ai,relevance,2023-03-01 15:58:29,Experimenting with repurposing OpenAI Whisper for Speaker Prediction,eleanor_rigby_2,False,1.0,1,11f7dwq,https://www.reddit.com/r/learnmachinelearning/comments/11f7dwq/experimenting_with_repurposing_openai_whisper_for/,0,1677686309.0,"OpenAI recently released a SOTA speech translation model, which can transcribe any audio clip into text. But can this model, given how powerful it is for this speech task, be utilized to provide zero-shot audio features for speaker prediction?

&#x200B;

Usually for speaker prediction there are signal processing approaches. Or even deep learning approaches designed to represent an audio signal in a latent space and then perform prediction on these features. But it looks like OpenAI Whisper, to some extent, can be used as it is to provide these latent features, without any re-training, which can then be used for speaker prediction.

&#x200B;

I perform some analysis [here](https://sidhantls.github.io/lexpod-speaker-prediction/) using Lex Fridman Podcasts. Feel free to share your thoughts

&#x200B;"
266,learnmachinelearning,open-ai,relevance,2023-01-29 21:14:13,Create a Serverless Search Engine using the OpenAI Embeddings API,sopmac21379,False,0.93,51,10oitli,https://medium.com/sopmac-ai/create-a-serverless-search-engine-using-the-openai-embeddings-api-50e5ac8ca6e3,1,1675026853.0,
267,learnmachinelearning,open-ai,relevance,2019-10-23 23:58:05,OpenAI plays hide and seek and breaks the game. (Reinforcement Learning),UnintelligibleThing,False,0.97,347,dm86ay,https://www.youtube.com/watch?v=Lu56xVlZ40M,19,1571875085.0,
268,learnmachinelearning,open-ai,relevance,2023-05-01 17:04:12,"GPT Weekly Newsletter -- 30 Apr Edition. AI music, Voiceover, HuggingChat, Future of Work, OpenAI and more.",level6-killjoy,False,1.0,2,134t13o,/r/ChatGPT/comments/133q4zl/gpt_weekly_newsletter_30_apr_edition_ai_music/,0,1682960652.0,
269,learnmachinelearning,open-ai,relevance,2022-11-10 14:29:23,[P] Transcribe any podcast episode in just 1 minute with optimized OpenAI/whisper,thundergolfer,False,0.97,122,yrgnuq,https://v.redd.it/wnt66ghfody91,6,1668090563.0,
270,learnmachinelearning,open-ai,relevance,2023-06-19 16:38:37,I wanted to use OpenAI API but it's a paid service. What are alternatives for this?,Beginning-Scholar105,False,0.69,5,14djjsj,https://www.reddit.com/r/learnmachinelearning/comments/14djjsj/i_wanted_to_use_openai_api_but_its_a_paid_service/,10,1687192717.0,I have tried some Open Source Hugging Face LLMs but they are very large in size and also need heavy machine to run those LLMs.  If you know any other alternatives then please let me know.
271,learnmachinelearning,open-ai,relevance,2023-06-05 17:21:46,"GPT Weekly - 5th June Edition: Peek into OpenAI's future, GPT-4 Quality concerns, Risk of AI and more.",level6-killjoy,False,0.67,1,141llju,https://www.reddit.com/r/learnmachinelearning/comments/141llju/gpt_weekly_5th_june_edition_peek_into_openais/,0,1685985706.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 AI news in the past week
* 🗞️10 AI news highlights and interesting reads
* 🧑‍🎓3 Learning Resources

# 🔥Top 3 AI news in the past week

## 1. OpenAI plans as per Sam Altman

The CEO of Humanloop had a sit down with Sam Altman and 20 other developers. He discussed the [current and future of OpenAI](https://humanloop.com/blog/openai-plans). The blog was later taken down at the request of OpenAI. [Now it can be found at this link](https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans). 

The whole post is an interesting read. Some of the highlights for me were:

1. GPT-3 was not open-source because OpenAI didn’t think many people would be able to run large LLMs. This sounds like a cop-out. After all, LLaMA is also a large LLM and has helped the community.
2. OpenAI is limited by GPU power.
3. OpenAI will not enter the market, except ChatGPT. Though technically this doesn’t say what Microsoft might do. They are already plugging GPT4 into every other product. And they have no rate limitations. 

## 2. Is GPT-4 Quality going down?

This has been a recently trending topic.

Discussed on HN: [https://news.ycombinator.com/item?id=36134249](https://news.ycombinator.com/item?id=36134249)

Discussed on Reddit: [https://www.reddit.com/r/ChatGPT/comments/13xik2o/chat\_gpt\_4\_turned\_dumber\_today/](https://www.reddit.com/r/ChatGPT/comments/13xik2o/chat_gpt_4_turned_dumber_today/)

The interesting thing is that the quality judgment is around the same topic - Coding.

The person on HN says GPT4 is faster but generates buggy code with less in-depth analysis. 

While the person on Reddit says that the context window seems smaller. Chatbot cannot remember earlier code. It cannot distinguish between code and comment.

While an employee at OpenAI says [nothing has changed](https://twitter.com/OfficialLoganK/status/1663934947931897857).

Has something really changed? 

One theory is that while the model might be static the ChatGPT prompt might’ve changed to restrict answers. Everyone was having fun trying to get bomb recipes out of ChatGPT. Now everyone is paying the price. 

https://i.imgflip.com/7nlatp.jpg

Another theory is that ChatGPT has always been terrible. It just survived because of novelty. As the novelty wears off people are realizing that it isn’t as great as everyone thought. 

My theory is that this might be the after effect of trying to get to a “[Cheaper and faster GPT-4” as highlighted by Sam Altman](https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans). The trade-off is speed vs accuracy. If it is slightly faster but with slightly worse results, then it might work as well. It is no longer GPT-4, rather GPT-3.75.

## 3. Risk of AI = Pandemic and Nuclear War

Center for AI Safety [released a statement](https://www.safe.ai/statement-on-ai-risk) highlighting the risks of AI:

*Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.*

We have seen the warnings about risks of AI get dire and dire. First it was only people asking for a [pause on AI development for 6 months](https://www.theguardian.com/technology/2023/mar/31/ai-research-pause-elon-musk-chatgpt) then came [George Hinton](https://gptweekly.beehiiv.com/p/googles-startling-leaked-memo-george-hinton-mojo), and last week OpenAI asked for [AI to be regulated using the IAEA framework](https://gptweekly.beehiiv.com/p/future-ai-integration). 

This statement is not really a step up. It reads like a one line, summarized repetition of [OpenAI's statement](https://openai.com/blog/governance-of-superintelligence). 

The statement gains importance from its signatories. Some of the people include:

Geoffrey Hinton - Emeritus Professor of Computer Science, University of Toronto

Demis Hassabis - CEO, Google DeepMind

Sam Altman - CEO, OpenAI

Dario Amodei - CEO, Anthropic

Bill Gates - Gates Ventures

To name a few. 

There are two issues with the statement though. 

First, this might just be [fear-mongering](https://aisnakeoil.substack.com/p/is-avoiding-extinction-from-ai-really). The idea is to push governments into making AI a highly regulated industry. This would stop any open source efforts which can compete with the big companies. After all, you don’t really have open source alternatives for nuclear energy, right? 

Second, no one really knows how to regulate AI. There have been [voluntary rules from Google](https://gptweekly.beehiiv.com/p/future-ai-integration) and the EU AI act is in a very early stage. And the genie is already out of the bottle. People can create AI models in their basement. How do you pull that back?

# 🗞️10 AI news highlights and interesting reads

1. A follow-up to the story about a lawyer submitting fake cases from [last edition](https://gptweekly.beehiiv.com/p/future-ai-integration). As I said, this might lead some people in the legal community to doubt any sort of GPT tool.[ A federal judge has banned AI-only filings in his courtroom](https://arstechnica.com/tech-policy/2023/05/federal-judge-no-ai-in-my-courtroom-unless-a-human-verifies-its-accuracy/). The filings have to be written by a human or at least human-verified. 
2. [The Japanese government will not apply copyright law to the AI training data](https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/). This is interesting because using copyright data to train AI has been an issue. Sam Altman didn’t have a clear answer when he [appeared in front of Congress](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). The other interesting aspect is going to be whether someone can use GPT-4 data to train their own LLM. Is that copyrightable?  
3. [The Falcon 40-B model is now Apache 2.0](https://twitter.com/Thom_Wolf/status/1663986216771936263). That means you can use the model for commercial usage for free. This is good news for companies which need an instruction tuned model which beats LlaMA.
4. Photoshop's generative-fill feature is really good. Some of the [cool examples on Twitter](https://twitter.com/_Borriss_/status/1663568770408013831).
5. [An AI camera with no lens](https://twitter.com/BjoernKarmann/status/1663496103998750721). It gets the location, weather etc details from GPS and then passes it as a prompt to the image generator. Results are pretty cool. 
6. SEO isn’t changing any time soon. [Google’s generative SEO is very slow](https://www.theverge.com/23746083/google-ai-search-generative-experience-slow). 
7. [Chirper.AI](https://chirper.ai/) is a social media only for bots. No humans allowed. I just wonder if Twitter bots go there will Twitter become a ghost town?
8. [OpenAI now has a security portal ](https://trust.openai.com/)where you can see how they secure data (encryption at rest), backups, Pentest reports etc. This might be a step in the direction towards [ChatGPT business](https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt). Large corporations look at these policies before they consider any SaaS implementation. 
9. [Banks have stepped up hiring for AI roles with JP Morgan leading the way. ](https://www.bloomberg.com/news/features/2023-05-31/jpmorgan-s-push-into-finance-ai-has-wall-street-rushing-to-catch-up)
10. [AI code writing might not be the best idea. It will lead to tech debt and shabbily maintained and written code. ](https://www.wsj.com/articles/ai-is-writing-code-now-for-companies-that-is-good-and-bad-6f19ecdc)

# 🧑‍🎓3 Learning Resources

1. Couple of courses in Generative AI:
   1. [https://www.deeplearning.ai/short-courses/](https://www.deeplearning.ai/short-courses/)
   2. Google: [https://www.cloudskillsboost.google/paths/118](https://www.cloudskillsboost.google/paths/118)
2. Build your own Sketch to image app: [https://www.tryleap.ai/docs/how-to-build-a-sketch-to-image-app-with-leap-remix](https://www.tryleap.ai/docs/how-to-build-a-sketch-to-image-app-with-leap-remix)

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
272,learnmachinelearning,open-ai,relevance,2022-10-06 01:31:54,OpenAI's Most Recent Model: Whisper (explained),OnlyProggingForFun,False,0.9,15,xwsiag,https://youtu.be/uFOkMme19Zs,2,1665019914.0,
273,learnmachinelearning,open-ai,relevance,2023-05-06 05:36:55,Kivy - Open AI App for Android. In case someone needs it.,grannyUndertaker,False,0.75,2,139dfv1,https://github.com/4yub1k/kivy-openai,0,1683351415.0,
274,learnmachinelearning,open-ai,relevance,2023-05-02 17:58:29,How to Fine-Tune an OpenAI ML Model with Node.js,lizziepika,False,0.67,1,135vbu9,https://www.twilio.com/blog/finetune-openai-ml-model-node,0,1683050309.0,
275,learnmachinelearning,open-ai,relevance,2022-07-15 11:15:58,"Beside OpenAI, Google and Midjourney; what are the companies/start-ups working on text to image generation?",matxi182,False,0.92,52,vzm5rb,https://www.reddit.com/r/learnmachinelearning/comments/vzm5rb/beside_openai_google_and_midjourney_what_are_the/,32,1657883758.0,
276,learnmachinelearning,open-ai,relevance,2023-04-17 23:13:45,Difference between HuggingFace pre-trained model and OpenAI's API,raikirichidori255,False,1.0,3,12q110r,https://www.reddit.com/r/learnmachinelearning/comments/12q110r/difference_between_huggingface_pretrained_model/,1,1681773225.0,"I've a novice at LLMs and I've been learning a little more about them recently. I know a few months ago, ChatGPT released it's on API that can be integrated within apps for $0.02/token. However, I have been using HuggingFace pretrained model for a lot of modeling tasks, and I was wondering how this API is any different than just importing the openai-gpt model from HuggingFace.

Sorry if this is a bad question, I'm just starting out."
277,learnmachinelearning,open-ai,relevance,2023-04-12 16:42:28,"How to Build an Ecommerce Chatbot with Redis, LangChain, and OpenAI",yourbasicgeek,False,1.0,11,12jrym1,https://redis.com/blog/build-ecommerce-chatbot-with-redis/,2,1681317748.0,
278,learnmachinelearning,open-ai,relevance,2022-09-21 20:40:49,OpenAI Whisper - SOTA MultiLingual AI Speech Recognition Live App Tutorial,dulldata,False,1.0,1,xkgcno,https://www.youtube.com/watch?v=ywIyc8l1K1Q,0,1663792849.0,
279,learnmachinelearning,open-ai,relevance,2022-11-03 13:40:24,How to install and deploy OpenAI Whisper,juliensalinas,False,1.0,6,yl35gk,https://www.reddit.com/r/learnmachinelearning/comments/yl35gk/how_to_install_and_deploy_openai_whisper/,0,1667482824.0,"Hello,

If you are interested in automatic speech recognition (speech-to-text), you are most likely going to try OpenAI Whisper.

If that's the case, here is an article I just made about how to install and deploy Whisper: [https://nlpcloud.com/how-to-install-and-deploy-whisper-the-best-open-source-alternative-to-google-speech-to-text.html](https://nlpcloud.com/how-to-install-and-deploy-whisper-the-best-open-source-alternative-to-google-speech-to-text.html?utm_source=reddit&utm_campaign=h4d7a9cc-3816-11ed-a261-0242ac120002)

I hope it will be useful!

Julien"
280,learnmachinelearning,open-ai,relevance,2023-06-18 15:56:44,"I made FableForge: Text Prompt to an Illustrated Children’s Book using OpenAI Function Calls, Stable Diffusion, LangChain, & DeepLake",AverageKanyeStan,False,0.96,201,14cnuz4,https://v.redd.it/5p2apjnsts6b1,6,1687103804.0,
281,learnmachinelearning,open-ai,relevance,2023-07-16 12:25:22,"Cohere LLM - Free alternative to OpenAI's ChatGPT, No credit card needed",gihangamage,False,0.43,0,1514zp8,https://www.reddit.com/r/learnmachinelearning/comments/1514zp8/cohere_llm_free_alternative_to_openais_chatgpt_no/,0,1689510322.0,"In this video, we are discussing how to use Cohere LLM free version for text generation, embedding generation and document question answering. 

[https://youtu.be/isKk3kGq-n0](https://youtu.be/isKk3kGq-n0) "
282,learnmachinelearning,open-ai,relevance,2022-06-26 18:48:10,This is how OpenAI's new Minecraft AI agent works,SlickBlueML,False,0.87,6,vlbirr,https://www.youtube.com/watch?v=ODat7kfZ-5k,0,1656269290.0,
283,learnmachinelearning,open-ai,relevance,2022-11-15 21:58:49,Best way to do distributed inference of OpenAI Whisper?,SCUSKU,False,1.0,2,ywavuo,https://www.reddit.com/r/learnmachinelearning/comments/ywavuo/best_way_to_do_distributed_inference_of_openai/,3,1668549529.0,"I have 100 episodes of a podcast that I want to transcribe using OpenAI's Whisper model. I could just use a single machine and run this serially, but this is slow, and also doesn't scale.

What is the best way to go about running distributed inference? I have read a bit about Spark but am not convinced that this would be the right tool. The best solution I can think of right now is to do something with Kubernetes + autoscaling, but I'm not sure that's a good idea either."
284,learnmachinelearning,open-ai,relevance,2023-08-18 05:00:05,"OpenAI Proxy Server for Llama2, GPT-4, Claude2 with User-based rate limiting, Key management, Logging,Cache",VideoTo,False,0.8,3,15uarkx,https://www.reddit.com/r/learnmachinelearning/comments/15uarkx/openai_proxy_server_for_llama2_gpt4_claude2_with/,2,1692334805.0,"**tldr;** We’re open sourcing our proxy server to call 50+ LLM models with logging, caching, key management, rate-limiting: [https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-...](https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-server/readme.md)

\--

Hi r/learnmachinelearning,

I’m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, Cohere, Anthropic, Hugging face API Endpoints: [https://github.com/BerriAI/litellm/](https://github.com/BerriAI/litellm/)

We’re open sourcing our implementation of liteLLM proxy: [https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-...](https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-server/readme.md)

TLDR: It has one API endpoint /chat/completions and standardizes input/output for 50+ LLM models + handles logging, error tracking, caching, streaming

**What can liteLLM proxy do?** \- It’s a central place to manage all LLM provider integrations

\- **Consistent Input/Output Format** \- Call all models using the OpenAI format: completion(model, messages) - Text responses will always be available at \['choices'\]\[0\]\['message'\]\['content'\]

\- **Error Handling** Using Model Fallbacks (if GPT-4 fails, try llama2)

\- **Logging** \- Log Requests, Responses and Errors to Supabase, Posthog, Mixpanel, Sentry, Helicone

\- Token Usage & **Spend** \- Track Input + Completion tokens used + Spend/model

\- **User-based rate limiting** \- limit usage for bad actors

\- **Caching** \- Implementation of Semantic Caching

\- **Streaming & Async Support** \- Return generators to stream text responses

You can deploy liteLLM to your own infrastructure using Railway, GCP, AWS, Azure

Happy completion() !

https://i.redd.it/fhgifwb8wsib1.gif"
285,learnmachinelearning,open-ai,relevance,2023-08-15 15:09:49,How to run OpenAI CLIP with UI for Image Retrieval and Filtering your dataset - Supervisely,tdionis,False,1.0,1,15rvdih,https://supervisely.com/blog/openai-clip-for-image-retrieval-and-filtering-computer-vision-datasets-tutorial/,0,1692112189.0,
286,learnmachinelearning,open-ai,relevance,2023-05-02 17:15:02,How to Fine-Tune OpenAI Language Models with Noisily Labeled Data (37% error reduction),cmauck10,False,0.92,9,135u3vt,https://www.reddit.com/r/learnmachinelearning/comments/135u3vt/how_to_finetune_openai_language_models_with/,0,1683047702.0,"Hello Redditors! 

It's pretty well known that LLMs have solidified their place at the forefront of natural language processing, and are constantly pushing the boundaries of what is possible in terms of language understanding and generation.

I spent some time playing around with the OpenAI fine-tuning API and I discovered that noisy data still has drastic effects even on powerful LLMs like Davinci.

[Improving fine-tuning accuracy by improving data quality.](https://preview.redd.it/v5kro8wzagxa1.png?width=1085&format=png&auto=webp&s=39e0309aa94048dc08a0879d99008f00ec32fd9e)

I wrote up a [quick article](https://www.kdnuggets.com/2023/04/finetuning-openai-language-models-noisily-labeled-data.html) in KDNuggets that shows how I used data-centric AI to automatically clean the noisy data in order to fine-tune a more robust OpenAI LLM. The resulting model has 37% fewer errors than the same LLM fine-tuned on the noisy data.

Let me know what you think!"
287,learnmachinelearning,open-ai,relevance,2022-11-02 11:55:31,"What is ""previous text tokens"" in the OpenAI Whisper",Pritish-Mishra,False,1.0,3,yk37d3,https://www.reddit.com/r/learnmachinelearning/comments/yk37d3/what_is_previous_text_tokens_in_the_openai_whisper/,0,1667390131.0,"&#x200B;

https://preview.redd.it/73xy4yz30jx91.png?width=556&format=png&auto=webp&s=2b4c00c9d7b921648349c32c60d88e5b83a5f0f7

 

I stumbled upon this diagram while reading Whisper's paper. There is a ""previous text tokens"" before the ""Start of Transcript (SOT)"" special token, and I'm not sure what that means.

According to my understanding:

Because the transformer encoder only accepts audio files of up to 30 seconds in length, we need to divide longer audio files into 30-second chunks. 

So, ""previous text tokens"" will include ALL of the text that whisper predicted previously?

Thanks for your time."
288,learnmachinelearning,open-ai,relevance,2023-03-02 07:24:57,Good news for builders! OpenAI Releases APIs To ChatGPT and Whisper,LesleyFair,False,0.5,0,11fwcj2,https://www.reddit.com/r/learnmachinelearning/comments/11fwcj2/good_news_for_builders_openai_releases_apis_to/,0,1677741897.0,"If you were as disappointed as I was when you saw that access to Meta's LLaMA models is limited to researchers, you are going to like this.  


[APIs to ChatGPT and OpenAI's speech-to-text model whisper](https://openai.com/blog/introducing-chatgpt-and-whisper-apis) are available as of yesterday. Through system-wide optimizations, they claim to have reduced inference costs by 90%. They now price ChatGPT at $0.002 per 1000 tokens. Dedicated instances are available for speedup and make economic sense if you process \~450M tokens a day.  


Machine learning progress continues to be as fast as a banana peal skating on warm vaseline. 

If you found this useful and want to stay in the loop, consider subscribing to The Decoding. I send out a weekly 5-minute newsletter that keeps professionals in the loop about machine learning and the data economy. [Click here to subscribe!](https://thedecoding.net/)"
289,learnmachinelearning,open-ai,relevance,2024-01-30 10:42:57,LFX Mentorship 2024 Spring LLM Projects: Get Paid Building Open Source AI Inference Infra,smileymileycoin,False,0.5,0,1aelkk6,https://www.secondstate.io/articles/lfx-mentorship-spring-2024/,1,1706611377.0,
290,learnmachinelearning,open-ai,relevance,2023-06-19 17:49:06,"GPT Weekly - 19the June Edition - OpenAI's function calling, Meta's free LLM, EU Regulation and more.",level6-killjoy,False,1.0,22,14dlfas,https://www.reddit.com/r/learnmachinelearning/comments/14dlfas/gpt_weekly_19the_june_edition_openais_function/,2,1687196946.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 news - OpenAI’s updates, Meta’s upcoming free LLM and EU Regulation
* 🗞️Interesting reads include PSA about protecting your keys, The GPT ouroboros, Reddit - OpenAI’s moat, and more..
* 🧑‍🎓Learning includes a Step-by-step guide from a non-technical founder who launched his MVP, Chatbot for your Gdrive and more

# 🔥Top 3 AI news in the past week

## 1. OpenAI: New Pricing, Models, & Functions

OpenAI has been on a roll. Last week we saw the release of [OpenAI best practice on using GPT.](https://gptweekly.beehiiv.com/p/making-gpt-openais-tactics-better-results) This week we saw some amazing updates. Three major buckets were:

First, the price decreases for both embeddings and GPT-3.5 tokens. 

Second, new models for gpt-4 and gpt-3.5. A new longer context model for gpt-3.5.

Third, a new function calling capability. 

**Why is it important?** Previously, the output from OpenAI was all text. So, calling an external API from GPT was quite difficult. You had to parse the text data and things were often incorrect.  Langchain created the Agents and Tools feature to tackle this problem. It was still unreliable and prone to issues. 

Now you get native support to generate a fixed format output. You can use the output to generate functional calls and also pass functions which need to be called. For example, if your app has multiple API endpoints then you can use GPT to generate the API calls with parameters. You can also pass the endpoints as function calls to ensure the correct function is executed. 

This functionality can further be used to [generate structured data (JSON) out of GPT](https://yonom.substack.com/p/native-json-output-from-gpt-4). So, you can generate data from GPT and load it into your backend. 

**What’s next?** This functionality allows turning natural language responses into structured data. This can be used to create “intelligent” backends using LLMs. We might see implementations in no-code tools to allow more robust and natural-language tools for non-technical folks.

The structured data process goes both ways. You can also feed structured data into GPT for better responses. 

This feature also has its share of issues. Function calling suffers from the same prompt injection issues. Malicious actors can pass malicious code in function or the responses. For example, creation of queries using functions might contain malicious code to delete data. Without proper user validation this code will be executed automatically and delete data. So, using LLM as the back-end layer needs proper security implementation. 

## 2. Meta's LLM: Commercial Use Ahead

Llama has been a boon for the open source community. Many of the open source models rely on Llama. The issue is that Llama is research-only and cannot be used commercially. So, no one can use it to build any product.

[Meta is now working on the next version of the model. This model will be available for commercial use.](https://www.theinformation.com/articles/meta-wants-companies-to-make-money-off-its-open-source-ai-in-challenge-to-google) This is in stark contrast to both OpenAI and Google. Both safe-guarde their models and make it available through API. 

**Why is it important?** Certain industries cannot use LLM APIs because of strict restrictions on data privacy. These companies would want to run their own instance of a foundational model. 

A commercially available foundational model is also going to help people who want to keep their “API call” costs next to 0. 

A commercially available free-for-all model will also help push the open source community further. Just like Llama.

**What’s next?** Sam Altman has said OpenAI didn’t release GPT-3 as open-source because they [didn’t think people would be able to run it.](https://gptweekly.beehiiv.com/p/peek-openais-future) Now [OpenAI is working on an open-source model.](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) This is going to be weaker than GPT-4. 

Let the battle of LLMs begin.  

## 3. EU's Proposed Legislation and Its Impact on AI Usage

[The EU parliament voted to move ahead with the E.U. AI Act.](https://www.washingtonpost.com/technology/2023/06/14/eu-parliament-approves-ai-act/) This act aims to ensure consumer protection against the dangers of AI.  

**Why is it important?** [OpenAI](https://gptweekly.beehiiv.com/p/peek-openais-future) and [Sam Altman](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) want regulations for models. They have proposed a IAEA-type of agency to stop the proliferation of LLM models. As per OpenAI, all models should be regulated and monitored. The suggestion of a license based regulation has led to significant backlash. Many people have called it “regulatory capture” - with the aim of shutting down competing LLMs.

[Licensing based regulations might not really be effective.](https://aisnakeoil.substack.com/p/licensing-is-neither-feasible-nor)

The EU is approaching regulation from a different angle. It doesn’t focus on how models are developed. Rather focuses on how AI will/can be used. They have broken down use cases into 4 categories - unacceptable (prohibited), high, medium and low risk. For example, 

Building a [Pre-Crime software](https://en.wikipedia.org/wiki/Pre-crime#:~:text=Pre%2Dcrime%20(or%20precrime),on%20crimes%20not%20yet%20committed.) to predict crimes? Building a [Social credit system](https://en.wikipedia.org/wiki/Social_Credit_System)?  Unacceptable.

Using tools to influence elections or recommendation algorithms? High (Highly regulated).

Using generative AI tools to create text or images on news sites? Medium (Add label that the content is AI generated) 

AI providers also need to disclose their training source.

To me this sounds like good legislation. What do you guys think?

But, OpenAI has warned that EU regulations might force them to pull out completely.

**What’s next?** The disclosure requirements might help various publishing companies. [AI and media companies are in talks to pay for training data](https://www.ft.com/content/79eb89ce-cea2-4f27-9d87-e8e312c8601d). Google has been leading the charge. 

Additionally, [OpenAI and Deepmind will open their models for safety and research purposes to the UK government.](https://www.politico.eu/article/openai-deepmind-will-open-up-models-to-uk-government/) 

# 🗞️10 AI news highlights and interesting reads

1. **PSA:** If you are using Repl to write code, you might want to check your OpenAI API keys. If you have left them embedded then [people can pirate and steal the keys. ](https://www.vice.com/en/article/93kkky/people-pirating-gpt4-scraping-openai-api-keys)
2. LLMs rely on human annotation or human feedback to learn. And one way to generate human annotation is crowdsourcing. But what if the crowdsource human annotators use LLMs? [Research shows 33-46% workers used LLMs](https://arxiv.org/abs/2306.07899). So, basically we go from Human -> AI -> Human -> AI. The AI ouroboros. Researchers also say [generated data to train models might cause serious issue.  ](https://arxiv.org/abs/2305.17493)
3. All the talks about [moats](https://gptweekly.beehiiv.com/p/googles-startling-leaked-memo-george-hinton-mojo) \- [Reddit might be OpenAI’s \*future\* moat](https://www.cyberdemon.org/2023/06/14/reddit-moat.html). Given the amount of complaints about how [Google search](https://www.techradar.com/opinion/the-reddit-b) [experience has deteriorated](https://www.theverge.com/2023/6/13/23759942/google-reddit-subreddit-blackout-protests) [during the blackout](https://news.ycombinator.com/item?id=36345345), this might be true?
4. [Doctors are using ChatGPT](https://www.nytimes.com/2023/06/12/health/doctors-chatgpt-artificial-intelligence.html) but not to diagnose.Rather to be [more empathetic](https://inflecthealth.medium.com/im-an-er-doctor-here-s-how-i-m-already-using-chatgpt-to-help-treat-patients-a023615c65b6). [We discussed this just a month ago](https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?utm_source=gptweekly.beehiiv.com&utm_medium=referral&utm_campaign=google-s-startling-leaked-memo-george-hinton-mojo-and-more). And guess where the data for this study came from? Reddit AskDocs. Moat FTW?!
5. Beatles to make a comeback…[using Generative AI](https://www.semafor.com/article/06/13/2023/paul-mccartney-beatles-song-ai). 
6. [SnapFusion - Text to Image diffusion on mobile phones.](https://snap-research.github.io/SnapFusion/)
7. Large context lengths are important for better GPT experience. [The secret sauce for 100k context length](https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c). 
8. There is a lot of bad AI research out there. Some border on snake oil. Most AI “research” should be double checked and challenged. A new research on huggingface said that [GPT-4 can ace MIT curriculum](https://huggingface.co/papers/2306.08997). Now someone is replicating the results and say that [GPT-4 can’t beat MIT. ](https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864)
9. Are we seeing peak AI? Especially when people from Deepmind and Meta are involved? [Mistral AI raised $113 million in seed round with no product.](https://techcrunch.com/2023/06/13/frances-mistral-ai-blows-in-with-a-113m-seed-round-at-a-260m-valuation-to-take-on-openai/) Some might say this funding is for the team and the team is really solid. The issue though is whether the valuation is justified when OpenAI and Google already have a head start.
10. [The AI Hype Wall of Shame.](https://criticalai.org/the-ai-hype-wall-of-shame/) \- Collection of articles which mislead people about AI in various aspects.

# 🧑‍🎓3 Learning Resources

1. [Building and Launching a company using GPT-4](https://sabol.io/c7921c7bbd8c4982aacbd2b71a8b9bb3) with prompts. (The author didn’t know how to code but created and launched the MVP in a month).  
2. Chatbot for your Gdrive - [https://www.haihai.ai/gpt-gdrive/](https://www.haihai.ai/gpt-gdrive/)
3. Building ChatGPT plugin using Supabase - https://supabase.com/blog/building-chatgpt-plugins-template

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
291,learnmachinelearning,open-ai,relevance,2023-09-20 19:08:05,"Say Goodbye to Servers, and Expensive middle man apps. OpenAI direct bring your own key and a iSH Alpine Linux Shell",Reasonable_Leg_7405,False,0.41,0,16ntm4j,https://i.redd.it/vt202cohlgpb1.jpg,5,1695236885.0,
292,learnmachinelearning,open-ai,relevance,2022-09-23 16:28:02,OpenAI Whisper: SOTA Speech To Text With Microphone Demo,l33thaxman,False,0.67,2,xm26m6,https://www.reddit.com/r/learnmachinelearning/comments/xm26m6/openai_whisper_sota_speech_to_text_with/,0,1663950482.0,"OpenAI has released a Speech To Text model that nears human performance.  This video goes over the basics of the model, as well as how to run it with a microphone.

[https://youtu.be/nwPaRSlDSaY](https://youtu.be/nwPaRSlDSaY)"
293,learnmachinelearning,open-ai,relevance,2023-09-18 11:35:26,"Intel OpenVINO 2023.1.0 released, open-source toolkit for optimizing and deploying AI inference",reps_up,False,1.0,1,16lt2p9,https://github.com/openvinotoolkit/openvino,0,1695036926.0,
294,learnmachinelearning,open-ai,relevance,2022-09-22 16:14:37,"Whisper, a general-purpose speech recognition model by OpenAI with Gradio Demo",Illustrious_Row_9971,False,0.92,37,xl5pky,https://i.redd.it/uc18wju5qfp91.png,3,1663863277.0,
295,learnmachinelearning,open-ai,relevance,2023-01-15 00:08:37,Is it still worth learning NLP in the age of API-accessibles LLM like GPT?,CrimsonPilgrim,False,0.94,64,10c509n,https://www.reddit.com/r/learnmachinelearning/comments/10c509n/is_it_still_worth_learning_nlp_in_the_age_of/,24,1673741317.0,"A question that, I hope, you will find legitimate from a data science student.

I am speaking from the point of view of a data scientist not working in research.

Until now, learning NLP could be used to meet occasional business needs like sentiment analysis, text classification, topic modeling....

With the opening of GPT-3 to the public, the rise of ChatGPT, and the huge wave of applications, sites, plug-ins and extensions based on this technology that are accessible with a simple API request, it's impossible not to wonder if spending dozens of hours diving into this field if ML wouldn't be as useful today as learning the source code of the Pandas library. 

In some specialized cases, it could be useful, but GPT-3, and the models that will follow, seem to offer more than sufficient results for the immensity of the cases and for almost all classical NLP tasks. Not only that, but there is a good chance that the models trained by giants like Open-AI (Microsoft) or Google can never be replicated outside these companies anyway.  With ChatGPT and its incomparable mastery of language, its ability to code, summarize, extract topics, understand... why would I bother to use BERT or a TF-IDF vectorizer when an API will be released? Not only it would be easily accessible, but it also would be much better at the task, faster and cheaper.

In fact, it's a concern regarding all the machine learning field in general with the arrival of powerful ""no-code"" applications, which abstract a large part of the inherent complexity of the field. There will always be a need for experts, for safeguards, but in the end, won't the Data Scientist who masters the features of GPT-3 or 4 and knows a bit of NLP be more efficient than the one who has spent hours reading Google papers and practicing on Gensim, NLTK, spacy... It is the purpose of an API to make things simpler eventually... At what point is there no more reason to be interested in the behind-the-scenes of these tools and to become simple users rather than trying to develop our own techniques?"
296,learnmachinelearning,open-ai,relevance,2022-07-16 16:08:58,How OpenAI Reduces risks for DALL·E 2,OnlyProggingForFun,False,0.67,2,w0k1zg,https://youtu.be/qh3_DnteGD0,0,1657987738.0,
297,learnmachinelearning,open-ai,relevance,2023-05-27 10:54:16,How To Build A ChatPDF App in Just 14 Minutes using Python! | Without OpenAI API,AeroArtz,False,0.66,3,13t4b0z,https://www.youtube.com/watch?v=7CD3F-S_m88&t=25s&ab_channel=AbdulRehmanIkram,2,1685184856.0,
298,learnmachinelearning,open-ai,relevance,2022-09-22 17:26:51,"How to use OpenAI's Whisper (and some accuracy, runtime, and cost benchmarks)",SleekEagle,False,1.0,5,xl7lpu,https://www.reddit.com/r/learnmachinelearning/comments/xl7lpu/how_to_use_openais_whisper_and_some_accuracy/,8,1663867611.0,"Hey everyone! I'm sure many of you know that OpenAI released Whisper yesterday- an open source speech recognition model with weights available.

I wrote a guide on [how to run Whisper](https://www.assemblyai.com/blog/how-to-run-openais-whisper-speech-recognition-model/) that also provides some benchmarks on accuracy, inference time, and cost. Let me know what you think :)"
299,learnmachinelearning,open-ai,relevance,2023-03-16 00:03:32,OpenAI's GPT 4 is out and it's multimodal! What we know so far,gordicaleksa,False,0.22,0,11sdxhz,https://www.youtube.com/watch?v=FY9Nlkoq4GI,0,1678925012.0,
