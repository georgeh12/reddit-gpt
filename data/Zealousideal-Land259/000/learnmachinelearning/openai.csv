,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,id,url,num_comments,created,body
0,learnmachinelearning,openai,top,2020-08-05 10:58:02,image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model,OnlyProggingForFun,False,0.97,636,i437om,https://www.youtube.com/watch?v=FwXQ568_io0,46,1596625082.0,
1,learnmachinelearning,openai,top,2023-01-10 11:12:01,Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI,BackgroundResult,False,0.97,452,1087ady,https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion,102,1673349121.0,
2,learnmachinelearning,openai,top,2019-10-23 23:58:05,OpenAI plays hide and seek and breaks the game. (Reinforcement Learning),UnintelligibleThing,False,0.97,346,dm86ay,https://www.youtube.com/watch?v=Lu56xVlZ40M,19,1571875085.0,
3,learnmachinelearning,openai,top,2023-01-19 07:56:20,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.96,332,10fw2df,https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/,47,1674114980.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
4,learnmachinelearning,openai,top,2022-01-22 13:55:19,"Consolidated Video lectures for Machine Learning(including DL, CV, NLP, etc)",slim_but_not_shady,False,0.99,256,sa30oc,https://www.reddit.com/r/learnmachinelearning/comments/sa30oc/consolidated_video_lectures_for_machine/,23,1642859719.0,"**Video Lectures for Machine Learning(Theory):**

**Machine Learning:**

Cornell CS4780: [https://www.youtube.com/playlist?list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS](https://www.youtube.com/playlist?list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS)

Stanford CS 229:

[https://www.youtube.com/playlist?list=PLoROMvodv4rNH7qL6-efu\_q2\_bPuy0adh](https://www.youtube.com/playlist?list=PLoROMvodv4rNH7qL6-efu_q2_bPuy0adh)

IIT Madras:

[https://www.youtube.com/playlist?list=PL1xHD4vteKYVpaIiy295pg6\_SY5qznc77](https://www.youtube.com/playlist?list=PL1xHD4vteKYVpaIiy295pg6_SY5qznc77)

IISc Bangalore(Rigorous Math):

[https://www.youtube.com/playlist?list=PLbMVogVj5nJSlpmy0ni\_5-RgbseafOViy](https://www.youtube.com/playlist?list=PLbMVogVj5nJSlpmy0ni_5-RgbseafOViy)

Applied Machine Learning Cornell CS5787:

[https://www.youtube.com/playlist?list=PL2UML\_KCiC0UlY7iCQDSiGDMovaupqc83](https://www.youtube.com/playlist?list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83)

Caltech's Machine Learning Course - CS 156 by Professor Yaser Abu-Mostafa:

[https://www.youtube.com/playlist?list=PL41qI9AD63BMXtmes0upOcPA5psKqVkgS](https://www.youtube.com/playlist?list=PL41qI9AD63BMXtmes0upOcPA5psKqVkgS)

StatQuest(Best resource for revision and visualization):

[https://www.youtube.com/user/joshstarmer?app=desktop](https://www.youtube.com/user/joshstarmer?app=desktop)

&#x200B;

**Deep Learning:**

IIT Madras(No prerequisites and great prof):

Part 1: [https://youtube.com/playlist?list=PLyqSpQzTE6M9gCgajvQbc68Hk\_JKGBAYT](https://youtube.com/playlist?list=PLyqSpQzTE6M9gCgajvQbc68Hk_JKGBAYT)

Part 2: [https://www.youtube.com/playlist?list=PLyqSpQzTE6M-\_1jAqrFCsgCcuTYm\_2urp](https://www.youtube.com/playlist?list=PLyqSpQzTE6M-_1jAqrFCsgCcuTYm_2urp)

Course link for slides and references: [http://www.cse.iitm.ac.in/\~miteshk/CS7015\_2018.html](http://www.cse.iitm.ac.in/~miteshk/CS7015_2018.html)

Neural Networks by Hinton:

[https://www.youtube.com/playlist?list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0](https://www.youtube.com/playlist?list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

 NYU DL (Taught by Prof Alfredo Canziani and Prof Yann Lecun):

[https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI](https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI) 

**Computer Vision(Deep Learning):**

Michigan University:

[https://youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r](https://youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r)

(This Michigan university course is the updated version of Stanford’s CS231n CV course and includes all the content covered by that as well)

Advanced Deep Learning for Computer Vision by TU Munich:

[https://www.youtube.com/playlist?list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39](https://www.youtube.com/playlist?list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39)

**Natural Language Processing(Deep Learning):**

Stanford CS 224n:

[https://youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z](https://youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)

Natural Language Understanding Stanford CS 224u:

[https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20](https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20)

Deep Learning for NLP at Oxford with Deep Mind 2017:

[https://www.youtube.com/playlist?list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm](https://www.youtube.com/playlist?list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm)

NLP CMU 11-411/11-611:

[https://www.youtube.com/playlist?list=PL4YhK0pT0ZhXteJ2OTzg4vgySjxTU\_QUs](https://www.youtube.com/playlist?list=PL4YhK0pT0ZhXteJ2OTzg4vgySjxTU_QUs)

CMU CS11-737 Multilingual Natural Language Processing:

[https://www.youtube.com/playlist?list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5](https://www.youtube.com/playlist?list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5)

**Reinforcement Learning:**

IIT Madras:

[https://youtube.com/playlist?list=PLEAYkSg4uSQ0Hkv\_1LHlJtC\_wqwVu6RQX](https://youtube.com/playlist?list=PLEAYkSg4uSQ0Hkv_1LHlJtC_wqwVu6RQX)

Stanford CS234:

[https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)

**Deep Reinforcement Learning:**

UC Berkeley CS 285:

[https://youtube.com/playlist?list=PL\_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc](https://youtube.com/playlist?list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc)

**Other:**

CS224W: Machine Learning with Graphs

[https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn](https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn)

Stanford CS330: Multi-Task and Meta-Learning

[https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5](https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5)

Explainable AI:

[https://www.youtube.com/playlist?list=PLV8yxwGOxvvovp-j6ztxhF3QcKXT6vORU](https://www.youtube.com/playlist?list=PLV8yxwGOxvvovp-j6ztxhF3QcKXT6vORU)

Explainable AI in Industry:

[https://www.youtube.com/playlist?list=PL9ekywqME2Aj8OmKoBUaYEH7Xzi-YCRBy](https://www.youtube.com/playlist?list=PL9ekywqME2Aj8OmKoBUaYEH7Xzi-YCRBy)

**Some Math lectures(refresher):**

Linear algebra(MIT):

[https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8](https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8)

Optimization(IIT Kanpur):

[https://www.youtube.com/playlist?list=PLbMVogVj5nJRRbofh3Qm3P6\_NVyevDGD\_](https://www.youtube.com/playlist?list=PLbMVogVj5nJRRbofh3Qm3P6_NVyevDGD_)

Multivariable Calculus(MIT):

[https://www.youtube.com/playlist?list=PL4C4C8A7D06566F38](https://www.youtube.com/playlist?list=PL4C4C8A7D06566F38)

Probability and Statistics(Harvard):

[https://www.youtube.com/playlist?list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo](https://www.youtube.com/playlist?list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo)

&#x200B;

If you are applying for a job, ML and DL is sufficient for a DS/ML Engineer role initially(Given that you know programming and have completed some projects). But depending on the JD and the work that the company does, Computer vision and Natural Language Processing questions can be expected.

Disclaimer: The video list includes some advanced topics(Meta-learning, Graph ML, etc) which might not be relevant for a person who is applying for a ML Engineer job(unless your job involves work or research related to those topics)

**Some basic Python libraries that you need to be familiar with:**

ML: Sckit-learn, xgboost, catboost, lightgbm, hyperopt etc

DL: Tensorflow, PyTorch, Keras, etc

NLP and transformers: HuggingFace

RL: OpenAI Gym, etc

Production: MLFlow, Apache Airflow, Kubeflow, etc (This is not a hardcore requirement but some companies ask questions on production tools)

Explainable AI: SHAP, LIME, ELI5, tf-explain, captum, etc( Not a hardcore requirement for interviews)"
5,learnmachinelearning,openai,top,2019-05-16 23:01:12,Learning Machine Learning Resources,rhklite,False,0.99,246,bpjh2a,https://www.reddit.com/r/learnmachinelearning/comments/bpjh2a/learning_machine_learning_resources/,14,1558047672.0,"I collected a bunch of machine learning resources for my self studying, thought I'd share it here, could be of use to other people.

&#x200B;

* ★ are resources that were highly recommended by others
* **tags:**    `course` ,   `book` ,   `git-repo` ,   `blog-post` ,   `video` ,   `cheat-sheet` ,   `list`

## Machine Learning

* [Coursera Machine Learning, Andrew Ng](https://www.coursera.org/learn/machine-learning)   `introductory course`  ★
* [Introduction to Computational Thinking and Data Science](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/)   `introductory course`
* [Machine Learning MIT Open Courseware](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/)   `course`
* [Amazon AWS Machine Learning Course](https://aws.amazon.com/training/learning-paths/machine-learning/)   `course`
* [Virgilio - Mentor for Data Science E-Learning](https://github.com/virgili0/Virgilio)   `course`

&#x200B;

* [Machine Learning Yearning - Andrew Ng](https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf)   `book`   ★
* [Mathmatics for Machine Learning, Marc Peter Deisenroth](https://mml-book.github.io/)   `book`
* [The Hundred-page Machine Learning Book, Andriy Burkov](http://themlbook.com/wiki/doku.php)   `book`
* [Model Based Machine Learning](http://mbmlbook.com/toc.html)  `book`
* [Coursera Machine Learning - Python Code, JWarmenhoven](https://github.com/JWarmenhoven/Coursera-Machine-Learning)   `git-repo`
* [Coursera Machine Learning - Python Code, kaleko](https://github.com/kaleko/CourseraML)   `git-repo`
* [Coursera Machine Learning - Python Code, dibgerge](https://github.com/dibgerge/ml-coursera-python-assignments)   `git-repo`
* [Machine Learning Git Codebook](https://www.reddit.com/r/learnmachinelearning/comments/ax6ep5/machine_learning_git_codebook_case_study_of/?utm_medium=android_app&utm_source=share)  `git-repo`

&#x200B;

* [A Complete Machine Learning Project Walk-Through in Python](https://morioh.com/p/b56ae6b04ffc/a-complete-machine-learning-project-walk-through-in-python)  `blog-post`
* [What's the best ML Paper you read in 2018?](https://www.reddit.com/r/MachineLearning/comments/a6cbzm/d_what_is_the_best_ml_paper_you_read_in_2018_and/)   `blog-post`
* [Seeing Theory](https://seeing-theory.brown.edu/basic-probability/index.html)   `blog-post`
* [The most complete chart of Neural Networks, explained](https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464)   `blog-post`
* [The Machine Learning cheat-sheet](https://github.com/remicnrd/ml_cheatsheet)   `cheatsheet`

## Deep Learning

* [Fast.ai Online Course](https://www.fast.ai/)  `course`  ★
* [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/2017/)   `course` ★
* [CS230: Deep Learning](https://cs230.stanford.edu/)   `course`
* [Google Machine Learning Crash Course with TensorFlow APIs](https://developers.google.com/machine-learning/crash-course/)   `course`
* [MIT Deep Learning](https://www.youtube.com/watch?v=O5xeyoRL95U&list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf)   `course`
* [Deep Learning - An MIT Press Book, Ian Goodfellow](http://www.deeplearningbook.org/)   `book` ★

&#x200B;

* [TensorFlow.js - Real-Time Objection Detection in 10 Lines of Code](https://hackernoon.com/tensorflow-js-real-time-object-detection-in-10-lines-of-code-baf15dfb95b2)  `blog-post`

&#x200B;

* [Build a TensorFlow Image Classifier in 5 Min](https://www.youtube.com/watch?v=QfNvhPx5Px8)   `video`

&#x200B;

* [Deep Learning cheat-sheets covering Stanford's CS 230 Class](https://stanford.edu/~shervine/teaching/cs-230/)   `cheat-sheet`
* [cheat-sheets for AI, Neural Nets, ML, Deep Learning & Data Science](https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-science-pdf-f22dc900d2d7)   `cheat-sheet`
* [Tensorflow-Cookbook](https://github.com/taki0112/Tensorflow-Cookbook)   `cheat-sheet`

&#x200B;

* [Deep Learning Papers Reading Roadmap](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap)   `list`  ★
* [Papers with Code](https://paperswithcode.com/sota)  `list`  ★

## Reinforcement Learning

* [CS294-112 Deep Reinforcement Learning](http://rail.eecs.berkeley.edu/deeprlcourse/)   `course`
* [CMPUT 609 Reinforcement Learning - Rich Sutton](https://drive.google.com/drive/folders/0B-WvrETGtkesN29sV1g3aXZ1Z0U)   `course`
* [Deep RL Bootcamp](https://www.youtube.com/watch?v=qaMdN6LS9rA&list=PLPfj7W0fIrmy3MfjPFbpy7jFGDmvspgHE)   `course`
* [Reinforcement Learning Crash Course](https://www.youtube.com/watch?v=sOiNMW8k4T0)   `course`

&#x200B;

* [Reinforcement Learning: An Introduction Richard, S.Sutton 2ndED 2018](http://incompleteideas.net/book/the-book-2nd.html)   `book`  ★

&#x200B;

* [Open AI Spinning Up](https://spinningup.openai.com/en/latest/index.html)   `github repo` ★
* [OpenAI - Gym](https://github.com/openai/gym/wiki)  `git-repo`
* [Stable Baseline: a Fork of OpenAI Baselines - Reinforcement Learning Made Easy](https://stable-baselines.readthedocs.io/en/master/)   `git-repo`
* [PyGame Learning Environment](https://pygame-learning-environment.readthedocs.io/en/latest/)   `git-repo`
* [S-RL Toolbox](https://s-rl-toolbox.readthedocs.io/en/latest/guide/rl.html)   `git-repo`

&#x200B;

* [Google AI Blog](https://ai.googleblog.com/2019/02/long-range-robotic-navigation-via.html?fbclid=IwAR2p5UBtLyXG1Dru5-zW_lnnZF3u3T03U3XF7_2jqBZY6h3ijeIzqmYuEpI)   `blog-post`  ★
* [An introduction to Q-Learning: Reinforcement Learning](https://medium.freecodecamp.org/an-introduction-to-q-learning-reinforcement-learning-14ac0b4493cc)   `blog-post`
* [Introduction: Reinforcement Learning with Open AI Gym](https://towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2)   `blog-post`
* [An intro to Advantage Actor Critic methods](https://medium.freecodecamp.org/an-intro-to-advantage-actor-critic-methods-lets-play-sonic-the-hedgehog-86d6240171d)   `blog-post`
* [Double Q-Learning, the Easy Way](https://towardsdatascience.com/double-q-learning-the-easy-way-a924c4085ec3?fbclid=IwAR17Ht_oyJL4_1AHTqcwf1EU1RziGgRrwTskKY1xRlpLLd3T7_NKMK_V6-g)   `blog-post`
* [A Beginner's Guide to Reinforcement Learning](https://skymind.ai/wiki/deep-reinforcement-learning)   `blog-post`
* [Papaers that criticize Deep Reinforcement Learning](https://www.reddit.com/r/MachineLearning/comments/bdgxin/d_any_papers_that_criticize_deep_reinforcement/)   `blog-post`

## Artificial Intelligence

* [Techniques in Artificial Intelligence (SMA 5504) MIT Open Courseware](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-825-techniques-in-artificial-intelligence-sma-5504-fall-2002/index.htm)  `course`
* [CS 188 - Introduction to Artificial Intelligence - UC Berkeley](https://inst.eecs.berkeley.edu/~cs188/fa18/)  `course`
* [Artifical Intelligence: Foundataions of Computational Agents, 2ndED 2017](https://artint.info/2e/html/ArtInt2e.html)   `book`

## Others

* [Awesome public datasets](https://github.com/awesomedata/awesome-public-datasets)   `list`
* [100+ Basic Machine Learning Interview Questions and Answers](http://theprofessionalspoint.blogspot.com/2019/01/100-basic-machine-learning-interview.html)   `blog-post`"
6,learnmachinelearning,openai,top,2019-08-27 14:19:56,[D] What do you use to keep you update on ML/DL?,pirate7777777,False,0.99,217,cw542g,https://www.reddit.com/r/learnmachinelearning/comments/cw542g/d_what_do_you_use_to_keep_you_update_on_mldl/,11,1566915596.0,"Hi everyone! What do you use to navigate-in-the-noise and keep you update in this field? *Excluding this subreddit* which type of resources do you recommend to check regularly?

&#x200B;

Here's my list:

***Newsletters (weekly)***:

\- [ImportAI (@JackClark)](https://jack-clark.net/)

\- [The batch (@Deeplearning.ai)](https://www.deeplearning.ai/thebatch/)

&#x200B;

**Podcast & Video (weekly/monthly)**

\- [Artificial Intelligence Podcast (@Lex Fridman)](https://lexfridman.com/ai/)

\- [Two Minute papers](https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg)

&#x200B;

**Blogs (RSS newsfeed)**

\- [DeepMind](https://deepmind.com/blog)

\- [OpenAI](https://openai.com/blog/)

\- [BAIR](https://bair.berkeley.edu/blog/)

\- [Google AI](https://ai.googleblog.com/)

\- [FAIR](https://research.fb.com/category/facebook-ai-research/)

&#x200B;

**MOOCs (once per year)**

\- [Deep learning for coders p1 & p2 (@fast.ai)](https://course.fast.ai/)

\- [CS231n: DL for CV](http://cs231n.stanford.edu/)

\- [CS224d: DL for NLP](https://cs224d.stanford.edu/)

&#x200B;

**Social (once per day/week)**

\- Twitter & LinkedIn are good quite good sometimes, but too noisy.

\- Facebook groups (such as [AIDL](https://www.facebook.com/groups/DeepNetGroup/)) but most of the time, the articles shared are not really good or particularly useful.

&#x200B;

**Conferences / Events (once per year)**

\- [NIPS](https://nips.cc/)

\- [PyTorch Dev Conference](https://pytorch.fbreg.com/)

\- [TF Dev Summit](https://www.tensorflow.org/dev-summit)"
7,learnmachinelearning,openai,top,2023-02-16 10:29:31,OpenAI Has Purchased AI.Com For ChatGPT For $11M,vadhavaniyafaijan,False,0.93,212,113nizs,https://www.theinsaneapp.com/2023/02/openai-purchased-ai-com-domain.html,23,1676543371.0,
8,learnmachinelearning,openai,top,2023-06-18 15:56:44,"I made FableForge: Text Prompt to an Illustrated Children’s Book using OpenAI Function Calls, Stable Diffusion, LangChain, & DeepLake",AverageKanyeStan,False,0.96,199,14cnuz4,https://v.redd.it/5p2apjnsts6b1,6,1687103804.0,
9,learnmachinelearning,openai,top,2023-01-16 12:28:25,I benchmarked OpenAI's GPT API vs other proprietary APIs on different NLP tasks,AImSamy,False,0.9,193,10ddc1f,https://www.reddit.com/gallery/10ddc1f,37,1673872105.0,
10,learnmachinelearning,openai,top,2022-04-08 15:20:26,OpenAI 's new model DALL·E 2 is amazing!,OnlyProggingForFun,False,0.94,194,tz5x2f,https://youtu.be/rdGVbPI42sA,8,1649431226.0,
11,learnmachinelearning,openai,top,2023-09-23 13:42:22,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.96,184,16q4ve6,https://www.reddit.com/r/learnmachinelearning/comments/16q4ve6/this_week_in_ai_all_the_major_ai_developments_in/,16,1695476542.0,"1. **Genmo** releases a new text-to-video model: **Genmo Replay** v0.1, which generates high-quality videos from text without the need for advanced prompt engineering. *Genmo is available for free to create AI videos* \[[*Details*](https://blog.genmo.ai/log/replay-ai-video) | [Genmo *Replay*](https://www.genmo.ai/)\] .
2. **OpenAI** unveils **DALL·E 3** \- a major update to the text-to-image model, which will be integrated in ChatGPT. It will be available to ChatGPT Plus and Enterprise users in October, via the API and in Labs later this fall. Creators can now also opt their images out from future training.
3. **Toyota Research Institute** has developed a technique, powered by generative AI, that enables teaching robots new manipulation abilities in a single afternoon. Using the same robot, same code, and same setup, TRI taught over 60 different dexterous behaviors like peeling vegetables, using hand mixers, preparing snacks, and flipping pancakes.
4. **Microsoft** announced:
   1. Availability of AI Copilot for Windows from September 26th. Copilot will incorporate the context and intelligence of the web, your work data and what you are doing in the moment on your PC to provide better assistance. It will be integrated in Windows 11, Microsoft 365, Edge and Bing.
   2. Bing will add support for DALL.E 3 and deliver more personalized answers based on search history.
   3. New AI powered experiences in Paint, Photos and Clipchamp.
   4. New AI-powered shopping experience
5. **ElevenLabs** released **Projects** \- a tool that lets you generate an entire audiobook at the click of a button. Projects now supports .epub, .pdf, and .txt file imports, as well as initializing a project from a URL.
6. **Deci** presents **DeciDiffusion 1.0** \- an open-source text-to-image latent diffusion model which is 3x faster than Stable Diffusion v1.5 with the same quality.
7. **Google researchers** present a new approach that produces photo-realistic animations from a single picture. The model is trained on automatically extracted motion trajectories from a large collection of real video sequences.
8. **Google** has updated Bard\*\]\*:
9. **Bard Extensions:** With extensions, Bard can now connect to your Google apps and services like Gmail, Docs, Drive, Google Maps, YouTube, and Google Flights and hotels.
10. Users can use Bard’s “Google it” button to more easily double-check its answers and evaluate whether there is content across the web to substantiate it.
11. Bard can now let you continue chat via **shared public links**
12. **YouTube** announces new AI tools for creators. **Dream Screen** will let users create an AI-generated video or image background from text. Automatic AI-dubbing tool called **Aloud**, which will be integrated into YouTube Studio. **AI-powered insights** to generate video ideas and draft outlines. **Assistive Search in Creator Music** where AI will suggest the right music based on your description of your content.
13. **Amazon** announced that its voice assistant Alexa is being upgraded with a new, custom-built large language model.
14. **IBM** open-sources **MoLM** \- a collection of ModuleFormer-based language models ranging in scale from 4 billion to 8 billion parameters. ModuleFormer is a new neural network architecture based on the Sparse Mixture of Experts (SMoE) by IBM researchers. .
15. **Neuralink**, Elon Musk's brain implant startup, set to begin human trials.
16. **Lexica** has released **Aperture v3.5** \- their latest next-gen image model that can create photorealistic images and follows your prompt with precision.
17. **OpenAI** has invited domain experts to collaborate in evaluating and improving the safety of OpenAI's models by joining the new **OpenAI Red Teaming Network**.
18. \*\*GitHub Copilot Chat (\*\*beta) is now available for all individuals.
19. **Replit** announced a virtual hackathon for projects built using **Replit ModelFarm**
20. **Oracle** brings voice-activated AI to healthcare with Clinical Digital Assistant.
21. **Google** and the Department of Defense are building an AI-powered microscope to help doctors spot cancer.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
12,learnmachinelearning,openai,top,2023-05-11 00:54:18,What do actual ML engineers think of ChatGPT?,PhillConners,False,0.96,151,13e8of2,https://www.reddit.com/r/learnmachinelearning/comments/13e8of2/what_do_actual_ml_engineers_think_of_chatgpt/,106,1683766458.0,"You have been doing this for awhile, now the world is obsessed with OpenAI and suddenly all full of AI “experts”."
13,learnmachinelearning,openai,top,2021-01-18 15:30:22,Reinforcement Learning Crash Course (Free),rroocckk,False,0.95,142,kzwso5,https://www.reddit.com/r/learnmachinelearning/comments/kzwso5/reinforcement_learning_crash_course_free/,18,1610983822.0,"I wanted to announce the new and free [Reinforcement Learning Crash Course](https://rlcourse.com).

This course takes a _unique hands-on approach_ to teaching Reinforcement Learning.

- Reinforcement Learning concepts are communicated primarily via code examples (Python, Gym and Keras). 

- Mathematical equations are kept to a minimum. 

Therefore, the course should appeal to you if you like a practical approach to learning, devoid of mathematical pedantry. Plus, you can be an absolute beginner. You don't need any prior machine learning knowledge to understand the content. Machine Learning and Deep Learning concepts are introduced and explained within the course when needed.

This is my attempt at creating a Reinforcement Learning course that **programmers** can love. I am hoping that this further democratizes the amazing capabilities of RL. I have tried to maintain the high standards found in David Silver's course or The Deep RL Bootcamp at Berkeley, but replacing mathematics with code as the main learning UI. I am also inspired by François Chollet's intuitive and code-first approach in his book Deep Learning with Python.

I make the course in my free time, and that allows me to upload 1 video on a new topic per week. The first chapter is already published at the time of this announcement and the rest will come in the next months according to a planned schedule. I have decided that if you enroll now (while the course is being made), it will be **free and you keep all the content forever**. 

In the already published chapter, you will be introduced to Reinforcement Learning basics. This way, you can already take the course for a test drive and see if you like my code-first approach. 

Take a look at the detailed syllabus to find what to expect from later chapters. Briefly speaking, we will take a code-oriented approach to learning classical Reinforcement Learning algorithms like GLIE Monte Carlo, SARSA etc. and Deep RL algorithms like PPO and DQN. We will pay special attention to the following topics: 

- Writing modular and extensible code
- How to make results reproducible
- Logging
- Monitoring
- Best practices for running RL experiments. 

There will also be plenty of practice problems where you will be able to test out your new skills. At the end of the course, you will have solved 5 interesting OpenAI Gym environments, covering everything from classic problems, bipedal walking to playing games. After doing the course, you will be able to confidently apply RL to other problems that catch your fancy.

Thank you for taking the time to read all of this.  The [course page](https://rlcourse.com) has more details."
14,learnmachinelearning,openai,top,2023-09-16 13:22:41,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.95,134,16k7heb,https://www.reddit.com/r/learnmachinelearning/comments/16k7heb/this_week_in_ai_all_the_major_ai_developments_in/,17,1694870561.0,"1. **Stability AI** launched Stable Audio, a generative AI tool for music & sound generation from text. The underlying latent diffusion model architecture uses audio conditioned on text metadata as well as audio file duration and start time.
2. **Coqui** released **XTTS** \- a new voice generation model that lets you clone voices in 13 different languages by using just a quick 3-second audio clip.
3. **Microsoft Research** released and open-sourced **Phi-1.5** \- a 1.3 billion parameter transformer-based model with performance on natural language tasks comparable to models 5x larger.
4. **Project Gutenberg**, Microsoft and MIT have worked together to use neural text-to-speech to create and release thousands of **human-quality free and open audiobooks**.
5. Researchers present **NExT-GPT -** an any-to-any multimodal LLM that accepts inputs and generate outputs in arbitrary combinations of text, images, videos, and audio.
6. **Chain of Density (CoD):** a new prompt introduced by researchers from Salesforce, MIT and Colombia University that generates more dense and human-preferable summaries compared to vanilla GPT-4.
7. **Adept** open-sources **Persimmon-8B**, releasing it under an Apache license. The model has been trained from scratch using a context size of 16K.
8. **Adobe's** **Firefly** generative AI models, after 176 days in beta, are now commercially available in Creative Cloud, Adobe Express, and Adobe Experience Cloud. Adobe is also launching Firefly as a standalone web app.
9. **Deci** released **DeciLM 6B**, a permissively licensed, open-source foundation LLM that is 15 times faster than Llama 2 while having comparable quality.
10. Researchers release **Scenimefy** \- a model transforming real-life photos into Shinkai-animation-style images.
11. **Microsoft** open sources **EvoDiff**, a novel protein-generating AI that could be used to create enzymes for new therapeutics and drug delivery methods as well as new enzymes for industrial chemical reactions.
12. Several companies including Adobe, IBM, Nvidia, Cohere, Palantir, Salesforce, Scale AI, and Stability AI have pledged to the White House to develop safe and trustworthy AI, in a voluntary agreement similar to an earlier one signed by Meta, Google, and OpenAI.
13. **Microsoft** will provide legal protection for customers who are sued for copyright infringement over content generated using Copilot, Bing Chat, and other AI services as long as they use built-in guardrails.
14. **NVIDIA** beta released **TensorRT** \- an open-source library that accelerates and optimizes inference performance on the latest LLMs on NVIDIA Tensor Core GPUs.
15. Pulitzer Prize winning novelist Michael Chabon and several other writers sue OpenAI of copyright infringement..
16. **NVIDIA** partners with two of India’s largest conglomerates, Reliance Industries Limited and Tata Group, to create an AI computing infrastructure and platforms for developing AI solutions.
17. **Roblox** announced a new conversational AI assistant that let creators build virtual assets and write code with the help of generative AI.
18. **Google** researchers introduced **MADLAD-400** \- a 3T token multilingual, general web-domain, document-level text dataset spanning 419 Languages.
19. A recent survey by **Salesforce** show that 65% of generative AI users are Millennials or Gen Z, and 72% are employed.  The survey included 4,000+ people across the United States, UK, Australia, and India.
20. **Meta** is reportedly working on an AI model designed to compete with GPT-4.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
15,learnmachinelearning,openai,top,2023-05-25 17:23:19,"Are people still coding stuff on their own like chatbots, image AIs, etc., or is everyone just using pretrained models and APIs now?",TrackLabs,False,0.91,94,13rnopr,https://www.reddit.com/r/learnmachinelearning/comments/13rnopr/are_people_still_coding_stuff_on_their_own_like/,35,1685035399.0,"I feel like everyone is just downloading models from huggingface at this point, or using GPT APIs and so on.

I also feel like there are not really tutorials anymore on YT and the web about how to code stuff like there used to be 5 to 2 years ago. Every video now is just ""how to use OpenAIs API"" or ""how to use llama model from huggingface"". 

I have a big problem with staying up to date on the stuff, I never really bothered using huggingface, and I dont really like the idea to just use other peoples pretrained models for everything, what actual contribution am I doing in my own projects then lol.

Would be cool if some people could give me some reality check on whats going on."
16,learnmachinelearning,openai,top,2023-06-14 09:08:23,"Introducing, OpenLLM 🎉",AaZasDass,False,0.96,88,149302y,https://www.reddit.com/r/learnmachinelearning/comments/149302y/introducing_openllm/,15,1686733703.0,"OpenLLM allows you to run inferences with any open-source LLMs, deploy to the cloud or on-premises, and build powerful AI apps. It includes simple and familiar APIs, enabling easy integration with tools such as LangChain, and BentoML! Discover more at [https://github.com/bentoml/OpenLLM](https://github.com/bentoml/OpenLLM)

To get started, install it with pip: `pip install -U openllm`  Currently, it has support for all major SOTA LLMs, including Falcon, ChatGLM, Dolly V2, StableLM, and more to come!

Some of the feature that is currently wip:

\- Fine-tuning API with `LLM.tuning()`

\- LangChain integration [https://github.com/hwchase17/langchain/pull/6064](https://github.com/hwchase17/langchain/pull/6064)

\- OpenAI Compatible API

    import openai
    
    openai.api_base = ""http://localhost:3000"" # Running with OpenLLM
    
    completion = openai.Completion.create(...)

We are currently actively developing the library, so we would love to hear your thoughts and feedback. Feel free also to join our [discord](https://l.bentoml.com/join-openllm-discord) to meet other fellows, AI application builders, and enthusiasts."
17,learnmachinelearning,openai,top,2022-10-19 09:27:38,Fixing YouTube Search with OpenAI's Whisper,jamescalam,False,0.95,79,y7xxri,https://www.reddit.com/r/learnmachinelearning/comments/y7xxri/fixing_youtube_search_with_openais_whisper/,13,1666171658.0,"Hi all, I wanted to [build a ""YouTube search"" app](https://www.pinecone.io/learn/openai-whisper/) for some time. Not the typical YouTube search where you return videos, but a YouTube search that returns the specific part of a video that answers your question. With text-based data this is pretty easy, but video/audio is less so.

That was until OpenAI (open sourced?) Whisper, a new SotA for speech-to-text. So I went ahead and built [""Ask YouTube""](https://huggingface.co/spaces/jamescalam/ask-youtube). A little search bar where you can ask technical questions and get the exact most relevant part from a set of videos (for now, the video scope is limited, I'll add more soon).

I explained everything I did to build it in [the linked article](https://pinecone.io/learn/openai-whisper/) and [video](https://youtu.be/vpU_6x3jowg). You could also just grab the app code and replicate it, I don't think it would take long. At a high level it is:

* Download YouTube audio with `pytube`
* Transcribe with OpenAI's Whisper
* Do some data prep
* Encode using Hugging Face / sentence-transformers
* Index and query with Pinecone vector DB

Then I wrapped all of this into a quick Streamlit web app and hosted it all for free on Hugging Face Spaces. One somewhat surprising thing here is absolutely everything was either open source or free, I didn't pay a dime!

Anyway, I hope this is interesting. Let me know what you think!"
18,learnmachinelearning,openai,top,2021-09-19 07:59:15,AI research papers explainer channel.,gauravc2796,False,0.84,80,pr3sc7,https://www.reddit.com/r/learnmachinelearning/comments/pr3sc7/ai_research_papers_explainer_channel/,12,1632038355.0,"Hi, I have started a youtube channel where I would provide some explainer on the latest AI research papers as I have happened to read a lot of them.  
If you have any suggestions, comments, or anything, do let me know.   
Your opinion would be highly valuable :)  
Channel: [https://www.youtube.com/channel/UCYEXrPn4gP9RbaSzZvxX6MA](https://www.youtube.com/channel/UCYEXrPn4gP9RbaSzZvxX6MA)  


Some Videos which have been created till now:

Textless NLP: [https://www.youtube.com/watch?v=zw\_QjUptr5o](https://www.youtube.com/watch?v=zw_QjUptr5o)  
Neural DB: [https://www.youtube.com/watch?v=Vo9L0LETMI4](https://www.youtube.com/watch?v=Vo9L0LETMI4)  
Perceiver IO: [https://www.youtube.com/watch?v=AS1Sh-KuNzs](https://www.youtube.com/watch?v=AS1Sh-KuNzs)  
Openai's GPT codex: [https://www.youtube.com/watch?v=8977dybJ7Ro](https://www.youtube.com/watch?v=8977dybJ7Ro)"
19,learnmachinelearning,openai,top,2019-04-14 05:14:01,Humans Call GG! OpenAI Five Bots Beat Top Pros OG in Dota 2,gwen0927,False,0.91,74,bczjd5,https://medium.com/syncedreview/humans-call-gg-openai-five-bots-beat-top-pros-og-in-dota-2-8508e59b8fd5,7,1555218841.0,
20,learnmachinelearning,openai,top,2019-04-25 04:55:07,"Took too long to research and write about DeepMind's AlphaStar. After OpenAI's Dota 2 bot, I finally wrote a technical summary.",jshek,False,0.94,72,bh4odw,https://www.reddit.com/r/learnmachinelearning/comments/bh4odw/took_too_long_to_research_and_write_about/,3,1556168107.0,"I've been researching and reading about AlphaStar for months, but I was never able to put pen to paper and write. After OpenAI's Dota 2 events the last two weeks, I forced myself to summarize all the research I had read into deep reinforcement learning onto an article. 

[https://www.senrigan.io/blog/takeaways-from-openai-5](https://www.senrigan.io/blog/takeaways-from-openai-5)

Love to know your thoughts! I compare both bots (OpenAI's Dota 2 vs. AlphaStar)."
21,learnmachinelearning,openai,top,2022-09-23 13:46:55,Created a GUI for OpenAI's Whisper Using Gradio,ImplodingCoding,False,0.96,70,xly2gp,https://v.redd.it/6djgfjpp4mp91,9,1663940815.0,
22,learnmachinelearning,openai,top,2018-11-09 03:14:53,"Spinning Up in Deep RL - ""...an educational resource produced by OpenAI that makes it easier to learn about deep reinforcement learning (deep RL).""",ClydeMachine,False,0.93,61,9vgwch,https://blog.openai.com/spinning-up-in-deep-rl/,3,1541733293.0,
23,learnmachinelearning,openai,top,2018-06-25 17:11:58,OpenAI Five,j_orshman,False,0.97,55,8ts9a7,https://blog.openai.com/openai-five/,2,1529946718.0,
24,learnmachinelearning,openai,top,2023-05-19 07:08:51,OpenAI Launches ChatGPT App For iOS Users,vadhavaniyafaijan,False,0.88,55,13lnv1e,https://www.theinsaneapp.com/2023/05/chatgpt-app-for-iphone-and-ipad.html,10,1684480131.0,
25,learnmachinelearning,openai,top,2023-01-29 21:14:13,Create a Serverless Search Engine using the OpenAI Embeddings API,sopmac21379,False,0.95,52,10oitli,https://medium.com/sopmac-ai/create-a-serverless-search-engine-using-the-openai-embeddings-api-50e5ac8ca6e3,1,1675026853.0,
26,learnmachinelearning,openai,top,2023-08-16 11:26:18,OpenAI Notebooks which are really helpful,vishank97,False,0.93,51,15sn6ti,https://www.reddit.com/r/learnmachinelearning/comments/15sn6ti/openai_notebooks_which_are_really_helpful/,2,1692185178.0,"The OpenAI cookbook is one of the most underrated and underused developer resources available today. Here are 7 notebooks you should know about:

1. Improve LLM reliability:  
[https://github.com/openai/openai-cookbook/blob/main/techniques\_to\_improve\_reliability.md](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)
2. Embedding long text inputs:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Embedding\_long\_inputs.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Embedding_long_inputs.ipynb)
3. Dynamic masks with DALLE:  
[https://github.com/openai/openai-cookbook/blob/main/examples/dalle/How\_to\_create\_dynamic\_masks\_with\_DALL-E\_and\_Segment\_Anything.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/dalle/How_to_create_dynamic_masks_with_DALL-E_and_Segment_Anything.ipynb)
4. Function calling to find places nearby:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Function\_calling\_finding\_nearby\_places.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Function_calling_finding_nearby_places.ipynb)
5. Visualize embeddings in 3D:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Visualizing\_embeddings\_in\_3D.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Visualizing_embeddings_in_3D.ipynb)
6. Pre and post-processing of Whisper transcripts:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Whisper\_processing\_guide.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Whisper_processing_guide.ipynb)
7. Search, Retrieval, and Chat:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Question\_answering\_using\_a\_search\_API.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_a_search_API.ipynb)

Big thanks to the creators of these notebooks!"
27,learnmachinelearning,openai,top,2023-04-29 09:21:53,Prompt Engineering Free Course For Beginners By OpenAI And Deep Learning AI,vadhavaniyafaijan,False,0.78,50,132o8tt,https://www.theinsaneapp.com/2023/04/free-prompt-engineering-course-for-beginners.html,7,1682760113.0,
28,learnmachinelearning,openai,top,2024-01-04 21:15:12,Natural Language Processing (NLP) Learning Path - In depth,millhouse056,False,0.98,47,18yo5kp,https://www.reddit.com/r/learnmachinelearning/comments/18yo5kp/natural_language_processing_nlp_learning_path_in/,9,1704402912.0,"Hi friends, i'm currently engaged in NLP and created an pretty extense roadmap or learning path so begginers don't feel lost, it covers from the basics to advanced cutting-edge concepts.

Feedback is appreciated.

&#x200B;

\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-

&#x200B;

NLP Learning Roadmap

1. Prerequisites:

&#x200B;

* Mathematics:

&#x200B;

* Linear algebra
* Probability and statistics

&#x200B;

* Programming:

&#x200B;

* Proficiency in a programming language (e.g., Python)

**2. Introduction to NLP:**

&#x200B;

* Definition      and scope of NLP
* Historical      development of NLP
* Key challenges      and applications

**3. Text Analysis:**

&#x200B;

* **Lexical Analysis:**

&#x200B;

* Word meaning and structure

· Morphology (word formation)

· lemmatization (base form identification)

&#x200B;

* **Syntactic Analysis:**

· Parts-of-speech tagging

· Dependency parsing

· Constituency parsing

&#x200B;

* **Semantic Analysis:**

· Extracting meaning

· Encompassing word embedding models like Word2Vec and GloVe

· Topic modeling

&#x200B;

* **Semantic Analysis:**

· Coreference resolution

· Discourse analysis

&#x200B;

**3. Text Processing:**

&#x200B;

* **Tokenization:**

&#x200B;

* Sentence tokenization
* Word tokenization
* Subword tokenization (Byte Pair Encoding, SentencePiece)

&#x200B;

* **Stop Words Removal:**

&#x200B;

* Importance and impact on NLP tasks
* Customizing stop word lists

&#x200B;

* **Stemming and Lemmatization:**

&#x200B;

* Porter stemming algorithm
* Snowball stemming algorithm
* Lemmatization techniques and challenges

&#x200B;

* **Part-of-Speech Tagging:**

 

* POS tagging algorithms (HMM-based, rule-based, and neural-based)
* Fine-grained POS tagging

**4. Text Representation:**

&#x200B;

* **Bag of Words (BoW):**

 

* Term Frequency (TF) and Inverse Document Frequency (IDF)
* Bag of N-grams

&#x200B;

* **TF-IDF:**

 

* Calculating TF-IDF scores
* Applications in information retrieval

&#x200B;

* **Word Embeddings:**

 

* Word2Vec:

&#x200B;

* Continuous Bag of Words (CBOW) model
* Skip-gram model
* GloVe (Global Vectors for Word Representation)

&#x200B;

* **Contextual Embeddings:**

 

* ELMo (Embeddings from Language Models)
* ULMFiT (Universal Language Model Fine-tuning)
* OpenAI GPT (Generative Pre-trained Transformer)

**5. NLP Libraries and Tools:**

&#x200B;

* NLTK      (Natural Language Toolkit)
* SpaCy
* scikit-learn
* Transformers      library (Hugging Face)

**6. Statistical Language Models:**

&#x200B;

* **N-grams:**

 

* Unigrams, bigrams, and trigrams
* N-gram language models

&#x200B;

* **Hidden Markov Models (HMM):**

 

* Basics of HMMs
* Applications in part-of-speech tagging

**7. Machine Learning for NLP:**

&#x200B;

* **Supervised Learning:**

 

* Text classification algorithms (Naive Bayes, Support Vector       Machines)
* Evaluation metrics (precision, recall, F1-score)

&#x200B;

* **Named Entity Recognition (NER):**

 

* Rule-based NER
* Machine learning-based NER
* Evaluation metrics for NER

&#x200B;

* **Sentiment Analysis:**

 

* Sentiment lexicons
* Machine learning approaches for sentiment analysis

**8. Sequence-to-Sequence Models:**

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Vanishing and exploding gradient problems
* Bidirectional RNNs

&#x200B;

* **Long Short-Term Memory (LSTM):**

 

* Architecture and key components
* Gating mechanisms

&#x200B;

* **Gated Recurrent Unit (GRU):**

 

* Simplified gating compared to LSTM
* Applications and advantages

**9. Deep Learning Architectures for NLP:**

&#x200B;

* **Convolutional Neural Networks (CNN) for Text:**

 

* Text classification with CNNs
* Hierarchical and multi-channel CNNs

&#x200B;

* **Transfer Learning in NLP:**

 

* Fine-tuning pre-trained models
* Universal Sentence Encoder

&#x200B;

* **Transformer Architecture:**

 

* Self-attention mechanism
* Multi-head attention
* Positional encoding

**10. Transduction and Recurrency:**

&#x200B;

* **Transduction in NLP:**

 

* Definition and applications
* Challenges in sequence-to-sequence transduction

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Applications beyond sequence-to-sequence tasks
* Challenges in training RNNs

**11. Advanced Topics in Sequence Modeling:**

&#x200B;

* **Attention Mechanism:**

 

* Scaled Dot-Product Attention
* Position-wise Feedforward Networks

&#x200B;

* **Self-Attention Mechanism:**

 

* The concept of self-attention
* Layer normalization in self-attention

&#x200B;

* **Multi-Head Attention:**

 

* Motivation and benefits
* Combining multiple attention heads

**12. Syntax and Parsing:**

&#x200B;

* **Dependency Parsing:**

 

* Dependency tree representation
* Transition-based and graph-based parsing

&#x200B;

* **Constituency Parsing:**

 

* Treebank representation
* Earley parsing algorithm

&#x200B;

* **Parsing Techniques:**

 

* Chart parsing (CYK parser)
* Shift-Reduce parsing

**13. Semantic Role Labeling (SRL) and Coreference Resolution:**

&#x200B;

* **Semantic Role Labeling:**

&#x200B;

* PropBank and FrameNet
* Neural approaches to SRL

&#x200B;

* **Coreference Resolution:**

&#x200B;

* Mention detection
* End-to-end coreference resolution models

**14. Evaluation Metrics:**

&#x200B;

* Precision,      Recall, F1-score
* BLEU      score for machine translation
* Perplexity      for language models

**15. NLP in Industry and Research:**

&#x200B;

* Case      studies and applications in various domains (healthcare, finance, legal,      etc.)
* Emerging      research trends in NLP

**16. Ethical Considerations and Bias in NLP:**

&#x200B;

* **Addressing Bias in NLP Models:**

&#x200B;

* Identifying and mitigating biases in training data
* Fairness-aware machine learning

&#x200B;

* **Ethical Considerations in NLP Research and      Deployment:**

&#x200B;

* Privacy concerns in NLP
* Responsible AI practices in NLP

**17. Continuous Learning and Keeping Updated:**

&#x200B;

* Follow      conferences (ACL, NAACL, EMNLP)
* Engage      with the NLP community
* Explore      recent research papers and advancements (Arxiv, NeurIPS)

**18. Projects and Hands-on Practice:**

&#x200B;

* Apply      knowledge through practical projects
* Contribute      to open-source NLP projects
* Participate      in Kaggle competitions

==============================="
29,learnmachinelearning,openai,top,2018-04-27 07:22:52,"Karpathy says NNs should avoid regression problems (in favor of classification). Yet in Q-Learning, the function approximator is often an NN, even when the action space is discrete (and Q-Learning could be converted to a classification problem). Is CS231n correct?",Frozen_Turtle,False,1.0,45,8f9tes,https://www.reddit.com/r/learnmachinelearning/comments/8f9tes/karpathy_says_nns_should_avoid_regression/,16,1524813772.0,"From https://cs231n.github.io/neural-networks-2/ (emphasis mine):

>It is important to note that the L2 loss is much harder to optimize than a more stable loss such as Softmax. Intuitively, it requires a very fragile and specific property from the network to output exactly one correct value for each input (and its augmentations). Notice that this is not the case with Softmax, where the precise value of each score is less important: It only matters that their magnitudes are appropriate. Additionally, the L2 loss is less robust because outliers can introduce huge gradients. ***When faced with a regression problem, first consider if it is absolutely inadequate to quantize the output into bins.*** For example, if you are predicting star rating for a product, it might work much better to use 5 independent classifiers for ratings of 1-5 stars instead of a regression loss. Classification has the additional benefit that it can give you a distribution over the regression outputs, not just a single output with no indication of its confidence. If you’re certain that classification is not appropriate, use the L2 but be careful: For example, the L2 is more fragile and applying dropout in the network (especially in the layer right before the L2 loss) is not a great idea.

Outliers are not an issue in RL, which leaves only this:

>L2 loss is much harder to optimize than a more stable loss such as Softmax. Intuitively, it requires a very fragile and specific property from the network to output exactly one correct value for each input (and its augmentations).

I don't know what what the above means: What is a property? Why is it fragile? What is an augmentation? If you have any answers or know any links that discuss this issue, please let me know.

The typical Q-learning function approximator predicts (continuous) q-values, on which the agent acts ε greedy. In RL problems with discrete action spaces, is it wise to modify the Q-learning algorithm to directly predict actions instead of Q-values? Or should I stick with ε-maxing over ""unstable"" q-values? 

Anyway, even though regression may be less stable than classification, it seems to work anyway if we throw enough episodes at it :)

---

Post nap realization:

David Silver discusses 3 types of value function approximators [here](https://youtu.be/UoPei5o4fps?t=522):

1) Input is the state, output is the value function.

2) Input is the state and action, output is a q value.

3) Input is the state, output is the q value for every action.

All types could be interpreted as regression NNs. However, through a certain lens and also by using loose definitions, type 3 is a classification NN. When I speak about classification and regression NNs, here's what I have in mind:

* classification NNs typically have an output node for each class. The last layer's activation function is typically a softmax.

* regression NNs typically have one output node with no activation function, aka the linear activation function.

Value function approximators type 1 and 2 look like regression NNs. Type 3 looks kiiiiiinda like a classification NN. It has an output node for each action, and predicts q-values, which technically makes it a regression. But since the next step in the Q-learning algorithm is a ε greedy action, the *system* of the NN+ε greedy is choosing an action, this effectively makes it a classification style NN. It is classifying which action to take given the state.

Anyway, Silver says their DQNs use type 3 in solving the Atari problems, so I'll probably use that in my attempts to solve OpenAI's gyms. If anyone wants to criticize my realization here, please do so! I hardly consider this a closed issue.

---
---
---

# Links I've found discussing NN and regression problems

Many links seem to ignore or fail to mention the above advice from CS231n:

* https://www.reddit.com/r/learnmachinelearning/comments/7j2l4o/what_do_i_have_to_change_for_a_neural_network_to/

* https://www.quora.com/Can-Deep-Learning-and-Neural-Networks-be-useful-for-regression-problems-where-the-output-variable-has-an-unknown-or-varying-in-real-time-upper-bound

* https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/

* https://www.reddit.com/r/learnmachinelearning/comments/65sh1x/creating_a_deep_neural_network_regression_model/

* https://www.quora.com/Can-Deep-Learning-and-Neural-Networks-be-useful-for-regression-problems-where-the-output-variable-has-an-unknown-or-varying-in-real-time-upper-bound

In particular, the DQN implementations I've seen all predict Q-values and not actions (even if the action space is discrete), such as:

* https://jaromiru.com/2016/10/03/lets-make-a-dqn-implementation/

* https://github.com/dennybritz/reinforcement-learning/blob/master/DQN/Deep%20Q%20Learning%20Solution.ipynb"
30,learnmachinelearning,openai,top,2023-11-23 10:24:00,"Nonfiction authors sue OpenAI, Microsoft for copyright infringement",anujtomar_17,False,0.83,38,181y9sl,https://newyorkverified.com/4324297-nonfiction-authors-sue-openai-microsoft-copyright-infringement/,34,1700735040.0,
31,learnmachinelearning,openai,top,2022-09-22 16:14:37,"Whisper, a general-purpose speech recognition model by OpenAI with Gradio Demo",Illustrious_Row_9971,False,0.95,40,xl5pky,https://i.redd.it/uc18wju5qfp91.png,3,1663863277.0,
32,learnmachinelearning,openai,top,2023-08-17 12:50:37,I'm trying to create a comprehensive table of the best AI tools to Increase Your Productivity + Automate Your Work- feel free to give some recs so I can add it to the list.,paulflythe,False,0.8,41,15tmnit,https://i.redd.it/sgcuo4o13oib1.png,19,1692276637.0,
33,learnmachinelearning,openai,top,2023-03-28 12:51:54,I am creating a tool that uses OpenAI models and an OCR to translate screenshots,K-RT-DEV,False,0.88,39,124nsy8,https://www.reddit.com/r/learnmachinelearning/comments/124nsy8/i_am_creating_a_tool_that_uses_openai_models_and/,15,1680007914.0,"Currently, the OCR is specifically for translating from Japanese, but I plan to add a range of OCRs and different translators to the system to accommodate the user's needs.  


https://i.redd.it/8ymk99uf8hqa1.gif

My idea is to have a system that leverages OpenAI models for *bagging*. This way, I can combine the output of multiple OCRs  to increase the accuracy of the recognized characters. Similarly, I can combine the output of multiple translators for the same phrase to improve the final result . Chat models can be particularly useful in providing **context** and a translation history to help the system understand how to conjugate phrases for translation.   


You can find the source code and an executable version on the [project's GitHub](https://github.com/K-RT-Dev/VGT)"
34,learnmachinelearning,openai,top,2022-02-03 18:39:05,[Project] Refining the Natural language processing course - Feedback v2 and thank you,sb2nov,False,0.91,37,sjqogi,https://www.reddit.com/r/learnmachinelearning/comments/sjqogi/project_refining_the_natural_language_processing/,2,1643913545.0,"I’m Sourabh, I lead one of the core Tensorflow teams at Google Brain and worked on data products at Coursera with Andrew Ng. Kaushik Rangadurai, ML Engineer at Facebook and I are leading a live, cohort based course on NLP starting March 14th. [https://corise.com/course/natural-language-processing](https://corise.com/course/natural-language-processing).

This is the second run of the class and we learned a lot from the feedback of the reddit community from the first run in November. Some of the changes we're making from the previous iteration:

1/ More focus on transformers and less on RNN/LSTM as hugging face is becoming the defacto for any nlp.

2/ Pytorch lightning has some really easy to use interfaces so better organizing the boiler plate code.

3/ OpenAI has opened the GPT-3 API so a deeper dive into current possibilities.

Would love to continue getting feedback and build this to be a great resource. The plan is to open the content after we refine it to a degree we're happy with. You can join the course (capped at about 30 students) at the link above. If you’re open to giving feedback on the class on how we can do better, happy to give a discount."
35,learnmachinelearning,openai,top,2018-06-13 15:25:24,Learning how to implement Q-Learning in Python and training with OpenAi Gym,brendanmartin,False,0.98,30,8qta4p,https://www.reddit.com/r/learnmachinelearning/comments/8qta4p/learning_how_to_implement_qlearning_in_python_and/,5,1528903524.0,"/u/satwik_ and I wrote an article about Reinforcement Q-Learning in Python and would love to answer any questions for anyone that's interested in learning how to apply Q-Learning to a project.

Article: https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/"
36,learnmachinelearning,openai,top,2023-05-29 17:37:32,"GPT Weekly - 29th May Edition: Facebook's massive STT and TTS Release, AI in Windows, Paralegal jobs are here to stay and more.",level6-killjoy,False,0.82,25,13v1asb,https://www.reddit.com/r/learnmachinelearning/comments/13v1asb/gpt_weekly_29th_may_edition_facebooks_massive_stt/,2,1685381852.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 AI news in the past week
* 🗞️10 AI news highlights and interesting reads
* 🧑‍🎓3 Learning Resources

# 🔥Top 3 AI news in the past week

## 1. Expanding Language Horizons

Facebook has [released an open source model called MMS (Massively Multilingual Search)](https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/) for STT (speech to text), TTS (text to speech) and language identification. 

This is a big breakthrough. Currently, STT and TTS models recognize only 100 languages. With this the technology has been expanded to 1100 languages. That is 10x the current best. 

Additionally, these models can recognize 4000+ languages. 

As per Facebook, they also have half the error rate of OpenAI’s Whisper.

These guys are on a roll.

## 2. Bing Chat Enters the OS

After [Google’s announcement](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin), it was time for Microsoft to announce AI products. Here’s a rundown of what was announced during Microsoft Build:

1. **Windows Copilot**  \- Microsoft is integrating AI directly into the OS. Now you can do everything you could do with Bing Chat but now on the OS. You can do the usual stuff - summarize emails, documents, re-write etc. But it goes beyond that by integrating into the installed applications.

Microsoft is also adopting OpenAI's plugin model. So, **you can use ChatGPT and Bing plugins to interact with the integrated AI.** 

The great thing about it is the direct integration into the OS. Eat your heart out, Mac users – at least for now 😀. Until Apple announces something similar. And someone will come up with an alternative solution. Especially, because of the privacy concerns with Microsoft telemetry. 

The bad thing is - [the security aspect of the plugins](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). It can open a whole new attack vector on the OS and antivirus softwares might struggle with it. 

It also might be the second nail in the coffin for all the summarize, “talk to your document” apps. Once, this feature is integrated with [Google Docs](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and Microsoft Office - why will you want to pay for extra apps?

1. **Search comes to ChatGPT**  \- Looks like OpenAI had enough of the testing and new features are being rolled out [left](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and [right](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). 

No prizes for guessing the search engine behind it. Ding, Ding, Ding..It’s Bing!

1. **Co-Pilot in PowerPages** \- Microsoft is now adding AI to their [PowerPages platform](https://powerpages.microsoft.com/en-in/), their low-code tool to build websites. It’ll help users to generate text, forms etc.
2. **Microsoft Fabric** \- A new data analytics platform built on top of Azure Data lake but can get data from S3, Google cloud etc. It can help users build pipelines, write code, and build ML models.

## 3. From Trusted Advisor to Nightmare: The Hazards of Depending on AI

Here’s a [fun story which is breaking out on Legal twitter](https://www.nytimes.com/2023/05/27/nyregion/avianca-airline-lawsuit-chatgpt.html). 

A man filed a personal injury lawsuit against Avianca airlines. Avianca's lawyers wasted no time and requested the judge to dismiss the case. The man's lawyer had a different plan in mind. He submitted a document citing half a dozen cases that bolstered his client's claims.

Here's the twist—the judge and Avianca's lawyer couldn't locate any of the referenced cases. Quite a conundrum, right? The lawyer was then asked to provide copies of these elusive cases. The lawyer submitted screenshots as evidence, taking extra precautions to ensure their authenticity. 

You already know the direction this story is taking. 

The lawyer had used ChatGPT to compose his brief. But little did he know that ChatGPT had supplied him with fake cases.

When asked to file tangible copies of these cases, the lawyer turned to ChatGPT once again. ChatGPT had reassured him that the cases were genuine. Feeling emboldened, the lawyer used ChatGPT to provide the requested copies. He even went as far as incorporating chat screenshots into a legal document.

The lawyer maintains that it was never his intention to deceive the court. He expressed regret for relying on ChatGPT for their research. Unfortunately, the judge isn't pleased with this turn of events. The judge has threatened sanctions against both the lawyer and his firm.

It serves as a stark reminder of how ChatGPT has fooled many people. There is a clear warning stating that ChatGPT may produce inaccurate information. But many tend to overlook these warnings. Even legal professionals!!

This story carries significant importance for those who fear job insecurity. The lawyer and his firm could have prevented the entire debacle. They should've used paralegal services. They instead relied on ChatGPT's. It's a hard lesson learned the hard way.

My sincere hope is that this story serves as a valuable lesson. It helps people avoid making similar mistakes. The legal community might become apprehensive about ChatGPT's use moving forward.

# 🗞️10 AI news highlights and interesting reads

1. [OpenAI says in 10 years AI could be as productive as one of today’s large corporations](https://openai.com/blog/governance-of-superintelligence). This poses an existential risk and they suggest some regulations to manage it. This poses an existential risk and they suggest some regulations to manage it. To achieve this, countries need to form something like the [IAEA](https://en.wikipedia.org/wiki/International_Atomic_Energy_Agency). The IAEA is an intergovernmental agency under the UN to oversee nuclear energy. This “AI agency” will monitor the AI systems and conduct inspections. Just like nuclear energy is tracked through signatures, they suggest using compute and energy usage to track systems.
2. In the meantime, [Google is working on voluntary rules](https://techcrunch.com/2023/05/24/eu-google-ai-pact/) until there are some real regulations in place. 
3. [As per Pew Research, 58% of Americans have heard of ChatGPT. Even less - 14% have tried ChatGPT. ](https://www.pewresearch.org/short-reads/2023/05/24/a-majority-of-americans-have-heard-of-chatgpt-but-few-have-tried-it-themselves/)
4. Sharing prompts and results has been a pain. Taking screenshots is one way. But then everyone has to type in the prompts manually. Or you can share as plain text. But ChatGPT results are non-deterministic. So, the results might not be the same. Even the lawyer above would’ve loved this feature. Now you will be able to [share your ChatGPT conversations publicly](https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq).
5. LLM Agents and plugins need to connect to tools to perform the tasks outside the LLM environment. So, it is important for the LLM to know which API to call and pass correct arguments. [Gorilla is a fine-tuned Llama-model which can generate the correct call and arguments](https://gorilla.cs.berkeley.edu/). 
6. If you are trying to build something beyond a document summarizer or a wrapper around GPT4 API, [things can be hard](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm). Finding the correct context window, dealing with slow responses (I am looking at you GPT-4) etc are some of the problems. 
7. [The AI boom could expose investors’ natural stupidity](https://www.reuters.com/breakingviews/ai-boom-could-expose-investors-natural-stupidity-2023-05-19/). 
8. [Chatbot leaderboard for the week](https://lmsys.org/blog/2023-05-25-leaderboard/). GPT-4 is still ahead.
9. [Google’s flood warning system is now available in 80 countries. ](https://blog.google/outreach-initiatives/sustainability/flood-hub-ai-flood-forecasting-more-countries/)
10. [GPT detectors are biased against non-native English writers](https://arxiv.org/abs/2304.02819)

# 🧑‍🎓3 Learning Resources

1. [Build a product using Replit+AI](https://www.priyaa.me/blog/building-with-ai-replit). The author is a non-technical person who won a hackathon competing with engineers. 
2. [LangChain 101](https://replit.com/@MckayWrigley). 
3. [NLP Course from HuggingFace](https://huggingface.co/learn/nlp-course/chapter0/1)

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
37,learnmachinelearning,openai,top,2023-08-02 18:21:44,A Brief History of Natural Language Generation [Timeline] —Thoughts? Corrections? Suggestions? Thanks!,Britney-Ramona,False,0.84,26,15ggib0,https://i.redd.it/meslnx7moqfb1.png,8,1691000504.0,
38,learnmachinelearning,openai,top,2022-12-12 19:17:50,"A web application tool for improving your written communication features paraphrasing, grammar checking, and text summarizing tool built with OpenAI API.",Austin_Nguyen_2k,False,0.95,28,zk8gr7,https://v.redd.it/95jm43veoi5a1,12,1670872670.0,
39,learnmachinelearning,openai,top,2023-12-28 19:48:58,Where do you find people you can constantly bother about technical issues.,uforanch,False,0.93,24,18t2qe0,https://www.reddit.com/r/learnmachinelearning/comments/18t2qe0/where_do_you_find_people_you_can_constantly/,13,1703792938.0,"Alright. I'm a former math academic. I've taken courses online for Deep Learning and NLP. I get the gist of it, generally. I know the math, I know what's happening, etc. I am currently trying to get to something original by making models from books and keras's site and then adapting them to other things. 

I'm running into a lot of weird issues.  Too many to get into here. Like my model will get the opposite results of the book, or won't predict on input it's supposed to, there's warnings being raised every command, etc. 

I've been to code meetups and have some software oriented friends. I generally don't find a lot of people into AI who aren't super busy and have time to just answer questions of ""How am I getting this error"". Most people don't even really want to do much besides send prompts to an openAI API, whereas I want to showcase I can build and use these models. 

Where do you find someone who can actually help or answer questions. Is there a notable discord or some space where I'm more likely to meet someone who can answer questions? 

&#x200B;"
40,learnmachinelearning,openai,top,2024-01-05 15:14:07,"This Week's Major AI developments in a nutshell (December Week 4, 2023 + January week 1, 2024)",wyem,False,0.96,23,18z95ko,https://www.reddit.com/r/learnmachinelearning/comments/18z95ko/this_weeks_major_ai_developments_in_a_nutshell/,1,1704467647.0,"1. **Meta** and UC, Berkeley introduced ***Audio2Photoreal***, a framework for generating full-bodied photorealistic avatars with gestures driven from audio of a dyadic conversation \[[*Details*](https://people.eecs.berkeley.edu/~evonne_ng/projects/audio2photoreal/) | [*GitHub*](https://github.com/facebookresearch/audio2photoreal)*\].*
2. **MyShell** along with researchers from MIT and Tsinghua University introduced ***OpenVoice***, an open sourcce voice cloning approach that is nearly instantaneous and provides granular control of tone, from emotion to accent, rhythm, pauses, and intonation, using just a small audio clip \[[*Details*](https://research.myshell.ai/open-voice) *|* [*Hugging Face*](https://huggingface.co/spaces/myshell-ai/OpenVoice)\] .
3. **Suno** and Nvidia present ***Parakeet***, a family of open source speech recognition models that top the Open ASR Leaderboard. Parkeet models effectively prevent the generation of hallucinated transcript and are robust to noisy audio. Available for commercial use under CC BY 4.0 \[[*Details*](https://nvidia.github.io/NeMo/blogs/2024/2024-01-parakeet/) | [*Hugging Face*](https://huggingface.co/spaces/nvidia/parakeet-rnnt-1.1b)\].
4. **Researchers** from Stanford University introduce ***Mobile-ALOHA***, an open-source robot hardware that can can autonomously complete complex mobile manipulation tasks that require whole-body control like cook and serve shrimp, call and take elevator, store a 3Ibs pot to a two-door cabinet etc., with just 50 demos \[[*Details*](https://mobile-aloha.github.io/)\].
5. **Allen Institute for AI** released ***Unified-IO 2*** (open-source), the first autoregressive multimodal model that is capable of understanding and generating image, text, audio, and action. The model is pre-trained from scratch on an extensive variety of multimodal data -- 1 billion image-text pairs, 1 trillion text tokens, 180 million video clips, 130 million interleaved image & text, 3 million 3D assets, and 1 million agent trajectories \[[*Details*](https://unified-io-2.allenai.org/)\].
6. **Alibaba** Research introduced ***DreamTalk***, a diffusion-based audio-driven expressive talking head generation framework that can produce high-quality talking head videos across diverse speaking styles \[[*Details*](https://dreamtalk-project.github.io/) *|* [*GitHub*](https://github.com/ali-vilab/dreamtalk)\].
7. **OpenAI’s app store** for GPTs will launch next week \[[*Details*](https://techcrunch.com/2024/01/04/openais-app-store-for-gpts-will-launch-next-week/)\].
8. **GitHub Copilot Chat**, powered by GPT-4, is now generally available for both Visual Studio Code and Visual Studio, and is included in all GitHub Copilot plans alongside the original GitHub Copilot \[[*Details*](https://github.blog/2023-12-29-github-copilot-chat-now-generally-available-for-organizations-and-individuals)\].
9. **Microsoft Research** presented a new and simple method for obtaining high-quality text embeddings using only synthetic data and less than 1k training step \[[*Paper*](https://arxiv.org/pdf/2401.00368.pdf)\] | [*Hugging Face*](https://huggingface.co/intfloat/e5-mistral-7b-instruct)\].
10. **Google DeepMind** introduced ***AutoRT, SARA-RT and RT-Trajectory*** to improve real-world robot data collection, speed, and generalization \[[*Details*](https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotic)\].
11. **Salesforce Research** presented ***MoonShot***, a new video generation model that conditions simultaneously on multimodal inputs of image and text, demonstrating significant improvement on visual quality and temporal consistency compared to existing models. The model can be easily repurposed for a variety of generative applications, such as personalized video generation, image animation and video editing. Models will be made public [here](https://github.com/salesforce/LAVIS) \[[*Details*](https://showlab.github.io/Moonshot/)\].
12. **Leonardo AI** released ***Leonardo Motion*** for generating videos from images. Available to all users, paid and free \[[*Link*](https://leonardo.ai/)\].
13. **JPMorgan AI Research** present ***DocLLM***, a layout-aware generative language model for multimodal document understanding. The spatial layout information is incorporated through bounding box coordinates of the text tokens obtained typically using optical character recognition (OCR), and does not rely on any vision encoder component \[[Details](https://arxiv.org/pdf/2401.00908.pdf)\].
14. **Alibaba Research** introduced ***Make-A-Character (Mach)***, a framework to create lifelike 3D avatars from text descriptions. Make-A-Character supports both English and Chinese prompts. \[[*Details*](https://human3daigc.github.io/MACH/) *|* [*Hugging Face*](https://huggingface.co/spaces/Human3DAIGC/Make-A-Character)\].
15. **Sony**, Canon and Nikon set to combat deepfakes with digital signature tech in future cameras \[[*Details*](https://www.techradar.com/cameras/photography/sony-canon-and-nikon-set-to-combat-deepfakes-with-digital-signature-tech-in-future-cameras)\].
16. **Meta AI** introduced ***Fairy***, a versatile and efficient video-to-video synthesis framework that generates high-quality videos with remarkable speed. Fairy generates 120-frame 512x384 videos (4-second duration at 30 FPS) in just 14 seconds, outpacing prior works by at least 44× \[[Details](https://fairy-video2video.github.io/)\].
17. **Apple** quietly released an open source multimodal LLM, called ***Ferret***, in October 2023 \[[*Details*](https://venturebeat.com/ai/apple-quietly-released-an-open-source-multimodal-llm-in-october/)\].
18. **Australian researchers** introduced a non-invasive AI system, called ***DeWave***, that can turn silent thoughts into text while only requiring users to wear a snug-fitting cap \[[*Details*](https://www.sciencealert.com/new-mind-reading-ai-translates-thoughts-directly-from-brainwaves-without-implants)\].
19. **Pika Labs** text-to-video AI platform **Pika 1.0** is now available to all and accessible via the web \[[*Link*](https://pika.art/)\].
20. **The New York Times** sued OpenAI and Microsoft for copyright infringement \[[*Details*](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html)\].

**Source**: [AI Brews newsletter-](https://aibrews.com/) you can subscribe [here](https://aibrews.substack.com/). it's free to join, sent only once a week with ***bite-sized news, learning resources and selected tools.*** *Thank you!*"
41,learnmachinelearning,openai,top,2023-10-19 17:47:15,is hosting a 7B model on cloud cheaper than accessing openai’s api,besabestin,False,0.86,20,17bozjd,https://www.reddit.com/r/learnmachinelearning/comments/17bozjd/is_hosting_a_7b_model_on_cloud_cheaper_than/,21,1697737635.0,"I have few questions related to this. Now that a lot of smaller models are becoming better and accessible, are they getting cheaper for access? llama and mistral models are getting better and also getting more improvements through quantization or better attention techniques.

I was using openai’s models and they cost so low unless you are summarizing tens of pages of pdf files. I am looking at like 20cents of my whole day use.

How are such models actually uploaded on cloud? Are the weights saved in database and stuff? I know there are tools like skyplot but how do they work underneath?"
42,learnmachinelearning,openai,top,2023-06-19 17:49:06,"GPT Weekly - 19the June Edition - OpenAI's function calling, Meta's free LLM, EU Regulation and more.",level6-killjoy,False,1.0,21,14dlfas,https://www.reddit.com/r/learnmachinelearning/comments/14dlfas/gpt_weekly_19the_june_edition_openais_function/,2,1687196946.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 news - OpenAI’s updates, Meta’s upcoming free LLM and EU Regulation
* 🗞️Interesting reads include PSA about protecting your keys, The GPT ouroboros, Reddit - OpenAI’s moat, and more..
* 🧑‍🎓Learning includes a Step-by-step guide from a non-technical founder who launched his MVP, Chatbot for your Gdrive and more

# 🔥Top 3 AI news in the past week

## 1. OpenAI: New Pricing, Models, & Functions

OpenAI has been on a roll. Last week we saw the release of [OpenAI best practice on using GPT.](https://gptweekly.beehiiv.com/p/making-gpt-openais-tactics-better-results) This week we saw some amazing updates. Three major buckets were:

First, the price decreases for both embeddings and GPT-3.5 tokens. 

Second, new models for gpt-4 and gpt-3.5. A new longer context model for gpt-3.5.

Third, a new function calling capability. 

**Why is it important?** Previously, the output from OpenAI was all text. So, calling an external API from GPT was quite difficult. You had to parse the text data and things were often incorrect.  Langchain created the Agents and Tools feature to tackle this problem. It was still unreliable and prone to issues. 

Now you get native support to generate a fixed format output. You can use the output to generate functional calls and also pass functions which need to be called. For example, if your app has multiple API endpoints then you can use GPT to generate the API calls with parameters. You can also pass the endpoints as function calls to ensure the correct function is executed. 

This functionality can further be used to [generate structured data (JSON) out of GPT](https://yonom.substack.com/p/native-json-output-from-gpt-4). So, you can generate data from GPT and load it into your backend. 

**What’s next?** This functionality allows turning natural language responses into structured data. This can be used to create “intelligent” backends using LLMs. We might see implementations in no-code tools to allow more robust and natural-language tools for non-technical folks.

The structured data process goes both ways. You can also feed structured data into GPT for better responses. 

This feature also has its share of issues. Function calling suffers from the same prompt injection issues. Malicious actors can pass malicious code in function or the responses. For example, creation of queries using functions might contain malicious code to delete data. Without proper user validation this code will be executed automatically and delete data. So, using LLM as the back-end layer needs proper security implementation. 

## 2. Meta's LLM: Commercial Use Ahead

Llama has been a boon for the open source community. Many of the open source models rely on Llama. The issue is that Llama is research-only and cannot be used commercially. So, no one can use it to build any product.

[Meta is now working on the next version of the model. This model will be available for commercial use.](https://www.theinformation.com/articles/meta-wants-companies-to-make-money-off-its-open-source-ai-in-challenge-to-google) This is in stark contrast to both OpenAI and Google. Both safe-guarde their models and make it available through API. 

**Why is it important?** Certain industries cannot use LLM APIs because of strict restrictions on data privacy. These companies would want to run their own instance of a foundational model. 

A commercially available foundational model is also going to help people who want to keep their “API call” costs next to 0. 

A commercially available free-for-all model will also help push the open source community further. Just like Llama.

**What’s next?** Sam Altman has said OpenAI didn’t release GPT-3 as open-source because they [didn’t think people would be able to run it.](https://gptweekly.beehiiv.com/p/peek-openais-future) Now [OpenAI is working on an open-source model.](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) This is going to be weaker than GPT-4. 

Let the battle of LLMs begin.  

## 3. EU's Proposed Legislation and Its Impact on AI Usage

[The EU parliament voted to move ahead with the E.U. AI Act.](https://www.washingtonpost.com/technology/2023/06/14/eu-parliament-approves-ai-act/) This act aims to ensure consumer protection against the dangers of AI.  

**Why is it important?** [OpenAI](https://gptweekly.beehiiv.com/p/peek-openais-future) and [Sam Altman](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) want regulations for models. They have proposed a IAEA-type of agency to stop the proliferation of LLM models. As per OpenAI, all models should be regulated and monitored. The suggestion of a license based regulation has led to significant backlash. Many people have called it “regulatory capture” - with the aim of shutting down competing LLMs.

[Licensing based regulations might not really be effective.](https://aisnakeoil.substack.com/p/licensing-is-neither-feasible-nor)

The EU is approaching regulation from a different angle. It doesn’t focus on how models are developed. Rather focuses on how AI will/can be used. They have broken down use cases into 4 categories - unacceptable (prohibited), high, medium and low risk. For example, 

Building a [Pre-Crime software](https://en.wikipedia.org/wiki/Pre-crime#:~:text=Pre%2Dcrime%20(or%20precrime),on%20crimes%20not%20yet%20committed.) to predict crimes? Building a [Social credit system](https://en.wikipedia.org/wiki/Social_Credit_System)?  Unacceptable.

Using tools to influence elections or recommendation algorithms? High (Highly regulated).

Using generative AI tools to create text or images on news sites? Medium (Add label that the content is AI generated) 

AI providers also need to disclose their training source.

To me this sounds like good legislation. What do you guys think?

But, OpenAI has warned that EU regulations might force them to pull out completely.

**What’s next?** The disclosure requirements might help various publishing companies. [AI and media companies are in talks to pay for training data](https://www.ft.com/content/79eb89ce-cea2-4f27-9d87-e8e312c8601d). Google has been leading the charge. 

Additionally, [OpenAI and Deepmind will open their models for safety and research purposes to the UK government.](https://www.politico.eu/article/openai-deepmind-will-open-up-models-to-uk-government/) 

# 🗞️10 AI news highlights and interesting reads

1. **PSA:** If you are using Repl to write code, you might want to check your OpenAI API keys. If you have left them embedded then [people can pirate and steal the keys. ](https://www.vice.com/en/article/93kkky/people-pirating-gpt4-scraping-openai-api-keys)
2. LLMs rely on human annotation or human feedback to learn. And one way to generate human annotation is crowdsourcing. But what if the crowdsource human annotators use LLMs? [Research shows 33-46% workers used LLMs](https://arxiv.org/abs/2306.07899). So, basically we go from Human -> AI -> Human -> AI. The AI ouroboros. Researchers also say [generated data to train models might cause serious issue.  ](https://arxiv.org/abs/2305.17493)
3. All the talks about [moats](https://gptweekly.beehiiv.com/p/googles-startling-leaked-memo-george-hinton-mojo) \- [Reddit might be OpenAI’s \*future\* moat](https://www.cyberdemon.org/2023/06/14/reddit-moat.html). Given the amount of complaints about how [Google search](https://www.techradar.com/opinion/the-reddit-b) [experience has deteriorated](https://www.theverge.com/2023/6/13/23759942/google-reddit-subreddit-blackout-protests) [during the blackout](https://news.ycombinator.com/item?id=36345345), this might be true?
4. [Doctors are using ChatGPT](https://www.nytimes.com/2023/06/12/health/doctors-chatgpt-artificial-intelligence.html) but not to diagnose.Rather to be [more empathetic](https://inflecthealth.medium.com/im-an-er-doctor-here-s-how-i-m-already-using-chatgpt-to-help-treat-patients-a023615c65b6). [We discussed this just a month ago](https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?utm_source=gptweekly.beehiiv.com&utm_medium=referral&utm_campaign=google-s-startling-leaked-memo-george-hinton-mojo-and-more). And guess where the data for this study came from? Reddit AskDocs. Moat FTW?!
5. Beatles to make a comeback…[using Generative AI](https://www.semafor.com/article/06/13/2023/paul-mccartney-beatles-song-ai). 
6. [SnapFusion - Text to Image diffusion on mobile phones.](https://snap-research.github.io/SnapFusion/)
7. Large context lengths are important for better GPT experience. [The secret sauce for 100k context length](https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c). 
8. There is a lot of bad AI research out there. Some border on snake oil. Most AI “research” should be double checked and challenged. A new research on huggingface said that [GPT-4 can ace MIT curriculum](https://huggingface.co/papers/2306.08997). Now someone is replicating the results and say that [GPT-4 can’t beat MIT. ](https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864)
9. Are we seeing peak AI? Especially when people from Deepmind and Meta are involved? [Mistral AI raised $113 million in seed round with no product.](https://techcrunch.com/2023/06/13/frances-mistral-ai-blows-in-with-a-113m-seed-round-at-a-260m-valuation-to-take-on-openai/) Some might say this funding is for the team and the team is really solid. The issue though is whether the valuation is justified when OpenAI and Google already have a head start.
10. [The AI Hype Wall of Shame.](https://criticalai.org/the-ai-hype-wall-of-shame/) \- Collection of articles which mislead people about AI in various aspects.

# 🧑‍🎓3 Learning Resources

1. [Building and Launching a company using GPT-4](https://sabol.io/c7921c7bbd8c4982aacbd2b71a8b9bb3) with prompts. (The author didn’t know how to code but created and launched the MVP in a month).  
2. Chatbot for your Gdrive - [https://www.haihai.ai/gpt-gdrive/](https://www.haihai.ai/gpt-gdrive/)
3. Building ChatGPT plugin using Supabase - https://supabase.com/blog/building-chatgpt-plugins-template

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
43,learnmachinelearning,openai,top,2023-07-03 15:01:23,How do embeddings encode semantic information?,crono760,False,0.96,19,14plgu8,https://www.reddit.com/r/learnmachinelearning/comments/14plgu8/how_do_embeddings_encode_semantic_information/,6,1688396483.0,"I don't quite get this part. If I understand embeddings, you take some text and pass it through a tokenizer. This doesn't encode semantics, just tokens and their positions. I agree that we can then use that embedding vector to determine which other embeddings are similar by some metric, such as cosine, but doesn't that just mean that they are similar in the sense of tokens and positions, not semantics?

For instance, the sentences ""the cat went to the mat"" and ""the cat went to the rug"" are both semantically and lexicographically similar, and would likely have very similar embeddings. But ""the cat went to the mat"" and ""the house feline moved itself so that its position coincided with the carpet"" are semantically similar but would, I assume, have drastically different embeddings, wouldn't they?

I'm trying to ask this in a model agnostic way, but if it matters let's assume the embeddings come from the openAI API."
44,learnmachinelearning,openai,top,2019-03-11 20:28:05,OpenAI Establishes For-Profit Company,gwen0927,False,0.92,20,azybh6,https://medium.com/syncedreview/openai-establishes-for-profit-company-9d595cc5f3c9,2,1552336085.0,
45,learnmachinelearning,openai,top,2023-09-28 15:50:53,Work asked me to tell them which PC to buy for me - Suggestions? plshelp,sim0of,False,0.95,19,16ujluo,https://www.reddit.com/r/learnmachinelearning/comments/16ujluo/work_asked_me_to_tell_them_which_pc_to_buy_for_me/,11,1695916253.0,"Hello everyone,

I have been working as a junior developer in this company for some months now

I have been using my own Acer Nitro 5 17"" (i7 11800h, RTX 3060 Laptop 6GB, 16GB Ram)

So far I've been involved in projects with computer vision, audio and nlp

This is an entirely new branch for the company and I'm still a student at the beginning of my journey, therefore there is no ""standard modus operandi"" for doing things and basically I'm the one responsible for telling them what piece of hardware is best for my needs

Anything that involves training we just rent GPUs from the major providers so I'm definitely not worrying about that

Things I will definitely be working on

\- OpenAI API integration  
\- NVIDIA NeMo framework  
\- YOLO  
\- Langchain, elastic and similars

&#x200B;

Since I've been busy studying and learning stuff I've never really bothered looking into hardware requirements for any of the things I've done/will do

Does the hardware choice matter in this case?  


They proposed me a laptop with i7 12th gen, 16GB Ram, and RTX4050 which costs 1k euros

I told them to hold off and that I would have done some further research because that doesn't look like a solid investment in my opinion

&#x200B;

**What (I think) I know:**

Budget I assume is something in the 1k - 2k range but they really just care about giving me something that allows me to provide good results

\- Pretty much when running models locally for testing and developing, they will run on a GPU, which I assume has to be powerful. But how powerful is powerful enough? 4060? 4080? 4090? Do mobile CPUs even make sense?  
\- I notices some dockerized services take up a fair bit of my current CPU, so is it coherent to assume that a more recent CPU with more cores and pretty much more power would be beneficial for my work?  
\- 16GB Ram nowadays is barely enough for google chrome with a few extensions so I don't really have any doubts that going for 32GB is a reasonable enough upgrade  
\- I work both at home, at the office and around the world when I'm in WFH mode, so a laptop would seem a better option than a Desktop PC, but is that actually the case?  


**What I don't know**

Aside from the fact that this section worringly overlaps with the ""what I know section""..  
I've only considered Windows laptops onto which I would at the very least make dual boot with linux if not exclusively linux because the NVIDIA NeMo framework can't run on windows

Given what I will do, should I even consider Apple? Like a Macbook Pro M1 or something like that?

  
I already have high end desktop pc at home and my current laptop is already something I'm comfortable bringing around, but one big limitation is that I always need to be plugged into a power source or the battery drains withing one hour of work  
AFAIK a macbook pro would kinda allow me to work anywhere so that'd be a cool quality of life upgrade but I doubt it's practically worth anything other than a ""cool!"" reaction

&#x200B;

As you can see there's a lot of stuff I don't know and I don't really know what I actually need

Thank you so much for any help and suggestion towards the right direction!  
"
46,learnmachinelearning,openai,top,2019-09-19 16:49:41,Apprenticeship Learning with Inverse Reinforcement Learning,rhklite,False,0.92,18,d6gs4u,https://www.reddit.com/r/learnmachinelearning/comments/d6gs4u/apprenticeship_learning_with_inverse/,1,1568911781.0,"Hi Guys,

My friends and I implemented the **P. Abbeel and A. Y. Ng, “Apprenticeship Learning via Inverse Reinforcement Learning.”** using CartPole model from openAI gym, thought i'd share it with you guys.

We have a double deep Q implementation using pytorch and a traditional Q learning version inside google colab. There is a set of presentation slides in out github explaining this as well.

you can run the google colab version directly in your browser without any setup. Just click ""open in playground mode"" and run the script

\- [github link](https://github.com/rhklite/apprenticeship_inverse_RL)

\- [traditional Q Google Colab link](https://colab.research.google.com/drive/1Tmc5fPHP9J0s-vQukLDzRywe47BNni37#scrollTo=bzxZCx5VD3xn)

\- [youtube link to double deep Q performance](https://www.youtube.com/watch?v=COAyi4-VlEw)

\- [youtube link to tabular Q performance](https://www.youtube.com/watch?v=Wd1xfNNo9kc)"
47,learnmachinelearning,openai,top,2017-12-01 16:13:33,"This Week in Machine Learning & AI talks to key members of the OpenAI Community, including Founder and CTO Greg Brockman, to talk AGI, Safety & Robotics! You don't want to miss it!",Fatman_Johnson,False,0.87,18,7gvzfj,https://twimlai.com/openai,2,1512144813.0,
48,learnmachinelearning,openai,top,2023-07-07 01:56:23,ML for DIY House Design,No-Dare-7624,False,0.88,17,14st4q5,https://www.reddit.com/r/learnmachinelearning/comments/14st4q5/ml_for_diy_house_design/,9,1688694983.0,"https://reddit.com/link/14st4q5/video/afhad8qnagab1/player

As an architect and computational designer, I've recently ventured into the exciting world of Machine Learning (ML) to bring an innovative touch to DIY house designs. My project, based in Grasshopper, integrates ML in the architectural process to predict the optimal wall/window configurations for desired temperature settings in diverse scenarios.

Starting with a modest dataset (2000 rooms), I developed a stacked ML model, part of a larger project, aiming to democratize house design by aiding DIY enthusiasts. My workflow was all about getting the model running first, even with limited data, and refining it as I gained more understanding and expanded the dataset, which is self-supervised. I'm using Ladybug a grasshopper plugin that it is the way to go for enviromental analysis, so I can generate new data on demand but it takes time to compute.

The most challenging part was predicting optimal configurations when all wall options were not available. I addressed this by merging outputs from the second (predict optimal configuration) and third neural (predict best configuration with aviable walls) networks, assigning more weight to the latter.

With the assistance of OpenAI's GPT-4, especially for Python, I am now focused on generating five times more data and scrutinizing model performance through metrics such as R-squared (0.8144), MSE(0.003), and MAE(0.0454). The best model so far is using Backpropagation and Sigmoid.

As an architect turned ML enthusiast, there's been a steep learning curve, but the journey has been rewarding. I'm keen to hear suggestions, particularly any rules of thumb from seasoned data scientists that could be missing from my toolkit. Looking forward to enriching this exciting intersection of architecture and ML!

Here is a small video of the first attempt of the first neural network that its just predict the solar radation.

[https://www.instagram.com/reel/CuPwUVNArTv/?utm\_source=ig\_web\_copy\_link&igshid=MzRlODBiNWFlZA==](https://www.instagram.com/reel/CuPwUVNArTv/?utm_source=ig_web_copy_link&igshid=MzRlODBiNWFlZA==)"
49,learnmachinelearning,openai,top,2022-02-01 07:17:02,Becoming a Data Scientist With No Degree,yoavrox,False,0.87,18,shozex,https://www.reddit.com/r/learnmachinelearning/comments/shozex/becoming_a_data_scientist_with_no_degree/,9,1643699822.0,"Hi all,

I recently started to become very interested in machine learning and AI as interesting and rewarding ways to positively affect the world in my career. 

After being ""infected with the bug"" I took fastai's 2020 course, and am now almost finished reading the book ""Mathematics for Machine Learning"", as well as working on fun ML side projects.

Thing is, I come from cybersecurity background with no degree. I have a lot of experience that will certainly help me (python, ability to research etc.), but I'm not sure what the best path forward is. 

Bottom line, my question is if I want to work for Deepmind or OpenAI (or some other place), will they accept me without a degree if I work my butt off learning and making projects? Or is it not feasible? 
Because I can't help but feel that during the 6 years it'll take me to get a master's I can learn more on my own.

I'd really appreciate any input and guidance :)"
50,learnmachinelearning,openai,top,2023-07-20 13:15:51,Free courses and guides for learning Generative AI,wyem,False,0.95,17,154qnsh,https://www.reddit.com/r/learnmachinelearning/comments/154qnsh/free_courses_and_guides_for_learning_generative_ai/,0,1689858951.0,"1. **Generative AI learning path by Google Cloud.** A series of 10 courses on generative AI products and technologies, from the fundamentals of Large Language Models to how to create and deploy generative AI solutions on Google Cloud \[[*Link*](https://www.cloudskillsboost.google/paths/118)\].
2. **Generative AI short courses** by DeepLearning.AI - Five short courses on generative AI including **LangChain for LLM Application Development, How Diffusion Models Work** and more. \[[*Link*](https://www.deeplearning.ai/short-courses/)\].
3. **LLM Bootcamp:** A series of free lectures by *The full Stack* on building and deploying LLM apps \[[*Link*](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/)\].
4. **Building AI Products with OpenAI** \- a free course by CoRise in collaboration with OpenAI \[[*Link*](https://corise.com/course/building-ai-products-with-openai)\].
5. Free Course by Activeloop on **LangChain & Vector Databases in Productio**n \[[*Link*](https://learn.activeloop.ai/courses/langchain)\].
6. **Pinecone learning center -** Lots of free guides as well as complete handbooks on LangChain, vector embeddings etc. by Pinecone **\[**[**Link**](https://www.pinecone.io/learn/)**\].**
7. **Build AI Apps with ChatGPT, Dall-E and GPT-4  -** a free course on Scrimba **\[**[*Link*](https://scrimba.com/learn/buildaiapps)**\].**
8. **Gartner Experts Answer the Top Generative AI Questions for Your Enterprise** \- a report by Gartner \[[*Link*](https://www.gartner.com/en/topics/generative-ai)\]
9. **GPT best practices:** A guide by *OpenAI* that shares strategies and tactics for getting better results from GPTs \[[*Link*](https://platform.openai.com/docs/guides/gpt-best-practices)\].
10. **OpenAI cookbook by OpenAI -** Examples and guides for using the OpenAI API **\[**[*Link*](https://github.com/openai/openai-cookbook/tree/main)**\].**
11. **Prompt injection explained**, with video, slides, and a transcript from a webinar organized by LangChain \[[*Link*](https://simonwillison.net/2023/May/2/prompt-injection-explained/)\].
12. A detailed guide to **Prompt Engineering by DAIR.AI** *\[*[*Link*](https://www.promptingguide.ai/)*\].*
13. What Are **Transformer Models** and How Do They Work - A tutorial by **Cohere AI** \[[*Link*](https://txt.cohere.ai/what-are-transformer-models/)\].  


I add learning resources as part of my AI newsletter. You can join for free [here](https://aibrews.com/). It’s sent only once a week with bite-sized news, learning resources and selected tools. "
51,learnmachinelearning,openai,top,2022-10-06 01:31:54,OpenAI's Most Recent Model: Whisper (explained),OnlyProggingForFun,False,0.94,16,xwsiag,https://youtu.be/uFOkMme19Zs,2,1665019914.0,
52,learnmachinelearning,openai,top,2019-07-25 04:36:56,Opinions on free resources to learn Deep Reinforcement Learning,rpicatoste_,False,0.94,16,chj0vl,https://www.reddit.com/r/learnmachinelearning/comments/chj0vl/opinions_on_free_resources_to_learn_deep/,6,1564029416.0,"I gathered a list of free resources to learn Deep  Reinforcement Learning, but given time availability I would like to  choose the one with highest output/time invested.

If you have followed any of these, could you please share: how good it was and what it took in terms of effort and time?

This is the list:

* [Spinning up deep learning](https://spinningup.openai.com/)
* [Depth first learning for AlphaGoZero](http://www.depthfirstlearning.com/2018/AlphaGoZero)
* [https://www.starai.io/course/](https://www.starai.io/course/)
* [Stanford cs234 Winter2019](http://web.stanford.edu/class/cs234/index.html) (videos [here](https://www.youtube.com/watch?v=FgzM3zpZ55o&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u))
* [David Silver course](http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html)
* [Skymind](https://skymind.ai/wiki/deep-reinforcement-learning)
* [Simonini's course](https://simoninithomas.github.io/Deep_reinforcement_learning_Course/)
* [CS 294-112 at UC Berkeley - Deep Reinforcement Learning](http://rail.eecs.berkeley.edu/deeprlcourse/)
* [Learning Reinforcement Learning by WildML](http://www.wildml.com/2016/10/learning-reinforcement-learning/)
* [Advanced Deep Learning and Reinforcement Learning - UCL and DeepMind](https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs) + [slides](https://github.com/enggen/DeepMind-Advanced-Deep-Learning-and-Reinforcement-Learning)

If you followed another resource and can give the same opinion please go ahead.

If it matters: I have been doing Machine Learning and Deep Learning for a  while, and my goal is to be able to train agents for which I can build  an environment. In other words, more practical, so I can use it, than  cutting edge/research.

Thank you! 

Other resources, mainly code:

* [https://github.com/dennybritz/reinforcement-learning](https://github.com/dennybritz/reinforcement-learning)
* [https://github.com/seungeunrho/minimalRL](https://github.com/seungeunrho/minimalRL)
* [https://www.reddit.com/r/reinforcementlearning/comments/a16o4h/d\_main\_deep\_reinforcement\_learning\_implementations/](https://www.reddit.com/r/reinforcementlearning/comments/a16o4h/d_main_deep_reinforcement_learning_implementations/)"
53,learnmachinelearning,openai,top,2023-04-22 05:51:13,Integrating Google search into OpenAI models like GPT-4,Ghost25,False,1.0,16,12uwd8p,https://www.reddit.com/r/learnmachinelearning/comments/12uwd8p/integrating_google_search_into_openai_models_like/,8,1682142673.0,"Thought I'd share an explanation of how I implemented Google search into my GPT-4 based chatbot.

Github here: https://github.com/sgreenb/pico_assistant

One extremally simple modification that dramatically improves the ability of a GPT to answer questions: letting it Google stuff.

Here’s a demo:

https://imgur.com/ZR6hvLg 1

The implementation works like this.

1. A user enters an input.
2. An agent called “Executive” looks at the input and decides if an API like Spotify, Twillio, or Gmail is needed or if it can be answered by the chatbot alone.
3. If the chatbot is needed the input is first sent to a Google agent. The Google agent’s system message looks like this:

```
{""role"":""system"", ""content"": ""You analyze a user's input to a large language model with \
training data that cuts off at September 2021. The current year is 2023. You decide how \
likely it is that a user's request will benefit from a Google search to help address the\
question. Respond with a number in the range 1-10, where 1 is very unlikely that a \
Google search would be beneficial, and 10 meaning a Google search is highly necessary.""}
```

This is quite fast, since it only needs to generate one or two tokens.

If the output is above some threshold (say 7), then we call another agent, the query agent, otherwise we return False and default to the normal chat agent.

```
    google_probability = int(completion.choices[0].message.content)
    if google_probability >= cutoff:
        search_results = trim_text(search_and_scrape(prompt))
        query_with_context = prompt + str(search_results)
        print(""\nPico: "", end='', flush=True)
        response = query_agent_stream(query_with_context)
        return response
    else:
        return False
```

When we call the query agent, we feed it the first part of a Google search we get from searching the input. We get that from the very simple trim_text and search_and_scrape functions that look like this:

```

def search_and_scrape(query):
    try:
        headers = {
            ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3""
        }
        url = f""https://www.google.com/search?q={query}""
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text()
            cleaned_text = ' '.join(text.split())
            return cleaned_text
        else:
            print(f""Failed to fetch search results for query: {query}, status code: {response.status_code}"")
            return None

    except Exception as e:
        print(f""Error fetching search results for query: {query}, error: {e}"")
        return None

def trim_text(text, start_index = 450, length=1500):
    return text[start_index:start_index + length]
```

The query agent has this system message:

```
{""role"":""system"", ""content"": ""You answer a user's question, given some text as context to help\
answer the question. The user request will be followed by the context. The context given is\
from the user's Google search results, it is current and up to date.\
Do not contradict the contents of the given text in your answer.""}
```

And that’s it. You can change the cutoff threshold or get more sophisticated with fetching web results. I hope you find this useful."
54,learnmachinelearning,openai,top,2020-07-27 00:13:59,"OpenAI's New Language Generator: GPT-3. This AI Generates Code, Websites, Songs & More From Words",OnlyProggingForFun,False,0.9,15,hyhvuk,https://www.youtube.com/watch?v=gDDnTZchKec,1,1595808839.0,
55,learnmachinelearning,openai,top,2023-11-22 19:05:16,Made some promises. Now I'm desperately trying to figure out how to conduct very large scale pdf doc analysis.,-rampant,False,0.89,13,181gxg0,https://www.reddit.com/r/learnmachinelearning/comments/181gxg0/made_some_promises_now_im_desperately_trying_to/,11,1700679916.0,"I have about a half million pdfs I need to summarize. Very wide range of types: invoices, diagrams, contracts, emails, letters, pictures, schedules, notices, data sheets, manuals, more. 

Which is... woof. Something else. I've been trying for many hours now to figure out a service/combination thereof that can get me there, but I'm seriously struggling. The *ideal* solution would be to throw the pdfs in and have it return a csv with dates and summaries, maybe parsed out email heading info.

I'm currently running these pdfs through Acrobat OCR now, which its own special hell.

I've tried myriad local and webhosted solutions. The BEST results in what is almost the perfect system for this I found on https://docalysis.com/. Good text results, works in batches, BUT I can only upload a single document at a time. They have a service to do batch processing and so I'm waiting to hear from them now. I imagine at the scale I need it's expensive.

I also got this solution working: https://github.com/mayooear/gpt4-pdf-chatbot-langchain. Seemed solid, I was able to upload a thousand pdfs in a single go, but it would keep returning information from only 2-3 documents. Upload 5? Results for 2-3. Upload a thousand? Results for 2-3. My uneducated guess is that it's hitting the OpenAI API token limit, but maybe not?

I know it's possible, just not whether it's feasible for an end user. Does anyone know a solution to accomplish this?"
56,learnmachinelearning,openai,top,2020-06-12 19:16:01,OpenAI API is magical...,zjost85,False,0.89,14,h7r4ov,https://youtu.be/CSe3_u9P-RM,0,1591989361.0,
57,learnmachinelearning,openai,top,2021-11-22 04:53:26,stable-retro: fork of OpenAI's gym-retro,matpoliquin,False,1.0,15,qzdego,https://www.reddit.com/r/learnmachinelearning/comments/qzdego/stableretro_fork_of_openais_gymretro/,0,1637556806.0,"Since OpenAI's gym-retro has been archived for a while and doesn't accept any PRs and new game/plateform integrations I created a fork called \*stable-retro\* (mostly tested with stable-baselines) If you have integrated a game or platform or made a fix you are welcomed to do a PR.

[~~https://github.com/MatPoliquin/stable-retro~~](https://github.com/MatPoliquin/stable-retro)

Project recently moved to Farama Foundation:

[https://github.com/Farama-Foundation/stable-retro](https://github.com/Farama-Foundation/stable-retro)

&#x200B;

Currently added games on top of gym-retro:

* Super Mario Bros 2 Japan (Lost Levels) - NES
* Hang On - SMS
* Punch Out - NES
* WWF Wrestlemania the Arcade Game - Genesis
* NHL 94 - Genesis
* NHL 94 (1 on 1 rom hack) - Genesis
* Super Hang On - Genesis
* Tetris - GameBoy
* Virtua Fighter 2 - Genesis

PvP games that support two models fighting each other:

* Samurai Showdown - Genesis
* WWF Wrestlemania the Arcade Game - Genesis
* Mortal Kombat II - Genesis
* NHL 94 - Genesis

## Fixes

* Fixed UI flickering issue in OpenAI integration tool
* fix compile with c++ >=17"
58,learnmachinelearning,openai,top,2023-08-13 01:03:38,"Besides HHH, what is RLHF actually good for? Every example I've ever seen has focused on lobotomizing models.",JonBon13,False,0.89,14,15pl55g,https://www.reddit.com/r/learnmachinelearning/comments/15pl55g/besides_hhh_what_is_rlhf_actually_good_for_every/,5,1691888618.0,"Most instruction following & SFT seems likely to become unnecessary as those data sets leak into pre-training. However, it seems like RLHF is not a 1-size fits all solution. However, I've only seen real ""value add"" use cases for HHH. 

**Are there examples of RLHF models that are actually ""task specific"" or ""better than"" GPT-4 + prompting?** I've seen the OpenAI & other graphs that show humans rank RLHF > SFT, but the ""chat"" example seems so incredibly generic. Are there cases where you can actually squeeze out large performance for certain useful tasks only with RLHF? 

What are the buyers of RLHF data on Surge/Scale actually trying to get models to do?"
59,learnmachinelearning,openai,top,2023-10-01 20:37:56,LLM Firewall - Guardrail Tutorial and Quickstart with OpenAI and Colab,Educational_Grass_38,False,0.94,13,16xc53k,https://m.youtube.com/watch?v=EnwVnz07h1I&pp=ygUSR3VhcmRyYWlsIEZpcmV3YWxs,5,1696192676.0,"Been working on a Firewall for devs to use in a few lines of code, to implement a protective layer around LLMs like OpenAI. Firewall has over 20+ detectors out-of-the-box including prompt injections, harmful content, toxicity and common security vulnerabilities.

Google Colab QuickStart: https://github.com/guardrail-ml/guardrail

Developer Docs: https://docs.useguardrail.com

Would appreciate if you could give a star and provide feedback, thanks!"
60,learnmachinelearning,openai,top,2023-07-19 16:01:34,Ensuring Reliable Few-Shot Prompt Selection for LLMs,cmauck10,False,0.9,13,153z22n,https://www.reddit.com/r/learnmachinelearning/comments/153z22n/ensuring_reliable_fewshot_prompt_selection_for/,0,1689782494.0,"Hello Redditors!

It's pretty well known that LLMs have firmly established themselves as leaders in the field of natural language processing, consistently pushing the limits of language comprehension and generation, which is widely acknowledged.

I spent a little time playing around with few-shot prompting for OpenAI's Davinci model and I discovered that noisy data still has drastic effects even on powerful LLMs like Davinci.

[mislabeled few-shot examples harms LLM performance drastically](https://preview.redd.it/9quf4bvk2ycb1.png?width=1994&format=png&auto=webp&s=cfbec1b30ffbaa592011355c503a568fb6c98148)

I wrote up a [quick article](https://www.kdnuggets.com/2023/07/ensuring-reliable-fewshot-prompt-selection-llms.html) in KDNuggets that shows how I used data-centric AI to automatically clean the noisy few-shot examples pool in order to achieve more accurate predictions. The resulting few-shot prompt with accurately labeled examples produced **20% fewer errors** than the original one with mislabeled examples.

This one was quite eye-opening for me and I hope you find it is as interesting as I did. Let me know what you think!"
61,learnmachinelearning,openai,top,2023-11-09 19:16:20,Overcame the OpenAI Assistant API Learning Curve Post-DevDay – Our Detailed Guide Inside,davorrunje,False,0.94,12,17rkmfw,https://www.reddit.com/r/learnmachinelearning/comments/17rkmfw/overcame_the_openai_assistant_api_learning_curve/,1,1699557380.0,"Hello AI enthusiasts,

Navigating the new Assistant API after the recent OpenAI DevDay? We know the official docs aren't quite there yet, and it can be a bit like finding your way in the dark.

To help out, we've put together a detailed walkthrough of our own experience – the missteps, the breakthroughs, and everything in between.

We believe this resource can save you some time and frustration. If you're planning to work with the Assistant API, give our guide a read and get a head start: [Our Guide to the Assistant API](https://airt.hashnode.dev/function-calling-and-code-interpretation-with-openais-assistant-api-a-quick-and-simple-tutorial)

Looking forward to your feedback and hope it helps!"
62,learnmachinelearning,openai,top,2023-01-27 19:38:05,"A python module to generate optimized prompts, Prompt-engineering & solve different NLP problems using GPT-n (GPT-3, ChatGPT) based models and return structured python object for easy parsing",StoicBatman,False,0.94,12,10mtvn5,https://www.reddit.com/r/learnmachinelearning/comments/10mtvn5/a_python_module_to_generate_optimized_prompts/,2,1674848285.0,"Hi folks,

I was working on a personal experimental project related to GPT-3, which I thought of making it open source now. It saves much time while working with LLMs.

If you are an industrial researcher or application developer, you probably have worked with GPT-3 apis. A common challenge when utilizing LLMs such as #GPT-3 and BLOOM is their tendency to produce uncontrollable & unstructured outputs, making it difficult to use them for various NLP tasks and applications.

To address this, we developed **Promptify**, a library that allows for the use of LLMs to solve NLP problems, including Named Entity Recognition, Binary Classification, Multi-Label Classification, and Question-Answering and return a python object for easy parsing to construct additional applications on top of GPT-n based models.

Features 🚀

* 🧙‍♀️ NLP Tasks (NER, Binary Text Classification, Multi-Label Classification etc.) in 2 lines of code with no training data required
* 🔨 Easily add one-shot, two-shot, or few-shot examples to the prompt
* ✌ Output is always provided as a Python object (e.g. list, dictionary) for easy parsing and filtering
* 💥 Custom examples and samples can be easily added to the prompt
* 💰 Optimized prompts to reduce OpenAI token costs

&#x200B;

* GITHUB: [https://github.com/promptslab/Promptify](https://github.com/promptslab/Promptify)
* Examples: [https://github.com/promptslab/Promptify/tree/main/examples](https://github.com/promptslab/Promptify/tree/main/examples)
* For quick demo -> [Colab](https://colab.research.google.com/drive/16DUUV72oQPxaZdGMH9xH1WbHYu6Jqk9Q?usp=sharing)

Try out and share your feedback. Thanks :)

Join our discord for Prompt-Engineering, LLMs and other latest research discussions  
[discord.gg/m88xfYMbK6](https://discord.gg/m88xfYMbK6)

[NER Example](https://preview.redd.it/bwnl67gu1nea1.png?width=1236&format=png&auto=webp&s=6c180552f65413c3a94ed06f5d47da93a9641392)

&#x200B;

https://preview.redd.it/vx9nb94w1nea1.png?width=1398&format=png&auto=webp&s=fc392c8ee5add4ee82f45c22a65532da89491f69"
63,learnmachinelearning,openai,top,2023-06-25 05:56:08,How to Fine Tune CLIP model from huggging face on Custom dataset,Inner_Kaleidoscope97,False,0.87,11,14ieb5j,https://www.reddit.com/r/learnmachinelearning/comments/14ieb5j/how_to_fine_tune_clip_model_from_huggging_face_on/,1,1687672568.0,"I am a Student , and am trying to finetune a OpenAI Clip model on a custom dataset , can someone help me understand how the custom dataset can be set as input data cause all the tutorials show the use of hugging face datasets only "
64,learnmachinelearning,openai,top,2023-01-10 19:15:50,What are the top AI tools to work with in 2023?,bruclinbrocoli,False,0.85,9,108i61p,https://www.reddit.com/r/learnmachinelearning/comments/108i61p/what_are_the_top_ai_tools_to_work_with_in_2023/,5,1673378150.0,"Thought this was a cool graphic - 

pulled from this free resource ([https://buildspace.so/notes/ai-stack-2023](https://buildspace.so/notes/ai-stack-2023)) 

Anything missing? 

https://preview.redd.it/ip41flonm9ba1.png?width=456&format=png&auto=webp&s=60c73b5d8fc50212c8e0fe8815b2d25f970ad34c"
65,learnmachinelearning,openai,top,2019-07-06 12:00:58,Trying to get started with OpenAI Retro. Any good tutorial recommendations?,ReasonablyBadass,False,0.85,8,c9su5w,https://www.reddit.com/r/learnmachinelearning/comments/c9su5w/trying_to_get_started_with_openai_retro_any_good/,2,1562414458.0,Specifcially an explanation for how actions are send to the game. The official documentation is...barely existant.
66,learnmachinelearning,openai,top,2023-05-30 13:11:21,Set Up OpenAI's CLIP on Amazon SageMaker for Inference,vanlifecoder,False,0.86,9,13vpxzn,https://rise.climb.dev/clip-on-sagemaker/,2,1685452281.0,
67,learnmachinelearning,openai,top,2020-05-05 18:34:16,AI song contest: Beatroots submission,AndroidNeedHeaven,False,0.93,11,ge3bi5,https://www.reddit.com/r/learnmachinelearning/comments/ge3bi5/ai_song_contest_beatroots_submission/,1,1588703656.0,"Can artificial intelligence already help composing songs that would be successful at winning the Eurovision contest? In the AI Song Contest teams from all over Europe and Australia compete attempting to create the next Eurovision hit with the help of artificial intelligence.

I am a member of the Beatroots team and our song was composed by an end-to-end algorithm. We put out our auto generated music on Spotify ([https://open.spotify.com/artist/0bEJEKrBzaYr6SJsdliQIU?si=z8I0oBIXTcSkUYNO-ATqkQ](https://open.spotify.com/artist/0bEJEKrBzaYr6SJsdliQIU?si=z8I0oBIXTcSkUYNO-ATqkQ)) You can create your own AI generated song with this algorithm in this Google Colab (you have to copy it locally before using, or run in playground mode): [https://colab.research.google.com/drive/1lNdSSTGQswsRO0fRiK4E82Eozmu1mOvI#scrollTo=Zah\_Sx1gHtE4](https://colab.research.google.com/drive/1lNdSSTGQswsRO0fRiK4E82Eozmu1mOvI#scrollTo=Zah_Sx1gHtE4)

We also gave a webinar on our approach, which you can find right here on youtube: [https://www.youtube.com/watch?v=pQCsZhVwdi8&t=8s](https://www.youtube.com/watch?v=pQCsZhVwdi8&t=8s)

We used 200 old Eurovision songs normalised in midi files split by section as training data. The encodings from Magenta's MusicVAE are the input of our custom built Variational Auto-Encoder. We built several models, each generating either an intro, verse, chorus... This is actually a very similar approach to the recent OpenAI Jukebox, but with symbolic music as input data instead of raw waveforms. Our model also runs on your desktop while you sit in your sofa next to your gf binging Gossip Girl :)

We combine all our section models to create the final song by implementing a shortest path algorithm between all generated harmonies in the MusicVAE encoding space.

Just as in the real competition, there is a jury as well as well as a public vote. Please vote for your favourite song on [https://www.vprobroadcast.com/titles/ai-songcontest/about.html](https://www.vprobroadcast.com/titles/ai-songcontest/about.html). You can vote until the 10th of May. There is also more information on each team's creation processes. SPOlLER: other teams have more professional sounding songs because they added a human touch, we went a bit too far and geeky with the staying inside and let everything be generated by our beloved laptops.

enjoy! :)

tldr; vote for Beatroots [https://www.vprobroadcast.com/titles/ai-songcontest/about.html](https://www.vprobroadcast.com/titles/ai-songcontest/about.html)."
68,learnmachinelearning,openai,top,2022-11-02 15:37:28,Deep Reinforcement Learning examples are Cartpole all the way down,ProbablySuspicious,False,0.92,10,yk8h3t,https://www.reddit.com/r/learnmachinelearning/comments/yk8h3t/deep_reinforcement_learning_examples_are_cartpole/,9,1667403448.0,"I built my own little board game and I'm trying to figure out how to build a neural network agent to learn and play it. There's a lot written about the theory, which I think I get, but practical examples seem limited to running pre-packaged OpenAI Gym setups and I don't see how to apply any of it to a new game. Where could I find an example coded from first principles?"
69,learnmachinelearning,openai,top,2023-05-16 00:19:20,Some Resources for Getting Started,Equivalent_Amoeba_30,False,0.87,11,13iph8f,https://www.reddit.com/r/learnmachinelearning/comments/13iph8f/some_resources_for_getting_started/,0,1684196360.0,"It's an incredibly exciting time in the field. One of the best things about this moment is the number of free or low-cost resources that exist for getting started. I have actually been pleasantly surprised by the number of high quality tutorials that are available on Youtube 🙃 Some of these are better than my Ivy League graduate courses!

1. Deep Learning - [deeplizard](https://www.youtube.com%2F@www.youtube.com/@deeplizard)
2. Generative AI - [BuildingIt AI](https://www.youtube.com%2F@www.youtube.com/@buildingitai)
3. Software Development- [Nicholas Renotte](https://www.youtube.com%2F@www.youtube.com/@NicholasRenotte)

As far as platforms go. There are plenty of playgrounds -

1. OpenAI - [https://chat.openai.com/auth/login](https://chat.openai.com/auth/login)
2. Kaggle - [Run Data Science & Machine Learning Code Online | Kaggle](https://www.kaggle.com/code)
3. StableDiffusion - [AI Playground](https://play.vercel.ai/)"
70,learnmachinelearning,openai,top,2023-05-02 17:15:02,How to Fine-Tune OpenAI Language Models with Noisily Labeled Data (37% error reduction),cmauck10,False,1.0,10,135u3vt,https://www.reddit.com/r/learnmachinelearning/comments/135u3vt/how_to_finetune_openai_language_models_with/,0,1683047702.0,"Hello Redditors! 

It's pretty well known that LLMs have solidified their place at the forefront of natural language processing, and are constantly pushing the boundaries of what is possible in terms of language understanding and generation.

I spent some time playing around with the OpenAI fine-tuning API and I discovered that noisy data still has drastic effects even on powerful LLMs like Davinci.

[Improving fine-tuning accuracy by improving data quality.](https://preview.redd.it/v5kro8wzagxa1.png?width=1085&format=png&auto=webp&s=39e0309aa94048dc08a0879d99008f00ec32fd9e)

I wrote up a [quick article](https://www.kdnuggets.com/2023/04/finetuning-openai-language-models-noisily-labeled-data.html) in KDNuggets that shows how I used data-centric AI to automatically clean the noisy data in order to fine-tune a more robust OpenAI LLM. The resulting model has 37% fewer errors than the same LLM fine-tuned on the noisy data.

Let me know what you think!"
71,learnmachinelearning,openai,top,2023-04-12 16:42:28,"How to Build an Ecommerce Chatbot with Redis, LangChain, and OpenAI",yourbasicgeek,False,1.0,11,12jrym1,https://redis.com/blog/build-ecommerce-chatbot-with-redis/,2,1681317748.0,
72,learnmachinelearning,openai,top,2023-07-24 10:06:29,My chatPDF doesn't remember the embeddings when I shutdown the server,Cold_Set_,False,0.92,10,1586bom,https://www.reddit.com/r/learnmachinelearning/comments/1586bom/my_chatpdf_doesnt_remember_the_embeddings_when_i/,8,1690193189.0,"Hello, me and a friend are making a web app with Langchain and with an OpenAI API where you can chat with a bot about your PDFs after uploading them in the database (chroma database).

The programs runs well, I upload a PDF, the program converts it into embeddings and replies well, but after reloading the page or restarting directly the server the chatbot kinda forgets he already has made the embeddings for that specific PDF and he tells me he has no idea or just give generic replies if the topic can be found on the internet.

Has anyone an idea how to solve this problem?"
73,learnmachinelearning,openai,top,2023-02-14 17:53:16,[P] Practical Steps to Reduce Hallucination and Improve Performance of Systems Built with Large Language Models like ChatGPT,vykthur,False,0.91,9,112bk1o,https://www.reddit.com/r/learnmachinelearning/comments/112bk1o/p_practical_steps_to_reduce_hallucination_and/,2,1676397196.0,"&#x200B;

[Practical steps to reduce hallucination and improve performance of systems built with large language models like ChatGPT](https://preview.redd.it/gksxjpnoz6ia1.png?width=1456&format=png&auto=webp&s=c34531fbe1311eab9323c148eef35fcf0d70decd)

Large language models (LLMs) like the GPT series (GPT3, 3.5, [ChatGPT](https://openai.com/blog/chatgpt/)) can be powerful tools in building useful applications. However, **LLMs are probabilistic** \- i.e., they generate text by learning a probability distribution over words seen during training. For example, given the following words as context “*rise and*”, an LLM can infer that the next word it should generate that fits this context is likely to be “*shine*”. While this setup ensures generated text is **coherent and human-like** (e.g., asking ChatGPT to rewrite the [Serenity Praye](https://en.wikipedia.org/wiki/Serenity_Prayer)r in the style of the [American Constitution](https://www.senate.gov/civics/constitution_item/constitution.htm) yields some intriguing prose), this resulting text may [**not be factual, or just plain incorrect**](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web) **(not grounded in the model’s input or training data) - aka hallucination**. In addition, another limitation of LLMs is that they struggle to address **tasks that need** [**complex multistep reasoning**](https://arxiv.org/pdf/2208.14271.pdf)**.** For example, asking the model to address mathematical word problems or puzzles often requires that the task is decomposed into steps, some computation applied to solve each step and some transformation applied to aggregate results into a final answer; this remains challenging for LLMs.  


Full article: [https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination](https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination) 

This post discusses the following:

* An overview on why hallucination will likely *always be a problem* with LLMs.
* Practical steps developers can take to reduce hallucination and improve performance including:  

   * Low temperature
   * Use of external knowledge bases
   * Chain of thought prompting
   * Self-consistency/voting
   * Task decomposition and agents
   * Correctness probabilities for result filtering
   * Task bench marks
   * Building defensive user interfaces."
74,learnmachinelearning,openai,top,2022-11-12 01:43:24,We just release a complete open-source solution for accelerating Stable Diffusion pretraining and fine-tuning!,HPCAI-Tech,False,0.76,8,ystctm,https://www.reddit.com/r/learnmachinelearning/comments/ystctm/we_just_release_a_complete_opensource_solution/,0,1668217404.0,"Hey folks. We just release a **complete open-source solution** for accelerating Stable Diffusion pretraining and fine-tuning. It help **reduce the pretraining cost by 6.5 times, and the hardware cost of fine-tuning by 7 times, while simultaneously speeding up the processes.**

Open source address: [**https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion**](https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion)

Our codebase for the diffusion models builds heavily on [OpenAI's ADM codebase](https://github.com/openai/guided-diffusion) , [lucidrains](https://github.com/lucidrains/denoising-diffusion-pytorch), [Stable Diffusion](https://github.com/CompVis/stable-diffusion), [Lightning](https://github.com/Lightning-AI/lightning) and [Hugging Face](https://huggingface.co/CompVis/stable-diffusion). Thanks for open-sourcing!

We also write a blog post about it. [https://medium.com/@yangyou\_berkeley/diffusion-pretraining-and-hardware-fine-tuning-can-be-almost-7x-cheaper-85e970fe207b](https://medium.com/@yangyou_berkeley/diffusion-pretraining-and-hardware-fine-tuning-can-be-almost-7x-cheaper-85e970fe207b)

Glad to know your thoughts about our work!

[Images Generated by Stable Diffusion](https://preview.redd.it/o43uyyjzcfz91.jpg?width=3306&format=pjpg&auto=webp&s=881e44d0b3d2577142fa0a1a8cf6cc4e5b759ea2)"
75,learnmachinelearning,openai,top,2020-06-20 10:42:35,OpenAI releases powerful text generator,f474m0r64n4,False,0.83,8,hck5cj,https://techxplore.com/news/2020-06-openai-powerful-text.html,1,1592649755.0,
76,learnmachinelearning,openai,top,2020-05-21 15:44:31,Openai not open anymore as they promise.,cudanexus,False,0.9,7,gnz7t5,https://www.reddit.com/r/learnmachinelearning/comments/gnz7t5/openai_not_open_anymore_as_they_promise/,0,1590075871.0,"I came across a blog today ""OpenAI’s supercomputer collaboration with Microsoft""  on venturebeat. Openai said they are licensing code generation ai model to Microsoft so Microsoft can commercialize and sell to partners. So  I think this model will not be opensource.

Roughly a year ago, Microsoft announced it would invest $1 billion in [OpenAI](https://venturebeat.com/2015/12/11/sam-altman-elon-musk-peter-thiel-and-others-commit-1b-to-nonprofit-artificial-research-lab-openai/) to jointly develop new technologies for Microsoft’s Azure cloud platform and to “further extend” large-scale AI capabilities that “deliver on the promise” of artificial general intelligence (AGI). In exchange, OpenAI agreed to license some of its intellectual property to Microsoft, which the company would then commercialize and sell to partners, and to train and run AI models on Azure as OpenAI worked to develop next-generation computing hardware.  
Link to the blog [venturebeat](https://venturebeat.com/2020/05/19/openai-microsoft-azure-supercomputer-ai-model-training/)"
77,learnmachinelearning,openai,top,2023-12-16 15:26:30,Is there any alternative for OpenAI API?,CrazyProgramm,False,0.83,8,18jti72,https://www.reddit.com/r/learnmachinelearning/comments/18jti72/is_there_any_alternative_for_openai_api/,12,1702740390.0, So I am from Sri Lanka and our university is going to organize a competition and we need OpenAI API for it but we don't have money to afford it. Is there any alternative API you guys know 
78,learnmachinelearning,openai,top,2023-06-26 12:23:07,"Best way to cost effectively ""upload"" a large PDF to a language model so that you can ask questions about it?",RepresentativeNet509,False,1.0,9,14jfvq8,https://www.reddit.com/r/learnmachinelearning/comments/14jfvq8/best_way_to_cost_effectively_upload_a_large_pdf/,13,1687782187.0," I have a 400 page PDF and need to get it into a language model (cost effectively) and then be able to ask the model questions about the document like ""on what page does the scope summary begin"" or ""are there any prohibitions to participate in this solicitation due to the size of respondent's business"".

I have been able to use ""Ask My PDF"" to upload part of the PDF to ChatGPT and this basically gives the outcome I want for the pages that are uploaded, but it invariably crashes every time and there is no way to pick up where the uploading of pages left off.

I am fairly technical; would NanoGPT be a better solution for this? I am also looking at fine-tuning a model on OpenAI's API, but that seems cumbersome and expensive for my use case.

Any thoughts are appreciated!"
79,learnmachinelearning,openai,top,2022-08-11 14:58:54,Learn multi-modal (image+text) ML with OpenAI's CLIP,jamescalam,False,0.9,7,wltheu,https://www.reddit.com/r/learnmachinelearning/comments/wltheu/learn_multimodal_imagetext_ml_with_openais_clip/,1,1660229934.0,"Hi all, I created a [walkthrough](https://towardsdatascience.com/quick-fire-guide-to-multi-modal-ml-with-openais-clip-2dad7e398ac0?sk=89bb2d8b8e583ed109d8a05e00366645) (and [video](https://youtu.be/989aKUVBfbk)) demoing how to use the text and image embeddings of OpenAI's CLIP. CLIP is a multi-modal model that uses a typical text transformer for text embeddings and a vision transformer (ViT, alt version uses Resnet) for image embeddings. During pertaining, CLIP learns to place (image, text) pairs into the same vector space. The result is a cool off-the-shelf model that can perform tasks across image and text data.

When I started using CLIP, I struggled to find how to use it for embedding text and images separately (all the examples tend to show placing both together and calc sim score directly, sans embedding output), so I hope this is helpful for anyone attempting the same.

Thanks all!"
80,learnmachinelearning,openai,top,2023-09-10 21:10:20,A Defacto Guide on Building Generative AI Apps with the Google PaLM API,vykthur,False,0.91,9,16fbuud,https://www.reddit.com/r/learnmachinelearning/comments/16fbuud/a_defacto_guide_on_building_generative_ai_apps/,0,1694380220.0,"[PaLM is a transformer-based large language model that can be used in building Generative AI app.](https://preview.redd.it/u4dx1h38thnb1.png?width=1456&format=png&auto=webp&s=3455c33a5494dfff8f2e787c805e76b38a34c722)

Full post [here](https://newsletter.victordibia.com/p/generative-ai-apps-google-palm).

Generative AI models such as [large language models (LLMs)](https://newsletter.victordibia.com/p/understanding-size-tradeoffs-with) offer developers an opportunity to build new experiences and offer value to end users. Tools like #ChatGPT powered by GPT3.5 and GPT4 models from OpenAI have demonstrated the capabilities of these models.

Similar to GPT models, PaLM is a transformer-based foundation model offered by Google as an API service. As a developer, understanding the capabilities of LLMs from multiple providers (e.g., OpenAI, Google, Anthropic, Cohere) can be valuable in making software design decisions (model selection, effort estimation, limitations, etc). In this post, I’ll dig into what I’ve learned while exploring the PaLM api, covering the following:

TLDR;

* Model [Overview](https://newsletter.victordibia.com/p/generative-ai-apps-google-palm): Overview of the PaLM model architecture (it is a transformer based model, trained on a mixture of language modeling objectives and extensive compute).
* [Api Interfaces](https://newsletter.victordibia.com/i/135691948/accessing-the-palm-api-makersuite-vs-vertex-client-libraries-vs-vertex-rest-api) : Pros/cons of different approaches to calling the PaLM api ([MakerSuite](https://makersuite.google.com/) vs Vertex Client Libraries vs Vertex REST Api).
* [Use Case Implementation](https://newsletter.victordibia.com/i/135691948/a-structured-data-extraction-use-case): Implementation and performance on a concrete/useful task - structured data extraction. We’ll use PaLM to analyze multiple book summaries (from the [CMU books Summary dataset](https://www.cs.cmu.edu/~dbamman/booksummaries.html)), extract a list of actors, their actions, relevance to a given user profile and plot these stats to extract insights.
* [Developer notes](https://newsletter.victordibia.com/i/135691948/developer-notes-on-the-palm-api) specific to the PaLM model. E.g., the API provides valuable citations for some responses, responses may be blocked due to safety filters, low-level prompting requirements, instruction following capabilities, etc

**Note:** This post focuses on text generation models fine tuned on multi-turn conversation applications (chat). It does not cover embedding models, multimodal models etc.

&#x200B;

## A Structured Data Extraction Use Case

For the purpose of this post, we will define **structured data extraction** as follows:

>**Structured Data Extraction**.Given some semi-structured or unstructured data (text), extract entities into a structured format (e.g., a JSON file, table or database).

&#x200B;

&#x200B;

[Structured Data Extraction-  Given some semi-structured or unstructured data \(text\), extract entities into a structured format \(e.g., a JSON file, table or database\).](https://preview.redd.it/qa5mut6gthnb1.png?width=1456&format=png&auto=webp&s=150b7fc0393111b025369dbf7b666e90a90e87b6)

&#x200B;

This general task is interesting as it also applies to **practical** business domains e.g.,

* **Hiring**: Improve candidate selection by quickly identifying relevant skills, experience, and qualifications.
* **Legal**: Legal firms and businesses can extract and analyze key data points from contracts, such as dates, terms, clauses, and parties involved, to identify potential legal risks, streamline negotiations, and improve overall contract management.
* **Customer Support:** Automating the extraction of structured data from customer support inquiries can help identify common issues, route queries to the appropriate support agents, and improve overall support efficiency and customer satisfaction.

We will explore this task using a [subset](https://github.com/chikne97/Book-Genre-Prediction) of the [CMU Book Summary dataset](https://www.cs.cmu.edu/~dbamman/booksummaries.html). Each row in the dataset has a **book name**, **genre** and **summary** (between 500 - 5000 characters) column. Our goal is to extract a **list of characters** in each summary, their **name, actions, gender** and finally **their relevance** given a user’s profile.

The overall implementation process is summarized as follows:

* Construct a random sample of the dataset (in the results below I use n=100)
* For each summary, prompt PaLM (**chat-bison**) to return a JSON data structure containing structured data (see prompt snippet below).
* Parse the structured data and assemble into a data frame
* Post process the data frame and plot results.

Example output text generated by PaLM is shown below:

    {'match': 'yes',   'match_reason': 'The book is a match because it is a crime novel and the user likes crime novels',   'characters': [{'name': 'Harry Hole',     'gender': 'male',     'actions': ['Harry went to the market',      'Harry bought a car',      'Harry investigated a crime']},    {'name': 'Rakel',     'gender': 'female',     'actions': ['Rakel met Harry',      'Rakel talked to Harry',      'Rakel fell in love with Harry']},    ...    {'name': 'Crown Prince of Norway',     'gender': 'male',     'actions': ['The Crown Prince of Norway was the target of an assassination attempt',      'The Crown Prince of Norway was saved by Harry',      ""The Crown Prince of Norway's identity was revealed""]}]
    }

Now that we have structured data, we can then parse this as JSON to get structured data and plot the results to extract insights. An example plot of extracted data are shown below:

&#x200B;

[Using the PaLM api to extract the number of characters from book summary text.](https://preview.redd.it/qeij6tmgthnb1.png?width=1456&format=png&auto=webp&s=37417d0e37c3cde74d35f078ee3e0735e18f677a)

&#x200B;

### Main Findings - Developer Notes on the PaLM API

While trying out the models, there were a few important differences in how the PalM api works, say compared to the OpenAI api or OSS models available via the transformers library. These may be due to optimizations that make these models efficient to serve at scale, subtle differences in model architecture or training data composition.

* ✅ **Citation**. license , safety attributes, author. This is a unique and highly positive thing with the PaLM api. If the generated content is related to a known author, or license, book title etc, this gets included in the responses. Excellent for building apps with attribution! As far as I know, **this is the only api** that explores doing this and it must take quite a significant amount of engineering to make this happen. Kudos!
* ⚠️ **Maximum number of responses**. Unlike other apis where you can generate n variations of responses bounded by the max output token size, PaLM api has a strict limit on this (some models have it set to 2, others 4). For most applications, this is fine. As an alternative, you can always make additional calls, or prompt the model to return a list of responses in a single call.
* ⚠️ **Alternating Message Authors**: the api strictly expects alternating authors for chat based messages. In [llmx](https://github.com/victordibia/llmx), I implement a simple check for consecutive messages and merge them with a newline character.
* ⚠️ **Blocked Responses** . In some cases, the PaLM api may block responses due to safety concerns. In such cases, the response contains a dedicated **blocked** field and a safetyAttributes dictionary that contains a list of categories (e.g., Derogatory, Profanity etc) and scores per category. This is useful to monitor for graceful degradation in apps (e.g., offering some recommendation to the user on how to recover from the failure).  
About **9%** of the responses in the structured data extraction from book summaries example above were blocked.
* ⚠️ **Prompt** **Sensitivity** . In the example use case above (structured task extraction), the model is required to output JSON structured data in a specific format defined in the prompt. I found that the \`codechat-bison\` model performed significantly worse (completely failed to follow the suggested output format) compared to the \`chat-bison\` model. This is likely because the task is not an explicit code generation task even though the model is prompted to output JSON structured text. I also found that it was necessary to include explicit commands such as “do not include double quotes in results” to get \`chat-bison\` to not make that specific mistake (which invalidates JSON parsing). In contrast, a general chat model like GPT 3.5/4 can address both text and code tasks equally well, easily avoiding formatting mistakes without any special prompting.

## Conclusion

With the right prompting, PaLM is a fairly capable model, with additional benefits benefits such as citations, fine grained access control via the Vertex AI GCP interface. I also found the api to be fast, with reasonable response times.

Learn more [here](https://newsletter.victordibia.com/p/generative-ai-apps-google-palm)."
81,learnmachinelearning,openai,top,2023-08-29 03:52:11,"Open-Source CodeLlama Server: Streaming, Caching, Model Fallbacks (OpenAI + Anthropic), Prompt-tracking",VideoTo,False,0.91,8,1647o7n,https://www.reddit.com/r/learnmachinelearning/comments/1647o7n/opensource_codellama_server_streaming_caching/,0,1693281131.0,"**TLDR;** We're open-sourcing our CodeLlama server. It handles streaming, caching, model fallbacks, and tracks prompts + token usage - [https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server](https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server)

\~\~

Hello r/learnmachinelearning,

I’m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, TogetherAI, Cohere, Anthropic, Baseten, Hugging face API Endpoints: [https://github.com/BerriAI/litellm/](https://github.com/BerriAI/litellm/)

We're open sourcing our CodeLlama server:

What can our server do? - It uses Together AI's CodeLlama to answer coding questions, with GPT-4 + Claude-2 as backups (you can easily switch this to any model from Huggingface, Replicate, Cohere, AI21, Azure, OpenAI, etc.)

Consistent Input/Output Format - Call all models using the OpenAI format: completion(model, messages) - Text responses will always be available at \['choices'\]\[0\]\['message'\]\['content'\]

* Streaming & Async Support - Return generators to stream text responses
* Error Handling Using Model Fallbacks (if Phind-CodeLlama fails, use Claude-2, fine-tuned GPT-3.5 etc.)
* Logging - It's integrated with promptlayer, so you can automatically track your prompt + model changes there.
* Token Usage & Spend - Track Input + Completion tokens used + Spend/model
* Caching - In-memory + Redis Cache solutions provided (works for streaming too!).

You can deploy liteLLM to your own infrastructure using Railway, GCP, AWS, Azure

Happy completion() !"
82,learnmachinelearning,openai,top,2023-02-01 19:06:42,Speech recognition for language that doesn't exist?,cantbebothered67836,False,0.89,7,10r30y6,https://www.reddit.com/r/learnmachinelearning/comments/10r30y6/speech_recognition_for_language_that_doesnt_exist/,7,1675278402.0,"I'm curious to know if there's a way to do speech-to-text without a pre-trained model for a particular language. It could be an obscure language that people haven't gotten around to train into a model yet, or a fictional language or just gibberish. More plainly I want to know if there's a way I can do, er, not so much speech recognition but sound recognition, or syllable recognition. Like if there's a model that recognizes sounds and can string them up into words according to how long the pause interval between those sounds is.

For example, this kid who's talking in a made up language (16 seconds into the video) -- the model would interpret him saying something like:

https://youtube.com/watch?v=CQiIyizGLjs&t=16s

""Colo mate fumala ya shina ma lata, ala siro koto ..."" etc you get the idea lol

Possible? openAI or anything like that?

Or if there's no pre-trained stuff I'm willing to do the nitty gritty myself, I just don't know where to start"
83,learnmachinelearning,openai,top,2021-02-23 16:28:26,I created an app that lets you try OpenAI's CLIP model from your browser (link in the comments),JaviFuentes94,False,0.88,6,lqmfbi,https://v.redd.it/wi4w8wof6vi61,1,1614097706.0,
84,learnmachinelearning,openai,top,2023-05-27 06:31:54,Train an AI to understand my codebase - Guidance needed,ThenChoice2,False,0.88,6,13t02cr,https://www.reddit.com/r/learnmachinelearning/comments/13t02cr/train_an_ai_to_understand_my_codebase_guidance/,1,1685169114.0,"Hey everyone,

As a backend developer with a dabbling interest in AI and Machine Learning, I've recently found myself fascinated by the potential of using AI models to interact with my codebase. Think of it like ChatGPT, but for my specific codebase. The goal would be to be able to ask my codebase questions.

I've played around with a few projects, and even tried to fine-tune some models, with mixed results at best. I've looked into options like AutoGPT and PrivateGPT, but I'm not entirely convinced they're the right fit for what I'm trying to achieve.

I do have an OpenAI key, but I'd prefer not to use it for this project. If I can find a working solution, I've got a sizeable amount of code to analyze, so scalability is a concern.

The challenging part, I think, is training a model on my code, which is composed of multiple projects and services. Ideally, the model should understand the concept of belonging to a particular service or project. I believe I can associate these ideas with the file paths, but the training part has me a bit stumped.

So, in a nutshell: does anyone know of an existing, relatively beginner-friendly solution I could use or adapt to my needs? All suggestions and insights are appreciated.

Thanks in advance!"
85,learnmachinelearning,openai,top,2023-06-17 15:49:30,How to Build LLM Applications With LangChain and Openai,mwitiderrick,False,0.82,7,14buddi,https://www.reddit.com/r/learnmachinelearning/comments/14buddi/how_to_build_llm_applications_with_langchain_and/,5,1687016970.0,"LangChain is one the most popular tools for building large language model applications.   You can use LangChain to build various applications, such as question-answering systems and chatbots.   Some of the modules in Langchain include: 

**•** **Models** for supported models and integrations 

**• Prompts** for making it easy to manage prompts 

**• Memory** for managing the memory between different model calls 

**• Indexes** for loading, querying, and updating external data 

**•Chains** for creating subsequent calls to an LLM

 **• Agents** to develop applications where the LLM model can direct itself 

**• Callbacks** for logging and streaming the intermediate steps in a chain 

Today over a thousand subscribers of mlnuggets got a tutorial on how to use LangChain and other language models, such as the ones from Openai, to create a system to transcribe and ask questions to YouTube videos. 

Check it out [https://www.machinelearningnuggets.com/how-to-build-llm-applications-with-langchain-and-openai/](https://www.machinelearningnuggets.com/how-to-build-llm-applications-with-langchain-and-openai/)"
86,learnmachinelearning,openai,top,2023-08-22 22:55:04,OpenAI Python Colab to Summarize and Chat with PDF,starlineventures,False,1.0,7,15yljxz,https://youtu.be/bypGr-Q8RB0,3,1692744904.0,
87,learnmachinelearning,openai,top,2024-01-12 11:17:44,Seeking Guidance on Image Classification Techniques for 10 M images,Numerous_Speed_9107,False,0.9,7,194splz,https://www.reddit.com/r/learnmachinelearning/comments/194splz/seeking_guidance_on_image_classification/,6,1705058264.0,"I find myself amidst a challenging task – classifying 10 million unlabelled images with alt text into approximately 200 classes.

As I delve into the preliminary research, my focus has narrowed down to two intriguing techniques.

* Contrastive learning for example MoCo
* OpenAI CLIP embeddings

I'm grappling with a quandary regarding contrastive learning. How can I effectively control or assign labels to similar embeddings, especially when the embedding space keeps shuffling as more data is introduced?

Considering OpenAI CLIP embeddings. Is it a more effective approach with specific advantages for my image classification task?

Open to community suggestions. Any overlooked viable options for this project? Your insights are valuable!"
88,learnmachinelearning,openai,top,2023-03-31 06:16:58,"If ChatGPT itself cannot be fine-tuned, what would bf the benefit of using the GPT3 offering of OpenAI vs my own?",Proxify,False,1.0,7,127c5iz,https://www.reddit.com/r/learnmachinelearning/comments/127c5iz/if_chatgpt_itself_cannot_be_finetuned_what_would/,5,1680243418.0,"Sorry, I'm somewhat new to this space and I'm reading about it and looking at the documentation from OpenAI.

From what I can tell, only their base models are available to fine-tune which, as far as I understand, would leave me in a situation in which fine-tuning any other GPT3 model would be comparable (vs their ""DaVinci"" model for instance).

Am I missing something here? Basically I'm wondering, other than their infrastructure (which is nothing to scoff at) why would I use their fine-tuning if the end result won't talk to the user as ChatGPT would."
89,learnmachinelearning,openai,top,2017-11-01 00:27:13,Q learning in python guide (request),45MonkeysInASuit,False,0.78,5,7a04u3,https://www.reddit.com/r/learnmachinelearning/comments/7a04u3/q_learning_in_python_guide_request/,0,1509496033.0,Im looking for a guide to implementing q learning (ideally in python with a neural net).  I would like something fairly simple in the examples (like a card game) that doesn't really on some form of video game (aka no openai gym).  I want these type of examples as I find they are easier to edit and learn from.
90,learnmachinelearning,openai,top,2019-02-23 10:25:23,Best way to label data for object detection,Carvalho96,False,0.81,6,atu3s1,https://www.reddit.com/r/learnmachinelearning/comments/atu3s1/best_way_to_label_data_for_object_detection/,9,1550917523.0,"Good day,

  
So I've got roughly 5k images (4k train, 1k test) for an object detection problem I'm working with, and was wondering if hand drawing bounding boxes for each of the objects for each of the images is really the only way to go about labeling the data? Is this really the way folks at Google, Facebook, Deepmind and OpenAI go about training their models?  


If there is any better way, or a standard ""best practice"" tool to be used for this task, please let me know?

&#x200B;

Thanks!"
91,learnmachinelearning,openai,top,2021-01-06 06:25:56,OpenAI's DALL·E: Creating Images from Text - Explainer Video,deeplearningperson,False,0.91,8,kri51z,https://youtu.be/UfAE-1vdj_E,0,1609914356.0,
92,learnmachinelearning,openai,top,2021-09-02 08:08:33,"Introductory Reinforcement Learning with OpenAI Gym, Google Colab, and RLlib",mgalarny,False,0.73,5,pgdh82,https://towardsdatascience.com/an-introduction-to-reinforcement-learning-with-openai-gym-rllib-and-google-colab-48fc1ddfb889,0,1630570113.0,
93,learnmachinelearning,openai,top,2023-09-24 18:22:54,LangLearnCopilot – Your Companion Python Package for Language Learning,osm3000,False,0.86,5,16r4rj2,https://www.reddit.com/r/learnmachinelearning/comments/16r4rj2/langlearncopilot_your_companion_python_package/,0,1695579774.0,"Original post: [https://www.reddit.com/r/Python/comments/16r4ddp/langlearncopilot\_your\_companion\_python\_package/](https://www.reddit.com/r/Python/comments/16r4ddp/langlearncopilot_your_companion_python_package/)

Link to the Github repo: [https://github.com/osm3000/LangLearnCopilot](https://github.com/osm3000/LangLearnCopilot)

Link to streamlit dashboard (if you are eager to try): [https://llcdashboard.streamlit.app/](https://llcdashboard.streamlit.app/)

For the full story, please check my blog: [https://osm3000.wordpress.com/2023/09/24/french-journey-part...](https://osm3000.wordpress.com/2023/09/24/french-journey-part-3/)

As  part of my ongoing quest to master the  French language — a journey  filled with numerous challenges — I've  turned to Python, creating a  practical tool in the form of a package  that can assist language  learners like myself. This is just one of  several tools I've either  developed or adopted, aimed at making language  learning more accessible  and effective.

This Python  package, based on  OpenAI GPT-4, comes with two main features. Firstly,  it has the  capacity to extract unique words from any URL or text and  subsequently  convert these into flashcards, compatible with Anki—a  popular, versatile  study tool. This allows learners to reinforce  vocabulary learning at  their own pace.

Secondly,  this tool can generate example sentences  for any word or set of words,  further converting these sentences into  flashcards. This aids not just  in vocabulary acquisition but also in  understanding the contextual  usage of words, a crucial part of gaining  fluency in any language.

I would love to hear your feedback and suggestions :)"
94,learnmachinelearning,openai,top,2022-04-10 04:14:06,How OpenAI's DALL-E 2 works explained at the level an average 15-year-old might understand (i.e. ELI-15) (not ELI-5),Wiskkey,False,0.78,5,u09u21,/r/bigsleep/comments/u08sjh/how_openais_dalle_2_works_explained_at_the_level/,0,1649564046.0,
95,learnmachinelearning,openai,top,2023-04-11 14:14:34,Help with pet project to learn - Running ChatGPT-2 at home,SigmaSixShooter,False,0.88,6,12il5t0,https://www.reddit.com/r/learnmachinelearning/comments/12il5t0/help_with_pet_project_to_learn_running_chatgpt2/,2,1681222474.0,"Greetings,

(Edit on Apr 12: Realized I screwed up and forgot I had a tokenize script as well. Updated things to properly reflect the process in case this is helpful for anyone else)

I know I'm probably the millionth person to ask, but I've tried as hard as I can to work through all of this and I've gotten stuck.

# The Goal

Train/fine-tune a model (not sure which) based on the TV show Firefly. I wanted to run this on the ChatGPT-2 model as that's what ChatGPT suggested. I've gathered the data, prepared it for training, and done the training itself. When I try to actually interact with it though, I get a lot of garbage back.

This is mostly a learning exercise for me as my end goal is to train/fine-tune something using internal data, so I need something that can run on consumer-grade hardware (I've got a 2019 MacBook Pro with an 8 core I9, AMD Radeon Pro 5300 and 32 gigs of ram). This would ultimately lead to something being used for commercial purposes, so I'm trying to be careful which models I use/train etc.


Here's a high level summary of what I've done, I'm hoping someone can help me understand where I might have went wrong. I'd greatly appreciate any assistance you're willing to provide. I've got some of my own thoughts/questions at the bottom of this post.

# Download ChatGPT-2

I made a clone of [https://github.com/openai/gpt-2](https://github.com/openai/gpt-2) on my local laptop

# Gather and prepare the data

I started out with a simple format where every line was formatted ""<Char Name>:<Dialogue>"" but ChatGPT eventually convinced me to convert this into JSON. I suspect this may be the heart of my problem. Below is a sample of what the JSON looks like. The  JSON is stored as one giant line in a text file, I'm not sure if that matters or not. It is valid JSON though.

Based on the recommendation from ChatGPT, I had this broken up into 80% for training data (training-data.json) and 20% for validation (validate-data.json)

```
$ cat training-data.json| jq | head
[
  {
    ""character"": ""Jayne"",
    ""dialogue"": ""Your move.""
  },
  {
    ""character"": ""Zoe"",
    ""dialogue"": ""That's a bold move.""
  },
```
# Tokenize the training data
(At least I think that's what I did here). The end result were two new files, `train_dataset.pt` and `valid_dataset.pt`. 

```
import torch
from transformers import GPT2TokenizerFast

tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')
tokenizer.add_special_tokens({'pad_token': '[PAD]'})

train_text = open('scripts/xaa', 'r').read()
valid_text = open('scripts/xab', 'r').read()

train_encodings = tokenizer(train_text, truncation=True, padding=True)
valid_encodings = tokenizer(valid_text, truncation=True, padding=True)

train_dataset = torch.utils.data.TensorDataset(
    torch.tensor(train_encodings['input_ids']),
    torch.tensor(train_encodings['attention_mask'])
)
valid_dataset = torch.utils.data.TensorDataset(
    torch.tensor(valid_encodings['input_ids']),
    torch.tensor(valid_encodings['attention_mask'])
)

print(""Sample"")
print(train_encodings['input_ids'][0:10])  # print the first 10 tokens
# Save the tokenized data to separate files
torch.save(train_dataset, 'train_dataset.pt')
torch.save(valid_dataset, 'valid_dataset.pt')
```

# Train the model?
I get confused by training and fine-tuning. The result of this was something output in the `models/gpt-finetuned` folder, so I guess I'm fine-tuning it. 

Code generated by ChatGPT

```
import torch
from torch.utils.data import DataLoader
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
from tqdm import trange
import sys
import time

# Check if GPU is available
device = torch.device(""mps"" if torch.backends.mps.is_available() else ""cpu"")
print(device)

if device == ""cpu"":
    sys.exit()

start_time = time.time()  # Record the start time

# Load the data
train_dataset = torch.load('train_dataset.pt')
valid_dataset = torch.load('valid_dataset.pt')

# Initialize the tokenizer and model
tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')
model = GPT2LMHeadModel.from_pretrained('gpt2')

# Set the batch size and number of epochs
batch_size = 5
num_epochs = 4

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=batch_size)

# Set up the optimizer and training parameters
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)
total_steps = len(train_loader) * num_epochs
warmup_steps = int(0.1 * total_steps)
num_steps = 0

# Set the device to GPU if available
device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
model.to(device)

# Train the model
for epoch in range(num_epochs):
    epoch_loss = 0
    progress_bar = trange(len(train_loader))
    for i, batch in enumerate(train_loader):
        # Move the batch to the device
        batch = tuple(t.to(device) for t in batch)
        inputs, labels = batch

        # Zero the gradients and forward pass
        optimizer.zero_grad()
        outputs = model(inputs, labels=labels)
        loss, logits = outputs[:2]
        epoch_loss += loss.item()

        # Backward pass and update parameters
        loss.backward()
        optimizer.step()
        scheduler.step(loss)

        # Update progress bar
        num_steps += 1
        progress_bar.update(1)
        progress_bar.set_description(f""Epoch {epoch + 1}/{num_epochs}"")
        progress_bar.set_postfix(loss=loss.item())

    # Print the average loss for the epoch
    print(f'Epoch {epoch + 1} Loss: {epoch_loss / len(train_loader)}')

# Save the model
model.save_pretrained('models/gpt2-finetuned')

end_time = time.time()  # Record the end time
total_duration = end_time - start_time  # Calculate the total duration
print(f""Total training time: {total_duration:.2f} seconds"")
```

# Trying it out

I then had ChatGPT create me a python script to run all of this.

```
import torch
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


def generate_response(model, tokenizer, prompt, max_length=100, num_return_sequences=1):
    input_ids = tokenizer.encode(prompt, return_tensors='pt')
    attention_mask = torch.ones(input_ids.shape, dtype=torch.long)
    output = model.generate(
        input_ids,
        attention_mask=attention_mask,
        max_length=max_length,
        num_return_sequences=num_return_sequences,
        no_repeat_ngram_size=2,
        temperature=5.0,
        top_p=1.5,
    )
    decoded_output = [tokenizer.decode(seq) for seq in output]
    return decoded_output


def main():
    model_name = 'models/gpt2-finetuned'
    model = GPT2LMHeadModel.from_pretrained(model_name)
    tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')  # Use the default GPT-2 tokenizer
    
    print(""Type 'quit' to exit the program."")
    while True:
        prompt = input(""Ask a question: "")
        if prompt.lower() == 'quit':
            break

        responses = generate_response(model, tokenizer, prompt)
        print(""Answer:"", responses[0].strip())

if __name__ == ""__main__"":
    main()
```

Running the above gets me something like this:
```
Ask a question: Give me an impression of Jayne from Firefly
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Answer: Give me an impression of Jayne from Firefly""

""I'm a big fan of the show""!
.!!!""!!!!!!!!?!!!!!!!!!""
,!!,!!:!!.!!?!!'!!"",!,!:!,!,!:!""!""!,!""!:!:!.!,!.!""!!!,!!!:!!!!!.!:!!!!,!!!!""!.!.!!!'!,!'!'!""!'!.!'!:!'!!!!!!!!?!!?!!!
```

This seems pretty far from desirable, but I can't really tell where I went wrong.

# Thoughts/questions

* I realize the data I gave it is just Character Name/Dialogue. Maybe it has no way of knowing everything I added was from Firefly....
* How could I better prepare the data for training? I think this is where I likely went wrong?
* Is there a better way I should have went about this?
* How can I further troubleshoot this?
* Is what I'm **trying** to do called ""fine tuning a model""?"
96,learnmachinelearning,openai,top,2022-12-28 17:37:46,chatGPT peeps- anyone else learn new stuff best by actually building something?,bruclinbrocoli,False,0.69,6,zxfnga,https://www.reddit.com/r/learnmachinelearning/comments/zxfnga/chatgpt_peeps_anyone_else_learn_new_stuff_best_by/,4,1672249066.0,"[This intro to chatGPT](https://buildspace.so/notes/intro-to-chatgpt) has some cool (free) challenges at the end to build a telegram bot, a business email generator, or a writing assistant.

What else have people found to learn bout chatGPT that's not just theory?

&#x200B;

https://preview.redd.it/smxv4mzldo8a1.png?width=1026&format=png&auto=webp&s=43081abbfcad449817e520b5e92ba599a18a1525"
97,learnmachinelearning,openai,top,2023-03-21 15:41:19,"Lets say I want ChatGPT to do my standup meeting for me. I should train it with ""what i did yesterday"", ""what Im doing"" , and ""what I plan to do after"" right? How do I train through the openAI API?",JonOfDoom,False,0.72,6,11xkl53,https://www.reddit.com/r/learnmachinelearning/comments/11xkl53/lets_say_i_want_chatgpt_to_do_my_standup_meeting/,1,1679413279.0,"Currently using [https://platform.openai.com/docs/guides/fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)  


What should my training samples be?   


Half the data I did yesterday? like...   
prompt: ""what did I do yesterday?"", completion: ""finished ticket A and B, did PR on ticket C""  


The other half how to answer standup?  
prompt: ""do standup"", completion: ""Yesterday I finished tickets A,B. Then peer reviewed ticket C""  


Im new to AI. Interested but felt that algorithms are too much. Figured the openAI api is now accessible and worth to try"
98,learnmachinelearning,openai,top,2023-02-20 19:01:54,Master ChatGPT Prompt Engineering (Deep Dive),jeyThaswan,False,0.7,4,117hd0f,https://www.reddit.com/r/learnmachinelearning/comments/117hd0f/master_chatgpt_prompt_engineering_deep_dive/,2,1676919714.0," 

I wrote a deep dive on prompt engineering as a resource for the AI community and my 10,000 daily newsletter subscribers ([Inclined.ai](https://www.inclined.ai/p/prompt-engineering-guide) if you're curious). We've included some examples so feel free to copy and paste the prompts into ChatGPT!

&#x200B;

**WHAT IS PROMPT ENGINEERING?**

The term is relatively new, and its origins are argued *(because we live in the internet age, and it’s harder to claim ownership)*. Prompt engineering is the ability to instruct and teach AI effectively.

If it helps, think of this as rapid testing or instruction writing for artificial intelligence.

What’s important is not to let this overwhelm you. The first prompting happened with the first AI model. The first example was showing computer images of circles and triangles. **Today’s neural networks can process way more data, creating complexities.**

So, the concept is simple, but digging into the full power of AI today is something else entirely.

We’re not talking about asking questions. Odds are, if you’re typing *“what’s 2+2”* into ChatGPT, then you need to keep reading.

We can all ask chatbots questions. That can work more often than not. But AI is not perfect. A common metaphor I see is to treat GPT-based large language models like the smartest five-year-old you’ve ever met.

I have a niece around that age and can’t imagine trying to get her to write an essay on the effects of soil mismanagement in relation to Reconstruction politics. *See! Your eyes glazed over reading that, so how do we make this work for our AI buddies?*

The Principles of Prompting

Stop asking single-line questions. *That’s like using a top-rated cookbook to find out how to make grilled cheese.*

**There are three ways to instantly get better at prompting** and go from grilled cheese to top-notch bolognese. From there, we can get into some specific prompt concepts and the ability to unlock ChatGPT’s full potential.

Principle 1: Context is King

GPT-3.5 is swimming in data. When you ask it for a simple request, it can end up complicating things more than you realize. Did you ever wonder why ChatGPT is so bad at math?

The reality is the LLM is taking words and turning them into patterns. From there, it’s making an educated guess.

Give your chat AI a frame to search into. If you give it a math problem, you need to make sure it grasps that you want it to do math. If you’d like ChatGPT to write a high school essay, you must ensure it knows to write at that level.

**Instead of:** “Plan a party for a kid.”

**Try:** “My child is turning 9. They like superheroes and the color red. Help me plan a party for this weekend. Ten of his friends are coming to my house.”

You’ll get a much better response this way. **Context is the cardinal direction** that helps your chat companion find the most correct guess and phrase it the best way.

Principle 2: Get Specific

Pretend you’re writing a law that’s going to be judged by the Supreme Court of the United States. You know what they look for: narrow tailoring.

**Keep things on track and stay focused.** Try to avoid prompting outside the specific request. You’ll only hurt the ability of the chat AI to give you a quality response. Odds are they’ll even skip over parts if you confuse them with too many requests.

It runs parallel with context. *If you set ChatGPT up in a room and then tell it to focus on describing the chair first, you’ll see better results.*

**Instead of:** “I’m going to a job interview. Write five questions for me to answer. Add tips for how to not get nervous before the interview. Do not create questions asking about my background.”

**Try:** “You’re interviewing a software engineer. Create five questions to ask them to understand their skill set and qualifications better.”

Nothing limits the number of prompts you can do. Focus and expand from the initial request and try not to do everything at once.

Principle 3: When in Doubt: “Let’s take this step-by-step.”

Welcome. **You discovered the magic word today.** This phrase slows everything down for the AI and gets you where you need to go.

You don’t need to start with this phrase. Using it tells ChatGPT to show their work.

We’ll explain where this concept comes from further in our briefing, but here’s the TL;DR: sometimes, there’s a part of our prompt it’s not identified correctly. “Let’s take this step-by-step,” reminds you and ChatGPT to **slow down and get specific.**

If you learn to utilize this phrase more often and find ways to make it work for you, you’ll become a better prompt engineer. One term can do a lot of heavy lifting.

**Pro-tip:** We’ve shown you “standard” prompts in all these examples. Many prompt engineers will use “Standard QA form” prompts. Here’s our example for this principle written that way.

**Example:**

*“Q: The Industrial Revolution rapidly changed the infrastructure in London. Describe three essential innovations from this period and connect them to Landon’s development.*

*A: Let’s take this step-by-step.”*

Even without our magic word, this style of standard prompting is quite helpful to adopt.

*However, we’re beginning to stumble into the advanced tactics used in prompt engineering, so it’s time for a new section.*

UNIQUE WAYS TO PROMPT

Let’s preface this: we can go super deep here. Prompt engineering is changing daily, and as these models get more sophisticated, the need to adapt prompts strengthens.

To keep things clean, I will go through these using our metaphor from earlier. **Let’s pretend ChatGPT is a super-intelligent toddler.**

*Got it? With that buy-in, we can continue.*

1/ Role Prompting

We’ll start with a popular tactic. **Our toddler is great at imagining things.** You tell them they’re a fireman, and suddenly they can give you detailed ways to ensure your apartment is up to code. Role-playing is a fun, easy way to build context.

The best part of role prompting is how easy it is to understand and use. All you need to do is tell ChatGPT to play a role. From there, the AI will do its best to fill the part *like that enthusiastic drama student from your old high school.*

You can even take this a step further. **Try framing your prompt as a script.** Tell the LLM specific instructions around a scene that gives you the answer to your question.

TRY IT OUT FOR YOURSELF:

Copy this prompt into ChatGPT and find a destination!

“Act as a travel guide. I will tell you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion: \[fill it in\]”

Why would you take that extra step? While popular, role prompting does not necessarily improve accuracy. *You can tell your five-year-old they’re a mathematician, and they’ll still manage to screw things up.*

Let’s get deeper.

2/ Chain-of-Thought Prompting

There’s a scene in ***Guardians of the Galaxy*** where Rocket Raccoon is trying to [teach young Groot](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3lvdXR1LmJlL0hyaW1mZ2pmNGs4IiwicG9zdF9pZCI6ImM0ODlmMzhkLTY3NDAtNGRmNS05MWJjLTM1ODA0YTVmNTZkMiIsInB1YmxpY2F0aW9uX2lkIjoiNjNkODQ2ZGUtZDFiZi00ZTVjLWJjYzgtOWMxYzlkMWIxMjA0IiwidmlzaXRfdG9rZW4iOiJkZWRiNmMyNy1hYmM0LTQ5ZDUtYWM2Ny04OTcyZmM1MGVmM2QiLCJpYXQiOjE2NzY5MTkwNjguMTUyLCJpc3MiOiJvcmNoaWQifQ.5eZkDLGRLCXXYv32FYT7kLSbdRK5OK1iemTRf3HVmJw)

how to activate a complicated device. That’s chain-of-thought prompting.

**You take an example question and answer it for ChatGPT.** Show them your chain of thought. Then you give it a new question in the same vein and ask it for an answer.

This prompt style allows you to get more specific. You’re telling your toddler they’re here to answer this particular question with one specific logic pattern.

Within this specific style is two other sub-categories. Let me give the rundown:

* Zero-shot Chain-of-Thought is “Let’s take this step-by-step” you frame the question the same, but don’t give it a precursor. Instead, you ask it to think through the points made. EX: Q: X is A. Y is B. What is C? A: Let’s take this step-by-step.
* Self-consistency is using several responses to find the most accurate answer. You give ChatGPT more swings at the ball. Take the hits and discover the grouping.

TRY IT OUT FOR YOURSELF:

Copy this prompt into ChatGPT and see how accurate it is:

“Q: Which is a faster way to get home?

Option 1: Take an 10 minutes bus, then an 40 minute bus, and finally a 10 minute train.

Option 2: Take a 90 minutes train, then a 45 minute bike ride, and finally a 10 minute bus.

A: Option 1 will take 10+40+10 = 60 minutes.

Option 2 will take 90+45+10=145 minutes.

Since Option 1 takes 60 minutes and Option 2 takes 145 minutes, Option 1 is faster.

Q: Which is a faster way to get to work?

Option 1: Take a 1000 minute bus, then a half hour train, and finally a 10 minute bike ride.

Option 2: Take an 800 minute bus, then an hour train, and finally a 30 minute bike ride.

A: ”

[Learnprompting.org](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwOi8vTGVhcm5wcm9tcHRpbmcub3JnIiwicG9zdF9pZCI6ImM0ODlmMzhkLTY3NDAtNGRmNS05MWJjLTM1ODA0YTVmNTZkMiIsInB1YmxpY2F0aW9uX2lkIjoiNjNkODQ2ZGUtZDFiZi00ZTVjLWJjYzgtOWMxYzlkMWIxMjA0IiwidmlzaXRfdG9rZW4iOiJkZWRiNmMyNy1hYmM0LTQ5ZDUtYWM2Ny04OTcyZmM1MGVmM2QiLCJpYXQiOjE2NzY5MTkwNjguMTUyLCJpc3MiOiJvcmNoaWQifQ.-wOnVYoMNWXYrR5NOB4YYKp4Lmj-aZq3y-pr4Hou9pE)

\- by leaving the “A:” blank you’re prompting ChatGPT for the answer

Alright, you’re almost there—one more to go.

3/ General Knowledge Prompting

You’re going to notice a trend here. This prompt style also circles context and narrow tailoring.

All you do is tell your toddler how the world works. The cow goes moo. The dog goes woof. So what does a cat say?

It’s an oversimplification, but the core reasoning is there. Show ChatGPT some knowledge and turn that into the only focus for that chat. You can take an article from the internet and summarize it for the model. Make sure to ask if it understands and relay the information to you.

Once you know you have the attention set in the suitable space, get to work. For instance, we can share an Inclined newsletter with it and tell ChatGPT about its structure and tone.

From there, you can provide new information and tell ChatGPT to summarize it within the same structure as Inclined. You both share the same general knowledge now.

TRY IT OUT FOR YOURSELF:

Copy this prompt into ChatGPT and test it out:

“Prompt 1. Look over this article here: \[pick an article\]. Breakdown its structure and general tone.

Prompt 2: Recall the structure and tone you mentioned above. Take that general knowledge and summarize this article: \[pick a new one\] using the same structure and tone.”

Note: this is a heavily simplified version of GA Prompting

Did you know some [people don’t consider](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL25ld3MueWNvbWJpbmF0b3IuY29tL2l0ZW0_aWQ9MzQ0OTU0NTUiLCJwb3N0X2lkIjoiYzQ4OWYzOGQtNjc0MC00ZGY1LTkxYmMtMzU4MDRhNWY1NmQyIiwicHVibGljYXRpb25faWQiOiI2M2Q4NDZkZS1kMWJmLTRlNWMtYmNjOC05YzFjOWQxYjEyMDQiLCJ2aXNpdF90b2tlbiI6ImRlZGI2YzI3LWFiYzQtNDlkNS1hYzY3LTg5NzJmYzUwZWYzZCIsImlhdCI6MTY3NjkxOTA2OC4xNTMsImlzcyI6Im9yY2hpZCJ9.yHKIPujINT89tsqOo07AXk6OrKNgoMjO3fBEYPkAdNY)

that prompt engineering?

PROMPT CULTURE

*“How can something not be prompt engineering if it’s a prompt style?”*

Good question, imaginary reader. The culture around this skill is relatively fresh. So some of **these concepts are seen as too easy** to be considered accurate prompt testing.

General knowledge prompting is simply establishing the context, and for some, that’s a baseline everyone needs to do. The same can be said for role prompting, too. *All of these tiny preferences are semantics.*

**Don’t sweat whether you’re a “real” prompt engineer.** Test this out and share your insights in these communities. The opportunity is there for you.

You may even know about DAN (we’ve covered it in previous newsletters) and other AI hacking methods. Those all start with prompt engineering. You can make the case that unless the AI behaves outside its parameters, you’re not genuinely doing prompt engineering.

I'm afraid I have to disagree with that, and **careers are sprouting up everywhere** that center directly on this skill. **Many require a core understanding of the prompt styles we’ve discussed.**

*Yep, you can learn this and make money from talking with AI.*

Anthropic even [posted a role for a prompt engineer](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL2pvYnMubGV2ZXIuY28vQW50aHJvcGljL2UzY2RlNDgxLWQ0NDYtNDYwZi1iNTc2LTkzY2FiNjdiZDFlZCIsInBvc3RfaWQiOiJjNDg5ZjM4ZC02NzQwLTRkZjUtOTFiYy0zNTgwNGE1ZjU2ZDIiLCJwdWJsaWNhdGlvbl9pZCI6IjYzZDg0NmRlLWQxYmYtNGU1Yy1iY2M4LTljMWM5ZDFiMTIwNCIsInZpc2l0X3Rva2VuIjoiZGVkYjZjMjctYWJjNC00OWQ1LWFjNjctODk3MmZjNTBlZjNkIiwiaWF0IjoxNjc2OTE5MDY4LjE1MywiaXNzIjoib3JjaGlkIn0.4s7Htzgoxv0_qM1Ten17oQ5h0_QGM6e1fGUYz_ymgJ4)

that nets a quarter million in salary. I did not make that up and even considered sprucing up the old resume. When a new skill like this comes about, it’s worth looking at.

There are many other examples like this, and OpenAI uses a red teaming strategy where their engineers attempt to prompt hack their own GPT models.

I can tell you all about the open roles here, but tomorrow the whole cycle will change. *Isn’t that exciting, though?* The entire identity around prompt engineering will change by this time next year.

WHAT SHOULD YOU TAKEAWAY?

Communication is everything. **Learning to speak with AI is rising in importance.**

We all watch with mouth agape at the new wonders in AI because we know this will disrupt every industry. If any of this piqued your interest, the window to pursue it is now open. Ride that wave and [learn](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL2xlYXJucHJvbXB0aW5nLm9yZy8iLCJwb3N0X2lkIjoiYzQ4OWYzOGQtNjc0MC00ZGY1LTkxYmMtMzU4MDRhNWY1NmQyIiwicHVibGljYXRpb25faWQiOiI2M2Q4NDZkZS1kMWJmLTRlNWMtYmNjOC05YzFjOWQxYjEyMDQiLCJ2aXNpdF90b2tlbiI6ImRlZGI2YzI3LWFiYzQtNDlkNS1hYzY3LTg5NzJmYzUwZWYzZCIsImlhdCI6MTY3NjkxOTA2OC4xNTMsImlzcyI6Im9yY2hpZCJ9.a67KDSN9yQfZsaMeHpdcbSbtPjD4yFcGW4stdxBjX1M)

to become a brilliant prompt engineer.

Heck, even if you don’t want to switch careers, **talking with ChatGPT and all the newest LLMs is becoming a part of our daily routine.** Get to the point where you maximize every interaction and work with these chatbots to upskill your workflow.

Prompt engineering can save you time, eliminate hassle, and even help you become a more patient person. Focus on what you want and explain it with intent.

Make magic happen, and remember: **take it step-by-step.**"
99,learnmachinelearning,openai,top,2019-05-12 16:22:04,What is OpenAI Gym used for?,codexblaze,False,1.0,5,bnqrdj,https://www.reddit.com/r/learnmachinelearning/comments/bnqrdj/what_is_openai_gym_used_for/,4,1557678124.0,I a beginner learning reinforcement learning. I was wondering what openAI Gym is used for.
100,learnmachinelearning,openai,comments,2023-05-11 00:54:18,What do actual ML engineers think of ChatGPT?,PhillConners,False,0.96,149,13e8of2,https://www.reddit.com/r/learnmachinelearning/comments/13e8of2/what_do_actual_ml_engineers_think_of_chatgpt/,106,1683766458.0,"You have been doing this for awhile, now the world is obsessed with OpenAI and suddenly all full of AI “experts”."
101,learnmachinelearning,openai,comments,2023-01-10 11:12:01,Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI,BackgroundResult,False,0.97,448,1087ady,https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion,102,1673349121.0,
102,learnmachinelearning,openai,comments,2023-01-19 07:56:20,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.96,333,10fw2df,https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/,47,1674114980.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
103,learnmachinelearning,openai,comments,2020-08-05 10:58:02,image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model,OnlyProggingForFun,False,0.97,636,i437om,https://www.youtube.com/watch?v=FwXQ568_io0,46,1596625082.0,
104,learnmachinelearning,openai,comments,2023-01-16 12:28:25,I benchmarked OpenAI's GPT API vs other proprietary APIs on different NLP tasks,AImSamy,False,0.9,199,10ddc1f,https://www.reddit.com/gallery/10ddc1f,37,1673872105.0,
105,learnmachinelearning,openai,comments,2023-05-25 17:23:19,"Are people still coding stuff on their own like chatbots, image AIs, etc., or is everyone just using pretrained models and APIs now?",TrackLabs,False,0.91,91,13rnopr,https://www.reddit.com/r/learnmachinelearning/comments/13rnopr/are_people_still_coding_stuff_on_their_own_like/,35,1685035399.0,"I feel like everyone is just downloading models from huggingface at this point, or using GPT APIs and so on.

I also feel like there are not really tutorials anymore on YT and the web about how to code stuff like there used to be 5 to 2 years ago. Every video now is just ""how to use OpenAIs API"" or ""how to use llama model from huggingface"". 

I have a big problem with staying up to date on the stuff, I never really bothered using huggingface, and I dont really like the idea to just use other peoples pretrained models for everything, what actual contribution am I doing in my own projects then lol.

Would be cool if some people could give me some reality check on whats going on."
106,learnmachinelearning,openai,comments,2023-11-23 10:24:00,"Nonfiction authors sue OpenAI, Microsoft for copyright infringement",anujtomar_17,False,0.84,40,181y9sl,https://newyorkverified.com/4324297-nonfiction-authors-sue-openai-microsoft-copyright-infringement/,34,1700735040.0,
107,learnmachinelearning,openai,comments,2023-02-16 10:29:31,OpenAI Has Purchased AI.Com For ChatGPT For $11M,vadhavaniyafaijan,False,0.93,209,113nizs,https://www.theinsaneapp.com/2023/02/openai-purchased-ai-com-domain.html,23,1676543371.0,
108,learnmachinelearning,openai,comments,2022-01-22 13:55:19,"Consolidated Video lectures for Machine Learning(including DL, CV, NLP, etc)",slim_but_not_shady,False,0.99,259,sa30oc,https://www.reddit.com/r/learnmachinelearning/comments/sa30oc/consolidated_video_lectures_for_machine/,23,1642859719.0,"**Video Lectures for Machine Learning(Theory):**

**Machine Learning:**

Cornell CS4780: [https://www.youtube.com/playlist?list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS](https://www.youtube.com/playlist?list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS)

Stanford CS 229:

[https://www.youtube.com/playlist?list=PLoROMvodv4rNH7qL6-efu\_q2\_bPuy0adh](https://www.youtube.com/playlist?list=PLoROMvodv4rNH7qL6-efu_q2_bPuy0adh)

IIT Madras:

[https://www.youtube.com/playlist?list=PL1xHD4vteKYVpaIiy295pg6\_SY5qznc77](https://www.youtube.com/playlist?list=PL1xHD4vteKYVpaIiy295pg6_SY5qznc77)

IISc Bangalore(Rigorous Math):

[https://www.youtube.com/playlist?list=PLbMVogVj5nJSlpmy0ni\_5-RgbseafOViy](https://www.youtube.com/playlist?list=PLbMVogVj5nJSlpmy0ni_5-RgbseafOViy)

Applied Machine Learning Cornell CS5787:

[https://www.youtube.com/playlist?list=PL2UML\_KCiC0UlY7iCQDSiGDMovaupqc83](https://www.youtube.com/playlist?list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83)

Caltech's Machine Learning Course - CS 156 by Professor Yaser Abu-Mostafa:

[https://www.youtube.com/playlist?list=PL41qI9AD63BMXtmes0upOcPA5psKqVkgS](https://www.youtube.com/playlist?list=PL41qI9AD63BMXtmes0upOcPA5psKqVkgS)

StatQuest(Best resource for revision and visualization):

[https://www.youtube.com/user/joshstarmer?app=desktop](https://www.youtube.com/user/joshstarmer?app=desktop)

&#x200B;

**Deep Learning:**

IIT Madras(No prerequisites and great prof):

Part 1: [https://youtube.com/playlist?list=PLyqSpQzTE6M9gCgajvQbc68Hk\_JKGBAYT](https://youtube.com/playlist?list=PLyqSpQzTE6M9gCgajvQbc68Hk_JKGBAYT)

Part 2: [https://www.youtube.com/playlist?list=PLyqSpQzTE6M-\_1jAqrFCsgCcuTYm\_2urp](https://www.youtube.com/playlist?list=PLyqSpQzTE6M-_1jAqrFCsgCcuTYm_2urp)

Course link for slides and references: [http://www.cse.iitm.ac.in/\~miteshk/CS7015\_2018.html](http://www.cse.iitm.ac.in/~miteshk/CS7015_2018.html)

Neural Networks by Hinton:

[https://www.youtube.com/playlist?list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0](https://www.youtube.com/playlist?list=PLiPvV5TNogxKKwvKb1RKwkq2hm7ZvpHz0)

 NYU DL (Taught by Prof Alfredo Canziani and Prof Yann Lecun):

[https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI](https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI) 

**Computer Vision(Deep Learning):**

Michigan University:

[https://youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r](https://youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r)

(This Michigan university course is the updated version of Stanford’s CS231n CV course and includes all the content covered by that as well)

Advanced Deep Learning for Computer Vision by TU Munich:

[https://www.youtube.com/playlist?list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39](https://www.youtube.com/playlist?list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39)

**Natural Language Processing(Deep Learning):**

Stanford CS 224n:

[https://youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z](https://youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)

Natural Language Understanding Stanford CS 224u:

[https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20](https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20)

Deep Learning for NLP at Oxford with Deep Mind 2017:

[https://www.youtube.com/playlist?list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm](https://www.youtube.com/playlist?list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm)

NLP CMU 11-411/11-611:

[https://www.youtube.com/playlist?list=PL4YhK0pT0ZhXteJ2OTzg4vgySjxTU\_QUs](https://www.youtube.com/playlist?list=PL4YhK0pT0ZhXteJ2OTzg4vgySjxTU_QUs)

CMU CS11-737 Multilingual Natural Language Processing:

[https://www.youtube.com/playlist?list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5](https://www.youtube.com/playlist?list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5)

**Reinforcement Learning:**

IIT Madras:

[https://youtube.com/playlist?list=PLEAYkSg4uSQ0Hkv\_1LHlJtC\_wqwVu6RQX](https://youtube.com/playlist?list=PLEAYkSg4uSQ0Hkv_1LHlJtC_wqwVu6RQX)

Stanford CS234:

[https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)

**Deep Reinforcement Learning:**

UC Berkeley CS 285:

[https://youtube.com/playlist?list=PL\_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc](https://youtube.com/playlist?list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc)

**Other:**

CS224W: Machine Learning with Graphs

[https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn](https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn)

Stanford CS330: Multi-Task and Meta-Learning

[https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5](https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5)

Explainable AI:

[https://www.youtube.com/playlist?list=PLV8yxwGOxvvovp-j6ztxhF3QcKXT6vORU](https://www.youtube.com/playlist?list=PLV8yxwGOxvvovp-j6ztxhF3QcKXT6vORU)

Explainable AI in Industry:

[https://www.youtube.com/playlist?list=PL9ekywqME2Aj8OmKoBUaYEH7Xzi-YCRBy](https://www.youtube.com/playlist?list=PL9ekywqME2Aj8OmKoBUaYEH7Xzi-YCRBy)

**Some Math lectures(refresher):**

Linear algebra(MIT):

[https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8](https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8)

Optimization(IIT Kanpur):

[https://www.youtube.com/playlist?list=PLbMVogVj5nJRRbofh3Qm3P6\_NVyevDGD\_](https://www.youtube.com/playlist?list=PLbMVogVj5nJRRbofh3Qm3P6_NVyevDGD_)

Multivariable Calculus(MIT):

[https://www.youtube.com/playlist?list=PL4C4C8A7D06566F38](https://www.youtube.com/playlist?list=PL4C4C8A7D06566F38)

Probability and Statistics(Harvard):

[https://www.youtube.com/playlist?list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo](https://www.youtube.com/playlist?list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo)

&#x200B;

If you are applying for a job, ML and DL is sufficient for a DS/ML Engineer role initially(Given that you know programming and have completed some projects). But depending on the JD and the work that the company does, Computer vision and Natural Language Processing questions can be expected.

Disclaimer: The video list includes some advanced topics(Meta-learning, Graph ML, etc) which might not be relevant for a person who is applying for a ML Engineer job(unless your job involves work or research related to those topics)

**Some basic Python libraries that you need to be familiar with:**

ML: Sckit-learn, xgboost, catboost, lightgbm, hyperopt etc

DL: Tensorflow, PyTorch, Keras, etc

NLP and transformers: HuggingFace

RL: OpenAI Gym, etc

Production: MLFlow, Apache Airflow, Kubeflow, etc (This is not a hardcore requirement but some companies ask questions on production tools)

Explainable AI: SHAP, LIME, ELI5, tf-explain, captum, etc( Not a hardcore requirement for interviews)"
109,learnmachinelearning,openai,comments,2023-10-19 17:47:15,is hosting a 7B model on cloud cheaper than accessing openai’s api,besabestin,False,0.86,20,17bozjd,https://www.reddit.com/r/learnmachinelearning/comments/17bozjd/is_hosting_a_7b_model_on_cloud_cheaper_than/,21,1697737635.0,"I have few questions related to this. Now that a lot of smaller models are becoming better and accessible, are they getting cheaper for access? llama and mistral models are getting better and also getting more improvements through quantization or better attention techniques.

I was using openai’s models and they cost so low unless you are summarizing tens of pages of pdf files. I am looking at like 20cents of my whole day use.

How are such models actually uploaded on cloud? Are the weights saved in database and stuff? I know there are tools like skyplot but how do they work underneath?"
110,learnmachinelearning,openai,comments,2023-08-17 12:50:37,I'm trying to create a comprehensive table of the best AI tools to Increase Your Productivity + Automate Your Work- feel free to give some recs so I can add it to the list.,paulflythe,False,0.8,39,15tmnit,https://i.redd.it/sgcuo4o13oib1.png,19,1692276637.0,
111,learnmachinelearning,openai,comments,2019-10-23 23:58:05,OpenAI plays hide and seek and breaks the game. (Reinforcement Learning),UnintelligibleThing,False,0.97,342,dm86ay,https://www.youtube.com/watch?v=Lu56xVlZ40M,19,1571875085.0,
112,learnmachinelearning,openai,comments,2023-10-06 12:17:41,Wrap my own API library in a GPT-like based chatbot,motorollo,False,0.5,0,171ati0,https://www.reddit.com/r/learnmachinelearning/comments/171ati0/wrap_my_own_api_library_in_a_gptlike_based_chatbot/,18,1696594661.0,"Hi everyone!
I am working on a project whose ultimate goal is to be able to chat with a chatbot that after a natural language request returns specific calls to library functions that implement calls to a tool's API.

A bit more into details: I have a tool that can be used by calling its HTTP API. In order to make these calls, I have built a library on top of the API, so as to simplify the calls and make them easier to use. I would like to have a chatbot whose model is trained on the library itself, so that, given a natural language request as input, it returns its translation into the library language. 

My first idea was to use OpenAI API service as a wrapper and eventually try other models in the future if I find a better and/or cheaper custom way to implement the chatbot.

My doubts are mainly 2:
1. Fine-tuning: which is the best way to fine-tune the OpenAI model for this use case?

2. Well formatted calls: how to avoid the chatbot from returning non-existing method calls or classes and stick with what is available in the library?

Any other suggestion outside the scope of the doubts are more than welcome.
Thank you very much in advance for every guy that will read the post."
113,learnmachinelearning,openai,comments,2021-01-18 15:30:22,Reinforcement Learning Crash Course (Free),rroocckk,False,0.95,142,kzwso5,https://www.reddit.com/r/learnmachinelearning/comments/kzwso5/reinforcement_learning_crash_course_free/,18,1610983822.0,"I wanted to announce the new and free [Reinforcement Learning Crash Course](https://rlcourse.com).

This course takes a _unique hands-on approach_ to teaching Reinforcement Learning.

- Reinforcement Learning concepts are communicated primarily via code examples (Python, Gym and Keras). 

- Mathematical equations are kept to a minimum. 

Therefore, the course should appeal to you if you like a practical approach to learning, devoid of mathematical pedantry. Plus, you can be an absolute beginner. You don't need any prior machine learning knowledge to understand the content. Machine Learning and Deep Learning concepts are introduced and explained within the course when needed.

This is my attempt at creating a Reinforcement Learning course that **programmers** can love. I am hoping that this further democratizes the amazing capabilities of RL. I have tried to maintain the high standards found in David Silver's course or The Deep RL Bootcamp at Berkeley, but replacing mathematics with code as the main learning UI. I am also inspired by François Chollet's intuitive and code-first approach in his book Deep Learning with Python.

I make the course in my free time, and that allows me to upload 1 video on a new topic per week. The first chapter is already published at the time of this announcement and the rest will come in the next months according to a planned schedule. I have decided that if you enroll now (while the course is being made), it will be **free and you keep all the content forever**. 

In the already published chapter, you will be introduced to Reinforcement Learning basics. This way, you can already take the course for a test drive and see if you like my code-first approach. 

Take a look at the detailed syllabus to find what to expect from later chapters. Briefly speaking, we will take a code-oriented approach to learning classical Reinforcement Learning algorithms like GLIE Monte Carlo, SARSA etc. and Deep RL algorithms like PPO and DQN. We will pay special attention to the following topics: 

- Writing modular and extensible code
- How to make results reproducible
- Logging
- Monitoring
- Best practices for running RL experiments. 

There will also be plenty of practice problems where you will be able to test out your new skills. At the end of the course, you will have solved 5 interesting OpenAI Gym environments, covering everything from classic problems, bipedal walking to playing games. After doing the course, you will be able to confidently apply RL to other problems that catch your fancy.

Thank you for taking the time to read all of this.  The [course page](https://rlcourse.com) has more details."
114,learnmachinelearning,openai,comments,2024-02-19 01:44:52,GPU vs CPU for inference,AI-Brain,False,0.67,3,1aubc4u,https://www.reddit.com/r/learnmachinelearning/comments/1aubc4u/gpu_vs_cpu_for_inference/,18,1708307092.0,"I read through some comments on the sub and understood that GPUs are mainly used for training and CPUs for inference. Had some follow ups: 
1. Is there a scenario where GPUs are better suited for inference? 
2. Would you say that if you are handling billions of inference requests then you should use GPUs? 
3. What makes GPUs inefficient for inference? (If any) 
4. When we use chatGPT, is OpenAI using CPUs for inference? 

Any insights would be helpful."
115,learnmachinelearning,openai,comments,2023-06-14 09:08:23,"Introducing, OpenLLM 🎉",AaZasDass,False,0.96,88,149302y,https://www.reddit.com/r/learnmachinelearning/comments/149302y/introducing_openllm/,15,1686733703.0,"OpenLLM allows you to run inferences with any open-source LLMs, deploy to the cloud or on-premises, and build powerful AI apps. It includes simple and familiar APIs, enabling easy integration with tools such as LangChain, and BentoML! Discover more at [https://github.com/bentoml/OpenLLM](https://github.com/bentoml/OpenLLM)

To get started, install it with pip: `pip install -U openllm`  Currently, it has support for all major SOTA LLMs, including Falcon, ChatGLM, Dolly V2, StableLM, and more to come!

Some of the feature that is currently wip:

\- Fine-tuning API with `LLM.tuning()`

\- LangChain integration [https://github.com/hwchase17/langchain/pull/6064](https://github.com/hwchase17/langchain/pull/6064)

\- OpenAI Compatible API

    import openai
    
    openai.api_base = ""http://localhost:3000"" # Running with OpenLLM
    
    completion = openai.Completion.create(...)

We are currently actively developing the library, so we would love to hear your thoughts and feedback. Feel free also to join our [discord](https://l.bentoml.com/join-openllm-discord) to meet other fellows, AI application builders, and enthusiasts."
116,learnmachinelearning,openai,comments,2023-10-13 21:02:42,ChatBase Backend: How Does it Work?,Nice-Ad1199,False,1.0,2,1778n3l,https://www.reddit.com/r/learnmachinelearning/comments/1778n3l/chatbase_backend_how_does_it_work/,17,1697230962.0,"Hey all,

I've been building my own ""personal assistant"" using the GPT API and Eleven Labs, and I am finally getting to the fine-tuning portion of everything. That being said, I have been primarily working with fine-tuning GPT directly through the OpenAI documentation, finding some success, but nothing too amazing quite yet.

&#x200B;

That being said, I was pointed to [ChatBase](https://www.chatbase.co/), a website that trains GPT on your data. I am assuming many of you have seen it, but the point is you can put documents, text, Q&A's, and web data which it will then train GPT on. The results are quite good with proper data, but it really doesn't require much to produce results.  


I imagine that they are using the same fine tuning techniques, but I question how they are able to produce such fantastic results with such little information. Perhaps there is something I am missing in the documentation? Does anybody know how one might be able to achieve similar results to a custom ChatBase model through their own GPT fine-tuning data set?"
117,learnmachinelearning,openai,comments,2023-09-16 13:22:41,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.95,133,16k7heb,https://www.reddit.com/r/learnmachinelearning/comments/16k7heb/this_week_in_ai_all_the_major_ai_developments_in/,17,1694870561.0,"1. **Stability AI** launched Stable Audio, a generative AI tool for music & sound generation from text. The underlying latent diffusion model architecture uses audio conditioned on text metadata as well as audio file duration and start time.
2. **Coqui** released **XTTS** \- a new voice generation model that lets you clone voices in 13 different languages by using just a quick 3-second audio clip.
3. **Microsoft Research** released and open-sourced **Phi-1.5** \- a 1.3 billion parameter transformer-based model with performance on natural language tasks comparable to models 5x larger.
4. **Project Gutenberg**, Microsoft and MIT have worked together to use neural text-to-speech to create and release thousands of **human-quality free and open audiobooks**.
5. Researchers present **NExT-GPT -** an any-to-any multimodal LLM that accepts inputs and generate outputs in arbitrary combinations of text, images, videos, and audio.
6. **Chain of Density (CoD):** a new prompt introduced by researchers from Salesforce, MIT and Colombia University that generates more dense and human-preferable summaries compared to vanilla GPT-4.
7. **Adept** open-sources **Persimmon-8B**, releasing it under an Apache license. The model has been trained from scratch using a context size of 16K.
8. **Adobe's** **Firefly** generative AI models, after 176 days in beta, are now commercially available in Creative Cloud, Adobe Express, and Adobe Experience Cloud. Adobe is also launching Firefly as a standalone web app.
9. **Deci** released **DeciLM 6B**, a permissively licensed, open-source foundation LLM that is 15 times faster than Llama 2 while having comparable quality.
10. Researchers release **Scenimefy** \- a model transforming real-life photos into Shinkai-animation-style images.
11. **Microsoft** open sources **EvoDiff**, a novel protein-generating AI that could be used to create enzymes for new therapeutics and drug delivery methods as well as new enzymes for industrial chemical reactions.
12. Several companies including Adobe, IBM, Nvidia, Cohere, Palantir, Salesforce, Scale AI, and Stability AI have pledged to the White House to develop safe and trustworthy AI, in a voluntary agreement similar to an earlier one signed by Meta, Google, and OpenAI.
13. **Microsoft** will provide legal protection for customers who are sued for copyright infringement over content generated using Copilot, Bing Chat, and other AI services as long as they use built-in guardrails.
14. **NVIDIA** beta released **TensorRT** \- an open-source library that accelerates and optimizes inference performance on the latest LLMs on NVIDIA Tensor Core GPUs.
15. Pulitzer Prize winning novelist Michael Chabon and several other writers sue OpenAI of copyright infringement..
16. **NVIDIA** partners with two of India’s largest conglomerates, Reliance Industries Limited and Tata Group, to create an AI computing infrastructure and platforms for developing AI solutions.
17. **Roblox** announced a new conversational AI assistant that let creators build virtual assets and write code with the help of generative AI.
18. **Google** researchers introduced **MADLAD-400** \- a 3T token multilingual, general web-domain, document-level text dataset spanning 419 Languages.
19. A recent survey by **Salesforce** show that 65% of generative AI users are Millennials or Gen Z, and 72% are employed.  The survey included 4,000+ people across the United States, UK, Australia, and India.
20. **Meta** is reportedly working on an AI model designed to compete with GPT-4.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
118,learnmachinelearning,openai,comments,2023-09-23 13:42:22,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.96,183,16q4ve6,https://www.reddit.com/r/learnmachinelearning/comments/16q4ve6/this_week_in_ai_all_the_major_ai_developments_in/,16,1695476542.0,"1. **Genmo** releases a new text-to-video model: **Genmo Replay** v0.1, which generates high-quality videos from text without the need for advanced prompt engineering. *Genmo is available for free to create AI videos* \[[*Details*](https://blog.genmo.ai/log/replay-ai-video) | [Genmo *Replay*](https://www.genmo.ai/)\] .
2. **OpenAI** unveils **DALL·E 3** \- a major update to the text-to-image model, which will be integrated in ChatGPT. It will be available to ChatGPT Plus and Enterprise users in October, via the API and in Labs later this fall. Creators can now also opt their images out from future training.
3. **Toyota Research Institute** has developed a technique, powered by generative AI, that enables teaching robots new manipulation abilities in a single afternoon. Using the same robot, same code, and same setup, TRI taught over 60 different dexterous behaviors like peeling vegetables, using hand mixers, preparing snacks, and flipping pancakes.
4. **Microsoft** announced:
   1. Availability of AI Copilot for Windows from September 26th. Copilot will incorporate the context and intelligence of the web, your work data and what you are doing in the moment on your PC to provide better assistance. It will be integrated in Windows 11, Microsoft 365, Edge and Bing.
   2. Bing will add support for DALL.E 3 and deliver more personalized answers based on search history.
   3. New AI powered experiences in Paint, Photos and Clipchamp.
   4. New AI-powered shopping experience
5. **ElevenLabs** released **Projects** \- a tool that lets you generate an entire audiobook at the click of a button. Projects now supports .epub, .pdf, and .txt file imports, as well as initializing a project from a URL.
6. **Deci** presents **DeciDiffusion 1.0** \- an open-source text-to-image latent diffusion model which is 3x faster than Stable Diffusion v1.5 with the same quality.
7. **Google researchers** present a new approach that produces photo-realistic animations from a single picture. The model is trained on automatically extracted motion trajectories from a large collection of real video sequences.
8. **Google** has updated Bard\*\]\*:
9. **Bard Extensions:** With extensions, Bard can now connect to your Google apps and services like Gmail, Docs, Drive, Google Maps, YouTube, and Google Flights and hotels.
10. Users can use Bard’s “Google it” button to more easily double-check its answers and evaluate whether there is content across the web to substantiate it.
11. Bard can now let you continue chat via **shared public links**
12. **YouTube** announces new AI tools for creators. **Dream Screen** will let users create an AI-generated video or image background from text. Automatic AI-dubbing tool called **Aloud**, which will be integrated into YouTube Studio. **AI-powered insights** to generate video ideas and draft outlines. **Assistive Search in Creator Music** where AI will suggest the right music based on your description of your content.
13. **Amazon** announced that its voice assistant Alexa is being upgraded with a new, custom-built large language model.
14. **IBM** open-sources **MoLM** \- a collection of ModuleFormer-based language models ranging in scale from 4 billion to 8 billion parameters. ModuleFormer is a new neural network architecture based on the Sparse Mixture of Experts (SMoE) by IBM researchers. .
15. **Neuralink**, Elon Musk's brain implant startup, set to begin human trials.
16. **Lexica** has released **Aperture v3.5** \- their latest next-gen image model that can create photorealistic images and follows your prompt with precision.
17. **OpenAI** has invited domain experts to collaborate in evaluating and improving the safety of OpenAI's models by joining the new **OpenAI Red Teaming Network**.
18. \*\*GitHub Copilot Chat (\*\*beta) is now available for all individuals.
19. **Replit** announced a virtual hackathon for projects built using **Replit ModelFarm**
20. **Oracle** brings voice-activated AI to healthcare with Clinical Digital Assistant.
21. **Google** and the Department of Defense are building an AI-powered microscope to help doctors spot cancer.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
119,learnmachinelearning,openai,comments,2020-07-30 10:03:42,Errors when using a DQN for the FrozenLake openai game,math7878,False,1.0,1,i0jfgg,https://www.reddit.com/r/learnmachinelearning/comments/i0jfgg/errors_when_using_a_dqn_for_the_frozenlake_openai/,16,1596103422.0,"Hey everyone, I am trying to make a DQN algorithm work for the FrozenLake-v0 game but am getting errors. I know that a DQN is probably an overkill but I would really like to get this to work. Here is the code:

    import gym
    import numpy as np
    import tensorflow as tf
    
    env = gym.make(""FrozenLake-v0"")
    
    n_actions = env.action_space.n
    input_dim = env.observation_space.n
    model = tf.keras.Sequential() 
    model.add(tf.keras.layers.Dense(64, input_dim = input_dim , activation = 'relu'))
    model.add(tf.keras.layers.Dense(32, activation = 'relu'))
    model.add(tf.keras.layers.Dense(n_actions, activation = 'linear'))
    model.compile(optimizer=tf.keras.optimizers.Adam(), loss = 'mse')
    
    def replay(replay_memory, minibatch_size=32):
        minibatch = np.random.choice(replay_memory, minibatch_size, replace=True)
        s_l =      np.array(list(map(lambda x: x['s'], minibatch)))
        a_l =      np.array(list(map(lambda x: x['a'], minibatch)))
        r_l =      np.array(list(map(lambda x: x['r'], minibatch)))
        sprime_l = np.array(list(map(lambda x: x['sprime'], minibatch)))
        done_l   = np.array(list(map(lambda x: x['done'], minibatch)))
        qvals_sprime_l = model.predict(sprime_l)
        target_f = model.predict(s_l) 
        for i,(s,a,r,qvals_sprime, done) in enumerate(zip(s_l,a_l,r_l,qvals_sprime_l, done_l)): 
            if not done:  target = r + gamma * np.max(qvals_sprime)
            else:         target = r
            target_f[i][a] = target
        model.fit(s_l,target_f, epochs=1, verbose=0)
        return model
    
    n_episodes = 500
    gamma = 0.99
    epsilon = 0.9
    minibatch_size = 32
    r_sums = []  
    replay_memory = []
    mem_max_size = 100000
    
    for n in range(n_episodes): 
        s = env.reset()
        done=False
        r_sum = 0
        print(s)
        while not done: 
            qvals_s = model.predict(s.reshape(16))
            if np.random.random() < epsilon:  a = env.action_space.sample()
            else:                             a = np.argmax(qvals_s); 
            sprime, r, done, info = env.step(a)
            r_sum += r 
            if len(replay_memory) > mem_max_size:
                replay_memory.pop(0)
            replay_memory.append({""s"":s,""a"":a,""r"":r,""sprime"":sprime,""done"":done})
            s=sprime
            model=replay(replay_memory, minibatch_size = minibatch_size)
        if epsilon > 0.1:      epsilon -= 0.001
        r_sums.append(r_sum)
        if n % 100 == 0: print(n)


And the errors I am getting are:

    Traceback (most recent call last):
      File ""froz_versuch.py"", line 48, in <module>
        qvals_s = model.predict(s.reshape(16))
    ValueError: cannot reshape array of size 1 into shape (16,)

And when I try to then change `qvals_s = model.predict(s.reshape(16))` to `qvals_s = model.predict(s.reshape(1))` I get the error:

    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 16 but received input with shape [None, 1]


I'd appreciate any help!"
120,learnmachinelearning,openai,comments,2018-04-27 07:22:52,"Karpathy says NNs should avoid regression problems (in favor of classification). Yet in Q-Learning, the function approximator is often an NN, even when the action space is discrete (and Q-Learning could be converted to a classification problem). Is CS231n correct?",Frozen_Turtle,False,1.0,45,8f9tes,https://www.reddit.com/r/learnmachinelearning/comments/8f9tes/karpathy_says_nns_should_avoid_regression/,16,1524813772.0,"From https://cs231n.github.io/neural-networks-2/ (emphasis mine):

>It is important to note that the L2 loss is much harder to optimize than a more stable loss such as Softmax. Intuitively, it requires a very fragile and specific property from the network to output exactly one correct value for each input (and its augmentations). Notice that this is not the case with Softmax, where the precise value of each score is less important: It only matters that their magnitudes are appropriate. Additionally, the L2 loss is less robust because outliers can introduce huge gradients. ***When faced with a regression problem, first consider if it is absolutely inadequate to quantize the output into bins.*** For example, if you are predicting star rating for a product, it might work much better to use 5 independent classifiers for ratings of 1-5 stars instead of a regression loss. Classification has the additional benefit that it can give you a distribution over the regression outputs, not just a single output with no indication of its confidence. If you’re certain that classification is not appropriate, use the L2 but be careful: For example, the L2 is more fragile and applying dropout in the network (especially in the layer right before the L2 loss) is not a great idea.

Outliers are not an issue in RL, which leaves only this:

>L2 loss is much harder to optimize than a more stable loss such as Softmax. Intuitively, it requires a very fragile and specific property from the network to output exactly one correct value for each input (and its augmentations).

I don't know what what the above means: What is a property? Why is it fragile? What is an augmentation? If you have any answers or know any links that discuss this issue, please let me know.

The typical Q-learning function approximator predicts (continuous) q-values, on which the agent acts ε greedy. In RL problems with discrete action spaces, is it wise to modify the Q-learning algorithm to directly predict actions instead of Q-values? Or should I stick with ε-maxing over ""unstable"" q-values? 

Anyway, even though regression may be less stable than classification, it seems to work anyway if we throw enough episodes at it :)

---

Post nap realization:

David Silver discusses 3 types of value function approximators [here](https://youtu.be/UoPei5o4fps?t=522):

1) Input is the state, output is the value function.

2) Input is the state and action, output is a q value.

3) Input is the state, output is the q value for every action.

All types could be interpreted as regression NNs. However, through a certain lens and also by using loose definitions, type 3 is a classification NN. When I speak about classification and regression NNs, here's what I have in mind:

* classification NNs typically have an output node for each class. The last layer's activation function is typically a softmax.

* regression NNs typically have one output node with no activation function, aka the linear activation function.

Value function approximators type 1 and 2 look like regression NNs. Type 3 looks kiiiiiinda like a classification NN. It has an output node for each action, and predicts q-values, which technically makes it a regression. But since the next step in the Q-learning algorithm is a ε greedy action, the *system* of the NN+ε greedy is choosing an action, this effectively makes it a classification style NN. It is classifying which action to take given the state.

Anyway, Silver says their DQNs use type 3 in solving the Atari problems, so I'll probably use that in my attempts to solve OpenAI's gyms. If anyone wants to criticize my realization here, please do so! I hardly consider this a closed issue.

---
---
---

# Links I've found discussing NN and regression problems

Many links seem to ignore or fail to mention the above advice from CS231n:

* https://www.reddit.com/r/learnmachinelearning/comments/7j2l4o/what_do_i_have_to_change_for_a_neural_network_to/

* https://www.quora.com/Can-Deep-Learning-and-Neural-Networks-be-useful-for-regression-problems-where-the-output-variable-has-an-unknown-or-varying-in-real-time-upper-bound

* https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/

* https://www.reddit.com/r/learnmachinelearning/comments/65sh1x/creating_a_deep_neural_network_regression_model/

* https://www.quora.com/Can-Deep-Learning-and-Neural-Networks-be-useful-for-regression-problems-where-the-output-variable-has-an-unknown-or-varying-in-real-time-upper-bound

In particular, the DQN implementations I've seen all predict Q-values and not actions (even if the action space is discrete), such as:

* https://jaromiru.com/2016/10/03/lets-make-a-dqn-implementation/

* https://github.com/dennybritz/reinforcement-learning/blob/master/DQN/Deep%20Q%20Learning%20Solution.ipynb"
121,learnmachinelearning,openai,comments,2023-03-20 18:42:54,[D] How do OpenAI and other companies manage to have real-time inference on model with billions of parameters over an API?,RaunchyAppleSauce,False,1.0,5,11wrdse,https://www.reddit.com/r/learnmachinelearning/comments/11wrdse/d_how_do_openai_and_other_companies_manage_to/,16,1679337774.0,"Hi, guys

I have been using OpenAI’s chatgpt through the app Poe and I find it very confusing how a model with billions of parameters is responding in real-time over an API.

How does one go about making inference fast, say 15-20ms, over an API for large models?

Thanks!"
122,learnmachinelearning,openai,comments,2019-08-11 14:32:04,`gpt2-client`: A New Wrapper for GPT-2,rish-16,False,1.0,4,coxeko,https://www.reddit.com/r/learnmachinelearning/comments/coxeko/gpt2client_a_new_wrapper_for_gpt2/,16,1565533924.0,"Hey everyone 👋🏻

I recently built a wrapper for OpenAI's \`gpt-2\` model called \`gpt2-client\`. Currently, the \`gpt-2\` repo is archived and the code is messy and riddled with bugs. My wrapper simplifies the entire process by enabling anyone to get started with text generation models without the fuss.

&#x200B;

[This is how it looks like](https://preview.redd.it/ookaj95lytf31.png?width=1584&format=png&auto=webp&s=efaea7da8edc03136c627223a2d71ff6a4ef0c73)

Please do go check it out here:

[https://github.com/rish-16/gpt2client](https://github.com/rish-16/gpt2client)

If you like it, a ⭐️ on GitHub would be highly appreciated! It's my first ever Python module I've released and am really excited about it.

If you run into any bugs, please do file an issue and if you have any suggestions or enhancements, please do file a PR with a short description of your awesome improvement.

Cheers!"
123,learnmachinelearning,openai,comments,2023-03-28 12:51:54,I am creating a tool that uses OpenAI models and an OCR to translate screenshots,K-RT-DEV,False,0.88,39,124nsy8,https://www.reddit.com/r/learnmachinelearning/comments/124nsy8/i_am_creating_a_tool_that_uses_openai_models_and/,15,1680007914.0,"Currently, the OCR is specifically for translating from Japanese, but I plan to add a range of OCRs and different translators to the system to accommodate the user's needs.  


https://i.redd.it/8ymk99uf8hqa1.gif

My idea is to have a system that leverages OpenAI models for *bagging*. This way, I can combine the output of multiple OCRs  to increase the accuracy of the recognized characters. Similarly, I can combine the output of multiple translators for the same phrase to improve the final result . Chat models can be particularly useful in providing **context** and a translation history to help the system understand how to conjugate phrases for translation.   


You can find the source code and an executable version on the [project's GitHub](https://github.com/K-RT-Dev/VGT)"
124,learnmachinelearning,openai,comments,2019-05-16 23:01:12,Learning Machine Learning Resources,rhklite,False,0.99,248,bpjh2a,https://www.reddit.com/r/learnmachinelearning/comments/bpjh2a/learning_machine_learning_resources/,14,1558047672.0,"I collected a bunch of machine learning resources for my self studying, thought I'd share it here, could be of use to other people.

&#x200B;

* ★ are resources that were highly recommended by others
* **tags:**    `course` ,   `book` ,   `git-repo` ,   `blog-post` ,   `video` ,   `cheat-sheet` ,   `list`

## Machine Learning

* [Coursera Machine Learning, Andrew Ng](https://www.coursera.org/learn/machine-learning)   `introductory course`  ★
* [Introduction to Computational Thinking and Data Science](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/)   `introductory course`
* [Machine Learning MIT Open Courseware](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/)   `course`
* [Amazon AWS Machine Learning Course](https://aws.amazon.com/training/learning-paths/machine-learning/)   `course`
* [Virgilio - Mentor for Data Science E-Learning](https://github.com/virgili0/Virgilio)   `course`

&#x200B;

* [Machine Learning Yearning - Andrew Ng](https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf)   `book`   ★
* [Mathmatics for Machine Learning, Marc Peter Deisenroth](https://mml-book.github.io/)   `book`
* [The Hundred-page Machine Learning Book, Andriy Burkov](http://themlbook.com/wiki/doku.php)   `book`
* [Model Based Machine Learning](http://mbmlbook.com/toc.html)  `book`
* [Coursera Machine Learning - Python Code, JWarmenhoven](https://github.com/JWarmenhoven/Coursera-Machine-Learning)   `git-repo`
* [Coursera Machine Learning - Python Code, kaleko](https://github.com/kaleko/CourseraML)   `git-repo`
* [Coursera Machine Learning - Python Code, dibgerge](https://github.com/dibgerge/ml-coursera-python-assignments)   `git-repo`
* [Machine Learning Git Codebook](https://www.reddit.com/r/learnmachinelearning/comments/ax6ep5/machine_learning_git_codebook_case_study_of/?utm_medium=android_app&utm_source=share)  `git-repo`

&#x200B;

* [A Complete Machine Learning Project Walk-Through in Python](https://morioh.com/p/b56ae6b04ffc/a-complete-machine-learning-project-walk-through-in-python)  `blog-post`
* [What's the best ML Paper you read in 2018?](https://www.reddit.com/r/MachineLearning/comments/a6cbzm/d_what_is_the_best_ml_paper_you_read_in_2018_and/)   `blog-post`
* [Seeing Theory](https://seeing-theory.brown.edu/basic-probability/index.html)   `blog-post`
* [The most complete chart of Neural Networks, explained](https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464)   `blog-post`
* [The Machine Learning cheat-sheet](https://github.com/remicnrd/ml_cheatsheet)   `cheatsheet`

## Deep Learning

* [Fast.ai Online Course](https://www.fast.ai/)  `course`  ★
* [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/2017/)   `course` ★
* [CS230: Deep Learning](https://cs230.stanford.edu/)   `course`
* [Google Machine Learning Crash Course with TensorFlow APIs](https://developers.google.com/machine-learning/crash-course/)   `course`
* [MIT Deep Learning](https://www.youtube.com/watch?v=O5xeyoRL95U&list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf)   `course`
* [Deep Learning - An MIT Press Book, Ian Goodfellow](http://www.deeplearningbook.org/)   `book` ★

&#x200B;

* [TensorFlow.js - Real-Time Objection Detection in 10 Lines of Code](https://hackernoon.com/tensorflow-js-real-time-object-detection-in-10-lines-of-code-baf15dfb95b2)  `blog-post`

&#x200B;

* [Build a TensorFlow Image Classifier in 5 Min](https://www.youtube.com/watch?v=QfNvhPx5Px8)   `video`

&#x200B;

* [Deep Learning cheat-sheets covering Stanford's CS 230 Class](https://stanford.edu/~shervine/teaching/cs-230/)   `cheat-sheet`
* [cheat-sheets for AI, Neural Nets, ML, Deep Learning & Data Science](https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-science-pdf-f22dc900d2d7)   `cheat-sheet`
* [Tensorflow-Cookbook](https://github.com/taki0112/Tensorflow-Cookbook)   `cheat-sheet`

&#x200B;

* [Deep Learning Papers Reading Roadmap](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap)   `list`  ★
* [Papers with Code](https://paperswithcode.com/sota)  `list`  ★

## Reinforcement Learning

* [CS294-112 Deep Reinforcement Learning](http://rail.eecs.berkeley.edu/deeprlcourse/)   `course`
* [CMPUT 609 Reinforcement Learning - Rich Sutton](https://drive.google.com/drive/folders/0B-WvrETGtkesN29sV1g3aXZ1Z0U)   `course`
* [Deep RL Bootcamp](https://www.youtube.com/watch?v=qaMdN6LS9rA&list=PLPfj7W0fIrmy3MfjPFbpy7jFGDmvspgHE)   `course`
* [Reinforcement Learning Crash Course](https://www.youtube.com/watch?v=sOiNMW8k4T0)   `course`

&#x200B;

* [Reinforcement Learning: An Introduction Richard, S.Sutton 2ndED 2018](http://incompleteideas.net/book/the-book-2nd.html)   `book`  ★

&#x200B;

* [Open AI Spinning Up](https://spinningup.openai.com/en/latest/index.html)   `github repo` ★
* [OpenAI - Gym](https://github.com/openai/gym/wiki)  `git-repo`
* [Stable Baseline: a Fork of OpenAI Baselines - Reinforcement Learning Made Easy](https://stable-baselines.readthedocs.io/en/master/)   `git-repo`
* [PyGame Learning Environment](https://pygame-learning-environment.readthedocs.io/en/latest/)   `git-repo`
* [S-RL Toolbox](https://s-rl-toolbox.readthedocs.io/en/latest/guide/rl.html)   `git-repo`

&#x200B;

* [Google AI Blog](https://ai.googleblog.com/2019/02/long-range-robotic-navigation-via.html?fbclid=IwAR2p5UBtLyXG1Dru5-zW_lnnZF3u3T03U3XF7_2jqBZY6h3ijeIzqmYuEpI)   `blog-post`  ★
* [An introduction to Q-Learning: Reinforcement Learning](https://medium.freecodecamp.org/an-introduction-to-q-learning-reinforcement-learning-14ac0b4493cc)   `blog-post`
* [Introduction: Reinforcement Learning with Open AI Gym](https://towardsdatascience.com/reinforcement-learning-with-openai-d445c2c687d2)   `blog-post`
* [An intro to Advantage Actor Critic methods](https://medium.freecodecamp.org/an-intro-to-advantage-actor-critic-methods-lets-play-sonic-the-hedgehog-86d6240171d)   `blog-post`
* [Double Q-Learning, the Easy Way](https://towardsdatascience.com/double-q-learning-the-easy-way-a924c4085ec3?fbclid=IwAR17Ht_oyJL4_1AHTqcwf1EU1RziGgRrwTskKY1xRlpLLd3T7_NKMK_V6-g)   `blog-post`
* [A Beginner's Guide to Reinforcement Learning](https://skymind.ai/wiki/deep-reinforcement-learning)   `blog-post`
* [Papaers that criticize Deep Reinforcement Learning](https://www.reddit.com/r/MachineLearning/comments/bdgxin/d_any_papers_that_criticize_deep_reinforcement/)   `blog-post`

## Artificial Intelligence

* [Techniques in Artificial Intelligence (SMA 5504) MIT Open Courseware](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-825-techniques-in-artificial-intelligence-sma-5504-fall-2002/index.htm)  `course`
* [CS 188 - Introduction to Artificial Intelligence - UC Berkeley](https://inst.eecs.berkeley.edu/~cs188/fa18/)  `course`
* [Artifical Intelligence: Foundataions of Computational Agents, 2ndED 2017](https://artint.info/2e/html/ArtInt2e.html)   `book`

## Others

* [Awesome public datasets](https://github.com/awesomedata/awesome-public-datasets)   `list`
* [100+ Basic Machine Learning Interview Questions and Answers](http://theprofessionalspoint.blogspot.com/2019/01/100-basic-machine-learning-interview.html)   `blog-post`"
125,learnmachinelearning,openai,comments,2023-06-26 12:23:07,"Best way to cost effectively ""upload"" a large PDF to a language model so that you can ask questions about it?",RepresentativeNet509,False,1.0,8,14jfvq8,https://www.reddit.com/r/learnmachinelearning/comments/14jfvq8/best_way_to_cost_effectively_upload_a_large_pdf/,13,1687782187.0," I have a 400 page PDF and need to get it into a language model (cost effectively) and then be able to ask the model questions about the document like ""on what page does the scope summary begin"" or ""are there any prohibitions to participate in this solicitation due to the size of respondent's business"".

I have been able to use ""Ask My PDF"" to upload part of the PDF to ChatGPT and this basically gives the outcome I want for the pages that are uploaded, but it invariably crashes every time and there is no way to pick up where the uploading of pages left off.

I am fairly technical; would NanoGPT be a better solution for this? I am also looking at fine-tuning a model on OpenAI's API, but that seems cumbersome and expensive for my use case.

Any thoughts are appreciated!"
126,learnmachinelearning,openai,comments,2023-05-18 13:36:49,Few shot learning to make gpt4 dumb,mr_dark_matter,False,0.43,0,13kzfxk,https://www.reddit.com/r/learnmachinelearning/comments/13kzfxk/few_shot_learning_to_make_gpt4_dumb/,13,1684417009.0,"If  gpt4 can be made to learn things by zero/few shot learning, is it not  vulnerable to exploits to make it dumb? Few shot learning to make it do  incorrect things. Done this at scale over distributed accounts, gpt4  will become dumb.

Is this really possible? If true, what is OpenAI doing to mitigate this?"
127,learnmachinelearning,openai,comments,2023-12-28 19:48:58,Where do you find people you can constantly bother about technical issues.,uforanch,False,0.93,24,18t2qe0,https://www.reddit.com/r/learnmachinelearning/comments/18t2qe0/where_do_you_find_people_you_can_constantly/,13,1703792938.0,"Alright. I'm a former math academic. I've taken courses online for Deep Learning and NLP. I get the gist of it, generally. I know the math, I know what's happening, etc. I am currently trying to get to something original by making models from books and keras's site and then adapting them to other things. 

I'm running into a lot of weird issues.  Too many to get into here. Like my model will get the opposite results of the book, or won't predict on input it's supposed to, there's warnings being raised every command, etc. 

I've been to code meetups and have some software oriented friends. I generally don't find a lot of people into AI who aren't super busy and have time to just answer questions of ""How am I getting this error"". Most people don't even really want to do much besides send prompts to an openAI API, whereas I want to showcase I can build and use these models. 

Where do you find someone who can actually help or answer questions. Is there a notable discord or some space where I'm more likely to meet someone who can answer questions? 

&#x200B;"
128,learnmachinelearning,openai,comments,2023-08-21 07:54:44,Steps to get into AI Development,_Powski_,False,0.5,0,15x0vti,https://www.reddit.com/r/learnmachinelearning/comments/15x0vti/steps_to_get_into_ai_development/,13,1692604484.0,"Hello.  
In my free time i want to dive a little into ai development. I have not much time, but a few hours during the week and few more on the weekend to learn. I am pretty good with c#, know some dart, java and scala.  
I have an idea for an app that is in my mind for a long time now. And now with the raise of AI it could be possible to build. I know that it will take me a long time but as a hobby project i would like to tackle that.   
*A similar question could have been already asked here but because i am new in this field i don't really know how the answer to my problem would look like.*

&#x200B;

Problem? I don't know where to start with learning AI Development. I could just google and start with some courses or tutorials but i dont want to spend weeks on learning something that wasn't even needed for the thing i want to do, but i wasn't understanding it so i didn't know.  


Can someone tell me what would be the best way to start and what exact thing i need to learn. ( I know how to build apps, just the ai part is missing for me)  


What i want to achieve:   
1. Users can upload short texts in the app(1000 words).  
2. Other users can choose texts and then ask questions about the text.  
3. Only information related to the chosen text is given. No need for the app to know anything else.   


Now i know that it would be possible to somehow work with the openAI API and somehow solve the problem with that. But would that be the best solution? Would it be possible even somehow without an internet connection just on the users device? Let the app learn the text and answer questions about that with a local LLM? 

So please can you give me a small guide where to start learning. Please also keep in mind that its only a hobby project for me and that i only want to learn the things i actually need for that."
129,learnmachinelearning,openai,comments,2022-10-19 09:27:38,Fixing YouTube Search with OpenAI's Whisper,jamescalam,False,0.95,78,y7xxri,https://www.reddit.com/r/learnmachinelearning/comments/y7xxri/fixing_youtube_search_with_openais_whisper/,13,1666171658.0,"Hi all, I wanted to [build a ""YouTube search"" app](https://www.pinecone.io/learn/openai-whisper/) for some time. Not the typical YouTube search where you return videos, but a YouTube search that returns the specific part of a video that answers your question. With text-based data this is pretty easy, but video/audio is less so.

That was until OpenAI (open sourced?) Whisper, a new SotA for speech-to-text. So I went ahead and built [""Ask YouTube""](https://huggingface.co/spaces/jamescalam/ask-youtube). A little search bar where you can ask technical questions and get the exact most relevant part from a set of videos (for now, the video scope is limited, I'll add more soon).

I explained everything I did to build it in [the linked article](https://pinecone.io/learn/openai-whisper/) and [video](https://youtu.be/vpU_6x3jowg). You could also just grab the app code and replicate it, I don't think it would take long. At a high level it is:

* Download YouTube audio with `pytube`
* Transcribe with OpenAI's Whisper
* Do some data prep
* Encode using Hugging Face / sentence-transformers
* Index and query with Pinecone vector DB

Then I wrapped all of this into a quick Streamlit web app and hosted it all for free on Hugging Face Spaces. One somewhat surprising thing here is absolutely everything was either open source or free, I didn't pay a dime!

Anyway, I hope this is interesting. Let me know what you think!"
130,learnmachinelearning,openai,comments,2022-04-13 16:27:40,Is there a way for neural network to mimic the way the brain stores memory?,x_m_n,False,1.0,2,u2u8l5,https://www.reddit.com/r/learnmachinelearning/comments/u2u8l5/is_there_a_way_for_neural_network_to_mimic_the/,13,1649867260.0,"Dislaimer: I'm a novice at both brain anatomy and neural network so please pardon any misunderstandings I have.

&#x200B;

From what I understand, the brain stores memory via connections between neurons. All the types of memory (scent, touch, feel, taste, vision, etc...) are just a certain set of neurons firing together. The more the memory is repeated/reinforced, the stronger the connections between those neurons, and they're more likely to be recalled (in tact). The more something is done, the more strengthen its neural pathways and eventually it becomes the equivalent of hardware accelerated process where you don't need to ""process"" and just do it.

Versus a computer/neural network stores memory in ... dedicated memory units. Variables, with data types. The connections between the neurons are for processing, not for storing memory.

Is there a way/neural network model that mimics the way the brain stores memory?

Also, just like how the brain have different regions that does different tasks, like the hippocampus stores memory, the left/right side of the brain does rationale/artistic, the frontal lobe does impulse control/decision making, the brain stem controls the limbs, olfactory recognizes smell, etc... is there certain neural network models that specialize in those tasks specifically? Or it just depends on which data set the neural network is trained on?

Are most of the neural network in use/research at the moment just a really expansive bunch of nodes with a bunch of inputs without any specialized areas? Or the specialized areas are activated based on which input is fed in? There's that neural network by OpenAI that does a bunch of things because it has tons of input nodes (again, can't remember the name. my hippocampus needs a jolt).

Just need some help conceptualize them all.

Thank you."
131,learnmachinelearning,openai,comments,2022-12-12 19:17:50,"A web application tool for improving your written communication features paraphrasing, grammar checking, and text summarizing tool built with OpenAI API.",Austin_Nguyen_2k,False,0.94,27,zk8gr7,https://v.redd.it/95jm43veoi5a1,12,1670872670.0,
132,learnmachinelearning,openai,comments,2021-09-19 07:59:15,AI research papers explainer channel.,gauravc2796,False,0.84,77,pr3sc7,https://www.reddit.com/r/learnmachinelearning/comments/pr3sc7/ai_research_papers_explainer_channel/,12,1632038355.0,"Hi, I have started a youtube channel where I would provide some explainer on the latest AI research papers as I have happened to read a lot of them.  
If you have any suggestions, comments, or anything, do let me know.   
Your opinion would be highly valuable :)  
Channel: [https://www.youtube.com/channel/UCYEXrPn4gP9RbaSzZvxX6MA](https://www.youtube.com/channel/UCYEXrPn4gP9RbaSzZvxX6MA)  


Some Videos which have been created till now:

Textless NLP: [https://www.youtube.com/watch?v=zw\_QjUptr5o](https://www.youtube.com/watch?v=zw_QjUptr5o)  
Neural DB: [https://www.youtube.com/watch?v=Vo9L0LETMI4](https://www.youtube.com/watch?v=Vo9L0LETMI4)  
Perceiver IO: [https://www.youtube.com/watch?v=AS1Sh-KuNzs](https://www.youtube.com/watch?v=AS1Sh-KuNzs)  
Openai's GPT codex: [https://www.youtube.com/watch?v=8977dybJ7Ro](https://www.youtube.com/watch?v=8977dybJ7Ro)"
133,learnmachinelearning,openai,comments,2023-12-16 15:26:30,Is there any alternative for OpenAI API?,CrazyProgramm,False,0.83,8,18jti72,https://www.reddit.com/r/learnmachinelearning/comments/18jti72/is_there_any_alternative_for_openai_api/,12,1702740390.0, So I am from Sri Lanka and our university is going to organize a competition and we need OpenAI API for it but we don't have money to afford it. Is there any alternative API you guys know 
134,learnmachinelearning,openai,comments,2023-02-20 15:42:13,"ChatGPT Response about the vinyl chloride spill in East Palestine, Ohio.",listenandlearn2,False,0.22,0,117adwo,https://www.reddit.com/r/learnmachinelearning/comments/117adwo/chatgpt_response_about_the_vinyl_chloride_spill/,12,1676907733.0," ChatGPT responded my prompt.  I'd love to hear your thoughts:

Vinyl Chloride spilled in East Palestine, Ohio about 300 miles away from Cincinnati. The chemical leaked into the Ohio River. How long will it take for the chemical to reach the water supply of Cincinnati which is also on the Ohio River?

The time it will take for Vinyl Chloride to reach Cincinnati's water supply from the spill site in East Palestine, Ohio will depend on several factors such as the amount of Vinyl Chloride spilled, the concentration of the chemical in the river, the flow rate of the river, and any barriers or dams along the river that may affect the movement of the chemical.

Assuming there are no significant barriers or dams along the river, the average flow rate of the Ohio River is approximately 1.5 miles per hour. Therefore, if the spill occurred in East Palestine, Ohio, which is 300 miles upstream from Cincinnati, it could take up to 200 hours (300 miles / 1.5 miles per hour) for the Vinyl Chloride to reach Cincinnati's water supply.

However, it is important to note that the actual time for the chemical to reach Cincinnati's water supply could be longer or shorter depending on the specific conditions of the spill and the river. It's also possible that officials may take steps to prevent the chemical from reaching the water supply, such as by diverting the river or shutting off water intake valves, in order to protect public health and safety.

📷📷Please timestamp this response

This response was generated on 2023-02-20.

📷📷Can you add the time the response was generated

Certainly! This response was generated at 2023-02-20 04:28:00 UTC.

Regenerate response[ChatGPT Feb 13 Version](https://help.openai.com/en/articles/6825453-chatgpt-release-notes). Free Research Preview. Our goal is to make AI systems more natural and safe to interact with. Your feedback will help us improve."
135,learnmachinelearning,openai,comments,2023-11-22 19:05:16,Made some promises. Now I'm desperately trying to figure out how to conduct very large scale pdf doc analysis.,-rampant,False,0.94,15,181gxg0,https://www.reddit.com/r/learnmachinelearning/comments/181gxg0/made_some_promises_now_im_desperately_trying_to/,11,1700679916.0,"I have about a half million pdfs I need to summarize. Very wide range of types: invoices, diagrams, contracts, emails, letters, pictures, schedules, notices, data sheets, manuals, more. 

Which is... woof. Something else. I've been trying for many hours now to figure out a service/combination thereof that can get me there, but I'm seriously struggling. The *ideal* solution would be to throw the pdfs in and have it return a csv with dates and summaries, maybe parsed out email heading info.

I'm currently running these pdfs through Acrobat OCR now, which its own special hell.

I've tried myriad local and webhosted solutions. The BEST results in what is almost the perfect system for this I found on https://docalysis.com/. Good text results, works in batches, BUT I can only upload a single document at a time. They have a service to do batch processing and so I'm waiting to hear from them now. I imagine at the scale I need it's expensive.

I also got this solution working: https://github.com/mayooear/gpt4-pdf-chatbot-langchain. Seemed solid, I was able to upload a thousand pdfs in a single go, but it would keep returning information from only 2-3 documents. Upload 5? Results for 2-3. Upload a thousand? Results for 2-3. My uneducated guess is that it's hitting the OpenAI API token limit, but maybe not?

I know it's possible, just not whether it's feasible for an end user. Does anyone know a solution to accomplish this?"
136,learnmachinelearning,openai,comments,2023-09-28 15:50:53,Work asked me to tell them which PC to buy for me - Suggestions? plshelp,sim0of,False,0.95,19,16ujluo,https://www.reddit.com/r/learnmachinelearning/comments/16ujluo/work_asked_me_to_tell_them_which_pc_to_buy_for_me/,11,1695916253.0,"Hello everyone,

I have been working as a junior developer in this company for some months now

I have been using my own Acer Nitro 5 17"" (i7 11800h, RTX 3060 Laptop 6GB, 16GB Ram)

So far I've been involved in projects with computer vision, audio and nlp

This is an entirely new branch for the company and I'm still a student at the beginning of my journey, therefore there is no ""standard modus operandi"" for doing things and basically I'm the one responsible for telling them what piece of hardware is best for my needs

Anything that involves training we just rent GPUs from the major providers so I'm definitely not worrying about that

Things I will definitely be working on

\- OpenAI API integration  
\- NVIDIA NeMo framework  
\- YOLO  
\- Langchain, elastic and similars

&#x200B;

Since I've been busy studying and learning stuff I've never really bothered looking into hardware requirements for any of the things I've done/will do

Does the hardware choice matter in this case?  


They proposed me a laptop with i7 12th gen, 16GB Ram, and RTX4050 which costs 1k euros

I told them to hold off and that I would have done some further research because that doesn't look like a solid investment in my opinion

&#x200B;

**What (I think) I know:**

Budget I assume is something in the 1k - 2k range but they really just care about giving me something that allows me to provide good results

\- Pretty much when running models locally for testing and developing, they will run on a GPU, which I assume has to be powerful. But how powerful is powerful enough? 4060? 4080? 4090? Do mobile CPUs even make sense?  
\- I notices some dockerized services take up a fair bit of my current CPU, so is it coherent to assume that a more recent CPU with more cores and pretty much more power would be beneficial for my work?  
\- 16GB Ram nowadays is barely enough for google chrome with a few extensions so I don't really have any doubts that going for 32GB is a reasonable enough upgrade  
\- I work both at home, at the office and around the world when I'm in WFH mode, so a laptop would seem a better option than a Desktop PC, but is that actually the case?  


**What I don't know**

Aside from the fact that this section worringly overlaps with the ""what I know section""..  
I've only considered Windows laptops onto which I would at the very least make dual boot with linux if not exclusively linux because the NVIDIA NeMo framework can't run on windows

Given what I will do, should I even consider Apple? Like a Macbook Pro M1 or something like that?

  
I already have high end desktop pc at home and my current laptop is already something I'm comfortable bringing around, but one big limitation is that I always need to be plugged into a power source or the battery drains withing one hour of work  
AFAIK a macbook pro would kinda allow me to work anywhere so that'd be a cool quality of life upgrade but I doubt it's practically worth anything other than a ""cool!"" reaction

&#x200B;

As you can see there's a lot of stuff I don't know and I don't really know what I actually need

Thank you so much for any help and suggestion towards the right direction!  
"
137,learnmachinelearning,openai,comments,2019-08-27 14:19:56,[D] What do you use to keep you update on ML/DL?,pirate7777777,False,0.99,212,cw542g,https://www.reddit.com/r/learnmachinelearning/comments/cw542g/d_what_do_you_use_to_keep_you_update_on_mldl/,11,1566915596.0,"Hi everyone! What do you use to navigate-in-the-noise and keep you update in this field? *Excluding this subreddit* which type of resources do you recommend to check regularly?

&#x200B;

Here's my list:

***Newsletters (weekly)***:

\- [ImportAI (@JackClark)](https://jack-clark.net/)

\- [The batch (@Deeplearning.ai)](https://www.deeplearning.ai/thebatch/)

&#x200B;

**Podcast & Video (weekly/monthly)**

\- [Artificial Intelligence Podcast (@Lex Fridman)](https://lexfridman.com/ai/)

\- [Two Minute papers](https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg)

&#x200B;

**Blogs (RSS newsfeed)**

\- [DeepMind](https://deepmind.com/blog)

\- [OpenAI](https://openai.com/blog/)

\- [BAIR](https://bair.berkeley.edu/blog/)

\- [Google AI](https://ai.googleblog.com/)

\- [FAIR](https://research.fb.com/category/facebook-ai-research/)

&#x200B;

**MOOCs (once per year)**

\- [Deep learning for coders p1 & p2 (@fast.ai)](https://course.fast.ai/)

\- [CS231n: DL for CV](http://cs231n.stanford.edu/)

\- [CS224d: DL for NLP](https://cs224d.stanford.edu/)

&#x200B;

**Social (once per day/week)**

\- Twitter & LinkedIn are good quite good sometimes, but too noisy.

\- Facebook groups (such as [AIDL](https://www.facebook.com/groups/DeepNetGroup/)) but most of the time, the articles shared are not really good or particularly useful.

&#x200B;

**Conferences / Events (once per year)**

\- [NIPS](https://nips.cc/)

\- [PyTorch Dev Conference](https://pytorch.fbreg.com/)

\- [TF Dev Summit](https://www.tensorflow.org/dev-summit)"
138,learnmachinelearning,openai,comments,2019-02-21 06:49:57,Why is openai's recent post being criticised?,timedacorn369,False,0.78,5,at00up,https://www.reddit.com/r/learnmachinelearning/comments/at00up/why_is_openais_recent_post_being_criticised/,10,1550731797.0,Openai recently made a blog post saying they developed a model which can generate fake news  and decided not to release it because it can be used for malicious purposes. Why is this decision being ridiculed in the machine learning community? 
139,learnmachinelearning,openai,comments,2023-05-19 07:08:51,OpenAI Launches ChatGPT App For iOS Users,vadhavaniyafaijan,False,0.87,53,13lnv1e,https://www.theinsaneapp.com/2023/05/chatgpt-app-for-iphone-and-ipad.html,10,1684480131.0,
140,learnmachinelearning,openai,comments,2023-06-19 16:38:37,I wanted to use OpenAI API but it's a paid service. What are alternatives for this?,Beginning-Scholar105,False,0.58,2,14djjsj,https://www.reddit.com/r/learnmachinelearning/comments/14djjsj/i_wanted_to_use_openai_api_but_its_a_paid_service/,10,1687192717.0,I have tried some Open Source Hugging Face LLMs but they are very large in size and also need heavy machine to run those LLMs.  If you know any other alternatives then please let me know.
141,learnmachinelearning,openai,comments,2023-10-10 13:31:04,Explained Simply: OpenAI's breakthrough paper about defeating Dota2 world champions!,mngrwl,False,0.31,0,174lahd,https://mngrwl.medium.com/explained-simply-how-a-i-defeated-world-champions-in-the-game-of-dota-2-f3df90d38a70,9,1696944664.0,
142,learnmachinelearning,openai,comments,2019-02-23 10:25:23,Best way to label data for object detection,Carvalho96,False,1.0,6,atu3s1,https://www.reddit.com/r/learnmachinelearning/comments/atu3s1/best_way_to_label_data_for_object_detection/,9,1550917523.0,"Good day,

  
So I've got roughly 5k images (4k train, 1k test) for an object detection problem I'm working with, and was wondering if hand drawing bounding boxes for each of the objects for each of the images is really the only way to go about labeling the data? Is this really the way folks at Google, Facebook, Deepmind and OpenAI go about training their models?  


If there is any better way, or a standard ""best practice"" tool to be used for this task, please let me know?

&#x200B;

Thanks!"
143,learnmachinelearning,openai,comments,2023-07-07 01:56:23,ML for DIY House Design,No-Dare-7624,False,0.83,17,14st4q5,https://www.reddit.com/r/learnmachinelearning/comments/14st4q5/ml_for_diy_house_design/,9,1688694983.0,"https://reddit.com/link/14st4q5/video/afhad8qnagab1/player

As an architect and computational designer, I've recently ventured into the exciting world of Machine Learning (ML) to bring an innovative touch to DIY house designs. My project, based in Grasshopper, integrates ML in the architectural process to predict the optimal wall/window configurations for desired temperature settings in diverse scenarios.

Starting with a modest dataset (2000 rooms), I developed a stacked ML model, part of a larger project, aiming to democratize house design by aiding DIY enthusiasts. My workflow was all about getting the model running first, even with limited data, and refining it as I gained more understanding and expanded the dataset, which is self-supervised. I'm using Ladybug a grasshopper plugin that it is the way to go for enviromental analysis, so I can generate new data on demand but it takes time to compute.

The most challenging part was predicting optimal configurations when all wall options were not available. I addressed this by merging outputs from the second (predict optimal configuration) and third neural (predict best configuration with aviable walls) networks, assigning more weight to the latter.

With the assistance of OpenAI's GPT-4, especially for Python, I am now focused on generating five times more data and scrutinizing model performance through metrics such as R-squared (0.8144), MSE(0.003), and MAE(0.0454). The best model so far is using Backpropagation and Sigmoid.

As an architect turned ML enthusiast, there's been a steep learning curve, but the journey has been rewarding. I'm keen to hear suggestions, particularly any rules of thumb from seasoned data scientists that could be missing from my toolkit. Looking forward to enriching this exciting intersection of architecture and ML!

Here is a small video of the first attempt of the first neural network that its just predict the solar radation.

[https://www.instagram.com/reel/CuPwUVNArTv/?utm\_source=ig\_web\_copy\_link&igshid=MzRlODBiNWFlZA==](https://www.instagram.com/reel/CuPwUVNArTv/?utm_source=ig_web_copy_link&igshid=MzRlODBiNWFlZA==)"
144,learnmachinelearning,openai,comments,2024-01-04 21:15:12,Natural Language Processing (NLP) Learning Path - In depth,millhouse056,False,0.96,45,18yo5kp,https://www.reddit.com/r/learnmachinelearning/comments/18yo5kp/natural_language_processing_nlp_learning_path_in/,9,1704402912.0,"Hi friends, i'm currently engaged in NLP and created an pretty extense roadmap or learning path so begginers don't feel lost, it covers from the basics to advanced cutting-edge concepts.

Feedback is appreciated.

&#x200B;

\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-

&#x200B;

NLP Learning Roadmap

1. Prerequisites:

&#x200B;

* Mathematics:

&#x200B;

* Linear algebra
* Probability and statistics

&#x200B;

* Programming:

&#x200B;

* Proficiency in a programming language (e.g., Python)

**2. Introduction to NLP:**

&#x200B;

* Definition      and scope of NLP
* Historical      development of NLP
* Key challenges      and applications

**3. Text Analysis:**

&#x200B;

* **Lexical Analysis:**

&#x200B;

* Word meaning and structure

· Morphology (word formation)

· lemmatization (base form identification)

&#x200B;

* **Syntactic Analysis:**

· Parts-of-speech tagging

· Dependency parsing

· Constituency parsing

&#x200B;

* **Semantic Analysis:**

· Extracting meaning

· Encompassing word embedding models like Word2Vec and GloVe

· Topic modeling

&#x200B;

* **Semantic Analysis:**

· Coreference resolution

· Discourse analysis

&#x200B;

**3. Text Processing:**

&#x200B;

* **Tokenization:**

&#x200B;

* Sentence tokenization
* Word tokenization
* Subword tokenization (Byte Pair Encoding, SentencePiece)

&#x200B;

* **Stop Words Removal:**

&#x200B;

* Importance and impact on NLP tasks
* Customizing stop word lists

&#x200B;

* **Stemming and Lemmatization:**

&#x200B;

* Porter stemming algorithm
* Snowball stemming algorithm
* Lemmatization techniques and challenges

&#x200B;

* **Part-of-Speech Tagging:**

 

* POS tagging algorithms (HMM-based, rule-based, and neural-based)
* Fine-grained POS tagging

**4. Text Representation:**

&#x200B;

* **Bag of Words (BoW):**

 

* Term Frequency (TF) and Inverse Document Frequency (IDF)
* Bag of N-grams

&#x200B;

* **TF-IDF:**

 

* Calculating TF-IDF scores
* Applications in information retrieval

&#x200B;

* **Word Embeddings:**

 

* Word2Vec:

&#x200B;

* Continuous Bag of Words (CBOW) model
* Skip-gram model
* GloVe (Global Vectors for Word Representation)

&#x200B;

* **Contextual Embeddings:**

 

* ELMo (Embeddings from Language Models)
* ULMFiT (Universal Language Model Fine-tuning)
* OpenAI GPT (Generative Pre-trained Transformer)

**5. NLP Libraries and Tools:**

&#x200B;

* NLTK      (Natural Language Toolkit)
* SpaCy
* scikit-learn
* Transformers      library (Hugging Face)

**6. Statistical Language Models:**

&#x200B;

* **N-grams:**

 

* Unigrams, bigrams, and trigrams
* N-gram language models

&#x200B;

* **Hidden Markov Models (HMM):**

 

* Basics of HMMs
* Applications in part-of-speech tagging

**7. Machine Learning for NLP:**

&#x200B;

* **Supervised Learning:**

 

* Text classification algorithms (Naive Bayes, Support Vector       Machines)
* Evaluation metrics (precision, recall, F1-score)

&#x200B;

* **Named Entity Recognition (NER):**

 

* Rule-based NER
* Machine learning-based NER
* Evaluation metrics for NER

&#x200B;

* **Sentiment Analysis:**

 

* Sentiment lexicons
* Machine learning approaches for sentiment analysis

**8. Sequence-to-Sequence Models:**

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Vanishing and exploding gradient problems
* Bidirectional RNNs

&#x200B;

* **Long Short-Term Memory (LSTM):**

 

* Architecture and key components
* Gating mechanisms

&#x200B;

* **Gated Recurrent Unit (GRU):**

 

* Simplified gating compared to LSTM
* Applications and advantages

**9. Deep Learning Architectures for NLP:**

&#x200B;

* **Convolutional Neural Networks (CNN) for Text:**

 

* Text classification with CNNs
* Hierarchical and multi-channel CNNs

&#x200B;

* **Transfer Learning in NLP:**

 

* Fine-tuning pre-trained models
* Universal Sentence Encoder

&#x200B;

* **Transformer Architecture:**

 

* Self-attention mechanism
* Multi-head attention
* Positional encoding

**10. Transduction and Recurrency:**

&#x200B;

* **Transduction in NLP:**

 

* Definition and applications
* Challenges in sequence-to-sequence transduction

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Applications beyond sequence-to-sequence tasks
* Challenges in training RNNs

**11. Advanced Topics in Sequence Modeling:**

&#x200B;

* **Attention Mechanism:**

 

* Scaled Dot-Product Attention
* Position-wise Feedforward Networks

&#x200B;

* **Self-Attention Mechanism:**

 

* The concept of self-attention
* Layer normalization in self-attention

&#x200B;

* **Multi-Head Attention:**

 

* Motivation and benefits
* Combining multiple attention heads

**12. Syntax and Parsing:**

&#x200B;

* **Dependency Parsing:**

 

* Dependency tree representation
* Transition-based and graph-based parsing

&#x200B;

* **Constituency Parsing:**

 

* Treebank representation
* Earley parsing algorithm

&#x200B;

* **Parsing Techniques:**

 

* Chart parsing (CYK parser)
* Shift-Reduce parsing

**13. Semantic Role Labeling (SRL) and Coreference Resolution:**

&#x200B;

* **Semantic Role Labeling:**

&#x200B;

* PropBank and FrameNet
* Neural approaches to SRL

&#x200B;

* **Coreference Resolution:**

&#x200B;

* Mention detection
* End-to-end coreference resolution models

**14. Evaluation Metrics:**

&#x200B;

* Precision,      Recall, F1-score
* BLEU      score for machine translation
* Perplexity      for language models

**15. NLP in Industry and Research:**

&#x200B;

* Case      studies and applications in various domains (healthcare, finance, legal,      etc.)
* Emerging      research trends in NLP

**16. Ethical Considerations and Bias in NLP:**

&#x200B;

* **Addressing Bias in NLP Models:**

&#x200B;

* Identifying and mitigating biases in training data
* Fairness-aware machine learning

&#x200B;

* **Ethical Considerations in NLP Research and      Deployment:**

&#x200B;

* Privacy concerns in NLP
* Responsible AI practices in NLP

**17. Continuous Learning and Keeping Updated:**

&#x200B;

* Follow      conferences (ACL, NAACL, EMNLP)
* Engage      with the NLP community
* Explore      recent research papers and advancements (Arxiv, NeurIPS)

**18. Projects and Hands-on Practice:**

&#x200B;

* Apply      knowledge through practical projects
* Contribute      to open-source NLP projects
* Participate      in Kaggle competitions

==============================="
145,learnmachinelearning,openai,comments,2022-11-02 15:37:28,Deep Reinforcement Learning examples are Cartpole all the way down,ProbablySuspicious,False,0.85,9,yk8h3t,https://www.reddit.com/r/learnmachinelearning/comments/yk8h3t/deep_reinforcement_learning_examples_are_cartpole/,9,1667403448.0,"I built my own little board game and I'm trying to figure out how to build a neural network agent to learn and play it. There's a lot written about the theory, which I think I get, but practical examples seem limited to running pre-packaged OpenAI Gym setups and I don't see how to apply any of it to a new game. Where could I find an example coded from first principles?"
146,learnmachinelearning,openai,comments,2019-12-03 21:48:05,[Q] How is the policy updated in PPO when the epsilon + advantage term is used?,Carcaso,False,0.81,3,e5oatd,https://www.reddit.com/r/learnmachinelearning/comments/e5oatd/q_how_is_the_policy_updated_in_ppo_when_the/,9,1575409685.0,"&#x200B;

[PPO Pseudocode](https://preview.redd.it/99g4w9mfmh241.png?width=2112&format=png&auto=webp&s=e737d6ef8c53f3f399f0a01512d363497ae2dde7)

How is the policy updated in the proximal policy optimization algorithm? When the function g is smaller, how does that end up updating the policy when using gradient ascent if it is not included? Is there a type of advantage estimation that utlizes the policy? I'm stumped as to how the weights of the policy can be updated when it isn't included in the term. I'm using pytorch and kept getting errors because of the this issue.

source: [https://spinningup.openai.com/en/latest/algorithms/ppo.html#proximal-policy-optimization](https://spinningup.openai.com/en/latest/algorithms/ppo.html#proximal-policy-optimization)"
147,learnmachinelearning,openai,comments,2022-09-23 13:46:55,Created a GUI for OpenAI's Whisper Using Gradio,ImplodingCoding,False,0.96,70,xly2gp,https://v.redd.it/6djgfjpp4mp91,9,1663940815.0,
148,learnmachinelearning,openai,comments,2022-02-01 07:17:02,Becoming a Data Scientist With No Degree,yoavrox,False,0.87,18,shozex,https://www.reddit.com/r/learnmachinelearning/comments/shozex/becoming_a_data_scientist_with_no_degree/,9,1643699822.0,"Hi all,

I recently started to become very interested in machine learning and AI as interesting and rewarding ways to positively affect the world in my career. 

After being ""infected with the bug"" I took fastai's 2020 course, and am now almost finished reading the book ""Mathematics for Machine Learning"", as well as working on fun ML side projects.

Thing is, I come from cybersecurity background with no degree. I have a lot of experience that will certainly help me (python, ability to research etc.), but I'm not sure what the best path forward is. 

Bottom line, my question is if I want to work for Deepmind or OpenAI (or some other place), will they accept me without a degree if I work my butt off learning and making projects? Or is it not feasible? 
Because I can't help but feel that during the 6 years it'll take me to get a master's I can learn more on my own.

I'd really appreciate any input and guidance :)"
149,learnmachinelearning,openai,comments,2023-08-02 18:21:44,A Brief History of Natural Language Generation [Timeline] —Thoughts? Corrections? Suggestions? Thanks!,Britney-Ramona,False,0.86,29,15ggib0,https://i.redd.it/meslnx7moqfb1.png,8,1691000504.0,
150,learnmachinelearning,openai,comments,2023-07-24 10:06:29,My chatPDF doesn't remember the embeddings when I shutdown the server,Cold_Set_,False,0.84,8,1586bom,https://www.reddit.com/r/learnmachinelearning/comments/1586bom/my_chatpdf_doesnt_remember_the_embeddings_when_i/,8,1690193189.0,"Hello, me and a friend are making a web app with Langchain and with an OpenAI API where you can chat with a bot about your PDFs after uploading them in the database (chroma database).

The programs runs well, I upload a PDF, the program converts it into embeddings and replies well, but after reloading the page or restarting directly the server the chatbot kinda forgets he already has made the embeddings for that specific PDF and he tells me he has no idea or just give generic replies if the topic can be found on the internet.

Has anyone an idea how to solve this problem?"
151,learnmachinelearning,openai,comments,2022-09-22 17:26:51,"How to use OpenAI's Whisper (and some accuracy, runtime, and cost benchmarks)",SleekEagle,False,1.0,6,xl7lpu,https://www.reddit.com/r/learnmachinelearning/comments/xl7lpu/how_to_use_openais_whisper_and_some_accuracy/,8,1663867611.0,"Hey everyone! I'm sure many of you know that OpenAI released Whisper yesterday- an open source speech recognition model with weights available.

I wrote a guide on [how to run Whisper](https://www.assemblyai.com/blog/how-to-run-openais-whisper-speech-recognition-model/) that also provides some benchmarks on accuracy, inference time, and cost. Let me know what you think :)"
152,learnmachinelearning,openai,comments,2023-02-23 15:35:40,"I've built a few tools on top of GPT-3.5 (text generation, q&a with embeddings). AMA about resources and AI dev stacks for building with OpenAI's APIs",TikkunCreation,False,0.75,2,11a0ka0,https://www.reddit.com/r/learnmachinelearning/comments/11a0ka0/ive_built_a_few_tools_on_top_of_gpt35_text/,8,1677166540.0,"Started building with GPT-3 in July 2022 and have built a few things since then.

Things I've done have involved:

* Text generation (the basic GPT function)
* Text embeddings (for search, and for similarity, and for q&a)
* Whisper (via serverless inference, and via API)
* Langchain and GPT-Index/LLama Index
* Pinecone for vector db

I don't know much, but I know infinitely more than when I started and I sure could've saved myself back then a lot of time.

So ask me anything that might save you time or wasted effort! Some suggested questions would be things about what the best tools and tutorials/examples to use for a given goal/project are, comparisons between tools/stacks. Also, go with any questions because other people from the subreddit will probably chime in too"
153,learnmachinelearning,openai,comments,2023-04-22 05:51:13,Integrating Google search into OpenAI models like GPT-4,Ghost25,False,1.0,15,12uwd8p,https://www.reddit.com/r/learnmachinelearning/comments/12uwd8p/integrating_google_search_into_openai_models_like/,8,1682142673.0,"Thought I'd share an explanation of how I implemented Google search into my GPT-4 based chatbot.

Github here: https://github.com/sgreenb/pico_assistant

One extremally simple modification that dramatically improves the ability of a GPT to answer questions: letting it Google stuff.

Here’s a demo:

https://imgur.com/ZR6hvLg 1

The implementation works like this.

1. A user enters an input.
2. An agent called “Executive” looks at the input and decides if an API like Spotify, Twillio, or Gmail is needed or if it can be answered by the chatbot alone.
3. If the chatbot is needed the input is first sent to a Google agent. The Google agent’s system message looks like this:

```
{""role"":""system"", ""content"": ""You analyze a user's input to a large language model with \
training data that cuts off at September 2021. The current year is 2023. You decide how \
likely it is that a user's request will benefit from a Google search to help address the\
question. Respond with a number in the range 1-10, where 1 is very unlikely that a \
Google search would be beneficial, and 10 meaning a Google search is highly necessary.""}
```

This is quite fast, since it only needs to generate one or two tokens.

If the output is above some threshold (say 7), then we call another agent, the query agent, otherwise we return False and default to the normal chat agent.

```
    google_probability = int(completion.choices[0].message.content)
    if google_probability >= cutoff:
        search_results = trim_text(search_and_scrape(prompt))
        query_with_context = prompt + str(search_results)
        print(""\nPico: "", end='', flush=True)
        response = query_agent_stream(query_with_context)
        return response
    else:
        return False
```

When we call the query agent, we feed it the first part of a Google search we get from searching the input. We get that from the very simple trim_text and search_and_scrape functions that look like this:

```

def search_and_scrape(query):
    try:
        headers = {
            ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3""
        }
        url = f""https://www.google.com/search?q={query}""
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text()
            cleaned_text = ' '.join(text.split())
            return cleaned_text
        else:
            print(f""Failed to fetch search results for query: {query}, status code: {response.status_code}"")
            return None

    except Exception as e:
        print(f""Error fetching search results for query: {query}, error: {e}"")
        return None

def trim_text(text, start_index = 450, length=1500):
    return text[start_index:start_index + length]
```

The query agent has this system message:

```
{""role"":""system"", ""content"": ""You answer a user's question, given some text as context to help\
answer the question. The user request will be followed by the context. The context given is\
from the user's Google search results, it is current and up to date.\
Do not contradict the contents of the given text in your answer.""}
```

And that’s it. You can change the cutoff threshold or get more sophisticated with fetching web results. I hope you find this useful."
154,learnmachinelearning,openai,comments,2022-04-08 15:20:26,OpenAI 's new model DALL·E 2 is amazing!,OnlyProggingForFun,False,0.94,193,tz5x2f,https://youtu.be/rdGVbPI42sA,8,1649431226.0,
155,learnmachinelearning,openai,comments,2023-09-15 19:03:23,"LLM for textbooks, feasible ?",Personal_Definition,False,1.0,2,16jlt3n,https://www.reddit.com/r/learnmachinelearning/comments/16jlt3n/llm_for_textbooks_feasible/,8,1694804603.0,"I want to build a webapp SAAS that allows you to chat with an AI tutor about  specific textbook. Some of these textbooks are in English and others are Arabic, conceptual , no equations or anything.
I couldn't find anything like this. Im a total noob with AI. but I think it can be made using langchain and openai api , can it ?"
156,learnmachinelearning,openai,comments,2023-04-29 09:21:53,Prompt Engineering Free Course For Beginners By OpenAI And Deep Learning AI,vadhavaniyafaijan,False,0.78,52,132o8tt,https://www.theinsaneapp.com/2023/04/free-prompt-engineering-course-for-beginners.html,7,1682760113.0,
157,learnmachinelearning,openai,comments,2023-02-01 19:06:42,Speech recognition for language that doesn't exist?,cantbebothered67836,False,0.81,6,10r30y6,https://www.reddit.com/r/learnmachinelearning/comments/10r30y6/speech_recognition_for_language_that_doesnt_exist/,7,1675278402.0,"I'm curious to know if there's a way to do speech-to-text without a pre-trained model for a particular language. It could be an obscure language that people haven't gotten around to train into a model yet, or a fictional language or just gibberish. More plainly I want to know if there's a way I can do, er, not so much speech recognition but sound recognition, or syllable recognition. Like if there's a model that recognizes sounds and can string them up into words according to how long the pause interval between those sounds is.

For example, this kid who's talking in a made up language (16 seconds into the video) -- the model would interpret him saying something like:

https://youtube.com/watch?v=CQiIyizGLjs&t=16s

""Colo mate fumala ya shina ma lata, ala siro koto ..."" etc you get the idea lol

Possible? openAI or anything like that?

Or if there's no pre-trained stuff I'm willing to do the nitty gritty myself, I just don't know where to start"
158,learnmachinelearning,openai,comments,2024-01-23 10:27:58,Should I train my own classification model?,iagovar,False,0.83,4,19dlflm,https://www.reddit.com/r/learnmachinelearning/comments/19dlflm/should_i_train_my_own_classification_model/,7,1706005678.0,"Should I train my own classification model?



I made a category filter for the [events section of this website](https://cometocoruna.com/events) where there's a category selector. The problem is that events are not being properly categorized.

I have to categorize the events myself as there's a mix of sources where they apply different or no categories at all.

I've tried to apply zero-shot models as there's obviously no model trained for my categories out there, with pretty poor results in general. I've also tried with OpenAI function calling and it does better, but I want to avoid calling an API as I don't get any profit from such site (can't run huge LLMs models locally neither, because of HW limitations).

**I've never done this** so I want to know if I'm in the right direction. I'm about to dive into training a distillBERT (apparently easier?) model to classify events with my own dataset, as I can get thousands of events easily.

Another problem is how I'm going to label such events myself, I guess I can go pretty far by going with a combination of hand-labeling, defining a hard-coded rule set and maybe also calling ChatGPT too, I don't have a clear strategy right now.


Is this a good idea?"
159,learnmachinelearning,openai,comments,2023-07-10 15:16:24,"ChatPDF: What ChatGPT Can't Do, This Can!",JunXiangLin,False,0.67,4,14vww3o,https://www.reddit.com/r/learnmachinelearning/comments/14vww3o/chatpdf_what_chatgpt_cant_do_this_can/,7,1689002184.0,"Believe many of people have been using **ChatGPT** for a while, and you are aware that although ChatGPT is powerful, it has the following limitations:

1. Unable to answer questions about events that occurred after **2021**.
2. Unable to directly upload your own data, such as **PDF, Excel, databases**, etc.
3. Inaccurate in performing **mathematical calculations**.

**Langchain** is a recent trending open-source project, which is a framework for developing Large Language Models (LLMs) applications. It supports the following:

1. Connecting LLM models with **external data sources**, such as PDF, Excel, databases, etc.
2. Allowing interaction between LLM models and other tools, such as **Google search**, enabling internet connectivity.
3. Rapid development of LLM model applications.

Today, I'd like to share a project called **ChatPDF**(strickly called **docGPT**, there're some different), built using the Langchain framework. It allows users to upload local documents and ask questions to the LLM model. In this tool, you can ask AI to summarize articles or inquire about any information in the document. Moreover, by leveraging the Langchain Agent functionality, the LLM model can collaborate with the Google Search API, enabling users to ask questions about current topics!

The project provides a detailed guide on how to create your own **docGPT**. It is built using the Langchain framework and Python Streamlit, which is a free and fast way to create online services. As long as you have an OPENAI API KEY, feel free to give it a try!

I encourage everyone to pay attention to the [Langchain open-source project](https://github.com/hwchase17/langchain) and leverage it to achieve tasks that ChatGPT cannot handle.

[Github Repository](https://github.com/Lin-jun-xiang/docGPT-streamlit/tree/main)

[ChatPDF Application](https://docgpt-app.streamlit.app/)

&#x200B;

https://preview.redd.it/q906a7imm5bb1.png?width=2560&format=png&auto=webp&s=acef45049bab805038f876eea56cc371b8a9a83a"
160,learnmachinelearning,openai,comments,2023-07-25 12:50:12,Weird chatgpt response,Nice-Elderberry-4490,False,0.36,0,1597mog,https://www.reddit.com/r/learnmachinelearning/comments/1597mog/weird_chatgpt_response/,7,1690289412.0,"Just got this response from the openai davinci model when I prompted:

“Give me a meal plan for the whole week”

Reply: 
##

6 Sc 7 6 Sc rS sc FF c K bI sq q Ja mk du uv aw jX xE ey fE dO qm Cy qL fi lL Xu py tI yN xt zt Dg Fz sL Nu Jd yX gH qL jR nW qq ZN Hd AW MN fO kS qt nY FM eBi rY Ci iR dd Fu yX fk lN xq Ni Cn ll zb kL pc Uu rG vn lm jO jl RF YA zb dM JW BK Dy XI lg xd hI dO tx IE my dP dx dc tX IE 30 AY AY Ci Ui yX Fe Fe ZF Cn Ui Qd zg zf fw Rg ri XP bX ig YU Gf af Fg rq QE NM rW MatkaX

SHARE THIS

##

Kind of scary of you ask me"
161,learnmachinelearning,openai,comments,2023-12-03 23:24:46,Please help,boscrew3,False,1.0,1,18a6hew,https://www.reddit.com/r/learnmachinelearning/comments/18a6hew/please_help/,7,1701645886.0,"Already posted before but i’ve gotten nowhere 
In my previous post i said i was using langchain and OpenAi api to diagnose Alzheimer’s (Got serious roasting for that) but i learned from that and i tried studying actual machine learning but i’m still very clueless. I know i’ll get it eventually but time is not on my side, my supervisor insists that this is the topic i must work on.
All i need is for the model to 
-Provide suggestions on diagnosis and treatment based on user input in text of their symptoms 
-Generate a list of hospitals near them that has the facilities to provide the services 

I’d really appreciate any help"
162,learnmachinelearning,openai,comments,2019-02-28 01:36:20,Could a ML system learn to play Minecraft?,CosmicPennyworth,False,0.67,1,avl9le,https://www.reddit.com/r/learnmachinelearning/comments/avl9le/could_a_ml_system_learn_to_play_minecraft/,7,1551317780.0,"On the internet I've seen people use machine learning to play video games. Someone did it with [GTA V](https://www.youtube.com/watch?v=rvnHikUJ9T0), and people have done it with [slither.io](https://github.com/PeterL328/SlitherIO-AI). OpenAI specializes in this sort of thing.

Is it possible with Minecraft? I'm interested in making a Minecraft bot as a personal project, but first I need to know if it would even be possible.

What I like about Minecraft as a ML problem is that, is that it offers multiple different tasks, all within the same 3D world. I've heard that multitask learning can make an AI generalize the information it learns. Maybe I could teach a Minecraft bot how to walk, pick things up, and look at a target, before moving on to more complex tasks like mining, building, fishing, farming, and fighting. 

Is this overly ambitious? Is it possible?

If it's possible, what techniques should I use?"
163,learnmachinelearning,openai,comments,2024-01-01 18:41:02,What are some speech to text APIs like whisper?,Hades_Kerbex22,False,1.0,2,18w38xe,https://www.reddit.com/r/learnmachinelearning/comments/18w38xe/what_are_some_speech_to_text_apis_like_whisper/,7,1704134462.0, So I need to have a speech to text functionality for a project of mine. It needs to be **multilingual (Hindi and English specifically) I've used whisper- both openAI and it's hugging face version**. Base and medium work the best as I need high accuracy and fast response The problem though is that base version is more inaccurate than I'd like when I use a language other than English. Medium on the other hand has excellent accuracy but takes too long Can anyone suggest me any alternatives preferably free to use ?? 
164,learnmachinelearning,openai,comments,2019-02-27 11:49:51,"DQN learns a bit at first, but then worsens",Naoshikuu,False,0.76,2,avcn01,https://www.reddit.com/r/learnmachinelearning/comments/avcn01/dqn_learns_a_bit_at_first_but_then_worsens/,7,1551268191.0,"Hi; I posted this on r/reinforcementlearning but there might be more relevant.

I've  implemented a quite standard DQN for a project in view to replicate  DeepMind's original work on Atari. I did a lot of trial and error and  finally got something that provided small results : I'm training the  final version of my code on Pong; within the first 5 epoch (50k  frames/epoch) it improved very nicely from -21 to -14 (30 episodes per  test) but has now been training for 50 epoch and only oscillated  downwards, reaching back some -20. (I'll try putting up the curve in  coms)

Do you have any idea why this might happen; any similar experience ? I'll try summing up my parameters and methods :

* Original  NN architecture (input: 4 84\*84 frames, 2 relu conv, 1 relu dense,  output: n\_actions) which should be easier to train. I apply a mask to  the output to select the actions during training.
* Adam optimizer, learnrate=2.5\*10\^-4, optimizing MSE
* Using Keras and TensorFlow, using Nvidia GTX 1080
* Using OpenAI gym with [these wrappers](https://github.com/openai/baselines/blob/master/baselines/common/atari_wrappers.py), except the 4-frame stacking I did myself (theoretically working). Actions spammed for 4frames as in the paper
* 0.3\*10⁶  memory (my own limitations) filled with random behavior for 10k frames;  minibatches of 32\*4 (agent selects 4 actions, then learns on bigger  minibatch, for GPU parallelism)
* annealing exploration parameter epsilon linearly from 1 to .05 over 10⁶ frames (tried 1 to .1) then constant
* Reloading fixed-Q-targets as in the 2015 paper, every 4k frames
* Discount gamma at .99, test exploration at .05

If you have the time and kindness to try & help, please don't hesitate to ask more about the setup.

What  bothers me is that it actually learns a bit, but at a bad level  (reaching an average of 15 at Breakout) before degrading, which  motivates my thinking that some bad hyper-parameter alchemy might be  causing the problem...

Any thoughts ? Thanks in advance for any help."
165,learnmachinelearning,openai,comments,2019-04-14 05:14:01,Humans Call GG! OpenAI Five Bots Beat Top Pros OG in Dota 2,gwen0927,False,0.91,73,bczjd5,https://medium.com/syncedreview/humans-call-gg-openai-five-bots-beat-top-pros-og-in-dota-2-8508e59b8fd5,7,1555218841.0,
166,learnmachinelearning,openai,comments,2020-07-02 08:46:06,Deep learning in gaming.,Ikcike,False,1.0,2,hjtg5z,https://www.reddit.com/r/learnmachinelearning/comments/hjtg5z/deep_learning_in_gaming/,7,1593679566.0,"Hey guys , I recently started learning about machine learning, and I saw OpenAI win against pro players in DOTA.
Of course DOTA provided every information they needed to do this and im 100% sure they could speed up the game and play multiple ones in order to teach it faster. 
I was wondering about this and I pretty much have a dream about making a deep learning program that is capable of being good in multiple games with the same script. 
My question is , is it possible to make a program that can learn multiple games with the same code and doesnt rely that much on importing the games images and telling it what to do in that particular image?"
167,learnmachinelearning,openai,comments,2022-12-13 16:27:07,"Help, I want to incorporate the OpenAI API into a python script as an excercise and I keep getting a timeout error.",Powersawer,False,0.83,4,zkzshv,https://www.reddit.com/r/learnmachinelearning/comments/zkzshv/help_i_want_to_incorporate_the_openai_api_into_a/,7,1670948827.0,"    import os
    
    import openai
    from flask import Flask, redirect, render_template, request, url_for
    
    app = Flask(__name__)
    openai.api_key = os.getenv(""API - KEY"")
    
    
    @app.route(""/"", methods=(""GET"", ""POST""))
    def index():
        if request.method == ""POST"":
            animal = request.form[""animal""]
            response = openai.Completion.create(
                model=""text-davinci-002"",
                prompt=generate_prompt(animal),
                temperature=0.6,
            )
            return redirect(url_for(""index"", result=response.choices[0].text))
    
        result = request.args.get(""result"")
        return render_template(""index.html"", result=result)
    
    
    def generate_prompt(animal):
        return """"""Suggest three names for an animal that is a superhero.
    
    Animal: Cat
    Names: Captain Sharpclaw, Agent Fluffball, The Incredible Feline
    Animal: Dog
    Names: Ruff the Protector, Wonder Canine, Sir Barks-a-Lot
    Animal: {}
    Names:"""""".format(
            animal.capitalize()
        )
------


Only thing I changed was the API Key to the one that was provided to me from the OpenAI website.

When I run this code, or any other OpenAI tutorial code for that matter, I get the following response:


    C:\Users\Administrator\PycharmProjects\OpenAIProject\venv\Scripts\python.exe C:\Users\Administrator\PycharmProjects\OpenAIProject\main.py 
    Traceback (most recent call last):
      File ""C:\Users\Administrator\PycharmProjects\OpenAIProject\main.py"", line 3, in <module>
        import openai
      File ""C:\Users\Administrator\PycharmProjects\OpenAIProject\venv\lib\site-packages\openai\__init__.py"", line 30, in <module>
        from openai.api_resources import *  # noqa
      File ""C:\Users\Administrator\PycharmProjects\OpenAIProject\venv\lib\site-packages\openai\api_resources\__init__.py"", line 1, in <module>
        from openai.api_resources.completion import Completion
      File ""C:\Users\Administrator\PycharmProjects\OpenAIProject\venv\lib\site-packages\openai\api_resources\completion.py"", line 14
        def create(cls, *args, timeout=None, **kwargs):
                                     ^
    SyntaxError: invalid syntax
    
    Process finished with exit code 1

   


So there seems to be some kind of timeout issue, but to be honest I don't quite understand what's supposed to be wrong.

Any help would be greatly appreciated. Running PyCharm on Win10."
168,learnmachinelearning,openai,comments,2023-07-03 15:01:23,How do embeddings encode semantic information?,crono760,False,1.0,20,14plgu8,https://www.reddit.com/r/learnmachinelearning/comments/14plgu8/how_do_embeddings_encode_semantic_information/,6,1688396483.0,"I don't quite get this part. If I understand embeddings, you take some text and pass it through a tokenizer. This doesn't encode semantics, just tokens and their positions. I agree that we can then use that embedding vector to determine which other embeddings are similar by some metric, such as cosine, but doesn't that just mean that they are similar in the sense of tokens and positions, not semantics?

For instance, the sentences ""the cat went to the mat"" and ""the cat went to the rug"" are both semantically and lexicographically similar, and would likely have very similar embeddings. But ""the cat went to the mat"" and ""the house feline moved itself so that its position coincided with the carpet"" are semantically similar but would, I assume, have drastically different embeddings, wouldn't they?

I'm trying to ask this in a model agnostic way, but if it matters let's assume the embeddings come from the openAI API."
169,learnmachinelearning,openai,comments,2021-08-03 06:46:05,Tinder bio generation with OpenAI GPT-3 API,shyamcody,False,1.0,2,owxtwt,https://shyambhu20.blogspot.com/2021/08/tinder-bio-generation-with-openai-gpt-3.html,6,1627973165.0,
170,learnmachinelearning,openai,comments,2023-01-10 19:15:50,What are the top AI tools to work with in 2023?,bruclinbrocoli,False,0.92,10,108i61p,https://www.reddit.com/r/learnmachinelearning/comments/108i61p/what_are_the_top_ai_tools_to_work_with_in_2023/,5,1673378150.0,"Thought this was a cool graphic - 

pulled from this free resource ([https://buildspace.so/notes/ai-stack-2023](https://buildspace.so/notes/ai-stack-2023)) 

Anything missing? 

https://preview.redd.it/ip41flonm9ba1.png?width=456&format=png&auto=webp&s=60c73b5d8fc50212c8e0fe8815b2d25f970ad34c"
171,learnmachinelearning,openai,comments,2023-04-13 09:37:37,[R] A walk-through tutorial on how to build custom OpenAI models by fine-tuning the existing ones,g_pipis,False,0.7,4,12kiyow,https://www.reddit.com/r/learnmachinelearning/comments/12kiyow/r_a_walkthrough_tutorial_on_how_to_build_custom/,6,1681378657.0," I have written this tutorial on [how to fine-tune OpenAI models](https://jorgepit-14189.medium.com/how-to-fine-tune-an-nlp-classification-model-with-openai-c096334ee158). This simple example is about an NLP binary classification task but you can apply the same logic for building custom models for sentiment analysis. Finally, you can build other custom models for other tasks such as NLG, Questions and Answers and so on.  
I would love to get feedback from the community and I am interested in other similar examples with fine-tuned OpenAI models"
172,learnmachinelearning,openai,comments,2019-01-25 06:39:00,PPO Objective Clarification,ejmejm1,False,0.67,2,ajmdmg,https://www.reddit.com/r/learnmachinelearning/comments/ajmdmg/ppo_objective_clarification/,6,1548398340.0,"I'm a little confused about the loss function for PPO given below.

[source: https:\/\/spinningup.openai.com\/en\/latest\/algorithms\/ppo.html](https://preview.redd.it/rfcnxedykic21.png?width=458&format=png&auto=webp&s=a6d3d8e5f34489e3e6f26bd5185a05538689b705)

If the actions are taken and advantage is calculated on the old policy (pi\_theta\_k), how is the new policy (pi\_theta) derived? Do you have to optimize with a vanilla policy gradient loss (-log(pi) \* advantage) to get the new policy, then revert the weights after the the pass-through or what? I feel like I am definitely over complicating this and missing something simple."
173,learnmachinelearning,openai,comments,2023-06-18 15:56:44,"I made FableForge: Text Prompt to an Illustrated Children’s Book using OpenAI Function Calls, Stable Diffusion, LangChain, & DeepLake",AverageKanyeStan,False,0.96,198,14cnuz4,https://v.redd.it/5p2apjnsts6b1,6,1687103804.0,
174,learnmachinelearning,openai,comments,2019-04-24 02:54:49,Just getting my feet wet with Deep Reinforcement Learning and I want to start a project but am struggling. Would appreciate some of veteran insights,KrombopulosMichael,False,0.67,2,bgpg1n,https://www.reddit.com/r/learnmachinelearning/comments/bgpg1n/just_getting_my_feet_wet_with_deep_reinforcement/,6,1556074489.0,"So I've been reading up on Deep Reinforcement Learning but I have no formal education on this topic. I have a high level picture of what I want to accomplish but am not sure the best way to go.

The project is to train a Pokemon Battling AI. I'm not sure how I'm going to get there quite yet (So any insight on this would also be welcome) but I'm somewhere between Double Dueling Deep Reinforcement Learning and some sort of Gradient Decent approach.

Step 1 for me (I think) is to get a Pokemon battle environment into OpenAI gym. My hang-up is how I simulate both players in the battle. Most tutorials and examples have a system where the agent interacts with the environment and then responds to some output. But in my case the environment also has a decision to make. So how to I simulate a second player?

My other question is more high level but I think related. How do I ensure that my agent is learning to beat all Pokemon trainers and all Pokemon teams? My thought is it might find the best policy for fighting a single opponent or team composition but that policy might be bad when one of the variables changes. Is this a common issue and can someone point me to some reading about it. Or explain it to me?

Thanks all. I'm just starting my ML journey and I'm loving it so far! Trying to soak as much as I can in"
175,learnmachinelearning,openai,comments,2023-01-19 16:38:05,Best Speech-to-Text Model - Open Source vs. Paid Services,Knecht_Christi,False,0.81,3,10g6a82,https://www.reddit.com/r/learnmachinelearning/comments/10g6a82/best_speechtotext_model_open_source_vs_paid/,6,1674146285.0,"**I'm building a tool to programmatically generate transcripts from sermons.**

I have access to hundreds of sermon transcripts (and 100x more very similar in domain data) but less than a 40 transcripts with audio (\~30 hours).

I want the lowest WER (Word Error Rate) possible and can budge 100 hours for this project in 2023.

# Train my own acoustic model with the best open source offering

* OpenAI's [Whisper](https://openai.com/blog/whisper/) seems to be the best available today?
* How much supervised data (e.g. hours of sermons with perfect transcripts) would I need to develop a model that would be more accurate than Google/AWS for my specific domain?
* Can I take a model already trained and ""tune"" it by augmenting the data I have?

# Use the best cloud speech-to-text API that I can provide in-domain data to to tune it

* AWS Transcribe and Google Speech to Text seem to be big players
* I've gone with AWS Transcribe since it can be tuned more easily with custom domain data (just upload text files) than Google's (which requires building phrase dictionaries with weights).
* Is there anything out there that's better for my use case?

**Any other thoughts on this on the whole?**

\----------------------------

# UPDATE three months later after trying both

**Whisper** blew my custom AWS model with tons of domain-specific text out of the water.  Long story short is to use Whisper for similar cases."
176,learnmachinelearning,openai,comments,2019-07-25 04:36:56,Opinions on free resources to learn Deep Reinforcement Learning,rpicatoste_,False,0.87,15,chj0vl,https://www.reddit.com/r/learnmachinelearning/comments/chj0vl/opinions_on_free_resources_to_learn_deep/,6,1564029416.0,"I gathered a list of free resources to learn Deep  Reinforcement Learning, but given time availability I would like to  choose the one with highest output/time invested.

If you have followed any of these, could you please share: how good it was and what it took in terms of effort and time?

This is the list:

* [Spinning up deep learning](https://spinningup.openai.com/)
* [Depth first learning for AlphaGoZero](http://www.depthfirstlearning.com/2018/AlphaGoZero)
* [https://www.starai.io/course/](https://www.starai.io/course/)
* [Stanford cs234 Winter2019](http://web.stanford.edu/class/cs234/index.html) (videos [here](https://www.youtube.com/watch?v=FgzM3zpZ55o&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u))
* [David Silver course](http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html)
* [Skymind](https://skymind.ai/wiki/deep-reinforcement-learning)
* [Simonini's course](https://simoninithomas.github.io/Deep_reinforcement_learning_Course/)
* [CS 294-112 at UC Berkeley - Deep Reinforcement Learning](http://rail.eecs.berkeley.edu/deeprlcourse/)
* [Learning Reinforcement Learning by WildML](http://www.wildml.com/2016/10/learning-reinforcement-learning/)
* [Advanced Deep Learning and Reinforcement Learning - UCL and DeepMind](https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs) + [slides](https://github.com/enggen/DeepMind-Advanced-Deep-Learning-and-Reinforcement-Learning)

If you followed another resource and can give the same opinion please go ahead.

If it matters: I have been doing Machine Learning and Deep Learning for a  while, and my goal is to be able to train agents for which I can build  an environment. In other words, more practical, so I can use it, than  cutting edge/research.

Thank you! 

Other resources, mainly code:

* [https://github.com/dennybritz/reinforcement-learning](https://github.com/dennybritz/reinforcement-learning)
* [https://github.com/seungeunrho/minimalRL](https://github.com/seungeunrho/minimalRL)
* [https://www.reddit.com/r/reinforcementlearning/comments/a16o4h/d\_main\_deep\_reinforcement\_learning\_implementations/](https://www.reddit.com/r/reinforcementlearning/comments/a16o4h/d_main_deep_reinforcement_learning_implementations/)"
177,learnmachinelearning,openai,comments,2021-10-03 11:49:44,What is the difference between OpenAI and the gpt3 algorithm?,Ok-War-9040,False,0.2,0,q0g7na,https://www.reddit.com/r/learnmachinelearning/comments/q0g7na/what_is_the_difference_between_openai_and_the/,6,1633261784.0,
178,learnmachinelearning,openai,comments,2021-03-26 04:34:14,MPI is killing me! PLEASE HELP!,Testost3r0ne,False,0.5,0,mdgrta,https://www.reddit.com/r/learnmachinelearning/comments/mdgrta/mpi_is_killing_me_please_help/,6,1616733254.0,"GOOD DAY. I've been trying to retrain OpenAI Jukebox on my local machine --- I don't have any issues with it in Google Colab now --- and I keep getting this error:

    DLL load failed: The specified module could not be found when doing “from mpi4py import MPI”

Yes, I have installed Microsoft MPI. Yes, I have followed every step in the repo. It's just that I can install mpi4py using Anaconda on Colab, but not on my local machine --- I have to use pip. I'm still not getting it to run! Can someone pleeeeeeaaasseee help me? Thanks."
179,learnmachinelearning,openai,comments,2024-01-12 11:17:44,Seeking Guidance on Image Classification Techniques for 10 M images,Numerous_Speed_9107,False,1.0,7,194splz,https://www.reddit.com/r/learnmachinelearning/comments/194splz/seeking_guidance_on_image_classification/,6,1705058264.0,"I find myself amidst a challenging task – classifying 10 million unlabelled images with alt text into approximately 200 classes.

As I delve into the preliminary research, my focus has narrowed down to two intriguing techniques.

* Contrastive learning for example MoCo
* OpenAI CLIP embeddings

I'm grappling with a quandary regarding contrastive learning. How can I effectively control or assign labels to similar embeddings, especially when the embedding space keeps shuffling as more data is introduced?

Considering OpenAI CLIP embeddings. Is it a more effective approach with specific advantages for my image classification task?

Open to community suggestions. Any overlooked viable options for this project? Your insights are valuable!"
180,learnmachinelearning,openai,comments,2023-08-13 01:03:38,"Besides HHH, what is RLHF actually good for? Every example I've ever seen has focused on lobotomizing models.",JonBon13,False,0.89,14,15pl55g,https://www.reddit.com/r/learnmachinelearning/comments/15pl55g/besides_hhh_what_is_rlhf_actually_good_for_every/,5,1691888618.0,"Most instruction following & SFT seems likely to become unnecessary as those data sets leak into pre-training. However, it seems like RLHF is not a 1-size fits all solution. However, I've only seen real ""value add"" use cases for HHH. 

**Are there examples of RLHF models that are actually ""task specific"" or ""better than"" GPT-4 + prompting?** I've seen the OpenAI & other graphs that show humans rank RLHF > SFT, but the ""chat"" example seems so incredibly generic. Are there cases where you can actually squeeze out large performance for certain useful tasks only with RLHF? 

What are the buyers of RLHF data on Surge/Scale actually trying to get models to do?"
181,learnmachinelearning,openai,comments,2017-06-16 14:27:36,How do I debug my q-learning solution for OpenAI's cartpole?,iamaroosterilluzion,False,1.0,3,6hmuov,https://www.reddit.com/r/learnmachinelearning/comments/6hmuov/how_do_i_debug_my_qlearning_solution_for_openais/,5,1497623256.0,"I tried to solve the cartpole game from OpenAI's gym using q-learning, but my implementation scores lower than the baseline (choosing random actions): https://pastebin.com/8wGn0LkA

Could anyone provide any suggestions or tips on how to go about debugging the algorithm? It's hard to inspect my q-learning state space because it's so large, and I can't think of any other good techniques for finding the bugs in my code.

I'm more interested in learning debugging techniques because I'd like to be more self sufficient, but feel free to mention any problems you see in the code as well. Thank you!"
182,learnmachinelearning,openai,comments,2023-06-17 15:49:30,How to Build LLM Applications With LangChain and Openai,mwitiderrick,False,0.89,7,14buddi,https://www.reddit.com/r/learnmachinelearning/comments/14buddi/how_to_build_llm_applications_with_langchain_and/,5,1687016970.0,"LangChain is one the most popular tools for building large language model applications.   You can use LangChain to build various applications, such as question-answering systems and chatbots.   Some of the modules in Langchain include: 

**•** **Models** for supported models and integrations 

**• Prompts** for making it easy to manage prompts 

**• Memory** for managing the memory between different model calls 

**• Indexes** for loading, querying, and updating external data 

**•Chains** for creating subsequent calls to an LLM

 **• Agents** to develop applications where the LLM model can direct itself 

**• Callbacks** for logging and streaming the intermediate steps in a chain 

Today over a thousand subscribers of mlnuggets got a tutorial on how to use LangChain and other language models, such as the ones from Openai, to create a system to transcribe and ask questions to YouTube videos. 

Check it out [https://www.machinelearningnuggets.com/how-to-build-llm-applications-with-langchain-and-openai/](https://www.machinelearningnuggets.com/how-to-build-llm-applications-with-langchain-and-openai/)"
183,learnmachinelearning,openai,comments,2023-10-01 20:37:56,LLM Firewall - Guardrail Tutorial and Quickstart with OpenAI and Colab,Educational_Grass_38,False,0.94,12,16xc53k,https://m.youtube.com/watch?v=EnwVnz07h1I&pp=ygUSR3VhcmRyYWlsIEZpcmV3YWxs,5,1696192676.0,"Been working on a Firewall for devs to use in a few lines of code, to implement a protective layer around LLMs like OpenAI. Firewall has over 20+ detectors out-of-the-box including prompt injections, harmful content, toxicity and common security vulnerabilities.

Google Colab QuickStart: https://github.com/guardrail-ml/guardrail

Developer Docs: https://docs.useguardrail.com

Would appreciate if you could give a star and provide feedback, thanks!"
184,learnmachinelearning,openai,comments,2023-03-31 06:16:58,"If ChatGPT itself cannot be fine-tuned, what would bf the benefit of using the GPT3 offering of OpenAI vs my own?",Proxify,False,0.86,5,127c5iz,https://www.reddit.com/r/learnmachinelearning/comments/127c5iz/if_chatgpt_itself_cannot_be_finetuned_what_would/,5,1680243418.0,"Sorry, I'm somewhat new to this space and I'm reading about it and looking at the documentation from OpenAI.

From what I can tell, only their base models are available to fine-tune which, as far as I understand, would leave me in a situation in which fine-tuning any other GPT3 model would be comparable (vs their ""DaVinci"" model for instance).

Am I missing something here? Basically I'm wondering, other than their infrastructure (which is nothing to scoff at) why would I use their fine-tuning if the end result won't talk to the user as ChatGPT would."
185,learnmachinelearning,openai,comments,2019-09-09 15:25:19,About RL Performance of OpenAI Retro Gym's RAM vs Image Observations,AnotherForce,False,1.0,3,d1sd6e,https://www.reddit.com/r/learnmachinelearning/comments/d1sd6e/about_rl_performance_of_openai_retro_gyms_ram_vs/,5,1568042719.0,"Using  similar agent architectures, should I expect a faster convergence for learning on RAM than learning on image observations? I'm new to reinforcement learning and therefor do not have a clue.

I  would argue that the size of the observations directly influence the  computation speed, is this correct? Because of this I would expect RAM  observations to speed up convergence of my DDQN implementation, is this a fair assumption?

Thanks for your help."
186,learnmachinelearning,openai,comments,2018-06-13 15:25:24,Learning how to implement Q-Learning in Python and training with OpenAi Gym,brendanmartin,False,1.0,30,8qta4p,https://www.reddit.com/r/learnmachinelearning/comments/8qta4p/learning_how_to_implement_qlearning_in_python_and/,5,1528903524.0,"/u/satwik_ and I wrote an article about Reinforcement Q-Learning in Python and would love to answer any questions for anyone that's interested in learning how to apply Q-Learning to a project.

Article: https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/"
187,learnmachinelearning,openai,comments,2023-09-20 19:08:05,"Say Goodbye to Servers, and Expensive middle man apps. OpenAI direct bring your own key and a iSH Alpine Linux Shell",Reasonable_Leg_7405,False,0.38,0,16ntm4j,https://i.redd.it/vt202cohlgpb1.jpg,5,1695236885.0,
188,learnmachinelearning,openai,comments,2018-08-05 09:24:08,"[Q] Reinforcement Learning PPO, Nan Issue",Jonas_SV,False,0.84,4,94qp5l,https://www.reddit.com/r/learnmachinelearning/comments/94qp5l/q_reinforcement_learning_ppo_nan_issue/,5,1533461048.0,"I'm trying to implement PPO, and i'm having problems with the actions turning NaN after just training for a few epochs. 
---

I've identified the culprit to be this line: (89)
```python
pi_div_piold    = tf.exp(self.obf.log_prob(self.actions) - self.old_obf.log_prob(self.actions))
```

The full code: https://github.com/JonasRSV/PPO
---

What happends is that it becomes infinite and then the loss becomes infinite and... Nans. 
---

The line is basically the division part of (6) in https://arxiv.org/pdf/1707.06347.pdf
but for some reason the objective function samples actions that later has no chance of being sampled.
---

I've compared with other implementations https://github.com/shareeff/PPO and OpenAI baseline https://github.com/openai/baselines/tree/master/baselines/ppo1.

---

I can't seem to identify where i've gone wrong :(. Thanks for reading, any insight would be super appreciated! 

"
189,learnmachinelearning,openai,comments,2024-01-30 18:40:34,"In the era of GPT, building an effective word similarity search in 2023",stoicbats_,False,0.67,1,1aevr5z,https://www.reddit.com/r/learnmachinelearning/comments/1aevr5z/in_the_era_of_gpt_building_an_effective_word/,5,1706640034.0,"Hello everyone,

I am currently tackling a project that involves a list of various brand names within a specific domain. For instance:

`domain_names = ['xyz', 'yza', 'tra', 'world']`

My goal is to develop a search s capable of analyzing word similarity. Specifically, the system should accept a word and return the top 'k' words that are most similar to it. I have experimented with OpenAI embeddings, particularly the latest Embedding Version 3 (3072 dimensions), but the results have been unsatisfactory.

Could someone suggest the most effective approaches for searching word-level similarities ?In the era of GPT, Would it be advisable to train my own Word2Vec model?"
190,learnmachinelearning,openai,comments,2018-11-14 17:01:38,OpenAI Founder: Short-Term AGI Is a Serious Possibility,Yuqing7,False,0.43,0,9x1w3l,https://medium.com/syncedreview/openai-founder-short-term-agi-is-a-serious-possibility-368424f7462f,5,1542214898.0,
191,learnmachinelearning,openai,comments,2022-11-27 17:20:01,How to generate example sentences from list of words (1 sentence per word),mamibe,False,0.83,4,z66tb1,https://www.reddit.com/r/learnmachinelearning/comments/z66tb1/how_to_generate_example_sentences_from_list_of/,4,1669569601.0,"How can I generate example sentences from a list of ~3000 words? Every sentence should be short (4-6 words) and every word should have an own sentence?

I tried with OpenAI's Playground (max length) and the following command (""Create an example sentence for every word in this list in first person singular and present tense. Do not use from other lines for the example sentences.""). The words were in separate lines (simulated with comma separated: south, wood, woman, first, laptop, money, spring (season)).

An example for a sentence that I'd like to generate would be: ""It's warm in the south."" (where south is the word)

OpenAI did the following things wrongly:

- It used words from multiple lines and combined them into one sentence (I don't want this)
- After around 20 lines, it did not generate new sentences but just repeat the word

My questions:

- What is the term for this type of text generation? Everything I find, e.g. on nlpcloud, is about generating full text from keywords, not text that includes those keywords
- Can I tweak OpenAI to do it the way I want?
- Which alternatives (free or paid, preferably hosted) do I have to do this sort of text generation?

Thanks!"
192,learnmachinelearning,openai,comments,2023-04-30 11:47:12,Consumer rig for running Coding AI assistant?,Alystan2,False,1.0,4,133n2qe,https://www.reddit.com/r/learnmachinelearning/comments/133n2qe/consumer_rig_for_running_coding_ai_assistant/,4,1682855232.0,"Hi all, I'd like you informed opinion (or harsh criticism if deserved).

I am trying to work out example of consumer grade hardware (let's say <5k$) necessary to run (inference only) a large language model locally as a **coding assistant**.

Let's assume that because of the sensitivity of the code I am working on, **I am not allowed to use OpenAI ChatGPT**, Microsoft co-pilot or even run my own model in a cloud provider like AWS or Google.

But nothing is stopping me from installing **Oobabooga Webui** with **StableVicuna**, **WizardLM** or whatever other language model effective in coding assistance.

My understanding is that (please correct me if untrue):

* Large models need large amount of VRAM (not sure what a 13B vs an 8B model will require though)
* nVidia cards are the most compatible with the ML libraries
* dedicated AI chips are very effective but insanely expensive

Requirements:

* can run (inference only) a large language model locally as a **coding assistant**.
* should be able to run newer upcoming models for the next two years
* the cheaper the better

Currently I am imagining that workable rig would be **built around a RTX4090 (24G) or RTX4080 (16G)**.

**What are your thoughts, suggestions or other considerations that I am totally missing?**

Bonus questions:  
\* can I stick two RTX4080 (16G) and load a model requiring 32G of VRAM?  
\* would investing in a motherboard capable of handling four x16 PCIe slot worth it for upgrade?  
\* any CPU / memory / other hardware preferences or counter indications?

Thank you for reading this far!"
193,learnmachinelearning,openai,comments,2023-07-06 12:21:54,USA Company Valuation w/ ChatGPT,MandM-DataScience,False,0.6,1,14s7lck,https://www.reddit.com/r/learnmachinelearning/comments/14s7lck/usa_company_valuation_w_chatgpt/,4,1688646114.0,"Hi everyone!

We just published our new AI project. Take a look at our python notebook and our example GOOGL valuation ;)

[https://www.kaggle.com/code/mandmdatascience/usa-company-valuation-with-chatgpt](https://www.kaggle.com/code/mandmdatascience/usa-company-valuation-with-chatgpt)

&#x200B;

[GOOGL Company Dashboard \(Tableau\)](https://preview.redd.it/ais9ff4p7cab1.png?width=989&format=png&auto=webp&s=299ab8984e0e6ac84112353d1c94b5df719e673f)

Technologies used:

* Python
* OpenAI models
* Valuation model (Prof. Damodaran)
* Tableau
* PowerBI

Every and each comment / feedback is greatly appreciated!

Thank you!  
M&M"
194,learnmachinelearning,openai,comments,2019-05-12 16:22:04,What is OpenAI Gym used for?,codexblaze,False,0.72,3,bnqrdj,https://www.reddit.com/r/learnmachinelearning/comments/bnqrdj/what_is_openai_gym_used_for/,4,1557678124.0,I a beginner learning reinforcement learning. I was wondering what openAI Gym is used for.
195,learnmachinelearning,openai,comments,2024-01-28 08:21:02,Best Practices for Semantic Search on 200k vectors (30GB) Worth of Embeddings?,stoicbats_,False,0.67,2,1acxy85,https://www.reddit.com/r/learnmachinelearning/comments/1acxy85/best_practices_for_semantic_search_on_200k/,4,1706430062.0,"Hi, I have converted some domain-specific name vectors into embeddings, with a dataset size of 200k words. All the embeddings were generated using OpenAI's embedding model 3 (3072 dim per embedding) . Now I am planning to implement semantic search similarity. Given a domain keyword, I want to find the top 5 most similar matches. After embedding all 280k words, the size of the JSON file containing the embeddings is around 30GB.

I am new to this domain and evaluating the best options.

1. Should I use a cloud vector database like Pinecone or Typsense, or host locally on DigitalOcean?
2. If I go with a cloud option like Typsense, what configuration (RAM, etc.) would I need for 280k embeddings (30GB in size)? And how much would it likely cost?

I have been confused for the past few days and unable to find useful resources. Any help or advice you could provide would be greatly appreciated."
196,learnmachinelearning,openai,comments,2020-02-16 11:10:24,Help for Personal project for league of legends machine learning,random_638,False,0.5,0,f4pbsu,https://www.reddit.com/r/learnmachinelearning/comments/f4pbsu/help_for_personal_project_for_league_of_legends/,4,1581851424.0,"Dissertations coming up and jm making a ML algorithm to detect gestures in real time and perform actions on your pc. Changing brightness, volume. I have a few months so I have time, I want to however create an ML for league of legends. You guys and gals probably get this a lot with league being the most played game in the world. I know that the dota 2 openai played against itself over 10,000 years worth of gaming.

Would anyone have any idea on where to start with this project? I have 1 rtx 2080 so it should be okay when actually starting to process all the data. Any links, books, programming libraries, IDE's (I use pycharm currently) would be much appreciated indeed. Thank you very much"
197,learnmachinelearning,openai,comments,2019-09-19 12:12:01,How to use Keras' Conv1D layer (or shouldn't I use it)?,AnotherForce,False,1.0,3,d6d54t,https://www.reddit.com/r/learnmachinelearning/comments/d6d54t/how_to_use_keras_conv1d_layer_or_shouldnt_i_use_it/,4,1568895121.0,"I have an numpy array of features of size 128 (RAM memory from an Atari game in OpenAI Gym). Time is important so I'm stacking 8 of these. I now have a numpy array with shape (8,128). Would I use Conv1D to further extract features from this array structure? Or should I use something else?

Thanks"
198,learnmachinelearning,openai,comments,2022-12-28 17:37:46,chatGPT peeps- anyone else learn new stuff best by actually building something?,bruclinbrocoli,False,0.7,5,zxfnga,https://www.reddit.com/r/learnmachinelearning/comments/zxfnga/chatgpt_peeps_anyone_else_learn_new_stuff_best_by/,4,1672249066.0,"[This intro to chatGPT](https://buildspace.so/notes/intro-to-chatgpt) has some cool (free) challenges at the end to build a telegram bot, a business email generator, or a writing assistant.

What else have people found to learn bout chatGPT that's not just theory?

&#x200B;

https://preview.redd.it/smxv4mzldo8a1.png?width=1026&format=png&auto=webp&s=43081abbfcad449817e520b5e92ba599a18a1525"
199,learnmachinelearning,openai,comments,2022-02-03 18:39:05,[Project] Refining the Natural language processing course - Feedback v2 and thank you,sb2nov,False,0.91,37,sjqogi,https://www.reddit.com/r/learnmachinelearning/comments/sjqogi/project_refining_the_natural_language_processing/,2,1643913545.0,"I’m Sourabh, I lead one of the core Tensorflow teams at Google Brain and worked on data products at Coursera with Andrew Ng. Kaushik Rangadurai, ML Engineer at Facebook and I are leading a live, cohort based course on NLP starting March 14th. [https://corise.com/course/natural-language-processing](https://corise.com/course/natural-language-processing).

This is the second run of the class and we learned a lot from the feedback of the reddit community from the first run in November. Some of the changes we're making from the previous iteration:

1/ More focus on transformers and less on RNN/LSTM as hugging face is becoming the defacto for any nlp.

2/ Pytorch lightning has some really easy to use interfaces so better organizing the boiler plate code.

3/ OpenAI has opened the GPT-3 API so a deeper dive into current possibilities.

Would love to continue getting feedback and build this to be a great resource. The plan is to open the content after we refine it to a degree we're happy with. You can join the course (capped at about 30 students) at the link above. If you’re open to giving feedback on the class on how we can do better, happy to give a discount."
200,learnmachinelearning,openai,relevance,2023-01-10 11:12:01,Microsoft Will Likely Invest $10 billion for 49 Percent Stake in OpenAI,BackgroundResult,False,0.97,449,1087ady,https://aisupremacy.substack.com/p/microsoft-will-likely-invest-10-billion,102,1673349121.0,
201,learnmachinelearning,openai,relevance,2024-02-16 09:14:37,Video Generated By OpenAI Sora! New OpenAI Text-To-Video Model,st1275857,False,0.71,3,1as4dzx,https://www.youtube.com/watch?v=KiP05mehXFQ,0,1708074877.0,This entire video is generated by OpenAI sora. It incredible how good it is. RIP to videographer. What do you guys think? 
202,learnmachinelearning,openai,relevance,2023-12-16 15:26:30,Is there any alternative for OpenAI API?,CrazyProgramm,False,0.77,7,18jti72,https://www.reddit.com/r/learnmachinelearning/comments/18jti72/is_there_any_alternative_for_openai_api/,12,1702740390.0, So I am from Sri Lanka and our university is going to organize a competition and we need OpenAI API for it but we don't have money to afford it. Is there any alternative API you guys know 
203,learnmachinelearning,openai,relevance,2023-02-16 10:29:31,OpenAI Has Purchased AI.Com For ChatGPT For $11M,vadhavaniyafaijan,False,0.93,210,113nizs,https://www.theinsaneapp.com/2023/02/openai-purchased-ai-com-domain.html,23,1676543371.0,
204,learnmachinelearning,openai,relevance,2023-11-17 01:24:48,OpenAI completions api timeout help,Artistic_Slip_8679,False,1.0,1,17x3d20,https://www.reddit.com/r/learnmachinelearning/comments/17x3d20/openai_completions_api_timeout_help/,0,1700184288.0,"I’ve got an angular/.NET website that is utilizing OpenAI’s completions API and I’m running into a timeout issue. My site has various limitations that basically cause my endpoint to timeout after 60 seconds. Is anyone aware of a way I can store the id of my request and check in on it rather than waiting for it? I’m slightly new to C# and am not sure how I can prevent this timeout without streaming client-side, which I don’t want to do since it’ll expose my API key. Any links, information, tutorials appreciated!"
205,learnmachinelearning,openai,relevance,2023-12-22 22:08:12,A dive into openai's whisper Model [Part 1],Amgadoz,False,1.0,1,18oq9kq,https://www.reddit.com/r/learnmachinelearning/comments/18oq9kq/a_dive_into_openais_whisper_model_part_1/,0,1703282892.0,"Hey fellow ML people!

I am writing a series of blog posts delving into the fascinating world of the Whisper ASR model, a cutting-edge technology in the realm of Automatic Speech Recognition. I will be focusing on the development process of whisper and how people at OpenAI develop SOTA models.

The first part is ready and you can find it here: [Whisper Deep Dive: How to Create Robust ASR (Part 1 of N)](https://amgadhasan.substack.com/p/whisper-how-to-create-robust-asr).

In the post, I discuss the first (and in my opinion the most important) part of developing whisper: the data curation.

Feel free to drop your thoughts, questions, feedback or insights in the comments section of the blog post or here on Reddit. Let's spark a conversation about the Whisper ASR model and its implications!

If you like it, please share it within your communities. I would highly appreciate it <3

Looking forward to your thoughts and discussions!

Cheers"
206,learnmachinelearning,openai,relevance,2023-10-19 17:47:15,is hosting a 7B model on cloud cheaper than accessing openai’s api,besabestin,False,0.89,22,17bozjd,https://www.reddit.com/r/learnmachinelearning/comments/17bozjd/is_hosting_a_7b_model_on_cloud_cheaper_than/,21,1697737635.0,"I have few questions related to this. Now that a lot of smaller models are becoming better and accessible, are they getting cheaper for access? llama and mistral models are getting better and also getting more improvements through quantization or better attention techniques.

I was using openai’s models and they cost so low unless you are summarizing tens of pages of pdf files. I am looking at like 20cents of my whole day use.

How are such models actually uploaded on cloud? Are the weights saved in database and stuff? I know there are tools like skyplot but how do they work underneath?"
207,learnmachinelearning,openai,relevance,2023-08-16 11:26:18,OpenAI Notebooks which are really helpful,vishank97,False,0.93,51,15sn6ti,https://www.reddit.com/r/learnmachinelearning/comments/15sn6ti/openai_notebooks_which_are_really_helpful/,2,1692185178.0,"The OpenAI cookbook is one of the most underrated and underused developer resources available today. Here are 7 notebooks you should know about:

1. Improve LLM reliability:  
[https://github.com/openai/openai-cookbook/blob/main/techniques\_to\_improve\_reliability.md](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)
2. Embedding long text inputs:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Embedding\_long\_inputs.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Embedding_long_inputs.ipynb)
3. Dynamic masks with DALLE:  
[https://github.com/openai/openai-cookbook/blob/main/examples/dalle/How\_to\_create\_dynamic\_masks\_with\_DALL-E\_and\_Segment\_Anything.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/dalle/How_to_create_dynamic_masks_with_DALL-E_and_Segment_Anything.ipynb)
4. Function calling to find places nearby:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Function\_calling\_finding\_nearby\_places.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Function_calling_finding_nearby_places.ipynb)
5. Visualize embeddings in 3D:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Visualizing\_embeddings\_in\_3D.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Visualizing_embeddings_in_3D.ipynb)
6. Pre and post-processing of Whisper transcripts:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Whisper\_processing\_guide.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Whisper_processing_guide.ipynb)
7. Search, Retrieval, and Chat:  
[https://github.com/openai/openai-cookbook/blob/main/examples/Question\_answering\_using\_a\_search\_API.ipynb](https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_a_search_API.ipynb)

Big thanks to the creators of these notebooks!"
208,learnmachinelearning,openai,relevance,2023-01-16 12:28:25,I benchmarked OpenAI's GPT API vs other proprietary APIs on different NLP tasks,AImSamy,False,0.9,197,10ddc1f,https://www.reddit.com/gallery/10ddc1f,37,1673872105.0,
209,learnmachinelearning,openai,relevance,2024-01-19 22:03:14,"Fine Tuning OpenAI CLIP, where am I missing out?",MaintenanceNo5993,False,1.0,1,19av4eh,https://www.reddit.com/r/learnmachinelearning/comments/19av4eh/fine_tuning_openai_clip_where_am_i_missing_out/,0,1705701794.0,"Since past 2 weeks I have been trying to **fine tune CLIP, train CLIP from scratch** on another dataset (MS COCO Captions). But the model is not able to learn anything it gets stuck at `0.1% TOP 1 acc. and 0.5% TOP 5 acc.` on ImageNetV2 dataset zero shot classification from the very first epoch. On looking the output from the very first epoch it starts to give image and text features such that the `image_features @ text_features.T` is full of `-1`

I am using the training code available at `https://github.com/mlfoundations/open_clip/tree/main/src/training`. I have read the paper and was able to make sense of their implementation.

I have searched in the literature, blogs, GitHub issues but haven't found the solution yet. What I have I done:

[x] Read the official paper and set the hyper params as they have mentioned.

[x] Asked on [`r/MachineLearing`](https://www.reddit.com/r/MachineLearning/comments/193gug2/d_fine_tuning_open_clip_model_causes_it_zero_shot/?utm_source=share&utm_medium=web2x&context=3) they advised for using gradient accumulation. I used it keeping batch size as 160, accumulating after step of 1, 200, 300, 400,..., at the end 1 epoch also but same thing was happening even after waiting till the 30th epoch.

[x] Used about 6 GPU days in running various experiments to fix this, 2 V100's 16 GB.

Most of the experiments were done on ViT-B-32 (scratch, pretrained on laion2b_s34b_b79k) and some on ConvNext-Base. 

Code at: https://codepad.site/edit/08t37xxp

Thank You <3!"
210,learnmachinelearning,openai,relevance,2023-08-31 15:54:43,OpenAI Function Calling Tutorial,kingabzpro,False,1.0,2,166exjp,https://www.reddit.com/r/learnmachinelearning/comments/166exjp/openai_function_calling_tutorial/,0,1693497283.0,"Learn how OpenAI's new Function Calling capability enables GPT models to generate structured JSON output, resolving common dev issues caused by irregular outputs.

https://www.datacamp.com/tutorial/open-ai-function-calling-tutorial"
211,learnmachinelearning,openai,relevance,2023-11-08 23:09:05,OpenAI api remember conversation context in Angular,Shacrak4,False,1.0,5,17qyjet,https://www.reddit.com/r/learnmachinelearning/comments/17qyjet/openai_api_remember_conversation_context_in/,1,1699484945.0,"I'm doing an Angular app which uses the chatgpt api to generate interactive stories based on a character and setting which are chosen by the user. I made an intermediary API(with node) to manage the different methods(post/get) and a service to inject my API where it's needed. The story is generated by chunks and in between them, the AI should also generate 3 options, the user chooses one and it would be sent back as a prompt so that the story can continue. I want the AI to remember the whole conversation, as it's really important that it knows how to behave, generate the story and the chunks it already sent. This last bit is where the problem lies, since this is a college project and my budget is really tight(due to national economic problems), I can't afford to make a conversation history and send it back as part of the new prompt because the usage cost would be too high. Is there a way to make the AI remember the conversation without having to always send it back with the new prompt(chosen option)?

Sorry if this is not the place to make this request but at this point I'm kinda desperate"
212,learnmachinelearning,openai,relevance,2024-01-04 12:35:54,Epstein Documents 2024: Full Search with OpenAI and Embeddings,vanlifecoder,False,0.67,1,18yc5pg,https://collie.ai/epstein2024,0,1704371754.0,
213,learnmachinelearning,openai,relevance,2023-06-29 00:28:52,OpenAI Function Calling Examples,sopmac21379,False,1.0,3,14lq1eg,https://medium.com/sopmac-ai/openai-function-calling-examples-a438268e0a77,3,1687998532.0,
214,learnmachinelearning,openai,relevance,2024-02-06 00:51:48,OpenAI's GPTs Ranks (Daily Update) - according to the official categories,SanBirth,False,0.5,0,1ajwxfm,https://www.reddit.com/r/learnmachinelearning/comments/1ajwxfm/openais_gpts_ranks_daily_update_according_to_the/,2,1707180708.0," It took 2 days to put all together, hope this helps, all data  official data sourced from Openai.

**Top Picks,**

[gptsapp.io/trending-gpts/top-1000-gpts-ranked](https://gptsapp.io/trending-gpts/top-1000-gpts-ranked)

**DALL·E**

[gptsapp.io/trending-gpts/dall-e-gpts](https://gptsapp.io/trending-gpts/dall-e-gpts)

**Writing**

[gptsapp.io/trending-gpts/writing-gpts](https://ptsapp.io/trending-gpts/writing-gpts)

**Productivity**

[gptsapp.io/trending-gpts/productivity-gpts](https://gptsapp.io/trending-gpts/productivity-gpts)

**Research & Analysis**

[gptsapp.io/trending-gpts/research-analysis-gpts](https://gptsapp.io/trending-gpts/research-analysis-gpts)

**Programming**

[gptsapp.io/trending-gpts/programming-gpts](https://gptsapp.io/trending-gpts/programming-gpts)

**Education**

[gptsapp.io/trending-gpts/education-gpts](https://gptsapp.io/trending-gpts/education-gpts)

**Lifestyle**

[gptsapp.io/trending-gpts/lifestyle-gpts](https://gptsapp.io/trending-gpts/lifestyle-gpts)

**Other**

[gptsapp.io/trending-gpts/other-gpts](https://gptsapp.io/trending-gpts/other-gpts)"
215,learnmachinelearning,openai,relevance,2024-02-17 16:14:04,"OpenAI's NEW AI Model ""SORA"" Just SHOCKED EVERYONE| Text To Video Generator",UseCreative4765,False,0.29,0,1at5hzf,https://youtu.be/CgYfgm7kzJo?si=QkwBGklzUuTNxnzG,0,1708186444.0,
216,learnmachinelearning,openai,relevance,2023-11-23 01:18:18,[P] An Open Source version of OpenAI Assistants API,louis3195,False,0.83,4,181pbow,https://twitter.com/louis030195/status/1727495156918861836,0,1700702298.0,
217,learnmachinelearning,openai,relevance,2023-10-10 13:31:04,Explained Simply: OpenAI's breakthrough paper about defeating Dota2 world champions!,mngrwl,False,0.33,0,174lahd,https://mngrwl.medium.com/explained-simply-how-a-i-defeated-world-champions-in-the-game-of-dota-2-f3df90d38a70,9,1696944664.0,
218,learnmachinelearning,openai,relevance,2023-09-10 20:05:36,Two models of OpenAI demonstrated separate personalities,Reasonable_Leg_7405,False,0.67,1,16fa5m0,https://i.redd.it/7uerqe0kihnb1.jpg,0,1694376336.0,
219,learnmachinelearning,openai,relevance,2023-05-19 07:08:51,OpenAI Launches ChatGPT App For iOS Users,vadhavaniyafaijan,False,0.86,52,13lnv1e,https://www.theinsaneapp.com/2023/05/chatgpt-app-for-iphone-and-ipad.html,10,1684480131.0,
220,learnmachinelearning,openai,relevance,2023-09-29 14:00:56,Question about using OpenAI embeddings to cluster my users,ihaveajob79,False,1.0,1,16vcfdj,https://www.reddit.com/r/learnmachinelearning/comments/16vcfdj/question_about_using_openai_embeddings_to_cluster/,2,1695996056.0,"Hi everyone. I'm a curious machine learning aficionado, but I learn as I go and have not a lot of formal training beyond college a while back. I'm working on a process to cluster my users by job title and industry, with the idea of showing them customized training and onboarding material for my app. So the process I follow, at a high level, is:

1. Compute embeddings for the set of (job-title, industry) pairs; I gave about 5000 total. Note that many job-title entries are set to 'unknown'.
2. Cluster the embeddings using k-means (Sklearn library). I tried with various numbers of clusters, between 20 and 200.
3. In the future, when new users arrive, I'd compute their embedding and find the nearest cluster for classification.

However, the clustering feels poor, with lots of outliers such as **<helpline accountibility officer | nonprofit or charitable organization>** in the same cluster as **<regional manager | automotive repair and maintenance>**, and in the same cluster there are lots of medical device manufacturing folks.

So I'm wondering what to try next, and I have some ideas but I have no intuition as to what might work best:

1. Throwing more data for each user, such as their email's domain name, in the hope that the embeddings can extract more meaning
2. Clustering job titles and industries separately, and then using both indexes to classify new users
3. Somehow processing the embeddings to reduce the dimmensionality (how?) so there's less overfitting

What would you do in my shoes? And thanks!"
221,learnmachinelearning,openai,relevance,2023-12-21 18:13:30,Langchain vs. LlamaIndex vs. OpenAI GPTs: Which one should you use?,OnlyProggingForFun,False,0.67,1,18ntbp9,https://youtu.be/g84uWgVXVYg,0,1703182410.0,
222,learnmachinelearning,openai,relevance,2023-11-06 18:23:17,OpenAI Whisper new model Large V3 just released and amazing,CeFurkan,False,1.0,3,17p9a5s,/r/OpenAI/comments/17p93sp/openai_whisper_new_model_large_v3_just_released/,0,1699294997.0,
223,learnmachinelearning,openai,relevance,2023-08-22 22:55:04,OpenAI Python Colab to Summarize and Chat with PDF,starlineventures,False,0.9,7,15yljxz,https://youtu.be/bypGr-Q8RB0,3,1692744904.0,
224,learnmachinelearning,openai,relevance,2023-08-28 15:51:49,Longer Responses from OpenAI's ChatCompletion object?,CartographerSuper506,False,0.5,0,163pqu6,https://www.reddit.com/r/learnmachinelearning/comments/163pqu6/longer_responses_from_openais_chatcompletion/,0,1693237909.0,"Hi all! Was just wondering if there's a way to encourage longer responses from the ChatCompletion object's create method? I know there's a max\_tokens parameter, but it wouldn't seem that would explain the short responses when its default value is set to inf. "
225,learnmachinelearning,openai,relevance,2023-10-01 20:37:56,LLM Firewall - Guardrail Tutorial and Quickstart with OpenAI and Colab,Educational_Grass_38,False,1.0,13,16xc53k,https://m.youtube.com/watch?v=EnwVnz07h1I&pp=ygUSR3VhcmRyYWlsIEZpcmV3YWxs,5,1696192676.0,"Been working on a Firewall for devs to use in a few lines of code, to implement a protective layer around LLMs like OpenAI. Firewall has over 20+ detectors out-of-the-box including prompt injections, harmful content, toxicity and common security vulnerabilities.

Google Colab QuickStart: https://github.com/guardrail-ml/guardrail

Developer Docs: https://docs.useguardrail.com

Would appreciate if you could give a star and provide feedback, thanks!"
226,learnmachinelearning,openai,relevance,2022-10-19 09:27:38,Fixing YouTube Search with OpenAI's Whisper,jamescalam,False,0.95,79,y7xxri,https://www.reddit.com/r/learnmachinelearning/comments/y7xxri/fixing_youtube_search_with_openais_whisper/,13,1666171658.0,"Hi all, I wanted to [build a ""YouTube search"" app](https://www.pinecone.io/learn/openai-whisper/) for some time. Not the typical YouTube search where you return videos, but a YouTube search that returns the specific part of a video that answers your question. With text-based data this is pretty easy, but video/audio is less so.

That was until OpenAI (open sourced?) Whisper, a new SotA for speech-to-text. So I went ahead and built [""Ask YouTube""](https://huggingface.co/spaces/jamescalam/ask-youtube). A little search bar where you can ask technical questions and get the exact most relevant part from a set of videos (for now, the video scope is limited, I'll add more soon).

I explained everything I did to build it in [the linked article](https://pinecone.io/learn/openai-whisper/) and [video](https://youtu.be/vpU_6x3jowg). You could also just grab the app code and replicate it, I don't think it would take long. At a high level it is:

* Download YouTube audio with `pytube`
* Transcribe with OpenAI's Whisper
* Do some data prep
* Encode using Hugging Face / sentence-transformers
* Index and query with Pinecone vector DB

Then I wrapped all of this into a quick Streamlit web app and hosted it all for free on Hugging Face Spaces. One somewhat surprising thing here is absolutely everything was either open source or free, I didn't pay a dime!

Anyway, I hope this is interesting. Let me know what you think!"
227,learnmachinelearning,openai,relevance,2023-07-01 00:43:36,Semantic Video Search using OpenAI's CLIP,vanlifecoder,False,0.86,5,14nh6nm,https://learn.mixpeek.com/what-is-semantic-video-search/,0,1688172216.0,
228,learnmachinelearning,openai,relevance,2023-12-22 19:43:21,Unlocking Intelligent Applications: A Guide to Deploying Azure OpenAI Models with Team GPT,LongjmpingShower,False,0.67,2,18on66a,https://www.reddit.com/r/learnmachinelearning/comments/18on66a/unlocking_intelligent_applications_a_guide_to/,0,1703274201.0,"Unlock the potential of Azure OpenAI models with this concise guide. Learn to seamlessly deploy your own model, enhanced by collaborative efforts within Team GPT, and revolutionize your applications with cutting-edge AI capabilities.  
**Learn more>>>**[https://team-gpt.com/learn/chatgpt-for-work-course/](https://team-gpt.com/learn/chatgpt-for-work-course/)  


https://preview.redd.it/h2lh3edogw7c1.png?width=699&format=png&auto=webp&s=aedb958abc90a58337b11b4e389e1ca896b4dd01

 "
229,learnmachinelearning,openai,relevance,2023-01-25 22:03:50,OpenAI's breakthrough,bradasm,False,0.13,0,10lb504,https://www.reddit.com/r/learnmachinelearning/comments/10lb504/openais_breakthrough/,0,1674684230.0,[https://twitter.com/make\_mhe/status/1618255363580755968](https://twitter.com/make_mhe/status/1618255363580755968)
230,learnmachinelearning,openai,relevance,2020-08-05 10:58:02,image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model,OnlyProggingForFun,False,0.97,637,i437om,https://www.youtube.com/watch?v=FwXQ568_io0,46,1596625082.0,
231,learnmachinelearning,openai,relevance,2023-04-17 18:43:11,OpenAI Demo Code Isn't Working?,Bodesterine555,False,1.0,1,12psbuy,https://www.reddit.com/r/learnmachinelearning/comments/12psbuy/openai_demo_code_isnt_working/,1,1681756991.0,"Hi there, I've used OpenAI's demo code (for GPT models) a number of times before, never had issues. Today I wanted to remind myself how everything works for a new project, and an unedited version (I added my API key, that's it) isn't working. I'm getting the error, ""Unexpected token '<', ""<!DOCTYPE ""... is not valid JSON""

&#x200B;

Any advice or ideas? I'm not a good programmer, I must be making a simple mistake here

https://preview.redd.it/82uzzm9ephua1.png?width=914&format=png&auto=webp&s=80bb05aa5b4e517fa20c280e045bfbca803b070e"
232,learnmachinelearning,openai,relevance,2023-06-17 15:49:30,How to Build LLM Applications With LangChain and Openai,mwitiderrick,False,0.8,6,14buddi,https://www.reddit.com/r/learnmachinelearning/comments/14buddi/how_to_build_llm_applications_with_langchain_and/,5,1687016970.0,"LangChain is one the most popular tools for building large language model applications.   You can use LangChain to build various applications, such as question-answering systems and chatbots.   Some of the modules in Langchain include: 

**•** **Models** for supported models and integrations 

**• Prompts** for making it easy to manage prompts 

**• Memory** for managing the memory between different model calls 

**• Indexes** for loading, querying, and updating external data 

**•Chains** for creating subsequent calls to an LLM

 **• Agents** to develop applications where the LLM model can direct itself 

**• Callbacks** for logging and streaming the intermediate steps in a chain 

Today over a thousand subscribers of mlnuggets got a tutorial on how to use LangChain and other language models, such as the ones from Openai, to create a system to transcribe and ask questions to YouTube videos. 

Check it out [https://www.machinelearningnuggets.com/how-to-build-llm-applications-with-langchain-and-openai/](https://www.machinelearningnuggets.com/how-to-build-llm-applications-with-langchain-and-openai/)"
233,learnmachinelearning,openai,relevance,2023-04-22 05:51:13,Integrating Google search into OpenAI models like GPT-4,Ghost25,False,1.0,15,12uwd8p,https://www.reddit.com/r/learnmachinelearning/comments/12uwd8p/integrating_google_search_into_openai_models_like/,8,1682142673.0,"Thought I'd share an explanation of how I implemented Google search into my GPT-4 based chatbot.

Github here: https://github.com/sgreenb/pico_assistant

One extremally simple modification that dramatically improves the ability of a GPT to answer questions: letting it Google stuff.

Here’s a demo:

https://imgur.com/ZR6hvLg 1

The implementation works like this.

1. A user enters an input.
2. An agent called “Executive” looks at the input and decides if an API like Spotify, Twillio, or Gmail is needed or if it can be answered by the chatbot alone.
3. If the chatbot is needed the input is first sent to a Google agent. The Google agent’s system message looks like this:

```
{""role"":""system"", ""content"": ""You analyze a user's input to a large language model with \
training data that cuts off at September 2021. The current year is 2023. You decide how \
likely it is that a user's request will benefit from a Google search to help address the\
question. Respond with a number in the range 1-10, where 1 is very unlikely that a \
Google search would be beneficial, and 10 meaning a Google search is highly necessary.""}
```

This is quite fast, since it only needs to generate one or two tokens.

If the output is above some threshold (say 7), then we call another agent, the query agent, otherwise we return False and default to the normal chat agent.

```
    google_probability = int(completion.choices[0].message.content)
    if google_probability >= cutoff:
        search_results = trim_text(search_and_scrape(prompt))
        query_with_context = prompt + str(search_results)
        print(""\nPico: "", end='', flush=True)
        response = query_agent_stream(query_with_context)
        return response
    else:
        return False
```

When we call the query agent, we feed it the first part of a Google search we get from searching the input. We get that from the very simple trim_text and search_and_scrape functions that look like this:

```

def search_and_scrape(query):
    try:
        headers = {
            ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3""
        }
        url = f""https://www.google.com/search?q={query}""
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text()
            cleaned_text = ' '.join(text.split())
            return cleaned_text
        else:
            print(f""Failed to fetch search results for query: {query}, status code: {response.status_code}"")
            return None

    except Exception as e:
        print(f""Error fetching search results for query: {query}, error: {e}"")
        return None

def trim_text(text, start_index = 450, length=1500):
    return text[start_index:start_index + length]
```

The query agent has this system message:

```
{""role"":""system"", ""content"": ""You answer a user's question, given some text as context to help\
answer the question. The user request will be followed by the context. The context given is\
from the user's Google search results, it is current and up to date.\
Do not contradict the contents of the given text in your answer.""}
```

And that’s it. You can change the cutoff threshold or get more sophisticated with fetching web results. I hope you find this useful."
234,learnmachinelearning,openai,relevance,2023-11-08 16:56:45,[P] Top 5 AI Announcements (and Implications) from the 1st OpenAI DevDay,vykthur,False,0.83,4,17qq0z9,https://www.reddit.com/r/learnmachinelearning/comments/17qq0z9/p_top_5_ai_announcements_and_implications_from/,0,1699462605.0,"OpenAI recently had the first   developer day, featuring several new announcements

https://preview.redd.it/ep1scxynm5zb1.png?width=1456&format=png&auto=webp&s=4be58601b9a0fb9bcc1ff17d25560257f895dca2

&#x200B;

Full post here: [https://newsletter.victordibia.com/p/top-5-ai-announcements-and-implications](https://newsletter.victordibia.com/p/top-5-ai-announcements-and-implications) 

TLDR.

* **💰📉 Cost Reduction**: The new GPT-4 and GPT-3.5 Turbo models are more capable yet cost less. 🤯🤯.
* **📈🧠 Improved Model Capabilities**: GPT-4 now includes a 128K token version (300 pages of text), features an updated knowledge cutoff (previously April 2021, now April 2023), and offers improved function calling.
* **🎛️🔧 Improved Model Control**: The new model series can generate valid JSON-formatted responses using a \`response\_format\` parameter and supports reproducible results through a seed parameter. Additionally, there is upcoming support for accessing log probabilities of generated tokens.
* **🤖🔗Agents: The Assistant API**: This API supports the **creation of agents** that can utilize external knowledge (RAG), **act** via tools (e.g., code execution and function calling), and maintain infinitely long conversations through Threads. All of this in a unified api for building agents.
* **🤖🛍️Agents: GPTAgents and Agent Store**: OpenAI will create a store where developers can bundle and share GPT agents with some revenue sharing. An Agent here is an LLM+Knowledge+Tools. 

&#x200B;

**High Level Implications** 

\- Cost reductions could make these models more practical to use (cost competitive with running smaller models at scale). 

&#x200B;

[Pricing of OpenAI models show cost reductions in successive GPT models from March - Nov 2023 . Davinci Source https:\/\/openai.com\/pricing](https://preview.redd.it/hfvytscem5zb1.png?width=1456&format=png&auto=webp&s=516a263a9b98165043c7b41946b70cce791cc861)

&#x200B;

&#x200B;

https://preview.redd.it/skio4eohm5zb1.png?width=1196&format=png&auto=webp&s=57299651d05a9469a90506e0b4724649c834b6ed

\- The Assistant API facilitates prototyping complex agent workflows, eliminating the extensive infrastructure work that was previously burdensome, such as implementing a RAG workflow, managing long conversation contexts, and executing code.

\- The capability to generate output constrained to a valid JSON format, the option to set a seed for reproducibility, and access to log probabilities are significant steps toward addressing **reliability issues** with large language models (LLMs).

While some of the ideas introduced may not be entirely new, they certainly represent significant quality-of-life improvements for engineers attempting to build Generative AI apps."
235,learnmachinelearning,openai,relevance,2022-04-08 15:20:26,OpenAI 's new model DALL·E 2 is amazing!,OnlyProggingForFun,False,0.94,196,tz5x2f,https://youtu.be/rdGVbPI42sA,8,1649431226.0,
236,learnmachinelearning,openai,relevance,2023-05-06 15:50:19,Exploring text embeddings with OpenAI and Seinfeld,AlphaX,False,1.0,1,139tm0j,https://medium.com/@alex.pusch/exploring-text-embeddings-with-openai-and-seinfeld-68753f2bfd9e,0,1683388219.0,
237,learnmachinelearning,openai,relevance,2023-04-29 09:21:53,Prompt Engineering Free Course For Beginners By OpenAI And Deep Learning AI,vadhavaniyafaijan,False,0.78,51,132o8tt,https://www.theinsaneapp.com/2023/04/free-prompt-engineering-course-for-beginners.html,7,1682760113.0,
238,learnmachinelearning,openai,relevance,2023-11-09 19:16:20,Overcame the OpenAI Assistant API Learning Curve Post-DevDay – Our Detailed Guide Inside,davorrunje,False,1.0,13,17rkmfw,https://www.reddit.com/r/learnmachinelearning/comments/17rkmfw/overcame_the_openai_assistant_api_learning_curve/,1,1699557380.0,"Hello AI enthusiasts,

Navigating the new Assistant API after the recent OpenAI DevDay? We know the official docs aren't quite there yet, and it can be a bit like finding your way in the dark.

To help out, we've put together a detailed walkthrough of our own experience – the missteps, the breakthroughs, and everything in between.

We believe this resource can save you some time and frustration. If you're planning to work with the Assistant API, give our guide a read and get a head start: [Our Guide to the Assistant API](https://airt.hashnode.dev/function-calling-and-code-interpretation-with-openais-assistant-api-a-quick-and-simple-tutorial)

Looking forward to your feedback and hope it helps!"
239,learnmachinelearning,openai,relevance,2022-09-23 13:46:55,Created a GUI for OpenAI's Whisper Using Gradio,ImplodingCoding,False,0.95,69,xly2gp,https://v.redd.it/6djgfjpp4mp91,9,1663940815.0,
240,learnmachinelearning,openai,relevance,2023-11-08 16:15:30,Function Calling and Code Interpretation with OpenAI's Assistant API: A Quick and Simple Tutorial,davorrunje,False,1.0,5,17qp4ni,https://airt.hashnode.dev/function-calling-and-code-interpretation-with-openais-assistant-api-a-quick-and-simple-tutorial,0,1699460130.0,
241,learnmachinelearning,openai,relevance,2023-08-26 01:51:31,Mail me a chunk of your logs to analyze root@email-openai.com,Reasonable_Leg_7405,False,0.25,0,161hzgb,https://i.redd.it/yd7u0e3u1dkb1.jpg,0,1693014691.0,
242,learnmachinelearning,openai,relevance,2023-05-30 13:11:21,Set Up OpenAI's CLIP on Amazon SageMaker for Inference,vanlifecoder,False,0.93,11,13vpxzn,https://rise.climb.dev/clip-on-sagemaker/,2,1685452281.0,
243,learnmachinelearning,openai,relevance,2023-03-28 12:51:54,I am creating a tool that uses OpenAI models and an OCR to translate screenshots,K-RT-DEV,False,0.87,39,124nsy8,https://www.reddit.com/r/learnmachinelearning/comments/124nsy8/i_am_creating_a_tool_that_uses_openai_models_and/,15,1680007914.0,"Currently, the OCR is specifically for translating from Japanese, but I plan to add a range of OCRs and different translators to the system to accommodate the user's needs.  


https://i.redd.it/8ymk99uf8hqa1.gif

My idea is to have a system that leverages OpenAI models for *bagging*. This way, I can combine the output of multiple OCRs  to increase the accuracy of the recognized characters. Similarly, I can combine the output of multiple translators for the same phrase to improve the final result . Chat models can be particularly useful in providing **context** and a translation history to help the system understand how to conjugate phrases for translation.   


You can find the source code and an executable version on the [project's GitHub](https://github.com/K-RT-Dev/VGT)"
244,learnmachinelearning,openai,relevance,2023-05-30 05:43:47,How to overcome OpenAI fine-tuning training data token limit?,Professor-Pumpkin,False,0.57,1,13vhs97,https://www.reddit.com/r/learnmachinelearning/comments/13vhs97/how_to_overcome_openai_finetuning_training_data/,0,1685425427.0,"I am using curie model to fine-tune in Python. Basically, I am passing the training data of form `{""prompt"":""completion""}`and I have 736 prompt-example pairs. My example completions are pretty long - I aim at generating a JSON file based on a description of fixed form. The fine-tune reports to be created, however, when retrieving the fine-tune model key via

    retrieve_response = openai.FineTune.retrieve(id=""fine_tune_model_id"") print(retrieve_response)  

I get the following messsage:

    {
      ""created_at"": 1685346828,
      ""events"": [
        {
          ""created_at"": 1685346828,
          ""level"": ""info"",
          ""message"": ""Created fine-tune: fine_tune_model_id"",
          ""object"": ""fine-tune-event""
        },
        {
          ""created_at"": 1685346879,
          ""level"": ""info"",
          ""message"": ""Error: The training file does not contain enough examples that fit within the 2048 tokens allowed for this model."",
          ""object"": ""fine-tune-event""
        }
    ...
    
    Cross-posted on https://stackoverflow.com/questions/76355721/openai-fine-tuning-training-data-exceeds-the-token-limit 

and thus the status failed, but for the ""training files"" object the status is proceeded (pretty obvious).

Is there a way to overcome the error above?

I do have an OpenAI subscription."
245,learnmachinelearning,openai,relevance,2023-03-01 15:58:29,Experimenting with repurposing OpenAI Whisper for Speaker Prediction,eleanor_rigby_2,False,1.0,1,11f7dwq,https://www.reddit.com/r/learnmachinelearning/comments/11f7dwq/experimenting_with_repurposing_openai_whisper_for/,0,1677686309.0,"OpenAI recently released a SOTA speech translation model, which can transcribe any audio clip into text. But can this model, given how powerful it is for this speech task, be utilized to provide zero-shot audio features for speaker prediction?

&#x200B;

Usually for speaker prediction there are signal processing approaches. Or even deep learning approaches designed to represent an audio signal in a latent space and then perform prediction on these features. But it looks like OpenAI Whisper, to some extent, can be used as it is to provide these latent features, without any re-training, which can then be used for speaker prediction.

&#x200B;

I perform some analysis [here](https://sidhantls.github.io/lexpod-speaker-prediction/) using Lex Fridman Podcasts. Feel free to share your thoughts

&#x200B;"
246,learnmachinelearning,openai,relevance,2023-01-29 21:14:13,Create a Serverless Search Engine using the OpenAI Embeddings API,sopmac21379,False,0.95,54,10oitli,https://medium.com/sopmac-ai/create-a-serverless-search-engine-using-the-openai-embeddings-api-50e5ac8ca6e3,1,1675026853.0,
247,learnmachinelearning,openai,relevance,2022-10-06 01:31:54,OpenAI's Most Recent Model: Whisper (explained),OnlyProggingForFun,False,0.94,16,xwsiag,https://youtu.be/uFOkMme19Zs,2,1665019914.0,
248,learnmachinelearning,openai,relevance,2019-10-23 23:58:05,OpenAI plays hide and seek and breaks the game. (Reinforcement Learning),UnintelligibleThing,False,0.97,337,dm86ay,https://www.youtube.com/watch?v=Lu56xVlZ40M,19,1571875085.0,
249,learnmachinelearning,openai,relevance,2023-06-19 16:38:37,I wanted to use OpenAI API but it's a paid service. What are alternatives for this?,Beginning-Scholar105,False,0.64,4,14djjsj,https://www.reddit.com/r/learnmachinelearning/comments/14djjsj/i_wanted_to_use_openai_api_but_its_a_paid_service/,10,1687192717.0,I have tried some Open Source Hugging Face LLMs but they are very large in size and also need heavy machine to run those LLMs.  If you know any other alternatives then please let me know.
250,learnmachinelearning,openai,relevance,2023-04-17 23:13:45,Difference between HuggingFace pre-trained model and OpenAI's API,raikirichidori255,False,1.0,3,12q110r,https://www.reddit.com/r/learnmachinelearning/comments/12q110r/difference_between_huggingface_pretrained_model/,1,1681773225.0,"I've a novice at LLMs and I've been learning a little more about them recently. I know a few months ago, ChatGPT released it's on API that can be integrated within apps for $0.02/token. However, I have been using HuggingFace pretrained model for a lot of modeling tasks, and I was wondering how this API is any different than just importing the openai-gpt model from HuggingFace.

Sorry if this is a bad question, I'm just starting out."
251,learnmachinelearning,openai,relevance,2023-05-02 17:58:29,How to Fine-Tune an OpenAI ML Model with Node.js,lizziepika,False,0.67,1,135vbu9,https://www.twilio.com/blog/finetune-openai-ml-model-node,0,1683050309.0,
252,learnmachinelearning,openai,relevance,2023-07-16 12:25:22,"Cohere LLM - Free alternative to OpenAI's ChatGPT, No credit card needed",gihangamage,False,0.43,0,1514zp8,https://www.reddit.com/r/learnmachinelearning/comments/1514zp8/cohere_llm_free_alternative_to_openais_chatgpt_no/,0,1689510322.0,"In this video, we are discussing how to use Cohere LLM free version for text generation, embedding generation and document question answering. 

[https://youtu.be/isKk3kGq-n0](https://youtu.be/isKk3kGq-n0) "
253,learnmachinelearning,openai,relevance,2022-11-03 13:40:24,How to install and deploy OpenAI Whisper,juliensalinas,False,1.0,5,yl35gk,https://www.reddit.com/r/learnmachinelearning/comments/yl35gk/how_to_install_and_deploy_openai_whisper/,0,1667482824.0,"Hello,

If you are interested in automatic speech recognition (speech-to-text), you are most likely going to try OpenAI Whisper.

If that's the case, here is an article I just made about how to install and deploy Whisper: [https://nlpcloud.com/how-to-install-and-deploy-whisper-the-best-open-source-alternative-to-google-speech-to-text.html](https://nlpcloud.com/how-to-install-and-deploy-whisper-the-best-open-source-alternative-to-google-speech-to-text.html?utm_source=reddit&utm_campaign=h4d7a9cc-3816-11ed-a261-0242ac120002)

I hope it will be useful!

Julien"
254,learnmachinelearning,openai,relevance,2023-04-12 16:42:28,"How to Build an Ecommerce Chatbot with Redis, LangChain, and OpenAI",yourbasicgeek,False,0.92,10,12jrym1,https://redis.com/blog/build-ecommerce-chatbot-with-redis/,2,1681317748.0,
255,learnmachinelearning,openai,relevance,2023-06-18 15:56:44,"I made FableForge: Text Prompt to an Illustrated Children’s Book using OpenAI Function Calls, Stable Diffusion, LangChain, & DeepLake",AverageKanyeStan,False,0.96,201,14cnuz4,https://v.redd.it/5p2apjnsts6b1,6,1687103804.0,
256,learnmachinelearning,openai,relevance,2023-08-18 05:00:05,"OpenAI Proxy Server for Llama2, GPT-4, Claude2 with User-based rate limiting, Key management, Logging,Cache",VideoTo,False,0.8,3,15uarkx,https://www.reddit.com/r/learnmachinelearning/comments/15uarkx/openai_proxy_server_for_llama2_gpt4_claude2_with/,2,1692334805.0,"**tldr;** We’re open sourcing our proxy server to call 50+ LLM models with logging, caching, key management, rate-limiting: [https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-...](https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-server/readme.md)

\--

Hi r/learnmachinelearning,

I’m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, Cohere, Anthropic, Hugging face API Endpoints: [https://github.com/BerriAI/litellm/](https://github.com/BerriAI/litellm/)

We’re open sourcing our implementation of liteLLM proxy: [https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-...](https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-server/readme.md)

TLDR: It has one API endpoint /chat/completions and standardizes input/output for 50+ LLM models + handles logging, error tracking, caching, streaming

**What can liteLLM proxy do?** \- It’s a central place to manage all LLM provider integrations

\- **Consistent Input/Output Format** \- Call all models using the OpenAI format: completion(model, messages) - Text responses will always be available at \['choices'\]\[0\]\['message'\]\['content'\]

\- **Error Handling** Using Model Fallbacks (if GPT-4 fails, try llama2)

\- **Logging** \- Log Requests, Responses and Errors to Supabase, Posthog, Mixpanel, Sentry, Helicone

\- Token Usage & **Spend** \- Track Input + Completion tokens used + Spend/model

\- **User-based rate limiting** \- limit usage for bad actors

\- **Caching** \- Implementation of Semantic Caching

\- **Streaming & Async Support** \- Return generators to stream text responses

You can deploy liteLLM to your own infrastructure using Railway, GCP, AWS, Azure

Happy completion() !

https://i.redd.it/fhgifwb8wsib1.gif"
257,learnmachinelearning,openai,relevance,2022-11-15 21:58:49,Best way to do distributed inference of OpenAI Whisper?,SCUSKU,False,1.0,2,ywavuo,https://www.reddit.com/r/learnmachinelearning/comments/ywavuo/best_way_to_do_distributed_inference_of_openai/,3,1668549529.0,"I have 100 episodes of a podcast that I want to transcribe using OpenAI's Whisper model. I could just use a single machine and run this serially, but this is slow, and also doesn't scale.

What is the best way to go about running distributed inference? I have read a bit about Spark but am not convinced that this would be the right tool. The best solution I can think of right now is to do something with Kubernetes + autoscaling, but I'm not sure that's a good idea either."
258,learnmachinelearning,openai,relevance,2023-08-15 15:09:49,How to run OpenAI CLIP with UI for Image Retrieval and Filtering your dataset - Supervisely,tdionis,False,1.0,1,15rvdih,https://supervisely.com/blog/openai-clip-for-image-retrieval-and-filtering-computer-vision-datasets-tutorial/,0,1692112189.0,
259,learnmachinelearning,openai,relevance,2023-05-11 02:01:17,OpenAI & GPT Dictionary of Vocabulary. Generative AI Terms To Know In 2023,OnlyProggingForFun,False,0.67,1,13ea36c,https://youtu.be/q4G6X09NEu4,0,1683770477.0,
260,learnmachinelearning,openai,relevance,2023-05-02 17:15:02,How to Fine-Tune OpenAI Language Models with Noisily Labeled Data (37% error reduction),cmauck10,False,0.92,9,135u3vt,https://www.reddit.com/r/learnmachinelearning/comments/135u3vt/how_to_finetune_openai_language_models_with/,0,1683047702.0,"Hello Redditors! 

It's pretty well known that LLMs have solidified their place at the forefront of natural language processing, and are constantly pushing the boundaries of what is possible in terms of language understanding and generation.

I spent some time playing around with the OpenAI fine-tuning API and I discovered that noisy data still has drastic effects even on powerful LLMs like Davinci.

[Improving fine-tuning accuracy by improving data quality.](https://preview.redd.it/v5kro8wzagxa1.png?width=1085&format=png&auto=webp&s=39e0309aa94048dc08a0879d99008f00ec32fd9e)

I wrote up a [quick article](https://www.kdnuggets.com/2023/04/finetuning-openai-language-models-noisily-labeled-data.html) in KDNuggets that shows how I used data-centric AI to automatically clean the noisy data in order to fine-tune a more robust OpenAI LLM. The resulting model has 37% fewer errors than the same LLM fine-tuned on the noisy data.

Let me know what you think!"
261,learnmachinelearning,openai,relevance,2022-11-02 11:55:31,"What is ""previous text tokens"" in the OpenAI Whisper",Pritish-Mishra,False,1.0,3,yk37d3,https://www.reddit.com/r/learnmachinelearning/comments/yk37d3/what_is_previous_text_tokens_in_the_openai_whisper/,0,1667390131.0,"&#x200B;

https://preview.redd.it/73xy4yz30jx91.png?width=556&format=png&auto=webp&s=2b4c00c9d7b921648349c32c60d88e5b83a5f0f7

 

I stumbled upon this diagram while reading Whisper's paper. There is a ""previous text tokens"" before the ""Start of Transcript (SOT)"" special token, and I'm not sure what that means.

According to my understanding:

Because the transformer encoder only accepts audio files of up to 30 seconds in length, we need to divide longer audio files into 30-second chunks. 

So, ""previous text tokens"" will include ALL of the text that whisper predicted previously?

Thanks for your time."
262,learnmachinelearning,openai,relevance,2023-06-19 17:49:06,"GPT Weekly - 19the June Edition - OpenAI's function calling, Meta's free LLM, EU Regulation and more.",level6-killjoy,False,0.93,20,14dlfas,https://www.reddit.com/r/learnmachinelearning/comments/14dlfas/gpt_weekly_19the_june_edition_openais_function/,2,1687196946.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 news - OpenAI’s updates, Meta’s upcoming free LLM and EU Regulation
* 🗞️Interesting reads include PSA about protecting your keys, The GPT ouroboros, Reddit - OpenAI’s moat, and more..
* 🧑‍🎓Learning includes a Step-by-step guide from a non-technical founder who launched his MVP, Chatbot for your Gdrive and more

# 🔥Top 3 AI news in the past week

## 1. OpenAI: New Pricing, Models, & Functions

OpenAI has been on a roll. Last week we saw the release of [OpenAI best practice on using GPT.](https://gptweekly.beehiiv.com/p/making-gpt-openais-tactics-better-results) This week we saw some amazing updates. Three major buckets were:

First, the price decreases for both embeddings and GPT-3.5 tokens. 

Second, new models for gpt-4 and gpt-3.5. A new longer context model for gpt-3.5.

Third, a new function calling capability. 

**Why is it important?** Previously, the output from OpenAI was all text. So, calling an external API from GPT was quite difficult. You had to parse the text data and things were often incorrect.  Langchain created the Agents and Tools feature to tackle this problem. It was still unreliable and prone to issues. 

Now you get native support to generate a fixed format output. You can use the output to generate functional calls and also pass functions which need to be called. For example, if your app has multiple API endpoints then you can use GPT to generate the API calls with parameters. You can also pass the endpoints as function calls to ensure the correct function is executed. 

This functionality can further be used to [generate structured data (JSON) out of GPT](https://yonom.substack.com/p/native-json-output-from-gpt-4). So, you can generate data from GPT and load it into your backend. 

**What’s next?** This functionality allows turning natural language responses into structured data. This can be used to create “intelligent” backends using LLMs. We might see implementations in no-code tools to allow more robust and natural-language tools for non-technical folks.

The structured data process goes both ways. You can also feed structured data into GPT for better responses. 

This feature also has its share of issues. Function calling suffers from the same prompt injection issues. Malicious actors can pass malicious code in function or the responses. For example, creation of queries using functions might contain malicious code to delete data. Without proper user validation this code will be executed automatically and delete data. So, using LLM as the back-end layer needs proper security implementation. 

## 2. Meta's LLM: Commercial Use Ahead

Llama has been a boon for the open source community. Many of the open source models rely on Llama. The issue is that Llama is research-only and cannot be used commercially. So, no one can use it to build any product.

[Meta is now working on the next version of the model. This model will be available for commercial use.](https://www.theinformation.com/articles/meta-wants-companies-to-make-money-off-its-open-source-ai-in-challenge-to-google) This is in stark contrast to both OpenAI and Google. Both safe-guarde their models and make it available through API. 

**Why is it important?** Certain industries cannot use LLM APIs because of strict restrictions on data privacy. These companies would want to run their own instance of a foundational model. 

A commercially available foundational model is also going to help people who want to keep their “API call” costs next to 0. 

A commercially available free-for-all model will also help push the open source community further. Just like Llama.

**What’s next?** Sam Altman has said OpenAI didn’t release GPT-3 as open-source because they [didn’t think people would be able to run it.](https://gptweekly.beehiiv.com/p/peek-openais-future) Now [OpenAI is working on an open-source model.](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) This is going to be weaker than GPT-4. 

Let the battle of LLMs begin.  

## 3. EU's Proposed Legislation and Its Impact on AI Usage

[The EU parliament voted to move ahead with the E.U. AI Act.](https://www.washingtonpost.com/technology/2023/06/14/eu-parliament-approves-ai-act/) This act aims to ensure consumer protection against the dangers of AI.  

**Why is it important?** [OpenAI](https://gptweekly.beehiiv.com/p/peek-openais-future) and [Sam Altman](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) want regulations for models. They have proposed a IAEA-type of agency to stop the proliferation of LLM models. As per OpenAI, all models should be regulated and monitored. The suggestion of a license based regulation has led to significant backlash. Many people have called it “regulatory capture” - with the aim of shutting down competing LLMs.

[Licensing based regulations might not really be effective.](https://aisnakeoil.substack.com/p/licensing-is-neither-feasible-nor)

The EU is approaching regulation from a different angle. It doesn’t focus on how models are developed. Rather focuses on how AI will/can be used. They have broken down use cases into 4 categories - unacceptable (prohibited), high, medium and low risk. For example, 

Building a [Pre-Crime software](https://en.wikipedia.org/wiki/Pre-crime#:~:text=Pre%2Dcrime%20(or%20precrime),on%20crimes%20not%20yet%20committed.) to predict crimes? Building a [Social credit system](https://en.wikipedia.org/wiki/Social_Credit_System)?  Unacceptable.

Using tools to influence elections or recommendation algorithms? High (Highly regulated).

Using generative AI tools to create text or images on news sites? Medium (Add label that the content is AI generated) 

AI providers also need to disclose their training source.

To me this sounds like good legislation. What do you guys think?

But, OpenAI has warned that EU regulations might force them to pull out completely.

**What’s next?** The disclosure requirements might help various publishing companies. [AI and media companies are in talks to pay for training data](https://www.ft.com/content/79eb89ce-cea2-4f27-9d87-e8e312c8601d). Google has been leading the charge. 

Additionally, [OpenAI and Deepmind will open their models for safety and research purposes to the UK government.](https://www.politico.eu/article/openai-deepmind-will-open-up-models-to-uk-government/) 

# 🗞️10 AI news highlights and interesting reads

1. **PSA:** If you are using Repl to write code, you might want to check your OpenAI API keys. If you have left them embedded then [people can pirate and steal the keys. ](https://www.vice.com/en/article/93kkky/people-pirating-gpt4-scraping-openai-api-keys)
2. LLMs rely on human annotation or human feedback to learn. And one way to generate human annotation is crowdsourcing. But what if the crowdsource human annotators use LLMs? [Research shows 33-46% workers used LLMs](https://arxiv.org/abs/2306.07899). So, basically we go from Human -> AI -> Human -> AI. The AI ouroboros. Researchers also say [generated data to train models might cause serious issue.  ](https://arxiv.org/abs/2305.17493)
3. All the talks about [moats](https://gptweekly.beehiiv.com/p/googles-startling-leaked-memo-george-hinton-mojo) \- [Reddit might be OpenAI’s \*future\* moat](https://www.cyberdemon.org/2023/06/14/reddit-moat.html). Given the amount of complaints about how [Google search](https://www.techradar.com/opinion/the-reddit-b) [experience has deteriorated](https://www.theverge.com/2023/6/13/23759942/google-reddit-subreddit-blackout-protests) [during the blackout](https://news.ycombinator.com/item?id=36345345), this might be true?
4. [Doctors are using ChatGPT](https://www.nytimes.com/2023/06/12/health/doctors-chatgpt-artificial-intelligence.html) but not to diagnose.Rather to be [more empathetic](https://inflecthealth.medium.com/im-an-er-doctor-here-s-how-i-m-already-using-chatgpt-to-help-treat-patients-a023615c65b6). [We discussed this just a month ago](https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?utm_source=gptweekly.beehiiv.com&utm_medium=referral&utm_campaign=google-s-startling-leaked-memo-george-hinton-mojo-and-more). And guess where the data for this study came from? Reddit AskDocs. Moat FTW?!
5. Beatles to make a comeback…[using Generative AI](https://www.semafor.com/article/06/13/2023/paul-mccartney-beatles-song-ai). 
6. [SnapFusion - Text to Image diffusion on mobile phones.](https://snap-research.github.io/SnapFusion/)
7. Large context lengths are important for better GPT experience. [The secret sauce for 100k context length](https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c). 
8. There is a lot of bad AI research out there. Some border on snake oil. Most AI “research” should be double checked and challenged. A new research on huggingface said that [GPT-4 can ace MIT curriculum](https://huggingface.co/papers/2306.08997). Now someone is replicating the results and say that [GPT-4 can’t beat MIT. ](https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864)
9. Are we seeing peak AI? Especially when people from Deepmind and Meta are involved? [Mistral AI raised $113 million in seed round with no product.](https://techcrunch.com/2023/06/13/frances-mistral-ai-blows-in-with-a-113m-seed-round-at-a-260m-valuation-to-take-on-openai/) Some might say this funding is for the team and the team is really solid. The issue though is whether the valuation is justified when OpenAI and Google already have a head start.
10. [The AI Hype Wall of Shame.](https://criticalai.org/the-ai-hype-wall-of-shame/) \- Collection of articles which mislead people about AI in various aspects.

# 🧑‍🎓3 Learning Resources

1. [Building and Launching a company using GPT-4](https://sabol.io/c7921c7bbd8c4982aacbd2b71a8b9bb3) with prompts. (The author didn’t know how to code but created and launched the MVP in a month).  
2. Chatbot for your Gdrive - [https://www.haihai.ai/gpt-gdrive/](https://www.haihai.ai/gpt-gdrive/)
3. Building ChatGPT plugin using Supabase - https://supabase.com/blog/building-chatgpt-plugins-template

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
263,learnmachinelearning,openai,relevance,2023-03-02 07:24:57,Good news for builders! OpenAI Releases APIs To ChatGPT and Whisper,LesleyFair,False,0.5,0,11fwcj2,https://www.reddit.com/r/learnmachinelearning/comments/11fwcj2/good_news_for_builders_openai_releases_apis_to/,0,1677741897.0,"If you were as disappointed as I was when you saw that access to Meta's LLaMA models is limited to researchers, you are going to like this.  


[APIs to ChatGPT and OpenAI's speech-to-text model whisper](https://openai.com/blog/introducing-chatgpt-and-whisper-apis) are available as of yesterday. Through system-wide optimizations, they claim to have reduced inference costs by 90%. They now price ChatGPT at $0.002 per 1000 tokens. Dedicated instances are available for speedup and make economic sense if you process \~450M tokens a day.  


Machine learning progress continues to be as fast as a banana peal skating on warm vaseline. 

If you found this useful and want to stay in the loop, consider subscribing to The Decoding. I send out a weekly 5-minute newsletter that keeps professionals in the loop about machine learning and the data economy. [Click here to subscribe!](https://thedecoding.net/)"
264,learnmachinelearning,openai,relevance,2023-09-20 19:08:05,"Say Goodbye to Servers, and Expensive middle man apps. OpenAI direct bring your own key and a iSH Alpine Linux Shell",Reasonable_Leg_7405,False,0.38,0,16ntm4j,https://i.redd.it/vt202cohlgpb1.jpg,5,1695236885.0,
265,learnmachinelearning,openai,relevance,2022-09-22 17:26:51,"How to use OpenAI's Whisper (and some accuracy, runtime, and cost benchmarks)",SleekEagle,False,1.0,5,xl7lpu,https://www.reddit.com/r/learnmachinelearning/comments/xl7lpu/how_to_use_openais_whisper_and_some_accuracy/,8,1663867611.0,"Hey everyone! I'm sure many of you know that OpenAI released Whisper yesterday- an open source speech recognition model with weights available.

I wrote a guide on [how to run Whisper](https://www.assemblyai.com/blog/how-to-run-openais-whisper-speech-recognition-model/) that also provides some benchmarks on accuracy, inference time, and cost. Let me know what you think :)"
266,learnmachinelearning,openai,relevance,2022-09-23 16:28:02,OpenAI Whisper: SOTA Speech To Text With Microphone Demo,l33thaxman,False,0.8,3,xm26m6,https://www.reddit.com/r/learnmachinelearning/comments/xm26m6/openai_whisper_sota_speech_to_text_with/,0,1663950482.0,"OpenAI has released a Speech To Text model that nears human performance.  This video goes over the basics of the model, as well as how to run it with a microphone.

[https://youtu.be/nwPaRSlDSaY](https://youtu.be/nwPaRSlDSaY)"
267,learnmachinelearning,openai,relevance,2022-09-22 16:14:37,"Whisper, a general-purpose speech recognition model by OpenAI with Gradio Demo",Illustrious_Row_9971,False,0.95,39,xl5pky,https://i.redd.it/uc18wju5qfp91.png,3,1663863277.0,
268,learnmachinelearning,openai,relevance,2022-11-28 01:26:10,How can a beginner make a beginners version of OpenAI's Playground?,Extension_Fan_8904,False,0.72,3,z6ixg4,https://www.reddit.com/r/learnmachinelearning/comments/z6ixg4/how_can_a_beginner_make_a_beginners_version_of/,1,1669598770.0,"I want to be able to create a prompt and have it respond with a completion that attempts to match the context or pattern that was provided. 

How can I do this as a beginner? Or is their a beginners version of this that I can do? How do I start? What do I need to learn?"
269,learnmachinelearning,openai,relevance,2023-03-16 00:03:32,OpenAI's GPT 4 is out and it's multimodal! What we know so far,gordicaleksa,False,0.3,0,11sdxhz,https://www.youtube.com/watch?v=FY9Nlkoq4GI,0,1678925012.0,
270,learnmachinelearning,openai,relevance,2022-07-16 16:08:58,How OpenAI Reduces risks for DALL·E 2,OnlyProggingForFun,False,0.67,2,w0k1zg,https://youtu.be/qh3_DnteGD0,0,1657987738.0,
271,learnmachinelearning,openai,relevance,2023-05-27 10:54:16,How To Build A ChatPDF App in Just 14 Minutes using Python! | Without OpenAI API,AeroArtz,False,0.56,1,13t4b0z,https://www.youtube.com/watch?v=7CD3F-S_m88&t=25s&ab_channel=AbdulRehmanIkram,2,1685184856.0,
272,learnmachinelearning,openai,relevance,2022-09-28 16:11:19,Optimization for audio transcription on hosted GPU using OpenAI Whisper,PlentifulPlatitudes,False,1.0,3,xqgt43,https://www.reddit.com/r/learnmachinelearning/comments/xqgt43/optimization_for_audio_transcription_on_hosted/,0,1664381479.0,"Hi there,

I've been trying out OpenAI's Whisper model. I am completely inexperienced in the skill of using GPU to run a model, and I don't have a machine with a GPU sufficient to run even the tiny Whisper model that OpenAI provides. Because of this, I've been using various hosted GPUs, most recently on [vast.ai](https://vast.ai).

I have experimented with different machines, especially with 1x, 2x, and 4x RTX3090's. However, it's taking \~5.5 minutes to transcribe a 12MB audio file using the small model, and that seems a bit slow. I was using the pytorch/jupyter notebook image, however, and I don't know if that is somehow the least efficient image for this use case.

Could anyone provide ideas on how to optimize the use of one of these hosted machines, so that I could transcribe the audio significantly faster?

Thanks in advance!"
273,learnmachinelearning,openai,relevance,2022-08-11 14:58:54,Learn multi-modal (image+text) ML with OpenAI's CLIP,jamescalam,False,0.91,8,wltheu,https://www.reddit.com/r/learnmachinelearning/comments/wltheu/learn_multimodal_imagetext_ml_with_openais_clip/,1,1660229934.0,"Hi all, I created a [walkthrough](https://towardsdatascience.com/quick-fire-guide-to-multi-modal-ml-with-openais-clip-2dad7e398ac0?sk=89bb2d8b8e583ed109d8a05e00366645) (and [video](https://youtu.be/989aKUVBfbk)) demoing how to use the text and image embeddings of OpenAI's CLIP. CLIP is a multi-modal model that uses a typical text transformer for text embeddings and a vision transformer (ViT, alt version uses Resnet) for image embeddings. During pertaining, CLIP learns to place (image, text) pairs into the same vector space. The result is a cool off-the-shelf model that can perform tasks across image and text data.

When I started using CLIP, I struggled to find how to use it for embedding text and images separately (all the examples tend to show placing both together and calc sim score directly, sans embedding output), so I hope this is helpful for anyone attempting the same.

Thanks all!"
274,learnmachinelearning,openai,relevance,2023-04-13 09:37:37,[R] A walk-through tutorial on how to build custom OpenAI models by fine-tuning the existing ones,g_pipis,False,0.78,5,12kiyow,https://www.reddit.com/r/learnmachinelearning/comments/12kiyow/r_a_walkthrough_tutorial_on_how_to_build_custom/,6,1681378657.0," I have written this tutorial on [how to fine-tune OpenAI models](https://jorgepit-14189.medium.com/how-to-fine-tune-an-nlp-classification-model-with-openai-c096334ee158). This simple example is about an NLP binary classification task but you can apply the same logic for building custom models for sentiment analysis. Finally, you can build other custom models for other tasks such as NLG, Questions and Answers and so on.  
I would love to get feedback from the community and I am interested in other similar examples with fine-tuned OpenAI models"
275,learnmachinelearning,openai,relevance,2022-11-15 16:44:54,Question regarding OpenAI embeddings model for text clustering (or any other model),SemperZero,False,1.0,1,yw2l3b,https://www.reddit.com/r/learnmachinelearning/comments/yw2l3b/question_regarding_openai_embeddings_model_for/,1,1668530694.0,"Hi there. I'm new to NLP, i've only read a few articles, watched some videos and worked on some simple text summarizing projects. 

I want to go to the next level and work on a project which clusters pieces of text together based on meaning. I've read some articles and understood what word embeddings are and a high level idea on how they are computed. For now let's say OpenAI or another tool is a black box which takes as input text and outputs embeddings. But hold on. I'm lost. What is the input and output again? I read multiple articles and guides, read code examples and i still don't get it. I have some questions:

1. Does OpenAI api return word embeddings or text embeddings? Does it simply average the word embeddings to return the text one? If not, what techniques does it use? One of their code examples shows one vector embedding per one text.

2. Does OpenAI train on my texts and return word embeddings based on their meaning in my text? if not then why doesn't it have a public cache with all words in the english dictionary and their corresponding vectors?

3. What does OpenAI have pre-trained? A model which returns one vector embedding based on an entire text? where can i find information about what this model is? this seems like the most plausible explanation based on what i've read (except 5.)

4. If i send multiple texts will the output be the same for all of them? if i send them in batches or all at once, will the results be the same. meaning, does it re-train something based on my examples? 

5. In pinecone's documentation it says ""If you want to use OpenAI Embeddings in your own project, the first step is to train a word2vec model on a large corpus of text"" -> what? isn't OpenAI model some kind of word2vec already trained?

6. Is it possible to make the model more specialised in a specific domain? such as medical texts or legal texts or programming documentations or whatever class of texts my dataset is composed of.

7. What other models would you suggest using for text clusters?

I'm not lost in the mathematical, algorithmic or programming concepts. I just don't understand what this api is and what it does even if i were to treat it as a black box. Please help. I'd also appreciate a lot some resources/guides to read and learn more about this <3"
276,learnmachinelearning,openai,relevance,2022-12-13 21:43:48,OpenAI Demo: Record yourself talking about a subject and get paraphrased notes,nvdnadj92,False,0.67,2,zl7xf5,https://soundingboard.ai,0,1670967828.0,
277,learnmachinelearning,openai,relevance,2023-06-12 17:23:33,"GPT Weekly - 12the June Edition - OpenAI GPT Best Practice, Deepmind's sorting algo, Bard Improvements and more.",level6-killjoy,False,0.75,2,147shn0,https://www.reddit.com/r/learnmachinelearning/comments/147shn0/gpt_weekly_12the_june_edition_openai_gpt_best/,0,1686590613.0," 

This is a recap covering the major news from last week.

* 🔥Google Deepmind’s sort solution, OpenAI best practice on GPT, and Bard improvements
* 🗞️Apple’s use of Generative AI and other 9 AI news highlights and interesting reads
* 🧑‍🎓Learning about tokenization and using Huggingface LLM with LangChain

🔥Top 3 AI news in the past week

# 1. Optimal solutions are inhuman

Sorting is one of the fundamental algorithms used on the internet everyday. Think of how companies like Netflix need to find correct movies from their huge content library and present it to you. More content is being generated everyday. So, there is a need for newer and more efficient algorithms.

Searching for these algorithms has been a human task. People coming up with efficient and optimal solutions. Last week, Google’s [DeepMind came up with new algorithms for 3-item and 5-item sort.](https://www.nature.com/articles/s41586-023-06004-9)

Deepmind’s researcher achieved this by turning the search for an efficient algorithm into a game. Then they trained Alphadev to play this game. When playing this game, Alphadev came up with unseen strategies. These “strategies” are the new sorting algorithms.

The solution isn’t revolutionary as it doesn’t find a new approach. This solution works by optimizing the current approach.

The algorithms have been added to C++ library. The first time a completely AI solution has been added to the library.

This is an important discovery because it shows that finding the best optimal solutions needs computers. As computers are able to go beyond what humans can perceive. Previously, Deepmind’s AlphaGo has [beaten the top rated Go player Lee Sedol in a similar way](https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol). It came up with moves which were never seen before.

On the other hand, computers might be restricted to what they have been taught. Someone was able to [replicate the discovery using ChatGPT](https://twitter.com/DimitrisPapail/status/1666843952824168465).

# 2. GPT Best Practices

There has been a [lot of noise about GPT-4’s quality going down.](https://gptweekly.beehiiv.com/p/peek-openais-future)

Now we have a [list of tactics and strategies straight from Open AI](https://platform.openai.com/docs/guides/gpt-best-practices) to get better results.

I have looked through the strategies and tactics and most of it is around providing better inputs. “Prompt Engineering”, if you may. Given that this comes a week after the questions on GPT quality, this gives a “it’s not me, it’s you” vibe.

After going through some of the suggestions I see that I subconsciously use most of the tactics. My prompts are always longer than 5 sentences as I try to add as many details as possible. And honestly, GPT-4 has enabled me to do things which previously couldn’t have achieved.

# 3. Logic and reasoning improvements in Bard

Bard, on the other hand, has been lacking. Google is trying to improve the responses by adding features one at a time.

Last week it was announced that [Bard will get better at logic and reason](https://blog.google/technology/ai/bard-improved-reasoning-google-sheets-export/). This is achieved using “implicit code execution”. Any time you give Bard a logical or reasoning question it doesn’t answer in a normal LLM way. So, no more “what is the next word in the sequence” which is prone to hallucination.

Instead Bard will now recognize that the prompt is a logical question. It will then write and execute code under the hood. It’ll respond to the question by taking the output of the execute code.

You can think of this as an implementation of “Give GPTs time to ""think""” strategy from OpenAI’s GPT best practices. As per Google, this improves the performance by 30%.

Give it a try and let me know?

# 🗞️10 AI news highlights and interesting reads

1. Apple did not showcase any generative AI products during the WWDC. Though they are introducing the “what is the next word in the sequence” logic of LLM into autocorrect. It can be summed thusly:

&#x200B;

https://preview.redd.it/ovnoasksfm5b1.jpg?width=900&format=pjpg&auto=webp&s=8e37990c268933497f003faf58b854a73129ca6a

1. [ChatGPT cannot read the name - davidjdl](https://twitter.com/goodside/status/1666598580319035392). Some think that this is due to tokenization of Reddit data. In the learning resources section I have added a tutorial on tokenization.
2. Browser extensions are a security nightmare. [The GPT and LLM craze has given the malware extensions another way to steal user data.](https://www.kolide.com/blog/ai-browser-extensions-are-a-security-nightmare) Beware of the summarization and “write for me” extensions.
3. Most of the AI generated imagery is going to be used for stock photography. But is the industry dying? [Here’s a look at the data so far.](https://www.stockperformer.com/blog/is-ai-killing-the-stock-industry-a-data-perspective/) The author’s conclusion is that early metrics show that finding AI stock images often don’t have people in it. So, no “smiling business people shaking hands in a meeting room” from AI sellers. This might change with MidJourney V5. Future is still unknown.
4. [Six tips for better coding with ChatGPT](https://www.nature.com/articles/d41586-023-01833-0). I have been using Trust, but verify mental model quite frequently. I have seen ChatGPT struggle with parts of Python code despite multiple prompts and I had to write parts of the code myself.
5. [GPT-5 isn’t coming any time soon](https://techcrunch.com/2023/06/07/openai-gpt5-sam-altman/).
6. AI startups might be too easy to copy. And with AI requiring lesser resources, [we might even see 1 person companies worth more than 1 million dollars](https://www.semafor.com/article/06/07/2023/are-ai-startups-too-easy-to-copy).
7. [Google’s vision for securing AI.](https://www.axios.com/2023/06/08/google-securing-ai-framework)
8. [A16z says AI will save the world.](https://a16z.com/2023/06/06/ai-will-save-the-world/)
9. AI pics might be used for disinformation. [The EU's solution is to label AI images to fight disinformation.](https://techcrunch.com/2023/06/06/eu-disinformation-code-generative-ai-labels/)

# 🧑‍🎓3 Learning Resources

1. If you are looking to build better solutions using GPT then understanding tokenizers is a must:  

   1. [https://simonwillison.net/2023/Jun/8/gpt-tokenizers/](https://simonwillison.net/2023/Jun/8/gpt-tokenizers/)
   2. [https://matt-rickard.com/the-problem-with-tokenization-in-llms](https://matt-rickard.com/the-problem-with-tokenization-in-llms)
2. Using Flowise and HuggingFace LLM and Langchain

[https://cobusgreyling.medium.com/how-to-use-huggingface-llms-with-langchain-flowise-2b2d0f639f03](https://cobusgreyling.medium.com/how-to-use-huggingface-llms-with-langchain-flowise-2b2d0f639f03)

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
278,learnmachinelearning,openai,relevance,2023-03-20 18:42:54,[D] How do OpenAI and other companies manage to have real-time inference on model with billions of parameters over an API?,RaunchyAppleSauce,False,0.84,4,11wrdse,https://www.reddit.com/r/learnmachinelearning/comments/11wrdse/d_how_do_openai_and_other_companies_manage_to/,16,1679337774.0,"Hi, guys

I have been using OpenAI’s chatgpt through the app Poe and I find it very confusing how a model with billions of parameters is responding in real-time over an API.

How does one go about making inference fast, say 15-20ms, over an API for large models?

Thanks!"
279,learnmachinelearning,openai,relevance,2022-12-23 21:24:24,Could I use sentiment analysis to refine my dataset for a customized openai model?,AdibIsWat,False,0.99,1,ztt1cd,https://www.reddit.com/r/learnmachinelearning/comments/ztt1cd/could_i_use_sentiment_analysis_to_refine_my/,0,1671830664.0,"I'm trying to train a model to talk like me using openai's API by scraping my discord chat logs and then parsing them into a `.jsonl` to create a dataset.

The problem is that individual chat messages are not a good example of how people talk in real life, so to parse my messages I check the timestamp of a message and its previous message, and if they are within 10 seconds, I consider them part of the same ""thought"", where each thought is one completion in my dataset. I know this isn't faultless, but I couldn't come up with a better method. It is also not easy to capture the context these thoughts, so all the prompts in my dataset are empty strings. This process produces a lot of entries in the dataset that are just complete gibberish and throw off the model.

Before spending hours trying to figure this out, I was wondering if it is even possible to use sentiment analysis to fix two of my problems:

1. filter out nonsensical thoughts from my dataset/only accept thoughts that convey an actual idea or complete thought
2. analyze thoughts and assign their general idea as its prompt"
280,learnmachinelearning,openai,relevance,2021-04-25 18:45:04,Pybullet and OpenAI,Z_AbdelKarim,False,0.6,1,myen59,https://www.reddit.com/r/learnmachinelearning/comments/myen59/pybullet_and_openai/,0,1619376304.0,"Hi there, I’m currently working on a project about training a drone with DQN (reinforcement learning).
I want to create simulation in Pybullet engine and train the drone there using OpenAI Gym.
If anyone of you already worked on a similar project could help by providing some documentation, videos or some advices. I would be very thankful. 
Thank you all."
281,learnmachinelearning,openai,relevance,2022-06-26 18:48:10,This is how OpenAI's new Minecraft AI agent works,SlickBlueML,False,0.99,6,vlbirr,https://www.youtube.com/watch?v=ODat7kfZ-5k,0,1656269290.0,
282,learnmachinelearning,openai,relevance,2023-05-01 17:04:12,"GPT Weekly Newsletter -- 30 Apr Edition. AI music, Voiceover, HuggingChat, Future of Work, OpenAI and more.",level6-killjoy,False,1.0,2,134t13o,/r/ChatGPT/comments/133q4zl/gpt_weekly_newsletter_30_apr_edition_ai_music/,0,1682960652.0,
283,learnmachinelearning,openai,relevance,2023-06-05 17:21:46,"GPT Weekly - 5th June Edition: Peek into OpenAI's future, GPT-4 Quality concerns, Risk of AI and more.",level6-killjoy,False,0.67,1,141llju,https://www.reddit.com/r/learnmachinelearning/comments/141llju/gpt_weekly_5th_june_edition_peek_into_openais/,0,1685985706.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 AI news in the past week
* 🗞️10 AI news highlights and interesting reads
* 🧑‍🎓3 Learning Resources

# 🔥Top 3 AI news in the past week

## 1. OpenAI plans as per Sam Altman

The CEO of Humanloop had a sit down with Sam Altman and 20 other developers. He discussed the [current and future of OpenAI](https://humanloop.com/blog/openai-plans). The blog was later taken down at the request of OpenAI. [Now it can be found at this link](https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans). 

The whole post is an interesting read. Some of the highlights for me were:

1. GPT-3 was not open-source because OpenAI didn’t think many people would be able to run large LLMs. This sounds like a cop-out. After all, LLaMA is also a large LLM and has helped the community.
2. OpenAI is limited by GPU power.
3. OpenAI will not enter the market, except ChatGPT. Though technically this doesn’t say what Microsoft might do. They are already plugging GPT4 into every other product. And they have no rate limitations. 

## 2. Is GPT-4 Quality going down?

This has been a recently trending topic.

Discussed on HN: [https://news.ycombinator.com/item?id=36134249](https://news.ycombinator.com/item?id=36134249)

Discussed on Reddit: [https://www.reddit.com/r/ChatGPT/comments/13xik2o/chat\_gpt\_4\_turned\_dumber\_today/](https://www.reddit.com/r/ChatGPT/comments/13xik2o/chat_gpt_4_turned_dumber_today/)

The interesting thing is that the quality judgment is around the same topic - Coding.

The person on HN says GPT4 is faster but generates buggy code with less in-depth analysis. 

While the person on Reddit says that the context window seems smaller. Chatbot cannot remember earlier code. It cannot distinguish between code and comment.

While an employee at OpenAI says [nothing has changed](https://twitter.com/OfficialLoganK/status/1663934947931897857).

Has something really changed? 

One theory is that while the model might be static the ChatGPT prompt might’ve changed to restrict answers. Everyone was having fun trying to get bomb recipes out of ChatGPT. Now everyone is paying the price. 

https://i.imgflip.com/7nlatp.jpg

Another theory is that ChatGPT has always been terrible. It just survived because of novelty. As the novelty wears off people are realizing that it isn’t as great as everyone thought. 

My theory is that this might be the after effect of trying to get to a “[Cheaper and faster GPT-4” as highlighted by Sam Altman](https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans). The trade-off is speed vs accuracy. If it is slightly faster but with slightly worse results, then it might work as well. It is no longer GPT-4, rather GPT-3.75.

## 3. Risk of AI = Pandemic and Nuclear War

Center for AI Safety [released a statement](https://www.safe.ai/statement-on-ai-risk) highlighting the risks of AI:

*Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.*

We have seen the warnings about risks of AI get dire and dire. First it was only people asking for a [pause on AI development for 6 months](https://www.theguardian.com/technology/2023/mar/31/ai-research-pause-elon-musk-chatgpt) then came [George Hinton](https://gptweekly.beehiiv.com/p/googles-startling-leaked-memo-george-hinton-mojo), and last week OpenAI asked for [AI to be regulated using the IAEA framework](https://gptweekly.beehiiv.com/p/future-ai-integration). 

This statement is not really a step up. It reads like a one line, summarized repetition of [OpenAI's statement](https://openai.com/blog/governance-of-superintelligence). 

The statement gains importance from its signatories. Some of the people include:

Geoffrey Hinton - Emeritus Professor of Computer Science, University of Toronto

Demis Hassabis - CEO, Google DeepMind

Sam Altman - CEO, OpenAI

Dario Amodei - CEO, Anthropic

Bill Gates - Gates Ventures

To name a few. 

There are two issues with the statement though. 

First, this might just be [fear-mongering](https://aisnakeoil.substack.com/p/is-avoiding-extinction-from-ai-really). The idea is to push governments into making AI a highly regulated industry. This would stop any open source efforts which can compete with the big companies. After all, you don’t really have open source alternatives for nuclear energy, right? 

Second, no one really knows how to regulate AI. There have been [voluntary rules from Google](https://gptweekly.beehiiv.com/p/future-ai-integration) and the EU AI act is in a very early stage. And the genie is already out of the bottle. People can create AI models in their basement. How do you pull that back?

# 🗞️10 AI news highlights and interesting reads

1. A follow-up to the story about a lawyer submitting fake cases from [last edition](https://gptweekly.beehiiv.com/p/future-ai-integration). As I said, this might lead some people in the legal community to doubt any sort of GPT tool.[ A federal judge has banned AI-only filings in his courtroom](https://arstechnica.com/tech-policy/2023/05/federal-judge-no-ai-in-my-courtroom-unless-a-human-verifies-its-accuracy/). The filings have to be written by a human or at least human-verified. 
2. [The Japanese government will not apply copyright law to the AI training data](https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/). This is interesting because using copyright data to train AI has been an issue. Sam Altman didn’t have a clear answer when he [appeared in front of Congress](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). The other interesting aspect is going to be whether someone can use GPT-4 data to train their own LLM. Is that copyrightable?  
3. [The Falcon 40-B model is now Apache 2.0](https://twitter.com/Thom_Wolf/status/1663986216771936263). That means you can use the model for commercial usage for free. This is good news for companies which need an instruction tuned model which beats LlaMA.
4. Photoshop's generative-fill feature is really good. Some of the [cool examples on Twitter](https://twitter.com/_Borriss_/status/1663568770408013831).
5. [An AI camera with no lens](https://twitter.com/BjoernKarmann/status/1663496103998750721). It gets the location, weather etc details from GPS and then passes it as a prompt to the image generator. Results are pretty cool. 
6. SEO isn’t changing any time soon. [Google’s generative SEO is very slow](https://www.theverge.com/23746083/google-ai-search-generative-experience-slow). 
7. [Chirper.AI](https://chirper.ai/) is a social media only for bots. No humans allowed. I just wonder if Twitter bots go there will Twitter become a ghost town?
8. [OpenAI now has a security portal ](https://trust.openai.com/)where you can see how they secure data (encryption at rest), backups, Pentest reports etc. This might be a step in the direction towards [ChatGPT business](https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt). Large corporations look at these policies before they consider any SaaS implementation. 
9. [Banks have stepped up hiring for AI roles with JP Morgan leading the way. ](https://www.bloomberg.com/news/features/2023-05-31/jpmorgan-s-push-into-finance-ai-has-wall-street-rushing-to-catch-up)
10. [AI code writing might not be the best idea. It will lead to tech debt and shabbily maintained and written code. ](https://www.wsj.com/articles/ai-is-writing-code-now-for-companies-that-is-good-and-bad-6f19ecdc)

# 🧑‍🎓3 Learning Resources

1. Couple of courses in Generative AI:
   1. [https://www.deeplearning.ai/short-courses/](https://www.deeplearning.ai/short-courses/)
   2. Google: [https://www.cloudskillsboost.google/paths/118](https://www.cloudskillsboost.google/paths/118)
2. Build your own Sketch to image app: [https://www.tryleap.ai/docs/how-to-build-a-sketch-to-image-app-with-leap-remix](https://www.tryleap.ai/docs/how-to-build-a-sketch-to-image-app-with-leap-remix)

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
284,learnmachinelearning,openai,relevance,2022-04-07 03:34:08,OpenAI's new model DALL·E 2 is amazing !,OnlyProggingForFun,False,1.0,5,ty3z2z,https://youtu.be/rdGVbPI42sA,1,1649302448.0,
285,learnmachinelearning,openai,relevance,2021-11-22 04:53:26,stable-retro: fork of OpenAI's gym-retro,matpoliquin,False,1.0,15,qzdego,https://www.reddit.com/r/learnmachinelearning/comments/qzdego/stableretro_fork_of_openais_gymretro/,0,1637556806.0,"Since OpenAI's gym-retro has been archived for a while and doesn't accept any PRs and new game/plateform integrations I created a fork called \*stable-retro\* (mostly tested with stable-baselines) If you have integrated a game or platform or made a fix you are welcomed to do a PR.

[~~https://github.com/MatPoliquin/stable-retro~~](https://github.com/MatPoliquin/stable-retro)

Project recently moved to Farama Foundation:

[https://github.com/Farama-Foundation/stable-retro](https://github.com/Farama-Foundation/stable-retro)

&#x200B;

Currently added games on top of gym-retro:

* Super Mario Bros 2 Japan (Lost Levels) - NES
* Hang On - SMS
* Punch Out - NES
* WWF Wrestlemania the Arcade Game - Genesis
* NHL 94 - Genesis
* NHL 94 (1 on 1 rom hack) - Genesis
* Super Hang On - Genesis
* Tetris - GameBoy
* Virtua Fighter 2 - Genesis

PvP games that support two models fighting each other:

* Samurai Showdown - Genesis
* WWF Wrestlemania the Arcade Game - Genesis
* Mortal Kombat II - Genesis
* NHL 94 - Genesis

## Fixes

* Fixed UI flickering issue in OpenAI integration tool
* fix compile with c++ >=17"
286,learnmachinelearning,openai,relevance,2022-09-21 20:40:49,OpenAI Whisper - SOTA MultiLingual AI Speech Recognition Live App Tutorial,dulldata,False,1.0,1,xkgcno,https://www.youtube.com/watch?v=ywIyc8l1K1Q,0,1663792849.0,
287,learnmachinelearning,openai,relevance,2022-12-28 16:02:55,Andrew Huberman transcripts app - high-quality transcription using OpenAI's largest Whisper model (see comment),gordicaleksa,False,1.0,2,zxd93g,https://www.hubermantranscripts.com/,2,1672243375.0,
288,learnmachinelearning,openai,relevance,2021-08-03 06:46:05,Tinder bio generation with OpenAI GPT-3 API,shyamcody,False,1.0,2,owxtwt,https://shyambhu20.blogspot.com/2021/08/tinder-bio-generation-with-openai-gpt-3.html,6,1627973165.0,
289,learnmachinelearning,openai,relevance,2022-12-12 19:17:50,"A web application tool for improving your written communication features paraphrasing, grammar checking, and text summarizing tool built with OpenAI API.",Austin_Nguyen_2k,False,0.95,29,zk8gr7,https://v.redd.it/95jm43veoi5a1,12,1670872670.0,
290,learnmachinelearning,openai,relevance,2022-06-23 08:39:46,Deep dive into OpenAI CLIP's code | Machine Learning Coding Series,gordicaleksa,False,1.0,3,vis76i,https://youtu.be/jwZQD0Cqz4o,0,1655973586.0,
291,learnmachinelearning,openai,relevance,2022-02-23 10:54:42,Tutorial: Getting Started with OpenAI API and GPT-3,python_engineer,False,1.0,5,szeop4,https://youtu.be/Zb5Nylziu6E,0,1645613682.0,
292,learnmachinelearning,openai,relevance,2021-03-24 22:37:47,Training OpenAI Jukebox on Windows,Testost3r0ne,False,1.0,1,mcisdh,https://www.reddit.com/r/learnmachinelearning/comments/mcisdh/training_openai_jukebox_on_windows/,2,1616625467.0,"Good day. I wanna train OpenAI Jukebox on Windows. But I'm getting all sorts of errors regarding MPI:

    DLL load failed: The specified module could not be found when doing “from mpi4py import MPI”

I have done all the possible solutions recommended to me on Stack Overflow and Github. I still get this error.... A little help pls?"
293,learnmachinelearning,openai,relevance,2023-02-22 19:36:48,"Learning Python, and having issues with 'import OpenAI' to do some tests with it in my little project",cleverestx,False,0.81,3,1199bfy,https://www.reddit.com/r/learnmachinelearning/comments/1199bfy/learning_python_and_having_issues_with_import/,0,1677094608.0,"Cmd line tells me requirement is already satisfied when I run pip install openai, but my code tells me:

***import openai***

***ModuleNotFoundError: No module named 'openai'***

I have a ChatGPT Key and it's ready in the code

I appreciate any guidance.  I am pretty new to it so be gentle, lol

&#x200B;

**\*edit, never-mind, I fixed it. through settings > python interpreter, I needed to add a different python version I had installed, and it works.**"
294,learnmachinelearning,openai,relevance,2021-10-03 11:49:44,What is the difference between OpenAI and the gpt3 algorithm?,Ok-War-9040,False,0.25,0,q0g7na,https://www.reddit.com/r/learnmachinelearning/comments/q0g7na/what_is_the_difference_between_openai_and_the/,6,1633261784.0,
295,learnmachinelearning,openai,relevance,2022-01-19 10:51:37,Create a good prompt for openAI text-generation model,Dario_Della,False,1.0,2,s7nin2,https://www.reddit.com/r/learnmachinelearning/comments/s7nin2/create_a_good_prompt_for_openai_textgeneration/,0,1642589497.0,"Hi guys, I'm a data science student and i'm trying to build a new dataset using OpenAi framework.

My idea is to use 5000 phrases and triples to train a data-to-text OpenAi model which given a triple generates of the text.

reading the OpneAi documentation, I found this script for reference:

    import os
    import openai
    
    openai.api_key = os.getenv(""OPENAI_API_KEY"")
    
    response = openai.Completion.create(
      engine=""davinci"",
      prompt=""English: I do not speak French.\nFrench: Je ne parle pas français.\n\nEnglish: See you later!\nFrench: À tout à l'heure!\n\nEnglish: Where is a good restaurant?\nFrench: Où est un bon restaurant?\n\nEnglish: What rooms do you have available?\nFrench: Quelles chambres avez-vous de disponible?\n\nEnglish: What time is breakfast?\nFrench:"",
      temperature=0.5,
      max_tokens=100,
      top_p=1.0,
      frequency_penalty=0.0,
      presence_penalty=0.0,
      stop=[""\n""]
    )

i would like that the above script follows this scructure: 

prompt = ""Triples: subject, predicate, object.\\nEnglish:text generated""

    import os
    import openai
    
    openai.api_key = ""mykey""
    
    response = openai.Completion.create(
      engine=""ada"",
      prompt= ""Triples: Aarhus_Airport, cityServed, Aarhus_Denmark.\nEnglish:The Aarhus     
           is the airport of Aarhus, Denmark.\n
               Triples:Alan_Bean, almaMater,UT_Austin_B.S._1955.\nEnglish:The Alma Mater 
           of Alan Bean is UT Austin, B.S. 1955.\n
               Triples:103_Colmore_Row, architecturalStyle, Brutalist_architecture.\n 
           English:The architecture style of 103 Colmore Row falls under Brutalist 
           architecture.\n
               Triples:The_Phoenix, Fast_food, riverside.\nEnglish:"",
      temperature=0.5,
      max_tokens=100,
      top_p=1.0,
      frequency_penalty=0.0,
      presence_penalty=0.0,
      stop=[""\n""]
    )

expected output from the last triple (The\_Phoenix, Fast\_food, riverside.):

    The Phoenix is a fast food place in the riverside area.

For example, given the webnlg dataset (xml file) with this strcuture:

     <entry category=""Airport"" eid=""Id1"" size=""1"">
          <originaltripleset>
            <otriple>Aarhus_Airport | cityServed | ""Aarhus, Denmark""@en</otriple>
          </originaltripleset>
          <modifiedtripleset>
            <mtriple>Aarhus_Airport | cityServed | ""Aarhus, Denmark""</mtriple>
          </modifiedtripleset>
          <lex comment=""good"" lid=""Id1"">The Aarhus is the airport of Aarhus, Denmark.</lex>
          <lex comment=""good"" lid=""Id2"">Aarhus Airport serves the city of Aarhus, Denmark.</lex>
        </entry>
    

I would like to randomly extract sentences and their triples from this dataset and use them as training. How can I insert them into the ""prompt"" variable automatically without writing by hand ?.

&#x200B;

Thanks!"
296,learnmachinelearning,openai,relevance,2023-05-09 18:05:05,"Building with LLMs, ChatGPT, and Working at OpenAI With Logan Kilpatrick (Dev Rel @OpenAI) - What's AI episode 11",OnlyProggingForFun,False,1.0,1,13d13os,https://youtu.be/zz4U3X3PD4s,0,1683655505.0,
297,learnmachinelearning,openai,relevance,2023-05-11 00:54:18,What do actual ML engineers think of ChatGPT?,PhillConners,False,0.96,152,13e8of2,https://www.reddit.com/r/learnmachinelearning/comments/13e8of2/what_do_actual_ml_engineers_think_of_chatgpt/,106,1683766458.0,"You have been doing this for awhile, now the world is obsessed with OpenAI and suddenly all full of AI “experts”."
298,learnmachinelearning,openai,relevance,2020-07-30 10:03:42,Errors when using a DQN for the FrozenLake openai game,math7878,False,1.0,1,i0jfgg,https://www.reddit.com/r/learnmachinelearning/comments/i0jfgg/errors_when_using_a_dqn_for_the_frozenlake_openai/,16,1596103422.0,"Hey everyone, I am trying to make a DQN algorithm work for the FrozenLake-v0 game but am getting errors. I know that a DQN is probably an overkill but I would really like to get this to work. Here is the code:

    import gym
    import numpy as np
    import tensorflow as tf
    
    env = gym.make(""FrozenLake-v0"")
    
    n_actions = env.action_space.n
    input_dim = env.observation_space.n
    model = tf.keras.Sequential() 
    model.add(tf.keras.layers.Dense(64, input_dim = input_dim , activation = 'relu'))
    model.add(tf.keras.layers.Dense(32, activation = 'relu'))
    model.add(tf.keras.layers.Dense(n_actions, activation = 'linear'))
    model.compile(optimizer=tf.keras.optimizers.Adam(), loss = 'mse')
    
    def replay(replay_memory, minibatch_size=32):
        minibatch = np.random.choice(replay_memory, minibatch_size, replace=True)
        s_l =      np.array(list(map(lambda x: x['s'], minibatch)))
        a_l =      np.array(list(map(lambda x: x['a'], minibatch)))
        r_l =      np.array(list(map(lambda x: x['r'], minibatch)))
        sprime_l = np.array(list(map(lambda x: x['sprime'], minibatch)))
        done_l   = np.array(list(map(lambda x: x['done'], minibatch)))
        qvals_sprime_l = model.predict(sprime_l)
        target_f = model.predict(s_l) 
        for i,(s,a,r,qvals_sprime, done) in enumerate(zip(s_l,a_l,r_l,qvals_sprime_l, done_l)): 
            if not done:  target = r + gamma * np.max(qvals_sprime)
            else:         target = r
            target_f[i][a] = target
        model.fit(s_l,target_f, epochs=1, verbose=0)
        return model
    
    n_episodes = 500
    gamma = 0.99
    epsilon = 0.9
    minibatch_size = 32
    r_sums = []  
    replay_memory = []
    mem_max_size = 100000
    
    for n in range(n_episodes): 
        s = env.reset()
        done=False
        r_sum = 0
        print(s)
        while not done: 
            qvals_s = model.predict(s.reshape(16))
            if np.random.random() < epsilon:  a = env.action_space.sample()
            else:                             a = np.argmax(qvals_s); 
            sprime, r, done, info = env.step(a)
            r_sum += r 
            if len(replay_memory) > mem_max_size:
                replay_memory.pop(0)
            replay_memory.append({""s"":s,""a"":a,""r"":r,""sprime"":sprime,""done"":done})
            s=sprime
            model=replay(replay_memory, minibatch_size = minibatch_size)
        if epsilon > 0.1:      epsilon -= 0.001
        r_sums.append(r_sum)
        if n % 100 == 0: print(n)


And the errors I am getting are:

    Traceback (most recent call last):
      File ""froz_versuch.py"", line 48, in <module>
        qvals_s = model.predict(s.reshape(16))
    ValueError: cannot reshape array of size 1 into shape (16,)

And when I try to then change `qvals_s = model.predict(s.reshape(16))` to `qvals_s = model.predict(s.reshape(1))` I get the error:

    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 16 but received input with shape [None, 1]


I'd appreciate any help!"
299,learnmachinelearning,openai,relevance,2023-03-31 06:16:58,"If ChatGPT itself cannot be fine-tuned, what would bf the benefit of using the GPT3 offering of OpenAI vs my own?",Proxify,False,0.86,5,127c5iz,https://www.reddit.com/r/learnmachinelearning/comments/127c5iz/if_chatgpt_itself_cannot_be_finetuned_what_would/,5,1680243418.0,"Sorry, I'm somewhat new to this space and I'm reading about it and looking at the documentation from OpenAI.

From what I can tell, only their base models are available to fine-tune which, as far as I understand, would leave me in a situation in which fine-tuning any other GPT3 model would be comparable (vs their ""DaVinci"" model for instance).

Am I missing something here? Basically I'm wondering, other than their infrastructure (which is nothing to scoff at) why would I use their fine-tuning if the end result won't talk to the user as ChatGPT would."
