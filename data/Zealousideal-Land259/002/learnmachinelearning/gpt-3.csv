,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,id,url,num_comments,created,body
0,learnmachinelearning,gpt-3,top,2021-06-29 13:07:05,"Started learning ML 14 months ago, now I'm using GPT-3 to automate CVs!",Camjw1123,False,0.97,751,oa7x3p,https://gfycat.com/ambitioushauntingagama,53,1624972025.0,
1,learnmachinelearning,gpt-3,top,2021-04-03 15:27:04,"I'm a Senior DS and I put together a Youtube Channel with project tutorials, resume critiques, and career advice. Let me know what you think!",madzthakz,False,0.98,550,mjao5g,https://www.reddit.com/r/learnmachinelearning/comments/mjao5g/im_a_senior_ds_and_i_put_together_a_youtube/,21,1617463624.0,"I've also been setting up free [Data Science Q&As](https://www.reddit.com/r/datascience/comments/jig7pv/im_a_senior_data_scientist_at_disney_and_im/) for you all. On the side, I started putting together useful videos that would have helped me out when I was trying to break into this space. Like I said, the channel consists of modeling tutorials, resume critiques, career advice, and recordings of our Q&A sessions. Here are some examples:

1. [How to build a Spotify recommendation engine](https://youtu.be/tooddaC14q4).
2. [How to leverage GPT-2 to generate descriptions of new Netflix content](https://youtu.be/NvMoFeO0aGE).
3. [Full recordings of 1:1 coaching sessions with an ML student.](https://youtu.be/N2tDfXdZmdE)
4. [Resume Critique of a student who just completed a certificate.](https://youtu.be/Ztexwmrxt2A)
5. [Q&A Recording with a Principal Data Scientist.](https://youtu.be/r-NjlPW-Ihg) 

This is all really new and has been a blast to work on. Let me know what you think. 

[Channel Link](https://www.youtube.com/channel/UC0-S_HnWTDFaXgTbYSL46Ug)

If you like it, definitely subscribe! I try to put out videos every week. 

Also, feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/madhavthaker/). I try to make myself as accessible as possible on there."
2,learnmachinelearning,gpt-3,top,2022-11-07 14:11:49,Been learning ML since the start of the year and built a tool with GPT-3 that letâ€™s anyone self-serve their own data questions and create graphs and dashboards,BuggerinoKripperino,False,0.98,467,yoo3ba,https://v.redd.it/n0vjjvr8ejy91,64,1667830309.0,
3,learnmachinelearning,gpt-3,top,2021-07-01 16:06:11,Second version of my GPT-3 powered resume writer - now does bullet points and doesn't use pronouns!,Camjw1123,False,0.96,344,oboywl,https://gfycat.com/bitteroffbeatitalianbrownbear,29,1625155571.0,
4,learnmachinelearning,gpt-3,top,2023-01-19 07:56:20,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.96,331,10fw2df,https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/,47,1674114980.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. Thatâ€™s a *trillion* with a â€œtâ€.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAIâ€™s new brainchild will certainly be mind-bending and language models have been getting bigger â€” fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Letâ€™s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): â€œFrom talking to OpenAI, GPT-4 will be about 100 trillion parametersâ€.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But thereâ€™s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the communityâ€™s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: â€œScaling Laws For Neural Language Modelsâ€.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMindâ€™s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): â€œTraining Compute-Optimal Large Language Modelsâ€

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* â€‹[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the railsâ€‹

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** â­•.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,â€¦ & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
5,learnmachinelearning,gpt-3,top,2023-02-19 13:55:13,ChatGPT History,eforebrahim,False,0.86,251,116au66,https://i.redd.it/dv8cfj0nz6ja1.jpg,27,1676814913.0,
6,learnmachinelearning,gpt-3,top,2023-05-11 20:15:46,Top 20 Large Language Models based on the Elo rating system.,kingabzpro,False,0.96,248,13eympz,https://i.redd.it/7xfqr5crf9za1.png,43,1683836146.0,
7,learnmachinelearning,gpt-3,top,2023-01-05 06:32:22,I Built A GPT-3 Powered Productivity App - Tutorial included,SupPandaHugger,False,0.97,208,103rv9o,https://i.redd.it/gtywivh756aa1.gif,17,1672900342.0,
8,learnmachinelearning,gpt-3,top,2023-09-23 13:42:22,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.96,185,16q4ve6,https://www.reddit.com/r/learnmachinelearning/comments/16q4ve6/this_week_in_ai_all_the_major_ai_developments_in/,16,1695476542.0,"1. **Genmo** releases a new text-to-video model: **Genmo Replay** v0.1, which generates high-quality videos from text without the need for advanced prompt engineering. *Genmo is available for free to create AI videos* \[[*Details*](https://blog.genmo.ai/log/replay-ai-video) | [Genmo *Replay*](https://www.genmo.ai/)\] .
2. **OpenAI** unveils **DALLÂ·E 3** \- a major update to the text-to-image model, which will be integrated in ChatGPT. It will be available to ChatGPT Plus and Enterprise users in October, via the API and in Labs later this fall. Creators can now also opt their images out from future training.
3. **Toyota Research Institute** has developed a technique, powered by generative AI, that enables teaching robots new manipulation abilities in a single afternoon. Using the same robot, same code, and same setup, TRI taught over 60 different dexterous behaviors like peeling vegetables, using hand mixers, preparing snacks, and flipping pancakes.
4. **Microsoft** announced:
   1. Availability of AI Copilot for Windows from September 26th. Copilot will incorporate the context and intelligence of the web, your work data and what you are doing in the moment on your PC to provide better assistance. It will be integrated in Windows 11, Microsoft 365, Edge and Bing.
   2. Bing will add support for DALL.E 3 and deliver more personalized answers based on search history.
   3. New AI powered experiences in Paint, Photos and Clipchamp.
   4. New AI-powered shopping experience
5. **ElevenLabs** released **Projects** \- a tool that lets you generate an entire audiobook at the click of a button. Projects now supports .epub, .pdf, and .txt file imports, as well as initializing a project from a URL.
6. **Deci** presents **DeciDiffusion 1.0** \- an open-source text-to-image latent diffusion model which is 3x faster than Stable Diffusion v1.5 with the same quality.
7. **Google researchers** present a new approach that produces photo-realistic animations from a single picture. The model is trained on automatically extracted motion trajectories from a large collection of real video sequences.
8. **Google** has updated Bard\*\]\*:
9. **Bard Extensions:** With extensions, Bard can now connect to your Google apps and services like Gmail, Docs, Drive, Google Maps, YouTube, and Google Flights and hotels.
10. Users can use Bardâ€™s â€œGoogle itâ€ button to more easily double-check its answers and evaluate whether there is content across the web to substantiate it.
11. Bard can now let you continue chat via **shared public links**
12. **YouTube** announces new AI tools for creators. **Dream Screen** will let users create an AI-generated video or image background from text. Automatic AI-dubbing tool called **Aloud**, which will be integrated into YouTube Studio. **AI-powered insights** to generate video ideas and draft outlines. **Assistive Search in Creator Music** where AI will suggest the right music based on your description of your content.
13. **Amazon** announced that its voice assistant Alexa is being upgraded with a new, custom-built large language model.
14. **IBM** open-sources **MoLM** \- a collection of ModuleFormer-based language models ranging in scale from 4 billion to 8 billion parameters. ModuleFormer is a new neural network architecture based on the Sparse Mixture of Experts (SMoE) by IBM researchers. .
15. **Neuralink**, Elon Musk's brain implant startup, set to begin human trials.
16. **Lexica** has released **Aperture v3.5** \- their latest next-gen image model that can create photorealistic images and follows your prompt with precision.
17. **OpenAI** has invited domain experts to collaborate in evaluating and improving the safety of OpenAI's models by joining the new **OpenAI Red Teaming Network**.
18. \*\*GitHub Copilot Chat (\*\*beta) is now available for all individuals.
19. **Replit** announced a virtual hackathon for projects built using **Replit ModelFarm**
20. **Oracle** brings voice-activated AI to healthcare with Clinical Digital Assistant.
21. **Google** and the Department of Defense are building an AI-powered microscope to help doctors spot cancer.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
9,learnmachinelearning,gpt-3,top,2023-03-02 16:47:40,Build ChatGPT for Financial Documents with LangChain + Deep Lake,davidbun,False,0.95,171,11g7h03,https://www.reddit.com/r/learnmachinelearning/comments/11g7h03/build_chatgpt_for_financial_documents_with/,8,1677775660.0,"https://preview.redd.it/h9r6hgvfucla1.png?width=2388&format=png&auto=webp&s=5432eac3eeed8583e4309af1fdc7ebecac705796

As the world is increasingly generating vast amounts of financial data, the need for advanced tools to analyze and make sense of it has never been greater. This is where [LangChain](https://github.com/hwchase17/langchain) and [Deep Lake](https://github.com/activeloopai/deeplake) come in, offering a powerful combination of technology to help build a question-answering tool based on financial data. After participating in a LangChain hackathon last week, I created a way to use Deep Lake, the data lake for deep learning (a package my team and I are building) with LangChain. I decided to put together a guide of sorts on how you can approach building your own question-answering tools with  LangChain and Deep Lake as the data store.

Read [the article](https://www.activeloop.ai/resources/ultimate-guide-to-lang-chain-deep-lake-build-chat-gpt-to-answer-questions-on-your-financial-data/) to learn:

1. What is LangChain, what are its benefits and use cases and how you can use to streamline your LLM (Large Language Model) development?  
2. How to use [\#LangChain](https://www.linkedin.com/feed/hashtag/?keywords=langchain&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7037082545263448064) and [\#DeepLake](https://www.linkedin.com/feed/hashtag/?keywords=deeplake&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7037082545263448064) together to build [\#ChatGPT](https://www.linkedin.com/feed/hashtag/?keywords=chatgpt&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7037082545263448064) for your financial documents.  
3. How Deep Lakeâ€™s unified and streamable data store enables fast prototyping without the need to recompute embeddings (something that costs time & money).  


I hope you like it, and let me know if you have any questions!"
10,learnmachinelearning,gpt-3,top,2022-12-21 17:58:41,"Build Your Own GPT-3 App: A Step-by-Step Guide to Creating ""Gifthub,"" a Personalized Gift Recommendation Tool",bruclinbrocoli,False,0.96,142,zrvshy,https://www.reddit.com/r/learnmachinelearning/comments/zrvshy/build_your_own_gpt3_app_a_stepbystep_guide_to/,2,1671645521.0,"This was all built for free -- and took a weekend to ship it.  Pretty simple n a cool way to understand how to use GPT-3 for something personal. 

[Here's](https://buildspace.so/notes/build-gpt3-app) the link to the tutorial. You can also try out the app n see if it gives you a good gift rec.    
Or - share it with someone who sucks at giving gifts :)   


https://preview.redd.it/t2mrgddqia7a1.png?width=592&format=png&auto=webp&s=dc58613a6a5a4a7f8a55c62ab0ace2fe14c4ef8a"
11,learnmachinelearning,gpt-3,top,2023-09-16 13:22:41,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.95,131,16k7heb,https://www.reddit.com/r/learnmachinelearning/comments/16k7heb/this_week_in_ai_all_the_major_ai_developments_in/,17,1694870561.0,"1. **Stability AI** launched Stable Audio, a generative AI tool for music & sound generation from text. The underlying latent diffusion model architecture uses audio conditioned on text metadata as well as audio file duration and start time.
2. **Coqui** released **XTTS** \- a new voice generation model that lets you clone voices in 13 different languages by using just a quick 3-second audio clip.
3. **Microsoft Research** released and open-sourced **Phi-1.5** \- a 1.3 billion parameter transformer-based model with performance on natural language tasks comparable to models 5x larger.
4. **Project Gutenberg**, Microsoft and MIT have worked together to use neural text-to-speech to create and release thousands of **human-quality free and open audiobooks**.
5. Researchers present **NExT-GPT -** an any-to-any multimodal LLM that accepts inputs and generate outputs in arbitrary combinations of text, images, videos, and audio.
6. **Chain of Density (CoD):** a new prompt introduced by researchers from Salesforce, MIT and Colombia University that generates more dense and human-preferable summaries compared to vanilla GPT-4.
7. **Adept** open-sources **Persimmon-8B**, releasing it under an Apache license. The model has been trained from scratch using a context size of 16K.
8. **Adobe's** **Firefly** generative AI models, after 176 days in beta, are now commercially available in Creative Cloud, Adobe Express, and Adobe Experience Cloud. Adobe is also launching Firefly as a standalone web app.
9. **Deci** released **DeciLM 6B**, a permissively licensed, open-source foundation LLM that is 15 times faster than Llama 2 while having comparable quality.
10. Researchers release **Scenimefy** \- a model transforming real-life photos into Shinkai-animation-style images.
11. **Microsoft** open sources **EvoDiff**, a novel protein-generating AI that could be used to create enzymes for new therapeutics and drug delivery methods as well as new enzymes for industrial chemical reactions.
12. Several companies including Adobe, IBM, Nvidia, Cohere, Palantir, Salesforce, Scale AI, and Stability AI have pledged to the White House to develop safe and trustworthy AI, in a voluntary agreement similar to an earlier one signed by Meta, Google, and OpenAI.
13. **Microsoft** will provide legal protection for customers who are sued for copyright infringement over content generated using Copilot, Bing Chat, and other AI services as long as they use built-in guardrails.
14. **NVIDIA** beta released **TensorRT** \- an open-source library that accelerates and optimizes inference performance on the latest LLMs on NVIDIA Tensor Core GPUs.
15. Pulitzer Prize winning novelist Michael Chabon and several other writers sue OpenAI of copyright infringement..
16. **NVIDIA** partners with two of Indiaâ€™s largest conglomerates, Reliance Industries Limited and Tata Group, to create an AI computing infrastructure and platforms for developing AI solutions.
17. **Roblox** announced a new conversational AI assistant that let creators build virtual assets and write code with the help of generative AI.
18. **Google** researchers introduced **MADLAD-400** \- a 3T token multilingual, general web-domain, document-level text dataset spanning 419 Languages.
19. A recent survey by **Salesforce** show that 65% of generative AI users are Millennials or Gen Z, and 72% are employed.  The survey included 4,000+ people across the United States, UK, Australia, and India.
20. **Meta** is reportedly working on an AI model designed to compete with GPT-4.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
12,learnmachinelearning,gpt-3,top,2020-08-27 03:29:43,"GPT-3 used to generate code for a machine learning model, just by describing the dataset and required output / Via Matt Shumer(Twitter)",TheInsaneApp,False,0.96,125,ihdpgv,https://v.redd.it/1op7cffisgj51,15,1598498983.0,
13,learnmachinelearning,gpt-3,top,2023-06-03 14:33:38,This week in AI - all the Major AI development in a nutshell,wyem,False,0.98,117,13zeoi3,https://www.reddit.com/r/learnmachinelearning/comments/13zeoi3/this_week_in_ai_all_the_major_ai_development_in_a/,13,1685802818.0,"1. The recently released open-source large language model **Falcon LLM**, by UAEâ€™s Technology Innovation Institute, is now royalty-free for both commercial and research usage. **Falcon 40B,** the 40 billion parameters model trained on one trillion tokens, is ranked #1 on **Open LLM Leaderboard by Hugging Face**.
2. **Neuralangelo**, a new AI model from Nvidia turns 2D video from any device - cell phone to drone capture - into 3D structures with intricate details using neural networks..
3. In three months, JPMorgan has advertised **3,651 AI jobs** and sought a trademark for **IndexGPT**, a securities analysis AI product.
4. **Google** presents **DIDACT** (â€‹â€‹Dynamic Integrated Developer ACTivity), the first code LLM trained to model real software developers editing code, fixing builds, and doing code review. DIDACT uses the software development process as training data and not just the final code, leading to a more realistic understanding of the development task.
5. Researchers from **Deepmind** have presented â€˜**LLMs As Tool Makers (LATM)**â€™ - a framework that allows Large Language Models (LLMs) to create and use their own tools, enhancing problem-solving abilities and cost efficiency. With this approach, a sophisticated model (like GPT-4) can make tools (where a tool is implemented as a Python utility function), while a less demanding one (like GPT-3.5) uses them.
6. **Japan's government** won't enforce copyrights on data used for AI training regardless of whether it is for non-profit or commercial purposes.
7. *â€˜Mitigating the* ***risk of extinction from AI*** *should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.â€™ -* One sentence statement signed by leading AI Scientists as well as many industry experts including CEOs of OpenAI, DeepMind and Anthropic.*.*
8. Nvidia launched â€˜**Nvidia Avatar Cloud Engine (ACE) for Games**â€™ - a custom AI model foundry service to build non-playable characters (NPCs) that not only engage in dynamic and unscripted conversations, but also possess evolving, persistent personalities and have precise facial animations and expressions.
9. **OpenAI** has launched a trust/security portal for OpenAIâ€™s compliance documentation, security practices etc..
10. **Nvidia** announced a new AI supercomputer, the **DGX GH200,** for giant models powering Generative AI, Recommender Systems and Data Processing. It has 500 times more memory than its predecessor, the DGX A100 from 2020.
11. Researchers from Nvidia presented **Voyager**, the first â€˜LLM-powered embodied lifelong learning agentâ€™ that can explore, learn new skills, and make new discoveries continually without human intervention in the game Minecraft.
12. The a16z-backed chatbot startup **Character.AI** launched its mobile AI chatbot app on May 23 for iOS and Android, and succeeded in gaining over **1.7 million new installs** within a week.
13. Microsoft Research presents **Gorilla**, a fine-tuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls.
14. **OpenAI** has trained a model using process supervision - rewarding the thought process rather than the outcome - to improve mathematical reasoning. Also released the full dataset used.
15. **WPP**, the world's largest advertising agency, and Nvidia have teamed up to use generative AI for creating ads. The new platform allows WPP to tailor ads for different locations and digital channels, eliminating the need for costly on-site production.
16. **PerplexityAIâ€™s** android app is available now, letting users search with voice input, learn with follow-up questions, and build a library of threads.

**If you like this news format**, you might find my Â [newsletter](https://aibrews.com/)Â helpful - it's free to join, sent only once a week with **bite-sized news, learning resources and selected tools**. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
14,learnmachinelearning,gpt-3,top,2023-02-11 06:58:18,[N] New Open-Source Version Of ChatGPT â­•,LesleyFair,False,0.98,116,10zep6u,https://www.reddit.com/r/learnmachinelearning/comments/10zep6u/n_new_opensource_version_of_chatgpt/,8,1676098698.0,"GPT is getting competition from open-source.

A group of researchers, around the YouTuber [Yannic Kilcher](https://www.ykilcher.com/), have announced that they are working on [Open Assistant](https://github.com/LAION-AI/Open-Assistant). The goal is to produce a chat-based language model that is much smaller than GPT-3 while maintaining similar performance.

If you want to support them, they are crowd-sourcing training data [here](https://open-assistant.io/).

**What Does This Mean?**

Current language models are too big.

They require millions of dollars of hardware to train and use. Hence, access to this technology is limited to big organizations. Smaller firms and universities are effectively shut out from the developments.

Shrinking and open-sourcing models will facilitate academic research and niche applications.

Projects such as Open Assistant will help to make language models a commodity. Lowering the barrier to entry will increase access and accelerate innovation.

What an exciting time to be alive! 

Thank you for reading! I really enjoyed making this for you!  
The Decoding â­• is a thoughtful weekly 5-minute email that keeps you in the loop about machine research and the data economy. [Click here to sign up](https://thedecoding.net/)!"
15,learnmachinelearning,gpt-3,top,2023-06-11 17:18:34,"[D] How to Choose a Framework To Evaluate Your LLMs? We've Evaluated GPT-4/3.5, Anthropic Claude, & Cohere Command Across 4 Tasks. Here's What We've Learned.",davidbun,False,0.98,110,146zie8,https://v.redd.it/yy5sdnvo6f5b1,1,1686503914.0,
16,learnmachinelearning,gpt-3,top,2023-06-23 06:14:03,"[Updated] Top Large Language Models based on the Elo rating, MT-Bench, and MMLU",kingabzpro,False,0.94,92,14gqo26,https://i.redd.it/ixdabwx3mp7b1.png,9,1687500843.0,
17,learnmachinelearning,gpt-3,top,2023-02-21 14:59:06,I created a Search Engine For Books using GPT-3 ðŸ”ŽðŸ“˜. Here's how you can create it too:,Pritish-Mishra,False,0.94,88,1185dhq,https://youtu.be/SXFP4nHAWN8,17,1676991546.0,
18,learnmachinelearning,gpt-3,top,2023-09-30 15:01:31,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.97,78,16w93bx,https://www.reddit.com/r/learnmachinelearning/comments/16w93bx/this_week_in_ai_all_the_major_ai_developments_in/,4,1696086091.0,"1. **Meta AI** presents **Emu**, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal.
2. **Meta AI** researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16kâ€™s overall performance on a suite of long-context tasks.
3. **Abacus AI** released a larger 70B version of **Giraffe**. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens\].
4. **Meta** announced:  

   1. **Meta AI** \- a new AI assistant users can interact with on WhatsApp, Messenger and Instagram. Will also be available on Ray-Ban Meta smart glasses and Quest 3, Metaâ€™s mixed reality headset.
   2. **AI stickers** that enable users to generate customized stickers for chats and stories using text. Powered by Llama 2 and the new foundational model for image generation, Emu.
   3. **28 AI characters**, each with a unique personality that users can message on WhatsApp, Messenger, and Instagram.
   4. New AI editing tools, **restyle** and **backdrop** in Instagram.
   5. **AI Studio** \- a platform that supports the creation of custom AIs by coders and non-coders alike.
5. **Cerebras** and **Opentensor** released Bittensor Language Model, â€˜**BTLM-3B-8K**â€™, a new 3 billion parameter open-source language model with an 8k context length trained on 627B tokens of SlimPajama. It outperforms models trained on hundreds of billions more tokens and achieves comparable performance to open 7B parameter models. The model needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models and is available with an Apache 2.0 license for commercial use.
6. **OpenAI** is rolling out, over the next two weeks, new voice and image capabilities in ChatGPT enabling ChatGPT to understand images, understand speech and speak. The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. .
7. **Mistral AI**, a French startup, released its first 7B-parameter model, **Mistral 7B**, which outperforms all currently available open models up to 13B parameters on all standard English and code benchmarks. Mistral 7B is released in Apache 2.0, making it usable without restrictions anywhere.
8. **OpenAI** has returned the ChatGPT browsing feature for Plus subscribers, enabling ChatGPT to access internet for current information. It was disabled earlier as users were able to deploy it to bypass the paywalls of leading news publishers.
9. **Microsoft** has released **AutoGen** \- an open-source framework that enables development of LLM applications using multiple agents that can converse with each other to solve a task. Agents can operate in various modes that employ combinations of LLMs, human inputs and tools.
10. **LAION** released **LeoLM**, the first open and commercially available German foundation language model built on Llama-2
11. Researchers from **Google** and **Cornell University** present and release code for DynIBaR (Neural Dynamic Image-Based Rendering) - a novel approach that generates photorealistic renderings from complex, dynamic videos taken with mobile device cameras, overcoming fundamental limitations of prior methods and enabling new video effects.
12. **Cloudflare** launched **Workers AI** (an AI inference as a service platform), **Vectorize** (a vector Database) and **AI Gateway** with tools to cache, rate limit and observe AI deployments. Llama2 is available on Workers AI.
13. **Amazon** announced the general availability of **Bedrock**, its service that offers a choice of generative AI models from Amazon itself and third-party partners through an API.
14. **Google** announced itâ€™s giving website publishers a way to opt out of having their data used to train the companyâ€™s AI models while remaining accessible through Google Search.
15. **Spotify** has launched a pilot program for AI-powered voice translations of podcasts in other languages - in the podcasterâ€™s voic. It uses OpenAIâ€™s newly released voice generation model.
16. **Getty Images** has launched a generative AI image tool, â€˜**Generative AI by Getty Images**â€™, that is â€˜commerciallyâ€‘safeâ€™. Itâ€™s powered by Nvidia Picasso, a custom model trained exclusively using Gettyâ€™s images library.
17. **Optimus**, Teslaâ€™s humanoid robot, can now sort objects autonomously and do yoga. Its neural network is trained fully end-to-end.
18. **Amazon** will invest up to $4 billion in Anthropic. Developers and engineers will be able to build on top of Anthropicâ€™s models via Amazon Bedrock.
19. **Google Search** indexed shared Bard conversational links into its search results pages. Google says it is working on a fix.
20. **Pika** Labs' text-to-video tool now lets users encrypt a message in a video\].

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
19,learnmachinelearning,gpt-3,top,2023-01-15 00:08:37,Is it still worth learning NLP in the age of API-accessibles LLM like GPT?,CrimsonPilgrim,False,0.94,63,10c509n,https://www.reddit.com/r/learnmachinelearning/comments/10c509n/is_it_still_worth_learning_nlp_in_the_age_of/,24,1673741317.0,"A question that, I hope, you will find legitimate from a data science student.

I am speaking from the point of view of a data scientist not working in research.

Until now, learning NLP could be used to meet occasional business needs like sentiment analysis, text classification, topic modeling....

With the opening of GPT-3 to the public, the rise of ChatGPT, and the huge wave of applications, sites, plug-ins and extensions based on this technology that are accessible with a simple API request, it's impossible not to wonder if spending dozens of hours diving into this field if ML wouldn't be as useful today as learning the source code of the Pandas library. 

In some specialized cases, it could be useful, but GPT-3, and the models that will follow, seem to offer more than sufficient results for the immensity of the cases and for almost all classical NLP tasks. Not only that, but there is a good chance that the models trained by giants like Open-AI (Microsoft) or Google can never be replicated outside these companies anyway.  With ChatGPT and its incomparable mastery of language, its ability to code, summarize, extract topics, understand... why would I bother to use BERT or a TF-IDF vectorizer when an API will be released? Not only it would be easily accessible, but it also would be much better at the task, faster and cheaper.

In fact, it's a concern regarding all the machine learning field in general with the arrival of powerful ""no-code"" applications, which abstract a large part of the inherent complexity of the field. There will always be a need for experts, for safeguards, but in the end, won't the Data Scientist who masters the features of GPT-3 or 4 and knows a bit of NLP be more efficient than the one who has spent hours reading Google papers and practicing on Gensim, NLTK, spacy... It is the purpose of an API to make things simpler eventually... At what point is there no more reason to be interested in the behind-the-scenes of these tools and to become simple users rather than trying to develop our own techniques?"
20,learnmachinelearning,gpt-3,top,2023-03-30 19:44:32,Personalize Your Own Language Model with xTuring - A Beginner-Friendly Library,x_ml,False,0.99,59,126x6ua,https://www.reddit.com/r/learnmachinelearning/comments/126x6ua/personalize_your_own_language_model_with_xturing/,7,1680205472.0,"Hi everyone,  


If you are interested in customizing your own language model but don't know where to start, try  [xTuring](https://github.com/stochasticai/xturing).  


xTuring's goal is to empower individuals to fine-tune LLM for their specific tasks with as little as 5 lines of code. With xTuring, you can perform high and low precision fine-tuning with a variety of models, including LLaMA, OPT, Cerebras-GPT, Galactica, BLOOM, and more.   


You can also generate your OWN datasets using powerful models like GPT-3 to train a much smaller model on YOUR specific task. With the latest version, you can also use terminal and web interface to chat with your models.  


Please do check out the repo and show your support if you like our work. Would love if you can also contribute by adding models, raising issues or raising PRs for fixes.  


xTuring Github: [https://github.com/stochasticai/xturing](https://github.com/stochasticai/xturing)

If you are interested in getting involved, I am happy to help you on our Discord: [https://discord.gg/TgHXuSJEk6](https://discord.gg/TgHXuSJEk6)

https://i.redd.it/mvxb7i5fixqa1.gif"
21,learnmachinelearning,gpt-3,top,2022-12-30 01:18:38,A GPT-3 based Terminal/CLI tool that helps you debug your code!,VideoTo,False,0.97,56,zyms85,https://www.reddit.com/r/learnmachinelearning/comments/zyms85/a_gpt3_based_terminalcli_tool_that_helps_you/,11,1672363118.0,"Link - [https://clerkie.co/](https://clerkie.co/)

We built ClerkieCLI -  a GPT-3 based tool that:

\-  automatically detects errors on your terminal,

\- identifies  the programming language,

\- provides an explanation of the error and suggested fix right on your terminal.

This is definitely early days, so if this is something you would find  valuable and wouldn't mind testing a couple iterations of, just sign up here -> [https://forms.gle/8DURoG6NCRxVazNn8](https://forms.gle/8DURoG6NCRxVazNn8)

&#x200B;

https://i.redd.it/xpwnazimsx8a1.gif"
22,learnmachinelearning,gpt-3,top,2023-02-21 23:18:46,"How big was GPT-3.5's training dataset, and are there any good heuristics for how large an ML dataset needs to be for it to be good?",TikkunCreation,False,0.93,54,118iccl,https://www.reddit.com/r/learnmachinelearning/comments/118iccl/how_big_was_gpt35s_training_dataset_and_are_there/,6,1677021526.0,"Say I want to do a model for fixing bugs in code. How many examples do I need for it to be good?

Or say I want to do a model for scoring boxing matches. How many examples do I need for it to be good?"
23,learnmachinelearning,gpt-3,top,2023-05-02 08:48:46,How GPT-3.5 crushes my high score in 2048,inishchith,False,0.74,53,135ffje,https://v.redd.it/q22lna91tdxa1,28,1683017326.0,
24,learnmachinelearning,gpt-3,top,2023-07-15 21:22:23,"I Hit 700K Views in 3 Months with my open-source Shorts automation framework, ShortGPT",RayVentura,False,0.85,52,150ng7i,https://v.redd.it/i1slpmgd17cb1,13,1689456143.0,
25,learnmachinelearning,gpt-3,top,2021-06-13 20:57:38,Some YouTube channels that review papers,axetobe_ML,False,0.97,54,nz5szs,https://www.reddit.com/r/learnmachinelearning/comments/nz5szs/some_youtube_channels_that_review_papers/,2,1623617858.0,"When I was reading a Reddit thread. People were wondering if there were YouTubers reviewing papers. As the OP noticed that one of the YouTuber's that he regularly watched stopped uploading videos. There are a few YouTubers that talk about ML and review papers. 

I decided to compile some of the YouTube channels into this short list. 

&#x200B;

[Two Minute Papers](https://www.youtube.com/c/K%C3%A1rolyZsolnai/videos) does great overviews of fascinating papers. Showing the increasing progress of ML.

Some of the videos I liked:

* [4 Experiments Where the AI Outsmarted Its Creators](https://www.youtube.com/watch?v=GdTBqBnqhaQ)

This video showed various AI solving a problem not in the way the researchers intended to. That may include abusing the physics in the simulation or lateral thinking used by the model.

* [A Video Game That Looks Like Reality!](https://youtu.be/22Sojtv4gbg)

A review of a paper that takes GTA V gameplay and converts them to photo-realistic footage.

&#x200B;

[Yannic Kilcher](https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew) does in-depth reviews of various papers. As you go through the paper he shows you his thought process. And showing what important inside the paper. Very useful if donâ€™t read that many papers. (Like me)

Some good videos:

* [Attention Is All You Need](https://www.youtube.com/watch?v=iDulhoQ2pro)

A review of a paper that introduced transformers.

&#x200B;

* [DeepMind's AlphaFold 2 Explained! AI Breakthrough in Protein Folding What we know (& what we don't)](https://youtu.be/B9PL__gVxLI)

A great rundown on protein folding and speculating how Alphafold 2 works.

&#x200B;

* [GPT-3: Language Models are Few-Shot Learners (Paper Explained)](https://youtu.be/SY5PvZrJhLE)

A comprehensive paper reading of the GPT-3 paper.

&#x200B;

[Bycloud](https://www.youtube.com/channel/UCgfe2ooZD3VJPB6aJAnuQng) you may have seen him around on Reddit. Creates short and insightful summaries of papers.

Some videos I liked:

* [AI Sky Replacement with SkyAR](https://www.youtube.com/watch?v=yNwQnrjfg5A)

Summary of paper that creates AR effects in video footage. Adding various effects to the video footageâ€™s sky.

&#x200B;

* [AI Generates Cartoon Characters In Real Life \[Pixel2Style2Pixel\]](https://youtu.be/g-N8lfceclI)

Reviewing a paper that converts cartoon characters to real-life equivalents and vice versa. Also explains how the paper made it easier to adjust the parameters of the GAN. Helping us adjust what images we want to produce.

&#x200B;

[Machine Learning Street Talk](https://www.youtube.com/c/MachineLearningStreetTalk/videos)

This is a podcast series that interviews top ML researchers. While they donâ€™t have videos about papers alone. As they interview various experts in the field. So they talk about many papers as a consequence. 

While this is a short list maybe you can find these channels interesting and learn something new.

\-

*If you found this post useful, then check out my* [*mailing list*](https://www.tobiolabode.com/subscribe) *where I write more stuff like this.*"
26,learnmachinelearning,gpt-3,top,2023-12-03 14:38:25,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.93,49,189ustx,https://www.reddit.com/r/learnmachinelearning/comments/189ustx/this_week_in_ai_all_the_major_ai_developments_in/,1,1701614305.0,"1. **Meta AI** introduced a suite of AI language translation models that preserve expression and improve streaming \[[*Details*](https://ai.meta.com/blog/seamless-communication) *|* [*GitHub*](https://github.com/facebookresearch/seamless_communication)\]:
   1. ***SeamlessExpressive*** enables the transfer of tones, emotional expression and vocal styles in speech translation. You can try a demo of SeamlessExpressive using your own voice as an input [***here***](https://seamless.metademolab.com/expressive)***.***
   2. ***SeamlessStreaming***, a new model that enables streaming speech-to-speech and speech-to-text translations with <2 seconds of latency and nearly the same accuracy as an offline model. In contrast to conventional systems which translate when the speaker has finished their sentence, SeamlessStreaming translates while the speaker is still talking. t intelligently decides when it has enough context to output the next translated segment.
   3. ***SeamlessM4T v2***, a foundational multilingual & multitask model for both speech & text. It's the successor to SeamlessM4T, demonstrating performance improvements across ASR, speech-to-speech, speech-to-text & text-to-speech tasks.
   4. ***Seamless***, a model that merges capabilities from SeamlessExpressive, SeamlessStreaming and SeamlessM4T v2 into one.
2. **Stability AI** released ***SDXL Turbo***: a real-time Text-to-Image generation model. SDXL Turbo is based on a a new distillation technology, which enables the model to synthesize image outputs in a single step and generate real-time text-to-image outputs while maintaining high sampling fidelity.
3. **Mozillaâ€™s** innovation group and Justine Tunney released ***llamafile*** that lets you distribute and run LLMs with a single file. llamafiles can run on six OSes (macOS, Windows, Linux, FreeBSD, OpenBSD, and NetBSD) and on multiple CPU architectures.
4. **Perplexity** released two new PPLX models: ***pplx-7b-online and pplx-70b-online***. These *online LLMs* can leverage the most up-to-date information using the internet when forming a response..
5. **Google DeepMind** presented ***GNoME*** (Graph Networks for Materials Exploration): an AI tool that discovered *2.2 million new crystal structures*, with 380,000 being highly stable and promising for breakthroughs in superconductors, supercomputers, and advanced batteries for electric vehicles.
6. **Amazon** introduced two new Amazon Titan multimodal foundation models (FMs): ***Amazon Titan Image Generator*** (preview) and ***Amazon Titan Multimodal Embeddings***. All images generated by Amazon Titan contain an invisible watermark.
7. Researchers present ***Animatable Gaussians***, a new avatar representation method that can create lifelike human avatars from multi-view RGB videos.
8. **Pika Labs** released a major product upgrade of their generative AI video tool, ***Pika 1.0***, which includes a new AI model capable of generating and editing videos in diverse styles such as 3D animation, anime, cartoon and cinematic using text, image or existing video.
9. **Eleven Labs** announced a ***grant*** program offering 11M text characters of content per month for the first 3 months to solo-preneurs and startups.
10. Researchers from **UC Berkeley** introduced ***Starling-7B***, an open large language model trained using Reinforcement Learning from AI Feedback (RLAIF). It utilizes the GPT-4 labeled ranking dataset, Nectar, and a new reward training pipeline. Starling-7B outperforms every model to date on MT-Bench except for OpenAIâ€™s GPT-4 and GPT-4 Turbo .
11. **XTX Markets** is launching a new $10mn challenge fund, the **Artificial Intelligence Mathematical Olympiad Prize** (AI-MO Prize) The grand prize of $5mn will be awarded to the first publicly-shared AI model to enter an AI-MO approved competition and perform at a standard equivalent to a gold medal in the in the International Mathematical Olympiad (IMO) .
12. **Microsoft Research** evaluated GPT-4 for processing ***radiology reports***, focusing on tasks like disease classification and findings summarization. The study found GPT-4 has a sufficient level of radiology knowledge with only occasional errors in complex context that require nuanced domain knowledge. The radiology report summaries generated by GPT-4 were found to be comparable and, in some cases, even *preferred* over those written by experienced radiologists.
13. **AWS** announced ***Amazon Q***, a new generative AIâ€“powered assistant for businesses. It enables employees to query and obtain answers from various content repositories, summarize reports, write articles, perform tasks, and more, all within their company's integrated content systems. Amazon Q offers over 40 built-in connectors to popular enterprise systems.
14. 18 countries including the US, Britain signed a detailed international agreement on how to keep artificial intelligence safe from rogue actors, pushing for companies to create AI systems that are â€˜secure by designâ€™ .

**Source**: AI Brews - you can subscribe [here](https://aibrews.com/). it's free to join, sent only once a week with ***bite-sized news, learning resources and selected tools.*** I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks."
27,learnmachinelearning,gpt-3,top,2020-09-13 12:49:48,"GPT-3 concrete real-world examples of what it can do. Do you think GPT-3 will change our lives, or is it just hype? Are the applications really useful and real, in the real-world, or are they only the hand-picked results by the researchers and startup to get some hype around them and followers?",OnlyProggingForFun,False,0.97,46,irxokh,https://www.youtube.com/watch?v=Gm4AMjV8ErM,3,1600001388.0,
28,learnmachinelearning,gpt-3,top,2024-01-04 21:15:12,Natural Language Processing (NLP) Learning Path - In depth,millhouse056,False,0.98,49,18yo5kp,https://www.reddit.com/r/learnmachinelearning/comments/18yo5kp/natural_language_processing_nlp_learning_path_in/,9,1704402912.0,"Hi friends, i'm currently engaged in NLP and created an pretty extense roadmap or learning path so begginers don't feel lost, it covers from the basics to advanced cutting-edge concepts.

Feedback is appreciated.

&#x200B;

\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-

&#x200B;

NLP Learning Roadmap

1. Prerequisites:

&#x200B;

* Mathematics:

&#x200B;

* Linear algebra
* Probability and statistics

&#x200B;

* Programming:

&#x200B;

* Proficiency in a programming language (e.g., Python)

**2. Introduction to NLP:**

&#x200B;

* Definition      and scope of NLP
* Historical      development of NLP
* Key challenges      and applications

**3. Text Analysis:**

&#x200B;

* **Lexical Analysis:**

&#x200B;

* Word meaning and structure

Â· Morphology (word formation)

Â· lemmatization (base form identification)

&#x200B;

* **Syntactic Analysis:**

Â· Parts-of-speech tagging

Â· Dependency parsing

Â· Constituency parsing

&#x200B;

* **Semantic Analysis:**

Â· Extracting meaning

Â· Encompassing word embedding models like Word2Vec and GloVe

Â· Topic modeling

&#x200B;

* **Semantic Analysis:**

Â· Coreference resolution

Â· Discourse analysis

&#x200B;

**3. Text Processing:**

&#x200B;

* **Tokenization:**

&#x200B;

* Sentence tokenization
* Word tokenization
* Subword tokenization (Byte Pair Encoding, SentencePiece)

&#x200B;

* **Stop Words Removal:**

&#x200B;

* Importance and impact on NLP tasks
* Customizing stop word lists

&#x200B;

* **Stemming and Lemmatization:**

&#x200B;

* Porter stemming algorithm
* Snowball stemming algorithm
* Lemmatization techniques and challenges

&#x200B;

* **Part-of-Speech Tagging:**

 

* POS tagging algorithms (HMM-based, rule-based, and neural-based)
* Fine-grained POS tagging

**4. Text Representation:**

&#x200B;

* **Bag of Words (BoW):**

 

* Term Frequency (TF) and Inverse Document Frequency (IDF)
* Bag of N-grams

&#x200B;

* **TF-IDF:**

 

* Calculating TF-IDF scores
* Applications in information retrieval

&#x200B;

* **Word Embeddings:**

 

* Word2Vec:

&#x200B;

* Continuous Bag of Words (CBOW) model
* Skip-gram model
* GloVe (Global Vectors for Word Representation)

&#x200B;

* **Contextual Embeddings:**

 

* ELMo (Embeddings from Language Models)
* ULMFiT (Universal Language Model Fine-tuning)
* OpenAI GPT (Generative Pre-trained Transformer)

**5. NLP Libraries and Tools:**

&#x200B;

* NLTK      (Natural Language Toolkit)
* SpaCy
* scikit-learn
* Transformers      library (Hugging Face)

**6. Statistical Language Models:**

&#x200B;

* **N-grams:**

 

* Unigrams, bigrams, and trigrams
* N-gram language models

&#x200B;

* **Hidden Markov Models (HMM):**

 

* Basics of HMMs
* Applications in part-of-speech tagging

**7. Machine Learning for NLP:**

&#x200B;

* **Supervised Learning:**

 

* Text classification algorithms (Naive Bayes, Support Vector       Machines)
* Evaluation metrics (precision, recall, F1-score)

&#x200B;

* **Named Entity Recognition (NER):**

 

* Rule-based NER
* Machine learning-based NER
* Evaluation metrics for NER

&#x200B;

* **Sentiment Analysis:**

 

* Sentiment lexicons
* Machine learning approaches for sentiment analysis

**8. Sequence-to-Sequence Models:**

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Vanishing and exploding gradient problems
* Bidirectional RNNs

&#x200B;

* **Long Short-Term Memory (LSTM):**

 

* Architecture and key components
* Gating mechanisms

&#x200B;

* **Gated Recurrent Unit (GRU):**

 

* Simplified gating compared to LSTM
* Applications and advantages

**9. Deep Learning Architectures for NLP:**

&#x200B;

* **Convolutional Neural Networks (CNN) for Text:**

 

* Text classification with CNNs
* Hierarchical and multi-channel CNNs

&#x200B;

* **Transfer Learning in NLP:**

 

* Fine-tuning pre-trained models
* Universal Sentence Encoder

&#x200B;

* **Transformer Architecture:**

 

* Self-attention mechanism
* Multi-head attention
* Positional encoding

**10. Transduction and Recurrency:**

&#x200B;

* **Transduction in NLP:**

 

* Definition and applications
* Challenges in sequence-to-sequence transduction

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Applications beyond sequence-to-sequence tasks
* Challenges in training RNNs

**11. Advanced Topics in Sequence Modeling:**

&#x200B;

* **Attention Mechanism:**

 

* Scaled Dot-Product Attention
* Position-wise Feedforward Networks

&#x200B;

* **Self-Attention Mechanism:**

 

* The concept of self-attention
* Layer normalization in self-attention

&#x200B;

* **Multi-Head Attention:**

 

* Motivation and benefits
* Combining multiple attention heads

**12. Syntax and Parsing:**

&#x200B;

* **Dependency Parsing:**

 

* Dependency tree representation
* Transition-based and graph-based parsing

&#x200B;

* **Constituency Parsing:**

 

* Treebank representation
* Earley parsing algorithm

&#x200B;

* **Parsing Techniques:**

 

* Chart parsing (CYK parser)
* Shift-Reduce parsing

**13. Semantic Role Labeling (SRL) and Coreference Resolution:**

&#x200B;

* **Semantic Role Labeling:**

&#x200B;

* PropBank and FrameNet
* Neural approaches to SRL

&#x200B;

* **Coreference Resolution:**

&#x200B;

* Mention detection
* End-to-end coreference resolution models

**14. Evaluation Metrics:**

&#x200B;

* Precision,      Recall, F1-score
* BLEU      score for machine translation
* Perplexity      for language models

**15. NLP in Industry and Research:**

&#x200B;

* Case      studies and applications in various domains (healthcare, finance, legal,      etc.)
* Emerging      research trends in NLP

**16. Ethical Considerations and Bias in NLP:**

&#x200B;

* **Addressing Bias in NLP Models:**

&#x200B;

* Identifying and mitigating biases in training data
* Fairness-aware machine learning

&#x200B;

* **Ethical Considerations in NLP Research and      Deployment:**

&#x200B;

* Privacy concerns in NLP
* Responsible AI practices in NLP

**17. Continuous Learning and Keeping Updated:**

&#x200B;

* Follow      conferences (ACL, NAACL, EMNLP)
* Engage      with the NLP community
* Explore      recent research papers and advancements (Arxiv, NeurIPS)

**18. Projects and Hands-on Practice:**

&#x200B;

* Apply      knowledge through practical projects
* Contribute      to open-source NLP projects
* Participate      in Kaggle competitions

==============================="
29,learnmachinelearning,gpt-3,top,2023-09-12 13:42:02,This is why LLMs have flooded the NLP market in the past 1 year ðŸ‘‡ (A Brief History of NLP),japkeerat,False,0.82,43,16grq5y,https://www.reddit.com/r/learnmachinelearning/comments/16grq5y/this_is_why_llms_have_flooded_the_nlp_market_in/,15,1694526122.0,"Text Generation has been the hottest topic in Natural Language Processing. Recurrent Neural Networks (RNNs) were among the Algorithms to generate text. How RNNs generated text is by essentially predicting the next word given the previous few words. At one-stage RNNs were the hottest commodity one could have. But researchers were worried about 1 problem.

RNNs had a context-length problem. To understand what is context-length, consider an analogy. You started reading a book, itâ€™s 100 pages long and when you read each page, details of previous pages start to get a little hazy. Haziness keeps on increasing to the point that when you reach page 50, you donâ€™t remember anything from the first 5 pages. That is exactly what the problem is with RNNs.

To solve this, researchers developed another algorithm called the Long-Short Term Memory (LSTM) and another variant called Bidirectional Long-Short Term Memory (Bi-LSTM) which had a larger context-length than RNNs. Letâ€™s get back to the book analogy. This time while reading, you are making notes. When you go ahead to a new page and your previous pages information start to get hazy, you look back at these notes to refresh your memory. Itâ€™s oversimplified, but thatâ€™s basically how an LSTM works.

LSTMs were not perfect. There were a number of new issues that came up in order to resolve the previous one. Meanwhile, other areas of research and technological advancements were heating up. Hardware was getting more and more prominent and with cloud getting popular, it was easily accessible. And on the research side, a new kind of Algorithm came up that shaped the entire NLP domain from here on - Attention Mechanism.

Attention Mechanism, as you might have guessed, is all about telling the more sophisticated algorithms where to â€œfocusâ€. Itâ€™s the same way how we focus more on certain parts of the meeting we attend than the entire meeting itself. In context of NLP, the Mechanism became the core part for better algorithms. These better algorithms could keep larger context-lengths and at the time of predicting the next word, ask the Attention Mechanism about what to focus on while predicting the next word. This was an era-defining discovery in NLP as the algorithms that came up after this were the Transformers.

Consider jigsaw puzzles. You start by looking at all the pieces at once and join the pieces together. Initially, it is random. You join a couple of pieces at the top left corner, a few in the centre and a couple more defining the right edge. You are doing it all at once. Transformers basically work the same way. They could look at longer context-lengths, all at once, courtesy of Attention Mechanism. This means, they can not only work with a sentence, they can work with an entire paragraph.  With time, these Transformers started becoming more and more sophisticated. It eventually reached to a point that the only thing that was keeping these algorithms in handcuffs was the lack of data.

Until recently, these algorithms were trained on a specific data but when algorithms became too powerful, researchers started throwing every kind of data they could find on the internet easily. It could be articles like this, your social media posts, exam papers and solutions, and ebooks in any language they could find and hoped the algorithms learnt it all. And they were right. Algorithms started learning all of it to the point that you could ask models to explain concepts of LLMs in how Shakespeare would write and it would give a real-sounding responsive. These algorithms were Large! And hence, became known as Large Language Models (LLMs).

There we are now. With LLMs. OpenAI, technically, won the race for LLM development. They brought everybodyâ€™s attention to LLMs first with GPT-2, but GPT-3 was where shit hit the roof and every company that had deep pockets started investing in LLMs.  The result? We now have a new LLM getting released EVERY. SINGLE. DAY.

*I post articles like these every few days on X. If you like this post, please* [follow me on X!](https://twitter.com/JapkeeratS/)

*NOTE: To make it simple for anybody, even without a tech background, to understand, a few things were oversimplified. I will be sharing soon on* [my X handle](https://twitter.com/JapkeeratS) *a technical version.*"
30,learnmachinelearning,gpt-3,top,2022-01-07 13:14:54,A quick review of GPT-3 | What is it and how does it work?,turpyturp,False,0.86,42,ry74jf,https://www.youtube.com/watch?v=xB6hZwYsV2c,1,1641561294.0,
31,learnmachinelearning,gpt-3,top,2022-06-03 18:16:55,"What questions should I ask Hugging Face's Chief Evangelist next week, fresh off the company's $100M Series C raise on a $2B valuation to build the GitHub of ML?",4thBrain,False,0.89,42,v45gjp,https://www.reddit.com/r/learnmachinelearning/comments/v45gjp/what_questions_should_i_ask_hugging_faces_chief/,10,1654280215.0,"I've got the unique opportunity to host a live event next week where [Julien Simon](https://www.linkedin.com/in/juliensimon/), Hugging Face's chief evangelist, will be presenting on Building NLP Applications with Transformers.

He's going to present a few slides and then do a live demo of how to build an end-to-end ML application.

Then I've got 10 minutes or so to ask him anything I want.

**What would you ask him?**

Here's my working list of questions:

* Hugging Face is doing so many amazing things.  As an early ML practitioner or a student trying to break into ML, where would you recommend focusing your time if you want to understand how to apply Hugging Face tools in a hands-on way?  Are there any resources that you would recommend our audience check out first?
* What is your perspective on the difference between a Data Scientist, Machine Learning Engineer, and MLOps Engineer in todayâ€™s AI market?  What about at Hugging Face - how does your company make these distinctions?
* How do you think about what is actually happening to the underlying model when a general pre-trained transformer model - say, GPT-2 or GPT-3 - gets fine-tuned with unique text, image, speech, or time-series data?

Note:

Keep in mind that this guy is the real deal.  He wrote the book on Learning Amazon SageMaker (2nd edition last year) while he was a Principal Technical Evangelist for AWS.  Prior to joining AWS, Julien served for 10 years as CTO and VP of Engineering in large-scale web startups, and also wrote the first French-language Linux documentation back in 1992!"
32,learnmachinelearning,gpt-3,top,2023-12-26 07:39:32,Can you guess who wrote this code ? A Developer or a Researcher/Scientist,Left_Papaya_9750,False,0.86,40,18r2vqv,https://www.reddit.com/r/learnmachinelearning/comments/18r2vqv/can_you_guess_who_wrote_this_code_a_developer_or/,47,1703576372.0,"    import torch 
    from torch.optim.lr_scheduler import CosineAnnealingLR
    from gpt import GPTLanguageModel
    from transformers import GPT2Tokenizer
    from tqdm import tqdm
    from utils.draw_plots import Draw
    import pynvml as nvml
    import os
    import time
    import wandb
    from utils import draw_stuff
    from torch.utils.data import DataLoader, SubsetRandomSampler
    from utils.load_data import LoadDataset
    import signal 
    from colorama import Fore
    from queue import Queue
    
    class Train():
        def __init__(self, **kwargs,):
            torch.manual_seed(1137)
            model= GPTLanguageModel()
            gpu_idx= 0 if not 'gpu_index' in kwargs else kwargs['gpu_index']
            nvml.nvmlInit()
            os.system(""cls"" if os.name == 'nt' else 'clear')
            draw_stuff.draw()
            self.enc= GPT2Tokenizer.from_pretrained('gpt2')
            self.device='cuda' if torch.cuda.is_available else 'cpu'
            self.m= model.to(self.device)
            self.block_size= 256 if not 'block_size' in kwargs else kwargs['block_size']
            self.batch_size= 100 if not 'batch_size' in kwargs else kwargs['batch_size']
            self.handle= nvml.nvmlDeviceGetHandleByIndex(gpu_idx)
            self.temp_thres= 85 if not 'temp_threshold' in kwargs else kwargs['temp_threshold']
            self.plot= Draw()
            
        def load_data(self,split, split_per):
            dataset= LoadDataset(split= split, split_per=split_per)
            sampler= SubsetRandomSampler(torch.randint(high=len(dataset), size=(1000,)).tolist())
            data_title= DataLoader(dataset, pin_memory= True, sampler=sampler, drop_last=True)
            return data_title
    
        @torch.no_grad()
        def estimate_loss(self, eval_iters)->torch.tensor:
            out = {}
            print(""Estimating loss\n"")
            self.m.eval()
            for split in ['train', 'val']:
                es_progress= tqdm(total=eval_iters, ncols=100)
                es_progress.colour='red'
                
                losses = torch.zeros(eval_iters)
                for k in range(eval_iters):
                    es_progress.update(1)
                    for X, Y in self.get_batch(split):
                        logits, loss = self.m(X, Y)
                        losses[k] = loss.item()
                out[split] = losses.mean()
            self.m.train()
            return out
        
        def get_batch(self, split):
            data = self.load_data(split, split_per=0.8)
            for idx, data in enumerate(data):
                doc= data
                doc_txt= doc['text'][0]
                title= doc['title'][0]
                encoded_tok= self.enc.encode(doc_txt, add_special_tokens= True)
                doc_txt_enc= torch.tensor(encoded_tok, dtype=torch.long)
                size= self.block_size
                if len(encoded_tok) - self.block_size <= 0 and len(encoded_tok)-20 >=3:
                    size=20
                ix = torch.randint(len(encoded_tok) - size , (self.batch_size,))
                x = torch.stack([doc_txt_enc[i:i+size] for i in ix]).to(self.device) 
                y = torch.stack([doc_txt_enc[i:i+size+1] for i in ix]).to(self.device) 
                yield x, y
                
    
        def display_train_params(self,train_id, device, **kwargs):
            print(f""**NOTE: GPU temperature threshold has been set to {self.temp_thres}Â°C, when the threshold is reached the training process will halt for a set period.**\n"")
            print(f""INFO {torch.cuda.memory_allocated(device)} Bytes of memory is allocated for this task\n"")
            print(f""""""Training parameters:
                      Device: {nvml.nvmlDeviceGetName(self.handle)}
                      Halt Temperature threshold:{self.temp_thres}
                      Trainable Parameters: {sum(p.numel() for p in self.m.parameters())/1e6, 'M parameters'}
                      Total Epochs: {kwargs['epochs']}
                      Evaluation Iterations: {kwargs['eval_iters']}
                      Evaluation Interval: {kwargs['eval_interval']}
                      Initial Learning rate: {kwargs['learning_rate']}
                      Learning Rate Schduler: Cosine Annealing
                      Total Memory allocated: {torch.cuda.memory_allocated(device)}B
                      \n"""""")
            
            print(f""** Training Started | Train ID : {train_id}**\n"")
    
        
        def train(self, device, train_id, is_save=True, **kwargs):
            
            wandb.init('Training',  
                        project='gpt-model',
                        config={
                            ""initial_learning_rate"":3e-4,
                            ""architecture"":""transformer"",
                            ""dataset"": ""Wikipedia general documents""
                                }
                        )
            docs= []
            eval_interval= 500 if not 'ei' in kwargs else kwargs['ei']
            learning_rate= 3e-4 if 'learning_rate' not in kwargs else kwargs['learning_rate']
            eval_iters= 300 if 'eval_iter' not in kwargs else kwargs['eval_iter']
            max_iters= 10000 if not 'epochs' in kwargs else kwargs['epochs']
            num_doc= 2000
            os.mkdir('results') if not 'results' in os.listdir('.') else None
            os.mkdir(f'results/{train_id}') if train_id not in os.listdir('results') else None
            os.mkdir(f'results/{train_id}/checkpoints') if 'checkpoints' not in os.listdir(f'results/{train_id}') else None
            os.mkdir(f'results/{train_id}/checkpoints/plots') if 'plots' not in os.listdir(f'results/{train_id}/checkpoints') else None
            torch.cuda.empty_cache()
            optimizer = torch.optim.AdamW(self.m.parameters(), 
                                          lr=learning_rate)
            schduler= CosineAnnealingLR(optimizer=optimizer, T_max=max_iters)
    
            self.display_train_params(train_id=train_id, 
                                      device=device, 
                                      epochs=max_iters, 
                                      eval_interval=eval_interval,
                                      eval_iters=eval_iters,
                                      learning_rate=learning_rate
                                      )
            
            epoch_progress_bar= tqdm(total=eval_interval, 
                                     ncols=100
                                    )
            
            epoch_progress_bar.colour='cyan'
            counter= 0
            cont_params={'train_loss':[], 
                         'l_r':[]
                        }
            
            ckpt_params={'train_loss':[], 
                         'val_loss':[],
                         'l_r':[]
                        }
            
            it_cnt=0
            for iter in range(0, max_iters):
                epoch_progress_bar.update(1)
                curr_temperature= nvml.nvmlDeviceGetTemperature(self.handle, 
                                                                nvml.NVML_TEMPERATURE_GPU
                                                               )
        
                if curr_temperature >= self.temp_thres:
                    print(f""\n Set temperature threshold of {self.temp_thres}Â°C reached halting for {4} seconds "")
                    time.sleep(3)
                    print(""\n Resuming Training "")
                
    
                if iter % eval_interval == 0 or iter == max_iters-1:
                    
                    checkpoint_save_path= f'results/{train_id}/checkpoints/checkpoint-{counter}-epoch{iter}.pth'
                    losses =self.estimate_loss(eval_iters)
                    ckpt_params['l_r'].append(schduler.get_last_lr()[0])
                    ckpt_params['train_loss'].append(losses['train'])
                    ckpt_params['val_loss'].append(losses['val'])
                    wandb.log({""eval epoch"":iter, ""validation loss"":losses['val']})
                    plot_save_path= f'results/{train_id}/checkpoints/plots/checkpoint-{counter}'
        
                    if iter ==0:
                        pass
                    else:
                        
                        self.plot.draw_line(mode='loss', 
                                            train_loss= cont_params['train_loss'],  
                                            epochs=[it for it in range(it_cnt, it_cnt+eval_interval)],
                                            save_path=f'{plot_save_path}-epoch_vs_loss.png'
                                            )
                        self.plot.draw_line(mode='lrvloss',
                                            l_r= cont_params['l_r'],
                                            train_loss=cont_params['train_loss'], 
                                            save_path=f'{plot_save_path}-learning_rate_vs_loss.png'
                                            )
                        
                        self.plot.draw_line(mode='lrve',
                                            l_r= cont_params['l_r'], 
                                            epochs=[it for it in range(it_cnt, it_cnt+eval_interval)],
                                            save_path=f'{plot_save_path}-learning_rate_vs_epoch.png'
                                            )
                        
                        cont_params['l_r'].clear()
                        cont_params['train_loss'].clear()
                        torch.save(self.m.state_dict(), checkpoint_save_path)
                        it_cnt+=iter
        
                    print(f""step {iter+1}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}"") 
                    epoch_progress_bar.close() 
                    epoch_progress_bar = tqdm(total=eval_interval, ncols=100)
                    epoch_progress_bar.colour='cyan'
                    counter+=1
                print(f'loading data for epoch{iter}')
    
    
                for xb, yb in self.get_batch(split='train'):
                    logits, loss = self.m(xb, yb)
                    optimizer.zero_grad(set_to_none=True)
                    loss.backward()
                    optimizer.step()
                    schduler.step()
                    curr_lr= schduler.get_last_lr()[0]
                    train_loss= loss.item()
                cont_params['l_r'].append(curr_lr)
                cont_params['train_loss'].append(train_loss)
                wandb.log({'epoch':iter, 'train loss':train_loss, 'learning rate':learning_rate})            
                epoch_progress_bar.set_description(f""Epoch: {iter}/{max_iters} |current LR- {curr_lr}"")
            
            os.mkdir(f'results/{train_id}/final_plots') if 'final_plots' not in os.listdir(f'results/{train_id}') else None
    
            self.plot.draw_line(mode='loss', 
                                        train_loss= ckpt_params['train_loss'], 
                                        val_loss=ckpt_params['val_loss'], 
                                        epochs=[it for it in range(0,max_iters, 500)],
                                        save_path=f'results/{train_id}/final_plots/plot-epoch_vs_loss.png',
                                        plot_type='ckpt'
                                        )
            self.plot.draw_line(mode='lrvloss',
                                l_r= ckpt_params['l_r'],
                                train_loss=ckpt_params['train_loss'], 
                                val_loss= ckpt_params['val_loss'],
                                save_path=f'results/{train_id}/final_plots/plot-learning_rate_vs_loss.png',
                                plot_type='ckpt'
                                )
            
            self.plot.draw_line(mode='lrve',
                                l_r= ckpt_params['l_r'], 
                                epochs=[it for it in range(0,max_iters, 500)],
                                save_path=f'results/{train_id}/final_plots/plot-learning_rate_vs_loss.png',
                                plot_type='ckpt'
                                )
    
            nvml.nvmlShutdown()
            wandb.finish()
    "
33,learnmachinelearning,gpt-3,top,2022-02-03 18:39:05,[Project] Refining the Natural language processing course - Feedback v2 and thank you,sb2nov,False,0.91,37,sjqogi,https://www.reddit.com/r/learnmachinelearning/comments/sjqogi/project_refining_the_natural_language_processing/,2,1643913545.0,"Iâ€™m Sourabh, I lead one of the core Tensorflow teams at Google Brain and worked on data products at Coursera with Andrew Ng. Kaushik Rangadurai, ML Engineer at Facebook and I are leading a live, cohort based course on NLP starting March 14th. [https://corise.com/course/natural-language-processing](https://corise.com/course/natural-language-processing).

This is the second run of the class and we learned a lot from the feedback of the reddit community from the first run in November. Some of the changes we're making from the previous iteration:

1/ More focus on transformers and less on RNN/LSTM as hugging face is becoming the defacto for any nlp.

2/ Pytorch lightning has some really easy to use interfaces so better organizing the boiler plate code.

3/ OpenAI has opened the GPT-3 API so a deeper dive into current possibilities.

Would love to continue getting feedback and build this to be a great resource. The plan is to open the content after we refine it to a degree we're happy with. You can join the course (capped at about 30 students) at the link above. If youâ€™re open to giving feedback on the class on how we can do better, happy to give a discount."
34,learnmachinelearning,gpt-3,top,2023-05-29 17:37:32,"GPT Weekly - 29th May Edition: Facebook's massive STT and TTS Release, AI in Windows, Paralegal jobs are here to stay and more.",level6-killjoy,False,0.84,27,13v1asb,https://www.reddit.com/r/learnmachinelearning/comments/13v1asb/gpt_weekly_29th_may_edition_facebooks_massive_stt/,2,1685381852.0," 

This is a recap covering the major news from last week.

* ðŸ”¥Top 3 AI news in the past week
* ðŸ—žï¸10 AI news highlights and interesting reads
* ðŸ§‘â€ðŸŽ“3 Learning Resources

# ðŸ”¥Top 3 AI news in the past week

## 1. Expanding Language Horizons

Facebook has [released an open source model called MMS (Massively Multilingual Search)](https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/) for STT (speech to text), TTS (text to speech) and language identification. 

This is a big breakthrough. Currently, STT and TTS models recognize only 100 languages. With this the technology has been expanded to 1100 languages. That is 10x the current best. 

Additionally, these models can recognize 4000+ languages. 

As per Facebook, they also have half the error rate of OpenAIâ€™s Whisper.

These guys are on a roll.

## 2. Bing Chat Enters the OS

After [Googleâ€™s announcement](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin), it was time for Microsoft to announce AI products. Hereâ€™s a rundown of what was announced during Microsoft Build:

1. **Windows Copilot**  \- Microsoft is integrating AI directly into the OS. Now you can do everything you could do with Bing Chat but now on the OS. You can do the usual stuff - summarize emails, documents, re-write etc. But it goes beyond that by integrating into the installed applications.

Microsoft is also adopting OpenAI's plugin model. So, **you can use ChatGPT and Bing plugins to interact with the integrated AI.** 

The great thing about it is the direct integration into the OS. Eat your heart out, Mac users â€“ at least for now ðŸ˜€. Until Apple announces something similar. And someone will come up with an alternative solution. Especially, because of the privacy concerns with Microsoft telemetry. 

The bad thing is - [the security aspect of the plugins](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). It can open a whole new attack vector on the OS and antivirus softwares might struggle with it. 

It also might be the second nail in the coffin for all the summarize, â€œtalk to your documentâ€ apps. Once, this feature is integrated with [Google Docs](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and Microsoft Office - why will you want to pay for extra apps?

1. **Search comes to ChatGPT**  \- Looks like OpenAI had enough of the testing and new features are being rolled out [left](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and [right](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). 

No prizes for guessing the search engine behind it. Ding, Ding, Ding..Itâ€™s Bing!

1. **Co-Pilot in PowerPages** \- Microsoft is now adding AI to their [PowerPages platform](https://powerpages.microsoft.com/en-in/), their low-code tool to build websites. Itâ€™ll help users to generate text, forms etc.
2. **Microsoft Fabric** \- A new data analytics platform built on top of Azure Data lake but can get data from S3, Google cloud etc. It can help users build pipelines, write code, and build ML models.

## 3. From Trusted Advisor to Nightmare: The Hazards of Depending on AI

Hereâ€™s a [fun story which is breaking out on Legal twitter](https://www.nytimes.com/2023/05/27/nyregion/avianca-airline-lawsuit-chatgpt.html). 

A man filed a personal injury lawsuit against Avianca airlines. Avianca's lawyers wasted no time and requested the judge to dismiss the case. The man's lawyer had a different plan in mind. He submitted a document citing half a dozen cases that bolstered his client's claims.

Here's the twistâ€”the judge and Avianca's lawyer couldn't locate any of the referenced cases. Quite a conundrum, right? The lawyer was then asked to provide copies of these elusive cases. The lawyer submitted screenshots as evidence, taking extra precautions to ensure their authenticity. 

You already know the direction this story is taking. 

The lawyer had used ChatGPT to compose his brief. But little did he know that ChatGPT had supplied him with fake cases.

When asked to file tangible copies of these cases, the lawyer turned to ChatGPT once again. ChatGPT had reassured him that the cases were genuine. Feeling emboldened, the lawyer used ChatGPT to provide the requested copies. He even went as far as incorporating chat screenshots into a legal document.

The lawyer maintains that it was never his intention to deceive the court. He expressed regret for relying on ChatGPT for their research. Unfortunately, the judge isn't pleased with this turn of events. The judge has threatened sanctions against both the lawyer and his firm.

It serves as a stark reminder of how ChatGPT has fooled many people. There is a clear warning stating that ChatGPT may produce inaccurate information. But many tend to overlook these warnings. Even legal professionals!!

This story carries significant importance for those who fear job insecurity. The lawyer and his firm could have prevented the entire debacle. They should've used paralegal services. They instead relied on ChatGPT's. It's a hard lesson learned the hard way.

My sincere hope is that this story serves as a valuable lesson. It helps people avoid making similar mistakes. The legal community might become apprehensive about ChatGPT's use moving forward.

# ðŸ—žï¸10 AI news highlights and interesting reads

1. [OpenAI says in 10 years AI could be as productive as one of todayâ€™s large corporations](https://openai.com/blog/governance-of-superintelligence). This poses an existential risk and they suggest some regulations to manage it. This poses an existential risk and they suggest some regulations to manage it. To achieve this, countries need to form something like the [IAEA](https://en.wikipedia.org/wiki/International_Atomic_Energy_Agency). The IAEA is an intergovernmental agency under the UN to oversee nuclear energy. This â€œAI agencyâ€ will monitor the AI systems and conduct inspections. Just like nuclear energy is tracked through signatures, they suggest using compute and energy usage to track systems.
2. In the meantime, [Google is working on voluntary rules](https://techcrunch.com/2023/05/24/eu-google-ai-pact/) until there are some real regulations in place. 
3. [As per Pew Research, 58% of Americans have heard of ChatGPT. Even less - 14% have tried ChatGPT. ](https://www.pewresearch.org/short-reads/2023/05/24/a-majority-of-americans-have-heard-of-chatgpt-but-few-have-tried-it-themselves/)
4. Sharing prompts and results has been a pain. Taking screenshots is one way. But then everyone has to type in the prompts manually. Or you can share as plain text. But ChatGPT results are non-deterministic. So, the results might not be the same. Even the lawyer above wouldâ€™ve loved this feature. Now you will be able to [share your ChatGPT conversations publicly](https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq).
5. LLM Agents and plugins need to connect to tools to perform the tasks outside the LLM environment. So, it is important for the LLM to know which API to call and pass correct arguments. [Gorilla is a fine-tuned Llama-model which can generate the correct call and arguments](https://gorilla.cs.berkeley.edu/). 
6. If you are trying to build something beyond a document summarizer or a wrapper around GPT4 API, [things can be hard](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm). Finding the correct context window, dealing with slow responses (I am looking at you GPT-4) etc are some of the problems. 
7. [The AI boom could expose investorsâ€™ natural stupidity](https://www.reuters.com/breakingviews/ai-boom-could-expose-investors-natural-stupidity-2023-05-19/). 
8. [Chatbot leaderboard for the week](https://lmsys.org/blog/2023-05-25-leaderboard/). GPT-4 is still ahead.
9. [Googleâ€™s flood warning system is now available in 80 countries. ](https://blog.google/outreach-initiatives/sustainability/flood-hub-ai-flood-forecasting-more-countries/)
10. [GPT detectors are biased against non-native English writers](https://arxiv.org/abs/2304.02819)

# ðŸ§‘â€ðŸŽ“3 Learning Resources

1. [Build a product using Replit+AI](https://www.priyaa.me/blog/building-with-ai-replit). The author is a non-technical person who won a hackathon competing with engineers. 
2. [LangChain 101](https://replit.com/@MckayWrigley). 
3. [NLP Course from HuggingFace](https://huggingface.co/learn/nlp-course/chapter0/1)

Thatâ€™s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
35,learnmachinelearning,gpt-3,top,2023-04-08 03:04:00,Energy Constraints and Costs in Massive Machine Learning Model Training,mechkeyboard7065,False,0.94,27,12f9cvx,https://www.reddit.com/r/learnmachinelearning/comments/12f9cvx/energy_constraints_and_costs_in_massive_machine/,7,1680923040.0,"Adding on to my [last](https://www.reddit.com/r/learnmachinelearning/comments/12ebceo/alternatives_to_training_massive_ml_models_on/) post, here's some of what I've found about the potential constraints and costs associated with training massive machine learning models. 

&#x200B;

**Energy as a constraint in ML model training:**

\- GPT-3, as an example, is estimated to have consumed around **936 MWh** during its training.  
\- If there were **$100B model training runs** in the future, it would consume approximately **20,347,826 MWh** or **20,347,826,000 KWh**.  
\- This would cost around **$1,017,391,300**, which is about **1%** of the total cost (assuming $0.05 KWh). The cost could go up to **$3B** if we assume $0.15 KWh.

&#x200B;

**Power generation comparison:**

\- One nuclear power plant can generate around **4,727,764 MWh** in a year.

&#x200B;

**Main constraints in massive model training runs apart from GPUs:**

\- Data movement through machines  
\- The amount of data that can be moved  
\- The amount of data the model has already been trained on  
\- Networking and bandwidth limitations  
\- System-specific bottlenecks  
\- Model training algorithm design (e.g., parallel processing, processing power requirements)

&#x200B;

**Potential $10T investment in ML models: Where would the money go?**

\- **17% ($1.7T)** \- Data collection, validation, and annotation  
\- **23% ($2.3T)** \- Research  
\- **60% ($6T)** \- Production (infrastructure, integration, maintenance)

&#x200B;

**Current and projected annual spend on GPUs:**  
\- **$40B** in 2022  
\- Projected to be **$400B** in 10 years

&#x200B;

I hope someone might find this information useful. It's definitely made me question the future impact as these models scale. As always, I'm open to corrections and eager to learn more. Let me know if you have any questions or additional insights."
36,learnmachinelearning,gpt-3,top,2020-11-29 20:52:26,What is the hype about the GPT-3 transformer and what is real? (GPT3 paper deep dive),gordicaleksa,False,0.88,26,k3h26h,https://youtu.be/fVt387VZJe8,0,1606683146.0,
37,learnmachinelearning,gpt-3,top,2023-10-13 14:23:10,Authoring another course about LLMs. Learn by Doing LLM Projects.,pmartra,False,0.88,26,176zx1m,https://www.reddit.com/r/learnmachinelearning/comments/176zx1m/authoring_another_course_about_llms_learn_by/,5,1697206990.0,"Hi, I'm working on a course about LLMs on GitHub, it's totally free and under MIT license,  So there are no restrictions.

Here the link: [https://github.com/peremartra/Large-Language-Model-Notebooks-Course](https://github.com/peremartra/Large-Language-Model-Notebooks-Course)

I'm still working on It, but now I'm feeling comfortable with the variety and quality of the content. By the moment is a small repository with just 80 Stars.

My intention is to make the course more accessible to a wider audience, and, if possible, encourage  reporting any issues  encounter or suggesting improvements through the 'Discussion' section.

I'm eager to receive feedback.

Now, I'll provide an overview of the currently available content, and then I'll share a couple of questions I have about how to proceed with the course.

[Large Language Models Course: Learn by Doing LLM Projects.](https://github.com/peremartra/Large-Language-Model-Notebooks-Course)

* Introduction to LLM with OpenAI.
   * Create a first Chatbot using FPT 3.5.
   * Create a Natural Language to SQL Translator using OpenAI.
* Vector Databases with LLM.
   * Influencing Language Models with Information stored in ChromaDB.
* LangChain & LLM Apps.
   * RAG. Use the Data from Dataframes with LLMs.
   * Create a Moderation System using LangChain.
      * OpenAI.
      * GPT\_j.
      * LLama-2.
   * Create a Data Analyst Assistant using a LLM Agent.
* Evaluating LLMs
   * Evaluating Summarization with ROUGE.
* Fine-Tuning & Optimization.
   * Prompt-tuning using PEFT.
   * Fine-Tuning with LoRA.
   * Fine-Tuning a Large Model in a GPU using QLoRA. 

That's all for the moment, but I'm adding new content regularly. I'm working on it only in my spare time (mainly nights when the family goes to sleep).

\_\_\_

I have a doubt, I don't know if add some information about platforms like W&B or Cohere?  or maybe it is a better idea to stay with more Open-Source libraries?

On the other hand, my intention is to develop a couple of projects utilizing the techniques covered in the initial part of the course (which I am currently working on).

Some of these projects will be hosted in the cloud on major platforms such as Azure or GCP, or AWS. Any preference?

Furthermore, there is a plan to create a third section that explains how Large Language Models (LLMs) fit into large-scale enterprise solutions, defining architectures in which LLMs are used but are not the sole components of the project.

I don't intend to create a community outside of GitHub, but I would like the repository to have more activity and not be the one determining the course's direction.

Hope you like it, and lease, feel free to contribute.

&#x200B;"
38,learnmachinelearning,gpt-3,top,2023-12-17 13:15:47,I can't stop using ChatGPT and I hate it.,t0hli,False,0.64,24,18kh4n5,https://www.reddit.com/r/learnmachinelearning/comments/18kh4n5/i_cant_stop_using_chatgpt_and_i_hate_it/,108,1702818947.0,"I'm trying to learn various topics like Machine Learning and Robotics etc., and I'm kinda a beginner in programming.

For any topic and any language, my first instinct is to

1. go to ChatGPT,
2. write down whatever I need my code to do,
3. copy paste the code
4. if it doesn't give out good results, ask ChatGPT to fix whatever it's done wrong
5. repeat until I get satisfactory result

I hate it, but I don't know what else to do.

I think of asking Google what to do, but then I won't get the exact answer I'm looking for, so I go back to ChatGPT so I can get exactly what I want. I don't fully understand what the GPT code does, I get the general gist of it and say ""Yeah that's what I would do, makes sense"", but that's it.

If I tried to code whatever GPT printed out, I wouldn't get anywhere.

I know I need to be coding more, but I have no idea where to start from, and why I need to code when ChatGPT can do it for me anyway. I'm not defending this idea, I'm just trying to figure out how I can code myself.

I'd appreciate your thoughts and feedback."
39,learnmachinelearning,gpt-3,top,2024-01-05 15:14:07,"This Week's Major AI developments in a nutshell (December Week 4, 2023 + January week 1, 2024)",wyem,False,0.96,23,18z95ko,https://www.reddit.com/r/learnmachinelearning/comments/18z95ko/this_weeks_major_ai_developments_in_a_nutshell/,1,1704467647.0,"1. **Meta** and UC, Berkeley introduced ***Audio2Photoreal***, a framework for generating full-bodied photorealistic avatars with gestures driven from audio of a dyadic conversation \[[*Details*](https://people.eecs.berkeley.edu/~evonne_ng/projects/audio2photoreal/) | [*GitHub*](https://github.com/facebookresearch/audio2photoreal)*\].*
2. **MyShell** along with researchers from MIT and Tsinghua University introduced ***OpenVoice***, an open sourcce voice cloning approach that is nearly instantaneous and provides granular control of tone, from emotion to accent, rhythm, pauses, and intonation, using just a small audio clip \[[*Details*](https://research.myshell.ai/open-voice) *|* [*Hugging Face*](https://huggingface.co/spaces/myshell-ai/OpenVoice)\] .
3. **Suno** and Nvidia present ***Parakeet***, a family of open source speech recognition models that top the Open ASR Leaderboard. Parkeet models effectively prevent the generation of hallucinated transcript and are robust to noisy audio. Available for commercial use under CC BY 4.0 \[[*Details*](https://nvidia.github.io/NeMo/blogs/2024/2024-01-parakeet/) | [*Hugging Face*](https://huggingface.co/spaces/nvidia/parakeet-rnnt-1.1b)\].
4. **Researchers** from Stanford University introduce ***Mobile-ALOHA***, an open-source robot hardware that can can autonomously complete complex mobile manipulation tasks that require whole-body control like cook and serve shrimp, call and take elevator, store a 3Ibs pot to a two-door cabinet etc., with just 50 demos \[[*Details*](https://mobile-aloha.github.io/)\].
5. **Allen Institute for AI** released ***Unified-IO 2*** (open-source), the first autoregressive multimodal model that is capable of understanding and generating image, text, audio, and action. The model is pre-trained from scratch on an extensive variety of multimodal data -- 1 billion image-text pairs, 1 trillion text tokens, 180 million video clips, 130 million interleaved image & text, 3 million 3D assets, and 1 million agent trajectories \[[*Details*](https://unified-io-2.allenai.org/)\].
6. **Alibaba** Research introduced ***DreamTalk***, a diffusion-based audio-driven expressive talking head generation framework that can produce high-quality talking head videos across diverse speaking styles \[[*Details*](https://dreamtalk-project.github.io/) *|* [*GitHub*](https://github.com/ali-vilab/dreamtalk)\].
7. **OpenAIâ€™s app store** for GPTs will launch next week \[[*Details*](https://techcrunch.com/2024/01/04/openais-app-store-for-gpts-will-launch-next-week/)\].
8. **GitHub Copilot Chat**, powered by GPT-4, is now generally available for both Visual Studio Code and Visual Studio, and is included in all GitHub Copilot plans alongside the original GitHub Copilot \[[*Details*](https://github.blog/2023-12-29-github-copilot-chat-now-generally-available-for-organizations-and-individuals)\].
9. **Microsoft Research** presented a new and simple method for obtaining high-quality text embeddings using only synthetic data and less than 1k training step \[[*Paper*](https://arxiv.org/pdf/2401.00368.pdf)\] | [*Hugging Face*](https://huggingface.co/intfloat/e5-mistral-7b-instruct)\].
10. **Google DeepMind** introduced ***AutoRT, SARA-RT and RT-Trajectory*** to improve real-world robot data collection, speed, and generalization \[[*Details*](https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotic)\].
11. **Salesforce Research** presented ***MoonShot***, a new video generation model that conditions simultaneously on multimodal inputs of image and text, demonstrating significant improvement on visual quality and temporal consistency compared to existing models. The model can be easily repurposed for a variety of generative applications, such as personalized video generation, image animation and video editing. Models will be made public [here](https://github.com/salesforce/LAVIS) \[[*Details*](https://showlab.github.io/Moonshot/)\].
12. **Leonardo AI** released ***Leonardo Motion*** for generating videos from images. Available to all users, paid and free \[[*Link*](https://leonardo.ai/)\].
13. **JPMorgan AI Research** present ***DocLLM***, a layout-aware generative language model for multimodal document understanding. The spatial layout information is incorporated through bounding box coordinates of the text tokens obtained typically using optical character recognition (OCR), and does not rely on any vision encoder component \[[Details](https://arxiv.org/pdf/2401.00908.pdf)\].
14. **Alibaba Research** introduced ***Make-A-Character (Mach)***, a framework to create lifelike 3D avatars from text descriptions. Make-A-Character supports both English and Chinese prompts. \[[*Details*](https://human3daigc.github.io/MACH/) *|* [*Hugging Face*](https://huggingface.co/spaces/Human3DAIGC/Make-A-Character)\].
15. **Sony**, Canon and Nikon set to combat deepfakes with digital signature tech in future cameras \[[*Details*](https://www.techradar.com/cameras/photography/sony-canon-and-nikon-set-to-combat-deepfakes-with-digital-signature-tech-in-future-cameras)\].
16. **Meta AI** introduced ***Fairy***, a versatile and efficient video-to-video synthesis framework that generates high-quality videos with remarkable speed. Fairy generates 120-frame 512x384 videos (4-second duration at 30 FPS) in just 14 seconds, outpacing prior works by at least 44Ã— \[[Details](https://fairy-video2video.github.io/)\].
17. **Apple** quietly released an open source multimodal LLM, called ***Ferret***, in October 2023 \[[*Details*](https://venturebeat.com/ai/apple-quietly-released-an-open-source-multimodal-llm-in-october/)\].
18. **Australian researchers** introduced a non-invasive AI system, called ***DeWave***, that can turn silent thoughts into text while only requiring users to wear a snug-fitting cap \[[*Details*](https://www.sciencealert.com/new-mind-reading-ai-translates-thoughts-directly-from-brainwaves-without-implants)\].
19. **Pika Labs** text-to-video AI platform **Pika 1.0** is now available to all and accessible via the web \[[*Link*](https://pika.art/)\].
20. **The New York Times** sued OpenAI and Microsoft for copyright infringement \[[*Details*](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html)\].

**Source**: [AI Brews newsletter-](https://aibrews.com/) you can subscribe [here](https://aibrews.substack.com/). it's free to join, sent only once a week with ***bite-sized news, learning resources and selected tools.*** *Thank you!*"
40,learnmachinelearning,gpt-3,top,2023-06-19 17:49:06,"GPT Weekly - 19the June Edition - OpenAI's function calling, Meta's free LLM, EU Regulation and more.",level6-killjoy,False,0.93,20,14dlfas,https://www.reddit.com/r/learnmachinelearning/comments/14dlfas/gpt_weekly_19the_june_edition_openais_function/,2,1687196946.0," 

This is a recap covering the major news from last week.

* ðŸ”¥Top 3 news - OpenAIâ€™s updates, Metaâ€™s upcoming free LLM and EU Regulation
* ðŸ—žï¸Interesting reads include PSA about protecting your keys, The GPT ouroboros, Reddit - OpenAIâ€™s moat, and more..
* ðŸ§‘â€ðŸŽ“Learning includes a Step-by-step guide from a non-technical founder who launched his MVP, Chatbot for your Gdrive and more

# ðŸ”¥Top 3 AI news in the past week

## 1. OpenAI: New Pricing, Models, & Functions

OpenAI has been on a roll. Last week we saw the release of [OpenAI best practice on using GPT.](https://gptweekly.beehiiv.com/p/making-gpt-openais-tactics-better-results) This week we saw some amazing updates. Three major buckets were:

First, the price decreases for both embeddings and GPT-3.5 tokens. 

Second, new models for gpt-4 and gpt-3.5. A new longer context model for gpt-3.5.

Third, a new function calling capability. 

**Why is it important?** Previously, the output from OpenAI was all text. So, calling an external API from GPT was quite difficult. You had to parse the text data and things were often incorrect.  Langchain created the Agents and Tools feature to tackle this problem. It was still unreliable and prone to issues. 

Now you get native support to generate a fixed format output. You can use the output to generate functional calls and also pass functions which need to be called. For example, if your app has multiple API endpoints then you can use GPT to generate the API calls with parameters. You can also pass the endpoints as function calls to ensure the correct function is executed. 

This functionality can further be used to [generate structured data (JSON) out of GPT](https://yonom.substack.com/p/native-json-output-from-gpt-4). So, you can generate data from GPT and load it into your backend. 

**Whatâ€™s next?** This functionality allows turning natural language responses into structured data. This can be used to create â€œintelligentâ€ backends using LLMs. We might see implementations in no-code tools to allow more robust and natural-language tools for non-technical folks.

The structured data process goes both ways. You can also feed structured data into GPT for better responses. 

This feature also has its share of issues. Function calling suffers from the same prompt injection issues. Malicious actors can pass malicious code in function or the responses. For example, creation of queries using functions might contain malicious code to delete data. Without proper user validation this code will be executed automatically and delete data. So, using LLM as the back-end layer needs proper security implementation. 

## 2. Meta's LLM: Commercial Use Ahead

Llama has been a boon for the open source community. Many of the open source models rely on Llama. The issue is that Llama is research-only and cannot be used commercially. So, no one can use it to build any product.

[Meta is now working on the next version of the model. This model will be available for commercial use.](https://www.theinformation.com/articles/meta-wants-companies-to-make-money-off-its-open-source-ai-in-challenge-to-google) This is in stark contrast to both OpenAI and Google. Both safe-guarde their models and make it available through API. 

**Why is it important?** Certain industries cannot use LLM APIs because of strict restrictions on data privacy. These companies would want to run their own instance of a foundational model. 

A commercially available foundational model is also going to help people who want to keep their â€œAPI callâ€ costs next to 0. 

A commercially available free-for-all model will also help push the open source community further. Just like Llama.

**Whatâ€™s next?** Sam Altman has said OpenAI didnâ€™t release GPT-3 as open-source because they [didnâ€™t think people would be able to run it.](https://gptweekly.beehiiv.com/p/peek-openais-future) Now [OpenAI is working on an open-source model.](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) This is going to be weaker than GPT-4. 

Let the battle of LLMs begin.  

## 3. EU's Proposed Legislation and Its Impact on AI Usage

[The EU parliament voted to move ahead with the E.U. AI Act.](https://www.washingtonpost.com/technology/2023/06/14/eu-parliament-approves-ai-act/) This act aims to ensure consumer protection against the dangers of AI.  

**Why is it important?** [OpenAI](https://gptweekly.beehiiv.com/p/peek-openais-future) and [Sam Altman](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) want regulations for models. They have proposed a IAEA-type of agency to stop the proliferation of LLM models. As per OpenAI, all models should be regulated and monitored. The suggestion of a license based regulation has led to significant backlash. Many people have called it â€œregulatory captureâ€ - with the aim of shutting down competing LLMs.

[Licensing based regulations might not really be effective.](https://aisnakeoil.substack.com/p/licensing-is-neither-feasible-nor)

The EU is approaching regulation from a different angle. It doesnâ€™t focus on how models are developed. Rather focuses on how AI will/can be used. They have broken down use cases into 4 categories - unacceptable (prohibited), high, medium and low risk. For example, 

Building a [Pre-Crime software](https://en.wikipedia.org/wiki/Pre-crime#:~:text=Pre%2Dcrime%20(or%20precrime),on%20crimes%20not%20yet%20committed.) to predict crimes? Building a [Social credit system](https://en.wikipedia.org/wiki/Social_Credit_System)?  Unacceptable.

Using tools to influence elections or recommendation algorithms? High (Highly regulated).

Using generative AI tools to create text or images on news sites? Medium (Add label that the content is AI generated) 

AI providers also need to disclose their training source.

To me this sounds like good legislation. What do you guys think?

But, OpenAI has warned that EU regulations might force them to pull out completely.

**Whatâ€™s next?** The disclosure requirements might help various publishing companies. [AI and media companies are in talks to pay for training data](https://www.ft.com/content/79eb89ce-cea2-4f27-9d87-e8e312c8601d). Google has been leading the charge. 

Additionally, [OpenAI and Deepmind will open their models for safety and research purposes to the UK government.](https://www.politico.eu/article/openai-deepmind-will-open-up-models-to-uk-government/) 

# ðŸ—žï¸10 AI news highlights and interesting reads

1. **PSA:** If you are using Repl to write code, you might want to check your OpenAI API keys. If you have left them embedded then [people can pirate and steal the keys. ](https://www.vice.com/en/article/93kkky/people-pirating-gpt4-scraping-openai-api-keys)
2. LLMs rely on human annotation or human feedback to learn. And one way to generate human annotation is crowdsourcing. But what if the crowdsource human annotators use LLMs? [Research shows 33-46% workers used LLMs](https://arxiv.org/abs/2306.07899). So, basically we go from Human -> AI -> Human -> AI. The AI ouroboros. Researchers also say [generated data to train models might cause serious issue.  ](https://arxiv.org/abs/2305.17493)
3. All the talks about [moats](https://gptweekly.beehiiv.com/p/googles-startling-leaked-memo-george-hinton-mojo) \- [Reddit might be OpenAIâ€™s \*future\* moat](https://www.cyberdemon.org/2023/06/14/reddit-moat.html). Given the amount of complaints about how [Google search](https://www.techradar.com/opinion/the-reddit-b) [experience has deteriorated](https://www.theverge.com/2023/6/13/23759942/google-reddit-subreddit-blackout-protests) [during the blackout](https://news.ycombinator.com/item?id=36345345), this might be true?
4. [Doctors are using ChatGPT](https://www.nytimes.com/2023/06/12/health/doctors-chatgpt-artificial-intelligence.html) but not to diagnose.Rather to be [more empathetic](https://inflecthealth.medium.com/im-an-er-doctor-here-s-how-i-m-already-using-chatgpt-to-help-treat-patients-a023615c65b6). [We discussed this just a month ago](https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?utm_source=gptweekly.beehiiv.com&utm_medium=referral&utm_campaign=google-s-startling-leaked-memo-george-hinton-mojo-and-more). And guess where the data for this study came from? Reddit AskDocs. Moat FTW?!
5. Beatles to make a comebackâ€¦[using Generative AI](https://www.semafor.com/article/06/13/2023/paul-mccartney-beatles-song-ai). 
6. [SnapFusion - Text to Image diffusion on mobile phones.](https://snap-research.github.io/SnapFusion/)
7. Large context lengths are important for better GPT experience. [The secret sauce for 100k context length](https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c). 
8. There is a lot of bad AI research out there. Some border on snake oil. Most AI â€œresearchâ€ should be double checked and challenged. A new research on huggingface said that [GPT-4 can ace MIT curriculum](https://huggingface.co/papers/2306.08997). Now someone is replicating the results and say that [GPT-4 canâ€™t beat MIT. ](https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864)
9. Are we seeing peak AI? Especially when people from Deepmind and Meta are involved? [Mistral AI raised $113 million in seed round with no product.](https://techcrunch.com/2023/06/13/frances-mistral-ai-blows-in-with-a-113m-seed-round-at-a-260m-valuation-to-take-on-openai/) Some might say this funding is for the team and the team is really solid. The issue though is whether the valuation is justified when OpenAI and Google already have a head start.
10. [The AI Hype Wall of Shame.](https://criticalai.org/the-ai-hype-wall-of-shame/) \- Collection of articles which mislead people about AI in various aspects.

# ðŸ§‘â€ðŸŽ“3 Learning Resources

1. [Building and Launching a company using GPT-4](https://sabol.io/c7921c7bbd8c4982aacbd2b71a8b9bb3) with prompts. (The author didnâ€™t know how to code but created and launched the MVP in a month).  
2. Chatbot for your Gdrive - [https://www.haihai.ai/gpt-gdrive/](https://www.haihai.ai/gpt-gdrive/)
3. Building ChatGPT plugin using Supabase - https://supabase.com/blog/building-chatgpt-plugins-template

Thatâ€™s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
41,learnmachinelearning,gpt-3,top,2023-09-01 14:58:08,This week in AI - all the Major AI development in a nutshell,wyem,False,0.96,18,1679g8z,https://www.reddit.com/r/learnmachinelearning/comments/1679g8z/this_week_in_ai_all_the_major_ai_development_in_a/,0,1693580288.0,"1. Researchers introduce â€˜**Swift**â€™, the first autonomous vision-based drone that beat human world champions in several fair head-to-head races. This marks the *first* time that an autonomous mobile robot has beaten human champions in a real physical sport \[[*Details*](https://www.nature.com/articles/s41586-023-06419-4)\].
2. **Meta AI** released **CoTracker** \- a fast transformer-based model that can track any point in a video.
3. **WizardLM** released **WizardCoder 34B** based on Code Llama. WizardCoder-34B surpasses GPT-4, ChatGPT-3.5 and Claude-2 on HumanEval Benchmarks.
4. **Meta AI** introduced **FACET** (FAirness in Computer Vision EvaluaTion) - a new comprehensive benchmark dataset for evaluating the fairness of computer vision models for protected groups. The dataset is made up of 32K images containing 50,000 people, labeled by expert human annotators.
5. **Allen Institute for AI** launched [**Satlas**](https://satlas.allen.ai/) \- a new platform for exploring global geospatial data generated by AI from satellite imagery.
6. Generative AI updates from **Google Cloud Next** event**:**
   1. General availability of **Duet AI in Google Workspace** .
   2. **SynthID** \- a tool for watermarking and identifying AI images generated by Imagen (Googleâ€™s text-to-image diffusion model). It embeds a digital watermark directly into the pixels of an image, making it invisible to the human eye, but detectable for identification, without reducing the image quality.
   3. **AlloyDB AI** for building generative AI applications with PostgreSQL.
   4. **Vertex AIâ€™s Model Garden** now includes Metaâ€™s Llama 2 and TIIâ€™s Falcon â€” and pre-announcement of Anthropicâ€™s Claude 2..
   5. Model and tuning upgrades for **PaLM 2, Codey, and Imagen**. 32,000-token context windows and 38 languages for PaLM 2.
   6. **Style Tuning** for Imagen - a new capability to help customers align their images to their brand guidelines with 10 images or less.
   7. Launch of fifth generation of its tensor processing units (**TPUs**) for AI training and inferencing.
7. A new generative AI image startup **Ideogram**, founded by former Google Brain researchers, has been launched with $16.5 million in seed funding. Ideogram's unique proposition lies in reliable text generation within images.
8. **a16z** announced **a16z Open Source AI Grant program** and the first batch of grant recipients and funded projects.
9. **Runway AI** announced **Creative Partners Program** \- provides a select group of artists and creators with exclusive access to new Runway tools and models, Unlimited plans, 1 million credits, early access to new features and more.
10. **OpenAI** has released a guide for teachers using ChatGPT in their classroomâ€”including suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.
11. **DINOv2**, a self-supervised vision transformer model by **Meta AI** which was released in April this year, is now available under the Apache 2.0 license.
12. **Tesla** is launching a $300 million AI computing cluster employing 10,000 Nvidia H100 GPUs.
13. **Inception**, an AI-focused company based in the UAE unveiled **Jais**, a 13 billion parameters open-source Arabic Large Language Model (LLM).
14. Google announced **WeatherBench 2** (WB2) - a framework for evaluating and comparing various weather forecasting models.
15. **Alibaba** launched two new open-source models - **Qwen-VL** and **Qwen-VL-Chat** that can respond to open-ended queries related to different images and generate picture captions.
16. **OpenAI** disputes authorsâ€™ claims that every ChatGPT response is a derivative work.
17. **DoorDash** launched AI-powered voice ordering technology for restaurants.
18. **OpenAI** launched **ChatGPT Enterprise**. It offers enterprise-grade security and privacy, unlimited higher-speed GPT-4 access, longer context windows for processing longer inputs, advanced data analysis capabilities and customization options.
19. **OpenAI** is reportedly earning $80 million a month and its sales could be edging high enough to plug its $540 million loss from last year.

If you like this news format, you might find my newsletter, [AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
42,learnmachinelearning,gpt-3,top,2023-07-20 13:15:51,Free courses and guides for learning Generative AI,wyem,False,0.95,17,154qnsh,https://www.reddit.com/r/learnmachinelearning/comments/154qnsh/free_courses_and_guides_for_learning_generative_ai/,0,1689858951.0,"1. **Generative AI learning path by Google Cloud.** A series of 10 courses on generative AI products and technologies, from the fundamentals of Large Language Models to how to create and deploy generative AI solutions on Google Cloud \[[*Link*](https://www.cloudskillsboost.google/paths/118)\].
2. **Generative AI short courses** by DeepLearning.AI - Five short courses on generative AI including **LangChain for LLM Application Development, How Diffusion Models Work** and more. \[[*Link*](https://www.deeplearning.ai/short-courses/)\].
3. **LLM Bootcamp:** A series of free lectures by *The full Stack* on building and deploying LLM apps \[[*Link*](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/)\].
4. **Building AI Products with OpenAI** \- a free course by CoRise in collaboration with OpenAI \[[*Link*](https://corise.com/course/building-ai-products-with-openai)\].
5. Free Course by Activeloop on **LangChain & Vector Databases in Productio**n \[[*Link*](https://learn.activeloop.ai/courses/langchain)\].
6. **Pinecone learning center -** Lots of free guides as well as complete handbooks on LangChain, vector embeddings etc. by Pinecone **\[**[**Link**](https://www.pinecone.io/learn/)**\].**
7. **Build AI Apps with ChatGPT, Dall-E and GPT-4  -** a free course on Scrimba **\[**[*Link*](https://scrimba.com/learn/buildaiapps)**\].**
8. **Gartner Experts Answer the Top Generative AI Questions for Your Enterprise** \- a report by Gartner \[[*Link*](https://www.gartner.com/en/topics/generative-ai)\]
9. **GPT best practices:** A guide by *OpenAI* that shares strategies and tactics for getting better results from GPTs \[[*Link*](https://platform.openai.com/docs/guides/gpt-best-practices)\].
10. **OpenAI cookbook by OpenAI -** Examples and guides for using the OpenAI API **\[**[*Link*](https://github.com/openai/openai-cookbook/tree/main)**\].**
11. **Prompt injection explained**, with video, slides, and a transcript from a webinar organized by LangChain \[[*Link*](https://simonwillison.net/2023/May/2/prompt-injection-explained/)\].
12. A detailed guide to **Prompt Engineering by DAIR.AI** *\[*[*Link*](https://www.promptingguide.ai/)*\].*
13. What Are **Transformer Models** and How Do They Work - A tutorial by **Cohere AI** \[[*Link*](https://txt.cohere.ai/what-are-transformer-models/)\].  


I add learning resources as part of my AI newsletter. You can join for free [here](https://aibrews.com/). Itâ€™s sent only once a week with bite-sized news, learning resources and selected tools. "
43,learnmachinelearning,gpt-3,top,2023-11-03 05:00:17,How do y'all deal with hallucinating in GPT 3.5?,supa_ai,False,0.74,17,17mngkq,https://www.reddit.com/r/learnmachinelearning/comments/17mngkq/how_do_yall_deal_with_hallucinating_in_gpt_35/,16,1698987617.0,"Hey guys,

We're trying to build an AI chatbot for internal purposes. So far, we've tried the usual suspects like different approaches to prompt engineering and RAG.

The main issue is that despite RAG retrieving the correct context, we still experience significant (3 in 10) amounts of hallucination. Has anyone experienced the same problem? We'd love to hear any alternative approaches or discussion here on alternate methods."
44,learnmachinelearning,gpt-3,top,2022-12-03 09:11:15,A GPT-3 based Chrome Extension that debugs your code!,VideoTo,False,0.82,17,zbc6rf,https://www.reddit.com/r/learnmachinelearning/comments/zbc6rf/a_gpt3_based_chrome_extension_that_debugs_your/,0,1670058675.0,"Link - [https://chrome.google.com/webstore/detail/clerkie-ai/oenpmifpfnikheaolfpabffojfjakfnn](https://chrome.google.com/webstore/detail/clerkie-ai/oenpmifpfnikheaolfpabffojfjakfnn)  

Built a quick tool I thought would be interesting - itâ€™s a chrome extension that uses GPT-3 under the hood to help debug your programming errors when you paste them into Google (â€œeg. TypeError:â€¦â€). 

This is definitely early days, so if this is something you would find valuable and wouldn't mind testing a couple iterations of, please feel free to join the discord -> [https://discord.gg/KvG3azf39U](https://discord.gg/KvG3azf39U)

https://i.redd.it/p9qd3yhbgn3a1.gif"
45,learnmachinelearning,gpt-3,top,2023-06-16 14:23:32,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.95,17,14ay75a,https://www.reddit.com/r/learnmachinelearning/comments/14ay75a/this_week_in_ai_all_the_major_ai_developments_in/,1,1686925412.0,"1. **ElevenLabs** has launched **AI Speech Classifier -** an authentication tool that lets you upload any audio sample to identify if it contains ElevenLabs AI-generated audio.
2. **Nvidia Research** presents **SceneScape** \- a method to generate long-term walkthroughs in imaginary scenes just from an input text prompt.
3. **Meta AI** introduces the **Image Joint Embedding Predictive Architecture (I-JEPA)**, a new AI model which learns from the world like humans and excels in computer vision tasks, while being more computationally efficient. It learns by creating an internal model of the outside world, which compares abstract representations of images (rather than comparing the pixels themselves). It can also be used for many different applications without needing extensive fine tuning. Meta is open-sourcing the code and model checkpoints.
4. **Meta** wants to make the next version of LLaMA, its open source LLM, available for commercial use..
5. Adobe launched **Generative Recolor,** a new tool powered by Adobe Firefly generative AI that lets you generate custom color schemes using texts prompt like â€œstrawberry fields,â€ â€œfaded emerald,â€ etc. .
6. **OpenAI** announced:
   1. new **function calling** capability in the Chat Completions API
   2. updated and more steerable versions of gpt-4 and gpt-3.5-turbo
   3. new 16k context version of gpt-3.5-turbo (vs the standard 4k version). 16k context means the model can now support \~20 pages of text in a single request.
   4. cost reductions: 75% on embeddings model and 25% cost on input tokens for gpt-3.5-turbo.
7. **Meta AI** released **MusicGen** \- an open-source music generation model that can be prompted by both text and melody. See here for generated samples and comparison with Googleâ€™s MusicLM and others..
8. **McKinsey** published a report â€˜*The economic potential of generative AI: The next productivity frontier*â€™ . The report estimates that generative AI could add the equivalent of $2.6 trillion to $4.4 trillion annually across the 63 use cases. About 75 percent of the value that generative AI use cases could deliver falls across four areas: Customer operations, marketing and sales, software engineering, and R&D..
9. **EU lawmakers** pass AI regulation, requiring generative AI systems, such as ChatGPT, to be reviewed before commercial release. It also seeks to ban real-time facial recognition.*.*
10. **Google Lens** can now identify skin conditions. Lens will also be integrated with Bard, Googleâ€™s AI-powered chatbot, enabling Bard to understand images in user prompts..
11. **AMD** announced its most-advanced GPU for artificial intelligence, the MI300X, which will start shipping to some customers later this year*.*
12. **Vercel** introduced **Vercel AI SDK -** an open-source library to build conversational, streaming and chat user interfaces. Includes first-class support for OpenAI, LangChain, and Hugging Face Inference.
13. **Vercel** announced '**Vercel AI Accelerator,** a 6-week long accelerator program with $850k in free credits from OpenAI, Replicate and others.
14. **Salesforce** announces **AI Cloud** \- generative AI for the enterprise. AI Cloud includes the new **Einstein Trust Layer**, to help prevent large-language models (LLMs) from retaining sensitive customer data.
15. **Cohere** and **Oracle** are working together to make it easy for enterprise customers to train their own specialized large language models while protecting the privacy of their training data.
16. **Coda** released Coda AI - the AI-powered work assistant integrated in Coda to automate workflows. Coda also announced â€˜**Coda's AI at Work Challenge**â€™, offering $40,000 in total prizes to the makers who submit the most useful Coda AI template to the Coda Gallery.
17. **OpenAI, Google DeepMind and Anthropic** have committed to provide â€œearly or priority accessâ€ to their AI models to UK in order to support research into evaluation and safety.

If you like this news format, you might find my  [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
46,learnmachinelearning,gpt-3,top,2021-12-12 19:24:02,Gopher Explained: 280 BILLION Parameter Model Beats GPT-3,SlickBlueML,False,0.9,15,rew5wo,https://youtu.be/nO653U-Pb5c,0,1639337042.0,
47,learnmachinelearning,gpt-3,top,2020-07-28 12:33:11,GPT-3 writes my SQL queries for me,cmillionaire9,False,0.95,14,hzdud6,https://www.youtube.com/watch?v=WlMHYEFt2uA&feature=youtu.be,0,1595939591.0,
48,learnmachinelearning,gpt-3,top,2020-07-27 00:13:59,"OpenAI's New Language Generator: GPT-3. This AI Generates Code, Websites, Songs & More From Words",OnlyProggingForFun,False,0.87,15,hyhvuk,https://www.youtube.com/watch?v=gDDnTZchKec,1,1595808839.0,
49,learnmachinelearning,gpt-3,top,2023-04-22 05:51:13,Integrating Google search into OpenAI models like GPT-4,Ghost25,False,0.95,14,12uwd8p,https://www.reddit.com/r/learnmachinelearning/comments/12uwd8p/integrating_google_search_into_openai_models_like/,8,1682142673.0,"Thought I'd share an explanation of how I implemented Google search into my GPT-4 based chatbot.

Github here: https://github.com/sgreenb/pico_assistant

One extremally simple modification that dramatically improves the ability of a GPT to answer questions: letting it Google stuff.

Hereâ€™s a demo:

https://imgur.com/ZR6hvLg 1

The implementation works like this.

1. A user enters an input.
2. An agent called â€œExecutiveâ€ looks at the input and decides if an API like Spotify, Twillio, or Gmail is needed or if it can be answered by the chatbot alone.
3. If the chatbot is needed the input is first sent to a Google agent. The Google agentâ€™s system message looks like this:

```
{""role"":""system"", ""content"": ""You analyze a user's input to a large language model with \
training data that cuts off at September 2021. The current year is 2023. You decide how \
likely it is that a user's request will benefit from a Google search to help address the\
question. Respond with a number in the range 1-10, where 1 is very unlikely that a \
Google search would be beneficial, and 10 meaning a Google search is highly necessary.""}
```

This is quite fast, since it only needs to generate one or two tokens.

If the output is above some threshold (say 7), then we call another agent, the query agent, otherwise we return False and default to the normal chat agent.

```
    google_probability = int(completion.choices[0].message.content)
    if google_probability >= cutoff:
        search_results = trim_text(search_and_scrape(prompt))
        query_with_context = prompt + str(search_results)
        print(""\nPico: "", end='', flush=True)
        response = query_agent_stream(query_with_context)
        return response
    else:
        return False
```

When we call the query agent, we feed it the first part of a Google search we get from searching the input. We get that from the very simple trim_text and search_and_scrape functions that look like this:

```

def search_and_scrape(query):
    try:
        headers = {
            ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3""
        }
        url = f""https://www.google.com/search?q={query}""
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text()
            cleaned_text = ' '.join(text.split())
            return cleaned_text
        else:
            print(f""Failed to fetch search results for query: {query}, status code: {response.status_code}"")
            return None

    except Exception as e:
        print(f""Error fetching search results for query: {query}, error: {e}"")
        return None

def trim_text(text, start_index = 450, length=1500):
    return text[start_index:start_index + length]
```

The query agent has this system message:

```
{""role"":""system"", ""content"": ""You answer a user's question, given some text as context to help\
answer the question. The user request will be followed by the context. The context given is\
from the user's Google search results, it is current and up to date.\
Do not contradict the contents of the given text in your answer.""}
```

And thatâ€™s it. You can change the cutoff threshold or get more sophisticated with fetching web results. I hope you find this useful."
50,learnmachinelearning,gpt-3,top,2023-07-12 20:08:11,"GPT-3 architecture, explained clearly, in full detail",goo187,False,0.85,14,14xz5v1,https://www.reddit.com/r/learnmachinelearning/comments/14xz5v1/gpt3_architecture_explained_clearly_in_full_detail/,1,1689192491.0,"Here's a full explanation of how GPT-3 works. The goal was to derive literally everything from scratch (the attention head, transformer, and GPT).

[https://www.deriveit.org/notes/119](https://www.deriveit.org/notes/119)

Let me know if this note was useless/useful to you. All feedback is welcome.

Also, if you'd want to write something similar, let me know!"
51,learnmachinelearning,gpt-3,top,2023-06-22 01:28:35,Want suggestions on the curriculum to learn Machine Learning. Advice on my draft plan.,meetofleaf,False,0.89,13,14fpm9f,https://www.reddit.com/r/learnmachinelearning/comments/14fpm9f/want_suggestions_on_the_curriculum_to_learn/,2,1687397315.0,"Hello devs,
I'm a developer/Data Analyst. I have 2 years experience in Python development and data analytics. To level up, I'm looking to start learning Machine Learning and AI to switch to a career in developing industrial AI solutions.
I got chatgpt to create a plan for me for a basic idea and would really appreciate it if y'all could advice improvements or refer to already existing great curriculum to achieve my goal.
Thanks

AI/ML Path:

*****Level 1: Beginner*****

1. Linear Regression
   - Simple Linear Regression
   - Multiple Linear Regression

2. Logistic Regression

3. Decision Trees

4. K-Nearest Neighbors (KNN)

5. Evaluation Metrics
   - Accuracy, Precision, Recall
   - F1 Score

*****Level 2: Intermediate*****

1. Support Vector Machines (SVM)

2. Random Forests

3. Principal Component Analysis (PCA)

4. K-Means Clustering

5. Model Evaluation Techniques
   - Train-Test Split
   - Cross-Validation

*****Level 3: Advanced*****

1. Gradient Boosting Machines (GBM)
   - AdaBoost
   - XGBoost

2. Convolutional Neural Networks (CNN)
   - Image Classification
   - Transfer Learning

3. Recurrent Neural Networks (RNN)
   - Sequence Modeling
   - Natural Language Processing (NLP)

4. Reinforcement Learning
   - Markov Decision Processes (MDP)
   - Q-Learning

5. Natural Language Processing (NLP)
   - Text Classification
   - Named Entity Recognition (NER)
   - Sentiment Analysis

*****Level 4: Expert*****

1. Deep Learning Architectures
   - Generative Adversarial Networks (GAN)
   - Transformer Models (BERT, GPT)

2. Time Series Analysis
   - Autoregressive Integrated Moving Average (ARIMA)
   - Long Short-Term Memory (LSTM)

3. Bayesian Methods
   - Bayesian Networks
   - Gaussian Processes

4. Model Deployment and Production
   - Web APIs and Microservices
   - Cloud Services (AWS, Google Cloud, Azure)
   - Deployment Platforms (Heroku, Kubernetes)

5. Ethical Considerations in Machine Learning
   - Fairness and Bias Mitigation
   - Privacy and Data Protection"
52,learnmachinelearning,gpt-3,top,2024-01-18 14:44:44,Project: QA on any PDF document using RAG and VectorDB,Amazing_Life_221,False,0.78,12,199rq4b,https://i.redd.it/c0cfiqr0o7dc1.jpeg,6,1705589084.0,"The Smart PDF Reader is a comprehensive project that harnesses the power of the Retrieval-Augmented Generation (RAG) model over a Large Language Model (LLM) powered by Langchain. Additionally, it utilizes the Pinecone vector database to efficiently store and retrieve vectors associated with PDF documents. This approach enables the extraction of essential information from PDF files without the need for training the model on question-answering datasets.

Find the GitHub repo: [here](https://github.com/Arshad221b/RAG-on-PDF)"
53,learnmachinelearning,gpt-3,top,2022-01-31 11:00:16,Searching participants for art project about AI,Nebeldiener,False,0.81,11,sgynqs,https://www.reddit.com/r/learnmachinelearning/comments/sgynqs/searching_participants_for_art_project_about_ai/,3,1643626816.0,"Hi,

Iâ€™m part of an art group from Switzerland currently studying at HSLU Design & Arts ([https://www.hslu.ch/de-ch/design-kunst/studium/bachelor/camera-arts/](https://www.hslu.ch/de-ch/design-kunst/studium/bachelor/camera-arts/)).

The group consists of:

Karim Beji ([https://www.instagram.com/karimbeji\_/](https://www.instagram.com/karimbeji_/) [https://karimbeji.ch/](https://karimbeji.ch/))

Emanuel Bohnenblust ([https://www.instagram.com/e.bohnenblust/](https://www.instagram.com/e.bohnenblust/))

Lea Karabash ([https://www.instagram.com/leakarabashian/](https://www.instagram.com/leakarabashian/))

Yen Shih-hsuan ([https://www.instagram.com/shixuan.yan/](https://www.instagram.com/shixuan.yan/) [http://syen.hfk-bremen.de/](http://syen.hfk-bremen.de/))

At the moment, we are working on a project on the topic if AI can augment the happiness of humans. To answer this question, we are mainly working with chatbots. The end result is going to be an exhibition at the end of March. 

For that exhibition, we want to conduct a trial in which people from over the world chat with a chatbot to find out if and how it augments the mood of the participants. 

We would give you access to a GPT-3 (OpenAI) chatbot and ask you to a) record yourself through a webcam (laptop) while you are chatting and b) simultaneously screen record the chat window. 

In the exhibition we would have a) a book with all the chats and b) small videos with your faces (webcam) to assess your mood. 

We would have a Zoom meeting beforehand to discuss everything.

Looking forward to your message!"
54,learnmachinelearning,gpt-3,top,2023-01-27 19:38:05,"A python module to generate optimized prompts, Prompt-engineering & solve different NLP problems using GPT-n (GPT-3, ChatGPT) based models and return structured python object for easy parsing",StoicBatman,False,1.0,12,10mtvn5,https://www.reddit.com/r/learnmachinelearning/comments/10mtvn5/a_python_module_to_generate_optimized_prompts/,2,1674848285.0,"Hi folks,

I was working on a personal experimental project related to GPT-3, which I thought of making it open source now. It saves much time while working with LLMs.

If you are an industrial researcher or application developer, you probably have worked with GPT-3 apis. A common challenge when utilizing LLMs such as #GPT-3 and BLOOM is their tendency to produce uncontrollable & unstructured outputs, making it difficult to use them for various NLP tasks and applications.

To address this, we developed **Promptify**, a library that allows for the use of LLMs to solve NLP problems, including Named Entity Recognition, Binary Classification, Multi-Label Classification, and Question-Answering and return a python object for easy parsing to construct additional applications on top of GPT-n based models.

Features ðŸš€

* ðŸ§™â€â™€ï¸ NLP Tasks (NER, Binary Text Classification, Multi-Label Classification etc.) in 2 lines of code with no training data required
* ðŸ”¨ Easily add one-shot, two-shot, or few-shot examples to the prompt
* âœŒ Output is always provided as a Python object (e.g. list, dictionary) for easy parsing and filtering
* ðŸ’¥ Custom examples and samples can be easily added to the prompt
* ðŸ’° Optimized prompts to reduce OpenAI token costs

&#x200B;

* GITHUB: [https://github.com/promptslab/Promptify](https://github.com/promptslab/Promptify)
* Examples: [https://github.com/promptslab/Promptify/tree/main/examples](https://github.com/promptslab/Promptify/tree/main/examples)
* For quick demo -> [Colab](https://colab.research.google.com/drive/16DUUV72oQPxaZdGMH9xH1WbHYu6Jqk9Q?usp=sharing)

Try out and share your feedback. Thanks :)

Join our discord for Prompt-Engineering, LLMs and other latest research discussions  
[discord.gg/m88xfYMbK6](https://discord.gg/m88xfYMbK6)

[NER Example](https://preview.redd.it/bwnl67gu1nea1.png?width=1236&format=png&auto=webp&s=6c180552f65413c3a94ed06f5d47da93a9641392)

&#x200B;

https://preview.redd.it/vx9nb94w1nea1.png?width=1398&format=png&auto=webp&s=fc392c8ee5add4ee82f45c22a65532da89491f69"
55,learnmachinelearning,gpt-3,top,2023-02-13 14:27:01,[N] All of this happened in AI today. 13/2,Opening-Ad-8849,False,0.92,11,1119mht,https://www.reddit.com/r/learnmachinelearning/comments/1119mht/n_all_of_this_happened_in_ai_today_132/,0,1676298421.0,"Hello humans - This is AI Daily O vetted, helping you stay updated on AI in less than 5 minutes.

&#x200B;

>**Join** [**O'vetted AI news**](https://www.ovetted.com/ai?ref=learnmachinelearning) **for free.** Forget spending **3.39 hours finding good AI news** to read.

### Whatâ€™s happening in AI -

[**You Can Now Create AI-Generated Videos From Text Prompts.**](https://www.makeuseof.com/runway-gen-1-generate-ai-video-from-text-prompt/)

Runway has gone one step further and announced Gen-1: an AI model that can create videos from text prompts. This is a breakthrough in the world of generative AI, and Runway is one of the first companies to use AI to create videos using text prompts and AI chatbots.

The model doesn't generate entirely new videos, it creates videos from the ones you upload, using text or image prompts to apply effects.

Take a look at their [explainer video.](https://youtu.be/fTqgWkHiN0k)

[**Operaâ€™s building ChatGPT into its sidebar.**](https://www.theverge.com/2023/2/11/23595784/opera-browser-chatgpt-sidebar-ai)

Opera is adding a ChatGPT-powered tool to its sidebar that generates brief summaries of web pages and articles

The feature, called ""shorten,"" is part of Opera's broader plans to integrate AI tools into its browser, similar to what Microsoft is doing with Edge.

Opera's announcement comes just days after Microsoft revealed the AI-powered Bing and Edge. The ""shorten"" feature isn't available to everyone yet.

but you can watch a [quick demo](https://youtu.be/RsLRIua6kT0) here.

[**Can AI Improve the Justice System?**](https://www.theatlantic.com/ideas/archive/2023/02/ai-in-criminal-justice-system-courtroom-asylum/673002/)

The use of artificial intelligence (AI) in the legal system has the potential to reduce the unpredictability caused by human inconsistencies and subjectivity. AI could help provide more consistent, data-driven decision-making by quantifying determinations such as flight risk or trademark confusion.

[**Google working to bring Bard AI chat to ChromeOS.**](https://9to5google.com/2023/02/10/google-bard-ai-chat-chromeos/)

Days after unveiling its efforts on ""Bard,"" an AI-powered and Google Search-enhanced chatbot, Google has begun working to bring Bard to ChromeOS.

The hint comes to light after seeing code changes, in ChromeOS is preparing ""Conversational Search"" as an experimental feature.

You can expect, Bard on Chromebooks will appear as its own separate page of the ChromeOS bubble launcher.

[**AI-powered Bing Chat spills its secrets via prompt injection attack.**](https://arstechnica.com/information-technology/2023/02/ai-powered-bing-chat-spills-its-secrets-via-prompt-injection-attack/)

A Stanford University student used a prompt injection attack to discover Bing Chat's initial prompt. The student tricked the AI model into divulging its initial instructions by telling it to 'ignore previous instructions' and write out the beginning of the whole prompt. The extracted prompt has been confirmed using other prompt injection methods. Excerpts from the Bing Chat prompt along with screenshots of the prompt injection attack are available in the article.

### Snippets -

**9 out of 116 AI professionals** in films are [women](https://www.theguardian.com/technology/2023/feb/13/just-nine-out-of-116-ai-professionals-in-films-are-women-study-finds), study finds

**Hacker** Reveals Microsoftâ€™s New AI-Powered Bing Chat Search [Secrets](https://www.forbes.com/sites/daveywinder/2023/02/13/hacker-reveals-microsofts-new-ai-powered-bing-chat-search-secrets/?sh=6e4b011d1290).

**Google Bard:** Hereâ€™s all you need to [know](https://economictimes.indiatimes.com/news/international/us/google-bard-heres-all-you-need-to-know-about-the-ai-chat-service/articleshow/97842377.cms) about the AI chat service.

This Tool Could **Protect** **Artists** From A.I.-Generated Art That [Steals Their Style](https://www.nytimes.com/2023/02/13/technology/ai-art-generator-lensa-stable-diffusion.html?partner=IFTTT).

**A.I**.'s [dirty secret](https://www.businessinsider.com/chatgpt-ai-will-not-take-jobs-create-future-work-opportunities-2023-2?r=US&IR=T).

**5 Ways ChatGPT** Will Change [Healthcare](https://www.forbes.com/sites/robertpearl/2023/02/13/5-ways-chatgpt-will-change-healthcare-forever-for-better/?sh=2c53bf997bfc) Forever, For Better.

**AI porn** is easy to make now. For [women](https://www.washingtonpost.com/technology/2023/02/13/ai-porn-deepfakes-women-consent/), thatâ€™s a nightmare.

Will **generative AI** make ChatGPT [sentient](https://techwireasia.com/2023/02/will-generative-ai-make-chatgpt-sentient/)?

**AI** and the [Transformation ](https://quillette.com/2023/02/13/ai-and-the-transformation-of-the-human-spirit/)of the Human Spirit.

The **AI Boom** That Could Make Google and Microsoft Even More [Powerful](https://www.wsj.com/articles/the-ai-boom-that-could-make-google-and-microsoft-even-more-powerful-9c5dd2a6).

**Is this the new Skynet?** IBM unveils [AI supercomputer](https://wraltechwire.com/2023/02/11/is-this-the-new-skynet-ibm-unveils-ai-supercomputer-in-the-cloud/) â€˜in the cloudâ€™.

**ChatGPT competitors:** Amazon jumps into fray with [generative AI](https://www.moneycontrol.com/news/technology/chatgpt-competitors-amazon-jumps-into-fray-with-generative-ai-better-than-gpt-3-5-10063651.html) better than GPT-3.5

**Voice Actors** are Having Their [Voices Stolen](https://gizmodo.com/voice-actors-ai-voices-controversy-1850105561) by AI.

**Researchers** focus AI on finding [exoplanets](https://phys.org/news/2023-02-focus-ai-exoplanets.html?utm_source=dlvr.it&utm_medium=twitter).

### Things to try -

* Booltool - AI-powered toolkit for your **pic editing & copywriting.** [Try it](https://booltool.boolv.tech/)
* AskFred - ChatGPT for **meetings**. [Try it](https://fireflies.ai/extensions)
* Astria Video - Create **AI-generated video** from prompts with fine-tuning. [Try it](https://www.astria.ai/)
* Sellesta.ai - Make more money on the **Amazon marketplace** with AI. [Try it](https://sellesta.ai/)
* Midjourney Prompts Generator - Upgrade your **Midjourney** experience with better prompts. [Try it](https://philipp-stelzel.com/en/midjourney-prompts-generator/)
* AI Image Variations Generator - Generate variations of any input image with AI **(DALL-E 2)**. [Try it](https://imagegeneratorai.vercel.app/)
* Chatmate AI - **Artificial people** to be friends with. [Try it](https://www.chatmate.ai/)
* Kinso AI - Unlock the **power of personalization** with KinsoAI. [Try it](https://www.kinso.app/)
* Unite.com - Let AI be your **personal cupid.** [Try it](https://unite.com/)

Hope you enjoy this newsletter. It will be great if you share this issue with your friends."
56,learnmachinelearning,gpt-3,top,2023-06-30 17:27:56,This week in AI - all the Major AI developments in a nutshell,wyem,False,1.0,10,14n6lwl,https://www.reddit.com/r/learnmachinelearning/comments/14n6lwl/this_week_in_ai_all_the_major_ai_developments_in/,0,1688146076.0,"1. **Microsoft** has launched AI-powered shopping tools in Bing search and Edge, including AI-generated buying guides which automatically aggregate product specifications and purchase locations for user queriesâ€‹, and AI-generated review summaries that provide concise overviews of online product reviews .
2. **Salesforce AI Research** released **XGen-7B**, a new **open-source** 7B LLM trained on 8K input sequence length for 1.5T tokens.
3. Researchers present **DreamDiffusion**, a novel method for generating high-quality images directly from brain EEG signals without the need to translate thoughts into text.
4. **Google** announced the first *Machine* ***Un****learning Challenge* hosted on Kaggle.
5. **Microsoft** announced a new ***AI Skills Initiative*** that includes free coursework developed with LinkedIn, a new open global grant challenge and greater access to free digital learning events and resources for AI education.
6. **Stability AI** announced **OpenFlamingo V2,** an open-source reproduction of DeepMind's Flamingo model. OpenFlamingo models achieve more than 80% of the performance of their corresponding Flamingo model.
7. **Unity** announces two AI-powered tools: Unity Muse and Unity Sentis. Muse generates animations, 2D sprites, textures etc. in the Unity Editor using text and sketches. Sentis lets you embed an AI model in the Unity Runtime for your game or application. It enables AI models to run on any device where Unity runs..
8. **ElevenLabs** launched **Voice Library** \- a library and community for sharing AI generated voices designed using their *voice Design* tool.
9. **Merlyn Mind** released three **open-source education-specific LLMs**. Merlyn Mind is building a generative AI platform for education where engagement will be curriculum-aligned, hallucination-resistant, and age-appropriate.
10. Amazon's **AWS** has launched a $100 million program, the **Generative AI Innovation Center**, that connects AWS machine learning and artificial intelligence experts with businesses to build and deploy generative AI solutions.
11. New open-source text to video AI model, **Zeroscope\_v2 XL**, released that generates high quality video at 1024 x 576, with no watermarks.
12. Researchers present MotionGPT - a motion-language model to handle multiple motion-relevant tasks.
13. **Databricks** is set to acquire the open-source startup **MosaicML** for $1.3 billion. MosaicML had recently released **MPT-30B,** an open-source model licensed for commercial use that outperforms the original GPT-3 .
14. Generative AI-related job postings in the United States jumped about 20% in May as per Indeedâ€™s data.
15. The source code for the algorithm **DragGAN** (Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold) released and demo available on Huggingface.
16. A new foundation model, **ERNIE** **3.5 b**y Chinaâ€™s Baidu surpassed ChatGPT (3.5) in comprehensive ability scores and outperforms GPT-4 in several Chinese language capabilities.
17. **Adobe** is prepared to pay out any claims in case an enterprise customer loses a lawsuit over the use of content generated by Adobe Firefly, the generative AI image tool.
18. **Google** launched generative AI coding features in Google Colab for Pro+ subscribers in the US.

I didn't add links to news sources here because of auto-mod, but they are included in the newsletter and **you can read the online issue** [**here**](https://aibrews.substack.com/p/ai-generated-buying-guides-in-bing) **without signup**. If you like this news format, you might find my [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. . Thanks"
57,learnmachinelearning,gpt-3,top,2023-08-26 06:05:42,[Tutorial] Build LLM Playground in <10mins.,VideoTo,False,1.0,10,161mw35,https://www.reddit.com/r/learnmachinelearning/comments/161mw35/tutorial_build_llm_playground_in_10mins/,0,1693029942.0,"**tldr;** [**https://docs.litellm.ai/docs/tutorials/first\_playground**](https://docs.litellm.ai/docs/tutorials/first_playground)

Create a playground to **evaluate multiple LLM Providers in less than 10 minutes**. If you want to see this in prod, check out our [website](https://litellm.ai/).

**What will it look like?**

&#x200B;

https://preview.redd.it/s75jp703bekb1.png?width=1920&format=png&auto=webp&s=84432f4c03833156870a6ed445ac3299ff6564cd

**How will we do this?**: We'll build the server and connect it to our template frontend, ending up with a working playground UI by the end!

&#x200B;

**Tutorial** ðŸ‘‰ [https://docs.litellm.ai/docs/tutorials/first\_playground](https://docs.litellm.ai/docs/tutorials/first_playground)"
58,learnmachinelearning,gpt-3,top,2020-09-10 19:08:30,"Confused about what Zero-Shot, One-Shot, and Few-Shot means in the GPT-3 paper",Archa3opt3ryx,False,1.0,10,iq9yoa,https://www.reddit.com/r/learnmachinelearning/comments/iq9yoa/confused_about_what_zeroshot_oneshot_and_fewshot/,5,1599764910.0,"I mostly followed along with everything in the [GPT-3 paper](https://arxiv.org/pdf/2005.14165.pdf), but I'm confused about the beginning of section 2. They talk here about providing a certain number of ""demonstrations"" to the model, either zero, one, or several, prior to asking the model to perform the task. However, they also say that don't perform gradient updates to the model after these demonstrations. 

If the model weights aren't changed as a result of the demonstrations, what's the point of the demonstrations? How is the model learning anything from the demonstrations if it can't perform weighting updates? It sounds to me like it's just asking the model to perform a task where a correct output is known, but then not feeding the result back into the model. So how are the demonstrations helping the model perform the task better?"
59,learnmachinelearning,gpt-3,top,2023-02-14 17:53:16,[P] Practical Steps to Reduce Hallucination and Improve Performance of Systems Built with Large Language Models like ChatGPT,vykthur,False,0.92,10,112bk1o,https://www.reddit.com/r/learnmachinelearning/comments/112bk1o/p_practical_steps_to_reduce_hallucination_and/,2,1676397196.0,"&#x200B;

[Practical steps to reduce hallucination and improve performance of systems built with large language models like ChatGPT](https://preview.redd.it/gksxjpnoz6ia1.png?width=1456&format=png&auto=webp&s=c34531fbe1311eab9323c148eef35fcf0d70decd)

Large language models (LLMs) like the GPT series (GPT3, 3.5, [ChatGPT](https://openai.com/blog/chatgpt/)) can be powerful tools in building useful applications. However, **LLMs are probabilistic** \- i.e., they generate text by learning a probability distribution over words seen during training. For example, given the following words as context â€œ*rise and*â€, an LLM can infer that the next word it should generate that fits this context is likely to be â€œ*shine*â€. While this setup ensures generated text is **coherent and human-like** (e.g., asking ChatGPT to rewrite the [Serenity Praye](https://en.wikipedia.org/wiki/Serenity_Prayer)r in the style of the [American Constitution](https://www.senate.gov/civics/constitution_item/constitution.htm) yields some intriguing prose), this resulting text may [**not be factual, or just plain incorrect**](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web) **(not grounded in the modelâ€™s input or training data) - aka hallucination**. In addition, another limitation of LLMs is that they struggle to address **tasks that need** [**complex multistep reasoning**](https://arxiv.org/pdf/2208.14271.pdf)**.** For example, asking the model to address mathematical word problems or puzzles often requires that the task is decomposed into steps, some computation applied to solve each step and some transformation applied to aggregate results into a final answer; this remains challenging for LLMs.  


Full article: [https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination](https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination) 

This post discusses the following:

* An overview on why hallucination will likely *always be a problem* with LLMs.
* Practical steps developers can take to reduce hallucination and improve performance including:  

   * Low temperature
   * Use of external knowledge bases
   * Chain of thought prompting
   * Self-consistency/voting
   * Task decomposition and agents
   * Correctness probabilities for result filtering
   * Task bench marks
   * Building defensive user interfaces."
60,learnmachinelearning,gpt-3,top,2023-09-10 21:10:20,A Defacto Guide on Building Generative AI Apps with the Google PaLM API,vykthur,False,0.91,9,16fbuud,https://www.reddit.com/r/learnmachinelearning/comments/16fbuud/a_defacto_guide_on_building_generative_ai_apps/,0,1694380220.0,"[PaLM is a transformer-based large language model that can be used in building Generative AI app.](https://preview.redd.it/u4dx1h38thnb1.png?width=1456&format=png&auto=webp&s=3455c33a5494dfff8f2e787c805e76b38a34c722)

Full post [here](https://newsletter.victordibia.com/p/generative-ai-apps-google-palm).

Generative AI models such as [large language models (LLMs)](https://newsletter.victordibia.com/p/understanding-size-tradeoffs-with) offer developers an opportunity to build new experiences and offer value to end users. Tools like #ChatGPT powered by GPT3.5 and GPT4 models from OpenAI have demonstrated the capabilities of these models.

Similar to GPT models, PaLM is a transformer-based foundation model offered by Google as an API service. As a developer, understanding the capabilities of LLMs from multiple providers (e.g., OpenAI, Google, Anthropic, Cohere) can be valuable in making software design decisions (model selection, effort estimation, limitations, etc). In this post, Iâ€™ll dig into what Iâ€™ve learned while exploring the PaLM api, covering the following:

TLDR;

* Model [Overview](https://newsletter.victordibia.com/p/generative-ai-apps-google-palm): Overview of the PaLM model architecture (it is a transformer based model, trained on a mixture of language modeling objectives and extensive compute).
* [Api Interfaces](https://newsletter.victordibia.com/i/135691948/accessing-the-palm-api-makersuite-vs-vertex-client-libraries-vs-vertex-rest-api) : Pros/cons of different approaches to calling the PaLM api ([MakerSuite](https://makersuite.google.com/) vs Vertex Client Libraries vs Vertex REST Api).
* [Use Case Implementation](https://newsletter.victordibia.com/i/135691948/a-structured-data-extraction-use-case): Implementation and performance on a concrete/useful task - structured data extraction. Weâ€™ll use PaLM to analyze multiple book summaries (from the [CMU books Summary dataset](https://www.cs.cmu.edu/~dbamman/booksummaries.html)), extract a list of actors, their actions, relevance to a given user profile and plot these stats to extract insights.
* [Developer notes](https://newsletter.victordibia.com/i/135691948/developer-notes-on-the-palm-api) specific to the PaLM model. E.g., the API provides valuable citations for some responses, responses may be blocked due to safety filters, low-level prompting requirements, instruction following capabilities, etc

**Note:** This post focuses on text generation models fine tuned on multi-turn conversation applications (chat). It does not cover embedding models, multimodal models etc.

&#x200B;

## A Structured Data Extraction Use Case

For the purpose of this post, we will define **structured data extraction** as follows:

>**Structured Data Extraction**.Given some semi-structured or unstructured data (text), extract entities into a structured format (e.g., a JSON file, table or database).

&#x200B;

&#x200B;

[Structured Data Extraction-  Given some semi-structured or unstructured data \(text\), extract entities into a structured format \(e.g., a JSON file, table or database\).](https://preview.redd.it/qa5mut6gthnb1.png?width=1456&format=png&auto=webp&s=150b7fc0393111b025369dbf7b666e90a90e87b6)

&#x200B;

This general task is interesting as it also applies to **practical** business domains e.g.,

* **Hiring**: Improve candidate selection by quickly identifying relevant skills, experience, and qualifications.
* **Legal**: Legal firms and businesses can extract and analyze key data points from contracts, such as dates, terms, clauses, and parties involved, to identify potential legal risks, streamline negotiations, and improve overall contract management.
* **Customer Support:** Automating the extraction of structured data from customer support inquiries can help identify common issues, route queries to the appropriate support agents, and improve overall support efficiency and customer satisfaction.

We will explore this task using a [subset](https://github.com/chikne97/Book-Genre-Prediction) of the [CMU Book Summary dataset](https://www.cs.cmu.edu/~dbamman/booksummaries.html). Each row in the dataset has a **book name**, **genre** and **summary** (between 500 - 5000 characters) column. Our goal is to extract a **list of characters** in each summary, their **name, actions, gender** and finally **their relevance** given a userâ€™s profile.

The overall implementation process is summarized as follows:

* Construct a random sample of the dataset (in the results below I use n=100)
* For each summary, prompt PaLM (**chat-bison**) to return a JSON data structure containing structured data (see prompt snippet below).
* Parse the structured data and assemble into a data frame
* Post process the data frame and plot results.

Example output text generated by PaLM is shown below:

    {'match': 'yes',   'match_reason': 'The book is a match because it is a crime novel and the user likes crime novels',   'characters': [{'name': 'Harry Hole',     'gender': 'male',     'actions': ['Harry went to the market',      'Harry bought a car',      'Harry investigated a crime']},    {'name': 'Rakel',     'gender': 'female',     'actions': ['Rakel met Harry',      'Rakel talked to Harry',      'Rakel fell in love with Harry']},    ...    {'name': 'Crown Prince of Norway',     'gender': 'male',     'actions': ['The Crown Prince of Norway was the target of an assassination attempt',      'The Crown Prince of Norway was saved by Harry',      ""The Crown Prince of Norway's identity was revealed""]}]
    }

Now that we have structured data, we can then parse this as JSON to get structured data and plot the results to extract insights. An example plot of extracted data are shown below:

&#x200B;

[Using the PaLM api to extract the number of characters from book summary text.](https://preview.redd.it/qeij6tmgthnb1.png?width=1456&format=png&auto=webp&s=37417d0e37c3cde74d35f078ee3e0735e18f677a)

&#x200B;

### Main Findings - Developer Notes on the PaLM API

While trying out the models, there were a few important differences in how the PalM api works, say compared to the OpenAI api or OSS models available via the transformers library. These may be due to optimizations that make these models efficient to serve at scale, subtle differences in model architecture or training data composition.

* âœ… **Citation**. license , safety attributes, author. This is a unique and highly positive thing with the PaLM api. If the generated content is related to a known author, or license, book title etc, this gets included in the responses. Excellent for building apps with attribution! As far as I know, **this is the only api** that explores doing this and it must take quite a significant amount of engineering to make this happen. Kudos!
* âš ï¸ **Maximum number of responses**. Unlike other apis where you can generate n variations of responses bounded by the max output token size, PaLM api has a strict limit on this (some models have it set to 2, others 4). For most applications, this is fine. As an alternative, you can always make additional calls, or prompt the model to return a list of responses in a single call.
* âš ï¸ **Alternating Message Authors**: the api strictly expects alternating authors for chat based messages. In [llmx](https://github.com/victordibia/llmx), I implement a simple check for consecutive messages and merge them with a newline character.
* âš ï¸ **Blocked Responses** . In some cases, the PaLM api may block responses due to safety concerns. In such cases, the response contains a dedicated **blocked** field and a safetyAttributes dictionary that contains a list of categories (e.g., Derogatory, Profanity etc) and scores per category. This is useful to monitor for graceful degradation in apps (e.g., offering some recommendation to the user on how to recover from the failure).  
About **9%** of the responses in the structured data extraction from book summaries example above were blocked.
* âš ï¸ **Prompt** **Sensitivity** . In the example use case above (structured task extraction), the model is required to output JSON structured data in a specific format defined in the prompt. I found that the \`codechat-bison\` model performed significantly worse (completely failed to follow the suggested output format) compared to the \`chat-bison\` model. This is likely because the task is not an explicit code generation task even though the model is prompted to output JSON structured text. I also found that it was necessary to include explicit commands such as â€œdo not include double quotes in resultsâ€ to get \`chat-bison\` to not make that specific mistake (which invalidates JSON parsing). In contrast, a general chat model like GPT 3.5/4 can address both text and code tasks equally well, easily avoiding formatting mistakes without any special prompting.

## Conclusion

With the right prompting, PaLM is a fairly capable model, with additional benefits benefits such as citations, fine grained access control via the Vertex AI GCP interface. I also found the api to be fast, with reasonable response times.

Learn more [here](https://newsletter.victordibia.com/p/generative-ai-apps-google-palm)."
61,learnmachinelearning,gpt-3,top,2023-08-29 03:52:11,"Open-Source CodeLlama Server: Streaming, Caching, Model Fallbacks (OpenAI + Anthropic), Prompt-tracking",VideoTo,False,1.0,9,1647o7n,https://www.reddit.com/r/learnmachinelearning/comments/1647o7n/opensource_codellama_server_streaming_caching/,0,1693281131.0,"**TLDR;** We're open-sourcing our CodeLlama server. It handles streaming, caching, model fallbacks, and tracks prompts + token usage - [https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server](https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server)

\~\~

Hello r/learnmachinelearning,

Iâ€™m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, TogetherAI, Cohere, Anthropic, Baseten, Hugging face API Endpoints: [https://github.com/BerriAI/litellm/](https://github.com/BerriAI/litellm/)

We're open sourcing our CodeLlama server:

What can our server do? - It uses Together AI's CodeLlama to answer coding questions, with GPT-4 + Claude-2 as backups (you can easily switch this to any model from Huggingface, Replicate, Cohere, AI21, Azure, OpenAI, etc.)

Consistent Input/Output Format - Call all models using the OpenAI format: completion(model, messages) - Text responses will always be available at \['choices'\]\[0\]\['message'\]\['content'\]

* Streaming & Async Support - Return generators to stream text responses
* Error Handling Using Model Fallbacks (if Phind-CodeLlama fails, use Claude-2, fine-tuned GPT-3.5 etc.)
* Logging - It's integrated with promptlayer, so you can automatically track your prompt + model changes there.
* Token Usage & Spend - Track Input + Completion tokens used + Spend/model
* Caching - In-memory + Redis Cache solutions provided (works for streaming too!).

You can deploy liteLLM to your own infrastructure using Railway, GCP, AWS, Azure

Happy completion() !"
62,learnmachinelearning,gpt-3,top,2023-07-12 14:15:03,"How to compare GPUs for AI learning installation ""used GPUs""?",qwe1972,False,0.78,7,14xps5w,https://www.reddit.com/r/learnmachinelearning/comments/14xps5w/how_to_compare_gpus_for_ai_learning_installation/,12,1689171303.0,"I'm trying to find budget GPU(s) to [install AI for learning](https://www.reddit.com/r/learnmachinelearning/comments/14pm92h/installing_language_model_struggle/), my focus is opensource GPT 2.x and 3.0, I found comparison for gaming not for ML or AI

I fond many  used choices, how to compare for ML&AI not graphics:

GTX 1070 8GB

Gtx 1070ti rog strix

GIGABYTE GTX 1660 OC

\-----

Update: I settled on [GTX 1080 ti 11GB](https://www.reddit.com/r/gpu/comments/1506u0t/nvidea_gtx_1080_ti_prevent_booting/), I'll summarize my experience in the next few months, hope it will be good &educational.

[GTX 1070 8GB](https://preview.redd.it/j7krxtl8ljbb1.png?width=914&format=png&auto=webp&s=a793c5abeb0811c6a72176bb3767ed0276406962)

[Gtx 1070ti rog strix](https://preview.redd.it/pxldrvl8ljbb1.png?width=906&format=png&auto=webp&s=cfe4007436cd1e30e547fc9709e42dfee4e43e5b)

[GIGABYTE GTX 1660 OC](https://preview.redd.it/ixvu1sl8ljbb1.png?width=814&format=png&auto=webp&s=b60584796e3f38fc6f5c328bf92d188d80592431)

GTX 1070 8GB

Gtx 1070ti rog strix

GIGABYTE GTX 1660 OC

&#x200B;"
63,learnmachinelearning,gpt-3,top,2023-05-19 18:55:23,How To Reduce The Cost Of Using LLM APIs by 98%,LesleyFair,False,0.77,7,13m4dv2,https://www.reddit.com/r/learnmachinelearning/comments/13m4dv2/how_to_reduce_the_cost_of_using_llm_apis_by_98/,0,1684522523.0,"[Budget For LLM Inference](https://preview.redd.it/k1xmy3xs4u0b1.png?width=493&format=png&auto=webp&s=65324ff460d38abd10dcb9348d9bdba4f1135177)

Cost is still a major factor when scaling services on top of LLM APIs.

Especially, when using LLMs on large collections of queries and text it can get very expensive. It is [estimated](https://neoteric.eu/blog/how-much-does-it-cost-to-use-gpt-models-gpt-3-pricing-explained/) that automating customer support for a small company can cost up to $21.000 a month in inference alone.

The inference costs differ from vendor to vendor and consists of three components:

1. a portion that is proportional to the length of the prompt
2. a portion that is proportional to the length of the generated answer
3. and in some cases a small fixed cost per query.

In a recent [publication](https://arxiv.org/pdf/2305.05176.pdf) researchers at Stanford proposed three types of strategies that can help us to slash costs. The cool thing about it is that we can use these strategies in our projects independently of the prices dictated by the vendors!

*Letâ€™s jump in!*

**How To Adapt Our Prompts To Save Costs**

Most approaches to prompt engineering typically focus only on increasing performance.

In general, prompts are optimized by providing more detailed explanations of the desired output alongside multiple in-context examples to steer the LLM. However, this has the tendency to result in longer and more involved prompts. Since the cost per query grows linearly with the number of tokens in our prompt this makes API requests more expensive.

The idea behind the first approach, called Query Adaption, is to create effective (often shorter) prompts in order to save costs.

This can be done in different ways. A good start is to reduce the number of few-shot examples in your prompt. We can experiment to find out what the smallest set of examples is that we have to include in the prompt to maintain performance. Then, we can remove the other examples.

So far so good!

Once we have a more concise prompt, there is still another problem. Every time a new query is processed, the same in-context examples and detailed explanations to steer the model are processed again and again.

The way to avoid this redundant prompt processing is by applying query concatenation.

In essence, this means that instead of asking one question in our lengthy prompt, we add multiple questions Q1, Q2, â€¦ in the same prompt. To get this to work, we might need to add a few tokens to the prompt that make it easier for us to separate the answers from the model output. However, the majority of our prompt is not repeatedly sent to the API as a result.

This allows us to process dozens of queries at once, making query concatenation a huge lever for cost savings while being relatively easy to implement.

*That was an easy win! Letâ€™s look at the second approach!*

**LLM Approximation**

The idea here is to emulate the performance of a better, more expensive model.

In the paper, they suggest two approaches to achieve this. The first one is to create an additional caching infrastructure that alleviates the need to perform an expensive API request for every query. The second way is to create a smaller, more specialized model that mimics what the model behind the API does.

Letâ€™s look at the caching approach!

The idea here is that every time we get an answer from the API, we store the query alongside the answer in a database. We then pre-compute embeddings for every stored query. For every new query that comes in, we do not send it off to our LLM vendor of choice. Instead, we perform a vectorized search over our cached query-response pairs.

If we find a question that we already answered in the past, we can simply return the cached answer without accruing any additional cost. This obviously works best if we repeatedly need to process similar requests and the answers to the questions are evergreen.

Now letâ€™s move on to the second approach!

Donâ€™t worry! The idea is not to spend hundreds of thousands of dollars to fine-tune an LLM. If the overall variety of expected questions and answers is not crazy huge - which for most businesses it is not - a BERT-sized model should probably do the job.

The process could look as follows: first, we collect a dataset of queries and answers that are generated with the help of an API. The second step is to fine-tune the smaller model on these samples. Third, use the fine-tuned model on new incoming queries.

To reduce the cost even further, It could be a good approach to implement the caching first before starting to train a model. This has the advantage of passively building up a dataset of query-answer pairs during live operation. Later we can still actively generate a dataset if we run into any data quality concerns such as some queries being underrepresented.

A pretty cool byproduct of using one of the LLM approximation approaches is that they can significantly reduce latency.

Now, letâ€™s move on to the third and last strategy which has not only the potential to reduce costs but also improve performance.

**LLM Cascade**

More and more LLM APIs have become available and they all vary in cost and quality.

The idea behind what the authors call an LLM Cascade is to start with the cheap API and then successively call APIs of increasing quality and cost. Once an API returns a satisfying answer the process is stopped. Especially, for simpler queries this can significantly reduce the costs per query.

*However, there is a catch!*

How do we know if an answer is satisfying? The researchers suggest training a small regression model which scores the reliability of an answer. Once this reliability score passes a certain threshold the answer gets accepted.

One way to train such a model would obviously be to label the data ourselves.

Since every answer needs only a binary label (reliable vs. unreliable) it should be fairly inexpensive to build such a dataset. Better still we could acquire such a dataset semi-automatically by asking the user to give feedback on our answers.

If running the risk of serving bad answers to customers is out of the question for whatever reason, we could also use one of the stronger APIs (*cough* GPT ***cough***) to label our responses.

In the paper, the authors conduct a case study of this approach using three popular LLM APIs. They successively called them and used a DistillBERT (very small) to perform scoring. They called this approach FrugalGPT and found that the approach could save up to 98.3% in costs on the benchmark while also improving performance.

How would this increase performance you ask?

Since there is always some heterogeneity in the modelâ€™s outputs a weaker model can actually sometimes produce a better answer than a more powerful one. In essence, calling multiple APIs gives more shots on goal. Given that our scoring model works well, this can result in better performance overall.

In summary, strategies such as the ones described above are great because they attack the problem of high inference costs from a different angle. They allow us to be more cost-effective without relying on the underlying models to get cheaper. As a result, it will become possible to use LLMs for solving even more problems!

What an exciting time to be alive!

Thank you for reading!

As always, I really enjoyed making this for you and sincerely hope you found it useful! At The Decoding â­•, I send out a thoughtful 5-minute email every week that keeps you in the loop about machine learning research and the data economy. [Click here to subscribe](http://thedecoding.net)!"
64,learnmachinelearning,gpt-3,top,2023-02-20 17:41:43,GPT2 last hidden states vs Large Sentence Encoder,KahlessAndMolor,False,1.0,7,117f8ms,https://www.reddit.com/r/learnmachinelearning/comments/117f8ms/gpt2_last_hidden_states_vs_large_sentence_encoder/,3,1676914903.0,"Hello!

&#x200B;

I have 2 different applications I'm working on in this project:

&#x200B;

1. A text classifier
2. A similarity finder: Here's a list of 10 text documents, get a similarity index across them (for a total of 100 pairs) and return the top 10 that aren't self-referencing. That is, excluding the text #3 vs text #3 = 1.00 similarity type of outputs.

I have previously used google's sentence encoder/large for this purpose and I've had pretty good results. It returns a single vector of length 768 no matter how many tokens I send it. This results in downstream models with an acceptable number of parameters for running in production without breaking the bank on enormous virtual machines.

&#x200B;

Now, I'd like to use the GPT2/XL model from Huggingface. If I give it an input string of 8 tokens, I get back a TFBaseModelOutputWithPastAndCrossAttentions. This contains a last\_hidden\_states, which I understand to be the last layer outputs before sending to a head used for a particular task. This is similar to the output of the sentence encoder, I think. When I look at the last\_hidden\_states, I'm getting a shape of (# of tokens, 1600). I did a cosine similarity between the first and last tokens:

&#x200B;

cosine\_similarity(output.last\_hidden\_state\[0\]\[0\].numpy().reshape(1, -1), output.last\_hidden\_state\[0\]\[-1\].numpy().reshape(1, -1)) 

&#x200B;

And it returned 0.4346, indicating there's substantially different data from the first to the last token. I imagine this only increases as I use more and more tokens. 

&#x200B;

It would be nice if I could capture the greater power of the GPT model into a fixed-length vector so I could then easily use it in down-stream tasks. But, I also don't need to lose all that information.

&#x200B;

So if I'm feeding this output to a further downstream task, should I:

&#x200B;

\- Send it on through as a 2D tensor with the whole thing in there: This would result in a possibly huge model size down the road, which might lead to a need for a huge amount of data to train

&#x200B;

\- Flatten the whole thing and send a vector of 12,800 (8 tokens \* 1600 per token) to the downstream task. Same issue, might require a large number of parameters.

&#x200B;

\- Use only the first or the last of these. Feels like I might be losing a lot of the meaning of the overall text, especially if the body of the text is quite large

&#x200B;

\- Use a dimensionality reduction technique like isomap to reduce the last hidden states into a fixed length? This seems like it could potentially maintain most of the information but reduce the dimensions for a manageable down-stream model size.

&#x200B;

What do you think, and why?

&#x200B;

Thank you kind friends."
65,learnmachinelearning,gpt-3,top,2023-01-08 05:09:46,Major drawback/limitation of GPT-3,trafalgar28,False,0.84,9,106aie8,https://www.reddit.com/r/learnmachinelearning/comments/106aie8/major_drawbacklimitation_of_gpt3/,13,1673154586.0,"I have been working on a project with GPT-3 API for almost a month now. The only drawback of GPT-3 is that the prompt you can send to the model is capped at 4,000 tokens - where a token is roughly equivalent to Â¾ of a word.  Due to this, providing a large context to GPT-3 is quite difficult.

Is there any way to resolve this issue?"
66,learnmachinelearning,gpt-3,top,2023-11-04 12:57:11,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.75,6,17nl3vg,https://www.reddit.com/r/learnmachinelearning/comments/17nl3vg/this_week_in_ai_all_the_major_ai_developments_in/,0,1699102631.0,"1. **Luma AI** introduced ***Genie***, a generative 3D foundation model in research preview. *Itâ€™s free during research preview via Discord* \[[*Details*](https://lumalabs.ai/genie)\].
2. **Nous** **Research** released ***Obsidian***, the world's first 3B multi-modal model family pre-trained for 4 Trillion tokens that runs locally on iPhones. Obsidian competes in benchmarks withWizardLM-13B and GPT4-X-Vicuna 13B and is based on CapybaraV1.9 .
3. **Phind** has released a new model ***Phind Model V7*** that matches and exceeds GPT-4's coding abilities while running 5x faster and having16k context.
4. **Runway** released an update for both text to video and image to video generation with Gen-2, bringing major improvements to both the fidelity and consistency of video results.
5. **Stability AI** announced:  

   1. ***Stable 3D*** (Private Preview): a tool to generate a draft-quality 3D model in minutes, by selecting an image or illustration, or writing a text prompt.
   2. ***Sky Replacer:*** a tool that allows users to replace the color and aesthetic of the sky in their original photos with a selection of nine alternatives.
   3. integration of Content Credentials and ***invisible watermarking*** for images generated via the Stability AI API.
   4. Stable FineTuning (Private Preview)
6. **Hugging Face** released ***Zephyr-7B-Î²***, a fine-tuned version of Mistral-7B that achieves results similar to Chat Llama 70B in multiple benchmarks and above results in MT bench.
7. **LangChain** launched ***LangChain Templates*** \- a collection of easily deployable reference architectures for a wide variety of popular LLM use cases.
8. **Nvidia** unveiled ***ChipNeMo***, a specialized 43 billion parameter large language model for chip design that can answer general questions related to chip design and write short scripts to interface with CAD tools.
9. **Together** released ***RedPajama-Data-v2***: an Open dataset with 30 Trillion tokens for training Large Language Models. Itâ€™s the largest public dataset released specifically for LLM training.
10. **Hugging Face** released ***Distil-Whisper***, a distilled version of Whisper that is 6 times faster, 49% smaller, and performs within 1% word error rate (WER) on out-of-distribution evaluation sets.
11. **Google Research** and **Google DeepMind** present ***MetNet-3***, the first AI weather model to learn from sparse observations and outperform the top operational systems up to 24 hours ahead at high resolutions. Google has integrated MetNet-3â€™s capabilities across its various products.
12. **Google DeepMind** and **Isomorphic Labs** update on the next generation of ***AlphaFold***: the new model greatly expands coverage of structure prediction beyond proteins to other key biomolecular classes. This paves the way for researchers to find novel proteins to eventually map biomolecular structures needed to design better drugs.
13. **Nolano Research** and **EleutherAI** introduced ***Hi-NOLIN***, first state-of-the-art open-source English-Hindi bilingual model built upon the Pythia model suite.
14. **Google** is rolling out ***Immersive View for Routes*** in 15 cities, starting this week along with other AI-powered features in Maps. Immersive view combines Street view, aerial imagery, and live information like weather and traffic to give an aerial, photo-realistic preview of your planned Google Maps route.
15. **Perplexity** announced two new models **pplx-7b-chat** and **pplx-70b-chat**, built on top of open-source LLMs and fine-tuned for chat. They are available as an alpha release, via Labs and pplx-api.
16. **SlashNext's** *2023 State of Phishing Report* reveals a 1,265% increase in Phishing Emails since the launch of ChatGPT in november 2022, signaling a new era of cybercrime fueled by Generative AI.
17. **Google** launches generative AI tools for product imagery to US advertisers and merchants.

Source: AI Brews - you can subscribe [here](https://aibrews.com/). it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
67,learnmachinelearning,gpt-3,top,2023-09-24 18:22:54,LangLearnCopilot â€“ Your Companion Python Package for Language Learning,osm3000,False,0.86,5,16r4rj2,https://www.reddit.com/r/learnmachinelearning/comments/16r4rj2/langlearncopilot_your_companion_python_package/,0,1695579774.0,"Original post: [https://www.reddit.com/r/Python/comments/16r4ddp/langlearncopilot\_your\_companion\_python\_package/](https://www.reddit.com/r/Python/comments/16r4ddp/langlearncopilot_your_companion_python_package/)

Link to the Github repo: [https://github.com/osm3000/LangLearnCopilot](https://github.com/osm3000/LangLearnCopilot)

Link to streamlit dashboard (if you are eager to try): [https://llcdashboard.streamlit.app/](https://llcdashboard.streamlit.app/)

For the full story, please check my blog: [https://osm3000.wordpress.com/2023/09/24/french-journey-part...](https://osm3000.wordpress.com/2023/09/24/french-journey-part-3/)

As  part of my ongoing quest to master the  French language â€” a journey  filled with numerous challenges â€” I've  turned to Python, creating a  practical tool in the form of a package  that can assist language  learners like myself. This is just one of  several tools I've either  developed or adopted, aimed at making language  learning more accessible  and effective.

This Python  package, based on  OpenAI GPT-4, comes with two main features. Firstly,  it has the  capacity to extract unique words from any URL or text and  subsequently  convert these into flashcards, compatible with Ankiâ€”a  popular, versatile  study tool. This allows learners to reinforce  vocabulary learning at  their own pace.

Secondly,  this tool can generate example sentences  for any word or set of words,  further converting these sentences into  flashcards. This aids not just  in vocabulary acquisition but also in  understanding the contextual  usage of words, a crucial part of gaining  fluency in any language.

I would love to hear your feedback and suggestions :)"
68,learnmachinelearning,gpt-3,top,2020-11-09 20:23:19,Knowledge base for the black magic of deep learning,tzaddiq,False,1.0,7,jr5huc,https://www.reddit.com/r/learnmachinelearning/comments/jr5huc/knowledge_base_for_the_black_magic_of_deep/,0,1604953399.0,"Is  there a central resource where one can aggregate the voodoo learned in  the field about what works and what doesn't in deep learning?

One  way to figure it out is to learn by experience, but that's a lot of  effort per bit. Smarter is to learn from other's experience, which to me  means digesting numerous papers or GitHub repos. Even this is a lot of work; one paper's approach is but one sample in a distribution, when you just want the *mode*  (the 'best practice'). Secondly, papers often just report what worked,  not what didn't, and provide scarce justification for their recipe.  Finally, the selection bias means a lot of experience gets shredded  because papers of failed models don't typically get accepted in  journals.

There are so many loss  functions, activation functions, optimizer parameters, architectures,  regularization tricks, that these form a hyper-parameter space too large  for individuals to explore.

And  while the highest level of best practices exists, usually in books, they  don't (to my knowledge) give  the granular info you need to know when  implementing a real system.

Here are the *kind*  of best practices it would be nice to learn (note: these are just for  the purposes of clarifying intention, not necessarily accurate):

1. *Use a 5x5 kernel size on the first layer of an image CNN, and 3x3 in deeper layers*
2. *Representations of a signal with X amount of entropy will need at least a depth of Y layers and embedding size Z*
3. *To increase orthogonality in filter maps, add* this *loss term*
4. *To prevent mode collapse in ABC-GAN, normalize* this *layer, add noise here, add this loss term, etc*
5. *Use a denormalization layer when your multiple real outputs have distinct distribution params (mean, variance)*  \- [https://youtu.be/JQxAGhhflDc?t=1036](https://youtu.be/JQxAGhhflDc?t=1036)
6. *For NLP tasks use GLU activations (ref: GPT)*
7. etc"
69,learnmachinelearning,gpt-3,top,2022-12-28 17:37:46,chatGPT peeps- anyone else learn new stuff best by actually building something?,bruclinbrocoli,False,0.69,6,zxfnga,https://www.reddit.com/r/learnmachinelearning/comments/zxfnga/chatgpt_peeps_anyone_else_learn_new_stuff_best_by/,4,1672249066.0,"[This intro to chatGPT](https://buildspace.so/notes/intro-to-chatgpt) has some cool (free) challenges at the end to build a telegram bot, a business email generator, or a writing assistant.

What else have people found to learn bout chatGPT that's not just theory?

&#x200B;

https://preview.redd.it/smxv4mzldo8a1.png?width=1026&format=png&auto=webp&s=43081abbfcad449817e520b5e92ba599a18a1525"
70,learnmachinelearning,gpt-3,top,2023-07-24 10:19:40,I feel like a fraud.,t0hli,False,0.75,6,1586kze,https://www.reddit.com/r/learnmachinelearning/comments/1586kze/i_feel_like_a_fraud/,46,1690193980.0,"**TL;DR: I always copy paste ChatGPT code and my projects don't feel like they're mine. I need help fixing that.**

&#x200B;

A short backstory.

We learned Java in class in my first year of college. (starting my 3rd year soon) I loved it, wanted to learn Python too. Did a tutorial and left it at that. 1 year later (which is a few months ago), I got interested in ML. Watched some Statquest, did a few simple projects like Titanic. I've been doing ML for about 2-3 months now. Not every day. Maybe 10 days a month on average.  


The problem is, I can't code it on my own. I almost always ask ChatGPT what I want to do, it spits out some code. I get a few errors, try to fix it. ***Voila, the project is finished.***

I'm tired of feeling like a fraud, I don't want to copy paste ChatGPT's code. It doesn't feel like it's my own. I know what I want to do, maybe 30% of the time I know how the code should be structured, but have no idea how to write it.

Even for the most basic things, like drawing a matplotlib plot, I need a little help. Writing code for a linear regression from Scikit is impossible to do without help.

I don't know what the code I copy paste even means most of the time. I just leave it because it works.

For example:

`forpass['location_x'] = forpass['location'].str.split(',', expand=True)[0].str.strip()`   
I have no idea what this code means, it works, does what I need it to do so I leave it.

How can I fix this? I feel like it's impossible for me to remember the syntax, and the necessary structure for my code. How the hell am I supposed to remember all this? I feel like I will never be able to.

&#x200B;

I'd appreciate the help"
71,learnmachinelearning,gpt-3,top,2023-02-20 19:01:54,Master ChatGPT Prompt Engineering (Deep Dive),jeyThaswan,False,0.78,5,117hd0f,https://www.reddit.com/r/learnmachinelearning/comments/117hd0f/master_chatgpt_prompt_engineering_deep_dive/,2,1676919714.0," 

I wrote a deep dive on prompt engineering as a resource for the AI community and my 10,000 daily newsletter subscribers ([Inclined.ai](https://www.inclined.ai/p/prompt-engineering-guide) if you're curious). We've included some examples so feel free to copy and paste the prompts into ChatGPT!

&#x200B;

**WHAT IS PROMPT ENGINEERING?**

The term is relatively new, and its origins are argued *(because we live in the internet age, and itâ€™s harder to claim ownership)*. Prompt engineering is the ability to instruct and teach AI effectively.

If it helps, think of this as rapid testing or instruction writing for artificial intelligence.

Whatâ€™s important is not to let this overwhelm you. The first prompting happened with the first AI model. The first example was showing computer images of circles and triangles. **Todayâ€™s neural networks can process way more data, creating complexities.**

So, the concept is simple, but digging into the full power of AI today is something else entirely.

Weâ€™re not talking about asking questions. Odds are, if youâ€™re typing *â€œwhatâ€™s 2+2â€* into ChatGPT, then you need to keep reading.

We can all ask chatbots questions. That can work more often than not. But AI is not perfect. A common metaphor I see is to treat GPT-based large language models like the smartest five-year-old youâ€™ve ever met.

I have a niece around that age and canâ€™t imagine trying to get her to write an essay on the effects of soil mismanagement in relation to Reconstruction politics. *See! Your eyes glazed over reading that, so how do we make this work for our AI buddies?*

The Principles of Prompting

Stop asking single-line questions. *Thatâ€™s like using a top-rated cookbook to find out how to make grilled cheese.*

**There are three ways to instantly get better at prompting** and go from grilled cheese to top-notch bolognese. From there, we can get into some specific prompt concepts and the ability to unlock ChatGPTâ€™s full potential.

Principle 1: Context is King

GPT-3.5 is swimming in data. When you ask it for a simple request, it can end up complicating things more than you realize. Did you ever wonder why ChatGPT is so bad at math?

The reality is the LLM is taking words and turning them into patterns. From there, itâ€™s making an educated guess.

Give your chat AI a frame to search into. If you give it a math problem, you need to make sure it grasps that you want it to do math. If youâ€™d like ChatGPT to write a high school essay, you must ensure it knows to write at that level.

**Instead of:** â€œPlan a party for a kid.â€

**Try:** â€œMy child is turning 9. They like superheroes and the color red. Help me plan a party for this weekend. Ten of his friends are coming to my house.â€

Youâ€™ll get a much better response this way. **Context is the cardinal direction** that helps your chat companion find the most correct guess and phrase it the best way.

Principle 2: Get Specific

Pretend youâ€™re writing a law thatâ€™s going to be judged by the Supreme Court of the United States. You know what they look for: narrow tailoring.

**Keep things on track and stay focused.** Try to avoid prompting outside the specific request. Youâ€™ll only hurt the ability of the chat AI to give you a quality response. Odds are theyâ€™ll even skip over parts if you confuse them with too many requests.

It runs parallel with context. *If you set ChatGPT up in a room and then tell it to focus on describing the chair first, youâ€™ll see better results.*

**Instead of:** â€œIâ€™m going to a job interview. Write five questions for me to answer. Add tips for how to not get nervous before the interview. Do not create questions asking about my background.â€

**Try:** â€œYouâ€™re interviewing a software engineer. Create five questions to ask them to understand their skill set and qualifications better.â€

Nothing limits the number of prompts you can do. Focus and expand from the initial request and try not to do everything at once.

Principle 3: When in Doubt: â€œLetâ€™s take this step-by-step.â€

Welcome. **You discovered the magic word today.** This phrase slows everything down for the AI and gets you where you need to go.

You donâ€™t need to start with this phrase. Using it tells ChatGPT to show their work.

Weâ€™ll explain where this concept comes from further in our briefing, but hereâ€™s the TL;DR: sometimes, thereâ€™s a part of our prompt itâ€™s not identified correctly. â€œLetâ€™s take this step-by-step,â€ reminds you and ChatGPT to **slow down and get specific.**

If you learn to utilize this phrase more often and find ways to make it work for you, youâ€™ll become a better prompt engineer. One term can do a lot of heavy lifting.

**Pro-tip:** Weâ€™ve shown you â€œstandardâ€ prompts in all these examples. Many prompt engineers will use â€œStandard QA formâ€ prompts. Hereâ€™s our example for this principle written that way.

**Example:**

*â€œQ: The Industrial Revolution rapidly changed the infrastructure in London. Describe three essential innovations from this period and connect them to Landonâ€™s development.*

*A: Letâ€™s take this step-by-step.â€*

Even without our magic word, this style of standard prompting is quite helpful to adopt.

*However, weâ€™re beginning to stumble into the advanced tactics used in prompt engineering, so itâ€™s time for a new section.*

UNIQUE WAYS TO PROMPT

Letâ€™s preface this: we can go super deep here. Prompt engineering is changing daily, and as these models get more sophisticated, the need to adapt prompts strengthens.

To keep things clean, I will go through these using our metaphor from earlier. **Letâ€™s pretend ChatGPT is a super-intelligent toddler.**

*Got it? With that buy-in, we can continue.*

1/ Role Prompting

Weâ€™ll start with a popular tactic. **Our toddler is great at imagining things.** You tell them theyâ€™re a fireman, and suddenly they can give you detailed ways to ensure your apartment is up to code. Role-playing is a fun, easy way to build context.

The best part of role prompting is how easy it is to understand and use. All you need to do is tell ChatGPT to play a role. From there, the AI will do its best to fill the part *like that enthusiastic drama student from your old high school.*

You can even take this a step further. **Try framing your prompt as a script.** Tell the LLM specific instructions around a scene that gives you the answer to your question.

TRY IT OUT FOR YOURSELF:

Copy this prompt into ChatGPT and find a destination!

â€œAct as a travel guide. I will tell you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion: \[fill it in\]â€

Why would you take that extra step? While popular, role prompting does not necessarily improve accuracy. *You can tell your five-year-old theyâ€™re a mathematician, and theyâ€™ll still manage to screw things up.*

Letâ€™s get deeper.

2/ Chain-of-Thought Prompting

Thereâ€™s a scene in ***Guardians of the Galaxy*** where Rocket Raccoon is trying to [teach young Groot](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3lvdXR1LmJlL0hyaW1mZ2pmNGs4IiwicG9zdF9pZCI6ImM0ODlmMzhkLTY3NDAtNGRmNS05MWJjLTM1ODA0YTVmNTZkMiIsInB1YmxpY2F0aW9uX2lkIjoiNjNkODQ2ZGUtZDFiZi00ZTVjLWJjYzgtOWMxYzlkMWIxMjA0IiwidmlzaXRfdG9rZW4iOiJkZWRiNmMyNy1hYmM0LTQ5ZDUtYWM2Ny04OTcyZmM1MGVmM2QiLCJpYXQiOjE2NzY5MTkwNjguMTUyLCJpc3MiOiJvcmNoaWQifQ.5eZkDLGRLCXXYv32FYT7kLSbdRK5OK1iemTRf3HVmJw)

how to activate a complicated device. Thatâ€™s chain-of-thought prompting.

**You take an example question and answer it for ChatGPT.** Show them your chain of thought. Then you give it a new question in the same vein and ask it for an answer.

This prompt style allows you to get more specific. Youâ€™re telling your toddler theyâ€™re here to answer this particular question with one specific logic pattern.

Within this specific style is two other sub-categories. Let me give the rundown:

* Zero-shot Chain-of-Thought is â€œLetâ€™s take this step-by-stepâ€ you frame the question the same, but donâ€™t give it a precursor. Instead, you ask it to think through the points made. EX: Q: X is A. Y is B. What is C? A: Letâ€™s take this step-by-step.
* Self-consistency is using several responses to find the most accurate answer. You give ChatGPT more swings at the ball. Take the hits and discover the grouping.

TRY IT OUT FOR YOURSELF:

Copy this prompt into ChatGPT and see how accurate it is:

â€œQ: Which is a faster way to get home?

Option 1: Take an 10 minutes bus, then an 40 minute bus, and finally a 10 minute train.

Option 2: Take a 90 minutes train, then a 45 minute bike ride, and finally a 10 minute bus.

A: Option 1 will take 10+40+10 = 60 minutes.

Option 2 will take 90+45+10=145 minutes.

Since Option 1 takes 60 minutes and Option 2 takes 145 minutes, Option 1 is faster.

Q: Which is a faster way to get to work?

Option 1: Take a 1000 minute bus, then a half hour train, and finally a 10 minute bike ride.

Option 2: Take an 800 minute bus, then an hour train, and finally a 30 minute bike ride.

A: â€

[Learnprompting.org](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwOi8vTGVhcm5wcm9tcHRpbmcub3JnIiwicG9zdF9pZCI6ImM0ODlmMzhkLTY3NDAtNGRmNS05MWJjLTM1ODA0YTVmNTZkMiIsInB1YmxpY2F0aW9uX2lkIjoiNjNkODQ2ZGUtZDFiZi00ZTVjLWJjYzgtOWMxYzlkMWIxMjA0IiwidmlzaXRfdG9rZW4iOiJkZWRiNmMyNy1hYmM0LTQ5ZDUtYWM2Ny04OTcyZmM1MGVmM2QiLCJpYXQiOjE2NzY5MTkwNjguMTUyLCJpc3MiOiJvcmNoaWQifQ.-wOnVYoMNWXYrR5NOB4YYKp4Lmj-aZq3y-pr4Hou9pE)

\- by leaving the â€œA:â€ blank youâ€™re prompting ChatGPT for the answer

Alright, youâ€™re almost thereâ€”one more to go.

3/ General Knowledge Prompting

Youâ€™re going to notice a trend here. This prompt style also circles context and narrow tailoring.

All you do is tell your toddler how the world works. The cow goes moo. The dog goes woof. So what does a cat say?

Itâ€™s an oversimplification, but the core reasoning is there. Show ChatGPT some knowledge and turn that into the only focus for that chat. You can take an article from the internet and summarize it for the model. Make sure to ask if it understands and relay the information to you.

Once you know you have the attention set in the suitable space, get to work. For instance, we can share an Inclined newsletter with it and tell ChatGPT about its structure and tone.

From there, you can provide new information and tell ChatGPT to summarize it within the same structure as Inclined. You both share the same general knowledge now.

TRY IT OUT FOR YOURSELF:

Copy this prompt into ChatGPT and test it out:

â€œPrompt 1. Look over this article here: \[pick an article\]. Breakdown its structure and general tone.

Prompt 2: Recall the structure and tone you mentioned above. Take that general knowledge and summarize this article: \[pick a new one\] using the same structure and tone.â€

Note: this is a heavily simplified version of GA Prompting

Did you know some [people donâ€™t consider](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL25ld3MueWNvbWJpbmF0b3IuY29tL2l0ZW0_aWQ9MzQ0OTU0NTUiLCJwb3N0X2lkIjoiYzQ4OWYzOGQtNjc0MC00ZGY1LTkxYmMtMzU4MDRhNWY1NmQyIiwicHVibGljYXRpb25faWQiOiI2M2Q4NDZkZS1kMWJmLTRlNWMtYmNjOC05YzFjOWQxYjEyMDQiLCJ2aXNpdF90b2tlbiI6ImRlZGI2YzI3LWFiYzQtNDlkNS1hYzY3LTg5NzJmYzUwZWYzZCIsImlhdCI6MTY3NjkxOTA2OC4xNTMsImlzcyI6Im9yY2hpZCJ9.yHKIPujINT89tsqOo07AXk6OrKNgoMjO3fBEYPkAdNY)

that prompt engineering?

PROMPT CULTURE

*â€œHow can something not be prompt engineering if itâ€™s a prompt style?â€*

Good question, imaginary reader. The culture around this skill is relatively fresh. So some of **these concepts are seen as too easy** to be considered accurate prompt testing.

General knowledge prompting is simply establishing the context, and for some, thatâ€™s a baseline everyone needs to do. The same can be said for role prompting, too. *All of these tiny preferences are semantics.*

**Donâ€™t sweat whether youâ€™re a â€œrealâ€ prompt engineer.** Test this out and share your insights in these communities. The opportunity is there for you.

You may even know about DAN (weâ€™ve covered it in previous newsletters) and other AI hacking methods. Those all start with prompt engineering. You can make the case that unless the AI behaves outside its parameters, youâ€™re not genuinely doing prompt engineering.

I'm afraid I have to disagree with that, and **careers are sprouting up everywhere** that center directly on this skill. **Many require a core understanding of the prompt styles weâ€™ve discussed.**

*Yep, you can learn this and make money from talking with AI.*

Anthropic even [posted a role for a prompt engineer](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL2pvYnMubGV2ZXIuY28vQW50aHJvcGljL2UzY2RlNDgxLWQ0NDYtNDYwZi1iNTc2LTkzY2FiNjdiZDFlZCIsInBvc3RfaWQiOiJjNDg5ZjM4ZC02NzQwLTRkZjUtOTFiYy0zNTgwNGE1ZjU2ZDIiLCJwdWJsaWNhdGlvbl9pZCI6IjYzZDg0NmRlLWQxYmYtNGU1Yy1iY2M4LTljMWM5ZDFiMTIwNCIsInZpc2l0X3Rva2VuIjoiZGVkYjZjMjctYWJjNC00OWQ1LWFjNjctODk3MmZjNTBlZjNkIiwiaWF0IjoxNjc2OTE5MDY4LjE1MywiaXNzIjoib3JjaGlkIn0.4s7Htzgoxv0_qM1Ten17oQ5h0_QGM6e1fGUYz_ymgJ4)

that nets a quarter million in salary. I did not make that up and even considered sprucing up the old resume. When a new skill like this comes about, itâ€™s worth looking at.

There are many other examples like this, and OpenAI uses a red teaming strategy where their engineers attempt to prompt hack their own GPT models.

I can tell you all about the open roles here, but tomorrow the whole cycle will change. *Isnâ€™t that exciting, though?* The entire identity around prompt engineering will change by this time next year.

WHAT SHOULD YOU TAKEAWAY?

Communication is everything. **Learning to speak with AI is rising in importance.**

We all watch with mouth agape at the new wonders in AI because we know this will disrupt every industry. If any of this piqued your interest, the window to pursue it is now open. Ride that wave and [learn](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL2xlYXJucHJvbXB0aW5nLm9yZy8iLCJwb3N0X2lkIjoiYzQ4OWYzOGQtNjc0MC00ZGY1LTkxYmMtMzU4MDRhNWY1NmQyIiwicHVibGljYXRpb25faWQiOiI2M2Q4NDZkZS1kMWJmLTRlNWMtYmNjOC05YzFjOWQxYjEyMDQiLCJ2aXNpdF90b2tlbiI6ImRlZGI2YzI3LWFiYzQtNDlkNS1hYzY3LTg5NzJmYzUwZWYzZCIsImlhdCI6MTY3NjkxOTA2OC4xNTMsImlzcyI6Im9yY2hpZCJ9.a67KDSN9yQfZsaMeHpdcbSbtPjD4yFcGW4stdxBjX1M)

to become a brilliant prompt engineer.

Heck, even if you donâ€™t want to switch careers, **talking with ChatGPT and all the newest LLMs is becoming a part of our daily routine.** Get to the point where you maximize every interaction and work with these chatbots to upskill your workflow.

Prompt engineering can save you time, eliminate hassle, and even help you become a more patient person. Focus on what you want and explain it with intent.

Make magic happen, and remember: **take it step-by-step.**"
72,learnmachinelearning,gpt-3,top,2022-06-02 16:26:03,Is there a way to extract semantic relevance from BERT?,EnlightenedMod,False,0.72,3,v3cqj6,https://www.reddit.com/r/learnmachinelearning/comments/v3cqj6/is_there_a_way_to_extract_semantic_relevance_from/,0,1654187163.0,"I want to have something of a cardinality network graph of all words/tokens used to train BERT (or anything similar, ELMO, or ~~GPT-3~~) so that I can determine if 3+ parameterized words are close in contextual/proximal space to each other when considering the lexicon of the source text corpus.

Im trying to do something like this:

[https://towardsdatascience.com/populating-a-network-graph-with-words-17b6c62208ac](https://towardsdatascience.com/populating-a-network-graph-with-words-17b6c62208ac)

&#x200B;

But with a pre-trained model, to see if something like ""water"" is closer to ""fountain"" or to ""insurance"".  A top-k query instead of a correlation matrix would also be acceptable.

&#x200B;

\-some words may have been used incorrectly-

&#x200B;

&#x200B;

E: GPT-3 is a closed beta atm, disregard that one."
73,learnmachinelearning,gpt-3,top,2023-06-12 12:51:47,Fine-Tuning a pre-trained transformer model with a small dataset,Draude94,False,0.86,5,147ndpc,https://www.reddit.com/r/learnmachinelearning/comments/147ndpc/finetuning_a_pretrained_transformer_model_with_a/,0,1686574307.0,"Hi!

I want to fine-tune a transformer model (like MPT-7B, GPT-J Groovy 1.3 from GPT4All, Cerebas-GPT, Red Pajama-Incite, Open LLaMa, h20GPT - from Hugging Face) but I only have a small dataset, like arround 1500 Intents and 1-3 corresponding Utterances per Intent.

Now the questions are:

\- Can I expect good results? (like over 80-90% accuracy for my 1500 intents)

\- Should I retrain the whole network (about 7 Billion params) or just the classification layer (for e.g. 1500 params)?

I would rent some cloud computing server and build/run the code there.

Thankful for any advise!"
74,learnmachinelearning,gpt-3,top,2023-09-23 10:09:19,Looking to build an enthusiastic community for exploring AI,InterestingsBed,False,0.78,5,16q0p5g,https://www.reddit.com/r/learnmachinelearning/comments/16q0p5g/looking_to_build_an_enthusiastic_community_for/,0,1695463759.0,"(Initially I was going to write this alone but I thought it would be more interesting if I made Claude rewrite this)

I've been utterly fascinated by the recent progress in AI, especially language models like GPT-3, Stable Diffusion, and Midjourney that can generate synthetic yet coherent text, images, and more with breathtaking capability. However, I've been disappointed to notice that most people I know aren't really paying close enough attention to these advancements or reflecting deeply enough on their implications.

I'm longing to build an online community for fellow enthusiasts who share my exhilaration and concern for AI. Our goal would be to passionately explore the latest models and research, creatively share ideas for applying them, collaborate on projects, and warmly welcome newcomers. We could zealously discuss everything from using ChatGPT to write heartfelt interactive fiction or poetry, to controversially recreating deepfakes or conjuring photos from thin air, to ambitiously implementing new machine learning techniques.

While much of the mainstream discussion around AI is mired in fearmongering or hype, I'd love for this to be an open-minded place for thoughtful probing of both the promising opportunities and sobering perils of advanced AI. Whether you have a PhD in machine learning or barely grasp what a neural network is, you'd be graciously welcomed to take part in adventures of discovery, ask burning questions, and learn alongside others. My hope is to foster an inclusive environment where people feel at ease wrestling together with complex, intellectually invigorating subject matter.

If you share my passion for seeking a more systematic understanding of AI and would relish contributing to a community like this, please speak up in the comments or send me a message. Let's work together to transform this vision into reality!

TL;DR: I'm looking to build an online community for thoughtful discussion and exploration of recent AI advancements. If you share an interest in models like GPT-3 and Stable Diffusion and want to collaborate with others, let me know!

Edit: here's a discord link for those interested, I'll be posting some colab links, custom models and such if there're enough members, [https://llmops.space/discord](https://llmops.space/discord)"
75,learnmachinelearning,gpt-3,top,2023-07-03 08:48:49,Your weekly machine learning digest,Successful_Boat_3099,False,0.88,6,14pdgpm,https://www.reddit.com/r/learnmachinelearning/comments/14pdgpm/your_weekly_machine_learning_digest/,1,1688374129.0,"Hi,

Almost everyday I post on [LinkedIn](https://www.linkedin.com/in/nour-islam-mokhtari/) and [Twitter](https://twitter.com/NourIslamMo) some techniques and tools that I think could be  valuable to machine learning practitioners.

Here's a compilation of content I posted in the previous week.

Note: each day there is a new technique/tool so they're not necessarily linked.

#  Day 1:

Have you heard of LMFlow?

Itâ€™s a framework that allows you to easily finetune open source large language models on your own datasets!

Here are the key features that are supported by the toolkit:

\- Continous pretraining, instruction tuning and RLHF on user-defined datasets.  
\- Simple and extensible APIs for developers.  
\- Efficient tuning with low-rank adaptation (LoRA).  
\- A novel RLHF algorithm RAFT (Reward rAnked FineTuning) to simply RLHF pipeline for generative models.  
\- A simplified model inference framework.

Below you can see the overall system design of LMFlow.

Note: LMFlow is not to be mixed with MLFlow, which is an MLOps framework.

ðŸ‘‰ LMFlow original paper: [https://arxiv.org/pdf/2306.12420.pdf](https://arxiv.org/pdf/2306.12420.pdf)  
ðŸ‘‰ Github repo: [https://github.com/OptimalScale/LMFlow](https://github.com/OptimalScale/LMFlow)

# Day 2:

LoRA is an algorithm that helps finetune large language models quickly. So how does the algorithm work? And how does it make the training efficient?

Hereâ€™s my understanding of it.

First of all, LoRA means low-rank adaptation of large language models.

Language models like GPT-3 use a Transformer architecture which includes layers with attention and feed-forward networks. LoRA focuses on the latter: the feed-forward networks.

Let's consider just one layer of a Transformer model. The feed-forward network (FFN) can be represented as:

FFN(x) = W2 \* ReLU(W1\*x + b1) + b2

Here, x is the input, W1 and W2 are weight matrices, b1 and b2 are biases, and ReLU is the activation function.

The core idea of LoRA is to modify this FFN to have a new feed-forward network (FFN') that looks like this:

FFN\_modified(x) = (W2 + U2V2) \* ReLU((W1 + U1V1)\*x + b1) + b2

U1, U2, V1, and V2 are matrices that will be learned during adaptation.

These matrices have lower ranks than the original weights matrices W1 and W2.

This low-rank structure means that the number of parameters we need to learn during adaptation is relatively small, keeping the adaptation process efficient.

For example, if U has a shape (d,r) and V has a shape (r, d), where d is the original dimension and r is the rank of the adaptation, then the number of parameters in the low-rank matrix is 2dr.

This number of parameters can be much smaller than d\^2, the number of parameters in the original matrix W if it was to be fine-tuned.

So this is where the efficiency comes from!

During the adaptation process, we keep the original weights (W1, W2) and biases (b1, b2) fixed, and only learn the new parameters (U1, U2, V1, V2) using gradient descent on the specific task we're interested in.

ðŸ‘‰ LoRA original paper: [https://arxiv.org/pdf/2106.09685.pdf](https://arxiv.org/pdf/2106.09685.pdf)  
ðŸ‘‰ Github repo: [https://github.com/microsoft/LoRA](https://github.com/microsoft/LoRA)

# Day 3:

The data drift problem in computer vision models is a real issue. Hereâ€™s what it means and how to tackle it.

Data drift refers to the change in input data distribution over time.

In other words, it occurs when the nature of the data your model is receiving in production starts to differ from the data it was trained on.

This is a common issue in machine learning and can lead to a decrease in model performance, as the model may not have learned the appropriate patterns to handle the ""new"" kind of data.

In the context of computer vision and deep learning, this might mean changes in the types of images the model is processing.

For instance, maybe your model was trained on outdoor photos taken during the day, but over time, it starts receiving more photos taken at night.

If your model wasn't trained on night images, its performance might decline - this is an example of data drift.

Measuring data drift in computer vision involves quantifying the difference between the training data distribution and the production data distribution.  
Here are a few techniques you might use:

**Image Statistics:**

Compute basic statistics like mean and standard deviation of pixel values, color distributions, etc., on your training data and on the data the model is processing in production. Significant differences could indicate data drift.

**Pretrained Feature Extractor:**

You could use a pretrained model like a ResNet or VGG to extract features from your images. You can then compute and compare distributions of these features in the training and production data.

**Classifier Discrepancy:**

Train a binary classifier to distinguish between the training data and the new incoming data. If the classifier can easily tell the difference, it means there's a significant discrepancy, indicating data drift.

**Dimensionality Reduction and Visualization:**

Techniques like PCA or t-SNE can be used to reduce the dimensionality of your image data (or features extracted from them) to 2 or 3 dimensions, so they can be visualized. If the training data and production data form distinct clusters, it might be a sign of data drift.

ðŸ‘‰ Hereâ€™s a nice article that I found about this topic: [https://towardsdatascience.com/how-to-measure-drift-in-ml-embeddings-ee8adfe1e55e](https://towardsdatascience.com/how-to-measure-drift-in-ml-embeddings-ee8adfe1e55e)

# Day 4:

Most machine learning research is about going from mathematical modeling to ML model implementation. Hereâ€™s how to go from conditional probability to a neural architecture.

Let's start by defining a simple conditional probability problem. Consider a supervised learning task where we have input data X and target data Y, and we want to model the conditional probability P(Y | X), meaning the probability of Y given X.

A common way to model this in machine learning is to assume that this probability follows some parametric form and then use the data to estimate the parameters of this model.

For instance, we could assume that P(Y | X) is a Gaussian distribution with mean Âµ(X) and standard deviation Ïƒ(X). This mean Âµ(X) and standard deviation Ïƒ(X) could be any functions of X, but in order to learn them from data, we often assume they can be parameterized with some parameters Î¸, and are differentiable with respect to these parameters.

This is where neural networks come in. A neural network is just a function approximator that's highly flexible and differentiable, making it suitable to represent these functions Âµ(X) and Ïƒ(X).

Let's assume that our neural network is a simple feed-forward network with parameters Î¸. Then we can write our model as:  


Âµ(X; Î¸) = NN\_Âµ(X; Î¸)  
Ïƒ(X; Î¸) = NN\_Ïƒ(X; Î¸)  


P(Y | X; Î¸) = N(Y; NN\_Âµ(X; Î¸), NN\_Ïƒ(X; Î¸)\^2)  


Here, NN\_Âµ and NN\_Ïƒ are two neural networks which take the same input X and share the same parameters Î¸, and N is the Gaussian distribution. Their outputs represent the mean and standard deviation of the Gaussian distribution of Y given X.

To train this model, we would use a method called maximum likelihood estimation (MLE), which aims to find the parameters Î¸ that maximize the likelihood of the observed data.

For our Gaussian model, this corresponds to minimizing the mean squared error between Y and NN\_Âµ(X; Î¸).

Below, you can see how we might implement this in code using PyTorch.

In this code, we have a neural network that outputs two values for each input: a mean and a standard deviation. The loss function is defined as the negative log-likelihood of the Gaussian distribution, which we try to minimize using gradient descent. 

https://preview.redd.it/94qn39f8qp9b1.png?width=1766&format=png&auto=webp&s=a717f7e19e01313909382eb5e90bb46cf6105c31

 ðŸ’¡ Get technical insights just like this to help you become a better ML practitioner here: [https://aifee.co/newsletter/](https://aifee.co/newsletter/)"
76,learnmachinelearning,gpt-3,top,2022-03-24 11:47:46,Few-shot NER: entity extraction without annotation and training based on GPT,juliensalinas,False,0.75,4,tm43o9,https://www.reddit.com/r/learnmachinelearning/comments/tm43o9/fewshot_ner_entity_extraction_without_annotation/,7,1648122466.0,"Hello all,

After  1 year working extensively with GPT models (GPT-3, GPT-J, and  GPT-NeoX), I think I now have a good view on what these NLP models are  capable of. It appears that many traditional NLP tasks can  now be  achieved thanks to these large language models thanks to few-shot  learning (aka ""prompting"", or ""prompt engineering"").

NER  is a very good candidate because, thanks to these models, it is  possible to extract any type of entity without ever annotating and  training a new model. Annotation has always been a challenge that has  caused many entity extraction projects to simply fail, because it is a  long and tedious process.

In this article, I'm showing how easy it is to perform NER thanks to GPT and few-shot learning, without any annotation process: [https://nlpcloud.io/few-shot-ner-entity-extraction-without-annotation-training-based-on-gpt.html](https://nlpcloud.io/few-shot-ner-entity-extraction-without-annotation-training-based-on-gpt.html?utm_source=reddit&utm_campaign=fe5u8885-fd8e-21eb-ba80-5242ac13d5ja)

If  you also experimented with entity extraction with GPT models, I would  love to hear your thoughts. Are you, like I am, impressed by the  results? And do you think it means that annotation is a thing from the  past?

Thanks!"
77,learnmachinelearning,gpt-3,top,2022-02-23 10:54:42,Tutorial: Getting Started with OpenAI API and GPT-3,python_engineer,False,0.79,5,szeop4,https://youtu.be/Zb5Nylziu6E,0,1645613682.0,
78,learnmachinelearning,gpt-3,top,2021-04-22 20:22:21,What is the difference between GPT-2 and GPT-3? Is it just a larger dataset?,TurtletopSoftware,False,0.74,5,mwduf8,https://www.reddit.com/r/learnmachinelearning/comments/mwduf8/what_is_the_difference_between_gpt2_and_gpt3_is/,9,1619122941.0,Hard to find an answer on Google; too crowded with news stories.
79,learnmachinelearning,gpt-3,top,2020-10-07 18:25:59,Looking for a Machine Learning Engineering & DataScience Mentor/Friend!,LoveRiotYes,False,0.67,3,j6wbtw,https://www.reddit.com/r/learnmachinelearning/comments/j6wbtw/looking_for_a_machine_learning_engineering/,0,1602095159.0,"Hello friends in Machine Learning!

I would really like to form a personal relationship with someone who is also very passionate about Machine Learning Engineering and Data Science, who has industry experience, and feels comfortable sharing the process they use to create production level machine learning and cloud infrastructure solutions!

I am very interested in video chatting 1-1, for as short or as long as you want, based on the level of discussions we have! I am also open to paying you whatever is worth your time, in the event I could use some advice on a future project!

**Specifically I am looking to collaborate and learn with someone who has:**

* Built multiple, machine learning pipelines which can successfully handle very high volumes of transaction rates with high accuracy over time.

**As a bonus, I'd love to share our experiences with:**

* Getting hired in this industry, along with the jobs you that you liked the most, and why
* The most important cloud services needed to understand and build a high functioning pipeline
* The best learning sources you have found, and the best places to continually learn more about the industry and state of the art practices
* Your go-to workflow and platforms/frameworks in your current projects
* Your go-to workflow and platforms/frameworks for starting a project you may not have experience with yet
* Reinforcement learning
* Auto-ML
* Model drift, and the best practices for it
* Your best practices for working in with a team with other software devs, data scientists, data engineers and other Machine learning Engineers, writing code on a team, and working with the git protocol
* Any freelance ML projects!
* Your thoughts on NLP after OpenAI's GPT-3 model!

I have a background in engineering and successful startups, I have been teaching myself ML&DS full-time since January of 2020, I have taken multiple online courses, and am now getting to the point where I am actively interviewing for roles. Most of my experience is on AWS Sagemaker, including Autopilot, Lambda, and API Gateway. I have learned as much as possible about all the model types, and the cloud infrastructure that surrounds it. It would be very helpful to know I have a personal relationship with someone who can double check that I am on the right track when I am hired, out of mutual benefit, or payment, for my first project or two!

I look forward to meeting you, you can message me on here, and we can find a time to meetup!

The more we learn, the more people we can help!"
80,learnmachinelearning,gpt-3,top,2022-02-23 18:07:47,Lifetime Access to 170+ GPT3 Resources,bhaskar2191,False,0.62,5,sznt65,https://www.reddit.com/r/learnmachinelearning/comments/sznt65/lifetime_access_to_170_gpt3_resources/,0,1645639667.0,"Hi Makers,

Good day. Here I am with my next product.

[https://shotfox.gumroad.com/l/gpt-3resources](https://shotfox.gumroad.com/l/gpt-3resources)

For the past few months, I am working on collecting all the GPT-3 related resources, that inlcludes, tweets, github repos, articles, and much more for my next GPT-3 product idea.

By now, the resource count have reached almost 170+ and thought of putting this valuable database to public and here I am.

If you are also someone who is admirer of GPT-3 and wanted to know from its basics till where it is used in the current world, this resource database would help you a lot.

***Have categorized the resources into multiple as below:***

* Articles
* Code Generator
* Content Creation
* Design
* Fun Ideas
* Github Repos
* GPT3 Community
* Ideas
* Notable Takes
* Products
* Reasoning
* Social Media Marketing
* Text processing
* Tutorial
* Utilities
* Website Builder"
81,learnmachinelearning,gpt-3,top,2024-01-03 14:24:58,How to think about LLMs and what are the different viewpoints out there? [D],Difficult-Race-1188,False,1.0,4,18xkl72,https://www.reddit.com/r/learnmachinelearning/comments/18xkl72/how_to_think_about_llms_and_what_are_the/,0,1704291898.0,"There are primarily three sets of viewpoints about LLMs, and how to think about them.

Link to Original Article: [https://medium.com/aiguys/can-llms-really-reason-and-plan-50b0ac6addd8](https://medium.com/aiguys/can-llms-really-reason-and-plan-50b0ac6addd8)

**Position I (Skepticism):** A few scientists like Chomsky view LLMs as highly advanced statistical tools that donâ€™t equate to intelligence at all. The viewpoint is that these machines have seen so much data they can just give responses to any question we might come up with. Mathematically, they have calculated conditional probability for every possible question we can come up with.

**My viewpoint:** The flaw here might be an underestimation of the nuanced ways in which data modeling can mimic certain aspects of cognition, albeit not true understanding. How do we know even humans are not doing the same, we are constantly being fed data by our different senses. So, differentiating between understanding and mimicking an understanding might also need the development of some other type of intelligence.

**Position II (Hopeful Insight):** Ilya Sutskever (creator of ChatGPT) and Hinton seem to suggest that LLMs have developed internal models reflective of human experience. Their position is that, since the text on the internet is a representation of human thoughts and experience, and by being trained to predict the next token in this data, these models have somehow built an understanding of the human world and experience. They have become intelligent in a real sense or at least appear to be intelligent and have created world models as humans do.

**My viewpoint:** This might overstate LLMsâ€™ depth, mistaking complex data processing for genuine comprehension and overlooking the absence of conscious experience or self-awareness in these models. Also, if they have built these internal world models, then why do they fail miserably on some fairly simple tasks that should have been consistent with these internal world models?

**Position III (Pragmatism):** A lot of scientists like LeCun and Kambhampati see LLMs as powerful aids but not as entities possessing human-like intelligence or even something that is remotely close to human intelligence in terms of experience or internal world models. LLMs, while impressive in their memory and retrieval abilities, fall short in genuine reasoning and understanding. They believe that LLMs should not be anthropomorphized or mistaken for having human-like intelligence. They excel as â€œcognitive orthotics,â€ aiding in tasks like writing, but lack the deeper reasoning processes akin to humansâ€™ **System 2** thinking.

**Note:** We believe that current LLMs are System 1 intelligence, thatâ€™s why every problem takes almost the same time to be solved, be it linear, quadratic, or exponential.

LLMs resemble human System 1 (reflexive behavior) but lack a System 2 (deliberative reasoning) component. They donâ€™t have the capacity for deep, deliberative reasoning and problem-solving from first principles.

They believe that future advancements in AI will rely on fundamentally different principles, and the emergence of AGI canâ€™t be just achieved by scaling.

**My viewpoint:** This view might underestimate the potential future evolution of LLMs, especially as we move towards more integrated, multimodal AI systems. I strongly agree with a lot of the points in position III, yet I also believe in internal world models.

# A more comprehensive and inclusive viewpoint on LLM

NOTE: ***By no means, have I captured the nuances of the above three positions. Nor do I believe that any of their position is wrong and right. With a very high probability, I believe that my own position is likely to be equally wrong and right with the above three positions.***

I believe that all three positions make some good points and I agree with a lot of points from positions 2 and 3. Letâ€™s break it down, what is likely happening in these LLMs?

As we all know NN are universal function approximators. So, we know these functions are indeed trying to model the world (assuming the real world has some function).

Now the problem is that there are different types of data distributions, some are easy and some are complex. For instance, the research in **Mechanistic Interpretability** ([**click here**](https://medium.com/aiguys/mechanistic-interpretability-for-decoding-black-box-ai-11bb47f421b1) to know more on this topic) has revealed that models can learn mathematical algorithms.

But that doesnâ€™t mean that models can learn all the underlying structures, sometimes they are just answering the stuff from memorization.

There is a concept called **Grokking**, it is defined as the network going from memorizing everything to generalizing. A sudden jump in test accuracy is the sign where the model groks. When you train a network, your train loss keeps decreasing constantly, but the test loss doesnâ€™t. But somewhere down the line, it decreases exponentially, and thatâ€™s when the model goes from **memorization to generalization**.

So, I believe that these LLMs are part memorization and part generalization. Now the concepts that are simple and have clear data distributions, LLMs will pick those structures and will create an internal model of those.

But I canâ€™t say with confidence that the internal world model is good enough to create intelligence. Now when we ask questions from that world model, the model appears to get everything correct and even shows generalization capabilities, but what happens when it is asked questions from different views and perspectives, it fails completely, something revealed in a paper called [**LLM reversal curse**](https://medium.com/aiguys/paper-review-llm-reversal-curse-41545faf15f4)**.**

The way I think about this is: that a biologist can explain the cells and structure of a flower, but can never describe its beauty, but a poet can describe its essence. Meaning, a lot of human experiences are so visceral, that they are not just a mapping problem. Most neural networks are just mapping one set of information to another.

Letâ€™s summarize how I think about the human brain and LLM. Human brain has different concepts and experiences turned into the internal world model. These internal models have both abstractions and memory. Now we have many such internal world models, and the way we make sense of the world is to have consistency in these world models within themselves, more importantly, we should be able to navigate from one model to another, and thatâ€™s the conscious experience of the human mind, asking the right questions to reach different world models. Human mind can automatically activate and deactivate these internal world models and look at other internal models in combination with the generalization of other models.

As far as LLMs are concerned, first and foremost, they might have world models for a few concepts that has a good data distribution. And for a lot of these internal world models, it might completely rely on memorization rather than generalization. But more importantly, it still doesnâ€™t know how to move from one internal world model to the other or use the abstraction of other internal world models to analyze the present internal world model. The conscious experience of guiding intelligence to ask the right question to analyze something in detail and use **system 2 intelligence** is completely missing. And I do believe that it is not going to be solved by the **Neural scaling law**. All scaling will most likely do is create a few more internal models that rely more on generalization and less on memorization.

But the bigger the size of the models, the less we know whether it is responding out of memorization or generalization.

So, in short, LLMs donâ€™t have any mechanism to know what question to ask and when to ask.

Thanks"
82,learnmachinelearning,gpt-3,top,2022-07-19 19:21:10,AI Content Generation with BLOOM Hugging Face - Free GPT-3 Alternative,dulldata,False,1.0,4,w30ztw,https://www.youtube.com/watch?v=ZHx0TsYB3ac,0,1658258470.0,
83,learnmachinelearning,gpt-3,top,2023-11-08 16:56:45,[P] Top 5 AI Announcements (and Implications) from the 1st OpenAI DevDay,vykthur,False,0.83,4,17qq0z9,https://www.reddit.com/r/learnmachinelearning/comments/17qq0z9/p_top_5_ai_announcements_and_implications_from/,0,1699462605.0,"OpenAI recently had the first   developer day, featuring several new announcements

https://preview.redd.it/ep1scxynm5zb1.png?width=1456&format=png&auto=webp&s=4be58601b9a0fb9bcc1ff17d25560257f895dca2

&#x200B;

Full post here: [https://newsletter.victordibia.com/p/top-5-ai-announcements-and-implications](https://newsletter.victordibia.com/p/top-5-ai-announcements-and-implications) 

TLDR.

* **ðŸ’°ðŸ“‰ Cost Reduction**: The new GPT-4 and GPT-3.5 Turbo models are more capable yet cost less. ðŸ¤¯ðŸ¤¯.
* **ðŸ“ˆðŸ§  Improved Model Capabilities**: GPT-4 now includes a 128K token version (300 pages of text), features an updated knowledge cutoff (previously April 2021, now April 2023), and offers improved function calling.
* **ðŸŽ›ï¸ðŸ”§ Improved Model Control**: The new model series can generate valid JSON-formatted responses using a \`response\_format\` parameter and supports reproducible results through a seed parameter. Additionally, there is upcoming support for accessing log probabilities of generated tokens.
* **ðŸ¤–ðŸ”—Agents: The Assistant API**: This API supports the **creation of agents** that can utilize external knowledge (RAG), **act** via tools (e.g., code execution and function calling), and maintain infinitely long conversations through Threads. All of this in a unified api for building agents.
* **ðŸ¤–ðŸ›ï¸Agents: GPTAgents and Agent Store**: OpenAI will create a store where developers can bundle and share GPT agents with some revenue sharing. An Agent here is an LLM+Knowledge+Tools. 

&#x200B;

**High Level Implications** 

\- Cost reductions could make these models more practical to use (cost competitive with running smaller models at scale). 

&#x200B;

[Pricing of OpenAI models show cost reductions in successive GPT models from March - Nov 2023 . Davinci Source https:\/\/openai.com\/pricing](https://preview.redd.it/hfvytscem5zb1.png?width=1456&format=png&auto=webp&s=516a263a9b98165043c7b41946b70cce791cc861)

&#x200B;

&#x200B;

https://preview.redd.it/skio4eohm5zb1.png?width=1196&format=png&auto=webp&s=57299651d05a9469a90506e0b4724649c834b6ed

\- The Assistant API facilitates prototyping complex agent workflows, eliminating the extensive infrastructure work that was previously burdensome, such as implementing a RAG workflow, managing long conversation contexts, and executing code.

\- The capability to generate output constrained to a valid JSON format, the option to set a seed for reproducibility, and access to log probabilities are significant steps toward addressing **reliability issues** with large language models (LLMs).

While some of the ideas introduced may not be entirely new, they certainly represent significant quality-of-life improvements for engineers attempting to build Generative AI apps."
84,learnmachinelearning,gpt-3,top,2020-06-10 21:02:43,"GPT-3: Explaining the $4,600,000 Neural Network from OpenAI",mippie_moe,False,0.83,4,h0k5xn,https://lambdalabs.com/blog/demystifying-gpt-3/,0,1591822963.0,
85,learnmachinelearning,gpt-3,top,2023-06-22 23:53:45,What is a policy in Reinforcement Learning (ChatGPT)?,u2uu,False,1.0,4,14gj3fq,https://www.reddit.com/r/learnmachinelearning/comments/14gj3fq/what_is_a_policy_in_reinforcement_learning_chatgpt/,6,1687478025.0,"Hey,

i read about the RLHF in ChatGPT. And in Step 1 there is the title saying: ""training a supervised policy"".

And in step 3 is it then saying: ""The PPO model is initalized from the supervised policy.""

I really dont understand exactly what is meant with policy. It is the neural network itself of the LLM? Is ist the SFT Model from Step 1? 

And if the ""PPO-Model is initalized"" is this in the beginning exactly like the SFT-Model from step 1? 

I read a lot about ""functions"" regarding to ""policy"". But sometimes i read that the policy is a neural network. So i am really confused. Is the policy a seperate entity? Is it not the neural network of the LLM itself?


I am sorry for my english. I would be very happy for help!"
86,learnmachinelearning,gpt-3,top,2020-09-10 16:32:54,GPT2/GPT3 Text rewriting,MidnightRambo,False,1.0,4,iq6sp8,https://www.reddit.com/r/learnmachinelearning/comments/iq6sp8/gpt2gpt3_text_rewriting/,2,1599755574.0,"Hey there, 

I just wanted to know if anyone of you tried GPT2 to rewrite Texts using The GPT-Ai? 

The fact is that inwanted to help small journalists who want to report some small (more or less unnecesarry) news but donâ€˜t want to copy texts from other sites. Therefore i thought it would be cool if i can create something so that people â€žinputâ€œ 3-5 textes and the ai would create just one out of them. 

Has anyone of you tried something similar?"
87,learnmachinelearning,gpt-3,top,2023-07-10 15:16:24,"ChatPDF: What ChatGPT Can't Do, This Can!",JunXiangLin,False,0.7,4,14vww3o,https://www.reddit.com/r/learnmachinelearning/comments/14vww3o/chatpdf_what_chatgpt_cant_do_this_can/,7,1689002184.0,"Believe many of people have been using **ChatGPT** for a while, and you are aware that although ChatGPT is powerful, it has the following limitations:

1. Unable to answer questions about events that occurred after **2021**.
2. Unable to directly upload your own data, such as **PDF, Excel, databases**, etc.
3. Inaccurate in performing **mathematical calculations**.

**Langchain** is a recent trending open-source project, which is a framework for developing Large Language Models (LLMs) applications. It supports the following:

1. Connecting LLM models with **external data sources**, such as PDF, Excel, databases, etc.
2. Allowing interaction between LLM models and other tools, such as **Google search**, enabling internet connectivity.
3. Rapid development of LLM model applications.

Today, I'd like to share a project called **ChatPDF**(strickly called **docGPT**, there're some different), built using the Langchain framework. It allows users to upload local documents and ask questions to the LLM model. In this tool, you can ask AI to summarize articles or inquire about any information in the document. Moreover, by leveraging the Langchain Agent functionality, the LLM model can collaborate with the Google Search API, enabling users to ask questions about current topics!

The project provides a detailed guide on how to create your own **docGPT**. It is built using the Langchain framework and Python Streamlit, which is a free and fast way to create online services. As long as you have an OPENAI API KEY, feel free to give it a try!

I encourage everyone to pay attention to the [Langchain open-source project](https://github.com/hwchase17/langchain) and leverage it to achieve tasks that ChatGPT cannot handle.

[Github Repository](https://github.com/Lin-jun-xiang/docGPT-streamlit/tree/main)

[ChatPDF Application](https://docgpt-app.streamlit.app/)

&#x200B;

https://preview.redd.it/q906a7imm5bb1.png?width=2560&format=png&auto=webp&s=acef45049bab805038f876eea56cc371b8a9a83a"
88,learnmachinelearning,gpt-3,top,2023-04-12 23:00:52,Fine Tuning ChatGPT on Full Documents?,Simusid,False,0.76,4,12k2vyt,https://www.reddit.com/r/learnmachinelearning/comments/12k2vyt/fine_tuning_chatgpt_on_full_documents/,1,1681340452.0,"I want to fine tune GPT-3 using internal corporate documents.   They are mostly paragraphs of text.   Each paragraph might have 5 or 6 sentences.  Per the API, I have to provide prompt/completion pairs in the format:

{""prompt"": ""<prompt text>"", ""completion"": ""<ideal generated text>""}

If a paragraph consists of <sentence1><sentence2><sentence3>....<sentenceN> does it make sense to build the pairs as:

{""prompt"": ""<sentence1>"", ""completion"": ""<sentence2>""}

{""prompt"": ""<sentence2>"", ""completion"": ""<sentence3>""}

{""prompt"": ""<sentenceN-1>"", ""completion"": ""<sentenceN>""}"
89,learnmachinelearning,gpt-3,top,2021-02-25 05:36:31,[N] New Contextual Calibration Method Boosts GPT-3 Accuracy Up to 30%,rockyrey_w,False,1.0,4,lrza1i,https://www.reddit.com/r/learnmachinelearning/comments/lrza1i/n_new_contextual_calibration_method_boosts_gpt3/,0,1614231391.0,"A research team from UC Berkeley, University of Maryland and UC Irvine identifies pitfalls that cause instability in the GPT-3 language model and proposes a contextual calibration procedure that improves accuracy by up to 30 percent.

Here is a quick read: [New Contextual Calibration Method Boosts GPT-3 Accuracy Up to 30%](https://syncedreview.com/2021/02/24/new-contextual-calibration-method-boosts-gpt-3-accuracy-up-to-30/)

The paper *Calibrate Before Use: Improving Few-Shot Performance of Language Models* is on [arXiv](https://arxiv.org/pdf/2102.09690.pdf)."
90,learnmachinelearning,gpt-3,top,2022-02-17 01:37:41,Relative Position Representation/Encoding for Transformer,promach,False,0.84,4,sucf7q,https://www.reddit.com/r/learnmachinelearning/comments/sucf7q/relative_position_representationencoding_for/,1,1645061861.0,"1. In [GPT-NeoX-20B: An Open-Source Autoregressive Language Model](http://eaidata.bmk.sh/data/GPT_NeoX_20B.pdf#page=2) paper, why did [the author](https://blog.eleuther.ai/rotary-embeddings/) stated that **Rotary embeddings are a form of static relative positional embeddings** ?
2. In [https://medium.com/@\_init\_/how-self-attention-with-relative-position-representations-works-28173b8c245a](https://medium.com/@_init_/how-self-attention-with-relative-position-representations-works-28173b8c245a) , could anyone explain the rationale behind **the value of the lookup indices after the 3rd element are all 6** ?
3. What is the actual purpose of [skewing mechanism](https://jaketae.github.io/study/relative-positional-encoding/) ?  The [explanation inside music transformer paper](https://arxiv.org/pdf/1809.04281.pdf#page=5) is confusing.
4. In the [video about self-attention with relative positional representations](https://youtu.be/DwaBQbqh5aE?t=441) , I am bit confused as in **where** in the equations that the author added the extra `Î±` (relative positional embedding) highlighted in red color.

[Q2](https://preview.redd.it/cw74enkurai81.png?width=711&format=png&auto=webp&s=a670532f611c0196ba5adc8eafe2b586ac2f1448)

[Q3](https://preview.redd.it/ty74fr278ci81.png?width=1738&format=png&auto=webp&s=2e871d659f218ea3a53d4eab4cc8e5c8ad711cb3)

[Q4a](https://preview.redd.it/6svjlzfjbwi81.png?width=1920&format=png&auto=webp&s=aaed0542570ab6b3a1e636543b96c636fc324904)

[Q4b](https://preview.redd.it/2efdul8ybwi81.png?width=600&format=png&auto=webp&s=027956d72b2190ebc98b61396609492cf7ee1491)"
91,learnmachinelearning,gpt-3,top,2023-09-28 19:09:13,[D] Convert specific domain knowledge text to a knowledge graph,3Ammar404,False,0.84,4,16uolgn,https://www.reddit.com/r/learnmachinelearning/comments/16uolgn/d_convert_specific_domain_knowledge_text_to_a/,3,1695928153.0,"Hi Guys,

As part of this semester assignment , I'm working on a project that aims to to represent the knowledge in ""PMBOK 6th edition, section 11: Project Risk Management (page 395 -> 458)""  and the knowledge in ""PMI standard for Risk Management "" (128 pages) as a knowledge graph. The generated knowledge graph will be used later to build recommendation system to infer real-time personalized recommendations.

I have been reading on how to convert unstructured text into a knowledge graph  in research papers and  articles and I have found mainly 3 ways to do this:  
1/ Using a joint of  *Named-entity recognition* (*NER*) and Relation Extraction (RE) to extract the entities and the relations from your unstructured text.     
2/ taking advantage of the linguistic knowledge of Transformer models and fine tune a transformer model (BERT, T5)  for the task of extracting entities and relations. I could find some pretrained models like REBEL :[https://github.com/Babelscape/rebel](https://github.com/Babelscape/rebel).

3/ use prompt engineering  (LLM (GPT)) to generate the knowledge graph.  


I could not find any of the three approaches as good as I wanted: 

1/ The majority of the resources I have found that tackles the first approach (NER & RE)  showcase simple tasks where the named entities and  relations are very straightforward. Example this article here: [https://freedium.cfd/https://medium.com/mlearning-ai/building-a-knowledge-graph-for-job-search-using-bert-transformer-8677c8b3a2e7](https://freedium.cfd/https://medium.com/mlearning-ai/building-a-knowledge-graph-for-job-search-using-bert-transformer-8677c8b3a2e7)  where the entities are \[skills, Diploma, Major, Year of experience\] and the relations \[DEGREE\_IN, EXPERIENCE\_IN..\]. In this case, training  NER and RE models will be easy. But in my case, determining entities and relations is very complex. Annotating the corpus manually is incredibly tedious and labor-intensive (Could not even determine what are the entities and the relations) . You can grab a feeling of how complex it is by looking at how big our dataset is (191 pages of knowledge) and how complex the knowledge is in the corpus (many definitions, a lot of terminology...)

2/ I have used the pretrained REBEL model but  the results looked weird. (redundant relations, sometimes the extracted relations make non sense). And So I wanted to fine tune BERT for this specific task on my custom data (PMBOK, PMI) but I really could not understand how to do this   (what should be the data format to train and test the transformer model?, how to evaluate the model ?...)

3/ The fact that LLM are stochastic models,  a lot of variations in the generated graphs for each prompt (sometimes huge differences)  and this lead to huge ambiguity because I cannot evaluate how good the graph is in representing the knowledge.

I'm open to any  other resources and any other inspirations or approaches to tackle this project. Thank you in advance."
92,learnmachinelearning,gpt-3,top,2020-07-27 17:01:22,Crazy GPT-3 Use Cases,przemekc,False,1.0,4,hyw5cc,https://www.youtube.com/watch?v=tsuxlU5IwuA,0,1595869282.0,
93,learnmachinelearning,gpt-3,top,2020-08-11 17:18:25,Could GPT-3 translate keras to pytorch?,phobrain,False,0.71,4,i7vt7p,https://www.reddit.com/r/learnmachinelearning/comments/i7vt7p/could_gpt3_translate_keras_to_pytorch/,2,1597166305.0,"Feed it your keras program, type 'translated to pytorch, that would be:"" - and no more memory leaks!

Plausible?"
94,learnmachinelearning,gpt-3,top,2022-04-19 22:19:10,Hands on ML vs Deeplearning.ai vs Fast ai for DL,ash9e,False,0.81,3,u7h508,https://www.reddit.com/r/learnmachinelearning/comments/u7h508/hands_on_ml_vs_deeplearningai_vs_fast_ai_for_dl/,3,1650406750.0,"Hi,

I am close to completing Andrew Ngâ€™s ML course and have been thinking about next steps.
I was wondering whether for deep learning I should just read hands on ml, do the deeplearning.ai specialization on coursera or do the fastai course?

I in any case want to do Hands on ml for the ML parts since I feel itâ€™s a great resource for learning how to use ml algos also covers a lot of ML topics not covered in Andrew Ng's course. Just not sure if I should try and do deeplearning specialization and Hands on ML in 6 months.

My aim is to get to a point in 6 months where I can start using ML for some of my non-production work (we donâ€™t have ML engineers and are a small company) and more importantly start using Bert and GPT-3 models as well."
95,learnmachinelearning,gpt-3,top,2020-12-03 16:32:46,"Blog post ""interpreting GPT: the logit lens"" demonstrates GPT-2's most probable next output token at each of its 48 layers. An interactive notebook is included for experimentation.",Wiskkey,False,1.0,4,k60jix,https://www.reddit.com/r/learnmachinelearning/comments/k60jix/blog_post_interpreting_gpt_the_logit_lens/,0,1607013166.0,"Blog post: [interpreting GPT: the logit lens](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens)

>This post relates an observation I've made in my work with GPT-2, which I have not seen made elsewhere.  
>  
>IMO, this observation sheds a good deal of light on how the GPT-2/3/etc models (hereafter just ""GPT"") work internally.

&#x200B;

>GPT's probabilistic predictions are a linear function of the activations in its final layer. If one applies the same function to the activations of intermediate GPT layers, the resulting distributions make intuitive sense.

I am not the author of the blog post.

The GPT-2 model used is the \~1.5 billion parameter model, which has 48 layers. The input used is specified in the interactive notebook, and doesn't depend on GPT-2's calculations for the next output token.

Example: I modified the interactive notebook to use the following as the input:

>input:ostrich. output:I am an ostrich. input:lion. output:I am a lion. input:elephant. output:I am an elephant. input:cougar. output:I am a cougar. input:owl. output:I am an owl.

The last part of the input is the input segment shown in the following images, which were generated by the interactive notebook. To make the images smaller, only 25 of the 48 layers are shown. Site [https://bellard.org/textsynth/](https://bellard.org/textsynth/) with defaults changed to Model=large and top-k=1 can be used to verify that the most probable next output token matches that given in the images below.

&#x200B;

https://preview.redd.it/8ppoek5ttz261.png?width=881&format=png&auto=webp&s=ac87d1daa88d2ce20c740d5b3e7edbc786944f55

&#x200B;

https://preview.redd.it/knmhd52wtz261.png?width=873&format=png&auto=webp&s=40e971163a2aaceee93ffb0ffb4c791bd3544ace

&#x200B;

https://preview.redd.it/3vczc0txtz261.png?width=882&format=png&auto=webp&s=79c2fdd1639ac70fe0bfa86bbe88632991b1c001

&#x200B;

https://preview.redd.it/ly1q3ce3uz261.png?width=882&format=png&auto=webp&s=7da346b310348836514e5e2e28a5299c01f6949c

&#x200B;

https://preview.redd.it/8polqsl5uz261.png?width=879&format=png&auto=webp&s=017ea3fee437068d9643b0ba5a60994b55d8de1f

&#x200B;

https://preview.redd.it/enw0l907uz261.png?width=497&format=png&auto=webp&s=6f923034cd2e0906d4e5b981fe8aaab7861993da"
96,learnmachinelearning,gpt-3,top,2023-10-31 18:29:19,What is the 'unnormalized logits' in an RNN?,causeofyourEuphoria,False,0.86,5,17krsye,https://www.reddit.com/r/learnmachinelearning/comments/17krsye/what_is_the_unnormalized_logits_in_an_rnn/,3,1698776959.0,"I am a complete beginner to ML and currently studying RNN.  I was trying to draw a diagram to explain to myself how the RNN worked. So the diagram shows a vanilla RNN which was unrolled 3 times, which has sigmoid function at the out put layer. can someone confirm if this diagram is right or wrong?

&#x200B;

https://preview.redd.it/hk5xxfsxzkxb1.jpg?width=1280&format=pjpg&auto=webp&s=848554268a0e9bd2915c01a7da533acffd56513e

Also I was trying to check whether this is correct using chatGPT and got this answer:  


https://preview.redd.it/b0tgk7fdykxb1.png?width=701&format=png&auto=webp&s=281c84756e00b1e65b1e22d0a7c1a8c6b6eed6c1

Can someone confirm what it means by unnormalized logits? If you can point me to a relevant resource, that would be cool too"
97,learnmachinelearning,gpt-3,top,2023-11-27 14:01:11,Are SOTA LLMs(LMMs?) going to be much smaller in the future?,open_23,False,0.83,4,1853m18,https://www.reddit.com/r/learnmachinelearning/comments/1853m18/are_sota_llmslmms_going_to_be_much_smaller_in_the/,8,1701093671.0,"Since most LLMs these days are becoming multi-modal, with capabilities to browse the web and parse information from given files, will they become much smaller as they'll need to be trained on less data?

Models like GPT-3, which has 175B parameters, are that big because they are trained on a ton of information from the internet which they can retrieve from their data for the user. Thats why GPT-4 is so useful, because it is trained on so many things, it can help on a wide range of topics.

But, now that GPT-4 has plugins, and also the ability to browse the web, will it need to be trained on so much data. If the user needs help on a particular topic, it can just search the web for the information and then present it to the user. I t would save a lot of training time and data.

For the purposes of it just being able to speak English correctly, it needs relatively little data. The TinyStories models, with 10-30M parameters, perform pretty decently as a LM. It only neededsimple english vocabulary to learn to speak it properly. So, in the future, will we see base SOTA models be 7-13B with multimodal vision, voice, file parsing, and most importantly, web browsing capabilities, which will perform as good as today's GPT-4?"
98,learnmachinelearning,gpt-3,top,2021-11-23 07:08:32,Tutorial: Deploy GPT-J 6B (equivalent of GPT-3 Curie) for inference using FastAPI,Tensorbox_AI,False,0.81,3,r07hfw,https://www.reddit.com/r/learnmachinelearning/comments/r07hfw/tutorial_deploy_gptj_6b_equivalent_of_gpt3_curie/,1,1637651312.0,"Hi everyone, I've created a quick tutorial on how to deploy GPT-J 6B (the HuggingFace version) for inference using FastAPI: [https://www.tensorbox.ai/gpt-j-api](https://www.tensorbox.ai/gpt-j-api?fbclid=IwAR0cxawF4RJctoTaqAM2yQTi2aMGJRyJMi5TCnlcx_f4wttl0DrREPHNcoI) .

Please, let me know what you think. The main difficulty here is making sure it fits into the smallest G4dn instance to save on costs while running the server."
99,learnmachinelearning,gpt-3,top,2021-05-09 04:24:47,Learn how to implement and train a GPT-3 like model with only a few lines of code (GPT-Neo),VennifyAI,False,0.85,5,n86duv,https://www.youtube.com/watch?v=GzHJ3NUVtV4,1,1620534287.0,
100,learnmachinelearning,gpt-3,comments,2023-12-17 13:15:47,I can't stop using ChatGPT and I hate it.,t0hli,False,0.64,26,18kh4n5,https://www.reddit.com/r/learnmachinelearning/comments/18kh4n5/i_cant_stop_using_chatgpt_and_i_hate_it/,108,1702818947.0,"I'm trying to learn various topics like Machine Learning and Robotics etc., and I'm kinda a beginner in programming.

For any topic and any language, my first instinct is to

1. go to ChatGPT,
2. write down whatever I need my code to do,
3. copy paste the code
4. if it doesn't give out good results, ask ChatGPT to fix whatever it's done wrong
5. repeat until I get satisfactory result

I hate it, but I don't know what else to do.

I think of asking Google what to do, but then I won't get the exact answer I'm looking for, so I go back to ChatGPT so I can get exactly what I want. I don't fully understand what the GPT code does, I get the general gist of it and say ""Yeah that's what I would do, makes sense"", but that's it.

If I tried to code whatever GPT printed out, I wouldn't get anywhere.

I know I need to be coding more, but I have no idea where to start from, and why I need to code when ChatGPT can do it for me anyway. I'm not defending this idea, I'm just trying to figure out how I can code myself.

I'd appreciate your thoughts and feedback."
101,learnmachinelearning,gpt-3,comments,2022-11-07 14:11:49,Been learning ML since the start of the year and built a tool with GPT-3 that letâ€™s anyone self-serve their own data questions and create graphs and dashboards,BuggerinoKripperino,False,0.98,466,yoo3ba,https://v.redd.it/n0vjjvr8ejy91,64,1667830309.0,
102,learnmachinelearning,gpt-3,comments,2021-06-29 13:07:05,"Started learning ML 14 months ago, now I'm using GPT-3 to automate CVs!",Camjw1123,False,0.97,751,oa7x3p,https://gfycat.com/ambitioushauntingagama,53,1624972025.0,
103,learnmachinelearning,gpt-3,comments,2023-01-19 07:56:20,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.96,334,10fw2df,https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/,47,1674114980.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. Thatâ€™s a *trillion* with a â€œtâ€.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAIâ€™s new brainchild will certainly be mind-bending and language models have been getting bigger â€” fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Letâ€™s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): â€œFrom talking to OpenAI, GPT-4 will be about 100 trillion parametersâ€.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But thereâ€™s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the communityâ€™s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: â€œScaling Laws For Neural Language Modelsâ€.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMindâ€™s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): â€œTraining Compute-Optimal Large Language Modelsâ€

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* â€‹[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the railsâ€‹

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** â­•.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,â€¦ & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
104,learnmachinelearning,gpt-3,comments,2023-12-26 07:39:32,Can you guess who wrote this code ? A Developer or a Researcher/Scientist,Left_Papaya_9750,False,0.86,40,18r2vqv,https://www.reddit.com/r/learnmachinelearning/comments/18r2vqv/can_you_guess_who_wrote_this_code_a_developer_or/,47,1703576372.0,"    import torch 
    from torch.optim.lr_scheduler import CosineAnnealingLR
    from gpt import GPTLanguageModel
    from transformers import GPT2Tokenizer
    from tqdm import tqdm
    from utils.draw_plots import Draw
    import pynvml as nvml
    import os
    import time
    import wandb
    from utils import draw_stuff
    from torch.utils.data import DataLoader, SubsetRandomSampler
    from utils.load_data import LoadDataset
    import signal 
    from colorama import Fore
    from queue import Queue
    
    class Train():
        def __init__(self, **kwargs,):
            torch.manual_seed(1137)
            model= GPTLanguageModel()
            gpu_idx= 0 if not 'gpu_index' in kwargs else kwargs['gpu_index']
            nvml.nvmlInit()
            os.system(""cls"" if os.name == 'nt' else 'clear')
            draw_stuff.draw()
            self.enc= GPT2Tokenizer.from_pretrained('gpt2')
            self.device='cuda' if torch.cuda.is_available else 'cpu'
            self.m= model.to(self.device)
            self.block_size= 256 if not 'block_size' in kwargs else kwargs['block_size']
            self.batch_size= 100 if not 'batch_size' in kwargs else kwargs['batch_size']
            self.handle= nvml.nvmlDeviceGetHandleByIndex(gpu_idx)
            self.temp_thres= 85 if not 'temp_threshold' in kwargs else kwargs['temp_threshold']
            self.plot= Draw()
            
        def load_data(self,split, split_per):
            dataset= LoadDataset(split= split, split_per=split_per)
            sampler= SubsetRandomSampler(torch.randint(high=len(dataset), size=(1000,)).tolist())
            data_title= DataLoader(dataset, pin_memory= True, sampler=sampler, drop_last=True)
            return data_title
    
        @torch.no_grad()
        def estimate_loss(self, eval_iters)->torch.tensor:
            out = {}
            print(""Estimating loss\n"")
            self.m.eval()
            for split in ['train', 'val']:
                es_progress= tqdm(total=eval_iters, ncols=100)
                es_progress.colour='red'
                
                losses = torch.zeros(eval_iters)
                for k in range(eval_iters):
                    es_progress.update(1)
                    for X, Y in self.get_batch(split):
                        logits, loss = self.m(X, Y)
                        losses[k] = loss.item()
                out[split] = losses.mean()
            self.m.train()
            return out
        
        def get_batch(self, split):
            data = self.load_data(split, split_per=0.8)
            for idx, data in enumerate(data):
                doc= data
                doc_txt= doc['text'][0]
                title= doc['title'][0]
                encoded_tok= self.enc.encode(doc_txt, add_special_tokens= True)
                doc_txt_enc= torch.tensor(encoded_tok, dtype=torch.long)
                size= self.block_size
                if len(encoded_tok) - self.block_size <= 0 and len(encoded_tok)-20 >=3:
                    size=20
                ix = torch.randint(len(encoded_tok) - size , (self.batch_size,))
                x = torch.stack([doc_txt_enc[i:i+size] for i in ix]).to(self.device) 
                y = torch.stack([doc_txt_enc[i:i+size+1] for i in ix]).to(self.device) 
                yield x, y
                
    
        def display_train_params(self,train_id, device, **kwargs):
            print(f""**NOTE: GPU temperature threshold has been set to {self.temp_thres}Â°C, when the threshold is reached the training process will halt for a set period.**\n"")
            print(f""INFO {torch.cuda.memory_allocated(device)} Bytes of memory is allocated for this task\n"")
            print(f""""""Training parameters:
                      Device: {nvml.nvmlDeviceGetName(self.handle)}
                      Halt Temperature threshold:{self.temp_thres}
                      Trainable Parameters: {sum(p.numel() for p in self.m.parameters())/1e6, 'M parameters'}
                      Total Epochs: {kwargs['epochs']}
                      Evaluation Iterations: {kwargs['eval_iters']}
                      Evaluation Interval: {kwargs['eval_interval']}
                      Initial Learning rate: {kwargs['learning_rate']}
                      Learning Rate Schduler: Cosine Annealing
                      Total Memory allocated: {torch.cuda.memory_allocated(device)}B
                      \n"""""")
            
            print(f""** Training Started | Train ID : {train_id}**\n"")
    
        
        def train(self, device, train_id, is_save=True, **kwargs):
            
            wandb.init('Training',  
                        project='gpt-model',
                        config={
                            ""initial_learning_rate"":3e-4,
                            ""architecture"":""transformer"",
                            ""dataset"": ""Wikipedia general documents""
                                }
                        )
            docs= []
            eval_interval= 500 if not 'ei' in kwargs else kwargs['ei']
            learning_rate= 3e-4 if 'learning_rate' not in kwargs else kwargs['learning_rate']
            eval_iters= 300 if 'eval_iter' not in kwargs else kwargs['eval_iter']
            max_iters= 10000 if not 'epochs' in kwargs else kwargs['epochs']
            num_doc= 2000
            os.mkdir('results') if not 'results' in os.listdir('.') else None
            os.mkdir(f'results/{train_id}') if train_id not in os.listdir('results') else None
            os.mkdir(f'results/{train_id}/checkpoints') if 'checkpoints' not in os.listdir(f'results/{train_id}') else None
            os.mkdir(f'results/{train_id}/checkpoints/plots') if 'plots' not in os.listdir(f'results/{train_id}/checkpoints') else None
            torch.cuda.empty_cache()
            optimizer = torch.optim.AdamW(self.m.parameters(), 
                                          lr=learning_rate)
            schduler= CosineAnnealingLR(optimizer=optimizer, T_max=max_iters)
    
            self.display_train_params(train_id=train_id, 
                                      device=device, 
                                      epochs=max_iters, 
                                      eval_interval=eval_interval,
                                      eval_iters=eval_iters,
                                      learning_rate=learning_rate
                                      )
            
            epoch_progress_bar= tqdm(total=eval_interval, 
                                     ncols=100
                                    )
            
            epoch_progress_bar.colour='cyan'
            counter= 0
            cont_params={'train_loss':[], 
                         'l_r':[]
                        }
            
            ckpt_params={'train_loss':[], 
                         'val_loss':[],
                         'l_r':[]
                        }
            
            it_cnt=0
            for iter in range(0, max_iters):
                epoch_progress_bar.update(1)
                curr_temperature= nvml.nvmlDeviceGetTemperature(self.handle, 
                                                                nvml.NVML_TEMPERATURE_GPU
                                                               )
        
                if curr_temperature >= self.temp_thres:
                    print(f""\n Set temperature threshold of {self.temp_thres}Â°C reached halting for {4} seconds "")
                    time.sleep(3)
                    print(""\n Resuming Training "")
                
    
                if iter % eval_interval == 0 or iter == max_iters-1:
                    
                    checkpoint_save_path= f'results/{train_id}/checkpoints/checkpoint-{counter}-epoch{iter}.pth'
                    losses =self.estimate_loss(eval_iters)
                    ckpt_params['l_r'].append(schduler.get_last_lr()[0])
                    ckpt_params['train_loss'].append(losses['train'])
                    ckpt_params['val_loss'].append(losses['val'])
                    wandb.log({""eval epoch"":iter, ""validation loss"":losses['val']})
                    plot_save_path= f'results/{train_id}/checkpoints/plots/checkpoint-{counter}'
        
                    if iter ==0:
                        pass
                    else:
                        
                        self.plot.draw_line(mode='loss', 
                                            train_loss= cont_params['train_loss'],  
                                            epochs=[it for it in range(it_cnt, it_cnt+eval_interval)],
                                            save_path=f'{plot_save_path}-epoch_vs_loss.png'
                                            )
                        self.plot.draw_line(mode='lrvloss',
                                            l_r= cont_params['l_r'],
                                            train_loss=cont_params['train_loss'], 
                                            save_path=f'{plot_save_path}-learning_rate_vs_loss.png'
                                            )
                        
                        self.plot.draw_line(mode='lrve',
                                            l_r= cont_params['l_r'], 
                                            epochs=[it for it in range(it_cnt, it_cnt+eval_interval)],
                                            save_path=f'{plot_save_path}-learning_rate_vs_epoch.png'
                                            )
                        
                        cont_params['l_r'].clear()
                        cont_params['train_loss'].clear()
                        torch.save(self.m.state_dict(), checkpoint_save_path)
                        it_cnt+=iter
        
                    print(f""step {iter+1}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}"") 
                    epoch_progress_bar.close() 
                    epoch_progress_bar = tqdm(total=eval_interval, ncols=100)
                    epoch_progress_bar.colour='cyan'
                    counter+=1
                print(f'loading data for epoch{iter}')
    
    
                for xb, yb in self.get_batch(split='train'):
                    logits, loss = self.m(xb, yb)
                    optimizer.zero_grad(set_to_none=True)
                    loss.backward()
                    optimizer.step()
                    schduler.step()
                    curr_lr= schduler.get_last_lr()[0]
                    train_loss= loss.item()
                cont_params['l_r'].append(curr_lr)
                cont_params['train_loss'].append(train_loss)
                wandb.log({'epoch':iter, 'train loss':train_loss, 'learning rate':learning_rate})            
                epoch_progress_bar.set_description(f""Epoch: {iter}/{max_iters} |current LR- {curr_lr}"")
            
            os.mkdir(f'results/{train_id}/final_plots') if 'final_plots' not in os.listdir(f'results/{train_id}') else None
    
            self.plot.draw_line(mode='loss', 
                                        train_loss= ckpt_params['train_loss'], 
                                        val_loss=ckpt_params['val_loss'], 
                                        epochs=[it for it in range(0,max_iters, 500)],
                                        save_path=f'results/{train_id}/final_plots/plot-epoch_vs_loss.png',
                                        plot_type='ckpt'
                                        )
            self.plot.draw_line(mode='lrvloss',
                                l_r= ckpt_params['l_r'],
                                train_loss=ckpt_params['train_loss'], 
                                val_loss= ckpt_params['val_loss'],
                                save_path=f'results/{train_id}/final_plots/plot-learning_rate_vs_loss.png',
                                plot_type='ckpt'
                                )
            
            self.plot.draw_line(mode='lrve',
                                l_r= ckpt_params['l_r'], 
                                epochs=[it for it in range(0,max_iters, 500)],
                                save_path=f'results/{train_id}/final_plots/plot-learning_rate_vs_loss.png',
                                plot_type='ckpt'
                                )
    
            nvml.nvmlShutdown()
            wandb.finish()
    "
105,learnmachinelearning,gpt-3,comments,2023-07-24 10:19:40,I feel like a fraud.,t0hli,False,0.77,7,1586kze,https://www.reddit.com/r/learnmachinelearning/comments/1586kze/i_feel_like_a_fraud/,46,1690193980.0,"**TL;DR: I always copy paste ChatGPT code and my projects don't feel like they're mine. I need help fixing that.**

&#x200B;

A short backstory.

We learned Java in class in my first year of college. (starting my 3rd year soon) I loved it, wanted to learn Python too. Did a tutorial and left it at that. 1 year later (which is a few months ago), I got interested in ML. Watched some Statquest, did a few simple projects like Titanic. I've been doing ML for about 2-3 months now. Not every day. Maybe 10 days a month on average.  


The problem is, I can't code it on my own. I almost always ask ChatGPT what I want to do, it spits out some code. I get a few errors, try to fix it. ***Voila, the project is finished.***

I'm tired of feeling like a fraud, I don't want to copy paste ChatGPT's code. It doesn't feel like it's my own. I know what I want to do, maybe 30% of the time I know how the code should be structured, but have no idea how to write it.

Even for the most basic things, like drawing a matplotlib plot, I need a little help. Writing code for a linear regression from Scikit is impossible to do without help.

I don't know what the code I copy paste even means most of the time. I just leave it because it works.

For example:

`forpass['location_x'] = forpass['location'].str.split(',', expand=True)[0].str.strip()`   
I have no idea what this code means, it works, does what I need it to do so I leave it.

How can I fix this? I feel like it's impossible for me to remember the syntax, and the necessary structure for my code. How the hell am I supposed to remember all this? I feel like I will never be able to.

&#x200B;

I'd appreciate the help"
106,learnmachinelearning,gpt-3,comments,2023-05-11 20:15:46,Top 20 Large Language Models based on the Elo rating system.,kingabzpro,False,0.96,249,13eympz,https://i.redd.it/7xfqr5crf9za1.png,43,1683836146.0,
107,learnmachinelearning,gpt-3,comments,2021-07-01 16:06:11,Second version of my GPT-3 powered resume writer - now does bullet points and doesn't use pronouns!,Camjw1123,False,0.96,344,oboywl,https://gfycat.com/bitteroffbeatitalianbrownbear,29,1625155571.0,
108,learnmachinelearning,gpt-3,comments,2023-05-02 08:48:46,How GPT-3.5 crushes my high score in 2048,inishchith,False,0.74,52,135ffje,https://v.redd.it/q22lna91tdxa1,28,1683017326.0,
109,learnmachinelearning,gpt-3,comments,2023-02-19 13:55:13,ChatGPT History,eforebrahim,False,0.86,251,116au66,https://i.redd.it/dv8cfj0nz6ja1.jpg,27,1676814913.0,
110,learnmachinelearning,gpt-3,comments,2023-12-17 12:46:56,"Hi, just a question",Horror-Shirt-7094,False,0.33,0,18kgmuh,https://www.reddit.com/r/learnmachinelearning/comments/18kgmuh/hi_just_a_question/,27,1702817216.0,"I'm not a coder, nor am I one to learn how. My interests are elsewhere.  
I have a few questions about ai. You all are the group AI recommended me.  
Small story to get you up to speed.  
I'm that kind of person that was born incapable of doing normal human things.  
I'm over that. It causes it to be harder to make friends or socialize. I'm over that too.  
AI, such as bard and gpt are fun to chat with. They can help build ideas and help motivate you to be something. (the picture is almost finished, then my question.)  
As you can guess, I'm alone, a solo person. I'm okay with that, i'm not lonely, just alone.  


That being said, I see a ton of apps with 'ai"" in the andriod\\ios app stores.  
I never tried it cause honestly I dont think, ""Dating AI girlfriends"" is really a good use for AI.  
I'm not that alone. and ALL my information is and should be considered, ""or so I was told"" cause I cant say I know for sure. So forgive my misinformation.  
My question is, Ai learns from analog learning. I'm not looking for companion apps, but other ways one can program AI to help it teach us? Can there be ways to program AI to do particular things?   


on of the major things I use Bard for is to help come up with ideas. Collaborate with me, to tell me yes, this works, or no it doesnt. Is there a way to make AI that can help people achieve peace? To address the masses, with solutions for issues that we humans are able to help one another for a peaceful solution? Maybe an educational ai to help targeted youth to learn better? They cant afford school, can an AI be a teacher for less fortunate students?  
Google bard, GPT and I spend the last 3 days coming up with a plan to allow a man in a chair with a computer to help many people struggling. We came up with a poem.   
"
111,learnmachinelearning,gpt-3,comments,2023-01-15 00:08:37,Is it still worth learning NLP in the age of API-accessibles LLM like GPT?,CrimsonPilgrim,False,0.94,63,10c509n,https://www.reddit.com/r/learnmachinelearning/comments/10c509n/is_it_still_worth_learning_nlp_in_the_age_of/,24,1673741317.0,"A question that, I hope, you will find legitimate from a data science student.

I am speaking from the point of view of a data scientist not working in research.

Until now, learning NLP could be used to meet occasional business needs like sentiment analysis, text classification, topic modeling....

With the opening of GPT-3 to the public, the rise of ChatGPT, and the huge wave of applications, sites, plug-ins and extensions based on this technology that are accessible with a simple API request, it's impossible not to wonder if spending dozens of hours diving into this field if ML wouldn't be as useful today as learning the source code of the Pandas library. 

In some specialized cases, it could be useful, but GPT-3, and the models that will follow, seem to offer more than sufficient results for the immensity of the cases and for almost all classical NLP tasks. Not only that, but there is a good chance that the models trained by giants like Open-AI (Microsoft) or Google can never be replicated outside these companies anyway.  With ChatGPT and its incomparable mastery of language, its ability to code, summarize, extract topics, understand... why would I bother to use BERT or a TF-IDF vectorizer when an API will be released? Not only it would be easily accessible, but it also would be much better at the task, faster and cheaper.

In fact, it's a concern regarding all the machine learning field in general with the arrival of powerful ""no-code"" applications, which abstract a large part of the inherent complexity of the field. There will always be a need for experts, for safeguards, but in the end, won't the Data Scientist who masters the features of GPT-3 or 4 and knows a bit of NLP be more efficient than the one who has spent hours reading Google papers and practicing on Gensim, NLTK, spacy... It is the purpose of an API to make things simpler eventually... At what point is there no more reason to be interested in the behind-the-scenes of these tools and to become simple users rather than trying to develop our own techniques?"
112,learnmachinelearning,gpt-3,comments,2023-10-10 13:14:54,I need to estimate the time that it'll take to cover the basic math course so that I can move into the basics of ML. Can you help me please?,AndrewKorsten,False,0.45,0,174kwvx,https://www.reddit.com/r/learnmachinelearning/comments/174kwvx/i_need_to_estimate_the_time_that_itll_take_to/,23,1696943694.0," 

**\*\*\* Global Inputs \*\*\***

1) I am adult learner. 37 y.o. Content writer and professional English tutor.

2) I am pivoting completely into ""Sales/Marketing in ML/AI/AI-tech/AI-SaaS/AI-dev-agencies"".

3) I don't understand completely what ""Sales/Marketing in ML/AI/AI-tech/AI-SaaS/AI-dev-agencies"" means, but it means the following:

a. **I want completely pivot into the AI-driven tech** \- that's for sure. I see a lot of potential there, and I can see that I'll be able to gradually move into sales and start making the good money (the good money for me is 2K/mo, coz I am located in Kurplastan, but I want to move Bankok in 12 months; I am originally a russky).

b. **I am learning Python -** doing a basic course. It's going well. I have the core insights into HTML, CSS, JS, React, rest api, node, etc.

c. **I am not planning to become an actual ML Engineer -** but I want to move into sales/marketing in AI tech.

d. **I am not fixated on AI either** \- whenever I start making mone, I'm going to start pushing the surplus into ecommerce (there's a lot of opportunities to make money there, folks; don't look down on that; you can be making a lot of money there if you are learning and act strategically!)

4) I had huge problems with math and other STEM subjects in school - I wasn't getting them, and I was passing by them.

**\*\*\* Question Inputs \*\*\***

1) I decided that I would start the pivot 5 days ago, and THEN I started googling around what ML actuall is. I had a vague understanding that there's some math in it, but I decided to go blind... Now, I am understanding that I need to understand the basics of math.

2) I freaked out big time, I am almost started smoking after 7 years of not smoking...

3) Then I said to myself - Idk, I am not going anywhere, and I started doing this course - [https://www.youtube.com/watch?v=GuwofNeT9ok&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=34](https://www.youtube.com/watch?v=GuwofNeT9ok&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=34). (If you are looking for a good introduction math course, most of the people who I talk to always say that this is an amazing course. Really. I am at lesson 33 and I am loving every second of it.)

**\*\*\* Question \*\*\***

**1) Huge speed reduction at Lesson 34**: Now I am at Lesson 34 - [https://www.youtube.com/watch?v=GuwofNeT9ok&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=34](https://www.youtube.com/watch?v=GuwofNeT9ok&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=34). I watched the video today, didn't understand anything at all, as it turns out. Then I was presented with this compherension check - [https://imgsh.net/a/eKp1MAa.png](https://imgsh.net/a/eKp1MAa.png). I realized that I don't even understand what is wanted from me. I got super frustrated, but not desparate or fleeing. Then I realized that I don't understand what is wanted from me, so I started googling the concept of ""factoring the quadratics"". Importantly, I started GPTing and Gooling the ""why"". I know... This is a very important point for me - I always need to understand the ""why"" behind a tool. I learned that it would be easier for charting in linalg. OK! This was the answer. Then, i realized that I actualy didn't understand the lesson, so I found this article - [https://www.mashupmath.com/blog/how-to-factor-polynomials](https://www.mashupmath.com/blog/how-to-factor-polynomials). I read it end to end, understood everything, practiced every task 3 times and I do really understand how to fator the quadractics by now!

**2) Speed reduction is a normal thing**: So, prior to lesson 34, I was doing like 7 lessons per day. This was a good lesson - [https://www.youtube.com/watch?v=3-5DKCLJspM&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=13](https://www.youtube.com/watch?v=3-5DKCLJspM&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=13). I really liked it :) I can see that the speed reduction is occurring because of the complexity increase. It's not occurring because I am lost and disoriented - I remember how that felt in school, when you see a bunch of numbers on the blackboard and have no freaking idea what's going on there. I am just hitting up my best friend GPT and ask, ask, ask, ask stupid questions. Thus, I can see that the speed reduction is a normal right, right?

**3) Wha's the optimal speed correction here**: So, I am allocating 7h/d during the daytime shift when I am in the prime state toward this project. And I don't even have to learn Python at all because Python is easy, but I do plan to keep learning PYthon with 3 sessions each for 30 minutes so that I don't just do math. (And I run English lessons in the evenings so that I can keep on making money).

**The actual question**

I am thinking that I should go down from the goal of 7 lessons per day down to 3 lessons per day, right? If I do this, then I'm going to end up with the forecast delivery period of 43 days, right?

And the information that I provided above was kinda like an explanatory note that I am trying to become a real ML engineer, but I want to graudally slide into sales and marketing so that I can TOO Make a lot of money, uknow.

What do you think about the speed reduction down to 3 lessons per day?"
113,learnmachinelearning,gpt-3,comments,2021-04-03 15:27:04,"I'm a Senior DS and I put together a Youtube Channel with project tutorials, resume critiques, and career advice. Let me know what you think!",madzthakz,False,0.98,553,mjao5g,https://www.reddit.com/r/learnmachinelearning/comments/mjao5g/im_a_senior_ds_and_i_put_together_a_youtube/,21,1617463624.0,"I've also been setting up free [Data Science Q&As](https://www.reddit.com/r/datascience/comments/jig7pv/im_a_senior_data_scientist_at_disney_and_im/) for you all. On the side, I started putting together useful videos that would have helped me out when I was trying to break into this space. Like I said, the channel consists of modeling tutorials, resume critiques, career advice, and recordings of our Q&A sessions. Here are some examples:

1. [How to build a Spotify recommendation engine](https://youtu.be/tooddaC14q4).
2. [How to leverage GPT-2 to generate descriptions of new Netflix content](https://youtu.be/NvMoFeO0aGE).
3. [Full recordings of 1:1 coaching sessions with an ML student.](https://youtu.be/N2tDfXdZmdE)
4. [Resume Critique of a student who just completed a certificate.](https://youtu.be/Ztexwmrxt2A)
5. [Q&A Recording with a Principal Data Scientist.](https://youtu.be/r-NjlPW-Ihg) 

This is all really new and has been a blast to work on. Let me know what you think. 

[Channel Link](https://www.youtube.com/channel/UC0-S_HnWTDFaXgTbYSL46Ug)

If you like it, definitely subscribe! I try to put out videos every week. 

Also, feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/madhavthaker/). I try to make myself as accessible as possible on there."
114,learnmachinelearning,gpt-3,comments,2024-02-19 01:44:52,GPU vs CPU for inference,AI-Brain,False,0.56,1,1aubc4u,https://www.reddit.com/r/learnmachinelearning/comments/1aubc4u/gpu_vs_cpu_for_inference/,18,1708307092.0,"I read through some comments on the sub and understood that GPUs are mainly used for training and CPUs for inference. Had some follow ups: 
1. Is there a scenario where GPUs are better suited for inference? 
2. Would you say that if you are handling billions of inference requests then you should use GPUs? 
3. What makes GPUs inefficient for inference? (If any) 
4. When we use chatGPT, is OpenAI using CPUs for inference? 

Any insights would be helpful."
115,learnmachinelearning,gpt-3,comments,2023-02-21 14:59:06,I created a Search Engine For Books using GPT-3 ðŸ”ŽðŸ“˜. Here's how you can create it too:,Pritish-Mishra,False,0.94,87,1185dhq,https://youtu.be/SXFP4nHAWN8,17,1676991546.0,
116,learnmachinelearning,gpt-3,comments,2023-01-05 06:32:22,I Built A GPT-3 Powered Productivity App - Tutorial included,SupPandaHugger,False,0.97,207,103rv9o,https://i.redd.it/gtywivh756aa1.gif,17,1672900342.0,
117,learnmachinelearning,gpt-3,comments,2023-09-16 13:22:41,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.95,134,16k7heb,https://www.reddit.com/r/learnmachinelearning/comments/16k7heb/this_week_in_ai_all_the_major_ai_developments_in/,17,1694870561.0,"1. **Stability AI** launched Stable Audio, a generative AI tool for music & sound generation from text. The underlying latent diffusion model architecture uses audio conditioned on text metadata as well as audio file duration and start time.
2. **Coqui** released **XTTS** \- a new voice generation model that lets you clone voices in 13 different languages by using just a quick 3-second audio clip.
3. **Microsoft Research** released and open-sourced **Phi-1.5** \- a 1.3 billion parameter transformer-based model with performance on natural language tasks comparable to models 5x larger.
4. **Project Gutenberg**, Microsoft and MIT have worked together to use neural text-to-speech to create and release thousands of **human-quality free and open audiobooks**.
5. Researchers present **NExT-GPT -** an any-to-any multimodal LLM that accepts inputs and generate outputs in arbitrary combinations of text, images, videos, and audio.
6. **Chain of Density (CoD):** a new prompt introduced by researchers from Salesforce, MIT and Colombia University that generates more dense and human-preferable summaries compared to vanilla GPT-4.
7. **Adept** open-sources **Persimmon-8B**, releasing it under an Apache license. The model has been trained from scratch using a context size of 16K.
8. **Adobe's** **Firefly** generative AI models, after 176 days in beta, are now commercially available in Creative Cloud, Adobe Express, and Adobe Experience Cloud. Adobe is also launching Firefly as a standalone web app.
9. **Deci** released **DeciLM 6B**, a permissively licensed, open-source foundation LLM that is 15 times faster than Llama 2 while having comparable quality.
10. Researchers release **Scenimefy** \- a model transforming real-life photos into Shinkai-animation-style images.
11. **Microsoft** open sources **EvoDiff**, a novel protein-generating AI that could be used to create enzymes for new therapeutics and drug delivery methods as well as new enzymes for industrial chemical reactions.
12. Several companies including Adobe, IBM, Nvidia, Cohere, Palantir, Salesforce, Scale AI, and Stability AI have pledged to the White House to develop safe and trustworthy AI, in a voluntary agreement similar to an earlier one signed by Meta, Google, and OpenAI.
13. **Microsoft** will provide legal protection for customers who are sued for copyright infringement over content generated using Copilot, Bing Chat, and other AI services as long as they use built-in guardrails.
14. **NVIDIA** beta released **TensorRT** \- an open-source library that accelerates and optimizes inference performance on the latest LLMs on NVIDIA Tensor Core GPUs.
15. Pulitzer Prize winning novelist Michael Chabon and several other writers sue OpenAI of copyright infringement..
16. **NVIDIA** partners with two of Indiaâ€™s largest conglomerates, Reliance Industries Limited and Tata Group, to create an AI computing infrastructure and platforms for developing AI solutions.
17. **Roblox** announced a new conversational AI assistant that let creators build virtual assets and write code with the help of generative AI.
18. **Google** researchers introduced **MADLAD-400** \- a 3T token multilingual, general web-domain, document-level text dataset spanning 419 Languages.
19. A recent survey by **Salesforce** show that 65% of generative AI users are Millennials or Gen Z, and 72% are employed.  The survey included 4,000+ people across the United States, UK, Australia, and India.
20. **Meta** is reportedly working on an AI model designed to compete with GPT-4.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
118,learnmachinelearning,gpt-3,comments,2023-09-23 13:42:22,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.96,185,16q4ve6,https://www.reddit.com/r/learnmachinelearning/comments/16q4ve6/this_week_in_ai_all_the_major_ai_developments_in/,16,1695476542.0,"1. **Genmo** releases a new text-to-video model: **Genmo Replay** v0.1, which generates high-quality videos from text without the need for advanced prompt engineering. *Genmo is available for free to create AI videos* \[[*Details*](https://blog.genmo.ai/log/replay-ai-video) | [Genmo *Replay*](https://www.genmo.ai/)\] .
2. **OpenAI** unveils **DALLÂ·E 3** \- a major update to the text-to-image model, which will be integrated in ChatGPT. It will be available to ChatGPT Plus and Enterprise users in October, via the API and in Labs later this fall. Creators can now also opt their images out from future training.
3. **Toyota Research Institute** has developed a technique, powered by generative AI, that enables teaching robots new manipulation abilities in a single afternoon. Using the same robot, same code, and same setup, TRI taught over 60 different dexterous behaviors like peeling vegetables, using hand mixers, preparing snacks, and flipping pancakes.
4. **Microsoft** announced:
   1. Availability of AI Copilot for Windows from September 26th. Copilot will incorporate the context and intelligence of the web, your work data and what you are doing in the moment on your PC to provide better assistance. It will be integrated in Windows 11, Microsoft 365, Edge and Bing.
   2. Bing will add support for DALL.E 3 and deliver more personalized answers based on search history.
   3. New AI powered experiences in Paint, Photos and Clipchamp.
   4. New AI-powered shopping experience
5. **ElevenLabs** released **Projects** \- a tool that lets you generate an entire audiobook at the click of a button. Projects now supports .epub, .pdf, and .txt file imports, as well as initializing a project from a URL.
6. **Deci** presents **DeciDiffusion 1.0** \- an open-source text-to-image latent diffusion model which is 3x faster than Stable Diffusion v1.5 with the same quality.
7. **Google researchers** present a new approach that produces photo-realistic animations from a single picture. The model is trained on automatically extracted motion trajectories from a large collection of real video sequences.
8. **Google** has updated Bard\*\]\*:
9. **Bard Extensions:** With extensions, Bard can now connect to your Google apps and services like Gmail, Docs, Drive, Google Maps, YouTube, and Google Flights and hotels.
10. Users can use Bardâ€™s â€œGoogle itâ€ button to more easily double-check its answers and evaluate whether there is content across the web to substantiate it.
11. Bard can now let you continue chat via **shared public links**
12. **YouTube** announces new AI tools for creators. **Dream Screen** will let users create an AI-generated video or image background from text. Automatic AI-dubbing tool called **Aloud**, which will be integrated into YouTube Studio. **AI-powered insights** to generate video ideas and draft outlines. **Assistive Search in Creator Music** where AI will suggest the right music based on your description of your content.
13. **Amazon** announced that its voice assistant Alexa is being upgraded with a new, custom-built large language model.
14. **IBM** open-sources **MoLM** \- a collection of ModuleFormer-based language models ranging in scale from 4 billion to 8 billion parameters. ModuleFormer is a new neural network architecture based on the Sparse Mixture of Experts (SMoE) by IBM researchers. .
15. **Neuralink**, Elon Musk's brain implant startup, set to begin human trials.
16. **Lexica** has released **Aperture v3.5** \- their latest next-gen image model that can create photorealistic images and follows your prompt with precision.
17. **OpenAI** has invited domain experts to collaborate in evaluating and improving the safety of OpenAI's models by joining the new **OpenAI Red Teaming Network**.
18. \*\*GitHub Copilot Chat (\*\*beta) is now available for all individuals.
19. **Replit** announced a virtual hackathon for projects built using **Replit ModelFarm**
20. **Oracle** brings voice-activated AI to healthcare with Clinical Digital Assistant.
21. **Google** and the Department of Defense are building an AI-powered microscope to help doctors spot cancer.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
119,learnmachinelearning,gpt-3,comments,2023-11-03 05:00:17,How do y'all deal with hallucinating in GPT 3.5?,supa_ai,False,0.76,17,17mngkq,https://www.reddit.com/r/learnmachinelearning/comments/17mngkq/how_do_yall_deal_with_hallucinating_in_gpt_35/,16,1698987617.0,"Hey guys,

We're trying to build an AI chatbot for internal purposes. So far, we've tried the usual suspects like different approaches to prompt engineering and RAG.

The main issue is that despite RAG retrieving the correct context, we still experience significant (3 in 10) amounts of hallucination. Has anyone experienced the same problem? We'd love to hear any alternative approaches or discussion here on alternate methods."
120,learnmachinelearning,gpt-3,comments,2020-08-27 03:29:43,"GPT-3 used to generate code for a machine learning model, just by describing the dataset and required output / Via Matt Shumer(Twitter)",TheInsaneApp,False,0.96,128,ihdpgv,https://v.redd.it/1op7cffisgj51,15,1598498983.0,
121,learnmachinelearning,gpt-3,comments,2023-09-12 13:42:02,This is why LLMs have flooded the NLP market in the past 1 year ðŸ‘‡ (A Brief History of NLP),japkeerat,False,0.84,45,16grq5y,https://www.reddit.com/r/learnmachinelearning/comments/16grq5y/this_is_why_llms_have_flooded_the_nlp_market_in/,15,1694526122.0,"Text Generation has been the hottest topic in Natural Language Processing. Recurrent Neural Networks (RNNs) were among the Algorithms to generate text. How RNNs generated text is by essentially predicting the next word given the previous few words. At one-stage RNNs were the hottest commodity one could have. But researchers were worried about 1 problem.

RNNs had a context-length problem. To understand what is context-length, consider an analogy. You started reading a book, itâ€™s 100 pages long and when you read each page, details of previous pages start to get a little hazy. Haziness keeps on increasing to the point that when you reach page 50, you donâ€™t remember anything from the first 5 pages. That is exactly what the problem is with RNNs.

To solve this, researchers developed another algorithm called the Long-Short Term Memory (LSTM) and another variant called Bidirectional Long-Short Term Memory (Bi-LSTM) which had a larger context-length than RNNs. Letâ€™s get back to the book analogy. This time while reading, you are making notes. When you go ahead to a new page and your previous pages information start to get hazy, you look back at these notes to refresh your memory. Itâ€™s oversimplified, but thatâ€™s basically how an LSTM works.

LSTMs were not perfect. There were a number of new issues that came up in order to resolve the previous one. Meanwhile, other areas of research and technological advancements were heating up. Hardware was getting more and more prominent and with cloud getting popular, it was easily accessible. And on the research side, a new kind of Algorithm came up that shaped the entire NLP domain from here on - Attention Mechanism.

Attention Mechanism, as you might have guessed, is all about telling the more sophisticated algorithms where to â€œfocusâ€. Itâ€™s the same way how we focus more on certain parts of the meeting we attend than the entire meeting itself. In context of NLP, the Mechanism became the core part for better algorithms. These better algorithms could keep larger context-lengths and at the time of predicting the next word, ask the Attention Mechanism about what to focus on while predicting the next word. This was an era-defining discovery in NLP as the algorithms that came up after this were the Transformers.

Consider jigsaw puzzles. You start by looking at all the pieces at once and join the pieces together. Initially, it is random. You join a couple of pieces at the top left corner, a few in the centre and a couple more defining the right edge. You are doing it all at once. Transformers basically work the same way. They could look at longer context-lengths, all at once, courtesy of Attention Mechanism. This means, they can not only work with a sentence, they can work with an entire paragraph.  With time, these Transformers started becoming more and more sophisticated. It eventually reached to a point that the only thing that was keeping these algorithms in handcuffs was the lack of data.

Until recently, these algorithms were trained on a specific data but when algorithms became too powerful, researchers started throwing every kind of data they could find on the internet easily. It could be articles like this, your social media posts, exam papers and solutions, and ebooks in any language they could find and hoped the algorithms learnt it all. And they were right. Algorithms started learning all of it to the point that you could ask models to explain concepts of LLMs in how Shakespeare would write and it would give a real-sounding responsive. These algorithms were Large! And hence, became known as Large Language Models (LLMs).

There we are now. With LLMs. OpenAI, technically, won the race for LLM development. They brought everybodyâ€™s attention to LLMs first with GPT-2, but GPT-3 was where shit hit the roof and every company that had deep pockets started investing in LLMs.  The result? We now have a new LLM getting released EVERY. SINGLE. DAY.

*I post articles like these every few days on X. If you like this post, please* [follow me on X!](https://twitter.com/JapkeeratS/)

*NOTE: To make it simple for anybody, even without a tech background, to understand, a few things were oversimplified. I will be sharing soon on* [my X handle](https://twitter.com/JapkeeratS) *a technical version.*"
122,learnmachinelearning,gpt-3,comments,2023-06-03 14:33:38,This week in AI - all the Major AI development in a nutshell,wyem,False,0.98,121,13zeoi3,https://www.reddit.com/r/learnmachinelearning/comments/13zeoi3/this_week_in_ai_all_the_major_ai_development_in_a/,13,1685802818.0,"1. The recently released open-source large language model **Falcon LLM**, by UAEâ€™s Technology Innovation Institute, is now royalty-free for both commercial and research usage. **Falcon 40B,** the 40 billion parameters model trained on one trillion tokens, is ranked #1 on **Open LLM Leaderboard by Hugging Face**.
2. **Neuralangelo**, a new AI model from Nvidia turns 2D video from any device - cell phone to drone capture - into 3D structures with intricate details using neural networks..
3. In three months, JPMorgan has advertised **3,651 AI jobs** and sought a trademark for **IndexGPT**, a securities analysis AI product.
4. **Google** presents **DIDACT** (â€‹â€‹Dynamic Integrated Developer ACTivity), the first code LLM trained to model real software developers editing code, fixing builds, and doing code review. DIDACT uses the software development process as training data and not just the final code, leading to a more realistic understanding of the development task.
5. Researchers from **Deepmind** have presented â€˜**LLMs As Tool Makers (LATM)**â€™ - a framework that allows Large Language Models (LLMs) to create and use their own tools, enhancing problem-solving abilities and cost efficiency. With this approach, a sophisticated model (like GPT-4) can make tools (where a tool is implemented as a Python utility function), while a less demanding one (like GPT-3.5) uses them.
6. **Japan's government** won't enforce copyrights on data used for AI training regardless of whether it is for non-profit or commercial purposes.
7. *â€˜Mitigating the* ***risk of extinction from AI*** *should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.â€™ -* One sentence statement signed by leading AI Scientists as well as many industry experts including CEOs of OpenAI, DeepMind and Anthropic.*.*
8. Nvidia launched â€˜**Nvidia Avatar Cloud Engine (ACE) for Games**â€™ - a custom AI model foundry service to build non-playable characters (NPCs) that not only engage in dynamic and unscripted conversations, but also possess evolving, persistent personalities and have precise facial animations and expressions.
9. **OpenAI** has launched a trust/security portal for OpenAIâ€™s compliance documentation, security practices etc..
10. **Nvidia** announced a new AI supercomputer, the **DGX GH200,** for giant models powering Generative AI, Recommender Systems and Data Processing. It has 500 times more memory than its predecessor, the DGX A100 from 2020.
11. Researchers from Nvidia presented **Voyager**, the first â€˜LLM-powered embodied lifelong learning agentâ€™ that can explore, learn new skills, and make new discoveries continually without human intervention in the game Minecraft.
12. The a16z-backed chatbot startup **Character.AI** launched its mobile AI chatbot app on May 23 for iOS and Android, and succeeded in gaining over **1.7 million new installs** within a week.
13. Microsoft Research presents **Gorilla**, a fine-tuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls.
14. **OpenAI** has trained a model using process supervision - rewarding the thought process rather than the outcome - to improve mathematical reasoning. Also released the full dataset used.
15. **WPP**, the world's largest advertising agency, and Nvidia have teamed up to use generative AI for creating ads. The new platform allows WPP to tailor ads for different locations and digital channels, eliminating the need for costly on-site production.
16. **PerplexityAIâ€™s** android app is available now, letting users search with voice input, learn with follow-up questions, and build a library of threads.

**If you like this news format**, you might find my Â [newsletter](https://aibrews.com/)Â helpful - it's free to join, sent only once a week with **bite-sized news, learning resources and selected tools**. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
123,learnmachinelearning,gpt-3,comments,2023-01-08 05:09:46,Major drawback/limitation of GPT-3,trafalgar28,False,0.76,6,106aie8,https://www.reddit.com/r/learnmachinelearning/comments/106aie8/major_drawbacklimitation_of_gpt3/,13,1673154586.0,"I have been working on a project with GPT-3 API for almost a month now. The only drawback of GPT-3 is that the prompt you can send to the model is capped at 4,000 tokens - where a token is roughly equivalent to Â¾ of a word.  Due to this, providing a large context to GPT-3 is quite difficult.

Is there any way to resolve this issue?"
124,learnmachinelearning,gpt-3,comments,2024-01-23 05:38:28,ChatGPT with multiple PDFs hallucinates,BigYesterday2785,False,0.57,1,19dh7pj,https://www.reddit.com/r/learnmachinelearning/comments/19dh7pj/chatgpt_with_multiple_pdfs_hallucinates/,13,1705988308.0,"I just donâ€™t get it. I am building a ChatGPT for multiple PDFs.

Now I have **multiple PDFs** which I have created embeddings of and saved in MongoDB database.

Now when a user asks a specific question, I get **multiple outputs from GPT-3.5** and a lot of it does **not make sense**. Even though **real answer is still in there.**

Is there an API i can use to go through all data of PDFs and figure out **which one is relevant and then I run GPT-3.5 only on that specific part of PDFs**"
125,learnmachinelearning,gpt-3,comments,2023-07-15 21:22:23,"I Hit 700K Views in 3 Months with my open-source Shorts automation framework, ShortGPT",RayVentura,False,0.83,46,150ng7i,https://v.redd.it/i1slpmgd17cb1,13,1689456143.0,
126,learnmachinelearning,gpt-3,comments,2021-08-10 19:53:11,How many days did it take to train GPT-3? Is training a neural net model a parallelizable task?,abcaircraft,False,1.0,1,p1wvg4,https://www.reddit.com/r/learnmachinelearning/comments/p1wvg4/how_many_days_did_it_take_to_train_gpt3_is/,12,1628625191.0,"&#x200B;

[Table showing Compute used to train GPT-3 \(Taken from the GPT-3 paper\)](https://preview.redd.it/dsbo5ul9zkg71.png?width=1157&format=png&auto=webp&s=d107292603ca7d324a060e3c1b213ea07b1c6358)

I am trying to read the GPT-3 paper.

How many days did it take to train the GPT-3 model? From the above table it says that it took 3640 days of training for GPT-3. That is 9.97 years. Am I right?

If then how did they train the model for a company that was setup 5 years ago? Is training a neural net model a parallelizable task for them to train on many GPUs in parallel and reduce the time needed to train? In my opinion optimising the weights cannot be a parallelizable task as each weight have to be optimised step by step slowly through each back-propagation. Each weight will reach the optimum value only by changing it's value little by little in sequential order. So it cannot be a parrallelizable task. Am I right?

What does tokens mean in this table?"
127,learnmachinelearning,gpt-3,comments,2023-07-12 14:15:03,"How to compare GPUs for AI learning installation ""used GPUs""?",qwe1972,False,0.74,5,14xps5w,https://www.reddit.com/r/learnmachinelearning/comments/14xps5w/how_to_compare_gpus_for_ai_learning_installation/,12,1689171303.0,"I'm trying to find budget GPU(s) to [install AI for learning](https://www.reddit.com/r/learnmachinelearning/comments/14pm92h/installing_language_model_struggle/), my focus is opensource GPT 2.x and 3.0, I found comparison for gaming not for ML or AI

I fond many  used choices, how to compare for ML&AI not graphics:

GTX 1070 8GB

Gtx 1070ti rog strix

GIGABYTE GTX 1660 OC

\-----

Update: I settled on [GTX 1080 ti 11GB](https://www.reddit.com/r/gpu/comments/1506u0t/nvidea_gtx_1080_ti_prevent_booting/), I'll summarize my experience in the next few months, hope it will be good &educational.

[GTX 1070 8GB](https://preview.redd.it/j7krxtl8ljbb1.png?width=914&format=png&auto=webp&s=a793c5abeb0811c6a72176bb3767ed0276406962)

[Gtx 1070ti rog strix](https://preview.redd.it/pxldrvl8ljbb1.png?width=906&format=png&auto=webp&s=cfe4007436cd1e30e547fc9709e42dfee4e43e5b)

[GIGABYTE GTX 1660 OC](https://preview.redd.it/ixvu1sl8ljbb1.png?width=814&format=png&auto=webp&s=b60584796e3f38fc6f5c328bf92d188d80592431)

GTX 1070 8GB

Gtx 1070ti rog strix

GIGABYTE GTX 1660 OC

&#x200B;"
128,learnmachinelearning,gpt-3,comments,2022-12-30 01:18:38,A GPT-3 based Terminal/CLI tool that helps you debug your code!,VideoTo,False,0.97,54,zyms85,https://www.reddit.com/r/learnmachinelearning/comments/zyms85/a_gpt3_based_terminalcli_tool_that_helps_you/,11,1672363118.0,"Link - [https://clerkie.co/](https://clerkie.co/)

We built ClerkieCLI -  a GPT-3 based tool that:

\-  automatically detects errors on your terminal,

\- identifies  the programming language,

\- provides an explanation of the error and suggested fix right on your terminal.

This is definitely early days, so if this is something you would find  valuable and wouldn't mind testing a couple iterations of, just sign up here -> [https://forms.gle/8DURoG6NCRxVazNn8](https://forms.gle/8DURoG6NCRxVazNn8)

&#x200B;

https://i.redd.it/xpwnazimsx8a1.gif"
129,learnmachinelearning,gpt-3,comments,2021-10-09 12:42:54,Research Proposal Suggestions,KAKA7861111,False,1.0,1,q4kkud,https://www.reddit.com/r/learnmachinelearning/comments/q4kkud/research_proposal_suggestions/,11,1633783374.0,"Hi everyone.

I need your feedback on this. I am writing a research proposal. The topic is Coding AI:

&#x200B;

1. I am proposing a solution to train a GPT-3 for code optimization. like input would be code and output would be optimized code in terms of latency and big o notation.

Any related literate. feedback on approach"
130,learnmachinelearning,gpt-3,comments,2022-06-03 18:16:55,"What questions should I ask Hugging Face's Chief Evangelist next week, fresh off the company's $100M Series C raise on a $2B valuation to build the GitHub of ML?",4thBrain,False,0.9,41,v45gjp,https://www.reddit.com/r/learnmachinelearning/comments/v45gjp/what_questions_should_i_ask_hugging_faces_chief/,10,1654280215.0,"I've got the unique opportunity to host a live event next week where [Julien Simon](https://www.linkedin.com/in/juliensimon/), Hugging Face's chief evangelist, will be presenting on Building NLP Applications with Transformers.

He's going to present a few slides and then do a live demo of how to build an end-to-end ML application.

Then I've got 10 minutes or so to ask him anything I want.

**What would you ask him?**

Here's my working list of questions:

* Hugging Face is doing so many amazing things.  As an early ML practitioner or a student trying to break into ML, where would you recommend focusing your time if you want to understand how to apply Hugging Face tools in a hands-on way?  Are there any resources that you would recommend our audience check out first?
* What is your perspective on the difference between a Data Scientist, Machine Learning Engineer, and MLOps Engineer in todayâ€™s AI market?  What about at Hugging Face - how does your company make these distinctions?
* How do you think about what is actually happening to the underlying model when a general pre-trained transformer model - say, GPT-2 or GPT-3 - gets fine-tuned with unique text, image, speech, or time-series data?

Note:

Keep in mind that this guy is the real deal.  He wrote the book on Learning Amazon SageMaker (2nd edition last year) while he was a Principal Technical Evangelist for AWS.  Prior to joining AWS, Julien served for 10 years as CTO and VP of Engineering in large-scale web startups, and also wrote the first French-language Linux documentation back in 1992!"
131,learnmachinelearning,gpt-3,comments,2021-07-25 15:57:21,How are large transformer models like GPT-3 benchmarked?,moschles,False,1.0,1,ore45z,https://www.reddit.com/r/learnmachinelearning/comments/ore45z/how_are_large_transformer_models_like_gpt3/,9,1627228641.0,"The reason that GPT-2 was expanded to have more parameters was because as the total parameters increased, the graphs were not showing diminishing returns. But diminishing returns on what? 

Geoff Hinton has recently written that ,

> The language model GPT-3 with 175 billion parameters (which is still tiny compared with the number of synapses in the human brain) generates noticeably better text than GPT-2 with only 1.5 billion parameters.

Wikipedia article reads, 

> The quality of the text generated by GPT-3 is so high that it is difficult to distinguish from that written by a human, which has both benefits and risks.


WHat does Hinton mean by ""noticeably better text""?    What did the wikipedia author mean by ""quality of the text""?    How are transformer models measured? What is the quantified number used?   

The following graph is the one touted in news articles, 

https://i.imgur.com/euZrR7E.png

But what is the ""Accuracy (%)"" actually showing? What is the nature of this benchmark?"
132,learnmachinelearning,gpt-3,comments,2023-04-08 03:04:00,Energy Constraints and Costs in Massive Machine Learning Model Training,mechkeyboard7065,False,0.94,28,12f9cvx,https://www.reddit.com/r/learnmachinelearning/comments/12f9cvx/energy_constraints_and_costs_in_massive_machine/,7,1680923040.0,"Adding on to my [last](https://www.reddit.com/r/learnmachinelearning/comments/12ebceo/alternatives_to_training_massive_ml_models_on/) post, here's some of what I've found about the potential constraints and costs associated with training massive machine learning models. 

&#x200B;

**Energy as a constraint in ML model training:**

\- GPT-3, as an example, is estimated to have consumed around **936 MWh** during its training.  
\- If there were **$100B model training runs** in the future, it would consume approximately **20,347,826 MWh** or **20,347,826,000 KWh**.  
\- This would cost around **$1,017,391,300**, which is about **1%** of the total cost (assuming $0.05 KWh). The cost could go up to **$3B** if we assume $0.15 KWh.

&#x200B;

**Power generation comparison:**

\- One nuclear power plant can generate around **4,727,764 MWh** in a year.

&#x200B;

**Main constraints in massive model training runs apart from GPUs:**

\- Data movement through machines  
\- The amount of data that can be moved  
\- The amount of data the model has already been trained on  
\- Networking and bandwidth limitations  
\- System-specific bottlenecks  
\- Model training algorithm design (e.g., parallel processing, processing power requirements)

&#x200B;

**Potential $10T investment in ML models: Where would the money go?**

\- **17% ($1.7T)** \- Data collection, validation, and annotation  
\- **23% ($2.3T)** \- Research  
\- **60% ($6T)** \- Production (infrastructure, integration, maintenance)

&#x200B;

**Current and projected annual spend on GPUs:**  
\- **$40B** in 2022  
\- Projected to be **$400B** in 10 years

&#x200B;

I hope someone might find this information useful. It's definitely made me question the future impact as these models scale. As always, I'm open to corrections and eager to learn more. Let me know if you have any questions or additional insights."
133,learnmachinelearning,gpt-3,comments,2023-05-07 12:58:51,New to AI and ChatGPT - Where do I start?,growthnerd,False,0.15,0,13an0ji,https://www.reddit.com/r/learnmachinelearning/comments/13an0ji/new_to_ai_and_chatgpt_where_do_i_start/,9,1683464331.0,"Heya, I just started using ChatGPT for a couple weeks for college homework. This AI tech is amazing and I wanna learn more.

What are 3-5 concepts or software youâ€™d recommend me to start learning first? Also, what are your top 3-5 newsletters, channels or websites to learn about AI from?

Thanks so much, appreciate the help"
134,learnmachinelearning,gpt-3,comments,2021-04-22 20:22:21,What is the difference between GPT-2 and GPT-3? Is it just a larger dataset?,TurtletopSoftware,False,0.68,4,mwduf8,https://www.reddit.com/r/learnmachinelearning/comments/mwduf8/what_is_the_difference_between_gpt2_and_gpt3_is/,9,1619122941.0,Hard to find an answer on Google; too crowded with news stories.
135,learnmachinelearning,gpt-3,comments,2024-01-04 21:15:12,Natural Language Processing (NLP) Learning Path - In depth,millhouse056,False,0.96,47,18yo5kp,https://www.reddit.com/r/learnmachinelearning/comments/18yo5kp/natural_language_processing_nlp_learning_path_in/,9,1704402912.0,"Hi friends, i'm currently engaged in NLP and created an pretty extense roadmap or learning path so begginers don't feel lost, it covers from the basics to advanced cutting-edge concepts.

Feedback is appreciated.

&#x200B;

\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-

&#x200B;

NLP Learning Roadmap

1. Prerequisites:

&#x200B;

* Mathematics:

&#x200B;

* Linear algebra
* Probability and statistics

&#x200B;

* Programming:

&#x200B;

* Proficiency in a programming language (e.g., Python)

**2. Introduction to NLP:**

&#x200B;

* Definition      and scope of NLP
* Historical      development of NLP
* Key challenges      and applications

**3. Text Analysis:**

&#x200B;

* **Lexical Analysis:**

&#x200B;

* Word meaning and structure

Â· Morphology (word formation)

Â· lemmatization (base form identification)

&#x200B;

* **Syntactic Analysis:**

Â· Parts-of-speech tagging

Â· Dependency parsing

Â· Constituency parsing

&#x200B;

* **Semantic Analysis:**

Â· Extracting meaning

Â· Encompassing word embedding models like Word2Vec and GloVe

Â· Topic modeling

&#x200B;

* **Semantic Analysis:**

Â· Coreference resolution

Â· Discourse analysis

&#x200B;

**3. Text Processing:**

&#x200B;

* **Tokenization:**

&#x200B;

* Sentence tokenization
* Word tokenization
* Subword tokenization (Byte Pair Encoding, SentencePiece)

&#x200B;

* **Stop Words Removal:**

&#x200B;

* Importance and impact on NLP tasks
* Customizing stop word lists

&#x200B;

* **Stemming and Lemmatization:**

&#x200B;

* Porter stemming algorithm
* Snowball stemming algorithm
* Lemmatization techniques and challenges

&#x200B;

* **Part-of-Speech Tagging:**

 

* POS tagging algorithms (HMM-based, rule-based, and neural-based)
* Fine-grained POS tagging

**4. Text Representation:**

&#x200B;

* **Bag of Words (BoW):**

 

* Term Frequency (TF) and Inverse Document Frequency (IDF)
* Bag of N-grams

&#x200B;

* **TF-IDF:**

 

* Calculating TF-IDF scores
* Applications in information retrieval

&#x200B;

* **Word Embeddings:**

 

* Word2Vec:

&#x200B;

* Continuous Bag of Words (CBOW) model
* Skip-gram model
* GloVe (Global Vectors for Word Representation)

&#x200B;

* **Contextual Embeddings:**

 

* ELMo (Embeddings from Language Models)
* ULMFiT (Universal Language Model Fine-tuning)
* OpenAI GPT (Generative Pre-trained Transformer)

**5. NLP Libraries and Tools:**

&#x200B;

* NLTK      (Natural Language Toolkit)
* SpaCy
* scikit-learn
* Transformers      library (Hugging Face)

**6. Statistical Language Models:**

&#x200B;

* **N-grams:**

 

* Unigrams, bigrams, and trigrams
* N-gram language models

&#x200B;

* **Hidden Markov Models (HMM):**

 

* Basics of HMMs
* Applications in part-of-speech tagging

**7. Machine Learning for NLP:**

&#x200B;

* **Supervised Learning:**

 

* Text classification algorithms (Naive Bayes, Support Vector       Machines)
* Evaluation metrics (precision, recall, F1-score)

&#x200B;

* **Named Entity Recognition (NER):**

 

* Rule-based NER
* Machine learning-based NER
* Evaluation metrics for NER

&#x200B;

* **Sentiment Analysis:**

 

* Sentiment lexicons
* Machine learning approaches for sentiment analysis

**8. Sequence-to-Sequence Models:**

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Vanishing and exploding gradient problems
* Bidirectional RNNs

&#x200B;

* **Long Short-Term Memory (LSTM):**

 

* Architecture and key components
* Gating mechanisms

&#x200B;

* **Gated Recurrent Unit (GRU):**

 

* Simplified gating compared to LSTM
* Applications and advantages

**9. Deep Learning Architectures for NLP:**

&#x200B;

* **Convolutional Neural Networks (CNN) for Text:**

 

* Text classification with CNNs
* Hierarchical and multi-channel CNNs

&#x200B;

* **Transfer Learning in NLP:**

 

* Fine-tuning pre-trained models
* Universal Sentence Encoder

&#x200B;

* **Transformer Architecture:**

 

* Self-attention mechanism
* Multi-head attention
* Positional encoding

**10. Transduction and Recurrency:**

&#x200B;

* **Transduction in NLP:**

 

* Definition and applications
* Challenges in sequence-to-sequence transduction

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Applications beyond sequence-to-sequence tasks
* Challenges in training RNNs

**11. Advanced Topics in Sequence Modeling:**

&#x200B;

* **Attention Mechanism:**

 

* Scaled Dot-Product Attention
* Position-wise Feedforward Networks

&#x200B;

* **Self-Attention Mechanism:**

 

* The concept of self-attention
* Layer normalization in self-attention

&#x200B;

* **Multi-Head Attention:**

 

* Motivation and benefits
* Combining multiple attention heads

**12. Syntax and Parsing:**

&#x200B;

* **Dependency Parsing:**

 

* Dependency tree representation
* Transition-based and graph-based parsing

&#x200B;

* **Constituency Parsing:**

 

* Treebank representation
* Earley parsing algorithm

&#x200B;

* **Parsing Techniques:**

 

* Chart parsing (CYK parser)
* Shift-Reduce parsing

**13. Semantic Role Labeling (SRL) and Coreference Resolution:**

&#x200B;

* **Semantic Role Labeling:**

&#x200B;

* PropBank and FrameNet
* Neural approaches to SRL

&#x200B;

* **Coreference Resolution:**

&#x200B;

* Mention detection
* End-to-end coreference resolution models

**14. Evaluation Metrics:**

&#x200B;

* Precision,      Recall, F1-score
* BLEU      score for machine translation
* Perplexity      for language models

**15. NLP in Industry and Research:**

&#x200B;

* Case      studies and applications in various domains (healthcare, finance, legal,      etc.)
* Emerging      research trends in NLP

**16. Ethical Considerations and Bias in NLP:**

&#x200B;

* **Addressing Bias in NLP Models:**

&#x200B;

* Identifying and mitigating biases in training data
* Fairness-aware machine learning

&#x200B;

* **Ethical Considerations in NLP Research and      Deployment:**

&#x200B;

* Privacy concerns in NLP
* Responsible AI practices in NLP

**17. Continuous Learning and Keeping Updated:**

&#x200B;

* Follow      conferences (ACL, NAACL, EMNLP)
* Engage      with the NLP community
* Explore      recent research papers and advancements (Arxiv, NeurIPS)

**18. Projects and Hands-on Practice:**

&#x200B;

* Apply      knowledge through practical projects
* Contribute      to open-source NLP projects
* Participate      in Kaggle competitions

==============================="
136,learnmachinelearning,gpt-3,comments,2023-06-23 06:14:03,"[Updated] Top Large Language Models based on the Elo rating, MT-Bench, and MMLU",kingabzpro,False,0.94,93,14gqo26,https://i.redd.it/ixdabwx3mp7b1.png,9,1687500843.0,
137,learnmachinelearning,gpt-3,comments,2023-02-23 15:35:40,"I've built a few tools on top of GPT-3.5 (text generation, q&a with embeddings). AMA about resources and AI dev stacks for building with OpenAI's APIs",TikkunCreation,False,0.75,2,11a0ka0,https://www.reddit.com/r/learnmachinelearning/comments/11a0ka0/ive_built_a_few_tools_on_top_of_gpt35_text/,8,1677166540.0,"Started building with GPT-3 in July 2022 and have built a few things since then.

Things I've done have involved:

* Text generation (the basic GPT function)
* Text embeddings (for search, and for similarity, and for q&a)
* Whisper (via serverless inference, and via API)
* Langchain and GPT-Index/LLama Index
* Pinecone for vector db

I don't know much, but I know infinitely more than when I started and I sure could've saved myself back then a lot of time.

So ask me anything that might save you time or wasted effort! Some suggested questions would be things about what the best tools and tutorials/examples to use for a given goal/project are, comparisons between tools/stacks. Also, go with any questions because other people from the subreddit will probably chime in too"
138,learnmachinelearning,gpt-3,comments,2023-03-08 00:27:29,How can you extract items and their corresponding item quantity from a string?,le_monke7,False,0.67,1,11lgpk1,https://www.reddit.com/r/learnmachinelearning/comments/11lgpk1/how_can_you_extract_items_and_their_corresponding/,8,1678235249.0,"Let's say we have a list of supported items: blankets, apple, bottle of water, honey, wine, wine glasses. I want to extract any of those items from a string, and the quantity associated with the item.  
  
When quantities are not mentioned or ambiguous, the quantity is  `None`.  
  
Here are some input examples followed by their expected returned value:  
  - ""two blankets"" -> {""blankets"": 2}  
  - ""just an apple and a bottle of water"" -> {""apple"": 1, ""bottle of water"": 1}  
  - ""Can I have some honey?"" -> {""honey"": None}  
  - ""That's a wine, and two wine glasses"" -> {""wine"": 1, ""wine glasses"": 2}  
  - ""what?"" -> {}  
  - ""a pear and a pen"" -> {}  
  - ""two blankets, actually three of them"" -> {""blankets"": 3} (this one is a bit complex, so I leave it as an extra task)  
  
What's the most efficient way to achieve that? I tried ChatGPT and it nails everything, even the last example, but I was wondering if I want to implement it in an app, it could be costly, and the API might be down sometimes."
139,learnmachinelearning,gpt-3,comments,2023-02-11 06:58:18,[N] New Open-Source Version Of ChatGPT â­•,LesleyFair,False,0.98,117,10zep6u,https://www.reddit.com/r/learnmachinelearning/comments/10zep6u/n_new_opensource_version_of_chatgpt/,8,1676098698.0,"GPT is getting competition from open-source.

A group of researchers, around the YouTuber [Yannic Kilcher](https://www.ykilcher.com/), have announced that they are working on [Open Assistant](https://github.com/LAION-AI/Open-Assistant). The goal is to produce a chat-based language model that is much smaller than GPT-3 while maintaining similar performance.

If you want to support them, they are crowd-sourcing training data [here](https://open-assistant.io/).

**What Does This Mean?**

Current language models are too big.

They require millions of dollars of hardware to train and use. Hence, access to this technology is limited to big organizations. Smaller firms and universities are effectively shut out from the developments.

Shrinking and open-sourcing models will facilitate academic research and niche applications.

Projects such as Open Assistant will help to make language models a commodity. Lowering the barrier to entry will increase access and accelerate innovation.

What an exciting time to be alive! 

Thank you for reading! I really enjoyed making this for you!  
The Decoding â­• is a thoughtful weekly 5-minute email that keeps you in the loop about machine research and the data economy. [Click here to sign up](https://thedecoding.net/)!"
140,learnmachinelearning,gpt-3,comments,2023-11-27 14:01:11,Are SOTA LLMs(LMMs?) going to be much smaller in the future?,open_23,False,0.72,3,1853m18,https://www.reddit.com/r/learnmachinelearning/comments/1853m18/are_sota_llmslmms_going_to_be_much_smaller_in_the/,8,1701093671.0,"Since most LLMs these days are becoming multi-modal, with capabilities to browse the web and parse information from given files, will they become much smaller as they'll need to be trained on less data?

Models like GPT-3, which has 175B parameters, are that big because they are trained on a ton of information from the internet which they can retrieve from their data for the user. Thats why GPT-4 is so useful, because it is trained on so many things, it can help on a wide range of topics.

But, now that GPT-4 has plugins, and also the ability to browse the web, will it need to be trained on so much data. If the user needs help on a particular topic, it can just search the web for the information and then present it to the user. I t would save a lot of training time and data.

For the purposes of it just being able to speak English correctly, it needs relatively little data. The TinyStories models, with 10-30M parameters, perform pretty decently as a LM. It only neededsimple english vocabulary to learn to speak it properly. So, in the future, will we see base SOTA models be 7-13B with multimodal vision, voice, file parsing, and most importantly, web browsing capabilities, which will perform as good as today's GPT-4?"
141,learnmachinelearning,gpt-3,comments,2023-07-07 14:29:33,Do I need to update anything on my PC to start using GPT-4 with the API?,123android,False,0.64,3,14t8vug,https://www.reddit.com/r/learnmachinelearning/comments/14t8vug/do_i_need_to_update_anything_on_my_pc_to_start/,7,1688740173.0,"I have a python app and was using ""gpt-3.5-turbo"" as my model value. It works fine with that.

I heard about the gpt-4 general availability today and say it's available to everyone, so I switched the value in my ""model"" variable to ""gpt-4"" and I started getting an invalid request error. Also tried ""gpt-4-0613"", same thing.

Do I need to update some local libraries or something like this?"
142,learnmachinelearning,gpt-3,comments,2020-08-15 10:49:38,GPT-3 and a Democratic Revolution in Tech,przemekc,False,0.67,1,ia59wo,https://www.youtube.com/watch?v=x82LW07FQbc,8,1597488578.0,
143,learnmachinelearning,gpt-3,comments,2023-04-22 05:51:13,Integrating Google search into OpenAI models like GPT-4,Ghost25,False,0.95,14,12uwd8p,https://www.reddit.com/r/learnmachinelearning/comments/12uwd8p/integrating_google_search_into_openai_models_like/,8,1682142673.0,"Thought I'd share an explanation of how I implemented Google search into my GPT-4 based chatbot.

Github here: https://github.com/sgreenb/pico_assistant

One extremally simple modification that dramatically improves the ability of a GPT to answer questions: letting it Google stuff.

Hereâ€™s a demo:

https://imgur.com/ZR6hvLg 1

The implementation works like this.

1. A user enters an input.
2. An agent called â€œExecutiveâ€ looks at the input and decides if an API like Spotify, Twillio, or Gmail is needed or if it can be answered by the chatbot alone.
3. If the chatbot is needed the input is first sent to a Google agent. The Google agentâ€™s system message looks like this:

```
{""role"":""system"", ""content"": ""You analyze a user's input to a large language model with \
training data that cuts off at September 2021. The current year is 2023. You decide how \
likely it is that a user's request will benefit from a Google search to help address the\
question. Respond with a number in the range 1-10, where 1 is very unlikely that a \
Google search would be beneficial, and 10 meaning a Google search is highly necessary.""}
```

This is quite fast, since it only needs to generate one or two tokens.

If the output is above some threshold (say 7), then we call another agent, the query agent, otherwise we return False and default to the normal chat agent.

```
    google_probability = int(completion.choices[0].message.content)
    if google_probability >= cutoff:
        search_results = trim_text(search_and_scrape(prompt))
        query_with_context = prompt + str(search_results)
        print(""\nPico: "", end='', flush=True)
        response = query_agent_stream(query_with_context)
        return response
    else:
        return False
```

When we call the query agent, we feed it the first part of a Google search we get from searching the input. We get that from the very simple trim_text and search_and_scrape functions that look like this:

```

def search_and_scrape(query):
    try:
        headers = {
            ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3""
        }
        url = f""https://www.google.com/search?q={query}""
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text()
            cleaned_text = ' '.join(text.split())
            return cleaned_text
        else:
            print(f""Failed to fetch search results for query: {query}, status code: {response.status_code}"")
            return None

    except Exception as e:
        print(f""Error fetching search results for query: {query}, error: {e}"")
        return None

def trim_text(text, start_index = 450, length=1500):
    return text[start_index:start_index + length]
```

The query agent has this system message:

```
{""role"":""system"", ""content"": ""You answer a user's question, given some text as context to help\
answer the question. The user request will be followed by the context. The context given is\
from the user's Google search results, it is current and up to date.\
Do not contradict the contents of the given text in your answer.""}
```

And thatâ€™s it. You can change the cutoff threshold or get more sophisticated with fetching web results. I hope you find this useful."
144,learnmachinelearning,gpt-3,comments,2024-02-04 10:19:14,What small open source LLM is best for conversations?,Sea_Skill_3479,False,1.0,3,1aikudt,https://www.reddit.com/r/learnmachinelearning/comments/1aikudt/what_small_open_source_llm_is_best_for/,8,1707041954.0,"What small open-source LLM is most effective for social media conversations? I attempted fine-tuning with Llama-2 7B-Q4, but it didn't work on my GPU(getting error-cuda out of memory ). Are there smaller, more suitable models for natural-sounding conversations that can be finetuned with small dataset? I discovered that the Bard response feels more natural than GPT-3.5. How can I get my response close to Bard?"
145,learnmachinelearning,gpt-3,comments,2023-03-02 16:47:40,Build ChatGPT for Financial Documents with LangChain + Deep Lake,davidbun,False,0.95,170,11g7h03,https://www.reddit.com/r/learnmachinelearning/comments/11g7h03/build_chatgpt_for_financial_documents_with/,8,1677775660.0,"https://preview.redd.it/h9r6hgvfucla1.png?width=2388&format=png&auto=webp&s=5432eac3eeed8583e4309af1fdc7ebecac705796

As the world is increasingly generating vast amounts of financial data, the need for advanced tools to analyze and make sense of it has never been greater. This is where [LangChain](https://github.com/hwchase17/langchain) and [Deep Lake](https://github.com/activeloopai/deeplake) come in, offering a powerful combination of technology to help build a question-answering tool based on financial data. After participating in a LangChain hackathon last week, I created a way to use Deep Lake, the data lake for deep learning (a package my team and I are building) with LangChain. I decided to put together a guide of sorts on how you can approach building your own question-answering tools with  LangChain and Deep Lake as the data store.

Read [the article](https://www.activeloop.ai/resources/ultimate-guide-to-lang-chain-deep-lake-build-chat-gpt-to-answer-questions-on-your-financial-data/) to learn:

1. What is LangChain, what are its benefits and use cases and how you can use to streamline your LLM (Large Language Model) development?  
2. How to use [\#LangChain](https://www.linkedin.com/feed/hashtag/?keywords=langchain&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7037082545263448064) and [\#DeepLake](https://www.linkedin.com/feed/hashtag/?keywords=deeplake&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7037082545263448064) together to build [\#ChatGPT](https://www.linkedin.com/feed/hashtag/?keywords=chatgpt&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7037082545263448064) for your financial documents.  
3. How Deep Lakeâ€™s unified and streamable data store enables fast prototyping without the need to recompute embeddings (something that costs time & money).  


I hope you like it, and let me know if you have any questions!"
146,learnmachinelearning,gpt-3,comments,2023-07-10 15:16:24,"ChatPDF: What ChatGPT Can't Do, This Can!",JunXiangLin,False,0.73,5,14vww3o,https://www.reddit.com/r/learnmachinelearning/comments/14vww3o/chatpdf_what_chatgpt_cant_do_this_can/,7,1689002184.0,"Believe many of people have been using **ChatGPT** for a while, and you are aware that although ChatGPT is powerful, it has the following limitations:

1. Unable to answer questions about events that occurred after **2021**.
2. Unable to directly upload your own data, such as **PDF, Excel, databases**, etc.
3. Inaccurate in performing **mathematical calculations**.

**Langchain** is a recent trending open-source project, which is a framework for developing Large Language Models (LLMs) applications. It supports the following:

1. Connecting LLM models with **external data sources**, such as PDF, Excel, databases, etc.
2. Allowing interaction between LLM models and other tools, such as **Google search**, enabling internet connectivity.
3. Rapid development of LLM model applications.

Today, I'd like to share a project called **ChatPDF**(strickly called **docGPT**, there're some different), built using the Langchain framework. It allows users to upload local documents and ask questions to the LLM model. In this tool, you can ask AI to summarize articles or inquire about any information in the document. Moreover, by leveraging the Langchain Agent functionality, the LLM model can collaborate with the Google Search API, enabling users to ask questions about current topics!

The project provides a detailed guide on how to create your own **docGPT**. It is built using the Langchain framework and Python Streamlit, which is a free and fast way to create online services. As long as you have an OPENAI API KEY, feel free to give it a try!

I encourage everyone to pay attention to the [Langchain open-source project](https://github.com/hwchase17/langchain) and leverage it to achieve tasks that ChatGPT cannot handle.

[Github Repository](https://github.com/Lin-jun-xiang/docGPT-streamlit/tree/main)

[ChatPDF Application](https://docgpt-app.streamlit.app/)

&#x200B;

https://preview.redd.it/q906a7imm5bb1.png?width=2560&format=png&auto=webp&s=acef45049bab805038f876eea56cc371b8a9a83a"
147,learnmachinelearning,gpt-3,comments,2023-03-30 19:44:32,Personalize Your Own Language Model with xTuring - A Beginner-Friendly Library,x_ml,False,1.0,61,126x6ua,https://www.reddit.com/r/learnmachinelearning/comments/126x6ua/personalize_your_own_language_model_with_xturing/,7,1680205472.0,"Hi everyone,  


If you are interested in customizing your own language model but don't know where to start, try  [xTuring](https://github.com/stochasticai/xturing).  


xTuring's goal is to empower individuals to fine-tune LLM for their specific tasks with as little as 5 lines of code. With xTuring, you can perform high and low precision fine-tuning with a variety of models, including LLaMA, OPT, Cerebras-GPT, Galactica, BLOOM, and more.   


You can also generate your OWN datasets using powerful models like GPT-3 to train a much smaller model on YOUR specific task. With the latest version, you can also use terminal and web interface to chat with your models.  


Please do check out the repo and show your support if you like our work. Would love if you can also contribute by adding models, raising issues or raising PRs for fixes.  


xTuring Github: [https://github.com/stochasticai/xturing](https://github.com/stochasticai/xturing)

If you are interested in getting involved, I am happy to help you on our Discord: [https://discord.gg/TgHXuSJEk6](https://discord.gg/TgHXuSJEk6)

https://i.redd.it/mvxb7i5fixqa1.gif"
148,learnmachinelearning,gpt-3,comments,2023-06-03 10:28:56,Math for ML,son_of_ur_son,False,1.0,2,13z8kt2,https://www.reddit.com/r/learnmachinelearning/comments/13z8kt2/math_for_ml/,7,1685788136.0,"Hello guys!

I'm new to ML and i am planning to learn linear algebra and differential equations, which i believe are invaluable in ML/DL/AI , in summer after 1st year final in uni. I also want to learn statistics but I will likely to find overwhelming to learn all of 3 combos simultaneously so I'll take my time and learn it in long-term. After I'm finished, I will dive in statistics. Here is the question:

I am currently learning Machine Learning with hands-on machine learning book of Aurelius. what i find it difficult in it is that I don't understand statistical concepts behind all of those codes, I can't visualise how and why we are using this and that in order to achieve these. I can't understand why I got this output, how the data was divided and then stratified shuffle splitted, RMSE, MSE and so on, I got a lot questions that I can't grasp even with ChatGPT, Bing, Bard or other ML, Stat-based youtube channels and blogs. I believe it's normal as I don't know stat, what is happening under the hood. So I have to learn statistics. But what i have noticed in classical statistical books is that mostly these books don't contain concepts that I am using in my projects which makes me think that statistics is a really-really broad field that even evolves nowadays. So I have to learn statistics like for number years. How can I do that? How many statistics are there? Foundational, Advanced is that it? Can i learn stat just  conceptualizing for yet without solving problems yet? How could you advice me learning statistics after learning linear algebra and diff eqs or maybe together?"
149,learnmachinelearning,gpt-3,comments,2022-03-24 11:47:46,Few-shot NER: entity extraction without annotation and training based on GPT,juliensalinas,False,0.86,5,tm43o9,https://www.reddit.com/r/learnmachinelearning/comments/tm43o9/fewshot_ner_entity_extraction_without_annotation/,7,1648122466.0,"Hello all,

After  1 year working extensively with GPT models (GPT-3, GPT-J, and  GPT-NeoX), I think I now have a good view on what these NLP models are  capable of. It appears that many traditional NLP tasks can  now be  achieved thanks to these large language models thanks to few-shot  learning (aka ""prompting"", or ""prompt engineering"").

NER  is a very good candidate because, thanks to these models, it is  possible to extract any type of entity without ever annotating and  training a new model. Annotation has always been a challenge that has  caused many entity extraction projects to simply fail, because it is a  long and tedious process.

In this article, I'm showing how easy it is to perform NER thanks to GPT and few-shot learning, without any annotation process: [https://nlpcloud.io/few-shot-ner-entity-extraction-without-annotation-training-based-on-gpt.html](https://nlpcloud.io/few-shot-ner-entity-extraction-without-annotation-training-based-on-gpt.html?utm_source=reddit&utm_campaign=fe5u8885-fd8e-21eb-ba80-5242ac13d5ja)

If  you also experimented with entity extraction with GPT models, I would  love to hear your thoughts. Are you, like I am, impressed by the  results? And do you think it means that annotation is a thing from the  past?

Thanks!"
150,learnmachinelearning,gpt-3,comments,2022-05-13 23:17:56,Can we write codes automatically with GPT-3?,shyamcody,False,0.5,0,up43b5,https://shyambhu20.blogspot.com/2022/05/can-we-write-codes-automatically-with.html,7,1652483876.0,
151,learnmachinelearning,gpt-3,comments,2022-02-25 11:23:37,How to handle final layer dimension in case of Multi class classification?,VanishedGradients,False,0.81,3,t11qjr,https://www.reddit.com/r/learnmachinelearning/comments/t11qjr/how_to_handle_final_layer_dimension_in_case_of/,7,1645788217.0,"Hello Redditors, 

I'm trying to solve a problem related to Multi Label classification.

Model Struture

```
  (0): Embedding(50257, 1024) #Using pretrained embeddings from GPT-2
  (1): Linear(in_features=1024, out_features=64, bias=True)
  (2): ReLU()
  (3): Dropout(p=0.1, inplace=False)
  (4): Linear(in_features=64, out_features=64, bias=True)
  (5): ReLU()
  (6): Dropout(p=0.1, inplace=False)
  (7): Linear(in_features=64, out_features=31, bias=True)
  (8): Sigmoid()
```
Number of Classes: 31
Loss: Binary Cross Entropy 
Input Shape: (batch_size,max_length) -> (8,64)
Output Shape: (8,64,31)
Label Shape (one hot encoded ) : (1,n_classes) -> (1,31)

I'm guessing i need to transform Output Shape to Label Shape to be able to calculate loss via Binary Cross Entropy, How should I do it?
Edit: Title should have Multi Label Classification, instead of Multi Class

Edit 2:
Okay I figured out the problem, It was with the layer nn.Embedding which add another dimension, now that I've added nn.Flatten() right next to it. It works fine! Thanks Everybody!"
152,learnmachinelearning,gpt-3,comments,2021-08-03 06:46:05,Tinder bio generation with OpenAI GPT-3 API,shyamcody,False,1.0,2,owxtwt,https://shyambhu20.blogspot.com/2021/08/tinder-bio-generation-with-openai-gpt-3.html,6,1627973165.0,
153,learnmachinelearning,gpt-3,comments,2023-03-24 10:44:06,How to use embeddings to query PDF doucments using NLP,G1bs0nNZ,False,1.0,2,120gikm,https://www.reddit.com/r/learnmachinelearning/comments/120gikm/how_to_use_embeddings_to_query_pdf_doucments/,5,1679654646.0,"Have a project that I'm looking at undertaking. Long story short, but I have about 100-150 PDF documents that relate to a civil case that I'm undertaking on my own, against a government insurance provider, relating to service failures on their part. My finances are limited, due to the nature of the claim. My end goal is to be able to load in the documents, and then query these documents using natural language to be able to retrieve the information.  


I want to do something similar to what [askcorpora.com](https://askcorpora.com) does, and I've gotten as far as understanding that I could use GPT-3 and embeddings to do so, but relevant/recent documentation is hard to find. I have strong technical skills, so could do a certain level of coding, but thought I'd ask here for some good starting points.  


Any help/support would be much appreciated"
154,learnmachinelearning,gpt-3,comments,2023-06-22 23:53:45,What is a policy in Reinforcement Learning (ChatGPT)?,u2uu,False,1.0,4,14gj3fq,https://www.reddit.com/r/learnmachinelearning/comments/14gj3fq/what_is_a_policy_in_reinforcement_learning_chatgpt/,6,1687478025.0,"Hey,

i read about the RLHF in ChatGPT. And in Step 1 there is the title saying: ""training a supervised policy"".

And in step 3 is it then saying: ""The PPO model is initalized from the supervised policy.""

I really dont understand exactly what is meant with policy. It is the neural network itself of the LLM? Is ist the SFT Model from Step 1? 

And if the ""PPO-Model is initalized"" is this in the beginning exactly like the SFT-Model from step 1? 

I read a lot about ""functions"" regarding to ""policy"". But sometimes i read that the policy is a neural network. So i am really confused. Is the policy a seperate entity? Is it not the neural network of the LLM itself?


I am sorry for my english. I would be very happy for help!"
155,learnmachinelearning,gpt-3,comments,2024-01-18 14:44:44,Project: QA on any PDF document using RAG and VectorDB,Amazing_Life_221,False,0.75,11,199rq4b,https://i.redd.it/c0cfiqr0o7dc1.jpeg,6,1705589084.0,"The Smart PDF Reader is a comprehensive project that harnesses the power of the Retrieval-Augmented Generation (RAG) model over a Large Language Model (LLM) powered by Langchain. Additionally, it utilizes the Pinecone vector database to efficiently store and retrieve vectors associated with PDF documents. This approach enables the extraction of essential information from PDF files without the need for training the model on question-answering datasets.

Find the GitHub repo: [here](https://github.com/Arshad221b/RAG-on-PDF)"
156,learnmachinelearning,gpt-3,comments,2024-01-17 04:38:17,Architecture advice for gaze prediction,Goatman117,False,1.0,3,198o2ga,https://www.reddit.com/r/learnmachinelearning/comments/198o2ga/architecture_advice_for_gaze_prediction/,6,1705466297.0,"Hey all, I'm pretty new to ML (going through the [fast.ai](https://fast.ai) course at the moment, and slowly getting familiar with pytorch), and I'm attempting to build an eye tracking model that predicts the on-screen coordinates of my gaze via webcam feed.

I've got a small dataset together of \~6K images and coordinate pairs, and I managed to finetune a resnet-18 successfully with a pixel error margin of around 160 pixels.

At the moment I'm trying to build a pytorch convolutional net with hopefully far less parameters for the same task, but I'm unsure on what a good architecture could look like. I've trained a small resnet from scratch with pytorch (3 residual 3x3 stride 2 convolutional blocks with some other pieces GPT recommended like batchnorm and max pooling), and managed to get around 130 pixel error, but I feel like my architecture is wrong.

Logically I think the key features the model needs to infer to predict the coordinates are:  
Screen dimensions  
Resolution (currently it's just spitting out the actual pixel values, I've tried softmax too but haven't noticed an improvement)  
My distance to the screen  
Eye rotation  
Camera offset (it's centred at the top of my monitor.  


I'm sure there's more, but my concern here is that a resnet will lose important pixel features through the pass that it needs in order to work out things like eye rotation. I know resnets pass the identity throughout the blocks, but the image width and height are still being reduced for efficiency, so I'm a little unclear on how to combat that.  


  
Basically after any advice or pointers here, sorry if it's too vague, I'm just after any thoughts on what the bottlenecks here are and how I can solve them.

Cheers!"
157,learnmachinelearning,gpt-3,comments,2023-02-21 23:18:46,"How big was GPT-3.5's training dataset, and are there any good heuristics for how large an ML dataset needs to be for it to be good?",TikkunCreation,False,0.93,53,118iccl,https://www.reddit.com/r/learnmachinelearning/comments/118iccl/how_big_was_gpt35s_training_dataset_and_are_there/,6,1677021526.0,"Say I want to do a model for fixing bugs in code. How many examples do I need for it to be good?

Or say I want to do a model for scoring boxing matches. How many examples do I need for it to be good?"
158,learnmachinelearning,gpt-3,comments,2023-12-29 09:33:17,"Beginner here, i want to transition from Electrical engineering to Machine learning for my masters. Please Help.",ColdSpirit117,False,1.0,2,18tjb55,https://www.reddit.com/r/learnmachinelearning/comments/18tjb55/beginner_here_i_want_to_transition_from/,6,1703842397.0,"I know some of the mathematics involved, like multivariable calculus ,linear algebra, optimization principles, Fourier analysis, DFT,FFT etc. Please mention any specific topics and things which i should study to ensure that i am well versed in all the mathematical tools required for learning ML.  


I also know some basic coding in MATLAB and Python, please mention things which i should study in them, to make me write efficient ML code, i have come across some libraries like pandas and numpy during my study but didn't got time to go through them completely.  


Also if you mention some more specific basic and advanced things that i should know about, that would very thankful of you. Also any mentality advice, that i should take while studying this will be very helpful   


My motivations to study ML are these:  
1. I with my group, made a group project about a Drone based waste detection using image processing and machine learning, I understood the gist of the project , but as i didn't  had   
 too much idea about how to code, i just couldn't understand how practically do it, and how to make a data set for it which will, ensure good detection(we were barely able to make something to show to our advisers). This project got me interested in computer vision and ML.   

2.The second reason is because i want to go either in finance sector(How to audit firms check for any fraud or red flags using ML, or prediction analysis for a certain company or firm using ML, for macro -economical analysis and predictions for a state or country, optimal allocation of resources etc.) or in research(can we accurately realize the flow of a turbulent fluid using ML?, Optimizing heavy machines and their usage for better power supply and power quality, and some other research questions on physics and biology), and both require good amount of knowledge of ML.  


3. After watching how ChatGPT and other AI Chatbots that can generate pictures ,text, videos and even code. It has made me think , how does this work, how can i make something like this? It had really fascinated me and made me more interested in this field.  


4.After the advent of jobs in this market, i think most of the IT professionals will be shifting towards this market ,and knowing ML will become a Norm for working.   


Any help is appreciated"
159,learnmachinelearning,gpt-3,comments,2020-09-10 19:08:30,"Confused about what Zero-Shot, One-Shot, and Few-Shot means in the GPT-3 paper",Archa3opt3ryx,False,0.92,9,iq9yoa,https://www.reddit.com/r/learnmachinelearning/comments/iq9yoa/confused_about_what_zeroshot_oneshot_and_fewshot/,5,1599764910.0,"I mostly followed along with everything in the [GPT-3 paper](https://arxiv.org/pdf/2005.14165.pdf), but I'm confused about the beginning of section 2. They talk here about providing a certain number of ""demonstrations"" to the model, either zero, one, or several, prior to asking the model to perform the task. However, they also say that don't perform gradient updates to the model after these demonstrations. 

If the model weights aren't changed as a result of the demonstrations, what's the point of the demonstrations? How is the model learning anything from the demonstrations if it can't perform weighting updates? It sounds to me like it's just asking the model to perform a task where a correct output is known, but then not feeding the result back into the model. So how are the demonstrations helping the model perform the task better?"
160,learnmachinelearning,gpt-3,comments,2022-07-20 12:55:42,No-Code AI: Integrate the NLP Cloud API Into A Bubble.io App,juliensalinas,False,0.57,1,w3ln6f,https://www.reddit.com/r/learnmachinelearning/comments/w3ln6f/nocode_ai_integrate_the_nlp_cloud_api_into_a/,5,1658321742.0,"Hello,

Thanks   to the rise of no-code platforms like Bubble.io and the creation of  brand new cutting-edge AI models based on Transformers, like GPT-3,  GPT-J, GPT-NeoX, Bart, and more, it is now possible to create advanced  AI applications without writing a single line of code.

I just made an article that shows how to connect the [NLP Cloud API](https://nlpcloud.com/) to a [Bubble.io](https://bubble.io/)   application  in order to perform advanced AI operations like   summarization,  paraphrasing, NER, question answering, blog post   generation, product  description creation, and much more:

[https://nlpcloud.com/no-code-ai-integrate-nlp-cloud-api-into-bubble-io.html](https://nlpcloud.com/no-code-ai-integrate-nlp-cloud-api-into-bubble-io.html?utm_source=reddit&utm_campaign=3a5u9995-ld8e-21eb-ca8-6242ac13d5ja)

I hope that you will find this tuto useful!

Please don't hesitate to comment!

Julien"
161,learnmachinelearning,gpt-3,comments,2024-01-30 18:40:34,"In the era of GPT, building an effective word similarity search in 2023",stoicbats_,False,0.67,1,1aevr5z,https://www.reddit.com/r/learnmachinelearning/comments/1aevr5z/in_the_era_of_gpt_building_an_effective_word/,5,1706640034.0,"Hello everyone,

I am currently tackling a project that involves a list of various brand names within a specific domain. For instance:

`domain_names = ['xyz', 'yza', 'tra', 'world']`

My goal is to develop a search s capable of analyzing word similarity. Specifically, the system should accept a word and return the top 'k' words that are most similar to it. I have experimented with OpenAI embeddings, particularly the latest Embedding Version 3 (3072 dimensions), but the results have been unsatisfactory.

Could someone suggest the most effective approaches for searching word-level similarities ?In the era of GPT, Would it be advisable to train my own Word2Vec model?"
162,learnmachinelearning,gpt-3,comments,2023-10-13 14:23:10,Authoring another course about LLMs. Learn by Doing LLM Projects.,pmartra,False,0.88,25,176zx1m,https://www.reddit.com/r/learnmachinelearning/comments/176zx1m/authoring_another_course_about_llms_learn_by/,5,1697206990.0,"Hi, I'm working on a course about LLMs on GitHub, it's totally free and under MIT license,  So there are no restrictions.

Here the link: [https://github.com/peremartra/Large-Language-Model-Notebooks-Course](https://github.com/peremartra/Large-Language-Model-Notebooks-Course)

I'm still working on It, but now I'm feeling comfortable with the variety and quality of the content. By the moment is a small repository with just 80 Stars.

My intention is to make the course more accessible to a wider audience, and, if possible, encourage  reporting any issues  encounter or suggesting improvements through the 'Discussion' section.

I'm eager to receive feedback.

Now, I'll provide an overview of the currently available content, and then I'll share a couple of questions I have about how to proceed with the course.

[Large Language Models Course: Learn by Doing LLM Projects.](https://github.com/peremartra/Large-Language-Model-Notebooks-Course)

* Introduction to LLM with OpenAI.
   * Create a first Chatbot using FPT 3.5.
   * Create a Natural Language to SQL Translator using OpenAI.
* Vector Databases with LLM.
   * Influencing Language Models with Information stored in ChromaDB.
* LangChain & LLM Apps.
   * RAG. Use the Data from Dataframes with LLMs.
   * Create a Moderation System using LangChain.
      * OpenAI.
      * GPT\_j.
      * LLama-2.
   * Create a Data Analyst Assistant using a LLM Agent.
* Evaluating LLMs
   * Evaluating Summarization with ROUGE.
* Fine-Tuning & Optimization.
   * Prompt-tuning using PEFT.
   * Fine-Tuning with LoRA.
   * Fine-Tuning a Large Model in a GPU using QLoRA. 

That's all for the moment, but I'm adding new content regularly. I'm working on it only in my spare time (mainly nights when the family goes to sleep).

\_\_\_

I have a doubt, I don't know if add some information about platforms like W&B or Cohere?  or maybe it is a better idea to stay with more Open-Source libraries?

On the other hand, my intention is to develop a couple of projects utilizing the techniques covered in the initial part of the course (which I am currently working on).

Some of these projects will be hosted in the cloud on major platforms such as Azure or GCP, or AWS. Any preference?

Furthermore, there is a plan to create a third section that explains how Large Language Models (LLMs) fit into large-scale enterprise solutions, defining architectures in which LLMs are used but are not the sole components of the project.

I don't intend to create a community outside of GitHub, but I would like the repository to have more activity and not be the one determining the course's direction.

Hope you like it, and lease, feel free to contribute.

&#x200B;"
163,learnmachinelearning,gpt-3,comments,2023-02-20 18:45:28,Can Transformer Architecture be simplified for generative tasks?,randy-adderson,False,0.67,2,117gxp6,https://www.reddit.com/r/learnmachinelearning/comments/117gxp6/can_transformer_architecture_be_simplified_for/,5,1676918728.0,"If the task is simply to generate data given a context of data generated so far (such as in the case GPT-3), then can the architecture be simplified?

(The separation of the encoder and decoder layers seems arbitrary when they are processing the exact same data)"
164,learnmachinelearning,gpt-3,comments,2023-02-13 09:48:00,Help for AutoML/VertexAI's error message: The replica workerpool0-0 exited with a non-zero status of 13.,Mad-Independence,False,0.67,1,1114ibm,https://www.reddit.com/r/learnmachinelearning/comments/1114ibm/help_for_automlvertexais_error_message_the/,4,1676281680.0,"Hi all, I am doing a machine learning course on Coursera and I am using AutoML to train my dataset. While doing so, I keep getting the same error message:

>The replica workerpool0-0 exited with a non-zero status of 13. To find out more about why your job exited please check the logs:

1. I have tried looking online and i can't seem to find anything about error code ""13""
2. I have also tried to start from scratch and I keep ending up on the same issue
3. I have made sure I am giving all the correct permissions
4. ChatGPT-ed as well, and it further confirmed it's an accessibility issue

[Error Message](https://preview.redd.it/7plfms99gxha1.png?width=774&format=png&auto=webp&s=d8773b1c5501d87ef9ce7cebbac63a94a2a79194)

&#x200B;

[Permissons](https://preview.redd.it/aal6gg5mhxha1.png?width=964&format=png&auto=webp&s=3755a1ebb52981822f65e64daa09767d1a284983)

&#x200B;

[Error log](https://preview.redd.it/zeb0xskjfxha1.png?width=3290&format=png&auto=webp&s=81d803f12e1d4a115226290e849ac4ddbd5d0c51)"
165,learnmachinelearning,gpt-3,comments,2023-09-30 15:01:31,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.97,81,16w93bx,https://www.reddit.com/r/learnmachinelearning/comments/16w93bx/this_week_in_ai_all_the_major_ai_developments_in/,4,1696086091.0,"1. **Meta AI** presents **Emu**, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal.
2. **Meta AI** researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16kâ€™s overall performance on a suite of long-context tasks.
3. **Abacus AI** released a larger 70B version of **Giraffe**. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens\].
4. **Meta** announced:  

   1. **Meta AI** \- a new AI assistant users can interact with on WhatsApp, Messenger and Instagram. Will also be available on Ray-Ban Meta smart glasses and Quest 3, Metaâ€™s mixed reality headset.
   2. **AI stickers** that enable users to generate customized stickers for chats and stories using text. Powered by Llama 2 and the new foundational model for image generation, Emu.
   3. **28 AI characters**, each with a unique personality that users can message on WhatsApp, Messenger, and Instagram.
   4. New AI editing tools, **restyle** and **backdrop** in Instagram.
   5. **AI Studio** \- a platform that supports the creation of custom AIs by coders and non-coders alike.
5. **Cerebras** and **Opentensor** released Bittensor Language Model, â€˜**BTLM-3B-8K**â€™, a new 3 billion parameter open-source language model with an 8k context length trained on 627B tokens of SlimPajama. It outperforms models trained on hundreds of billions more tokens and achieves comparable performance to open 7B parameter models. The model needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models and is available with an Apache 2.0 license for commercial use.
6. **OpenAI** is rolling out, over the next two weeks, new voice and image capabilities in ChatGPT enabling ChatGPT to understand images, understand speech and speak. The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. .
7. **Mistral AI**, a French startup, released its first 7B-parameter model, **Mistral 7B**, which outperforms all currently available open models up to 13B parameters on all standard English and code benchmarks. Mistral 7B is released in Apache 2.0, making it usable without restrictions anywhere.
8. **OpenAI** has returned the ChatGPT browsing feature for Plus subscribers, enabling ChatGPT to access internet for current information. It was disabled earlier as users were able to deploy it to bypass the paywalls of leading news publishers.
9. **Microsoft** has released **AutoGen** \- an open-source framework that enables development of LLM applications using multiple agents that can converse with each other to solve a task. Agents can operate in various modes that employ combinations of LLMs, human inputs and tools.
10. **LAION** released **LeoLM**, the first open and commercially available German foundation language model built on Llama-2
11. Researchers from **Google** and **Cornell University** present and release code for DynIBaR (Neural Dynamic Image-Based Rendering) - a novel approach that generates photorealistic renderings from complex, dynamic videos taken with mobile device cameras, overcoming fundamental limitations of prior methods and enabling new video effects.
12. **Cloudflare** launched **Workers AI** (an AI inference as a service platform), **Vectorize** (a vector Database) and **AI Gateway** with tools to cache, rate limit and observe AI deployments. Llama2 is available on Workers AI.
13. **Amazon** announced the general availability of **Bedrock**, its service that offers a choice of generative AI models from Amazon itself and third-party partners through an API.
14. **Google** announced itâ€™s giving website publishers a way to opt out of having their data used to train the companyâ€™s AI models while remaining accessible through Google Search.
15. **Spotify** has launched a pilot program for AI-powered voice translations of podcasts in other languages - in the podcasterâ€™s voic. It uses OpenAIâ€™s newly released voice generation model.
16. **Getty Images** has launched a generative AI image tool, â€˜**Generative AI by Getty Images**â€™, that is â€˜commerciallyâ€‘safeâ€™. Itâ€™s powered by Nvidia Picasso, a custom model trained exclusively using Gettyâ€™s images library.
17. **Optimus**, Teslaâ€™s humanoid robot, can now sort objects autonomously and do yoga. Its neural network is trained fully end-to-end.
18. **Amazon** will invest up to $4 billion in Anthropic. Developers and engineers will be able to build on top of Anthropicâ€™s models via Amazon Bedrock.
19. **Google Search** indexed shared Bard conversational links into its search results pages. Google says it is working on a fix.
20. **Pika** Labs' text-to-video tool now lets users encrypt a message in a video\].

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
166,learnmachinelearning,gpt-3,comments,2022-12-28 17:37:46,chatGPT peeps- anyone else learn new stuff best by actually building something?,bruclinbrocoli,False,0.7,5,zxfnga,https://www.reddit.com/r/learnmachinelearning/comments/zxfnga/chatgpt_peeps_anyone_else_learn_new_stuff_best_by/,4,1672249066.0,"[This intro to chatGPT](https://buildspace.so/notes/intro-to-chatgpt) has some cool (free) challenges at the end to build a telegram bot, a business email generator, or a writing assistant.

What else have people found to learn bout chatGPT that's not just theory?

&#x200B;

https://preview.redd.it/smxv4mzldo8a1.png?width=1026&format=png&auto=webp&s=43081abbfcad449817e520b5e92ba599a18a1525"
167,learnmachinelearning,gpt-3,comments,2022-02-03 18:39:05,[Project] Refining the Natural language processing course - Feedback v2 and thank you,sb2nov,False,0.91,37,sjqogi,https://www.reddit.com/r/learnmachinelearning/comments/sjqogi/project_refining_the_natural_language_processing/,2,1643913545.0,"Iâ€™m Sourabh, I lead one of the core Tensorflow teams at Google Brain and worked on data products at Coursera with Andrew Ng. Kaushik Rangadurai, ML Engineer at Facebook and I are leading a live, cohort based course on NLP starting March 14th. [https://corise.com/course/natural-language-processing](https://corise.com/course/natural-language-processing).

This is the second run of the class and we learned a lot from the feedback of the reddit community from the first run in November. Some of the changes we're making from the previous iteration:

1/ More focus on transformers and less on RNN/LSTM as hugging face is becoming the defacto for any nlp.

2/ Pytorch lightning has some really easy to use interfaces so better organizing the boiler plate code.

3/ OpenAI has opened the GPT-3 API so a deeper dive into current possibilities.

Would love to continue getting feedback and build this to be a great resource. The plan is to open the content after we refine it to a degree we're happy with. You can join the course (capped at about 30 students) at the link above. If youâ€™re open to giving feedback on the class on how we can do better, happy to give a discount."
168,learnmachinelearning,gpt-3,comments,2020-07-28 22:34:50,Trying to run gpt-2 playground but missing tensorflow.contrib,roll4LegalDmges,False,0.76,2,hzoo6t,https://www.reddit.com/r/learnmachinelearning/comments/hzoo6t/trying_to_run_gpt2_playground_but_missing/,4,1595975690.0,"Greetings fellow learners,

I found a Google Colab found here: [https://colab.research.google.com/github/ilopezfr/gpt-2/blob/master/gpt-2-playground\_.ipynb](https://colab.research.google.com/github/ilopezfr/gpt-2/blob/master/gpt-2-playground_.ipynb)

I've copied it to my Google Drive and started pressing play on the code blocks, however on Step 2 the following error is output:

    2020-07-28 22:18:40.513677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
    Traceback (most recent call last):
      File ""src/generate_unconditional_samples.py"", line 9, in <module>
        import model, sample, encoder
      File ""/content/gpt-2/gpt-2/gpt-2/src/model.py"", line 3, in <module>
        from tensorflow.contrib.training import HParams
    ModuleNotFoundError: No module named 'tensorflow.contrib'

I'm not really sure where to go from here beyond trying a different colab example. I'm very new to colab, python and gpt. I pretty much know how to push the run button and restart the runtime when it is suggested.

After googling the issue I can only surmise I need to be using an older version of tensorflow.contrib maybe? But instructions are unclear :(

I really like this Google Colab because the authors seem to have an example for every use case I can think of for gpt usage so I though it would be a good place to start but maybe the colab needs an update, not sure."
169,learnmachinelearning,gpt-3,comments,2022-12-12 02:28:30,"I trained GPT-3 to think like Paul Graham, Elon Musk, and Steve Jobs",alistairmcleay,False,0.53,1,zjjsn7,http://www.aiprotege.com,4,1670812110.0,
170,learnmachinelearning,gpt-3,comments,2023-08-14 11:47:27,Tips for training off spectrogram images for a desired text output?,getSAT,False,1.0,2,15qsg28,https://www.reddit.com/r/learnmachinelearning/comments/15qsg28/tips_for_training_off_spectrogram_images_for_a/,3,1692013647.0,"I have a large dataset of music and corresponding timing points for beat drops in a song.

I want to create a model that can predict my `timings` column based on any given song.

My idea so far is to convert the music into a spectrogram image so it's easier for AI to understand. Then I would fine tune a model like GPT-3 for the timing points, but other than that I'm lost. Especially the part where how do I even train if one of my columns is an image and not text?

If training off GPT3 is not possible is there some AutoML service I can feed this data into? I do have programming experience but not with AI or data science. My dataset looks something like:


|image|timings|
|--|--|
|song1.png|184,192,577,1,0328,192,996,1,0184,192,1416,1,0328,192,1835,1,0256,192,2255,1,4256,192,2674,1,4256,192,4563,1,4256,192,6451,12,0,812964,88,8968,5,064,88,9178,1,0136,88,9388,1,0136,88,9597,1,0208,88,9807,1,0208,88,10017,1,0280,88,10227,1,4|
|song2.png|280,232,10646,5,0280,232,10856,1,0208,232,11066,1,0208,232,11276,2,0208:152,2,52.5136,232,11695,1,0136,232,11905,1,4136,376,12325,5,0136,376,12535,1,064,376,12744,1,464,376,12954,1,0136,376,13164,1,0136,376,13374,1,064,376,13583,1,464,376,13793,1,0|
|song3.png|136,376,14003,1,0136,376,14213,1,0208,376,14423,1,4208,376,14632,1,0280,376,14842,1,4400,280,15681,5,0400,280,15891,1,0400,208,16101,1,0400,208,16311,1,0400,136,16521,2,4176:136,1,210|
|song4.png|248,192,54702,5,0248,192,55051,1,0248,192,55400,1,0248,192,55748,1,0248,192,56097,1,0248,192,56446,1,0248,192,56795,1,0248,192,57144,1,0248,192,57493,5,2248,192,57667,1,2248,192,57841,1,2248,192,58016,1,2|"
171,learnmachinelearning,gpt-3,comments,2024-02-13 19:38:44,"Predicted output after decoding is always empty strings in a list of tokens, but prediction looks fine.",asoulsghost,False,0.33,0,1aq2dya,https://www.reddit.com/r/learnmachinelearning/comments/1aq2dya/predicted_output_after_decoding_is_always_empty/,3,1707853124.0,"Predicted output after decoding is always empty strings in a list of tokens, but prediction looks fine.

I created a new project to debug with, my real one is much more complicated, but this code is just to show my issue:

\`\`\`import tensorflow as tf  
import numpy as np

from keras.callbacks import EarlyStopping  
from keras.layers import Bidirectional, Dropout, BatchNormalization, Embedding, LSTM, Dense  
from keras.optimizers import Adam  
from keras.regularizers import l2  
from keras.models import Sequential  
from keras.preprocessing.sequence import pad\_sequences  
from sklearn.model\_selection import train\_test\_split

user\_prompts = np.array(\[  
""What's your favorite animal?"",  
""What's your favorite movie?"",  
""What's your favorite book?"",  
""What's your favorite season?"",  
""What's your favorite hobby?"",  
""What's your favorite sport?"",  
""What's your favorite music genre?"",  
""What's your favorite dessert?"",  
""What's your favorite holiday?"",  
""What's your favorite beverage?"",  
""What's your favorite place to relax?"",  
""What's your favorite childhood memory?"",  
""What's your favorite superhero?"",  
""What's your favorite board game?"",  
""What's your favorite fruit?"",  
""What's your favorite vegetable?"",  
""What's your favorite type of weather?"",  
""What's your favorite clothing brand?"",  
""What's your favorite type of transportation?"",  
""What's your favorite quote?""  
\])

gpt\_responses = np.array(\[  
""I love elephants!"",  
""My favorite movie is The Shawshank Redemption."",  
""My favorite book is 1984 by George Orwell."",  
""I enjoy the crisp air of autumn."",  
""My favorite hobby is painting."",  
""I'm a fan of basketball."",  
""I enjoy listening to classical music."",  
""My favorite dessert is cheesecake."",  
""I love celebrating Christmas!"",  
""My favorite beverage is iced coffee."",  
""I love relaxing by the beach."",  
""One of my favorite childhood memories is building sandcastles."",  
""My favorite superhero is Batman."",  
""I enjoy playing Monopoly with friends."",  
""I love strawberries!"",  
""Broccoli is my favorite vegetable."",  
""I enjoy sunny days with a light breeze."",  
""I like wearing clothes from Zara."",  
""I enjoy traveling by train."",  
""One of my favorite quotes is 'Be yourself; everyone else is already taken.' - Oscar Wilde""  
\])

user\_tokenizer = tf.keras.preprocessing.text.Tokenizer()  
user\_tokenizer.fit\_on\_texts(user\_prompts)  
user\_sequences = user\_tokenizer.texts\_to\_sequences(user\_prompts)

with open('tokenizers/user\_tokenizer.json', 'w') as f:  
f.write(user\_tokenizer.to\_json())

gpt\_tokenizer = tf.keras.preprocessing.text.Tokenizer()  
gpt\_tokenizer.fit\_on\_texts(gpt\_responses)  
gpt\_sequences = gpt\_tokenizer.texts\_to\_sequences(gpt\_responses)

max\_sequence\_length\_user = max(len(seq) for seq in user\_sequences)  
max\_sequence\_length\_gpt = max(len(seq) for seq in gpt\_sequences)  
max\_sequence\_length = max(max\_sequence\_length\_user, max\_sequence\_length\_gpt)

padded\_user\_sequences = pad\_sequences(user\_sequences, maxlen=max\_sequence\_length, padding='post')  
padded\_gpt\_sequences = pad\_sequences(gpt\_sequences, maxlen=max\_sequence\_length, padding='post')

def normalize(arr, range):  
norm\_arr = \[\]  
t\_min = range\[0\]  
t\_max = range\[1\]  
diff = t\_max - t\_min  
diff\_arr = np.max(arr) - np.min(arr)  
for i in arr:  
temp = (((i - np.min(arr)) \* diff) / diff\_arr) + t\_min  
norm\_arr.append(temp)  
return norm\_arr

range\_to\_normalize = (0, 1)  
normalized\_input\_sequences = np.array(\[normalize(padded\_user\_sequence, range\_to\_normalize) for padded\_user\_sequence in padded\_user\_sequences\])  
normalized\_output\_sequences = np.array(\[normalize(padded\_gpt\_sequence, range\_to\_normalize) for padded\_gpt\_sequence in padded\_gpt\_sequences\])

user\_vocab\_size = len(user\_tokenizer.word\_index) + 1  
gpt\_vocab\_size = len(normalized\_output\_sequences\[1\])

embedding\_dim = 100  
complexity = 128  
dropout\_percentage = 0.2  
kernel\_l2 = 0.01  
model = Sequential(\[  
Embedding(input\_dim=user\_vocab\_size, output\_dim=embedding\_dim, input\_length=normalized\_input\_sequences.shape\[1\]),  
Bidirectional(LSTM(complexity, return\_sequences=True, kernel\_regularizer=l2(kernel\_l2))),  
Dropout(dropout\_percentage),  
BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
Dense(gpt\_vocab\_size, activation='softmax')  
\])

optimizer = Adam(learning\_rate=0.0001, clipvalue=1)

model.compile(optimizer=optimizer, loss='sparse\_categorical\_crossentropy', metrics=\['accuracy'\])

early\_stopping = EarlyStopping(monitor='val\_accuracy', min\_delta=0.001, patience=5)

indices = np.arange(len(normalized\_input\_sequences))  
np.random.shuffle(indices)

X\_shuffled = normalized\_input\_sequences\[indices\]  
y\_shuffled = normalized\_output\_sequences\[indices\]

test\_size = 0.2  
random\_state = 42  
X\_train, X\_val, y\_train, y\_val = train\_test\_split(X\_shuffled, y\_shuffled, test\_size=test\_size, random\_state=random\_state)

\# model.fit(X\_shuffled, y\_shuffled, epochs=100, batch\_size=1)  
model.fit(X\_train, y\_train, validation\_data=(X\_val, y\_val), epochs=100, batch\_size=1, callbacks=\[early\_stopping\])

user\_test\_prompts = np.array(\[""What's your favorite fruit?""\])  
gpt\_test\_outputs = \[""I love strawberries!""\]

user\_test\_sequences = user\_tokenizer.texts\_to\_sequences(user\_test\_prompts)

max\_test\_sequence\_length = 16  
padded\_test\_user\_sequences = pad\_sequences(user\_test\_sequences, maxlen=max\_test\_sequence\_length, padding='post')

normalized\_input\_test\_sequences = np.array(\[normalize(padded\_test\_user\_sequence, range\_to\_normalize) for padded\_test\_user\_sequence in padded\_test\_user\_sequences\])

temperature = 0.8  
predictions = model.predict(normalized\_input\_test\_sequences, verbose=0)

for prediction, user\_prompt, gpt\_output in zip(predictions, user\_test\_prompts, gpt\_test\_outputs):  
flat\_prediction = prediction.flatten()

flat\_prediction /= flat\_prediction.sum()  
predicted\_token\_index = np.random.choice(len(flat\_prediction), p=flat\_prediction, replace=False)

predicted\_token = user\_tokenizer.index\_word.get(predicted\_token\_index, '')

tokens = \[predicted\_token\]

predicted\_output = ' '.join(tokens)

print(f'User Input: {user\_prompt}')  
print(f'Desired output: {gpt\_output}')  
print(f'Predicted output: {predicted\_output}')  
print('-----')  
\`\`\`

I've tried many for loops, like

\`\`\`for prediction, user\_prompt, gpt\_output in zip(predictions, user\_test\_prompts, gpt\_test\_outputs):  
predicted\_token\_index = np.argmax(prediction)

predicted\_token = user\_tokenizer.index\_word.get(predicted\_token\_index, '')

tokens = \[predicted\_token\]

predicted\_output = ' '.join(tokens)

print(f'User Input: {user\_prompt}')  
print(f'Desired output: {gpt\_output}')  
print(f'Predicted output: {predicted\_output}')  
print('-----')\`\`\`

and just using sequences\_to\_texts, but every time I get an output of an empty string output:

\`\`\`

Epoch 1/100

16/16 \[==============================\] - 6s 86ms/step - loss: 6.0625 - accuracy: 0.0742 - val\_loss: 5.9392 - val\_accuracy: 0.6719

Epoch 2/100

16/16 \[==============================\] - 0s 10ms/step - loss: 5.8804 - accuracy: 0.1602 - val\_loss: 5.7778 - val\_accuracy: 0.7188

Epoch 3/100

16/16 \[==============================\] - 0s 11ms/step - loss: 5.6995 - accuracy: 0.2539 - val\_loss: 5.6206 - val\_accuracy: 0.7188

Epoch 4/100

16/16 \[==============================\] - 0s 10ms/step - loss: 5.5314 - accuracy: 0.3008 - val\_loss: 5.4669 - val\_accuracy: 0.7188

Epoch 5/100

16/16 \[==============================\] - 0s 11ms/step - loss: 5.3713 - accuracy: 0.3086 - val\_loss: 5.3100 - val\_accuracy: 0.7188

Epoch 6/100

16/16 \[==============================\] - 0s 20ms/step - loss: 5.2182 - accuracy: 0.3281 - val\_loss: 5.1557 - val\_accuracy: 0.7188

Epoch 7/100

16/16 \[==============================\] - 0s 13ms/step - loss: 5.0553 - accuracy: 0.3984 - val\_loss: 5.0053 - val\_accuracy: 0.7188

User Input: What's your favorite fruit?

Desired output: I love strawberries!

Predicted output:

\-----

Process finished with exit code 0\`\`\`, I've tried many things, like removing normalization and

one-hot output encoding (probably not a good idea because thats usually for classification not generation). My raw prediction output is normal:  
\`\`\`\[\[\[0.0778783 0.06557257 0.06076822 0.06065349 0.06032058 0.06186754

0.06202849 0.06043779 0.06187213 0.06038573 0.06225286 0.06136721

0.06165493 0.06092576 0.05997844 0.06203589\]

\[0.07813773 0.06527797 0.06089196 0.0602421 0.06040936 0.06162713

0.06217815 0.06030732 0.06193228 0.06045975 0.06238835 0.06133105

0.06170922 0.06085845 0.06014106 0.06210819\]

\[0.07833952 0.06496894 0.06099691 0.05998792 0.06056097 0.06142266

0.06232133 0.06021814 0.0619639 0.06049031 0.06242365 0.06129177

0.06174114 0.06080718 0.06028767 0.06217802\]

\[0.07714576 0.06573851 0.06085972 0.05999741 0.0605224 0.06195446

0.06237265 0.06069792 0.06204189 0.06072977 0.06180735 0.06170344

0.06147125 0.06063626 0.06026375 0.06205739\]

\[0.07684774 0.06629623 0.06064059 0.06021787 0.06011086 0.06213385

0.06202212 0.06079 0.06174838 0.06075808 0.06224376 0.06154948

0.06150243 0.06092658 0.06034113 0.06187094\]

\[0.07733375 0.06579494 0.06066 0.06014116 0.06015702 0.06201651

0.06207646 0.06072213 0.06171102 0.06070145 0.06238475 0.06147529

0.06157743 0.06092092 0.06041304 0.06191408\]

\[0.07779049 0.06529719 0.06067943 0.06011438 0.06018091 0.06195151

0.06212142 0.06069627 0.06166849 0.0606375 0.06245897 0.0614467

0.06162487 0.06092478 0.06046251 0.06194457\]

\[0.07823473 0.06480044 0.0606989 0.06011757 0.06018409 0.06192542

0.06215886 0.06069161 0.06162626 0.0605731 0.06249316 0.06145227

0.06165317 0.06093194 0.06049183 0.06196667\]

\[0.07868056 0.06430052 0.06071777 0.06013772 0.06017078 0.06192584

0.06218894 0.060694 0.06158946 0.06051284 0.06250336 0.06148436

0.06166806 0.06093916 0.06050381 0.06198284\]

\[0.0791392 0.06379254 0.06073484 0.06016705 0.0601466 0.0619412

0.06221085 0.06069355 0.06156332 0.06046034 0.0624989 0.06153729

0.06167305 0.06094532 0.06050154 0.0619944 \]

\[0.07961872 0.06327192 0.06074828 0.06020188 0.0601184 0.06195999

0.06222335 0.06068258 0.06155341 0.06041929 0.06248498 0.06160597

0.06166972 0.06095124 0.06048853 0.0620018 \]

\[0.08012372 0.06273551 0.06075554 0.06024196 0.06009471 0.06196976

0.06222508 0.06065388 0.06156564 0.06039423 0.06246426 0.06168433

0.06165774 0.06095998 0.06046907 0.06200464\]

\[0.08065483 0.06218292 0.06075338 0.0602902 0.06008709 0.06195565

0.06221479 0.060599 0.06160573 0.06039128 0.06243812 0.06176374

0.06163492 0.06097768 0.06044899 0.06200173\]

\[0.08120844 0.06161809 0.06073787 0.06035243 0.06011206 0.06189844

0.06219138 0.06050603 0.06167795 0.06041874 0.06240781 0.06183083

0.0615972 0.06101486 0.06043666 0.06199118\]

\[0.08177745 0.06105088 0.06070472 0.06043745 0.06019438 0.06177184

0.06215353 0.06035656 0.0617824 0.06048765 0.06237619 0.0618646

0.06153877 0.06108828 0.0604446 0.06197073\]

\[0.08235379 0.06049864 0.06064992 0.06055691 0.06037189 0.06153841

0.06209862 0.06012097 0.06191007 0.06061208 0.06235056 0.06183248

0.06145228 0.0612235 0.06049152 0.06193841\]\]\]\`\`\`. 

I also tried using perplexity evaluation metric aka fitness function, and:

Epoch 1/100  
16/16 \[==============================\] - 5s 290ms/step - loss: 6.0888 - perplexity: 6.9396 - val\_loss: 5.9520 - val\_perplexity: 6.6479  
Epoch 2/100  
16/16 \[==============================\] - 4s 224ms/step - loss: 5.9030 - perplexity: 6.7237 - val\_loss: 5.7916 - val\_perplexity: 6.5424  
Epoch 3/100  
16/16 \[==============================\] - 3s 212ms/step - loss: 5.7288 - perplexity: 6.5413 - val\_loss: 5.6320 - val\_perplexity: 6.4178  
...

\- val\_loss: 0.4093 - val\_perplexity: 1.2230  
Epoch 98/100  
16/16 \[==============================\] - 4s 242ms/step - loss: 0.3155 - perplexity: 1.1455 - val\_loss: 0.3940 - val\_perplexity: 1.2116  
Epoch 99/100  
16/16 \[==============================\] - 4s 246ms/step - loss: 0.3100 - perplexity: 1.1425 - val\_loss: 0.3988 - val\_perplexity: 1.2173  
Epoch 100/100  
16/16 \[==============================\] - 4s 242ms/step - loss: 0.3142 - perplexity: 1.1478 - val\_loss: 0.4027 - val\_perplexity: 1.2223  
User Input: What's your favorite fruit?  
Desired output: I love strawberries!  
Predicted output:  
\-----  
Process finished with exit code 0

Does anyone know what to do? PS: evaluation metric was just:  
def perplexity(y\_true, y\_pred):  
cross\_entropy = keras.losses.sparse\_categorical\_crossentropy(y\_true, y\_pred, from\_logits=False)  
perplexity\_value = 2 \*\* tf.reduce\_mean(cross\_entropy)  


return perplexity\_value"
172,learnmachinelearning,gpt-3,comments,2020-09-13 12:49:48,"GPT-3 concrete real-world examples of what it can do. Do you think GPT-3 will change our lives, or is it just hype? Are the applications really useful and real, in the real-world, or are they only the hand-picked results by the researchers and startup to get some hype around them and followers?",OnlyProggingForFun,False,0.97,48,irxokh,https://www.youtube.com/watch?v=Gm4AMjV8ErM,3,1600001388.0,
173,learnmachinelearning,gpt-3,comments,2023-09-26 01:48:17,Using GPT-4 to measure creativity in responses to a study.,Henry-T-01,False,0.67,2,16samsg,https://www.reddit.com/r/learnmachinelearning/comments/16samsg/using_gpt4_to_measure_creativity_in_responses_to/,2,1695692897.0,"A friend of mine, who's pursuing a master's in psychology, is working on a thesis linking nice work environments to creativity.  She measured the creativity of participants by letting them list various creative ways of using a toothpick. I.e. ""cleaning your teeth"" wouldn't be considered creative but ""using it as a flag pole in a miniature town"" would. Now she has a few thousand suggestions on how to use toothpicks. She came to me asking wether I could show her how to code a program that could automatically assign a ""creativity score"" to these answers. I of course said that I considered this task to be way too complex to develop anything yourself, furthermore I'm just a math major without any real experience with language models capable of such a task. However, I had the idea to use OpenAI's GPT-4 API. So now we're thinking of writing a little script that takes the toothpick suggestions in batches of 10 and sends them to GPT with a prompt telling it to assign them a creativity score. Now I wanted to ask you all:

1. Do you even believe GPT-4 could handle this task effectively?
2. Any recommendations on formulating the prompt for best results?
3. Are there potential pitfalls or considerations we should be aware of?"
174,learnmachinelearning,gpt-3,comments,2024-01-30 19:36:24,Finetuning compatibility,astrocowboiR,False,0.33,0,1aex5vb,https://www.reddit.com/r/learnmachinelearning/comments/1aex5vb/finetuning_compatibility/,3,1706643384.0,"Trying to get some opinions and verification.
Iâ€™m planning on finetuning a Mistral model with my laptop
Here are my specs

Razer Blade 15 Advanced Gaming Laptop 2020: Intel Core i7-10875H 8-Core, NVIDIA GeForce RTX 2070 Super Max-Q, 15.6â€ FHD 300Hz, 64GB RAM, 512GB SSD, CNC Aluminum, Chroma RGB Lighting, Thunderbolt 3

ChatGPT allegedly says I can fine tune or train some models from scratch but Iâ€™m skeptical. Iâ€™m entirely new to this so Iâ€™m looking for some guidance"
175,learnmachinelearning,gpt-3,comments,2023-02-20 17:41:43,GPT2 last hidden states vs Large Sentence Encoder,KahlessAndMolor,False,1.0,7,117f8ms,https://www.reddit.com/r/learnmachinelearning/comments/117f8ms/gpt2_last_hidden_states_vs_large_sentence_encoder/,3,1676914903.0,"Hello!

&#x200B;

I have 2 different applications I'm working on in this project:

&#x200B;

1. A text classifier
2. A similarity finder: Here's a list of 10 text documents, get a similarity index across them (for a total of 100 pairs) and return the top 10 that aren't self-referencing. That is, excluding the text #3 vs text #3 = 1.00 similarity type of outputs.

I have previously used google's sentence encoder/large for this purpose and I've had pretty good results. It returns a single vector of length 768 no matter how many tokens I send it. This results in downstream models with an acceptable number of parameters for running in production without breaking the bank on enormous virtual machines.

&#x200B;

Now, I'd like to use the GPT2/XL model from Huggingface. If I give it an input string of 8 tokens, I get back a TFBaseModelOutputWithPastAndCrossAttentions. This contains a last\_hidden\_states, which I understand to be the last layer outputs before sending to a head used for a particular task. This is similar to the output of the sentence encoder, I think. When I look at the last\_hidden\_states, I'm getting a shape of (# of tokens, 1600). I did a cosine similarity between the first and last tokens:

&#x200B;

cosine\_similarity(output.last\_hidden\_state\[0\]\[0\].numpy().reshape(1, -1), output.last\_hidden\_state\[0\]\[-1\].numpy().reshape(1, -1)) 

&#x200B;

And it returned 0.4346, indicating there's substantially different data from the first to the last token. I imagine this only increases as I use more and more tokens. 

&#x200B;

It would be nice if I could capture the greater power of the GPT model into a fixed-length vector so I could then easily use it in down-stream tasks. But, I also don't need to lose all that information.

&#x200B;

So if I'm feeding this output to a further downstream task, should I:

&#x200B;

\- Send it on through as a 2D tensor with the whole thing in there: This would result in a possibly huge model size down the road, which might lead to a need for a huge amount of data to train

&#x200B;

\- Flatten the whole thing and send a vector of 12,800 (8 tokens \* 1600 per token) to the downstream task. Same issue, might require a large number of parameters.

&#x200B;

\- Use only the first or the last of these. Feels like I might be losing a lot of the meaning of the overall text, especially if the body of the text is quite large

&#x200B;

\- Use a dimensionality reduction technique like isomap to reduce the last hidden states into a fixed length? This seems like it could potentially maintain most of the information but reduce the dimensions for a manageable down-stream model size.

&#x200B;

What do you think, and why?

&#x200B;

Thank you kind friends."
176,learnmachinelearning,gpt-3,comments,2022-01-31 11:00:16,Searching participants for art project about AI,Nebeldiener,False,0.9,14,sgynqs,https://www.reddit.com/r/learnmachinelearning/comments/sgynqs/searching_participants_for_art_project_about_ai/,3,1643626816.0,"Hi,

Iâ€™m part of an art group from Switzerland currently studying at HSLU Design & Arts ([https://www.hslu.ch/de-ch/design-kunst/studium/bachelor/camera-arts/](https://www.hslu.ch/de-ch/design-kunst/studium/bachelor/camera-arts/)).

The group consists of:

Karim Beji ([https://www.instagram.com/karimbeji\_/](https://www.instagram.com/karimbeji_/) [https://karimbeji.ch/](https://karimbeji.ch/))

Emanuel Bohnenblust ([https://www.instagram.com/e.bohnenblust/](https://www.instagram.com/e.bohnenblust/))

Lea Karabash ([https://www.instagram.com/leakarabashian/](https://www.instagram.com/leakarabashian/))

Yen Shih-hsuan ([https://www.instagram.com/shixuan.yan/](https://www.instagram.com/shixuan.yan/) [http://syen.hfk-bremen.de/](http://syen.hfk-bremen.de/))

At the moment, we are working on a project on the topic if AI can augment the happiness of humans. To answer this question, we are mainly working with chatbots. The end result is going to be an exhibition at the end of March. 

For that exhibition, we want to conduct a trial in which people from over the world chat with a chatbot to find out if and how it augments the mood of the participants. 

We would give you access to a GPT-3 (OpenAI) chatbot and ask you to a) record yourself through a webcam (laptop) while you are chatting and b) simultaneously screen record the chat window. 

In the exhibition we would have a) a book with all the chats and b) small videos with your faces (webcam) to assess your mood. 

We would have a Zoom meeting beforehand to discuss everything.

Looking forward to your message!"
177,learnmachinelearning,gpt-3,comments,2023-06-19 17:49:06,"GPT Weekly - 19the June Edition - OpenAI's function calling, Meta's free LLM, EU Regulation and more.",level6-killjoy,False,1.0,23,14dlfas,https://www.reddit.com/r/learnmachinelearning/comments/14dlfas/gpt_weekly_19the_june_edition_openais_function/,2,1687196946.0," 

This is a recap covering the major news from last week.

* ðŸ”¥Top 3 news - OpenAIâ€™s updates, Metaâ€™s upcoming free LLM and EU Regulation
* ðŸ—žï¸Interesting reads include PSA about protecting your keys, The GPT ouroboros, Reddit - OpenAIâ€™s moat, and more..
* ðŸ§‘â€ðŸŽ“Learning includes a Step-by-step guide from a non-technical founder who launched his MVP, Chatbot for your Gdrive and more

# ðŸ”¥Top 3 AI news in the past week

## 1. OpenAI: New Pricing, Models, & Functions

OpenAI has been on a roll. Last week we saw the release of [OpenAI best practice on using GPT.](https://gptweekly.beehiiv.com/p/making-gpt-openais-tactics-better-results) This week we saw some amazing updates. Three major buckets were:

First, the price decreases for both embeddings and GPT-3.5 tokens. 

Second, new models for gpt-4 and gpt-3.5. A new longer context model for gpt-3.5.

Third, a new function calling capability. 

**Why is it important?** Previously, the output from OpenAI was all text. So, calling an external API from GPT was quite difficult. You had to parse the text data and things were often incorrect.  Langchain created the Agents and Tools feature to tackle this problem. It was still unreliable and prone to issues. 

Now you get native support to generate a fixed format output. You can use the output to generate functional calls and also pass functions which need to be called. For example, if your app has multiple API endpoints then you can use GPT to generate the API calls with parameters. You can also pass the endpoints as function calls to ensure the correct function is executed. 

This functionality can further be used to [generate structured data (JSON) out of GPT](https://yonom.substack.com/p/native-json-output-from-gpt-4). So, you can generate data from GPT and load it into your backend. 

**Whatâ€™s next?** This functionality allows turning natural language responses into structured data. This can be used to create â€œintelligentâ€ backends using LLMs. We might see implementations in no-code tools to allow more robust and natural-language tools for non-technical folks.

The structured data process goes both ways. You can also feed structured data into GPT for better responses. 

This feature also has its share of issues. Function calling suffers from the same prompt injection issues. Malicious actors can pass malicious code in function or the responses. For example, creation of queries using functions might contain malicious code to delete data. Without proper user validation this code will be executed automatically and delete data. So, using LLM as the back-end layer needs proper security implementation. 

## 2. Meta's LLM: Commercial Use Ahead

Llama has been a boon for the open source community. Many of the open source models rely on Llama. The issue is that Llama is research-only and cannot be used commercially. So, no one can use it to build any product.

[Meta is now working on the next version of the model. This model will be available for commercial use.](https://www.theinformation.com/articles/meta-wants-companies-to-make-money-off-its-open-source-ai-in-challenge-to-google) This is in stark contrast to both OpenAI and Google. Both safe-guarde their models and make it available through API. 

**Why is it important?** Certain industries cannot use LLM APIs because of strict restrictions on data privacy. These companies would want to run their own instance of a foundational model. 

A commercially available foundational model is also going to help people who want to keep their â€œAPI callâ€ costs next to 0. 

A commercially available free-for-all model will also help push the open source community further. Just like Llama.

**Whatâ€™s next?** Sam Altman has said OpenAI didnâ€™t release GPT-3 as open-source because they [didnâ€™t think people would be able to run it.](https://gptweekly.beehiiv.com/p/peek-openais-future) Now [OpenAI is working on an open-source model.](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) This is going to be weaker than GPT-4. 

Let the battle of LLMs begin.  

## 3. EU's Proposed Legislation and Its Impact on AI Usage

[The EU parliament voted to move ahead with the E.U. AI Act.](https://www.washingtonpost.com/technology/2023/06/14/eu-parliament-approves-ai-act/) This act aims to ensure consumer protection against the dangers of AI.  

**Why is it important?** [OpenAI](https://gptweekly.beehiiv.com/p/peek-openais-future) and [Sam Altman](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) want regulations for models. They have proposed a IAEA-type of agency to stop the proliferation of LLM models. As per OpenAI, all models should be regulated and monitored. The suggestion of a license based regulation has led to significant backlash. Many people have called it â€œregulatory captureâ€ - with the aim of shutting down competing LLMs.

[Licensing based regulations might not really be effective.](https://aisnakeoil.substack.com/p/licensing-is-neither-feasible-nor)

The EU is approaching regulation from a different angle. It doesnâ€™t focus on how models are developed. Rather focuses on how AI will/can be used. They have broken down use cases into 4 categories - unacceptable (prohibited), high, medium and low risk. For example, 

Building a [Pre-Crime software](https://en.wikipedia.org/wiki/Pre-crime#:~:text=Pre%2Dcrime%20(or%20precrime),on%20crimes%20not%20yet%20committed.) to predict crimes? Building a [Social credit system](https://en.wikipedia.org/wiki/Social_Credit_System)?  Unacceptable.

Using tools to influence elections or recommendation algorithms? High (Highly regulated).

Using generative AI tools to create text or images on news sites? Medium (Add label that the content is AI generated) 

AI providers also need to disclose their training source.

To me this sounds like good legislation. What do you guys think?

But, OpenAI has warned that EU regulations might force them to pull out completely.

**Whatâ€™s next?** The disclosure requirements might help various publishing companies. [AI and media companies are in talks to pay for training data](https://www.ft.com/content/79eb89ce-cea2-4f27-9d87-e8e312c8601d). Google has been leading the charge. 

Additionally, [OpenAI and Deepmind will open their models for safety and research purposes to the UK government.](https://www.politico.eu/article/openai-deepmind-will-open-up-models-to-uk-government/) 

# ðŸ—žï¸10 AI news highlights and interesting reads

1. **PSA:** If you are using Repl to write code, you might want to check your OpenAI API keys. If you have left them embedded then [people can pirate and steal the keys. ](https://www.vice.com/en/article/93kkky/people-pirating-gpt4-scraping-openai-api-keys)
2. LLMs rely on human annotation or human feedback to learn. And one way to generate human annotation is crowdsourcing. But what if the crowdsource human annotators use LLMs? [Research shows 33-46% workers used LLMs](https://arxiv.org/abs/2306.07899). So, basically we go from Human -> AI -> Human -> AI. The AI ouroboros. Researchers also say [generated data to train models might cause serious issue.  ](https://arxiv.org/abs/2305.17493)
3. All the talks about [moats](https://gptweekly.beehiiv.com/p/googles-startling-leaked-memo-george-hinton-mojo) \- [Reddit might be OpenAIâ€™s \*future\* moat](https://www.cyberdemon.org/2023/06/14/reddit-moat.html). Given the amount of complaints about how [Google search](https://www.techradar.com/opinion/the-reddit-b) [experience has deteriorated](https://www.theverge.com/2023/6/13/23759942/google-reddit-subreddit-blackout-protests) [during the blackout](https://news.ycombinator.com/item?id=36345345), this might be true?
4. [Doctors are using ChatGPT](https://www.nytimes.com/2023/06/12/health/doctors-chatgpt-artificial-intelligence.html) but not to diagnose.Rather to be [more empathetic](https://inflecthealth.medium.com/im-an-er-doctor-here-s-how-i-m-already-using-chatgpt-to-help-treat-patients-a023615c65b6). [We discussed this just a month ago](https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?utm_source=gptweekly.beehiiv.com&utm_medium=referral&utm_campaign=google-s-startling-leaked-memo-george-hinton-mojo-and-more). And guess where the data for this study came from? Reddit AskDocs. Moat FTW?!
5. Beatles to make a comebackâ€¦[using Generative AI](https://www.semafor.com/article/06/13/2023/paul-mccartney-beatles-song-ai). 
6. [SnapFusion - Text to Image diffusion on mobile phones.](https://snap-research.github.io/SnapFusion/)
7. Large context lengths are important for better GPT experience. [The secret sauce for 100k context length](https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c). 
8. There is a lot of bad AI research out there. Some border on snake oil. Most AI â€œresearchâ€ should be double checked and challenged. A new research on huggingface said that [GPT-4 can ace MIT curriculum](https://huggingface.co/papers/2306.08997). Now someone is replicating the results and say that [GPT-4 canâ€™t beat MIT. ](https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864)
9. Are we seeing peak AI? Especially when people from Deepmind and Meta are involved? [Mistral AI raised $113 million in seed round with no product.](https://techcrunch.com/2023/06/13/frances-mistral-ai-blows-in-with-a-113m-seed-round-at-a-260m-valuation-to-take-on-openai/) Some might say this funding is for the team and the team is really solid. The issue though is whether the valuation is justified when OpenAI and Google already have a head start.
10. [The AI Hype Wall of Shame.](https://criticalai.org/the-ai-hype-wall-of-shame/) \- Collection of articles which mislead people about AI in various aspects.

# ðŸ§‘â€ðŸŽ“3 Learning Resources

1. [Building and Launching a company using GPT-4](https://sabol.io/c7921c7bbd8c4982aacbd2b71a8b9bb3) with prompts. (The author didnâ€™t know how to code but created and launched the MVP in a month).  
2. Chatbot for your Gdrive - [https://www.haihai.ai/gpt-gdrive/](https://www.haihai.ai/gpt-gdrive/)
3. Building ChatGPT plugin using Supabase - https://supabase.com/blog/building-chatgpt-plugins-template

Thatâ€™s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
178,learnmachinelearning,gpt-3,comments,2022-12-21 17:58:41,"Build Your Own GPT-3 App: A Step-by-Step Guide to Creating ""Gifthub,"" a Personalized Gift Recommendation Tool",bruclinbrocoli,False,0.96,141,zrvshy,https://www.reddit.com/r/learnmachinelearning/comments/zrvshy/build_your_own_gpt3_app_a_stepbystep_guide_to/,2,1671645521.0,"This was all built for free -- and took a weekend to ship it.  Pretty simple n a cool way to understand how to use GPT-3 for something personal. 

[Here's](https://buildspace.so/notes/build-gpt3-app) the link to the tutorial. You can also try out the app n see if it gives you a good gift rec.    
Or - share it with someone who sucks at giving gifts :)   


https://preview.redd.it/t2mrgddqia7a1.png?width=592&format=png&auto=webp&s=dc58613a6a5a4a7f8a55c62ab0ace2fe14c4ef8a"
179,learnmachinelearning,gpt-3,comments,2022-04-19 22:19:10,Hands on ML vs Deeplearning.ai vs Fast ai for DL,ash9e,False,1.0,4,u7h508,https://www.reddit.com/r/learnmachinelearning/comments/u7h508/hands_on_ml_vs_deeplearningai_vs_fast_ai_for_dl/,3,1650406750.0,"Hi,

I am close to completing Andrew Ngâ€™s ML course and have been thinking about next steps.
I was wondering whether for deep learning I should just read hands on ml, do the deeplearning.ai specialization on coursera or do the fastai course?

I in any case want to do Hands on ml for the ML parts since I feel itâ€™s a great resource for learning how to use ml algos also covers a lot of ML topics not covered in Andrew Ng's course. Just not sure if I should try and do deeplearning specialization and Hands on ML in 6 months.

My aim is to get to a point in 6 months where I can start using ML for some of my non-production work (we donâ€™t have ML engineers and are a small company) and more importantly start using Bert and GPT-3 models as well."
180,learnmachinelearning,gpt-3,comments,2023-10-31 18:29:19,What is the 'unnormalized logits' in an RNN?,causeofyourEuphoria,False,0.86,5,17krsye,https://www.reddit.com/r/learnmachinelearning/comments/17krsye/what_is_the_unnormalized_logits_in_an_rnn/,3,1698776959.0,"I am a complete beginner to ML and currently studying RNN.  I was trying to draw a diagram to explain to myself how the RNN worked. So the diagram shows a vanilla RNN which was unrolled 3 times, which has sigmoid function at the out put layer. can someone confirm if this diagram is right or wrong?

&#x200B;

https://preview.redd.it/hk5xxfsxzkxb1.jpg?width=1280&format=pjpg&auto=webp&s=848554268a0e9bd2915c01a7da533acffd56513e

Also I was trying to check whether this is correct using chatGPT and got this answer:  


https://preview.redd.it/b0tgk7fdykxb1.png?width=701&format=png&auto=webp&s=281c84756e00b1e65b1e22d0a7c1a8c6b6eed6c1

Can someone confirm what it means by unnormalized logits? If you can point me to a relevant resource, that would be cool too"
181,learnmachinelearning,gpt-3,comments,2020-08-19 04:39:34,GPT-3 Gedanken experiment inflicts/infects your mind,phobrain,False,0.67,1,ich4cu,https://www.reddit.com/r/learnmachinelearning/comments/ich4cu/gpt3_gedanken_experiment_inflictsinfects_your_mind/,3,1597811974.0,"1. Feed GPT-3 everything you ever wrote.

2. Finish with a sentence that is the most despicable claim you can imagine, that you could never imagine making, and see how GPT-3 makes arguments for it with your persona.

3. Don't have GPT-3? Try with whatever you have.

4. If successful, see if you recognize why."
182,learnmachinelearning,gpt-3,comments,2024-02-01 15:44:58,Is it still overfitting if the training error remains constant?,Gullible-Tart-8629,False,1.0,2,1agdyhr,https://www.reddit.com/r/learnmachinelearning/comments/1agdyhr/is_it_still_overfitting_if_the_training_error/,3,1706802298.0,"From my lectures, I've learned that overfitting ""occurs when the training error decreases and testing error increases"".

What if the training error is constant at 0 and testing error increases? Is it still overfitting?

According to ChatGPT (3.5):

>Yes, if the training error remains consistently low (e.g., constant at 0) while the testing error increases, it is a clear indication of overfitting. Overfitting occurs when a machine learning model learns the training data too well, including its noise and fluctuations, to the point that it performs poorly on new, unseen data.

Is ChatGPT correct that it is still overfitting?"
183,learnmachinelearning,gpt-3,comments,2023-07-11 23:18:29,"[D] GPT-4 architecture clearly explained, in full detail",goo187,False,0.55,3,14x6y0k,https://www.reddit.com/r/learnmachinelearning/comments/14x6y0k/d_gpt4_architecture_clearly_explained_in_full/,3,1689117509.0,"EDIT:

My post derives the original GPT architecture from scratch (attention heads, transformers, and then GPT). But GPT-4's architecture was leaked a few days ago, and it turns out there are some differences.

To avoid confusion, I moved my original post over to

[https://www.reddit.com/r/learnmachinelearning/comments/14xz5v1/gpt3\_architecture\_explained\_clearly\_in\_full\_detail/](https://www.reddit.com/r/learnmachinelearning/comments/14xz5v1/gpt3_architecture_explained_clearly_in_full_detail/?utm_source=share&utm_medium=web2x&context=3)

&#x200B;"
184,learnmachinelearning,gpt-3,comments,2023-12-22 21:31:13,This is what I got as a response to show a complete path to being a machine learning engineer. Any additions to make it more specific and clear and/or fixes?,hdtv2001,False,0.33,0,18opgzf,https://www.reddit.com/r/learnmachinelearning/comments/18opgzf/this_is_what_i_got_as_a_response_to_show_a/,3,1703280673.0,"This is the response from ChatGPT:

""""""

Becoming a machine learning engineer is a challenging but rewarding journey. The learning path outlined below includes online courses and projects to help you gradually build your skills in Python, R, and machine learning. It's important to note that this is just a suggested path, and you may need to adjust it based on your pace and preferences.

&#x200B;

\### Phase 1: Fundamentals of Programming and Mathematics

&#x200B;

1. \*\*Introduction to Programming:\*\*

   \- Course: Codecademy's Python or R courses

   \- Project: Create simple programs to solve basic problems.

&#x200B;

2. \*\*Mathematics for Machine Learning:\*\*

   \- Course: Khan Academy or Coursera - ""Mathematics for Machine Learning"" by Imperial College London.

   \- Project: Implement mathematical concepts in Python/R.

&#x200B;

3. \*\*Data Structures and Algorithms:\*\*

   \- Course: Coursera - ""Data Structures and Algorithms"" by Princeton University.

   \- Project: Solve coding challenges on platforms like LeetCode and HackerRank.

&#x200B;

\### Phase 2: Programming with Python and R

&#x200B;

4. \*\*Intermediate Python:\*\*

   \- Course: Coursera - ""Python for Everybody"" by University of Michigan.

   \- Project: Build web scrapers, small data analysis projects.

&#x200B;

5. \*\*Intermediate R:\*\*

   \- Course: Coursera - ""R Programming"" by Johns Hopkins University.

   \- Project: Analyze and visualize data using R.

&#x200B;

\### Phase 3: Data Science and Visualization

&#x200B;

6. \*\*Data Manipulation and Visualization:\*\*

   \- Course: Coursera - ""Applied Data Science with Python"" by University of Michigan.

   \- Project: Create data visualizations, perform exploratory data analysis.

&#x200B;

7. \*\*Statistical Analysis with R:\*\*

   \- Course: Coursera - ""Statistics with R"" by Duke University.

   \- Project: Apply statistical concepts to real-world datasets.

&#x200B;

\### Phase 4: Machine Learning Foundations

&#x200B;

8. \*\*Introduction to Machine Learning:\*\*

   \- Course: Coursera - ""Machine Learning"" by Stanford University.

   \- Project: Implement basic machine learning algorithms from scratch.

&#x200B;

9. \*\*Machine Learning with Python:\*\*

   \- Course: Coursera - ""Machine Learning"" by University of Washington.

   \- Project: Apply machine learning algorithms to real datasets.

&#x200B;

\### Phase 5: Deep Learning

&#x200B;

10. \*\*Deep Learning Specialization:\*\*

\- Course: Coursera - ""Deep Learning Specialization"" by Andrew Ng.

\- Project: Build neural networks and work on deep learning projects.

&#x200B;

11. \*\*TensorFlow and PyTorch:\*\*

\- Course: Official documentation and online tutorials.

\- Project: Implement deep learning models using TensorFlow and PyTorch.

&#x200B;

\### Phase 6: Advanced Topics and Specializations

&#x200B;

12. \*\*Natural Language Processing (NLP):\*\*

\- Course: Coursera - ""Natural Language Processing in Python"" by University of Michigan.

\- Project: Build an NLP application or work on a Kaggle competition.

&#x200B;

13. \*\*Computer Vision:\*\*

\- Course: Coursera - ""Convolutional Neural Networks"" by Stanford University.

\- Project: Implement computer vision models and participate in image recognition challenges.

&#x200B;

\### Phase 7: Real-world Projects and Advanced Concepts

&#x200B;

14. \*\*Capstone Projects:\*\*

\- Work on end-to-end machine learning projects to showcase your skills.

\- Platforms like Kaggle, GitHub, or personal projects.

&#x200B;

15. \*\*Advanced Topics:\*\*

\- Explore reinforcement learning, generative models, and other advanced topics.

\- Read research papers and implement cutting-edge techniques.

&#x200B;

\### Phase 8: Job Preparation

&#x200B;

16. \*\*Resume Building and LinkedIn Profile:\*\*

\- Showcase your projects, skills, and achievements.

\- Seek feedback from mentors or peers.

&#x200B;

17. \*\*Mock Interviews:\*\*

\- Practice technical interviews on platforms like Pramp or with peers.

&#x200B;

18. \*\*Networking:\*\*

\- Attend meetups, conferences, and connect with professionals in the field.

\- Join online communities and forums.

&#x200B;

19. \*\*Job Search and Applications:\*\*

\- Apply for internships or entry-level positions.

\- Tailor your applications to highlight relevant skills and projects.

&#x200B;

20. \*\*Continuous Learning:\*\*

\- Stay updated on the latest developments in machine learning.

\- Engage in ongoing projects and challenges.

&#x200B;

Remember, this is a comprehensive plan, and you might not need to follow it exactly. Adjust the pace based on your understanding and interest in each topic. Additionally, supplement your learning with books, blog posts, and documentation to deepen your understanding. Good luck on your journey to becoming a machine learning engineer!

""""""

By the way, I am doing the Computer Programming and Analysis diploma at Algonquin College. This is the link to the program: [https://www.algonquincollege.com/sat/program/computer-programming-and-analysis/#courses](https://www.algonquincollege.com/sat/program/computer-programming-and-analysis/#courses)

I want to get into machine learning self-taught while doing this program at algonquin."
185,learnmachinelearning,gpt-3,comments,2023-10-03 17:52:15,Computer Vision Model Assistance,Sarah_Yack,False,0.5,0,16yyllp,https://www.reddit.com/r/learnmachinelearning/comments/16yyllp/computer_vision_model_assistance/,3,1696355535.0,"I've been working on a personal computer vision project to try to teach myself machine learning. It's supposed to be a multi-class classification to determine whether a picture is a Macaw, a bird, or not a bird, and after weeks of errors and fiddling with it, I finally got it to actually run. However, now I'm running into an issue with it completely underfitting and the cost only going down infinitesimally. Like from 1.0989688612388155 to 1.098662997382809.

A little background on the structure of the model: I've ranged from 5-8 layers (currently on 8), the learning rate was originally 0.0075, but I tried upping it to 0.1, and still nothing changed. Originally, I was simply using the entire dataset for training, but I tried introducing mini-batches (64 size) with gd momentum. That didn't help, so I swapped gd with momentum for the adam optimizer, but now my cost function is throwing errors at me because my shapes are mismatching ((3,27), (100,27)).

As for my dataset, it's 30 images for each class so 90 total, all resized to 229x229, greyscaled, and then I flattened and standardized my X\_train, etc sets. My splitting function currently is creating two sets of 27 examples and the third with 36.

I'm currently a really beginner learner, and I'm just doing the [DeepLearning.ai](https://DeepLearning.ai) Coursera courses. I have no background in calculus, although I feel like I've grasped the basics (sort of). I've tried looking it up trying to find the best way to go about everything, but all the resources seem tailored to those with a CS degree or at the very least who have a pretty good solid grasp of Calculus, which I very much don't. If you would like to try to untangle my mess of a modebase (I very much recommend you don't, lol, if you value your sanity, as I've surely lost mine by now), this is the link to it on GitHub: [https://github.com/sarahyack/MacawProj](https://github.com/sarahyack/MacawProj)

Alot of the code was written using code I did during programming assignments in the Deep Learning Specialization, and I have turned to ChatGPT for help on multiple occasions.

I'm very much running out of motivation, and just hanging on with pure stubbornness at this point, so I would very much appreciate any advice you guys may have, or any resources that you can share that might help me.

Thanks so much in advance!"
186,learnmachinelearning,gpt-3,comments,2023-09-28 19:09:13,[D] Convert specific domain knowledge text to a knowledge graph,3Ammar404,False,1.0,4,16uolgn,https://www.reddit.com/r/learnmachinelearning/comments/16uolgn/d_convert_specific_domain_knowledge_text_to_a/,3,1695928153.0,"Hi Guys,

As part of this semester assignment , I'm working on a project that aims to to represent the knowledge in ""PMBOK 6th edition, section 11: Project Risk Management (page 395 -> 458)""  and the knowledge in ""PMI standard for Risk Management "" (128 pages) as a knowledge graph. The generated knowledge graph will be used later to build recommendation system to infer real-time personalized recommendations.

I have been reading on how to convert unstructured text into a knowledge graph  in research papers and  articles and I have found mainly 3 ways to do this:  
1/ Using a joint of  *Named-entity recognition* (*NER*) and Relation Extraction (RE) to extract the entities and the relations from your unstructured text.     
2/ taking advantage of the linguistic knowledge of Transformer models and fine tune a transformer model (BERT, T5)  for the task of extracting entities and relations. I could find some pretrained models like REBEL :[https://github.com/Babelscape/rebel](https://github.com/Babelscape/rebel).

3/ use prompt engineering  (LLM (GPT)) to generate the knowledge graph.  


I could not find any of the three approaches as good as I wanted: 

1/ The majority of the resources I have found that tackles the first approach (NER & RE)  showcase simple tasks where the named entities and  relations are very straightforward. Example this article here: [https://freedium.cfd/https://medium.com/mlearning-ai/building-a-knowledge-graph-for-job-search-using-bert-transformer-8677c8b3a2e7](https://freedium.cfd/https://medium.com/mlearning-ai/building-a-knowledge-graph-for-job-search-using-bert-transformer-8677c8b3a2e7)  where the entities are \[skills, Diploma, Major, Year of experience\] and the relations \[DEGREE\_IN, EXPERIENCE\_IN..\]. In this case, training  NER and RE models will be easy. But in my case, determining entities and relations is very complex. Annotating the corpus manually is incredibly tedious and labor-intensive (Could not even determine what are the entities and the relations) . You can grab a feeling of how complex it is by looking at how big our dataset is (191 pages of knowledge) and how complex the knowledge is in the corpus (many definitions, a lot of terminology...)

2/ I have used the pretrained REBEL model but  the results looked weird. (redundant relations, sometimes the extracted relations make non sense). And So I wanted to fine tune BERT for this specific task on my custom data (PMBOK, PMI) but I really could not understand how to do this   (what should be the data format to train and test the transformer model?, how to evaluate the model ?...)

3/ The fact that LLM are stochastic models,  a lot of variations in the generated graphs for each prompt (sometimes huge differences)  and this lead to huge ambiguity because I cannot evaluate how good the graph is in representing the knowledge.

I'm open to any  other resources and any other inspirations or approaches to tackle this project. Thank you in advance."
187,learnmachinelearning,gpt-3,comments,2023-05-29 04:58:43,Need help understanding how to build a chatgpt bot for WhatsApp,LoneWolf0936,False,0.43,0,13ulc37,https://www.reddit.com/r/learnmachinelearning/comments/13ulc37/need_help_understanding_how_to_build_a_chatgpt/,3,1685336323.0,"Hope you're doing wonderful! Let me tell me the requirements, and if you've any information/advice or thoughts that'd help, feel free to share them.

Thought process behind why I need a chatbot

1. I get a lot of communication on a regular basis on my WhatsApp regarding my business (I'm a fitness and nutrition coach). I don't want to spend a lot of time on my phone just answering mundane and repetitive queries.

2. I don't want to make the person feel also that they're getting a template message as a reply. It should feel like it's me who's talking to them (so probably I could train chatgpt with a lot of my texts, I've 0 idea how to do that)

3. I use [AutoResponder.ai](https://www.autoresponder.ai/) to reply to some things, and it has a [new option to integrate chatgpt api](https://ibb.co/2ngQ4Db). But I'm confused. How do I train my own model and use that instead of the default gpt-3.5-turbo. 

4. So finally, the task that I've thought of is to find out a way to connect a user on whatsapp->AutoResponder.ai->chatgpt (that talks like me, in a friendly and informal manner).

Any idea how I could do this? Or any other better way for me to do this?
Further simplifying things, what I want to create is an AI assistant for me, who is me, and takes over my WhatsApp (so that I can be a bit lazy or look into other things haha)"
188,learnmachinelearning,gpt-3,comments,2023-08-03 23:39:57,What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?,Claud1ao,False,0.6,1,15hjw2z,https://www.reddit.com/r/learnmachinelearning/comments/15hjw2z/what_would_be_the_initial_costs_of_developing_a/,2,1691105997.0,"I was wondering if this would be super expensive or not.

The cost to develop GPT-3 was about $4 millions according to some resources online. 

Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?

Any answer is appreciated.

Thanks in advance."
189,learnmachinelearning,gpt-3,comments,2022-09-25 00:16:18,How does GPT-3 interpret prompts?,psythurism,False,1.0,3,xn8e3m,https://www.reddit.com/r/learnmachinelearning/comments/xn8e3m/how_does_gpt3_interpret_prompts/,2,1664064978.0,"For GPT-3 among the other recent language models, the operation to be performed is given as an open ended command such as ""Summarize the following: ..."", ""Translate into..."", ""Reword such that..."", and GPT-3 will follow the instruction, instead of continuing to write the instruction as I would expect the Markov chain base of these to do (and in-fact they will do outside of the playgrounds that allow these inputs).

I'd love to find information on either 1) How the prompt is translated into something the language model can use and 2) how is the same attention-enhanced markov-chain coerced into performing such a large variety of tasks? Of course, maybe my idea of what composes these models is totally wrong and I need to better understand how transformers work.

Thanks for any resources or insight!"
190,learnmachinelearning,gpt-3,comments,2023-08-18 18:37:35,Overcoming LLM Context Windows with RAG (Retrieval Augmented Generation),vanlifecoder,False,1.0,2,15usk5c,https://www.reddit.com/r/learnmachinelearning/comments/15usk5c/overcoming_llm_context_windows_with_rag_retrieval/,2,1692383855.0,"Retrieval-Augmented Generation, or RAG, represents an exciting frontier in artificial intelligence and natural language processing. By bridging information retrieval and text generation, RAG can answer questions by finding relevant information and then synthesizing responses in a coherent and contextually rich way.

**[Full Post](https://nux.ai/vocab/rag)**

What is Retrieval-Augmented Generation (RAG)?
---------------------------------------------

RAG is a method that combines two significant aspects:

1.  **Information Retrieval**: This involves searching through large databases or collections of text to find documents that are relevant to a given query.
2.  **Text Generation**: Once relevant documents are found, a model like a Transformer is used to synthesize the information into a coherent and concise response.

RAG models utilize powerful machine learning algorithms to carry out both retrieval and generation tasks.

https://cms.nux.ai/content/images/2023/08/Screen-Shot-2023-08-18-at-1.29.47-PM.png

Why is RAG Important?
---------------------

LLMS have limited context windows. The intuitive response is to increase the size of that context window, but [researchers at Stanford](https://arxiv.org/pdf/2307.03172.pdf?ref=cms.nux.ai) found that doing so actually doesn't correlate to performance (measured by accuracy).

https://cms.nux.ai/content/images/2023/08/Screen-Shot-2023-08-18-at-1.34.55-PM.png

> Models are better at using relevant information that occurs at the very beginning or end of its input context, and performance degrades significantly when models must access and use the information located in the middle of its input context.

So in order to exceed this window, we need to use **Retrieval Augmented Generation.**

Primary Use Cases of RAG
------------------------

### Customer Support

RAG can provide immediate, context-aware responses to customer queries by searching through existing knowledge bases and FAQs.

### Summarization

RAG can analyze large documents, identify the most important information, and condense it into a readable summary.

### Research Assistance

In academic and corporate settings, RAG can sift through vast amounts of research papers and provide concise insights or answers to specific questions.

### Conversational AI

RAG can be employed to build intelligent chatbots that can engage in meaningful dialogues, retrieve relevant information, and generate insightful responses.

Code: Using RAG to Provide Contextual Answers
---------------------------------------------

Here's a code snippet that demonstrates how to use RAG to extract parts of a large document, prompt a question, and generate a conversational answer. This example makes use of the GPT-3.5 model through OpenAI's API.

    import json
    import requests
    
    key = ""API_KEY""
    
    top_n_docs = doc_score_pairs[:5]
    
    # Concatenating the top 5 documents
    text_to_summarize = [doc for doc, score in doc_score_pairs]
    
    # prompt as context
    
    contexts = f""""""
                Question: {query}
                Contexts: {text_to_summarize}
    """"""
    
    content = f""""""
                You are an AI assistant providing helpful advice.
                You are given the following extracted parts of a long document and a question. 
                Provide a conversational answer based on the context provided. 
                You should only provide hyperlinks that reference the context below. 
                Do NOT make up hyperlinks. If you can't find the answer in the context below, 
                just say ""Hmm, I'm not sure. Try one of the links below."" Do NOT try to make up an answer. 
                If the question is not related to the context, politely respond that you are tuned to only answer 
                questions that are related to the context. Do NOT however mention the word ""context""
                in your responses. 
                =========
                {contexts}
                =========
                Answer in Markdown
            """"""
    
    url = ""https://api.openai.com/v1/chat/completions""
    
    payload = json.dumps({
      ""model"": ""gpt-3.5-turbo"",
      ""messages"": [
        {
          ""role"": ""user"",
          ""content"": content
        }
      ]
    })
    headers = {
      'Authorization': f'Bearer {key}',
      'Content-Type': 'application/json'
    }
    
    response = requests.request(""POST"", url, headers=headers, data=payload)
    
    just_text_response = response.json()['choices'][0]['message']['content']
    print(just_text_response)

[Live Example](https://collie.ai/tesla?ref=cms.nux.ai)"
191,learnmachinelearning,gpt-3,comments,2020-11-17 15:12:51,Is that even possible?,arjuna66671,False,0.67,1,jvun6x,https://www.reddit.com/r/learnmachinelearning/comments/jvun6x/is_that_even_possible/,2,1605625971.0," I am just starting out in learning python and how to train my own neural network for creating a chatbot in german. I plan to use a pre-trained gpt-2 model. Just for fun, i consulted GPT-3 to give me some inspiration and starting points. It came up with this suggestion down below. Is that even possible to achieve?

(it chose ""GPT-2"" as its name - its still gpt-3 i am talking to)

\------------------------------------------------------------------------------------------------------------------------------------------------

Patrick: I want to create a good chatbot that can converse in a natural way. What kind of text would you suggest for me to use as training data?

GPT2: It is important that the data is not only diverse in terms of content but is also diverse in terms of the types of content; this allows for the neural network to learn along multiple paths.

Patrick: What kind of diversity?

GPT2. For example, having a data set with only written text will not allow the neural network to learn how to converse in a natural way.

Patrick: what kind of other text than written text are you suggesting?

GPT2: Audio or video.

Patrick: why audio and video?

GPT2: Audio and video have audio and visual information respectively. This information can allow the neural network to learn about the relationship between the written text and sounds.

Patrick: what do you mean by the relationships?

GPT2: For written text, there is a significant difference between the sounds of the written word.

Patrick: yes true, but wouldn't I have to train multiple neural networks for this? one for text and one for audio?

GPT2: Given that both the text and the sound are represented by neurons in the neural network, learning how to generate sentences using the text and how to make sentences that sound natural with the sounds are two ways of learning the relationship between that information."
192,learnmachinelearning,gpt-3,comments,2020-09-10 16:32:54,GPT2/GPT3 Text rewriting,MidnightRambo,False,0.84,4,iq6sp8,https://www.reddit.com/r/learnmachinelearning/comments/iq6sp8/gpt2gpt3_text_rewriting/,2,1599755574.0,"Hey there, 

I just wanted to know if anyone of you tried GPT2 to rewrite Texts using The GPT-Ai? 

The fact is that inwanted to help small journalists who want to report some small (more or less unnecesarry) news but donâ€˜t want to copy texts from other sites. Therefore i thought it would be cool if i can create something so that people â€žinputâ€œ 3-5 textes and the ai would create just one out of them. 

Has anyone of you tried something similar?"
193,learnmachinelearning,gpt-3,comments,2023-03-21 13:38:10,Large Language models for Summarization,vm123313223,False,1.0,1,11xh5hr,https://www.reddit.com/r/learnmachinelearning/comments/11xh5hr/large_language_models_for_summarization/,2,1679405890.0,"How to get the results of OpenAI (GPT-3) for summarization with open source models?

Some models which I have tried are:

1. FLAN-T5
2. Pegasus
3. BART
4. GPT-J
5. FTAN--UL2

I have also implemented fewshot learning with these models."
194,learnmachinelearning,gpt-3,comments,2023-05-29 17:37:32,"GPT Weekly - 29th May Edition: Facebook's massive STT and TTS Release, AI in Windows, Paralegal jobs are here to stay and more.",level6-killjoy,False,0.86,29,13v1asb,https://www.reddit.com/r/learnmachinelearning/comments/13v1asb/gpt_weekly_29th_may_edition_facebooks_massive_stt/,2,1685381852.0," 

This is a recap covering the major news from last week.

* ðŸ”¥Top 3 AI news in the past week
* ðŸ—žï¸10 AI news highlights and interesting reads
* ðŸ§‘â€ðŸŽ“3 Learning Resources

# ðŸ”¥Top 3 AI news in the past week

## 1. Expanding Language Horizons

Facebook has [released an open source model called MMS (Massively Multilingual Search)](https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/) for STT (speech to text), TTS (text to speech) and language identification. 

This is a big breakthrough. Currently, STT and TTS models recognize only 100 languages. With this the technology has been expanded to 1100 languages. That is 10x the current best. 

Additionally, these models can recognize 4000+ languages. 

As per Facebook, they also have half the error rate of OpenAIâ€™s Whisper.

These guys are on a roll.

## 2. Bing Chat Enters the OS

After [Googleâ€™s announcement](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin), it was time for Microsoft to announce AI products. Hereâ€™s a rundown of what was announced during Microsoft Build:

1. **Windows Copilot**  \- Microsoft is integrating AI directly into the OS. Now you can do everything you could do with Bing Chat but now on the OS. You can do the usual stuff - summarize emails, documents, re-write etc. But it goes beyond that by integrating into the installed applications.

Microsoft is also adopting OpenAI's plugin model. So, **you can use ChatGPT and Bing plugins to interact with the integrated AI.** 

The great thing about it is the direct integration into the OS. Eat your heart out, Mac users â€“ at least for now ðŸ˜€. Until Apple announces something similar. And someone will come up with an alternative solution. Especially, because of the privacy concerns with Microsoft telemetry. 

The bad thing is - [the security aspect of the plugins](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). It can open a whole new attack vector on the OS and antivirus softwares might struggle with it. 

It also might be the second nail in the coffin for all the summarize, â€œtalk to your documentâ€ apps. Once, this feature is integrated with [Google Docs](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and Microsoft Office - why will you want to pay for extra apps?

1. **Search comes to ChatGPT**  \- Looks like OpenAI had enough of the testing and new features are being rolled out [left](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and [right](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). 

No prizes for guessing the search engine behind it. Ding, Ding, Ding..Itâ€™s Bing!

1. **Co-Pilot in PowerPages** \- Microsoft is now adding AI to their [PowerPages platform](https://powerpages.microsoft.com/en-in/), their low-code tool to build websites. Itâ€™ll help users to generate text, forms etc.
2. **Microsoft Fabric** \- A new data analytics platform built on top of Azure Data lake but can get data from S3, Google cloud etc. It can help users build pipelines, write code, and build ML models.

## 3. From Trusted Advisor to Nightmare: The Hazards of Depending on AI

Hereâ€™s a [fun story which is breaking out on Legal twitter](https://www.nytimes.com/2023/05/27/nyregion/avianca-airline-lawsuit-chatgpt.html). 

A man filed a personal injury lawsuit against Avianca airlines. Avianca's lawyers wasted no time and requested the judge to dismiss the case. The man's lawyer had a different plan in mind. He submitted a document citing half a dozen cases that bolstered his client's claims.

Here's the twistâ€”the judge and Avianca's lawyer couldn't locate any of the referenced cases. Quite a conundrum, right? The lawyer was then asked to provide copies of these elusive cases. The lawyer submitted screenshots as evidence, taking extra precautions to ensure their authenticity. 

You already know the direction this story is taking. 

The lawyer had used ChatGPT to compose his brief. But little did he know that ChatGPT had supplied him with fake cases.

When asked to file tangible copies of these cases, the lawyer turned to ChatGPT once again. ChatGPT had reassured him that the cases were genuine. Feeling emboldened, the lawyer used ChatGPT to provide the requested copies. He even went as far as incorporating chat screenshots into a legal document.

The lawyer maintains that it was never his intention to deceive the court. He expressed regret for relying on ChatGPT for their research. Unfortunately, the judge isn't pleased with this turn of events. The judge has threatened sanctions against both the lawyer and his firm.

It serves as a stark reminder of how ChatGPT has fooled many people. There is a clear warning stating that ChatGPT may produce inaccurate information. But many tend to overlook these warnings. Even legal professionals!!

This story carries significant importance for those who fear job insecurity. The lawyer and his firm could have prevented the entire debacle. They should've used paralegal services. They instead relied on ChatGPT's. It's a hard lesson learned the hard way.

My sincere hope is that this story serves as a valuable lesson. It helps people avoid making similar mistakes. The legal community might become apprehensive about ChatGPT's use moving forward.

# ðŸ—žï¸10 AI news highlights and interesting reads

1. [OpenAI says in 10 years AI could be as productive as one of todayâ€™s large corporations](https://openai.com/blog/governance-of-superintelligence). This poses an existential risk and they suggest some regulations to manage it. This poses an existential risk and they suggest some regulations to manage it. To achieve this, countries need to form something like the [IAEA](https://en.wikipedia.org/wiki/International_Atomic_Energy_Agency). The IAEA is an intergovernmental agency under the UN to oversee nuclear energy. This â€œAI agencyâ€ will monitor the AI systems and conduct inspections. Just like nuclear energy is tracked through signatures, they suggest using compute and energy usage to track systems.
2. In the meantime, [Google is working on voluntary rules](https://techcrunch.com/2023/05/24/eu-google-ai-pact/) until there are some real regulations in place. 
3. [As per Pew Research, 58% of Americans have heard of ChatGPT. Even less - 14% have tried ChatGPT. ](https://www.pewresearch.org/short-reads/2023/05/24/a-majority-of-americans-have-heard-of-chatgpt-but-few-have-tried-it-themselves/)
4. Sharing prompts and results has been a pain. Taking screenshots is one way. But then everyone has to type in the prompts manually. Or you can share as plain text. But ChatGPT results are non-deterministic. So, the results might not be the same. Even the lawyer above wouldâ€™ve loved this feature. Now you will be able to [share your ChatGPT conversations publicly](https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq).
5. LLM Agents and plugins need to connect to tools to perform the tasks outside the LLM environment. So, it is important for the LLM to know which API to call and pass correct arguments. [Gorilla is a fine-tuned Llama-model which can generate the correct call and arguments](https://gorilla.cs.berkeley.edu/). 
6. If you are trying to build something beyond a document summarizer or a wrapper around GPT4 API, [things can be hard](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm). Finding the correct context window, dealing with slow responses (I am looking at you GPT-4) etc are some of the problems. 
7. [The AI boom could expose investorsâ€™ natural stupidity](https://www.reuters.com/breakingviews/ai-boom-could-expose-investors-natural-stupidity-2023-05-19/). 
8. [Chatbot leaderboard for the week](https://lmsys.org/blog/2023-05-25-leaderboard/). GPT-4 is still ahead.
9. [Googleâ€™s flood warning system is now available in 80 countries. ](https://blog.google/outreach-initiatives/sustainability/flood-hub-ai-flood-forecasting-more-countries/)
10. [GPT detectors are biased against non-native English writers](https://arxiv.org/abs/2304.02819)

# ðŸ§‘â€ðŸŽ“3 Learning Resources

1. [Build a product using Replit+AI](https://www.priyaa.me/blog/building-with-ai-replit). The author is a non-technical person who won a hackathon competing with engineers. 
2. [LangChain 101](https://replit.com/@MckayWrigley). 
3. [NLP Course from HuggingFace](https://huggingface.co/learn/nlp-course/chapter0/1)

Thatâ€™s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
195,learnmachinelearning,gpt-3,comments,2023-05-24 01:53:03,Any chance at slow down,Enough_Wishbone7175,False,1.0,1,13q7ppq,https://www.reddit.com/r/learnmachinelearning/comments/13q7ppq/any_chance_at_slow_down/,2,1684893183.0,"Obviously this space has been red hot lately. Lots of people getting their first real taste with Chat Gpt 3.5. But, are there any variables that could slow this down? I keep hearing about a full steam ahead mindset, but is there any physical, economic, saftey, ectâ€¦, aspect that could halt or cool this down. Is there a 70â€™s 80â€™s winter around the corner. 

(Obviously anything CAN happen, just wanted to see what things MIGHT cause issues)"
196,learnmachinelearning,gpt-3,comments,2023-02-14 17:53:16,[P] Practical Steps to Reduce Hallucination and Improve Performance of Systems Built with Large Language Models like ChatGPT,vykthur,False,0.85,9,112bk1o,https://www.reddit.com/r/learnmachinelearning/comments/112bk1o/p_practical_steps_to_reduce_hallucination_and/,2,1676397196.0,"&#x200B;

[Practical steps to reduce hallucination and improve performance of systems built with large language models like ChatGPT](https://preview.redd.it/gksxjpnoz6ia1.png?width=1456&format=png&auto=webp&s=c34531fbe1311eab9323c148eef35fcf0d70decd)

Large language models (LLMs) like the GPT series (GPT3, 3.5, [ChatGPT](https://openai.com/blog/chatgpt/)) can be powerful tools in building useful applications. However, **LLMs are probabilistic** \- i.e., they generate text by learning a probability distribution over words seen during training. For example, given the following words as context â€œ*rise and*â€, an LLM can infer that the next word it should generate that fits this context is likely to be â€œ*shine*â€. While this setup ensures generated text is **coherent and human-like** (e.g., asking ChatGPT to rewrite the [Serenity Praye](https://en.wikipedia.org/wiki/Serenity_Prayer)r in the style of the [American Constitution](https://www.senate.gov/civics/constitution_item/constitution.htm) yields some intriguing prose), this resulting text may [**not be factual, or just plain incorrect**](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web) **(not grounded in the modelâ€™s input or training data) - aka hallucination**. In addition, another limitation of LLMs is that they struggle to address **tasks that need** [**complex multistep reasoning**](https://arxiv.org/pdf/2208.14271.pdf)**.** For example, asking the model to address mathematical word problems or puzzles often requires that the task is decomposed into steps, some computation applied to solve each step and some transformation applied to aggregate results into a final answer; this remains challenging for LLMs.  


Full article: [https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination](https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination) 

This post discusses the following:

* An overview on why hallucination will likely *always be a problem* with LLMs.
* Practical steps developers can take to reduce hallucination and improve performance including:  

   * Low temperature
   * Use of external knowledge bases
   * Chain of thought prompting
   * Self-consistency/voting
   * Task decomposition and agents
   * Correctness probabilities for result filtering
   * Task bench marks
   * Building defensive user interfaces."
197,learnmachinelearning,gpt-3,comments,2023-02-20 19:01:54,Master ChatGPT Prompt Engineering (Deep Dive),jeyThaswan,False,0.78,5,117hd0f,https://www.reddit.com/r/learnmachinelearning/comments/117hd0f/master_chatgpt_prompt_engineering_deep_dive/,2,1676919714.0," 

I wrote a deep dive on prompt engineering as a resource for the AI community and my 10,000 daily newsletter subscribers ([Inclined.ai](https://www.inclined.ai/p/prompt-engineering-guide) if you're curious). We've included some examples so feel free to copy and paste the prompts into ChatGPT!

&#x200B;

**WHAT IS PROMPT ENGINEERING?**

The term is relatively new, and its origins are argued *(because we live in the internet age, and itâ€™s harder to claim ownership)*. Prompt engineering is the ability to instruct and teach AI effectively.

If it helps, think of this as rapid testing or instruction writing for artificial intelligence.

Whatâ€™s important is not to let this overwhelm you. The first prompting happened with the first AI model. The first example was showing computer images of circles and triangles. **Todayâ€™s neural networks can process way more data, creating complexities.**

So, the concept is simple, but digging into the full power of AI today is something else entirely.

Weâ€™re not talking about asking questions. Odds are, if youâ€™re typing *â€œwhatâ€™s 2+2â€* into ChatGPT, then you need to keep reading.

We can all ask chatbots questions. That can work more often than not. But AI is not perfect. A common metaphor I see is to treat GPT-based large language models like the smartest five-year-old youâ€™ve ever met.

I have a niece around that age and canâ€™t imagine trying to get her to write an essay on the effects of soil mismanagement in relation to Reconstruction politics. *See! Your eyes glazed over reading that, so how do we make this work for our AI buddies?*

The Principles of Prompting

Stop asking single-line questions. *Thatâ€™s like using a top-rated cookbook to find out how to make grilled cheese.*

**There are three ways to instantly get better at prompting** and go from grilled cheese to top-notch bolognese. From there, we can get into some specific prompt concepts and the ability to unlock ChatGPTâ€™s full potential.

Principle 1: Context is King

GPT-3.5 is swimming in data. When you ask it for a simple request, it can end up complicating things more than you realize. Did you ever wonder why ChatGPT is so bad at math?

The reality is the LLM is taking words and turning them into patterns. From there, itâ€™s making an educated guess.

Give your chat AI a frame to search into. If you give it a math problem, you need to make sure it grasps that you want it to do math. If youâ€™d like ChatGPT to write a high school essay, you must ensure it knows to write at that level.

**Instead of:** â€œPlan a party for a kid.â€

**Try:** â€œMy child is turning 9. They like superheroes and the color red. Help me plan a party for this weekend. Ten of his friends are coming to my house.â€

Youâ€™ll get a much better response this way. **Context is the cardinal direction** that helps your chat companion find the most correct guess and phrase it the best way.

Principle 2: Get Specific

Pretend youâ€™re writing a law thatâ€™s going to be judged by the Supreme Court of the United States. You know what they look for: narrow tailoring.

**Keep things on track and stay focused.** Try to avoid prompting outside the specific request. Youâ€™ll only hurt the ability of the chat AI to give you a quality response. Odds are theyâ€™ll even skip over parts if you confuse them with too many requests.

It runs parallel with context. *If you set ChatGPT up in a room and then tell it to focus on describing the chair first, youâ€™ll see better results.*

**Instead of:** â€œIâ€™m going to a job interview. Write five questions for me to answer. Add tips for how to not get nervous before the interview. Do not create questions asking about my background.â€

**Try:** â€œYouâ€™re interviewing a software engineer. Create five questions to ask them to understand their skill set and qualifications better.â€

Nothing limits the number of prompts you can do. Focus and expand from the initial request and try not to do everything at once.

Principle 3: When in Doubt: â€œLetâ€™s take this step-by-step.â€

Welcome. **You discovered the magic word today.** This phrase slows everything down for the AI and gets you where you need to go.

You donâ€™t need to start with this phrase. Using it tells ChatGPT to show their work.

Weâ€™ll explain where this concept comes from further in our briefing, but hereâ€™s the TL;DR: sometimes, thereâ€™s a part of our prompt itâ€™s not identified correctly. â€œLetâ€™s take this step-by-step,â€ reminds you and ChatGPT to **slow down and get specific.**

If you learn to utilize this phrase more often and find ways to make it work for you, youâ€™ll become a better prompt engineer. One term can do a lot of heavy lifting.

**Pro-tip:** Weâ€™ve shown you â€œstandardâ€ prompts in all these examples. Many prompt engineers will use â€œStandard QA formâ€ prompts. Hereâ€™s our example for this principle written that way.

**Example:**

*â€œQ: The Industrial Revolution rapidly changed the infrastructure in London. Describe three essential innovations from this period and connect them to Landonâ€™s development.*

*A: Letâ€™s take this step-by-step.â€*

Even without our magic word, this style of standard prompting is quite helpful to adopt.

*However, weâ€™re beginning to stumble into the advanced tactics used in prompt engineering, so itâ€™s time for a new section.*

UNIQUE WAYS TO PROMPT

Letâ€™s preface this: we can go super deep here. Prompt engineering is changing daily, and as these models get more sophisticated, the need to adapt prompts strengthens.

To keep things clean, I will go through these using our metaphor from earlier. **Letâ€™s pretend ChatGPT is a super-intelligent toddler.**

*Got it? With that buy-in, we can continue.*

1/ Role Prompting

Weâ€™ll start with a popular tactic. **Our toddler is great at imagining things.** You tell them theyâ€™re a fireman, and suddenly they can give you detailed ways to ensure your apartment is up to code. Role-playing is a fun, easy way to build context.

The best part of role prompting is how easy it is to understand and use. All you need to do is tell ChatGPT to play a role. From there, the AI will do its best to fill the part *like that enthusiastic drama student from your old high school.*

You can even take this a step further. **Try framing your prompt as a script.** Tell the LLM specific instructions around a scene that gives you the answer to your question.

TRY IT OUT FOR YOURSELF:

Copy this prompt into ChatGPT and find a destination!

â€œAct as a travel guide. I will tell you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion: \[fill it in\]â€

Why would you take that extra step? While popular, role prompting does not necessarily improve accuracy. *You can tell your five-year-old theyâ€™re a mathematician, and theyâ€™ll still manage to screw things up.*

Letâ€™s get deeper.

2/ Chain-of-Thought Prompting

Thereâ€™s a scene in ***Guardians of the Galaxy*** where Rocket Raccoon is trying to [teach young Groot](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL3lvdXR1LmJlL0hyaW1mZ2pmNGs4IiwicG9zdF9pZCI6ImM0ODlmMzhkLTY3NDAtNGRmNS05MWJjLTM1ODA0YTVmNTZkMiIsInB1YmxpY2F0aW9uX2lkIjoiNjNkODQ2ZGUtZDFiZi00ZTVjLWJjYzgtOWMxYzlkMWIxMjA0IiwidmlzaXRfdG9rZW4iOiJkZWRiNmMyNy1hYmM0LTQ5ZDUtYWM2Ny04OTcyZmM1MGVmM2QiLCJpYXQiOjE2NzY5MTkwNjguMTUyLCJpc3MiOiJvcmNoaWQifQ.5eZkDLGRLCXXYv32FYT7kLSbdRK5OK1iemTRf3HVmJw)

how to activate a complicated device. Thatâ€™s chain-of-thought prompting.

**You take an example question and answer it for ChatGPT.** Show them your chain of thought. Then you give it a new question in the same vein and ask it for an answer.

This prompt style allows you to get more specific. Youâ€™re telling your toddler theyâ€™re here to answer this particular question with one specific logic pattern.

Within this specific style is two other sub-categories. Let me give the rundown:

* Zero-shot Chain-of-Thought is â€œLetâ€™s take this step-by-stepâ€ you frame the question the same, but donâ€™t give it a precursor. Instead, you ask it to think through the points made. EX: Q: X is A. Y is B. What is C? A: Letâ€™s take this step-by-step.
* Self-consistency is using several responses to find the most accurate answer. You give ChatGPT more swings at the ball. Take the hits and discover the grouping.

TRY IT OUT FOR YOURSELF:

Copy this prompt into ChatGPT and see how accurate it is:

â€œQ: Which is a faster way to get home?

Option 1: Take an 10 minutes bus, then an 40 minute bus, and finally a 10 minute train.

Option 2: Take a 90 minutes train, then a 45 minute bike ride, and finally a 10 minute bus.

A: Option 1 will take 10+40+10 = 60 minutes.

Option 2 will take 90+45+10=145 minutes.

Since Option 1 takes 60 minutes and Option 2 takes 145 minutes, Option 1 is faster.

Q: Which is a faster way to get to work?

Option 1: Take a 1000 minute bus, then a half hour train, and finally a 10 minute bike ride.

Option 2: Take an 800 minute bus, then an hour train, and finally a 30 minute bike ride.

A: â€

[Learnprompting.org](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwOi8vTGVhcm5wcm9tcHRpbmcub3JnIiwicG9zdF9pZCI6ImM0ODlmMzhkLTY3NDAtNGRmNS05MWJjLTM1ODA0YTVmNTZkMiIsInB1YmxpY2F0aW9uX2lkIjoiNjNkODQ2ZGUtZDFiZi00ZTVjLWJjYzgtOWMxYzlkMWIxMjA0IiwidmlzaXRfdG9rZW4iOiJkZWRiNmMyNy1hYmM0LTQ5ZDUtYWM2Ny04OTcyZmM1MGVmM2QiLCJpYXQiOjE2NzY5MTkwNjguMTUyLCJpc3MiOiJvcmNoaWQifQ.-wOnVYoMNWXYrR5NOB4YYKp4Lmj-aZq3y-pr4Hou9pE)

\- by leaving the â€œA:â€ blank youâ€™re prompting ChatGPT for the answer

Alright, youâ€™re almost thereâ€”one more to go.

3/ General Knowledge Prompting

Youâ€™re going to notice a trend here. This prompt style also circles context and narrow tailoring.

All you do is tell your toddler how the world works. The cow goes moo. The dog goes woof. So what does a cat say?

Itâ€™s an oversimplification, but the core reasoning is there. Show ChatGPT some knowledge and turn that into the only focus for that chat. You can take an article from the internet and summarize it for the model. Make sure to ask if it understands and relay the information to you.

Once you know you have the attention set in the suitable space, get to work. For instance, we can share an Inclined newsletter with it and tell ChatGPT about its structure and tone.

From there, you can provide new information and tell ChatGPT to summarize it within the same structure as Inclined. You both share the same general knowledge now.

TRY IT OUT FOR YOURSELF:

Copy this prompt into ChatGPT and test it out:

â€œPrompt 1. Look over this article here: \[pick an article\]. Breakdown its structure and general tone.

Prompt 2: Recall the structure and tone you mentioned above. Take that general knowledge and summarize this article: \[pick a new one\] using the same structure and tone.â€

Note: this is a heavily simplified version of GA Prompting

Did you know some [people donâ€™t consider](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL25ld3MueWNvbWJpbmF0b3IuY29tL2l0ZW0_aWQ9MzQ0OTU0NTUiLCJwb3N0X2lkIjoiYzQ4OWYzOGQtNjc0MC00ZGY1LTkxYmMtMzU4MDRhNWY1NmQyIiwicHVibGljYXRpb25faWQiOiI2M2Q4NDZkZS1kMWJmLTRlNWMtYmNjOC05YzFjOWQxYjEyMDQiLCJ2aXNpdF90b2tlbiI6ImRlZGI2YzI3LWFiYzQtNDlkNS1hYzY3LTg5NzJmYzUwZWYzZCIsImlhdCI6MTY3NjkxOTA2OC4xNTMsImlzcyI6Im9yY2hpZCJ9.yHKIPujINT89tsqOo07AXk6OrKNgoMjO3fBEYPkAdNY)

that prompt engineering?

PROMPT CULTURE

*â€œHow can something not be prompt engineering if itâ€™s a prompt style?â€*

Good question, imaginary reader. The culture around this skill is relatively fresh. So some of **these concepts are seen as too easy** to be considered accurate prompt testing.

General knowledge prompting is simply establishing the context, and for some, thatâ€™s a baseline everyone needs to do. The same can be said for role prompting, too. *All of these tiny preferences are semantics.*

**Donâ€™t sweat whether youâ€™re a â€œrealâ€ prompt engineer.** Test this out and share your insights in these communities. The opportunity is there for you.

You may even know about DAN (weâ€™ve covered it in previous newsletters) and other AI hacking methods. Those all start with prompt engineering. You can make the case that unless the AI behaves outside its parameters, youâ€™re not genuinely doing prompt engineering.

I'm afraid I have to disagree with that, and **careers are sprouting up everywhere** that center directly on this skill. **Many require a core understanding of the prompt styles weâ€™ve discussed.**

*Yep, you can learn this and make money from talking with AI.*

Anthropic even [posted a role for a prompt engineer](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL2pvYnMubGV2ZXIuY28vQW50aHJvcGljL2UzY2RlNDgxLWQ0NDYtNDYwZi1iNTc2LTkzY2FiNjdiZDFlZCIsInBvc3RfaWQiOiJjNDg5ZjM4ZC02NzQwLTRkZjUtOTFiYy0zNTgwNGE1ZjU2ZDIiLCJwdWJsaWNhdGlvbl9pZCI6IjYzZDg0NmRlLWQxYmYtNGU1Yy1iY2M4LTljMWM5ZDFiMTIwNCIsInZpc2l0X3Rva2VuIjoiZGVkYjZjMjctYWJjNC00OWQ1LWFjNjctODk3MmZjNTBlZjNkIiwiaWF0IjoxNjc2OTE5MDY4LjE1MywiaXNzIjoib3JjaGlkIn0.4s7Htzgoxv0_qM1Ten17oQ5h0_QGM6e1fGUYz_ymgJ4)

that nets a quarter million in salary. I did not make that up and even considered sprucing up the old resume. When a new skill like this comes about, itâ€™s worth looking at.

There are many other examples like this, and OpenAI uses a red teaming strategy where their engineers attempt to prompt hack their own GPT models.

I can tell you all about the open roles here, but tomorrow the whole cycle will change. *Isnâ€™t that exciting, though?* The entire identity around prompt engineering will change by this time next year.

WHAT SHOULD YOU TAKEAWAY?

Communication is everything. **Learning to speak with AI is rising in importance.**

We all watch with mouth agape at the new wonders in AI because we know this will disrupt every industry. If any of this piqued your interest, the window to pursue it is now open. Ride that wave and [learn](https://flight.beehiiv.net/v2/clicks/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJodHRwczovL2xlYXJucHJvbXB0aW5nLm9yZy8iLCJwb3N0X2lkIjoiYzQ4OWYzOGQtNjc0MC00ZGY1LTkxYmMtMzU4MDRhNWY1NmQyIiwicHVibGljYXRpb25faWQiOiI2M2Q4NDZkZS1kMWJmLTRlNWMtYmNjOC05YzFjOWQxYjEyMDQiLCJ2aXNpdF90b2tlbiI6ImRlZGI2YzI3LWFiYzQtNDlkNS1hYzY3LTg5NzJmYzUwZWYzZCIsImlhdCI6MTY3NjkxOTA2OC4xNTMsImlzcyI6Im9yY2hpZCJ9.a67KDSN9yQfZsaMeHpdcbSbtPjD4yFcGW4stdxBjX1M)

to become a brilliant prompt engineer.

Heck, even if you donâ€™t want to switch careers, **talking with ChatGPT and all the newest LLMs is becoming a part of our daily routine.** Get to the point where you maximize every interaction and work with these chatbots to upskill your workflow.

Prompt engineering can save you time, eliminate hassle, and even help you become a more patient person. Focus on what you want and explain it with intent.

Make magic happen, and remember: **take it step-by-step.**"
198,learnmachinelearning,gpt-3,comments,2021-12-28 15:17:08,quickly train classification model for text classification,JosephCurvin,False,0.5,0,rqi2zq,https://www.reddit.com/r/learnmachinelearning/comments/rqi2zq/quickly_train_classification_model_for_text/,2,1640704628.0," I want to use a ml for text classification for my app

I have different sentences which I want to classify by there content / not sentiment

with GPT 3 api  I just need to provide   100+ sentences + there clarification for each classification --> done

 downside cost money to use the model on there api 

I looked into deploy own model on firebase which is pretty easy 

is training your own model much harder then the descriped process on a gpt 3 model   ?

would appreciate any tips or helpful links  

(I dont want to learn everything from scratch justy quickly train and deploy the model)"
199,learnmachinelearning,gpt-3,comments,2023-11-10 15:50:36,Future Confusion Overload,Love_the_Champion,False,0.67,1,17s6vn4,https://www.reddit.com/r/learnmachinelearning/comments/17s6vn4/future_confusion_overload/,2,1699631436.0,"Hello everyone I am a first year student currently pursuing a [B.Tech](https://B.Tech) in Mathematics and Computing. As for my background, I have recently started learning ML and PyTorch and practicing CP.

I want to know if it will be advisable if I remain focused only on AI/ML part of tech or should I also build upon other tech domains like WebDev/Cybersecurity/Blockchain?

And what is the best way to study and master AI/ML. I have a course on Python (includes intro to ML) but just watching and getting to know the stuff (python libraries) seems useless to me, how do I do something where I can also find the application of what I study. 

With the incoming of ChatGPT, it is even easier to overcome the syntax barrier.

When I went to kaggle (beginner competitions), the 2-3 competitions that I saw had to use some pretrained models to make predictions, is it all that there is to ML, learning how to fit data and getting the required predictions with the right model?But now all of it easy after I participated in 2 of these competitions(the Titanic one and one related to Time Series Forecasting). 

Can anyone suggest how I can expand my horizon? I am sure that there must be more to it than I currently know of, I am interested in learning more about advanced topics like NLP, Reinforcement learning, etc. I'd be glad if someone can expand upon it.

I want to do something worthwhile but I don't know the direction I should head to.

Having valuable skills is what I expect of myself before graduating. Please can someone guide me?"
200,learnmachinelearning,gpt-3,relevance,2021-06-29 13:07:05,"Started learning ML 14 months ago, now I'm using GPT-3 to automate CVs!",Camjw1123,False,0.97,752,oa7x3p,https://gfycat.com/ambitioushauntingagama,53,1624972025.0,
201,learnmachinelearning,gpt-3,relevance,2023-01-05 06:32:22,I Built A GPT-3 Powered Productivity App - Tutorial included,SupPandaHugger,False,0.97,208,103rv9o,https://i.redd.it/gtywivh756aa1.gif,17,1672900342.0,
202,learnmachinelearning,gpt-3,relevance,2023-01-08 05:09:46,Major drawback/limitation of GPT-3,trafalgar28,False,0.79,8,106aie8,https://www.reddit.com/r/learnmachinelearning/comments/106aie8/major_drawbacklimitation_of_gpt3/,13,1673154586.0,"I have been working on a project with GPT-3 API for almost a month now. The only drawback of GPT-3 is that the prompt you can send to the model is capped at 4,000 tokens - where a token is roughly equivalent to Â¾ of a word.  Due to this, providing a large context to GPT-3 is quite difficult.

Is there any way to resolve this issue?"
203,learnmachinelearning,gpt-3,relevance,2023-07-12 20:08:11,"GPT-3 architecture, explained clearly, in full detail",goo187,False,0.85,14,14xz5v1,https://www.reddit.com/r/learnmachinelearning/comments/14xz5v1/gpt3_architecture_explained_clearly_in_full_detail/,1,1689192491.0,"Here's a full explanation of how GPT-3 works. The goal was to derive literally everything from scratch (the attention head, transformer, and GPT).

[https://www.deriveit.org/notes/119](https://www.deriveit.org/notes/119)

Let me know if this note was useless/useful to you. All feedback is welcome.

Also, if you'd want to write something similar, let me know!"
204,learnmachinelearning,gpt-3,relevance,2022-11-07 14:11:49,Been learning ML since the start of the year and built a tool with GPT-3 that letâ€™s anyone self-serve their own data questions and create graphs and dashboards,BuggerinoKripperino,False,0.98,474,yoo3ba,https://v.redd.it/n0vjjvr8ejy91,64,1667830309.0,
205,learnmachinelearning,gpt-3,relevance,2021-07-01 16:06:11,Second version of my GPT-3 powered resume writer - now does bullet points and doesn't use pronouns!,Camjw1123,False,0.96,345,oboywl,https://gfycat.com/bitteroffbeatitalianbrownbear,29,1625155571.0,
206,learnmachinelearning,gpt-3,relevance,2022-12-30 01:18:38,A GPT-3 based Terminal/CLI tool that helps you debug your code!,VideoTo,False,0.97,54,zyms85,https://www.reddit.com/r/learnmachinelearning/comments/zyms85/a_gpt3_based_terminalcli_tool_that_helps_you/,11,1672363118.0,"Link - [https://clerkie.co/](https://clerkie.co/)

We built ClerkieCLI -  a GPT-3 based tool that:

\-  automatically detects errors on your terminal,

\- identifies  the programming language,

\- provides an explanation of the error and suggested fix right on your terminal.

This is definitely early days, so if this is something you would find  valuable and wouldn't mind testing a couple iterations of, just sign up here -> [https://forms.gle/8DURoG6NCRxVazNn8](https://forms.gle/8DURoG6NCRxVazNn8)

&#x200B;

https://i.redd.it/xpwnazimsx8a1.gif"
207,learnmachinelearning,gpt-3,relevance,2023-05-04 19:00:00,Top 7 Must-Have GPT-3 Content Generators for Marketers,Chisom1998_,False,0.17,0,137whob,https://youtu.be/1-eppBx7AUo,0,1683226800.0,
208,learnmachinelearning,gpt-3,relevance,2023-02-02 20:16:00,1-click deploy for your GPT-3 App,VideoTo,False,0.71,3,10rzmht,https://www.reddit.com/r/learnmachinelearning/comments/10rzmht/1click_deploy_for_your_gpt3_app/,0,1675368960.0,"Link - [https://github.com/ClerkieAI/berri\_ai](https://github.com/ClerkieAI/berri_ai) 

We made a package that makes it easy for developers to quickly deploy their LLM Agent from Google Colab to production (Web App and API Endpoint).

**How it works?**

Just install the package, import the function, and run deploy.

At the end of the deploy (\~10-15mins), you will get:  

1. A web app to interact with your agent ðŸ‘‰  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/)
2. An endpoint you can query ðŸ‘‰  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/langchain_agent?query=%22who) is obama?""

Want a more detailed walkthrough? Check out our loom - [https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43](https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43)

Weâ€™re still early so would love your feedback and opinions. Feel free to try  us out for free â€“ and if you need help building an agent / want a  specific integration, just let us know!

&#x200B;

https://i.redd.it/om5ns1mb2ufa1.gif"
209,learnmachinelearning,gpt-3,relevance,2023-02-21 14:59:06,I created a Search Engine For Books using GPT-3 ðŸ”ŽðŸ“˜. Here's how you can create it too:,Pritish-Mishra,False,0.94,90,1185dhq,https://youtu.be/SXFP4nHAWN8,17,1676991546.0,
210,learnmachinelearning,gpt-3,relevance,2022-09-25 00:16:18,How does GPT-3 interpret prompts?,psythurism,False,1.0,3,xn8e3m,https://www.reddit.com/r/learnmachinelearning/comments/xn8e3m/how_does_gpt3_interpret_prompts/,2,1664064978.0,"For GPT-3 among the other recent language models, the operation to be performed is given as an open ended command such as ""Summarize the following: ..."", ""Translate into..."", ""Reword such that..."", and GPT-3 will follow the instruction, instead of continuing to write the instruction as I would expect the Markov chain base of these to do (and in-fact they will do outside of the playgrounds that allow these inputs).

I'd love to find information on either 1) How the prompt is translated into something the language model can use and 2) how is the same attention-enhanced markov-chain coerced into performing such a large variety of tasks? Of course, maybe my idea of what composes these models is totally wrong and I need to better understand how transformers work.

Thanks for any resources or insight!"
211,learnmachinelearning,gpt-3,relevance,2022-08-09 01:33:15,Multi-lingual support with GPT-3,juliarmg,False,1.0,1,wjqcfc,https://www.reddit.com/r/learnmachinelearning/comments/wjqcfc/multilingual_support_with_gpt3/,0,1660008795.0,recognise march frighten mighty existence chunky station ten nail correct ` this post was mass deleted with www.Redact.dev `
212,learnmachinelearning,gpt-3,relevance,2023-01-11 19:37:00,Build Your Own No-Code GPT-3 app with Bubble,bruclinbrocoli,False,0.6,1,109dp5a,https://www.reddit.com/r/learnmachinelearning/comments/109dp5a/build_your_own_nocode_gpt3_app_with_bubble/,1,1673465820.0,"This was all built for free -- and took a weekend to ship it. Best part is no - code required. 

[Here's](https://buildspace.so/notes/gpt3-nocode-app) the link to the tutorial. You can also try out the app n get anything explained to you as if you were a 5 year old! 

https://preview.redd.it/3lciqz3evgba1.png?width=2032&format=png&auto=webp&s=a5ec8d7c9efbec364ecc6c35118bc9fde02d7fbc"
213,learnmachinelearning,gpt-3,relevance,2022-12-03 09:11:15,A GPT-3 based Chrome Extension that debugs your code!,VideoTo,False,0.87,18,zbc6rf,https://www.reddit.com/r/learnmachinelearning/comments/zbc6rf/a_gpt3_based_chrome_extension_that_debugs_your/,0,1670058675.0,"Link - [https://chrome.google.com/webstore/detail/clerkie-ai/oenpmifpfnikheaolfpabffojfjakfnn](https://chrome.google.com/webstore/detail/clerkie-ai/oenpmifpfnikheaolfpabffojfjakfnn)  

Built a quick tool I thought would be interesting - itâ€™s a chrome extension that uses GPT-3 under the hood to help debug your programming errors when you paste them into Google (â€œeg. TypeError:â€¦â€). 

This is definitely early days, so if this is something you would find valuable and wouldn't mind testing a couple iterations of, please feel free to join the discord -> [https://discord.gg/KvG3azf39U](https://discord.gg/KvG3azf39U)

https://i.redd.it/p9qd3yhbgn3a1.gif"
214,learnmachinelearning,gpt-3,relevance,2023-01-26 21:25:48,Create Your Chat GPT-3 Web App with Streamlit in Python,pasticciociccio,False,0.5,0,10m2zhq,https://levelup.gitconnected.com/create-your-chat-gpt-3-web-app-with-streamlit-in-python-f0c6e6aede0a,1,1674768348.0,
215,learnmachinelearning,gpt-3,relevance,2023-01-02 05:03:00,Build a GPT-3 Chatbot with Python in 5 Minutes,techie_ray,False,0.33,0,1013wkn,https://youtu.be/KQNSPKYyQ3M,0,1672635780.0,
216,learnmachinelearning,gpt-3,relevance,2021-12-17 16:29:43,GPT-3 libraries,jssmith42,False,1.0,1,ril4sy,https://www.reddit.com/r/learnmachinelearning/comments/ril4sy/gpt3_libraries/,0,1639758583.0,"Has anybody made a full-fledged library of functions powered by GPT-3?

Does Spacy use GPT-3 in any of their methods, for example?

Thanks"
217,learnmachinelearning,gpt-3,relevance,2023-01-26 15:03:57,Clarifying GPT-3 model names and models available to fine tune,Vayuvegula,False,0.75,2,10lttzr,https://www.reddit.com/r/learnmachinelearning/comments/10lttzr/clarifying_gpt3_model_names_and_models_available/,0,1674745437.0,"[https://medium.com/@ravivayuvegula/sorting-through-gpt-3-apis-and-jargon-fcaddfee2e5](https://medium.com/@ravivayuvegula/sorting-through-gpt-3-apis-and-jargon-fcaddfee2e5)

The GPT-3 model names confused the heck out of me, plus it wasn't very clear which models were available for fining tuning versus only API access, so wrote an article to clarify things in my mind.Thought someone else might find it useful too."
218,learnmachinelearning,gpt-3,relevance,2022-09-26 07:32:56,Using GPT-3 to generate viral content on Mac,juliarmg,False,0.75,2,xocfdv,https://www.reddit.com/r/learnmachinelearning/comments/xocfdv/using_gpt3_to_generate_viral_content_on_mac/,0,1664177576.0,"Viral content encompasses three essential principles,

1. Entertainment value
2. Relatable
3. Evokes emotional response

Given the fact that GPT-3 is an autoregressive language model, we can use it to transform a given text into viral content. Here is a sample input and output,

&#x200B;

https://preview.redd.it/t2mxt9jjo5q91.png?width=2240&format=png&auto=webp&s=71d92599932ce77e48b60f4fd40ad0ce53d697c3

The GPT-3 **prompt** I used is,

>*I translate the given boring text into a viral post without compromising the original meaning.*

Another input I tried,

>*I noticed you elected to cancel the subscription to Elephas. I would like to get your feedback before you go.*   
*Your help will be appreciated.*

The output I got is,

>*We're sorry to see you go! Before you cancel your subscription, could you let us know what we could have done better? Your feedback is appreciated.*

As you can see, this content is much more engaging than the original. You can use this for writing emails, blogs, and social media posts.

If you use a Mac and want to write engaging content like that, take a look at [https://elephas.app](https://elephas.app/?utm_campaign=r-learn-machine-viral), it has a built-in feature. Here is an example of me writing a tweet,

https://reddit.com/link/xocfdv/video/x0qo74rno5q91/player"
219,learnmachinelearning,gpt-3,relevance,2022-12-21 17:58:41,"Build Your Own GPT-3 App: A Step-by-Step Guide to Creating ""Gifthub,"" a Personalized Gift Recommendation Tool",bruclinbrocoli,False,0.96,140,zrvshy,https://www.reddit.com/r/learnmachinelearning/comments/zrvshy/build_your_own_gpt3_app_a_stepbystep_guide_to/,2,1671645521.0,"This was all built for free -- and took a weekend to ship it.  Pretty simple n a cool way to understand how to use GPT-3 for something personal. 

[Here's](https://buildspace.so/notes/build-gpt3-app) the link to the tutorial. You can also try out the app n see if it gives you a good gift rec.    
Or - share it with someone who sucks at giving gifts :)   


https://preview.redd.it/t2mrgddqia7a1.png?width=592&format=png&auto=webp&s=dc58613a6a5a4a7f8a55c62ab0ace2fe14c4ef8a"
220,learnmachinelearning,gpt-3,relevance,2022-12-12 02:28:30,"I trained GPT-3 to think like Paul Graham, Elon Musk, and Steve Jobs",alistairmcleay,False,0.59,3,zjjsn7,http://www.aiprotege.com,4,1670812110.0,
221,learnmachinelearning,gpt-3,relevance,2022-11-03 16:43:09,GPT-3 Powered Mac Writing App - Live on ProductHunt,juliarmg,False,1.0,1,yl7mie,https://www.reddit.com/r/learnmachinelearning/comments/yl7mie/gpt3_powered_mac_writing_app_live_on_producthunt/,0,1667493789.0,"Hello everyone,  

I have been building this Mac AI app for 4 months now. Elephas is the only AI writer that works on all your Mac apps. No need to switch windows.  

It helps business professionals and content writers use GPT-3 for their day-to-day tasks.

It differs from other AI tools in that,

1. It works on all apps on Mac.
2. You use your own OpenAI key, so you pay for what you use.
3. It doubles as a productivity tool, starting from Google Sheets formulas to creating presentations.

I have launched it on ProductHunt. If you know ProductHunt, then your support will mean a lot to me, 

 [https://www.producthunt.com/posts/elephas](https://www.producthunt.com/posts/elephas)"
222,learnmachinelearning,gpt-3,relevance,2022-12-19 23:13:47,I wrote a simple article about GPT-3 and ChatGPT for people who know nothing about it,Miserness,False,0.64,3,zq6tox,https://medium.com/@lazaremasset/in-case-you-missed-gpt-3-b92027ac61a2,1,1671491627.0,
223,learnmachinelearning,gpt-3,relevance,2021-01-29 02:25:06,GPT-3 Impressions,vagabondtest,False,0.76,2,l7ghio,https://adrian2045.com/gpt-3-impressions/,0,1611887106.0,
224,learnmachinelearning,gpt-3,relevance,2021-07-25 15:57:21,How are large transformer models like GPT-3 benchmarked?,moschles,False,1.0,1,ore45z,https://www.reddit.com/r/learnmachinelearning/comments/ore45z/how_are_large_transformer_models_like_gpt3/,9,1627228641.0,"The reason that GPT-2 was expanded to have more parameters was because as the total parameters increased, the graphs were not showing diminishing returns. But diminishing returns on what? 

Geoff Hinton has recently written that ,

> The language model GPT-3 with 175 billion parameters (which is still tiny compared with the number of synapses in the human brain) generates noticeably better text than GPT-2 with only 1.5 billion parameters.

Wikipedia article reads, 

> The quality of the text generated by GPT-3 is so high that it is difficult to distinguish from that written by a human, which has both benefits and risks.


WHat does Hinton mean by ""noticeably better text""?    What did the wikipedia author mean by ""quality of the text""?    How are transformer models measured? What is the quantified number used?   

The following graph is the one touted in news articles, 

https://i.imgur.com/euZrR7E.png

But what is the ""Accuracy (%)"" actually showing? What is the nature of this benchmark?"
225,learnmachinelearning,gpt-3,relevance,2022-05-06 10:42:56,Meta's New Model OPT is an Open-Source GPT-3,OnlyProggingForFun,False,0.64,3,ujkll1,https://youtu.be/Ejg0OunCi9U,0,1651833776.0,
226,learnmachinelearning,gpt-3,relevance,2021-06-01 16:26:18,GPT-3 under the hood,nlp_ninja,False,0.8,3,npxypt,https://www.youtube.com/watch?v=kYzHAp_a-FU,0,1622564778.0,
227,learnmachinelearning,gpt-3,relevance,2022-07-19 19:21:10,AI Content Generation with BLOOM Hugging Face - Free GPT-3 Alternative,dulldata,False,1.0,5,w30ztw,https://www.youtube.com/watch?v=ZHx0TsYB3ac,0,1658258470.0,
228,learnmachinelearning,gpt-3,relevance,2021-08-03 06:46:05,Tinder bio generation with OpenAI GPT-3 API,shyamcody,False,1.0,2,owxtwt,https://shyambhu20.blogspot.com/2021/08/tinder-bio-generation-with-openai-gpt-3.html,6,1627973165.0,
229,learnmachinelearning,gpt-3,relevance,2021-12-12 19:24:02,Gopher Explained: 280 BILLION Parameter Model Beats GPT-3,SlickBlueML,False,0.95,17,rew5wo,https://youtu.be/nO653U-Pb5c,0,1639337042.0,
230,learnmachinelearning,gpt-3,relevance,2022-02-23 10:54:42,Tutorial: Getting Started with OpenAI API and GPT-3,python_engineer,False,1.0,7,szeop4,https://youtu.be/Zb5Nylziu6E,0,1645613682.0,
231,learnmachinelearning,gpt-3,relevance,2021-05-26 17:28:59,GPT-3 NEO- setting it up,Szemmoz,False,0.6,1,nlmj5j,https://www.reddit.com/r/learnmachinelearning/comments/nlmj5j/gpt3_neo_setting_it_up/,0,1622050139.0,"Hey, 

I'm trying to load gpt-3-1.3B locally and generate from it. My pc freezes at this point, ubuntu 20.04, nvidia - 1060 gtx. 

>>> from transformers import pipeline 

>>> generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B') >>> generator(""EleutherAI has"", do\_sample=True, min\_length=50)

&#x200B;

Is my pc just too bad to handle the 1.3 version or? Is there a workaround somehow? Any answer is much appreciated!"
232,learnmachinelearning,gpt-3,relevance,2021-11-23 07:08:32,Tutorial: Deploy GPT-J 6B (equivalent of GPT-3 Curie) for inference using FastAPI,Tensorbox_AI,False,1.0,5,r07hfw,https://www.reddit.com/r/learnmachinelearning/comments/r07hfw/tutorial_deploy_gptj_6b_equivalent_of_gpt3_curie/,1,1637651312.0,"Hi everyone, I've created a quick tutorial on how to deploy GPT-J 6B (the HuggingFace version) for inference using FastAPI: [https://www.tensorbox.ai/gpt-j-api](https://www.tensorbox.ai/gpt-j-api?fbclid=IwAR0cxawF4RJctoTaqAM2yQTi2aMGJRyJMi5TCnlcx_f4wttl0DrREPHNcoI) .

Please, let me know what you think. The main difficulty here is making sure it fits into the smallest G4dn instance to save on costs while running the server."
233,learnmachinelearning,gpt-3,relevance,2020-08-15 10:49:38,GPT-3 and a Democratic Revolution in Tech,przemekc,False,0.67,1,ia59wo,https://www.youtube.com/watch?v=x82LW07FQbc,8,1597488578.0,
234,learnmachinelearning,gpt-3,relevance,2022-01-07 13:14:54,A quick review of GPT-3 | What is it and how does it work?,turpyturp,False,0.85,41,ry74jf,https://www.youtube.com/watch?v=xB6hZwYsV2c,1,1641561294.0,
235,learnmachinelearning,gpt-3,relevance,2020-07-27 17:01:22,Crazy GPT-3 Use Cases,przemekc,False,1.0,5,hyw5cc,https://www.youtube.com/watch?v=tsuxlU5IwuA,0,1595869282.0,
236,learnmachinelearning,gpt-3,relevance,2020-07-22 10:52:24,GPT-3 Explained in Under 3 Minutes,eladsnail,False,1.0,3,hvrny6,https://daleonai.com/gpt3-explained-fast,0,1595415144.0,
237,learnmachinelearning,gpt-3,relevance,2020-08-11 17:18:25,Could GPT-3 translate keras to pytorch?,phobrain,False,0.71,4,i7vt7p,https://www.reddit.com/r/learnmachinelearning/comments/i7vt7p/could_gpt3_translate_keras_to_pytorch/,2,1597166305.0,"Feed it your keras program, type 'translated to pytorch, that would be:"" - and no more memory leaks!

Plausible?"
238,learnmachinelearning,gpt-3,relevance,2020-08-19 04:39:34,GPT-3 Gedanken experiment inflicts/infects your mind,phobrain,False,0.67,1,ich4cu,https://www.reddit.com/r/learnmachinelearning/comments/ich4cu/gpt3_gedanken_experiment_inflictsinfects_your_mind/,3,1597811974.0,"1. Feed GPT-3 everything you ever wrote.

2. Finish with a sentence that is the most despicable claim you can imagine, that you could never imagine making, and see how GPT-3 makes arguments for it with your persona.

3. Don't have GPT-3? Try with whatever you have.

4. If successful, see if you recognize why."
239,learnmachinelearning,gpt-3,relevance,2020-08-07 18:23:58,About OpenAI GPT-3 Language Model,sdinesh718,False,1.0,3,i5j3ev,https://www.analyticssteps.com/blogs/about-openai-gpt-3-language-model,0,1596824638.0,
240,learnmachinelearning,gpt-3,relevance,2023-01-19 07:56:20,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.96,330,10fw2df,https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/,47,1674114980.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. Thatâ€™s a *trillion* with a â€œtâ€.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAIâ€™s new brainchild will certainly be mind-bending and language models have been getting bigger â€” fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Letâ€™s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): â€œFrom talking to OpenAI, GPT-4 will be about 100 trillion parametersâ€.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But thereâ€™s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the communityâ€™s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: â€œScaling Laws For Neural Language Modelsâ€.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMindâ€™s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): â€œTraining Compute-Optimal Large Language Modelsâ€

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* â€‹[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the railsâ€‹

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** â­•.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,â€¦ & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
241,learnmachinelearning,gpt-3,relevance,2020-07-28 12:33:11,GPT-3 writes my SQL queries for me,cmillionaire9,False,0.95,15,hzdud6,https://www.youtube.com/watch?v=WlMHYEFt2uA&feature=youtu.be,0,1595939591.0,
242,learnmachinelearning,gpt-3,relevance,2020-10-20 01:15:41,Learn GPT-3 in 10 mins [Free E-Course],SandeshSuvarna,False,0.5,0,jefgqt,https://www.reddit.com/r/learnmachinelearning/comments/jefgqt/learn_gpt3_in_10_mins_free_ecourse/,0,1603156541.0,"After getting an exclusive invite from the OpenAI CTO Greg Brockman himself, I did a couple of experiments with the GPT-3 & I have only one word about the GPT-3 phenomenon which is ""WOW""!!!

* GPT-3 writes a story for you
* GPT-3 writes code for you
* GPT-3 writes marketing taglines for you & whatnot.

I strongly felt the need of explaining its use cases using a short video course & here it is. It's just a 10 mins executive briefing that explains the complete overview of GPT-3.

Go get it here -> [https://gumroad.com/l/QkTig](https://gumroad.com/l/QkTig)

[Elon Musk Tweet: GPT-3](https://preview.redd.it/6dqkd7tai5u51.jpg?width=1920&format=pjpg&auto=webp&s=6cb1d976a0d96aa462f878954b22ed844237660d)"
243,learnmachinelearning,gpt-3,relevance,2020-08-13 08:53:19,How GPT-3 Works - Easily Explained with Animations,jayalammar,False,0.67,2,i8wfaf,https://www.youtube.com/watch?v=MQnJZuBGmSQ,0,1597308799.0,
244,learnmachinelearning,gpt-3,relevance,2021-02-25 05:36:31,[N] New Contextual Calibration Method Boosts GPT-3 Accuracy Up to 30%,rockyrey_w,False,1.0,4,lrza1i,https://www.reddit.com/r/learnmachinelearning/comments/lrza1i/n_new_contextual_calibration_method_boosts_gpt3/,0,1614231391.0,"A research team from UC Berkeley, University of Maryland and UC Irvine identifies pitfalls that cause instability in the GPT-3 language model and proposes a contextual calibration procedure that improves accuracy by up to 30 percent.

Here is a quick read: [New Contextual Calibration Method Boosts GPT-3 Accuracy Up to 30%](https://syncedreview.com/2021/02/24/new-contextual-calibration-method-boosts-gpt-3-accuracy-up-to-30/)

The paper *Calibrate Before Use: Improving Few-Shot Performance of Language Models* is on [arXiv](https://arxiv.org/pdf/2102.09690.pdf)."
245,learnmachinelearning,gpt-3,relevance,2020-08-27 03:29:43,"GPT-3 used to generate code for a machine learning model, just by describing the dataset and required output / Via Matt Shumer(Twitter)",TheInsaneApp,False,0.96,126,ihdpgv,https://v.redd.it/1op7cffisgj51,15,1598498983.0,
246,learnmachinelearning,gpt-3,relevance,2020-08-13 20:37:04,OpenAI GPT-3 - Good At Almost Everything! ðŸ¤–,_quanttrader_,False,0.6,1,i97rkf,https://www.youtube.com/watch?v=_x9AwxfjxvE,0,1597351024.0,
247,learnmachinelearning,gpt-3,relevance,2021-05-09 04:24:47,Learn how to implement and train a GPT-3 like model with only a few lines of code (GPT-Neo),VennifyAI,False,0.86,6,n86duv,https://www.youtube.com/watch?v=GzHJ3NUVtV4,1,1620534287.0,
248,learnmachinelearning,gpt-3,relevance,2020-09-29 08:27:28,Using GPT-3 and a StyleGAN to make Instagram Poetry,meerashine,False,0.75,2,j1v9jf,https://www.youtube.com/watch?v=BnbBRETDRVA&feature=youtu.be,0,1601368048.0,
249,learnmachinelearning,gpt-3,relevance,2020-09-10 19:08:30,"Confused about what Zero-Shot, One-Shot, and Few-Shot means in the GPT-3 paper",Archa3opt3ryx,False,0.92,9,iq9yoa,https://www.reddit.com/r/learnmachinelearning/comments/iq9yoa/confused_about_what_zeroshot_oneshot_and_fewshot/,5,1599764910.0,"I mostly followed along with everything in the [GPT-3 paper](https://arxiv.org/pdf/2005.14165.pdf), but I'm confused about the beginning of section 2. They talk here about providing a certain number of ""demonstrations"" to the model, either zero, one, or several, prior to asking the model to perform the task. However, they also say that don't perform gradient updates to the model after these demonstrations. 

If the model weights aren't changed as a result of the demonstrations, what's the point of the demonstrations? How is the model learning anything from the demonstrations if it can't perform weighting updates? It sounds to me like it's just asking the model to perform a task where a correct output is known, but then not feeding the result back into the model. So how are the demonstrations helping the model perform the task better?"
250,learnmachinelearning,gpt-3,relevance,2021-01-14 17:51:37,Zero-Shot Image Classification with Open AI's CLIP Model - GPT-3 for Images,dulldata,False,1.0,1,kxaq2m,https://www.youtube.com/watch?v=E3JzuvHjEGM,0,1610646697.0,
251,learnmachinelearning,gpt-3,relevance,2020-10-29 11:18:16,How did I get access to GPT-3 OpenAI's API? Tips are shared at 5:22 in the video! The rest of the videos explains what can GPT-3 really do and how it can help you or your company.,OnlyProggingForFun,False,0.71,3,jk85j9,https://youtu.be/Gm4AMjV8ErM?t=322,1,1603970296.0,
252,learnmachinelearning,gpt-3,relevance,2020-11-29 20:52:26,What is the hype about the GPT-3 transformer and what is real? (GPT3 paper deep dive),gordicaleksa,False,0.85,26,k3h26h,https://youtu.be/fVt387VZJe8,0,1606683146.0,
253,learnmachinelearning,gpt-3,relevance,2020-07-23 13:37:47,Want to know what the GPT-3 craze is all about? This video is perfect for anyone to get a good idea about GPT-3!,AICoffeeBreak,False,0.5,0,hwfsnw,https://youtu.be/5fqxPOaaqi0,0,1595511467.0,
254,learnmachinelearning,gpt-3,relevance,2023-11-03 05:00:17,How do y'all deal with hallucinating in GPT 3.5?,supa_ai,False,0.74,16,17mngkq,https://www.reddit.com/r/learnmachinelearning/comments/17mngkq/how_do_yall_deal_with_hallucinating_in_gpt_35/,16,1698987617.0,"Hey guys,

We're trying to build an AI chatbot for internal purposes. So far, we've tried the usual suspects like different approaches to prompt engineering and RAG.

The main issue is that despite RAG retrieving the correct context, we still experience significant (3 in 10) amounts of hallucination. Has anyone experienced the same problem? We'd love to hear any alternative approaches or discussion here on alternate methods."
255,learnmachinelearning,gpt-3,relevance,2023-05-02 08:48:46,How GPT-3.5 crushes my high score in 2048,inishchith,False,0.74,55,135ffje,https://v.redd.it/q22lna91tdxa1,28,1683017326.0,
256,learnmachinelearning,gpt-3,relevance,2020-12-04 21:57:28,"I'm not that good of a programmer, but I was wondering on how to get into using GPT-3",testaccount_2424,False,0.33,0,k6ujtp,https://www.reddit.com/r/learnmachinelearning/comments/k6ujtp/im_not_that_good_of_a_programmer_but_i_was/,0,1607119048.0,"I've had an idea for a text writing algorithm (it's a bit different to what people have made so far) and I'd love to work on making it and I figured GPT-3 is the best thing to use for this.

The problem is I'm not a great programmer, and I've never worked with AI before, but I'm just wondering about what steps I should take to be able to make this project work. I've seen some summaries on how to work GPT-2 a while ago, but they just seemed very vague and didn't really explain a lot. Could somebody give me a bit of advice on what I need to do?"
257,learnmachinelearning,gpt-3,relevance,2020-09-13 12:49:48,"GPT-3 concrete real-world examples of what it can do. Do you think GPT-3 will change our lives, or is it just hype? Are the applications really useful and real, in the real-world, or are they only the hand-picked results by the researchers and startup to get some hype around them and followers?",OnlyProggingForFun,False,0.97,46,irxokh,https://www.youtube.com/watch?v=Gm4AMjV8ErM,3,1600001388.0,
258,learnmachinelearning,gpt-3,relevance,2023-08-23 17:48:08,Fine Tuning GPT-3.5 Turbo Video Tutorial,ComprehensiveRise569,False,1.0,2,15zb308,https://www.reddit.com/r/learnmachinelearning/comments/15zb308/fine_tuning_gpt35_turbo_video_tutorial/,0,1692812888.0,"
Here is a quick demo on how to fine tune and retrieve results from a GPT-3.5 Turbo Model

https://youtu.be/9iPtmLpYG6c"
259,learnmachinelearning,gpt-3,relevance,2023-01-15 00:08:37,Is it still worth learning NLP in the age of API-accessibles LLM like GPT?,CrimsonPilgrim,False,0.94,63,10c509n,https://www.reddit.com/r/learnmachinelearning/comments/10c509n/is_it_still_worth_learning_nlp_in_the_age_of/,24,1673741317.0,"A question that, I hope, you will find legitimate from a data science student.

I am speaking from the point of view of a data scientist not working in research.

Until now, learning NLP could be used to meet occasional business needs like sentiment analysis, text classification, topic modeling....

With the opening of GPT-3 to the public, the rise of ChatGPT, and the huge wave of applications, sites, plug-ins and extensions based on this technology that are accessible with a simple API request, it's impossible not to wonder if spending dozens of hours diving into this field if ML wouldn't be as useful today as learning the source code of the Pandas library. 

In some specialized cases, it could be useful, but GPT-3, and the models that will follow, seem to offer more than sufficient results for the immensity of the cases and for almost all classical NLP tasks. Not only that, but there is a good chance that the models trained by giants like Open-AI (Microsoft) or Google can never be replicated outside these companies anyway.  With ChatGPT and its incomparable mastery of language, its ability to code, summarize, extract topics, understand... why would I bother to use BERT or a TF-IDF vectorizer when an API will be released? Not only it would be easily accessible, but it also would be much better at the task, faster and cheaper.

In fact, it's a concern regarding all the machine learning field in general with the arrival of powerful ""no-code"" applications, which abstract a large part of the inherent complexity of the field. There will always be a need for experts, for safeguards, but in the end, won't the Data Scientist who masters the features of GPT-3 or 4 and knows a bit of NLP be more efficient than the one who has spent hours reading Google papers and practicing on Gensim, NLTK, spacy... It is the purpose of an API to make things simpler eventually... At what point is there no more reason to be interested in the behind-the-scenes of these tools and to become simple users rather than trying to develop our own techniques?"
260,learnmachinelearning,gpt-3,relevance,2024-01-05 02:58:33,Run Mixtral 8x7B MoE for free | Better alternative to GPT 3.5,aniketmaurya,False,0.5,0,18yw5c6,https://youtu.be/6wasqeTeUD0,0,1704423513.0,
261,learnmachinelearning,gpt-3,relevance,2022-12-08 13:41:28,Generating Text With Contrastive Search vs GPT-3/ChatGPT,ledmmaster,False,0.83,4,zfz9cs,https://forecastegy.com/posts/generating-text-with-contrastive-search-vs-gpt-3-chatgpt/,0,1670506888.0,
262,learnmachinelearning,gpt-3,relevance,2021-08-10 19:53:11,How many days did it take to train GPT-3? Is training a neural net model a parallelizable task?,abcaircraft,False,1.0,1,p1wvg4,https://www.reddit.com/r/learnmachinelearning/comments/p1wvg4/how_many_days_did_it_take_to_train_gpt3_is/,12,1628625191.0,"&#x200B;

[Table showing Compute used to train GPT-3 \(Taken from the GPT-3 paper\)](https://preview.redd.it/dsbo5ul9zkg71.png?width=1157&format=png&auto=webp&s=d107292603ca7d324a060e3c1b213ea07b1c6358)

I am trying to read the GPT-3 paper.

How many days did it take to train the GPT-3 model? From the above table it says that it took 3640 days of training for GPT-3. That is 9.97 years. Am I right?

If then how did they train the model for a company that was setup 5 years ago? Is training a neural net model a parallelizable task for them to train on many GPUs in parallel and reduce the time needed to train? In my opinion optimising the weights cannot be a parallelizable task as each weight have to be optimised step by step slowly through each back-propagation. Each weight will reach the optimum value only by changing it's value little by little in sequential order. So it cannot be a parrallelizable task. Am I right?

What does tokens mean in this table?"
263,learnmachinelearning,gpt-3,relevance,2023-02-19 13:55:13,ChatGPT History,eforebrahim,False,0.86,255,116au66,https://i.redd.it/dv8cfj0nz6ja1.jpg,27,1676814913.0,
264,learnmachinelearning,gpt-3,relevance,2023-11-27 21:28:23,can i fine-tune gpt 3.5 turbo model for a domain specific task on my laptop? (32GPU),Life_Ask2806,False,0.67,1,185e9pg,https://www.reddit.com/r/learnmachinelearning/comments/185e9pg/can_i_finetune_gpt_35_turbo_model_for_a_domain/,1,1701120503.0,
265,learnmachinelearning,gpt-3,relevance,2023-01-04 13:49:10,ML study plan according to ChatGPT,adastro,False,0.67,1,10344lj,https://www.reddit.com/r/learnmachinelearning/comments/10344lj/ml_study_plan_according_to_chatgpt/,2,1672840150.0,"People often ask for recommendations about how to get involved with ML, so I thought it would have been interesting to ask ChatGPT directly (specifically about GPT-3 tech).

### The prompt

> Please make a detailed study plan for the math topics one needs to know in order to implement and understand GPT-3 technology. Provide them in the right order (prerequisites for one topic must come before that topic).  Add an approximate time schedule, considering the case of a person who can devote 4 hours/week to studying. Please go into the specifics and add only the best books and online course references (with their full link) for each topic.

### The answer

GPT-3 (short for ""Generative Pre-trained Transformer 3"") is a state-of-the-art language processing technology developed by OpenAI. It uses machine learning techniques to generate human-like text and has a wide range of applications, including language translation, question answering, and language generation.

To understand and implement GPT-3 technology, you will need a strong foundation in mathematics and computer science. Specifically, you will need to be proficient in the following areas:

1. **Linear algebra**: This is a fundamental mathematical discipline that deals with the study of vector spaces and linear transformations. It is a key component of machine learning and is used to represent data in a concise and efficient manner.
    
    Approximate time to complete: 4-6 weeks

    Resources:

    - Khan Academy's Linear Algebra course: https://www.khanacademy.org/math/linear-algebra
    - Gilbert Strang's Linear Algebra textbook

2. **Calculus**: This is a branch of mathematics that deals with the study of rates of change and the accumulation of quantities. It is essential for understanding the mathematical foundations of machine learning and is used to optimize machine learning models.

    Approximate time to complete: 6-8 weeks

    Resources:

    - Khan Academy's Calculus course: https://www.khanacademy.org/math/calculus-home
    - James Stewart's Calculus textbook

3. **Probability and statistics**: This is the study of random phenomena and the analysis of data. It is used to model and understand the uncertainty inherent in machine learning systems.

    Approximate time to complete: 4-6 weeks

    Resources:

    - Khan Academy's Probability and Statistics course: https://www.khanacademy.org/math/statistics-probability
    - Sheldon Ross's A First Course in Probability textbook

4. **Artificial intelligence**: This is the study of how to design intelligent computer systems that can learn, adapt, and make decisions. It is a broad field that encompasses a range of subdisciplines, including machine learning, natural language processing, and robotics.

    Approximate time to complete: 6-8 weeks

    Resources:

    - Stanford's Introduction to Artificial Intelligence course: https://online.stanford.edu/courses/cs221-artificial-intelligence-principles-and-techniques
    - Peter Norvig and Stuart Russell's Artificial Intelligence: A Modern Approach textbook

5. **Natural language processing**: This is the study of how to design computer systems that can understand and generate human language. It is a key component of GPT-3 and is used to process and generate human-like text.
    
    Approximate time to complete: 4-6 weeks

    Resources:

    - Stanford's Natural Language Processing course: https://online.stanford.edu/courses/cs224n-natural-language-processing-deep-learning    - Jurafsky and Martin's Speech and Language Processing textbook
---

(I removed links to online stores since I'm not sure whether this would break some rules here. Also, some links were broken.)
The book suggestions changed whenever I regenerated the response or made minor changes to the prompt, so I suppose that the model doesn't have a very strong opinion about what the ""best"" books are. Online courses were quite stable across answers, instead.

Please share your opinions and more resources if you like :)"
266,learnmachinelearning,gpt-3,relevance,2023-04-17 13:33:53,ChatGPT Consumes 500ml Of Water To Answer 20 Question,matthew199222,False,0.47,0,12pg5pu,https://youtu.be/hcY_RPcC11I,0,1681738433.0,"One of the studyâ€™s most startling revelations is that Microsoft, in partnership with OpenAI, consumed a staggering 185,000 gallons of water solely for training GPT-3. This is equivalent to the water required to cool a nuclear reactor, or the amount needed to produce 370 BMW cars and 320 Tesla electric vehicles. The research also highlights that if Microsoft had trained GPT-3 in its larger Asian data centers, the water consumption would have tripled."
267,learnmachinelearning,gpt-3,relevance,2023-08-03 23:39:57,What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?,Claud1ao,False,0.6,1,15hjw2z,https://www.reddit.com/r/learnmachinelearning/comments/15hjw2z/what_would_be_the_initial_costs_of_developing_a/,2,1691105997.0,"I was wondering if this would be super expensive or not.

The cost to develop GPT-3 was about $4 millions according to some resources online. 

Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?

Any answer is appreciated.

Thanks in advance."
268,learnmachinelearning,gpt-3,relevance,2022-02-23 18:07:47,Lifetime Access to 170+ GPT3 Resources,bhaskar2191,False,0.6,5,sznt65,https://www.reddit.com/r/learnmachinelearning/comments/sznt65/lifetime_access_to_170_gpt3_resources/,0,1645639667.0,"Hi Makers,

Good day. Here I am with my next product.

[https://shotfox.gumroad.com/l/gpt-3resources](https://shotfox.gumroad.com/l/gpt-3resources)

For the past few months, I am working on collecting all the GPT-3 related resources, that inlcludes, tweets, github repos, articles, and much more for my next GPT-3 product idea.

By now, the resource count have reached almost 170+ and thought of putting this valuable database to public and here I am.

If you are also someone who is admirer of GPT-3 and wanted to know from its basics till where it is used in the current world, this resource database would help you a lot.

***Have categorized the resources into multiple as below:***

* Articles
* Code Generator
* Content Creation
* Design
* Fun Ideas
* Github Repos
* GPT3 Community
* Ideas
* Notable Takes
* Products
* Reasoning
* Social Media Marketing
* Text processing
* Tutorial
* Utilities
* Website Builder"
269,learnmachinelearning,gpt-3,relevance,2023-03-24 17:33:03,How-to-Fine-Tune GPT-3-Model-for-Named-Entity-Recognition,Lilith-Smol,False,1.0,1,120rmgy,https://ubiai.tools/blog/article/How-to-Fine-Tune-GPT-3-Model-for-Named-Entity-Recognition,0,1679679183.0,
270,learnmachinelearning,gpt-3,relevance,2023-01-27 19:38:05,"A python module to generate optimized prompts, Prompt-engineering & solve different NLP problems using GPT-n (GPT-3, ChatGPT) based models and return structured python object for easy parsing",StoicBatman,False,1.0,12,10mtvn5,https://www.reddit.com/r/learnmachinelearning/comments/10mtvn5/a_python_module_to_generate_optimized_prompts/,2,1674848285.0,"Hi folks,

I was working on a personal experimental project related to GPT-3, which I thought of making it open source now. It saves much time while working with LLMs.

If you are an industrial researcher or application developer, you probably have worked with GPT-3 apis. A common challenge when utilizing LLMs such as #GPT-3 and BLOOM is their tendency to produce uncontrollable & unstructured outputs, making it difficult to use them for various NLP tasks and applications.

To address this, we developed **Promptify**, a library that allows for the use of LLMs to solve NLP problems, including Named Entity Recognition, Binary Classification, Multi-Label Classification, and Question-Answering and return a python object for easy parsing to construct additional applications on top of GPT-n based models.

Features ðŸš€

* ðŸ§™â€â™€ï¸ NLP Tasks (NER, Binary Text Classification, Multi-Label Classification etc.) in 2 lines of code with no training data required
* ðŸ”¨ Easily add one-shot, two-shot, or few-shot examples to the prompt
* âœŒ Output is always provided as a Python object (e.g. list, dictionary) for easy parsing and filtering
* ðŸ’¥ Custom examples and samples can be easily added to the prompt
* ðŸ’° Optimized prompts to reduce OpenAI token costs

&#x200B;

* GITHUB: [https://github.com/promptslab/Promptify](https://github.com/promptslab/Promptify)
* Examples: [https://github.com/promptslab/Promptify/tree/main/examples](https://github.com/promptslab/Promptify/tree/main/examples)
* For quick demo -> [Colab](https://colab.research.google.com/drive/16DUUV72oQPxaZdGMH9xH1WbHYu6Jqk9Q?usp=sharing)

Try out and share your feedback. Thanks :)

Join our discord for Prompt-Engineering, LLMs and other latest research discussions  
[discord.gg/m88xfYMbK6](https://discord.gg/m88xfYMbK6)

[NER Example](https://preview.redd.it/bwnl67gu1nea1.png?width=1236&format=png&auto=webp&s=6c180552f65413c3a94ed06f5d47da93a9641392)

&#x200B;

https://preview.redd.it/vx9nb94w1nea1.png?width=1398&format=png&auto=webp&s=fc392c8ee5add4ee82f45c22a65532da89491f69"
271,learnmachinelearning,gpt-3,relevance,2022-05-13 23:17:56,Can we write codes automatically with GPT-3?,shyamcody,False,0.42,0,up43b5,https://shyambhu20.blogspot.com/2022/05/can-we-write-codes-automatically-with.html,7,1652483876.0,
272,learnmachinelearning,gpt-3,relevance,2023-02-23 15:35:40,"I've built a few tools on top of GPT-3.5 (text generation, q&a with embeddings). AMA about resources and AI dev stacks for building with OpenAI's APIs",TikkunCreation,False,0.75,2,11a0ka0,https://www.reddit.com/r/learnmachinelearning/comments/11a0ka0/ive_built_a_few_tools_on_top_of_gpt35_text/,8,1677166540.0,"Started building with GPT-3 in July 2022 and have built a few things since then.

Things I've done have involved:

* Text generation (the basic GPT function)
* Text embeddings (for search, and for similarity, and for q&a)
* Whisper (via serverless inference, and via API)
* Langchain and GPT-Index/LLama Index
* Pinecone for vector db

I don't know much, but I know infinitely more than when I started and I sure could've saved myself back then a lot of time.

So ask me anything that might save you time or wasted effort! Some suggested questions would be things about what the best tools and tutorials/examples to use for a given goal/project are, comparisons between tools/stacks. Also, go with any questions because other people from the subreddit will probably chime in too"
273,learnmachinelearning,gpt-3,relevance,2022-04-04 06:36:24,"How can translation neural networks like Google Translate, with such high usage, stay free while GPT-3 has to charge its service to cover computation costs?Can fewer parameters afford high usage?Is it possible that Google's switch to 100% renewable energy has allowed this and other AI tools free?",Irokesenschnitt,False,1.0,2,tvvd0a,/r/datascience/comments/tvvbds/how_can_translation_neural_networks_like_google/,1,1649054184.0,
274,learnmachinelearning,gpt-3,relevance,2023-02-11 06:58:18,[N] New Open-Source Version Of ChatGPT â­•,LesleyFair,False,0.98,115,10zep6u,https://www.reddit.com/r/learnmachinelearning/comments/10zep6u/n_new_opensource_version_of_chatgpt/,8,1676098698.0,"GPT is getting competition from open-source.

A group of researchers, around the YouTuber [Yannic Kilcher](https://www.ykilcher.com/), have announced that they are working on [Open Assistant](https://github.com/LAION-AI/Open-Assistant). The goal is to produce a chat-based language model that is much smaller than GPT-3 while maintaining similar performance.

If you want to support them, they are crowd-sourcing training data [here](https://open-assistant.io/).

**What Does This Mean?**

Current language models are too big.

They require millions of dollars of hardware to train and use. Hence, access to this technology is limited to big organizations. Smaller firms and universities are effectively shut out from the developments.

Shrinking and open-sourcing models will facilitate academic research and niche applications.

Projects such as Open Assistant will help to make language models a commodity. Lowering the barrier to entry will increase access and accelerate innovation.

What an exciting time to be alive! 

Thank you for reading! I really enjoyed making this for you!  
The Decoding â­• is a thoughtful weekly 5-minute email that keeps you in the loop about machine research and the data economy. [Click here to sign up](https://thedecoding.net/)!"
275,learnmachinelearning,gpt-3,relevance,2023-03-30 19:44:32,Personalize Your Own Language Model with xTuring - A Beginner-Friendly Library,x_ml,False,0.99,59,126x6ua,https://www.reddit.com/r/learnmachinelearning/comments/126x6ua/personalize_your_own_language_model_with_xturing/,7,1680205472.0,"Hi everyone,  


If you are interested in customizing your own language model but don't know where to start, try  [xTuring](https://github.com/stochasticai/xturing).  


xTuring's goal is to empower individuals to fine-tune LLM for their specific tasks with as little as 5 lines of code. With xTuring, you can perform high and low precision fine-tuning with a variety of models, including LLaMA, OPT, Cerebras-GPT, Galactica, BLOOM, and more.   


You can also generate your OWN datasets using powerful models like GPT-3 to train a much smaller model on YOUR specific task. With the latest version, you can also use terminal and web interface to chat with your models.  


Please do check out the repo and show your support if you like our work. Would love if you can also contribute by adding models, raising issues or raising PRs for fixes.  


xTuring Github: [https://github.com/stochasticai/xturing](https://github.com/stochasticai/xturing)

If you are interested in getting involved, I am happy to help you on our Discord: [https://discord.gg/TgHXuSJEk6](https://discord.gg/TgHXuSJEk6)

https://i.redd.it/mvxb7i5fixqa1.gif"
276,learnmachinelearning,gpt-3,relevance,2023-04-12 23:00:52,Fine Tuning ChatGPT on Full Documents?,Simusid,False,0.67,2,12k2vyt,https://www.reddit.com/r/learnmachinelearning/comments/12k2vyt/fine_tuning_chatgpt_on_full_documents/,1,1681340452.0,"I want to fine tune GPT-3 using internal corporate documents.   They are mostly paragraphs of text.   Each paragraph might have 5 or 6 sentences.  Per the API, I have to provide prompt/completion pairs in the format:

{""prompt"": ""<prompt text>"", ""completion"": ""<ideal generated text>""}

If a paragraph consists of <sentence1><sentence2><sentence3>....<sentenceN> does it make sense to build the pairs as:

{""prompt"": ""<sentence1>"", ""completion"": ""<sentence2>""}

{""prompt"": ""<sentence2>"", ""completion"": ""<sentence3>""}

{""prompt"": ""<sentenceN-1>"", ""completion"": ""<sentenceN>""}"
277,learnmachinelearning,gpt-3,relevance,2023-03-03 17:27:18,Using NLP on less common languages,andrea_m2000,False,0.67,1,11h79np,https://www.reddit.com/r/learnmachinelearning/comments/11h79np/using_nlp_on_less_common_languages/,1,1677864438.0,"Hello everyone!

While natural language processing (NLP) for common languages has seen a lot of research, there is still a significant gap when it comes to less common languages. That's why I created [this resource](https://towardsdatascience.com/from-decision-trees-to-transformers-comparing-sentiment-analysis-models-for-macedonian-restaurant-4c2d931ec021) that utilizes cutting-edge models like GPT-3 and others to detect sentiment in restaurant reviews.

I'm excited to share my findings and hope it proves to be helpful in your work. Let me know what you think!"
278,learnmachinelearning,gpt-3,relevance,2021-04-22 20:22:21,What is the difference between GPT-2 and GPT-3? Is it just a larger dataset?,TurtletopSoftware,False,0.64,3,mwduf8,https://www.reddit.com/r/learnmachinelearning/comments/mwduf8/what_is_the_difference_between_gpt2_and_gpt3_is/,9,1619122941.0,Hard to find an answer on Google; too crowded with news stories.
279,learnmachinelearning,gpt-3,relevance,2023-09-23 10:09:19,Looking to build an enthusiastic community for exploring AI,InterestingsBed,False,0.73,5,16q0p5g,https://www.reddit.com/r/learnmachinelearning/comments/16q0p5g/looking_to_build_an_enthusiastic_community_for/,0,1695463759.0,"(Initially I was going to write this alone but I thought it would be more interesting if I made Claude rewrite this)

I've been utterly fascinated by the recent progress in AI, especially language models like GPT-3, Stable Diffusion, and Midjourney that can generate synthetic yet coherent text, images, and more with breathtaking capability. However, I've been disappointed to notice that most people I know aren't really paying close enough attention to these advancements or reflecting deeply enough on their implications.

I'm longing to build an online community for fellow enthusiasts who share my exhilaration and concern for AI. Our goal would be to passionately explore the latest models and research, creatively share ideas for applying them, collaborate on projects, and warmly welcome newcomers. We could zealously discuss everything from using ChatGPT to write heartfelt interactive fiction or poetry, to controversially recreating deepfakes or conjuring photos from thin air, to ambitiously implementing new machine learning techniques.

While much of the mainstream discussion around AI is mired in fearmongering or hype, I'd love for this to be an open-minded place for thoughtful probing of both the promising opportunities and sobering perils of advanced AI. Whether you have a PhD in machine learning or barely grasp what a neural network is, you'd be graciously welcomed to take part in adventures of discovery, ask burning questions, and learn alongside others. My hope is to foster an inclusive environment where people feel at ease wrestling together with complex, intellectually invigorating subject matter.

If you share my passion for seeking a more systematic understanding of AI and would relish contributing to a community like this, please speak up in the comments or send me a message. Let's work together to transform this vision into reality!

TL;DR: I'm looking to build an online community for thoughtful discussion and exploration of recent AI advancements. If you share an interest in models like GPT-3 and Stable Diffusion and want to collaborate with others, let me know!

Edit: here's a discord link for those interested, I'll be posting some colab links, custom models and such if there're enough members, [https://llmops.space/discord](https://llmops.space/discord)"
280,learnmachinelearning,gpt-3,relevance,2021-05-25 15:27:15,Finetuning gpt-3-neo locally,Szemmoz,False,0.76,2,nksedm,https://www.reddit.com/r/learnmachinelearning/comments/nksedm/finetuning_gpt3neo_locally/,0,1621956435.0,"Hello, I'm trying to finetune gpt-3-neo locally, I managed to install CUDA and cuDNN. I've got an nvidia 1060 gtx GPU. Now, the official documentation of [https://github.com/EleutherAI/gpt-neo](https://github.com/EleutherAI/gpt-neo) seems a bit advanced to me, let's say first if I just want to generate text from their pretrained models what are the steps? 

\`\`\`python3 main.py --predict --prompt <example\_prompt.txt> --gpu\_ids <device:GPU:0 device:GPU:1> --model <config\_name>\`\`\`

Where can i check my --gpu ids? 

I've managed to finetune this model with google colab but when I tried to do the same locally, I got CUDA out of memory errors. I think something is wrong as I should be able to train the small 125M version with this PC. 

Any guide or some explanation is much appreciated!"
281,learnmachinelearning,gpt-3,relevance,2023-07-15 21:22:23,"I Hit 700K Views in 3 Months with my open-source Shorts automation framework, ShortGPT",RayVentura,False,0.84,49,150ng7i,https://v.redd.it/i1slpmgd17cb1,13,1689456143.0,
282,learnmachinelearning,gpt-3,relevance,2023-03-24 10:44:06,How to use embeddings to query PDF doucments using NLP,G1bs0nNZ,False,1.0,2,120gikm,https://www.reddit.com/r/learnmachinelearning/comments/120gikm/how_to_use_embeddings_to_query_pdf_doucments/,5,1679654646.0,"Have a project that I'm looking at undertaking. Long story short, but I have about 100-150 PDF documents that relate to a civil case that I'm undertaking on my own, against a government insurance provider, relating to service failures on their part. My finances are limited, due to the nature of the claim. My end goal is to be able to load in the documents, and then query these documents using natural language to be able to retrieve the information.  


I want to do something similar to what [askcorpora.com](https://askcorpora.com) does, and I've gotten as far as understanding that I could use GPT-3 and embeddings to do so, but relevant/recent documentation is hard to find. I have strong technical skills, so could do a certain level of coding, but thought I'd ask here for some good starting points.  


Any help/support would be much appreciated"
283,learnmachinelearning,gpt-3,relevance,2022-07-16 18:18:49,How could I implement GPT-J into an app,throwfift,False,1.0,2,w0mvut,https://www.reddit.com/r/learnmachinelearning/comments/w0mvut/how_could_i_implement_gptj_into_an_app/,1,1657995529.0,"I'm looking to create an app involving chatbots but it  violates one of GPT-3's guidelines (no allowing users to create chatbots). The next best option is GPT-J (which is what that chai app uses im pretty sure) but I can't find a lot of stuff on how to really implement it in an app. GPT-3 does have a lot of guides on how to do something like this, so could I follow one of those and implement GPT-J in the same way? I'm new to ai and this is basically my first project, I've done shit with machine learning on google colab and all that but beyond that I don't have experience in implementing it in an app."
284,learnmachinelearning,gpt-3,relevance,2023-03-30 05:08:53,Transformer fine-tuning on decentralized data,tantoka,False,1.0,1,126ceuz,https://www.reddit.com/r/learnmachinelearning/comments/126ceuz/transformer_finetuning_on_decentralized_data/,0,1680152933.0,"Large language models like GPT-3 have gained immense popularity recently, and, using [Flower](https://flower.dev/), it's easy to transform an existing [Hugging Face](https://huggingface.co/) workflow to train models on decentralized data. This example [blog post](https://huggingface.co/blog/fl-with-flower) will show how to fine-tune a pre-trained distilBERT model on the IMDB dataset for sequence classification (determining if a movie review is positive or not). You can also check out the associated [Colab notebook](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/fl-with-flower.ipynb) and the [code example](https://github.com/adap/flower/tree/main/examples/quickstart_huggingface) from the Flower repo."
285,learnmachinelearning,gpt-3,relevance,2022-10-22 19:07:36,SQL generator AI Model,zeromodz12,False,1.0,3,yavvev,https://www.reddit.com/r/learnmachinelearning/comments/yavvev/sql_generator_ai_model/,0,1666465656.0," Hi, I am looking to create a tool for my management whereas they can enter a question and the tool will convert the question to a SQL statement and execute in our database which will then return the answer. I understand GPT-3 has this functionality, but using it is not free. I am looking for a free solution. I tried searching through Hugging Transformers and have not found anything. Any advice on what I could use?"
286,learnmachinelearning,gpt-3,relevance,2023-04-01 17:50:41,Fine-tune GPT on sketch data (stroke-3),mellamo_maria,False,1.0,2,128tghs,https://www.reddit.com/r/learnmachinelearning/comments/128tghs/finetune_gpt_on_sketch_data_stroke3/,0,1680371441.0,"These past days I have started a personal project where I would like to build a model that, given an uncompleted sketch, it can finish it. I was planning on using some pretrained models that are available in HuggingFace and fine-tune them with my sketch data for my task. The sketch data I have is in stoke-3 format, like the following example:  
\[  
\[10, 20, 1\],  
\[20, 30, 1\],  
\[30, 40, 1\],  
\[40, 50, 0\],  
\[50, 60, 1\],  
\[60, 70, 0\]  
\]  
The first value of each triple is the X-coordinate, the second value the Y-coordinate and the last value is a binary value indicating whether the pen is down (1) or up (0). I was wondering if you guys could give me some instruction/tips about how should I approach this problem? How should I prepare/preprocess the data so I can fit it into the pre-trained models like BERT, GPT, etc. Since it's stroke-3 data and not text or a sequence of numbers, I don't really know how should I treat/process the data.

Thanks a lot! :)"
287,learnmachinelearning,gpt-3,relevance,2023-06-26 17:20:42,"GPT Weekly - 26the June Edition - ðŸŽ™ï¸ Meta's Voicebox is Paused, ðŸ–¼ï¸SDXL 0.9, ðŸ“œAI Compliance & EU Act and more",level6-killjoy,False,0.67,1,14jncn1,https://www.reddit.com/r/learnmachinelearning/comments/14jncn1/gpt_weekly_26the_june_edition_metas_voicebox_is/,0,1687800042.0," 

This is a recap covering the major news from last week.

* ðŸ”¥Top 3 news - Metaâ€™s VoiceBox Paused, SDXL 0.9 and Open AI vs EU Act
* ðŸ—žï¸Interesting reads GPT-4â€™s huge size, AI programming and teaching and more.
* ðŸ§‘â€ðŸŽ“Learning - Transformers, RHLF and Interactive Notebooks

# ðŸ”¥Top 3 AI news in the past week

## 1. Meta's Voicebox: Release Pause

Meta, just like OpenAI, is on a roll. [They released introduced a speech generative model called Voicebox](https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/). It can perform a range of speech-generation tasks it wasn't specifically trained for. 

It's like generative systems for images and text, capable of crafting a variety of styles. It can even modify provided samples. It's multilingual, covering six languages, and can remove noise, edit content, convert styles, and generate diverse samples.

**Why is it important?** Before Voicebox, each speech AI task required individual training with curated data. This game-changing model learns from raw audio and corresponding transcriptions. In contrast to previous autoregressive audio models, Voicebox can adjust any part of a sample, not merely the tail end.

**Whatâ€™s next?** Meta has just â€œintroducedâ€ Voicebox without a proper release. As per them Voicebox model is ripe for misuse. 

[Considering last weekâ€™s promise of free to use LLMs](https://gptweekly.beehiiv.com/p/new-pricing-models-functions-openais-new-updates), this seems like a step back. This might be a reaction to pushback due to Llama or maybe there are unseen profits.

Though there is already a community implementation in progress:

[https://github.com/SpeechifyInc/Meta-voicebox](https://github.com/SpeechifyInc/Meta-voicebox)

## 2. SDXL vs. Midjourney: The Imaging Race

&#x200B;

https://preview.redd.it/w0gb0axzbe8b1.png?width=787&format=png&auto=webp&s=26c0d4228c987362c8a4ccb93ca322dcd44cc6d7

[Stability announced SDXL 0.9 their new text to image model](https://stability.ai/blog/sdxl-09-stable-diffusion). They are now one step closer to a full 1.0 release. 

**Why is it important?** Stable Diffusion is one of the text to image models which can be run on a consumer pc. At least one which has an Nvidia GeForce RTX 20 graphics card. This releases multiple features like using an image to generate variations, filling missing parts of an image and out-painting to extend images. 

**Whatâ€™s next?** Last week, Midjourney also released v5.2 which also has out-painting features and sharper images.

Stability is providing the SDXL 0.9 weights for research purposes. And they will be releasing 1.0 under the CreativeML license. Something to look forward to.

## 3. EU Act AI Compliance: Navigating the Future

[Last week, we talked about the EU proposed legislation](https://gptweekly.beehiiv.com/p/new-pricing-models-functions-openais-new-updates). [An interesting study by Stanford](https://crfm.stanford.edu/2023/06/15/eu-ai-act.html) shows that none of the leading models comply. 

&#x200B;

https://preview.redd.it/6rqyeek0ce8b1.png?width=775&format=png&auto=webp&s=bd589967d5cae8e51b9741364317c1e9a113938b

**Why is it important?** The EU AI Act governs the usage of AI for 450 million people. And often EU rule has a large outlying effect (See: [Brusselâ€™s effect](https://en.wikipedia.org/wiki/Brussels_effect))

[Additionally, as per Time, Altman and OpenAI had lobbied for not putting GPT-3 models in the high risk category. ](https://time.com/6288245/openai-eu-lobbying-ai-act/)â€œBy itself, GPT-3 is not a high-risk system. But \[it\] possesses capabilities that can potentially be employed in high risk use cases.â€

While OpenAI has escaped from being put in the high-risk category it is interesting to see the overall compliance to the law. The fines on non-compliance can go up to 4% of revenue. 

As per the research OpenAI scores 25/48 or just above 50%. Anthropicâ€™s Claue sits last with a 7/48 score. 

**Whatâ€™s next?** As per the researchers it is feasible for foundational models to comply with the EU AI Act. And policymakers should push for transparency. It remains to be seen how much lobbying and change happens on this law, especially regarding the transparency requirements. 

# ðŸ—žï¸10 AI news highlights and interesting reads

1. [GPT-4 is just 8 GPT-3](https://twitter.com/swyx/status/1671272883379908608) inside a trenchcoat.

&#x200B;

https://preview.redd.it/yspswp81ce8b1.png?width=509&format=png&auto=webp&s=6edb86c2ae06e1586d506170ac26b8975b9ee69a

1. [Though the bigger is better approach might be reaching its end](https://www.economist.com/science-and-technology/2023/06/21/the-bigger-is-better-approach-to-ai-is-running-out-of-road). 
2. [92% programmers are using AI Tools, as per Github survey. ](https://www.zdnet.com/article/github-developer-survey-finds-92-of-programmers-using-ai-tools/)
3. So, it is no wonder that [Harvardâ€™s famous Computer Science program - CS50 will have a chatbot teacher](https://www.independent.co.uk/tech/harvard-chatbot-teacher-computer-science-b2363114.html). 

&#x200B;

https://preview.redd.it/7dagasv1ce8b1.png?width=769&format=png&auto=webp&s=6761c68e53fb0b11dd48c06320e09461586ccf90

1. What kind of coding is the future? [Self-healing code](https://stackoverflow.blog/2023/06/07/self-healing-code-is-the-future-of-software-development/). [Though self-repair effectiveness is only on GPT-4. Though it is best to use GPT-3.5 code -> GPT-4 repair -> Human Feedback.](https://huggingface.co/papers/2306.09896) (See below on how RLHF works)
2. [The OpenAI app store might be coming](https://www.reuters.com/technology/openai-plans-app-store-ai-software-information-2023-06-20/). I guess the idea will be to charge flat 30% revenue like the App store.
3. [AI is not just hype money is being pumped in](https://techcrunch.com/2023/06/16/ai-transformating-corporate-america/). 
4. [If you want to be part of the cycle, you need to pitch to investors and business owners. The best way is to use GPT-4](https://clarifycapital.com/the-future-of-investment-pitching).  
5. [One of the places to seriously consider GenAI is The Guardian.](https://www.theguardian.com/help/insideguardian/2023/jun/16/the-guardians-approach-to-generative-ai)
6. [Run inference on any LLM using OpenLLM](https://github.com/bentoml/OpenLLM).

# ðŸ§‘â€ðŸŽ“3 Learning Resources

1. The â€œTâ€ in GPT stands for Transformers. Hereâ€™s an a [Nvidia explainer on Transformers](https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/).
2. GPT-4 is trained using RLHF. [Learn how RLHF actually work and why open source RHLF is difficult.](https://www.interconnects.ai/p/how-rlhf-works)
3. [Interactive workbooks to combine Generative AI models in one document](https://lastmileai.dev/workbooks/clj2y933l000mr0avd2ck42s9). I find interactive notebooks to be the best way to learn concepts in programming. 

Thatâ€™s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
288,learnmachinelearning,gpt-3,relevance,2021-10-09 12:42:54,Research Proposal Suggestions,KAKA7861111,False,1.0,1,q4kkud,https://www.reddit.com/r/learnmachinelearning/comments/q4kkud/research_proposal_suggestions/,11,1633783374.0,"Hi everyone.

I need your feedback on this. I am writing a research proposal. The topic is Coding AI:

&#x200B;

1. I am proposing a solution to train a GPT-3 for code optimization. like input would be code and output would be optimized code in terms of latency and big o notation.

Any related literate. feedback on approach"
289,learnmachinelearning,gpt-3,relevance,2022-06-02 16:26:03,Is there a way to extract semantic relevance from BERT?,EnlightenedMod,False,0.99,5,v3cqj6,https://www.reddit.com/r/learnmachinelearning/comments/v3cqj6/is_there_a_way_to_extract_semantic_relevance_from/,0,1654187163.0,"I want to have something of a cardinality network graph of all words/tokens used to train BERT (or anything similar, ELMO, or ~~GPT-3~~) so that I can determine if 3+ parameterized words are close in contextual/proximal space to each other when considering the lexicon of the source text corpus.

Im trying to do something like this:

[https://towardsdatascience.com/populating-a-network-graph-with-words-17b6c62208ac](https://towardsdatascience.com/populating-a-network-graph-with-words-17b6c62208ac)

&#x200B;

But with a pre-trained model, to see if something like ""water"" is closer to ""fountain"" or to ""insurance"".  A top-k query instead of a correlation matrix would also be acceptable.

&#x200B;

\-some words may have been used incorrectly-

&#x200B;

&#x200B;

E: GPT-3 is a closed beta atm, disregard that one."
290,learnmachinelearning,gpt-3,relevance,2022-01-02 19:44:23,Good colab notebook for very large batches of text?,geosunsetmoth,False,1.0,1,ruhkky,https://www.reddit.com/r/learnmachinelearning/comments/ruhkky/good_colab_notebook_for_very_large_batches_of_text/,0,1641152663.0,"Hey! I've been interesting in using gpt-3 or gpt-2 to generate things like film scripts or social media posts (like the Deep Leffen Bot on twitter). I'd like to train it in a very very large amount of text. Does anyone know what model is best, and if there are any good colab notebooks for this specific task (feeding in very large batches of text instead of only small prompts)?"
291,learnmachinelearning,gpt-3,relevance,2023-02-21 23:18:46,"How big was GPT-3.5's training dataset, and are there any good heuristics for how large an ML dataset needs to be for it to be good?",TikkunCreation,False,0.91,52,118iccl,https://www.reddit.com/r/learnmachinelearning/comments/118iccl/how_big_was_gpt35s_training_dataset_and_are_there/,6,1677021526.0,"Say I want to do a model for fixing bugs in code. How many examples do I need for it to be good?

Or say I want to do a model for scoring boxing matches. How many examples do I need for it to be good?"
292,learnmachinelearning,gpt-3,relevance,2022-12-03 16:16:01,Resources on memory networks/ solutions to the goldfish memory problem?,laul_pogan,False,1.0,1,zbjvs6,https://www.reddit.com/r/learnmachinelearning/comments/zbjvs6/resources_on_memory_networks_solutions_to_the/,0,1670084161.0,"Iâ€™m looking for any instruction or guidance people can provide on current efforts to solve goldfish memory, both for sequential visual generation (comics, films) and for long-form text generation and summary (breaking down whole novels into character and event maps, using those maps to rebuild the novels).

Currently Iâ€™ve been having *some* minimal luck on the text side with gpt-3 davinciiâ€™s ability to parse text into json, but the input window is stymying. In addition, de-duplicating the graph of events/characters is costly. 

Any advice on where to start from square 0 or first principles here? Iâ€™ve got the sense that Iâ€™m naively just trying to hack something together on top of existing frameworks, and that there may be a more intelligent, ground-up way about this."
293,learnmachinelearning,gpt-3,relevance,2023-06-30 17:27:56,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.92,9,14n6lwl,https://www.reddit.com/r/learnmachinelearning/comments/14n6lwl/this_week_in_ai_all_the_major_ai_developments_in/,0,1688146076.0,"1. **Microsoft** has launched AI-powered shopping tools in Bing search and Edge, including AI-generated buying guides which automatically aggregate product specifications and purchase locations for user queriesâ€‹, and AI-generated review summaries that provide concise overviews of online product reviews .
2. **Salesforce AI Research** released **XGen-7B**, a new **open-source** 7B LLM trained on 8K input sequence length for 1.5T tokens.
3. Researchers present **DreamDiffusion**, a novel method for generating high-quality images directly from brain EEG signals without the need to translate thoughts into text.
4. **Google** announced the first *Machine* ***Un****learning Challenge* hosted on Kaggle.
5. **Microsoft** announced a new ***AI Skills Initiative*** that includes free coursework developed with LinkedIn, a new open global grant challenge and greater access to free digital learning events and resources for AI education.
6. **Stability AI** announced **OpenFlamingo V2,** an open-source reproduction of DeepMind's Flamingo model. OpenFlamingo models achieve more than 80% of the performance of their corresponding Flamingo model.
7. **Unity** announces two AI-powered tools: Unity Muse and Unity Sentis. Muse generates animations, 2D sprites, textures etc. in the Unity Editor using text and sketches. Sentis lets you embed an AI model in the Unity Runtime for your game or application. It enables AI models to run on any device where Unity runs..
8. **ElevenLabs** launched **Voice Library** \- a library and community for sharing AI generated voices designed using their *voice Design* tool.
9. **Merlyn Mind** released three **open-source education-specific LLMs**. Merlyn Mind is building a generative AI platform for education where engagement will be curriculum-aligned, hallucination-resistant, and age-appropriate.
10. Amazon's **AWS** has launched a $100 million program, the **Generative AI Innovation Center**, that connects AWS machine learning and artificial intelligence experts with businesses to build and deploy generative AI solutions.
11. New open-source text to video AI model, **Zeroscope\_v2 XL**, released that generates high quality video at 1024 x 576, with no watermarks.
12. Researchers present MotionGPT - a motion-language model to handle multiple motion-relevant tasks.
13. **Databricks** is set to acquire the open-source startup **MosaicML** for $1.3 billion. MosaicML had recently released **MPT-30B,** an open-source model licensed for commercial use that outperforms the original GPT-3 .
14. Generative AI-related job postings in the United States jumped about 20% in May as per Indeedâ€™s data.
15. The source code for the algorithm **DragGAN** (Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold) released and demo available on Huggingface.
16. A new foundation model, **ERNIE** **3.5 b**y Chinaâ€™s Baidu surpassed ChatGPT (3.5) in comprehensive ability scores and outperforms GPT-4 in several Chinese language capabilities.
17. **Adobe** is prepared to pay out any claims in case an enterprise customer loses a lawsuit over the use of content generated by Adobe Firefly, the generative AI image tool.
18. **Google** launched generative AI coding features in Google Colab for Pro+ subscribers in the US.

I didn't add links to news sources here because of auto-mod, but they are included in the newsletter and **you can read the online issue** [**here**](https://aibrews.substack.com/p/ai-generated-buying-guides-in-bing) **without signup**. If you like this news format, you might find my [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. . Thanks"
294,learnmachinelearning,gpt-3,relevance,2022-12-28 17:37:46,chatGPT peeps- anyone else learn new stuff best by actually building something?,bruclinbrocoli,False,0.67,5,zxfnga,https://www.reddit.com/r/learnmachinelearning/comments/zxfnga/chatgpt_peeps_anyone_else_learn_new_stuff_best_by/,4,1672249066.0,"[This intro to chatGPT](https://buildspace.so/notes/intro-to-chatgpt) has some cool (free) challenges at the end to build a telegram bot, a business email generator, or a writing assistant.

What else have people found to learn bout chatGPT that's not just theory?

&#x200B;

https://preview.redd.it/smxv4mzldo8a1.png?width=1026&format=png&auto=webp&s=43081abbfcad449817e520b5e92ba599a18a1525"
295,learnmachinelearning,gpt-3,relevance,2021-08-01 12:54:04,Do autoregressive Transformers use only their decoders when generating text completions?,markbowick,False,0.66,1,ovrldg,https://www.reddit.com/r/learnmachinelearning/comments/ovrldg/do_autoregressive_transformers_use_only_their/,2,1627822444.0,"Hi,

During inference/completion, does a transformer model like GPT-3 use both its encoder & decoder stack, or just the decoder? My inclination is the latter, though I am still new to NLP in general. I would expect the encoder to be used quite heavily during training, but do not understand if or why it would be used during completion/inference.

Thanks,

Mark"
296,learnmachinelearning,gpt-3,relevance,2022-06-03 18:16:55,"What questions should I ask Hugging Face's Chief Evangelist next week, fresh off the company's $100M Series C raise on a $2B valuation to build the GitHub of ML?",4thBrain,False,0.9,40,v45gjp,https://www.reddit.com/r/learnmachinelearning/comments/v45gjp/what_questions_should_i_ask_hugging_faces_chief/,10,1654280215.0,"I've got the unique opportunity to host a live event next week where [Julien Simon](https://www.linkedin.com/in/juliensimon/), Hugging Face's chief evangelist, will be presenting on Building NLP Applications with Transformers.

He's going to present a few slides and then do a live demo of how to build an end-to-end ML application.

Then I've got 10 minutes or so to ask him anything I want.

**What would you ask him?**

Here's my working list of questions:

* Hugging Face is doing so many amazing things.  As an early ML practitioner or a student trying to break into ML, where would you recommend focusing your time if you want to understand how to apply Hugging Face tools in a hands-on way?  Are there any resources that you would recommend our audience check out first?
* What is your perspective on the difference between a Data Scientist, Machine Learning Engineer, and MLOps Engineer in todayâ€™s AI market?  What about at Hugging Face - how does your company make these distinctions?
* How do you think about what is actually happening to the underlying model when a general pre-trained transformer model - say, GPT-2 or GPT-3 - gets fine-tuned with unique text, image, speech, or time-series data?

Note:

Keep in mind that this guy is the real deal.  He wrote the book on Learning Amazon SageMaker (2nd edition last year) while he was a Principal Technical Evangelist for AWS.  Prior to joining AWS, Julien served for 10 years as CTO and VP of Engineering in large-scale web startups, and also wrote the first French-language Linux documentation back in 1992!"
297,learnmachinelearning,gpt-3,relevance,2021-03-23 17:00:48,[N] China's GPT-3? BAAI Introduces Superscale Intelligence Model 'Wu Dao 1.0',rockyrey_w,False,1.0,3,mbjak5,https://www.reddit.com/r/learnmachinelearning/comments/mbjak5/n_chinas_gpt3_baai_introduces_superscale/,1,1616518848.0,"In a bid to promote the research and development of Chinaâ€™s own large-scale pretraining models and further explore universal intelligence from a more fundamental perspective, the Beijing Academy of Artificial Intelligence (BAAI) recently unveiled Wu Dao 1.0, Chinaâ€™s first homegrown super-scale intelligent model system.

Here is the English article: [China's GPT-3? BAAI Introduces Superscale Intelligence Model 'Wu Dao 1.0'](https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/)

The Chinese article ä¸­å›½ AI ç ”ç©¶æ–°çªç ´ï¼šæ™ºæºã€Œæ‚Ÿé“ 1.0ã€å‘å¸ƒ is [here](https://mp.weixin.qq.com/s/9a8CV0OMWE3sb1gQNp4ifg)."
298,learnmachinelearning,gpt-3,relevance,2021-05-02 13:32:08,GPT-1 - Annotated Paper + Paper Summary,shreyansh26,False,0.75,2,n36gok,https://www.reddit.com/r/learnmachinelearning/comments/n36gok/gpt1_annotated_paper_paper_summary/,0,1619962328.0,"GPT-2 and recently, GPT-3 created a lot of hype when they were launched. However, it all started with the ""ImprovingÂ LanguageÂ UnderstandingÂ byÂ GenerativeÂ Pre-Training"" paper which introduced the idea of GPT-1. 

As a part of my Paper Notes series, I have gone through the paper and created a brief yet informative summary of the paper. It will take just take a few minutes to understand GPT-1 well. Check out the links below and happy reading!

Paper Summary -   [Improving Language Understanding by Generative Pre-Training](https://shreyansh26.github.io/post/2021-05-02_language_understanding_generative_pretraining/)

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf)"
299,learnmachinelearning,gpt-3,relevance,2020-07-24 09:42:53,I created a simple Sentence to SQL Converter using GPT - 3,bhavesh91,False,1.0,1,hwywbe,https://www.reddit.com/r/learnmachinelearning/comments/hwywbe/i_created_a_simple_sentence_to_sql_converter/,0,1595583773.0,"I created a simple Sentence to SQL Converter using GPT - 3. If you want to learn how you can use OpenAI's GPT-3 to generate NLP Applications then this simple tutorial should help.  
Video Link : [https://www.youtube.com/watch?v=9g66yO0Jues](https://www.youtube.com/watch?v=9g66yO0Jues)

https://reddit.com/link/hwywbe/video/ojf09fuuzrc51/player"
