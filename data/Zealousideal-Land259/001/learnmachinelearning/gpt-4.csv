,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,id,url,num_comments,created,body
0,learnmachinelearning,gpt-4,top,2021-04-03 15:27:04,"I'm a Senior DS and I put together a Youtube Channel with project tutorials, resume critiques, and career advice. Let me know what you think!",madzthakz,False,0.98,553,mjao5g,https://www.reddit.com/r/learnmachinelearning/comments/mjao5g/im_a_senior_ds_and_i_put_together_a_youtube/,21,1617463624.0,"I've also been setting up free [Data Science Q&As](https://www.reddit.com/r/datascience/comments/jig7pv/im_a_senior_data_scientist_at_disney_and_im/) for you all. On the side, I started putting together useful videos that would have helped me out when I was trying to break into this space. Like I said, the channel consists of modeling tutorials, resume critiques, career advice, and recordings of our Q&A sessions. Here are some examples:

1. [How to build a Spotify recommendation engine](https://youtu.be/tooddaC14q4).
2. [How to leverage GPT-2 to generate descriptions of new Netflix content](https://youtu.be/NvMoFeO0aGE).
3. [Full recordings of 1:1 coaching sessions with an ML student.](https://youtu.be/N2tDfXdZmdE)
4. [Resume Critique of a student who just completed a certificate.](https://youtu.be/Ztexwmrxt2A)
5. [Q&A Recording with a Principal Data Scientist.](https://youtu.be/r-NjlPW-Ihg) 

This is all really new and has been a blast to work on. Let me know what you think. 

[Channel Link](https://www.youtube.com/channel/UC0-S_HnWTDFaXgTbYSL46Ug)

If you like it, definitely subscribe! I try to put out videos every week. 

Also, feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/madhavthaker/). I try to make myself as accessible as possible on there."
1,learnmachinelearning,gpt-4,top,2023-01-19 07:56:20,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.96,332,10fw2df,https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/,47,1674114980.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
2,learnmachinelearning,gpt-4,top,2023-05-11 20:15:46,Top 20 Large Language Models based on the Elo rating system.,kingabzpro,False,0.96,248,13eympz,https://i.redd.it/7xfqr5crf9za1.png,43,1683836146.0,
3,learnmachinelearning,gpt-4,top,2023-09-23 13:42:22,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.96,181,16q4ve6,https://www.reddit.com/r/learnmachinelearning/comments/16q4ve6/this_week_in_ai_all_the_major_ai_developments_in/,16,1695476542.0,"1. **Genmo** releases a new text-to-video model: **Genmo Replay** v0.1, which generates high-quality videos from text without the need for advanced prompt engineering. *Genmo is available for free to create AI videos* \[[*Details*](https://blog.genmo.ai/log/replay-ai-video) | [Genmo *Replay*](https://www.genmo.ai/)\] .
2. **OpenAI** unveils **DALL·E 3** \- a major update to the text-to-image model, which will be integrated in ChatGPT. It will be available to ChatGPT Plus and Enterprise users in October, via the API and in Labs later this fall. Creators can now also opt their images out from future training.
3. **Toyota Research Institute** has developed a technique, powered by generative AI, that enables teaching robots new manipulation abilities in a single afternoon. Using the same robot, same code, and same setup, TRI taught over 60 different dexterous behaviors like peeling vegetables, using hand mixers, preparing snacks, and flipping pancakes.
4. **Microsoft** announced:
   1. Availability of AI Copilot for Windows from September 26th. Copilot will incorporate the context and intelligence of the web, your work data and what you are doing in the moment on your PC to provide better assistance. It will be integrated in Windows 11, Microsoft 365, Edge and Bing.
   2. Bing will add support for DALL.E 3 and deliver more personalized answers based on search history.
   3. New AI powered experiences in Paint, Photos and Clipchamp.
   4. New AI-powered shopping experience
5. **ElevenLabs** released **Projects** \- a tool that lets you generate an entire audiobook at the click of a button. Projects now supports .epub, .pdf, and .txt file imports, as well as initializing a project from a URL.
6. **Deci** presents **DeciDiffusion 1.0** \- an open-source text-to-image latent diffusion model which is 3x faster than Stable Diffusion v1.5 with the same quality.
7. **Google researchers** present a new approach that produces photo-realistic animations from a single picture. The model is trained on automatically extracted motion trajectories from a large collection of real video sequences.
8. **Google** has updated Bard\*\]\*:
9. **Bard Extensions:** With extensions, Bard can now connect to your Google apps and services like Gmail, Docs, Drive, Google Maps, YouTube, and Google Flights and hotels.
10. Users can use Bard’s “Google it” button to more easily double-check its answers and evaluate whether there is content across the web to substantiate it.
11. Bard can now let you continue chat via **shared public links**
12. **YouTube** announces new AI tools for creators. **Dream Screen** will let users create an AI-generated video or image background from text. Automatic AI-dubbing tool called **Aloud**, which will be integrated into YouTube Studio. **AI-powered insights** to generate video ideas and draft outlines. **Assistive Search in Creator Music** where AI will suggest the right music based on your description of your content.
13. **Amazon** announced that its voice assistant Alexa is being upgraded with a new, custom-built large language model.
14. **IBM** open-sources **MoLM** \- a collection of ModuleFormer-based language models ranging in scale from 4 billion to 8 billion parameters. ModuleFormer is a new neural network architecture based on the Sparse Mixture of Experts (SMoE) by IBM researchers. .
15. **Neuralink**, Elon Musk's brain implant startup, set to begin human trials.
16. **Lexica** has released **Aperture v3.5** \- their latest next-gen image model that can create photorealistic images and follows your prompt with precision.
17. **OpenAI** has invited domain experts to collaborate in evaluating and improving the safety of OpenAI's models by joining the new **OpenAI Red Teaming Network**.
18. \*\*GitHub Copilot Chat (\*\*beta) is now available for all individuals.
19. **Replit** announced a virtual hackathon for projects built using **Replit ModelFarm**
20. **Oracle** brings voice-activated AI to healthcare with Clinical Digital Assistant.
21. **Google** and the Department of Defense are building an AI-powered microscope to help doctors spot cancer.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
4,learnmachinelearning,gpt-4,top,2023-07-25 20:56:55,Hi r/learnmachinelearning! To make CUDA development easier I made a GPT-4 powered NVIDIA bot that knows about all the CUDA docs and forum answers (demo link in comments),srnsnemil,False,0.96,171,159kt6u,https://v.redd.it/58hbh8q0d6eb1,15,1690318615.0,
5,learnmachinelearning,gpt-4,top,2023-09-16 13:22:41,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.95,131,16k7heb,https://www.reddit.com/r/learnmachinelearning/comments/16k7heb/this_week_in_ai_all_the_major_ai_developments_in/,17,1694870561.0,"1. **Stability AI** launched Stable Audio, a generative AI tool for music & sound generation from text. The underlying latent diffusion model architecture uses audio conditioned on text metadata as well as audio file duration and start time.
2. **Coqui** released **XTTS** \- a new voice generation model that lets you clone voices in 13 different languages by using just a quick 3-second audio clip.
3. **Microsoft Research** released and open-sourced **Phi-1.5** \- a 1.3 billion parameter transformer-based model with performance on natural language tasks comparable to models 5x larger.
4. **Project Gutenberg**, Microsoft and MIT have worked together to use neural text-to-speech to create and release thousands of **human-quality free and open audiobooks**.
5. Researchers present **NExT-GPT -** an any-to-any multimodal LLM that accepts inputs and generate outputs in arbitrary combinations of text, images, videos, and audio.
6. **Chain of Density (CoD):** a new prompt introduced by researchers from Salesforce, MIT and Colombia University that generates more dense and human-preferable summaries compared to vanilla GPT-4.
7. **Adept** open-sources **Persimmon-8B**, releasing it under an Apache license. The model has been trained from scratch using a context size of 16K.
8. **Adobe's** **Firefly** generative AI models, after 176 days in beta, are now commercially available in Creative Cloud, Adobe Express, and Adobe Experience Cloud. Adobe is also launching Firefly as a standalone web app.
9. **Deci** released **DeciLM 6B**, a permissively licensed, open-source foundation LLM that is 15 times faster than Llama 2 while having comparable quality.
10. Researchers release **Scenimefy** \- a model transforming real-life photos into Shinkai-animation-style images.
11. **Microsoft** open sources **EvoDiff**, a novel protein-generating AI that could be used to create enzymes for new therapeutics and drug delivery methods as well as new enzymes for industrial chemical reactions.
12. Several companies including Adobe, IBM, Nvidia, Cohere, Palantir, Salesforce, Scale AI, and Stability AI have pledged to the White House to develop safe and trustworthy AI, in a voluntary agreement similar to an earlier one signed by Meta, Google, and OpenAI.
13. **Microsoft** will provide legal protection for customers who are sued for copyright infringement over content generated using Copilot, Bing Chat, and other AI services as long as they use built-in guardrails.
14. **NVIDIA** beta released **TensorRT** \- an open-source library that accelerates and optimizes inference performance on the latest LLMs on NVIDIA Tensor Core GPUs.
15. Pulitzer Prize winning novelist Michael Chabon and several other writers sue OpenAI of copyright infringement..
16. **NVIDIA** partners with two of India’s largest conglomerates, Reliance Industries Limited and Tata Group, to create an AI computing infrastructure and platforms for developing AI solutions.
17. **Roblox** announced a new conversational AI assistant that let creators build virtual assets and write code with the help of generative AI.
18. **Google** researchers introduced **MADLAD-400** \- a 3T token multilingual, general web-domain, document-level text dataset spanning 419 Languages.
19. A recent survey by **Salesforce** show that 65% of generative AI users are Millennials or Gen Z, and 72% are employed.  The survey included 4,000+ people across the United States, UK, Australia, and India.
20. **Meta** is reportedly working on an AI model designed to compete with GPT-4.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
6,learnmachinelearning,gpt-4,top,2023-06-03 14:33:38,This week in AI - all the Major AI development in a nutshell,wyem,False,0.98,119,13zeoi3,https://www.reddit.com/r/learnmachinelearning/comments/13zeoi3/this_week_in_ai_all_the_major_ai_development_in_a/,13,1685802818.0,"1. The recently released open-source large language model **Falcon LLM**, by UAE’s Technology Innovation Institute, is now royalty-free for both commercial and research usage. **Falcon 40B,** the 40 billion parameters model trained on one trillion tokens, is ranked #1 on **Open LLM Leaderboard by Hugging Face**.
2. **Neuralangelo**, a new AI model from Nvidia turns 2D video from any device - cell phone to drone capture - into 3D structures with intricate details using neural networks..
3. In three months, JPMorgan has advertised **3,651 AI jobs** and sought a trademark for **IndexGPT**, a securities analysis AI product.
4. **Google** presents **DIDACT** (​​Dynamic Integrated Developer ACTivity), the first code LLM trained to model real software developers editing code, fixing builds, and doing code review. DIDACT uses the software development process as training data and not just the final code, leading to a more realistic understanding of the development task.
5. Researchers from **Deepmind** have presented ‘**LLMs As Tool Makers (LATM)**’ - a framework that allows Large Language Models (LLMs) to create and use their own tools, enhancing problem-solving abilities and cost efficiency. With this approach, a sophisticated model (like GPT-4) can make tools (where a tool is implemented as a Python utility function), while a less demanding one (like GPT-3.5) uses them.
6. **Japan's government** won't enforce copyrights on data used for AI training regardless of whether it is for non-profit or commercial purposes.
7. *‘Mitigating the* ***risk of extinction from AI*** *should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.’ -* One sentence statement signed by leading AI Scientists as well as many industry experts including CEOs of OpenAI, DeepMind and Anthropic.*.*
8. Nvidia launched ‘**Nvidia Avatar Cloud Engine (ACE) for Games**’ - a custom AI model foundry service to build non-playable characters (NPCs) that not only engage in dynamic and unscripted conversations, but also possess evolving, persistent personalities and have precise facial animations and expressions.
9. **OpenAI** has launched a trust/security portal for OpenAI’s compliance documentation, security practices etc..
10. **Nvidia** announced a new AI supercomputer, the **DGX GH200,** for giant models powering Generative AI, Recommender Systems and Data Processing. It has 500 times more memory than its predecessor, the DGX A100 from 2020.
11. Researchers from Nvidia presented **Voyager**, the first ‘LLM-powered embodied lifelong learning agent’ that can explore, learn new skills, and make new discoveries continually without human intervention in the game Minecraft.
12. The a16z-backed chatbot startup **Character.AI** launched its mobile AI chatbot app on May 23 for iOS and Android, and succeeded in gaining over **1.7 million new installs** within a week.
13. Microsoft Research presents **Gorilla**, a fine-tuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls.
14. **OpenAI** has trained a model using process supervision - rewarding the thought process rather than the outcome - to improve mathematical reasoning. Also released the full dataset used.
15. **WPP**, the world's largest advertising agency, and Nvidia have teamed up to use generative AI for creating ads. The new platform allows WPP to tailor ads for different locations and digital channels, eliminating the need for costly on-site production.
16. **PerplexityAI’s** android app is available now, letting users search with voice input, learn with follow-up questions, and build a library of threads.

**If you like this news format**, you might find my  [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with **bite-sized news, learning resources and selected tools**. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
7,learnmachinelearning,gpt-4,top,2023-06-11 17:18:34,"[D] How to Choose a Framework To Evaluate Your LLMs? We've Evaluated GPT-4/3.5, Anthropic Claude, & Cohere Command Across 4 Tasks. Here's What We've Learned.",davidbun,False,0.98,109,146zie8,https://v.redd.it/yy5sdnvo6f5b1,1,1686503914.0,
8,learnmachinelearning,gpt-4,top,2023-06-23 06:14:03,"[Updated] Top Large Language Models based on the Elo rating, MT-Bench, and MMLU",kingabzpro,False,0.94,93,14gqo26,https://i.redd.it/ixdabwx3mp7b1.png,9,1687500843.0,
9,learnmachinelearning,gpt-4,top,2023-09-30 15:01:31,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.97,81,16w93bx,https://www.reddit.com/r/learnmachinelearning/comments/16w93bx/this_week_in_ai_all_the_major_ai_developments_in/,4,1696086091.0,"1. **Meta AI** presents **Emu**, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal.
2. **Meta AI** researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks.
3. **Abacus AI** released a larger 70B version of **Giraffe**. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens\].
4. **Meta** announced:  

   1. **Meta AI** \- a new AI assistant users can interact with on WhatsApp, Messenger and Instagram. Will also be available on Ray-Ban Meta smart glasses and Quest 3, Meta’s mixed reality headset.
   2. **AI stickers** that enable users to generate customized stickers for chats and stories using text. Powered by Llama 2 and the new foundational model for image generation, Emu.
   3. **28 AI characters**, each with a unique personality that users can message on WhatsApp, Messenger, and Instagram.
   4. New AI editing tools, **restyle** and **backdrop** in Instagram.
   5. **AI Studio** \- a platform that supports the creation of custom AIs by coders and non-coders alike.
5. **Cerebras** and **Opentensor** released Bittensor Language Model, ‘**BTLM-3B-8K**’, a new 3 billion parameter open-source language model with an 8k context length trained on 627B tokens of SlimPajama. It outperforms models trained on hundreds of billions more tokens and achieves comparable performance to open 7B parameter models. The model needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models and is available with an Apache 2.0 license for commercial use.
6. **OpenAI** is rolling out, over the next two weeks, new voice and image capabilities in ChatGPT enabling ChatGPT to understand images, understand speech and speak. The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. .
7. **Mistral AI**, a French startup, released its first 7B-parameter model, **Mistral 7B**, which outperforms all currently available open models up to 13B parameters on all standard English and code benchmarks. Mistral 7B is released in Apache 2.0, making it usable without restrictions anywhere.
8. **OpenAI** has returned the ChatGPT browsing feature for Plus subscribers, enabling ChatGPT to access internet for current information. It was disabled earlier as users were able to deploy it to bypass the paywalls of leading news publishers.
9. **Microsoft** has released **AutoGen** \- an open-source framework that enables development of LLM applications using multiple agents that can converse with each other to solve a task. Agents can operate in various modes that employ combinations of LLMs, human inputs and tools.
10. **LAION** released **LeoLM**, the first open and commercially available German foundation language model built on Llama-2
11. Researchers from **Google** and **Cornell University** present and release code for DynIBaR (Neural Dynamic Image-Based Rendering) - a novel approach that generates photorealistic renderings from complex, dynamic videos taken with mobile device cameras, overcoming fundamental limitations of prior methods and enabling new video effects.
12. **Cloudflare** launched **Workers AI** (an AI inference as a service platform), **Vectorize** (a vector Database) and **AI Gateway** with tools to cache, rate limit and observe AI deployments. Llama2 is available on Workers AI.
13. **Amazon** announced the general availability of **Bedrock**, its service that offers a choice of generative AI models from Amazon itself and third-party partners through an API.
14. **Google** announced it’s giving website publishers a way to opt out of having their data used to train the company’s AI models while remaining accessible through Google Search.
15. **Spotify** has launched a pilot program for AI-powered voice translations of podcasts in other languages - in the podcaster’s voic. It uses OpenAI’s newly released voice generation model.
16. **Getty Images** has launched a generative AI image tool, ‘**Generative AI by Getty Images**’, that is ‘commercially‑safe’. It’s powered by Nvidia Picasso, a custom model trained exclusively using Getty’s images library.
17. **Optimus**, Tesla’s humanoid robot, can now sort objects autonomously and do yoga. Its neural network is trained fully end-to-end.
18. **Amazon** will invest up to $4 billion in Anthropic. Developers and engineers will be able to build on top of Anthropic’s models via Amazon Bedrock.
19. **Google Search** indexed shared Bard conversational links into its search results pages. Google says it is working on a fix.
20. **Pika** Labs' text-to-video tool now lets users encrypt a message in a video\].

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
10,learnmachinelearning,gpt-4,top,2023-01-15 00:08:37,Is it still worth learning NLP in the age of API-accessibles LLM like GPT?,CrimsonPilgrim,False,0.94,64,10c509n,https://www.reddit.com/r/learnmachinelearning/comments/10c509n/is_it_still_worth_learning_nlp_in_the_age_of/,24,1673741317.0,"A question that, I hope, you will find legitimate from a data science student.

I am speaking from the point of view of a data scientist not working in research.

Until now, learning NLP could be used to meet occasional business needs like sentiment analysis, text classification, topic modeling....

With the opening of GPT-3 to the public, the rise of ChatGPT, and the huge wave of applications, sites, plug-ins and extensions based on this technology that are accessible with a simple API request, it's impossible not to wonder if spending dozens of hours diving into this field if ML wouldn't be as useful today as learning the source code of the Pandas library. 

In some specialized cases, it could be useful, but GPT-3, and the models that will follow, seem to offer more than sufficient results for the immensity of the cases and for almost all classical NLP tasks. Not only that, but there is a good chance that the models trained by giants like Open-AI (Microsoft) or Google can never be replicated outside these companies anyway.  With ChatGPT and its incomparable mastery of language, its ability to code, summarize, extract topics, understand... why would I bother to use BERT or a TF-IDF vectorizer when an API will be released? Not only it would be easily accessible, but it also would be much better at the task, faster and cheaper.

In fact, it's a concern regarding all the machine learning field in general with the arrival of powerful ""no-code"" applications, which abstract a large part of the inherent complexity of the field. There will always be a need for experts, for safeguards, but in the end, won't the Data Scientist who masters the features of GPT-3 or 4 and knows a bit of NLP be more efficient than the one who has spent hours reading Google papers and practicing on Gensim, NLTK, spacy... It is the purpose of an API to make things simpler eventually... At what point is there no more reason to be interested in the behind-the-scenes of these tools and to become simple users rather than trying to develop our own techniques?"
11,learnmachinelearning,gpt-4,top,2023-04-30 15:45:04,I don't have a PhD but this just feels wrong. Can a person with a PhD confirm?,flaky_psyche,False,0.76,63,133v9s5,https://i.redd.it/fmkvgop7l1xa1.jpg,238,1682869504.0,
12,learnmachinelearning,gpt-4,top,2023-12-25 17:15:18,"Have we reached a ceiling with transformer-based models? If so, what is the next step?",swagonflyyyy,False,0.86,62,18qmohw,https://www.reddit.com/r/learnmachinelearning/comments/18qmohw/have_we_reached_a_ceiling_with_transformerbased/,134,1703524518.0,"About a month ago Bill Gates hypothesized that models like GPT-4 will probably have reached a ceiling in terms of performance and these models will most likely expand in breadth instead of depth, which makes sense since models like GPT-4 are transitioning to multi-modality (presumably transformers-based).

This got me thinking. If if is indeed true that transformers are reaching peak performance, then what would the next model be? We are still nowhere near AGI simply because neural networks are just a very small piece of the puzzle. 

That being said, is it possible to get a pre-existing machine learning model to essentially create other machine learning models? I mean, it would still have its biases based on prior training but could perhaps the field of unsupervised learning essentially construct new models via data gathered and keep trying to create different types of models until it successfully self-creates a unique model suited for the task?

Its a little hard to explain where I'm going with this but this is what I'm thinking:

\- The model is given a task to complete.

\- The model gathers data and tries to structure a unique model architecture via unsupervised learning and essentially trial-and-error.

\- If the model's newly-created model fails to reach a threshold, use a loss function to calibrate the model architecture and try again.

\- If the newly-created model succeeds, the model's weights are saved.

This is an oversimplification of my hypothesis and I'm sure there is active research in the field of auto-ML but if this were consistently successful, could this be a new step into AGI since we have created a model that can create its own models for hypothetically any given task?

I'm thinking LLMs could help define the context of the task and perhaps attempt to generate a new architecture based on the task given to it but it would still fall under a transformer-based model builder, which kind of puts us back in square one."
13,learnmachinelearning,gpt-4,top,2021-06-13 20:57:38,Some YouTube channels that review papers,axetobe_ML,False,0.96,51,nz5szs,https://www.reddit.com/r/learnmachinelearning/comments/nz5szs/some_youtube_channels_that_review_papers/,2,1623617858.0,"When I was reading a Reddit thread. People were wondering if there were YouTubers reviewing papers. As the OP noticed that one of the YouTuber's that he regularly watched stopped uploading videos. There are a few YouTubers that talk about ML and review papers. 

I decided to compile some of the YouTube channels into this short list. 

&#x200B;

[Two Minute Papers](https://www.youtube.com/c/K%C3%A1rolyZsolnai/videos) does great overviews of fascinating papers. Showing the increasing progress of ML.

Some of the videos I liked:

* [4 Experiments Where the AI Outsmarted Its Creators](https://www.youtube.com/watch?v=GdTBqBnqhaQ)

This video showed various AI solving a problem not in the way the researchers intended to. That may include abusing the physics in the simulation or lateral thinking used by the model.

* [A Video Game That Looks Like Reality!](https://youtu.be/22Sojtv4gbg)

A review of a paper that takes GTA V gameplay and converts them to photo-realistic footage.

&#x200B;

[Yannic Kilcher](https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew) does in-depth reviews of various papers. As you go through the paper he shows you his thought process. And showing what important inside the paper. Very useful if don’t read that many papers. (Like me)

Some good videos:

* [Attention Is All You Need](https://www.youtube.com/watch?v=iDulhoQ2pro)

A review of a paper that introduced transformers.

&#x200B;

* [DeepMind's AlphaFold 2 Explained! AI Breakthrough in Protein Folding What we know (& what we don't)](https://youtu.be/B9PL__gVxLI)

A great rundown on protein folding and speculating how Alphafold 2 works.

&#x200B;

* [GPT-3: Language Models are Few-Shot Learners (Paper Explained)](https://youtu.be/SY5PvZrJhLE)

A comprehensive paper reading of the GPT-3 paper.

&#x200B;

[Bycloud](https://www.youtube.com/channel/UCgfe2ooZD3VJPB6aJAnuQng) you may have seen him around on Reddit. Creates short and insightful summaries of papers.

Some videos I liked:

* [AI Sky Replacement with SkyAR](https://www.youtube.com/watch?v=yNwQnrjfg5A)

Summary of paper that creates AR effects in video footage. Adding various effects to the video footage’s sky.

&#x200B;

* [AI Generates Cartoon Characters In Real Life \[Pixel2Style2Pixel\]](https://youtu.be/g-N8lfceclI)

Reviewing a paper that converts cartoon characters to real-life equivalents and vice versa. Also explains how the paper made it easier to adjust the parameters of the GAN. Helping us adjust what images we want to produce.

&#x200B;

[Machine Learning Street Talk](https://www.youtube.com/c/MachineLearningStreetTalk/videos)

This is a podcast series that interviews top ML researchers. While they don’t have videos about papers alone. As they interview various experts in the field. So they talk about many papers as a consequence. 

While this is a short list maybe you can find these channels interesting and learn something new.

\-

*If you found this post useful, then check out my* [*mailing list*](https://www.tobiolabode.com/subscribe) *where I write more stuff like this.*"
14,learnmachinelearning,gpt-4,top,2023-12-03 14:38:25,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.91,46,189ustx,https://www.reddit.com/r/learnmachinelearning/comments/189ustx/this_week_in_ai_all_the_major_ai_developments_in/,1,1701614305.0,"1. **Meta AI** introduced a suite of AI language translation models that preserve expression and improve streaming \[[*Details*](https://ai.meta.com/blog/seamless-communication) *|* [*GitHub*](https://github.com/facebookresearch/seamless_communication)\]:
   1. ***SeamlessExpressive*** enables the transfer of tones, emotional expression and vocal styles in speech translation. You can try a demo of SeamlessExpressive using your own voice as an input [***here***](https://seamless.metademolab.com/expressive)***.***
   2. ***SeamlessStreaming***, a new model that enables streaming speech-to-speech and speech-to-text translations with <2 seconds of latency and nearly the same accuracy as an offline model. In contrast to conventional systems which translate when the speaker has finished their sentence, SeamlessStreaming translates while the speaker is still talking. t intelligently decides when it has enough context to output the next translated segment.
   3. ***SeamlessM4T v2***, a foundational multilingual & multitask model for both speech & text. It's the successor to SeamlessM4T, demonstrating performance improvements across ASR, speech-to-speech, speech-to-text & text-to-speech tasks.
   4. ***Seamless***, a model that merges capabilities from SeamlessExpressive, SeamlessStreaming and SeamlessM4T v2 into one.
2. **Stability AI** released ***SDXL Turbo***: a real-time Text-to-Image generation model. SDXL Turbo is based on a a new distillation technology, which enables the model to synthesize image outputs in a single step and generate real-time text-to-image outputs while maintaining high sampling fidelity.
3. **Mozilla’s** innovation group and Justine Tunney released ***llamafile*** that lets you distribute and run LLMs with a single file. llamafiles can run on six OSes (macOS, Windows, Linux, FreeBSD, OpenBSD, and NetBSD) and on multiple CPU architectures.
4. **Perplexity** released two new PPLX models: ***pplx-7b-online and pplx-70b-online***. These *online LLMs* can leverage the most up-to-date information using the internet when forming a response..
5. **Google DeepMind** presented ***GNoME*** (Graph Networks for Materials Exploration): an AI tool that discovered *2.2 million new crystal structures*, with 380,000 being highly stable and promising for breakthroughs in superconductors, supercomputers, and advanced batteries for electric vehicles.
6. **Amazon** introduced two new Amazon Titan multimodal foundation models (FMs): ***Amazon Titan Image Generator*** (preview) and ***Amazon Titan Multimodal Embeddings***. All images generated by Amazon Titan contain an invisible watermark.
7. Researchers present ***Animatable Gaussians***, a new avatar representation method that can create lifelike human avatars from multi-view RGB videos.
8. **Pika Labs** released a major product upgrade of their generative AI video tool, ***Pika 1.0***, which includes a new AI model capable of generating and editing videos in diverse styles such as 3D animation, anime, cartoon and cinematic using text, image or existing video.
9. **Eleven Labs** announced a ***grant*** program offering 11M text characters of content per month for the first 3 months to solo-preneurs and startups.
10. Researchers from **UC Berkeley** introduced ***Starling-7B***, an open large language model trained using Reinforcement Learning from AI Feedback (RLAIF). It utilizes the GPT-4 labeled ranking dataset, Nectar, and a new reward training pipeline. Starling-7B outperforms every model to date on MT-Bench except for OpenAI’s GPT-4 and GPT-4 Turbo .
11. **XTX Markets** is launching a new $10mn challenge fund, the **Artificial Intelligence Mathematical Olympiad Prize** (AI-MO Prize) The grand prize of $5mn will be awarded to the first publicly-shared AI model to enter an AI-MO approved competition and perform at a standard equivalent to a gold medal in the in the International Mathematical Olympiad (IMO) .
12. **Microsoft Research** evaluated GPT-4 for processing ***radiology reports***, focusing on tasks like disease classification and findings summarization. The study found GPT-4 has a sufficient level of radiology knowledge with only occasional errors in complex context that require nuanced domain knowledge. The radiology report summaries generated by GPT-4 were found to be comparable and, in some cases, even *preferred* over those written by experienced radiologists.
13. **AWS** announced ***Amazon Q***, a new generative AI–powered assistant for businesses. It enables employees to query and obtain answers from various content repositories, summarize reports, write articles, perform tasks, and more, all within their company's integrated content systems. Amazon Q offers over 40 built-in connectors to popular enterprise systems.
14. 18 countries including the US, Britain signed a detailed international agreement on how to keep artificial intelligence safe from rogue actors, pushing for companies to create AI systems that are ‘secure by design’ .

**Source**: AI Brews - you can subscribe [here](https://aibrews.com/). it's free to join, sent only once a week with ***bite-sized news, learning resources and selected tools.*** I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks."
15,learnmachinelearning,gpt-4,top,2024-01-04 21:15:12,Natural Language Processing (NLP) Learning Path - In depth,millhouse056,False,0.98,48,18yo5kp,https://www.reddit.com/r/learnmachinelearning/comments/18yo5kp/natural_language_processing_nlp_learning_path_in/,9,1704402912.0,"Hi friends, i'm currently engaged in NLP and created an pretty extense roadmap or learning path so begginers don't feel lost, it covers from the basics to advanced cutting-edge concepts.

Feedback is appreciated.

&#x200B;

\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-

&#x200B;

NLP Learning Roadmap

1. Prerequisites:

&#x200B;

* Mathematics:

&#x200B;

* Linear algebra
* Probability and statistics

&#x200B;

* Programming:

&#x200B;

* Proficiency in a programming language (e.g., Python)

**2. Introduction to NLP:**

&#x200B;

* Definition      and scope of NLP
* Historical      development of NLP
* Key challenges      and applications

**3. Text Analysis:**

&#x200B;

* **Lexical Analysis:**

&#x200B;

* Word meaning and structure

· Morphology (word formation)

· lemmatization (base form identification)

&#x200B;

* **Syntactic Analysis:**

· Parts-of-speech tagging

· Dependency parsing

· Constituency parsing

&#x200B;

* **Semantic Analysis:**

· Extracting meaning

· Encompassing word embedding models like Word2Vec and GloVe

· Topic modeling

&#x200B;

* **Semantic Analysis:**

· Coreference resolution

· Discourse analysis

&#x200B;

**3. Text Processing:**

&#x200B;

* **Tokenization:**

&#x200B;

* Sentence tokenization
* Word tokenization
* Subword tokenization (Byte Pair Encoding, SentencePiece)

&#x200B;

* **Stop Words Removal:**

&#x200B;

* Importance and impact on NLP tasks
* Customizing stop word lists

&#x200B;

* **Stemming and Lemmatization:**

&#x200B;

* Porter stemming algorithm
* Snowball stemming algorithm
* Lemmatization techniques and challenges

&#x200B;

* **Part-of-Speech Tagging:**

 

* POS tagging algorithms (HMM-based, rule-based, and neural-based)
* Fine-grained POS tagging

**4. Text Representation:**

&#x200B;

* **Bag of Words (BoW):**

 

* Term Frequency (TF) and Inverse Document Frequency (IDF)
* Bag of N-grams

&#x200B;

* **TF-IDF:**

 

* Calculating TF-IDF scores
* Applications in information retrieval

&#x200B;

* **Word Embeddings:**

 

* Word2Vec:

&#x200B;

* Continuous Bag of Words (CBOW) model
* Skip-gram model
* GloVe (Global Vectors for Word Representation)

&#x200B;

* **Contextual Embeddings:**

 

* ELMo (Embeddings from Language Models)
* ULMFiT (Universal Language Model Fine-tuning)
* OpenAI GPT (Generative Pre-trained Transformer)

**5. NLP Libraries and Tools:**

&#x200B;

* NLTK      (Natural Language Toolkit)
* SpaCy
* scikit-learn
* Transformers      library (Hugging Face)

**6. Statistical Language Models:**

&#x200B;

* **N-grams:**

 

* Unigrams, bigrams, and trigrams
* N-gram language models

&#x200B;

* **Hidden Markov Models (HMM):**

 

* Basics of HMMs
* Applications in part-of-speech tagging

**7. Machine Learning for NLP:**

&#x200B;

* **Supervised Learning:**

 

* Text classification algorithms (Naive Bayes, Support Vector       Machines)
* Evaluation metrics (precision, recall, F1-score)

&#x200B;

* **Named Entity Recognition (NER):**

 

* Rule-based NER
* Machine learning-based NER
* Evaluation metrics for NER

&#x200B;

* **Sentiment Analysis:**

 

* Sentiment lexicons
* Machine learning approaches for sentiment analysis

**8. Sequence-to-Sequence Models:**

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Vanishing and exploding gradient problems
* Bidirectional RNNs

&#x200B;

* **Long Short-Term Memory (LSTM):**

 

* Architecture and key components
* Gating mechanisms

&#x200B;

* **Gated Recurrent Unit (GRU):**

 

* Simplified gating compared to LSTM
* Applications and advantages

**9. Deep Learning Architectures for NLP:**

&#x200B;

* **Convolutional Neural Networks (CNN) for Text:**

 

* Text classification with CNNs
* Hierarchical and multi-channel CNNs

&#x200B;

* **Transfer Learning in NLP:**

 

* Fine-tuning pre-trained models
* Universal Sentence Encoder

&#x200B;

* **Transformer Architecture:**

 

* Self-attention mechanism
* Multi-head attention
* Positional encoding

**10. Transduction and Recurrency:**

&#x200B;

* **Transduction in NLP:**

 

* Definition and applications
* Challenges in sequence-to-sequence transduction

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Applications beyond sequence-to-sequence tasks
* Challenges in training RNNs

**11. Advanced Topics in Sequence Modeling:**

&#x200B;

* **Attention Mechanism:**

 

* Scaled Dot-Product Attention
* Position-wise Feedforward Networks

&#x200B;

* **Self-Attention Mechanism:**

 

* The concept of self-attention
* Layer normalization in self-attention

&#x200B;

* **Multi-Head Attention:**

 

* Motivation and benefits
* Combining multiple attention heads

**12. Syntax and Parsing:**

&#x200B;

* **Dependency Parsing:**

 

* Dependency tree representation
* Transition-based and graph-based parsing

&#x200B;

* **Constituency Parsing:**

 

* Treebank representation
* Earley parsing algorithm

&#x200B;

* **Parsing Techniques:**

 

* Chart parsing (CYK parser)
* Shift-Reduce parsing

**13. Semantic Role Labeling (SRL) and Coreference Resolution:**

&#x200B;

* **Semantic Role Labeling:**

&#x200B;

* PropBank and FrameNet
* Neural approaches to SRL

&#x200B;

* **Coreference Resolution:**

&#x200B;

* Mention detection
* End-to-end coreference resolution models

**14. Evaluation Metrics:**

&#x200B;

* Precision,      Recall, F1-score
* BLEU      score for machine translation
* Perplexity      for language models

**15. NLP in Industry and Research:**

&#x200B;

* Case      studies and applications in various domains (healthcare, finance, legal,      etc.)
* Emerging      research trends in NLP

**16. Ethical Considerations and Bias in NLP:**

&#x200B;

* **Addressing Bias in NLP Models:**

&#x200B;

* Identifying and mitigating biases in training data
* Fairness-aware machine learning

&#x200B;

* **Ethical Considerations in NLP Research and      Deployment:**

&#x200B;

* Privacy concerns in NLP
* Responsible AI practices in NLP

**17. Continuous Learning and Keeping Updated:**

&#x200B;

* Follow      conferences (ACL, NAACL, EMNLP)
* Engage      with the NLP community
* Explore      recent research papers and advancements (Arxiv, NeurIPS)

**18. Projects and Hands-on Practice:**

&#x200B;

* Apply      knowledge through practical projects
* Contribute      to open-source NLP projects
* Participate      in Kaggle competitions

==============================="
16,learnmachinelearning,gpt-4,top,2023-12-26 07:39:32,Can you guess who wrote this code ? A Developer or a Researcher/Scientist,Left_Papaya_9750,False,0.87,44,18r2vqv,https://www.reddit.com/r/learnmachinelearning/comments/18r2vqv/can_you_guess_who_wrote_this_code_a_developer_or/,47,1703576372.0,"    import torch 
    from torch.optim.lr_scheduler import CosineAnnealingLR
    from gpt import GPTLanguageModel
    from transformers import GPT2Tokenizer
    from tqdm import tqdm
    from utils.draw_plots import Draw
    import pynvml as nvml
    import os
    import time
    import wandb
    from utils import draw_stuff
    from torch.utils.data import DataLoader, SubsetRandomSampler
    from utils.load_data import LoadDataset
    import signal 
    from colorama import Fore
    from queue import Queue
    
    class Train():
        def __init__(self, **kwargs,):
            torch.manual_seed(1137)
            model= GPTLanguageModel()
            gpu_idx= 0 if not 'gpu_index' in kwargs else kwargs['gpu_index']
            nvml.nvmlInit()
            os.system(""cls"" if os.name == 'nt' else 'clear')
            draw_stuff.draw()
            self.enc= GPT2Tokenizer.from_pretrained('gpt2')
            self.device='cuda' if torch.cuda.is_available else 'cpu'
            self.m= model.to(self.device)
            self.block_size= 256 if not 'block_size' in kwargs else kwargs['block_size']
            self.batch_size= 100 if not 'batch_size' in kwargs else kwargs['batch_size']
            self.handle= nvml.nvmlDeviceGetHandleByIndex(gpu_idx)
            self.temp_thres= 85 if not 'temp_threshold' in kwargs else kwargs['temp_threshold']
            self.plot= Draw()
            
        def load_data(self,split, split_per):
            dataset= LoadDataset(split= split, split_per=split_per)
            sampler= SubsetRandomSampler(torch.randint(high=len(dataset), size=(1000,)).tolist())
            data_title= DataLoader(dataset, pin_memory= True, sampler=sampler, drop_last=True)
            return data_title
    
        @torch.no_grad()
        def estimate_loss(self, eval_iters)->torch.tensor:
            out = {}
            print(""Estimating loss\n"")
            self.m.eval()
            for split in ['train', 'val']:
                es_progress= tqdm(total=eval_iters, ncols=100)
                es_progress.colour='red'
                
                losses = torch.zeros(eval_iters)
                for k in range(eval_iters):
                    es_progress.update(1)
                    for X, Y in self.get_batch(split):
                        logits, loss = self.m(X, Y)
                        losses[k] = loss.item()
                out[split] = losses.mean()
            self.m.train()
            return out
        
        def get_batch(self, split):
            data = self.load_data(split, split_per=0.8)
            for idx, data in enumerate(data):
                doc= data
                doc_txt= doc['text'][0]
                title= doc['title'][0]
                encoded_tok= self.enc.encode(doc_txt, add_special_tokens= True)
                doc_txt_enc= torch.tensor(encoded_tok, dtype=torch.long)
                size= self.block_size
                if len(encoded_tok) - self.block_size <= 0 and len(encoded_tok)-20 >=3:
                    size=20
                ix = torch.randint(len(encoded_tok) - size , (self.batch_size,))
                x = torch.stack([doc_txt_enc[i:i+size] for i in ix]).to(self.device) 
                y = torch.stack([doc_txt_enc[i:i+size+1] for i in ix]).to(self.device) 
                yield x, y
                
    
        def display_train_params(self,train_id, device, **kwargs):
            print(f""**NOTE: GPU temperature threshold has been set to {self.temp_thres}°C, when the threshold is reached the training process will halt for a set period.**\n"")
            print(f""INFO {torch.cuda.memory_allocated(device)} Bytes of memory is allocated for this task\n"")
            print(f""""""Training parameters:
                      Device: {nvml.nvmlDeviceGetName(self.handle)}
                      Halt Temperature threshold:{self.temp_thres}
                      Trainable Parameters: {sum(p.numel() for p in self.m.parameters())/1e6, 'M parameters'}
                      Total Epochs: {kwargs['epochs']}
                      Evaluation Iterations: {kwargs['eval_iters']}
                      Evaluation Interval: {kwargs['eval_interval']}
                      Initial Learning rate: {kwargs['learning_rate']}
                      Learning Rate Schduler: Cosine Annealing
                      Total Memory allocated: {torch.cuda.memory_allocated(device)}B
                      \n"""""")
            
            print(f""** Training Started | Train ID : {train_id}**\n"")
    
        
        def train(self, device, train_id, is_save=True, **kwargs):
            
            wandb.init('Training',  
                        project='gpt-model',
                        config={
                            ""initial_learning_rate"":3e-4,
                            ""architecture"":""transformer"",
                            ""dataset"": ""Wikipedia general documents""
                                }
                        )
            docs= []
            eval_interval= 500 if not 'ei' in kwargs else kwargs['ei']
            learning_rate= 3e-4 if 'learning_rate' not in kwargs else kwargs['learning_rate']
            eval_iters= 300 if 'eval_iter' not in kwargs else kwargs['eval_iter']
            max_iters= 10000 if not 'epochs' in kwargs else kwargs['epochs']
            num_doc= 2000
            os.mkdir('results') if not 'results' in os.listdir('.') else None
            os.mkdir(f'results/{train_id}') if train_id not in os.listdir('results') else None
            os.mkdir(f'results/{train_id}/checkpoints') if 'checkpoints' not in os.listdir(f'results/{train_id}') else None
            os.mkdir(f'results/{train_id}/checkpoints/plots') if 'plots' not in os.listdir(f'results/{train_id}/checkpoints') else None
            torch.cuda.empty_cache()
            optimizer = torch.optim.AdamW(self.m.parameters(), 
                                          lr=learning_rate)
            schduler= CosineAnnealingLR(optimizer=optimizer, T_max=max_iters)
    
            self.display_train_params(train_id=train_id, 
                                      device=device, 
                                      epochs=max_iters, 
                                      eval_interval=eval_interval,
                                      eval_iters=eval_iters,
                                      learning_rate=learning_rate
                                      )
            
            epoch_progress_bar= tqdm(total=eval_interval, 
                                     ncols=100
                                    )
            
            epoch_progress_bar.colour='cyan'
            counter= 0
            cont_params={'train_loss':[], 
                         'l_r':[]
                        }
            
            ckpt_params={'train_loss':[], 
                         'val_loss':[],
                         'l_r':[]
                        }
            
            it_cnt=0
            for iter in range(0, max_iters):
                epoch_progress_bar.update(1)
                curr_temperature= nvml.nvmlDeviceGetTemperature(self.handle, 
                                                                nvml.NVML_TEMPERATURE_GPU
                                                               )
        
                if curr_temperature >= self.temp_thres:
                    print(f""\n Set temperature threshold of {self.temp_thres}°C reached halting for {4} seconds "")
                    time.sleep(3)
                    print(""\n Resuming Training "")
                
    
                if iter % eval_interval == 0 or iter == max_iters-1:
                    
                    checkpoint_save_path= f'results/{train_id}/checkpoints/checkpoint-{counter}-epoch{iter}.pth'
                    losses =self.estimate_loss(eval_iters)
                    ckpt_params['l_r'].append(schduler.get_last_lr()[0])
                    ckpt_params['train_loss'].append(losses['train'])
                    ckpt_params['val_loss'].append(losses['val'])
                    wandb.log({""eval epoch"":iter, ""validation loss"":losses['val']})
                    plot_save_path= f'results/{train_id}/checkpoints/plots/checkpoint-{counter}'
        
                    if iter ==0:
                        pass
                    else:
                        
                        self.plot.draw_line(mode='loss', 
                                            train_loss= cont_params['train_loss'],  
                                            epochs=[it for it in range(it_cnt, it_cnt+eval_interval)],
                                            save_path=f'{plot_save_path}-epoch_vs_loss.png'
                                            )
                        self.plot.draw_line(mode='lrvloss',
                                            l_r= cont_params['l_r'],
                                            train_loss=cont_params['train_loss'], 
                                            save_path=f'{plot_save_path}-learning_rate_vs_loss.png'
                                            )
                        
                        self.plot.draw_line(mode='lrve',
                                            l_r= cont_params['l_r'], 
                                            epochs=[it for it in range(it_cnt, it_cnt+eval_interval)],
                                            save_path=f'{plot_save_path}-learning_rate_vs_epoch.png'
                                            )
                        
                        cont_params['l_r'].clear()
                        cont_params['train_loss'].clear()
                        torch.save(self.m.state_dict(), checkpoint_save_path)
                        it_cnt+=iter
        
                    print(f""step {iter+1}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}"") 
                    epoch_progress_bar.close() 
                    epoch_progress_bar = tqdm(total=eval_interval, ncols=100)
                    epoch_progress_bar.colour='cyan'
                    counter+=1
                print(f'loading data for epoch{iter}')
    
    
                for xb, yb in self.get_batch(split='train'):
                    logits, loss = self.m(xb, yb)
                    optimizer.zero_grad(set_to_none=True)
                    loss.backward()
                    optimizer.step()
                    schduler.step()
                    curr_lr= schduler.get_last_lr()[0]
                    train_loss= loss.item()
                cont_params['l_r'].append(curr_lr)
                cont_params['train_loss'].append(train_loss)
                wandb.log({'epoch':iter, 'train loss':train_loss, 'learning rate':learning_rate})            
                epoch_progress_bar.set_description(f""Epoch: {iter}/{max_iters} |current LR- {curr_lr}"")
            
            os.mkdir(f'results/{train_id}/final_plots') if 'final_plots' not in os.listdir(f'results/{train_id}') else None
    
            self.plot.draw_line(mode='loss', 
                                        train_loss= ckpt_params['train_loss'], 
                                        val_loss=ckpt_params['val_loss'], 
                                        epochs=[it for it in range(0,max_iters, 500)],
                                        save_path=f'results/{train_id}/final_plots/plot-epoch_vs_loss.png',
                                        plot_type='ckpt'
                                        )
            self.plot.draw_line(mode='lrvloss',
                                l_r= ckpt_params['l_r'],
                                train_loss=ckpt_params['train_loss'], 
                                val_loss= ckpt_params['val_loss'],
                                save_path=f'results/{train_id}/final_plots/plot-learning_rate_vs_loss.png',
                                plot_type='ckpt'
                                )
            
            self.plot.draw_line(mode='lrve',
                                l_r= ckpt_params['l_r'], 
                                epochs=[it for it in range(0,max_iters, 500)],
                                save_path=f'results/{train_id}/final_plots/plot-learning_rate_vs_loss.png',
                                plot_type='ckpt'
                                )
    
            nvml.nvmlShutdown()
            wandb.finish()
    "
17,learnmachinelearning,gpt-4,top,2023-12-07 01:31:55,Why can't AI models do complex math?,open_23,False,0.69,39,18ck15r,https://www.reddit.com/r/learnmachinelearning/comments/18ck15r/why_cant_ai_models_do_complex_math/,93,1701912715.0,"Computers, at its most fundamental level, is made up of boolean logic. Mathematics is basically the language of logic.

SHouldn't AI models, or computers in general be able to do more advanced math than just crunching large numbers? Why haven't anyone used computers to solve any of the Millenium Prize Problems or some other difficult proof. 

GPT-4 and recently  Gemini, has decent enough grade school level math solving capabilities but absolute atrocious at solving slightly more complex problems. But, I guess thats to be expected since they're LLMs. But, why hasn't anyone built an AI model geared towards just solving mathemaths problems? Also, what kind of different architecture would such a model need?"
18,learnmachinelearning,gpt-4,top,2023-02-12 03:54:05,[N] All of this you need to know happening in ML/AI.,Opening-Ad-8849,False,0.78,33,1106e9p,https://www.reddit.com/r/learnmachinelearning/comments/1106e9p/n_all_of_this_you_need_to_know_happening_in_mlai/,0,1676174045.0,"Hello humans - This is AI Daily by Ovetted, helping you stay updated on AI in less than 5 minutes.

Originally published on [https://www.ovetted.com/ai](https://www.ovetted.com/ai).

### What’s happening in AI -

[**The AI doctor will see you now: ChatGPT passes the gold-standard US medical exam.**](https://www.dailymail.co.uk/health/article-11732687/The-AI-doctor-ChatGPT-passes-gold-standard-medical-exam.html)

ChatGPT has passed the gold-standard exam required to practice medicine in the US

The artificial intelligence program scored 52.4 and 75 percent across the three-part Medical Licensing Exam (USMLE).

[**Google and Microsoft announced plans to incorporate AI into search engines.**](https://youtu.be/EBDJ9MGSV6k)

Google and Microsoft plan to incorporate AI into their search engines to change how people use the internet. Microsoft has announced that AI will soon allow conversations with its software and search engine Bing, while Google has announced similar plans.

As the most profitable software business is searching both companies are trying to take advantage of AI to rule the search engine market. 

[**Integrating the generative AI means a fivefold increase in Computing power & carbon emission.**](https://www.wired.com/story/the-generative-ai-search-race-has-a-dirty-secret/)

The integration of artificial intelligence (AI) into search engines could lead to a significant increase in the amount of energy that tech companies require and the amount of carbon they emit.

Training these models takes a huge amount of computational power, but only big tech companies can do so because they have the resources.

### Snippets -

**Human & AI:** How Will [Humans and A.I](https://www.nytimes.com/2023/02/10/opinion/letters/artificial-intelligence.html?smid=url-share). Get Along?

**OpenAI in office apps:** Microsoft Has Plans to Shove Its Bing AI Into [Word, PowerPoint, and More](https://gizmodo.com/microsoft-bing-ai-powerpoint-word-prometheus-1850098510). 

**WTF:** This AI Image Fooled Judges and [Won](https://petapixel.com/2023/02/10/ai-image-fools-judges-and-wins-photography-contest/) a Photography Contest.

**Hype:** Why the ChatGPT AI Chatbot Is [Blowing](https://www.cnet.com/tech/computing/why-the-chatgpt-ai-chatbot-is-blowing-everybodys-mind/) Everybody's Mind.

**Oops:** New AI voice-cloning tools 'add fuel' to [misinformation](https://abcnews.go.com/US/wireStory/new-ai-voice-cloning-tools-add-fuel-misinformation-97046760) fire.

**Oh no:** [Microsoft](https://www.businessinsider.com/microsoft-layoffs-cloud-ai-artificial-intelligence-2023-2?IR=T) is even cutting cloud and AI workers in its plan to lay off 10,000 employees.

**Wow:** AI In 2023 And [Beyond](https://www.forbes.com/sites/forbestechcouncil/2023/02/10/ai-in-2023-and-beyond-the-top-research-and-development-trends-to-keep-an-eye-on/?sh=5e2a45a7deae): The Top Research And Development Trends To Keep An Eye On.

**Realistic** newscasts feature AI-generated [anchors](https://edition.cnn.com/videos/business/2023/02/11/deepfake-newscast-ai-chinese-messaging-wang-pkg-ac360-vpx.cnn) disparaging the US.

**Google** cautions against '[hallucinating](https://www.reuters.com/technology/google-cautions-against-hallucinating-chatbots-report-2023-02-11/)' chatbots.

### Things to try -

* Someone made a **Discord bot** that can **write** **poems, descriptions, and titles on the image you provide**. Using GPT3 & CLIP. - [Try now](https://discord.gg/m4taXd6AB3)
* **Lalal AI** can **extract vocal accompaniment and other instruments** from any audio or video. - [Try now](https://www.lalal.ai/)
* What if you can create your own ChatGPT? well, you can make your own chatbot with your own data by using **customGPT**. - [Try now](https://customgpt.ai/)
* Do you create content for websites or any kind of digital content? Well, **metagenie** can help you to create **metadata like Titles, Descriptions, Tags, and Thumbnail Ideas.** \- [Try now](https://www.metagenieai.com/)
* **Snape** is here to help you write your custom job description generator. - [Try now](https://snape.springworks.in/)
* Give a try to this AI food robot that gives you **food pictures and recipes generated by AI. -** [Try now](https://aifoodrobot.com/)
* Need a **coding assistant** try spell box. That uses artificial intelligence to create the code you need from simple prompts. - [Try now](https://spellbox.app/)"
19,learnmachinelearning,gpt-4,top,2023-05-29 17:37:32,"GPT Weekly - 29th May Edition: Facebook's massive STT and TTS Release, AI in Windows, Paralegal jobs are here to stay and more.",level6-killjoy,False,0.86,28,13v1asb,https://www.reddit.com/r/learnmachinelearning/comments/13v1asb/gpt_weekly_29th_may_edition_facebooks_massive_stt/,2,1685381852.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 AI news in the past week
* 🗞️10 AI news highlights and interesting reads
* 🧑‍🎓3 Learning Resources

# 🔥Top 3 AI news in the past week

## 1. Expanding Language Horizons

Facebook has [released an open source model called MMS (Massively Multilingual Search)](https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/) for STT (speech to text), TTS (text to speech) and language identification. 

This is a big breakthrough. Currently, STT and TTS models recognize only 100 languages. With this the technology has been expanded to 1100 languages. That is 10x the current best. 

Additionally, these models can recognize 4000+ languages. 

As per Facebook, they also have half the error rate of OpenAI’s Whisper.

These guys are on a roll.

## 2. Bing Chat Enters the OS

After [Google’s announcement](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin), it was time for Microsoft to announce AI products. Here’s a rundown of what was announced during Microsoft Build:

1. **Windows Copilot**  \- Microsoft is integrating AI directly into the OS. Now you can do everything you could do with Bing Chat but now on the OS. You can do the usual stuff - summarize emails, documents, re-write etc. But it goes beyond that by integrating into the installed applications.

Microsoft is also adopting OpenAI's plugin model. So, **you can use ChatGPT and Bing plugins to interact with the integrated AI.** 

The great thing about it is the direct integration into the OS. Eat your heart out, Mac users – at least for now 😀. Until Apple announces something similar. And someone will come up with an alternative solution. Especially, because of the privacy concerns with Microsoft telemetry. 

The bad thing is - [the security aspect of the plugins](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). It can open a whole new attack vector on the OS and antivirus softwares might struggle with it. 

It also might be the second nail in the coffin for all the summarize, “talk to your document” apps. Once, this feature is integrated with [Google Docs](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and Microsoft Office - why will you want to pay for extra apps?

1. **Search comes to ChatGPT**  \- Looks like OpenAI had enough of the testing and new features are being rolled out [left](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and [right](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). 

No prizes for guessing the search engine behind it. Ding, Ding, Ding..It’s Bing!

1. **Co-Pilot in PowerPages** \- Microsoft is now adding AI to their [PowerPages platform](https://powerpages.microsoft.com/en-in/), their low-code tool to build websites. It’ll help users to generate text, forms etc.
2. **Microsoft Fabric** \- A new data analytics platform built on top of Azure Data lake but can get data from S3, Google cloud etc. It can help users build pipelines, write code, and build ML models.

## 3. From Trusted Advisor to Nightmare: The Hazards of Depending on AI

Here’s a [fun story which is breaking out on Legal twitter](https://www.nytimes.com/2023/05/27/nyregion/avianca-airline-lawsuit-chatgpt.html). 

A man filed a personal injury lawsuit against Avianca airlines. Avianca's lawyers wasted no time and requested the judge to dismiss the case. The man's lawyer had a different plan in mind. He submitted a document citing half a dozen cases that bolstered his client's claims.

Here's the twist—the judge and Avianca's lawyer couldn't locate any of the referenced cases. Quite a conundrum, right? The lawyer was then asked to provide copies of these elusive cases. The lawyer submitted screenshots as evidence, taking extra precautions to ensure their authenticity. 

You already know the direction this story is taking. 

The lawyer had used ChatGPT to compose his brief. But little did he know that ChatGPT had supplied him with fake cases.

When asked to file tangible copies of these cases, the lawyer turned to ChatGPT once again. ChatGPT had reassured him that the cases were genuine. Feeling emboldened, the lawyer used ChatGPT to provide the requested copies. He even went as far as incorporating chat screenshots into a legal document.

The lawyer maintains that it was never his intention to deceive the court. He expressed regret for relying on ChatGPT for their research. Unfortunately, the judge isn't pleased with this turn of events. The judge has threatened sanctions against both the lawyer and his firm.

It serves as a stark reminder of how ChatGPT has fooled many people. There is a clear warning stating that ChatGPT may produce inaccurate information. But many tend to overlook these warnings. Even legal professionals!!

This story carries significant importance for those who fear job insecurity. The lawyer and his firm could have prevented the entire debacle. They should've used paralegal services. They instead relied on ChatGPT's. It's a hard lesson learned the hard way.

My sincere hope is that this story serves as a valuable lesson. It helps people avoid making similar mistakes. The legal community might become apprehensive about ChatGPT's use moving forward.

# 🗞️10 AI news highlights and interesting reads

1. [OpenAI says in 10 years AI could be as productive as one of today’s large corporations](https://openai.com/blog/governance-of-superintelligence). This poses an existential risk and they suggest some regulations to manage it. This poses an existential risk and they suggest some regulations to manage it. To achieve this, countries need to form something like the [IAEA](https://en.wikipedia.org/wiki/International_Atomic_Energy_Agency). The IAEA is an intergovernmental agency under the UN to oversee nuclear energy. This “AI agency” will monitor the AI systems and conduct inspections. Just like nuclear energy is tracked through signatures, they suggest using compute and energy usage to track systems.
2. In the meantime, [Google is working on voluntary rules](https://techcrunch.com/2023/05/24/eu-google-ai-pact/) until there are some real regulations in place. 
3. [As per Pew Research, 58% of Americans have heard of ChatGPT. Even less - 14% have tried ChatGPT. ](https://www.pewresearch.org/short-reads/2023/05/24/a-majority-of-americans-have-heard-of-chatgpt-but-few-have-tried-it-themselves/)
4. Sharing prompts and results has been a pain. Taking screenshots is one way. But then everyone has to type in the prompts manually. Or you can share as plain text. But ChatGPT results are non-deterministic. So, the results might not be the same. Even the lawyer above would’ve loved this feature. Now you will be able to [share your ChatGPT conversations publicly](https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq).
5. LLM Agents and plugins need to connect to tools to perform the tasks outside the LLM environment. So, it is important for the LLM to know which API to call and pass correct arguments. [Gorilla is a fine-tuned Llama-model which can generate the correct call and arguments](https://gorilla.cs.berkeley.edu/). 
6. If you are trying to build something beyond a document summarizer or a wrapper around GPT4 API, [things can be hard](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm). Finding the correct context window, dealing with slow responses (I am looking at you GPT-4) etc are some of the problems. 
7. [The AI boom could expose investors’ natural stupidity](https://www.reuters.com/breakingviews/ai-boom-could-expose-investors-natural-stupidity-2023-05-19/). 
8. [Chatbot leaderboard for the week](https://lmsys.org/blog/2023-05-25-leaderboard/). GPT-4 is still ahead.
9. [Google’s flood warning system is now available in 80 countries. ](https://blog.google/outreach-initiatives/sustainability/flood-hub-ai-flood-forecasting-more-countries/)
10. [GPT detectors are biased against non-native English writers](https://arxiv.org/abs/2304.02819)

# 🧑‍🎓3 Learning Resources

1. [Build a product using Replit+AI](https://www.priyaa.me/blog/building-with-ai-replit). The author is a non-technical person who won a hackathon competing with engineers. 
2. [LangChain 101](https://replit.com/@MckayWrigley). 
3. [NLP Course from HuggingFace](https://huggingface.co/learn/nlp-course/chapter0/1)

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
20,learnmachinelearning,gpt-4,top,2023-07-16 08:58:51,Avoid clickbait content on Youtube with ChatGPT3.5/4,Particular_Account_2,False,0.82,25,1511b08,https://www.reddit.com/r/learnmachinelearning/comments/1511b08/avoid_clickbait_content_on_youtube_with_chatgpt354/,8,1689497931.0,"I built an app that I've been using for weeks now which lets you view a brief summary of any youtube video so you can avoid annoying clickbait content or just quickly get the gist of a video. 

The app that uses the web version of chatGPT3.5/4 rather than the API so that summaries can be generated for free by anyone logged in to ChatGPT. I've uploaded it to the Chrome store. Check it out here:

[https://chrome.google.com/webstore/detail/youtube-video-summaries-p/bajbfiocljodaddcdfkndlmgjbjbmjkf](https://chrome.google.com/webstore/detail/youtube-video-summaries-p/bajbfiocljodaddcdfkndlmgjbjbmjkf)

Take it for a spin, leave a review, and/or some feedback -- would love some feedback on the prompts I'm using. Thanks!"
21,learnmachinelearning,gpt-4,top,2023-04-08 03:04:00,Energy Constraints and Costs in Massive Machine Learning Model Training,mechkeyboard7065,False,0.91,26,12f9cvx,https://www.reddit.com/r/learnmachinelearning/comments/12f9cvx/energy_constraints_and_costs_in_massive_machine/,7,1680923040.0,"Adding on to my [last](https://www.reddit.com/r/learnmachinelearning/comments/12ebceo/alternatives_to_training_massive_ml_models_on/) post, here's some of what I've found about the potential constraints and costs associated with training massive machine learning models. 

&#x200B;

**Energy as a constraint in ML model training:**

\- GPT-3, as an example, is estimated to have consumed around **936 MWh** during its training.  
\- If there were **$100B model training runs** in the future, it would consume approximately **20,347,826 MWh** or **20,347,826,000 KWh**.  
\- This would cost around **$1,017,391,300**, which is about **1%** of the total cost (assuming $0.05 KWh). The cost could go up to **$3B** if we assume $0.15 KWh.

&#x200B;

**Power generation comparison:**

\- One nuclear power plant can generate around **4,727,764 MWh** in a year.

&#x200B;

**Main constraints in massive model training runs apart from GPUs:**

\- Data movement through machines  
\- The amount of data that can be moved  
\- The amount of data the model has already been trained on  
\- Networking and bandwidth limitations  
\- System-specific bottlenecks  
\- Model training algorithm design (e.g., parallel processing, processing power requirements)

&#x200B;

**Potential $10T investment in ML models: Where would the money go?**

\- **17% ($1.7T)** \- Data collection, validation, and annotation  
\- **23% ($2.3T)** \- Research  
\- **60% ($6T)** \- Production (infrastructure, integration, maintenance)

&#x200B;

**Current and projected annual spend on GPUs:**  
\- **$40B** in 2022  
\- Projected to be **$400B** in 10 years

&#x200B;

I hope someone might find this information useful. It's definitely made me question the future impact as these models scale. As always, I'm open to corrections and eager to learn more. Let me know if you have any questions or additional insights."
22,learnmachinelearning,gpt-4,top,2023-12-17 13:15:47,I can't stop using ChatGPT and I hate it.,t0hli,False,0.64,24,18kh4n5,https://www.reddit.com/r/learnmachinelearning/comments/18kh4n5/i_cant_stop_using_chatgpt_and_i_hate_it/,108,1702818947.0,"I'm trying to learn various topics like Machine Learning and Robotics etc., and I'm kinda a beginner in programming.

For any topic and any language, my first instinct is to

1. go to ChatGPT,
2. write down whatever I need my code to do,
3. copy paste the code
4. if it doesn't give out good results, ask ChatGPT to fix whatever it's done wrong
5. repeat until I get satisfactory result

I hate it, but I don't know what else to do.

I think of asking Google what to do, but then I won't get the exact answer I'm looking for, so I go back to ChatGPT so I can get exactly what I want. I don't fully understand what the GPT code does, I get the general gist of it and say ""Yeah that's what I would do, makes sense"", but that's it.

If I tried to code whatever GPT printed out, I wouldn't get anywhere.

I know I need to be coding more, but I have no idea where to start from, and why I need to code when ChatGPT can do it for me anyway. I'm not defending this idea, I'm just trying to figure out how I can code myself.

I'd appreciate your thoughts and feedback."
23,learnmachinelearning,gpt-4,top,2024-01-05 15:14:07,"This Week's Major AI developments in a nutshell (December Week 4, 2023 + January week 1, 2024)",wyem,False,0.96,23,18z95ko,https://www.reddit.com/r/learnmachinelearning/comments/18z95ko/this_weeks_major_ai_developments_in_a_nutshell/,1,1704467647.0,"1. **Meta** and UC, Berkeley introduced ***Audio2Photoreal***, a framework for generating full-bodied photorealistic avatars with gestures driven from audio of a dyadic conversation \[[*Details*](https://people.eecs.berkeley.edu/~evonne_ng/projects/audio2photoreal/) | [*GitHub*](https://github.com/facebookresearch/audio2photoreal)*\].*
2. **MyShell** along with researchers from MIT and Tsinghua University introduced ***OpenVoice***, an open sourcce voice cloning approach that is nearly instantaneous and provides granular control of tone, from emotion to accent, rhythm, pauses, and intonation, using just a small audio clip \[[*Details*](https://research.myshell.ai/open-voice) *|* [*Hugging Face*](https://huggingface.co/spaces/myshell-ai/OpenVoice)\] .
3. **Suno** and Nvidia present ***Parakeet***, a family of open source speech recognition models that top the Open ASR Leaderboard. Parkeet models effectively prevent the generation of hallucinated transcript and are robust to noisy audio. Available for commercial use under CC BY 4.0 \[[*Details*](https://nvidia.github.io/NeMo/blogs/2024/2024-01-parakeet/) | [*Hugging Face*](https://huggingface.co/spaces/nvidia/parakeet-rnnt-1.1b)\].
4. **Researchers** from Stanford University introduce ***Mobile-ALOHA***, an open-source robot hardware that can can autonomously complete complex mobile manipulation tasks that require whole-body control like cook and serve shrimp, call and take elevator, store a 3Ibs pot to a two-door cabinet etc., with just 50 demos \[[*Details*](https://mobile-aloha.github.io/)\].
5. **Allen Institute for AI** released ***Unified-IO 2*** (open-source), the first autoregressive multimodal model that is capable of understanding and generating image, text, audio, and action. The model is pre-trained from scratch on an extensive variety of multimodal data -- 1 billion image-text pairs, 1 trillion text tokens, 180 million video clips, 130 million interleaved image & text, 3 million 3D assets, and 1 million agent trajectories \[[*Details*](https://unified-io-2.allenai.org/)\].
6. **Alibaba** Research introduced ***DreamTalk***, a diffusion-based audio-driven expressive talking head generation framework that can produce high-quality talking head videos across diverse speaking styles \[[*Details*](https://dreamtalk-project.github.io/) *|* [*GitHub*](https://github.com/ali-vilab/dreamtalk)\].
7. **OpenAI’s app store** for GPTs will launch next week \[[*Details*](https://techcrunch.com/2024/01/04/openais-app-store-for-gpts-will-launch-next-week/)\].
8. **GitHub Copilot Chat**, powered by GPT-4, is now generally available for both Visual Studio Code and Visual Studio, and is included in all GitHub Copilot plans alongside the original GitHub Copilot \[[*Details*](https://github.blog/2023-12-29-github-copilot-chat-now-generally-available-for-organizations-and-individuals)\].
9. **Microsoft Research** presented a new and simple method for obtaining high-quality text embeddings using only synthetic data and less than 1k training step \[[*Paper*](https://arxiv.org/pdf/2401.00368.pdf)\] | [*Hugging Face*](https://huggingface.co/intfloat/e5-mistral-7b-instruct)\].
10. **Google DeepMind** introduced ***AutoRT, SARA-RT and RT-Trajectory*** to improve real-world robot data collection, speed, and generalization \[[*Details*](https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotic)\].
11. **Salesforce Research** presented ***MoonShot***, a new video generation model that conditions simultaneously on multimodal inputs of image and text, demonstrating significant improvement on visual quality and temporal consistency compared to existing models. The model can be easily repurposed for a variety of generative applications, such as personalized video generation, image animation and video editing. Models will be made public [here](https://github.com/salesforce/LAVIS) \[[*Details*](https://showlab.github.io/Moonshot/)\].
12. **Leonardo AI** released ***Leonardo Motion*** for generating videos from images. Available to all users, paid and free \[[*Link*](https://leonardo.ai/)\].
13. **JPMorgan AI Research** present ***DocLLM***, a layout-aware generative language model for multimodal document understanding. The spatial layout information is incorporated through bounding box coordinates of the text tokens obtained typically using optical character recognition (OCR), and does not rely on any vision encoder component \[[Details](https://arxiv.org/pdf/2401.00908.pdf)\].
14. **Alibaba Research** introduced ***Make-A-Character (Mach)***, a framework to create lifelike 3D avatars from text descriptions. Make-A-Character supports both English and Chinese prompts. \[[*Details*](https://human3daigc.github.io/MACH/) *|* [*Hugging Face*](https://huggingface.co/spaces/Human3DAIGC/Make-A-Character)\].
15. **Sony**, Canon and Nikon set to combat deepfakes with digital signature tech in future cameras \[[*Details*](https://www.techradar.com/cameras/photography/sony-canon-and-nikon-set-to-combat-deepfakes-with-digital-signature-tech-in-future-cameras)\].
16. **Meta AI** introduced ***Fairy***, a versatile and efficient video-to-video synthesis framework that generates high-quality videos with remarkable speed. Fairy generates 120-frame 512x384 videos (4-second duration at 30 FPS) in just 14 seconds, outpacing prior works by at least 44× \[[Details](https://fairy-video2video.github.io/)\].
17. **Apple** quietly released an open source multimodal LLM, called ***Ferret***, in October 2023 \[[*Details*](https://venturebeat.com/ai/apple-quietly-released-an-open-source-multimodal-llm-in-october/)\].
18. **Australian researchers** introduced a non-invasive AI system, called ***DeWave***, that can turn silent thoughts into text while only requiring users to wear a snug-fitting cap \[[*Details*](https://www.sciencealert.com/new-mind-reading-ai-translates-thoughts-directly-from-brainwaves-without-implants)\].
19. **Pika Labs** text-to-video AI platform **Pika 1.0** is now available to all and accessible via the web \[[*Link*](https://pika.art/)\].
20. **The New York Times** sued OpenAI and Microsoft for copyright infringement \[[*Details*](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html)\].

**Source**: [AI Brews newsletter-](https://aibrews.com/) you can subscribe [here](https://aibrews.substack.com/). it's free to join, sent only once a week with ***bite-sized news, learning resources and selected tools.*** *Thank you!*"
24,learnmachinelearning,gpt-4,top,2023-06-19 17:49:06,"GPT Weekly - 19the June Edition - OpenAI's function calling, Meta's free LLM, EU Regulation and more.",level6-killjoy,False,1.0,23,14dlfas,https://www.reddit.com/r/learnmachinelearning/comments/14dlfas/gpt_weekly_19the_june_edition_openais_function/,2,1687196946.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 news - OpenAI’s updates, Meta’s upcoming free LLM and EU Regulation
* 🗞️Interesting reads include PSA about protecting your keys, The GPT ouroboros, Reddit - OpenAI’s moat, and more..
* 🧑‍🎓Learning includes a Step-by-step guide from a non-technical founder who launched his MVP, Chatbot for your Gdrive and more

# 🔥Top 3 AI news in the past week

## 1. OpenAI: New Pricing, Models, & Functions

OpenAI has been on a roll. Last week we saw the release of [OpenAI best practice on using GPT.](https://gptweekly.beehiiv.com/p/making-gpt-openais-tactics-better-results) This week we saw some amazing updates. Three major buckets were:

First, the price decreases for both embeddings and GPT-3.5 tokens. 

Second, new models for gpt-4 and gpt-3.5. A new longer context model for gpt-3.5.

Third, a new function calling capability. 

**Why is it important?** Previously, the output from OpenAI was all text. So, calling an external API from GPT was quite difficult. You had to parse the text data and things were often incorrect.  Langchain created the Agents and Tools feature to tackle this problem. It was still unreliable and prone to issues. 

Now you get native support to generate a fixed format output. You can use the output to generate functional calls and also pass functions which need to be called. For example, if your app has multiple API endpoints then you can use GPT to generate the API calls with parameters. You can also pass the endpoints as function calls to ensure the correct function is executed. 

This functionality can further be used to [generate structured data (JSON) out of GPT](https://yonom.substack.com/p/native-json-output-from-gpt-4). So, you can generate data from GPT and load it into your backend. 

**What’s next?** This functionality allows turning natural language responses into structured data. This can be used to create “intelligent” backends using LLMs. We might see implementations in no-code tools to allow more robust and natural-language tools for non-technical folks.

The structured data process goes both ways. You can also feed structured data into GPT for better responses. 

This feature also has its share of issues. Function calling suffers from the same prompt injection issues. Malicious actors can pass malicious code in function or the responses. For example, creation of queries using functions might contain malicious code to delete data. Without proper user validation this code will be executed automatically and delete data. So, using LLM as the back-end layer needs proper security implementation. 

## 2. Meta's LLM: Commercial Use Ahead

Llama has been a boon for the open source community. Many of the open source models rely on Llama. The issue is that Llama is research-only and cannot be used commercially. So, no one can use it to build any product.

[Meta is now working on the next version of the model. This model will be available for commercial use.](https://www.theinformation.com/articles/meta-wants-companies-to-make-money-off-its-open-source-ai-in-challenge-to-google) This is in stark contrast to both OpenAI and Google. Both safe-guarde their models and make it available through API. 

**Why is it important?** Certain industries cannot use LLM APIs because of strict restrictions on data privacy. These companies would want to run their own instance of a foundational model. 

A commercially available foundational model is also going to help people who want to keep their “API call” costs next to 0. 

A commercially available free-for-all model will also help push the open source community further. Just like Llama.

**What’s next?** Sam Altman has said OpenAI didn’t release GPT-3 as open-source because they [didn’t think people would be able to run it.](https://gptweekly.beehiiv.com/p/peek-openais-future) Now [OpenAI is working on an open-source model.](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) This is going to be weaker than GPT-4. 

Let the battle of LLMs begin.  

## 3. EU's Proposed Legislation and Its Impact on AI Usage

[The EU parliament voted to move ahead with the E.U. AI Act.](https://www.washingtonpost.com/technology/2023/06/14/eu-parliament-approves-ai-act/) This act aims to ensure consumer protection against the dangers of AI.  

**Why is it important?** [OpenAI](https://gptweekly.beehiiv.com/p/peek-openais-future) and [Sam Altman](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) want regulations for models. They have proposed a IAEA-type of agency to stop the proliferation of LLM models. As per OpenAI, all models should be regulated and monitored. The suggestion of a license based regulation has led to significant backlash. Many people have called it “regulatory capture” - with the aim of shutting down competing LLMs.

[Licensing based regulations might not really be effective.](https://aisnakeoil.substack.com/p/licensing-is-neither-feasible-nor)

The EU is approaching regulation from a different angle. It doesn’t focus on how models are developed. Rather focuses on how AI will/can be used. They have broken down use cases into 4 categories - unacceptable (prohibited), high, medium and low risk. For example, 

Building a [Pre-Crime software](https://en.wikipedia.org/wiki/Pre-crime#:~:text=Pre%2Dcrime%20(or%20precrime),on%20crimes%20not%20yet%20committed.) to predict crimes? Building a [Social credit system](https://en.wikipedia.org/wiki/Social_Credit_System)?  Unacceptable.

Using tools to influence elections or recommendation algorithms? High (Highly regulated).

Using generative AI tools to create text or images on news sites? Medium (Add label that the content is AI generated) 

AI providers also need to disclose their training source.

To me this sounds like good legislation. What do you guys think?

But, OpenAI has warned that EU regulations might force them to pull out completely.

**What’s next?** The disclosure requirements might help various publishing companies. [AI and media companies are in talks to pay for training data](https://www.ft.com/content/79eb89ce-cea2-4f27-9d87-e8e312c8601d). Google has been leading the charge. 

Additionally, [OpenAI and Deepmind will open their models for safety and research purposes to the UK government.](https://www.politico.eu/article/openai-deepmind-will-open-up-models-to-uk-government/) 

# 🗞️10 AI news highlights and interesting reads

1. **PSA:** If you are using Repl to write code, you might want to check your OpenAI API keys. If you have left them embedded then [people can pirate and steal the keys. ](https://www.vice.com/en/article/93kkky/people-pirating-gpt4-scraping-openai-api-keys)
2. LLMs rely on human annotation or human feedback to learn. And one way to generate human annotation is crowdsourcing. But what if the crowdsource human annotators use LLMs? [Research shows 33-46% workers used LLMs](https://arxiv.org/abs/2306.07899). So, basically we go from Human -> AI -> Human -> AI. The AI ouroboros. Researchers also say [generated data to train models might cause serious issue.  ](https://arxiv.org/abs/2305.17493)
3. All the talks about [moats](https://gptweekly.beehiiv.com/p/googles-startling-leaked-memo-george-hinton-mojo) \- [Reddit might be OpenAI’s \*future\* moat](https://www.cyberdemon.org/2023/06/14/reddit-moat.html). Given the amount of complaints about how [Google search](https://www.techradar.com/opinion/the-reddit-b) [experience has deteriorated](https://www.theverge.com/2023/6/13/23759942/google-reddit-subreddit-blackout-protests) [during the blackout](https://news.ycombinator.com/item?id=36345345), this might be true?
4. [Doctors are using ChatGPT](https://www.nytimes.com/2023/06/12/health/doctors-chatgpt-artificial-intelligence.html) but not to diagnose.Rather to be [more empathetic](https://inflecthealth.medium.com/im-an-er-doctor-here-s-how-i-m-already-using-chatgpt-to-help-treat-patients-a023615c65b6). [We discussed this just a month ago](https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?utm_source=gptweekly.beehiiv.com&utm_medium=referral&utm_campaign=google-s-startling-leaked-memo-george-hinton-mojo-and-more). And guess where the data for this study came from? Reddit AskDocs. Moat FTW?!
5. Beatles to make a comeback…[using Generative AI](https://www.semafor.com/article/06/13/2023/paul-mccartney-beatles-song-ai). 
6. [SnapFusion - Text to Image diffusion on mobile phones.](https://snap-research.github.io/SnapFusion/)
7. Large context lengths are important for better GPT experience. [The secret sauce for 100k context length](https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c). 
8. There is a lot of bad AI research out there. Some border on snake oil. Most AI “research” should be double checked and challenged. A new research on huggingface said that [GPT-4 can ace MIT curriculum](https://huggingface.co/papers/2306.08997). Now someone is replicating the results and say that [GPT-4 can’t beat MIT. ](https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864)
9. Are we seeing peak AI? Especially when people from Deepmind and Meta are involved? [Mistral AI raised $113 million in seed round with no product.](https://techcrunch.com/2023/06/13/frances-mistral-ai-blows-in-with-a-113m-seed-round-at-a-260m-valuation-to-take-on-openai/) Some might say this funding is for the team and the team is really solid. The issue though is whether the valuation is justified when OpenAI and Google already have a head start.
10. [The AI Hype Wall of Shame.](https://criticalai.org/the-ai-hype-wall-of-shame/) \- Collection of articles which mislead people about AI in various aspects.

# 🧑‍🎓3 Learning Resources

1. [Building and Launching a company using GPT-4](https://sabol.io/c7921c7bbd8c4982aacbd2b71a8b9bb3) with prompts. (The author didn’t know how to code but created and launched the MVP in a month).  
2. Chatbot for your Gdrive - [https://www.haihai.ai/gpt-gdrive/](https://www.haihai.ai/gpt-gdrive/)
3. Building ChatGPT plugin using Supabase - https://supabase.com/blog/building-chatgpt-plugins-template

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
25,learnmachinelearning,gpt-4,top,2023-05-15 06:27:00,Bilingual people : How good is AI at machine translation today?,moschles,False,0.83,20,13hzvkc,https://www.reddit.com/r/learnmachinelearning/comments/13hzvkc/bilingual_people_how_good_is_ai_at_machine/,22,1684132020.0,"In the wake of GPT-4 and chatGPT, how good would you rank machine translators in terms of their accuracy?

Are they only useful for one-off sentences? Do they fail when presented with any kind of moderately complex articles? Do they perform vastly different depending on the languages?     Are they still really stupid, or does their output blow you away now?"
26,learnmachinelearning,gpt-4,top,2023-09-01 14:58:08,This week in AI - all the Major AI development in a nutshell,wyem,False,1.0,19,1679g8z,https://www.reddit.com/r/learnmachinelearning/comments/1679g8z/this_week_in_ai_all_the_major_ai_development_in_a/,0,1693580288.0,"1. Researchers introduce ‘**Swift**’, the first autonomous vision-based drone that beat human world champions in several fair head-to-head races. This marks the *first* time that an autonomous mobile robot has beaten human champions in a real physical sport \[[*Details*](https://www.nature.com/articles/s41586-023-06419-4)\].
2. **Meta AI** released **CoTracker** \- a fast transformer-based model that can track any point in a video.
3. **WizardLM** released **WizardCoder 34B** based on Code Llama. WizardCoder-34B surpasses GPT-4, ChatGPT-3.5 and Claude-2 on HumanEval Benchmarks.
4. **Meta AI** introduced **FACET** (FAirness in Computer Vision EvaluaTion) - a new comprehensive benchmark dataset for evaluating the fairness of computer vision models for protected groups. The dataset is made up of 32K images containing 50,000 people, labeled by expert human annotators.
5. **Allen Institute for AI** launched [**Satlas**](https://satlas.allen.ai/) \- a new platform for exploring global geospatial data generated by AI from satellite imagery.
6. Generative AI updates from **Google Cloud Next** event**:**
   1. General availability of **Duet AI in Google Workspace** .
   2. **SynthID** \- a tool for watermarking and identifying AI images generated by Imagen (Google’s text-to-image diffusion model). It embeds a digital watermark directly into the pixels of an image, making it invisible to the human eye, but detectable for identification, without reducing the image quality.
   3. **AlloyDB AI** for building generative AI applications with PostgreSQL.
   4. **Vertex AI’s Model Garden** now includes Meta’s Llama 2 and TII’s Falcon — and pre-announcement of Anthropic’s Claude 2..
   5. Model and tuning upgrades for **PaLM 2, Codey, and Imagen**. 32,000-token context windows and 38 languages for PaLM 2.
   6. **Style Tuning** for Imagen - a new capability to help customers align their images to their brand guidelines with 10 images or less.
   7. Launch of fifth generation of its tensor processing units (**TPUs**) for AI training and inferencing.
7. A new generative AI image startup **Ideogram**, founded by former Google Brain researchers, has been launched with $16.5 million in seed funding. Ideogram's unique proposition lies in reliable text generation within images.
8. **a16z** announced **a16z Open Source AI Grant program** and the first batch of grant recipients and funded projects.
9. **Runway AI** announced **Creative Partners Program** \- provides a select group of artists and creators with exclusive access to new Runway tools and models, Unlimited plans, 1 million credits, early access to new features and more.
10. **OpenAI** has released a guide for teachers using ChatGPT in their classroom—including suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.
11. **DINOv2**, a self-supervised vision transformer model by **Meta AI** which was released in April this year, is now available under the Apache 2.0 license.
12. **Tesla** is launching a $300 million AI computing cluster employing 10,000 Nvidia H100 GPUs.
13. **Inception**, an AI-focused company based in the UAE unveiled **Jais**, a 13 billion parameters open-source Arabic Large Language Model (LLM).
14. Google announced **WeatherBench 2** (WB2) - a framework for evaluating and comparing various weather forecasting models.
15. **Alibaba** launched two new open-source models - **Qwen-VL** and **Qwen-VL-Chat** that can respond to open-ended queries related to different images and generate picture captions.
16. **OpenAI** disputes authors’ claims that every ChatGPT response is a derivative work.
17. **DoorDash** launched AI-powered voice ordering technology for restaurants.
18. **OpenAI** launched **ChatGPT Enterprise**. It offers enterprise-grade security and privacy, unlimited higher-speed GPT-4 access, longer context windows for processing longer inputs, advanced data analysis capabilities and customization options.
19. **OpenAI** is reportedly earning $80 million a month and its sales could be edging high enough to plug its $540 million loss from last year.

If you like this news format, you might find my newsletter, [AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
27,learnmachinelearning,gpt-4,top,2023-04-28 16:04:48,A Lightweight Alternative to GPT-4 for Enhanced Vision-language Understanding,kingabzpro,False,0.95,20,131yxdl,https://www.kdnuggets.com/2023/04/minigpt4-lightweight-alternative-gpt4-enhanced-visionlanguage-understanding.html,0,1682697888.0,
28,learnmachinelearning,gpt-4,top,2023-07-07 01:56:23,ML for DIY House Design,No-Dare-7624,False,0.88,17,14st4q5,https://www.reddit.com/r/learnmachinelearning/comments/14st4q5/ml_for_diy_house_design/,9,1688694983.0,"https://reddit.com/link/14st4q5/video/afhad8qnagab1/player

As an architect and computational designer, I've recently ventured into the exciting world of Machine Learning (ML) to bring an innovative touch to DIY house designs. My project, based in Grasshopper, integrates ML in the architectural process to predict the optimal wall/window configurations for desired temperature settings in diverse scenarios.

Starting with a modest dataset (2000 rooms), I developed a stacked ML model, part of a larger project, aiming to democratize house design by aiding DIY enthusiasts. My workflow was all about getting the model running first, even with limited data, and refining it as I gained more understanding and expanded the dataset, which is self-supervised. I'm using Ladybug a grasshopper plugin that it is the way to go for enviromental analysis, so I can generate new data on demand but it takes time to compute.

The most challenging part was predicting optimal configurations when all wall options were not available. I addressed this by merging outputs from the second (predict optimal configuration) and third neural (predict best configuration with aviable walls) networks, assigning more weight to the latter.

With the assistance of OpenAI's GPT-4, especially for Python, I am now focused on generating five times more data and scrutinizing model performance through metrics such as R-squared (0.8144), MSE(0.003), and MAE(0.0454). The best model so far is using Backpropagation and Sigmoid.

As an architect turned ML enthusiast, there's been a steep learning curve, but the journey has been rewarding. I'm keen to hear suggestions, particularly any rules of thumb from seasoned data scientists that could be missing from my toolkit. Looking forward to enriching this exciting intersection of architecture and ML!

Here is a small video of the first attempt of the first neural network that its just predict the solar radation.

[https://www.instagram.com/reel/CuPwUVNArTv/?utm\_source=ig\_web\_copy\_link&igshid=MzRlODBiNWFlZA==](https://www.instagram.com/reel/CuPwUVNArTv/?utm_source=ig_web_copy_link&igshid=MzRlODBiNWFlZA==)"
29,learnmachinelearning,gpt-4,top,2023-07-20 13:15:51,Free courses and guides for learning Generative AI,wyem,False,0.95,17,154qnsh,https://www.reddit.com/r/learnmachinelearning/comments/154qnsh/free_courses_and_guides_for_learning_generative_ai/,0,1689858951.0,"1. **Generative AI learning path by Google Cloud.** A series of 10 courses on generative AI products and technologies, from the fundamentals of Large Language Models to how to create and deploy generative AI solutions on Google Cloud \[[*Link*](https://www.cloudskillsboost.google/paths/118)\].
2. **Generative AI short courses** by DeepLearning.AI - Five short courses on generative AI including **LangChain for LLM Application Development, How Diffusion Models Work** and more. \[[*Link*](https://www.deeplearning.ai/short-courses/)\].
3. **LLM Bootcamp:** A series of free lectures by *The full Stack* on building and deploying LLM apps \[[*Link*](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/)\].
4. **Building AI Products with OpenAI** \- a free course by CoRise in collaboration with OpenAI \[[*Link*](https://corise.com/course/building-ai-products-with-openai)\].
5. Free Course by Activeloop on **LangChain & Vector Databases in Productio**n \[[*Link*](https://learn.activeloop.ai/courses/langchain)\].
6. **Pinecone learning center -** Lots of free guides as well as complete handbooks on LangChain, vector embeddings etc. by Pinecone **\[**[**Link**](https://www.pinecone.io/learn/)**\].**
7. **Build AI Apps with ChatGPT, Dall-E and GPT-4  -** a free course on Scrimba **\[**[*Link*](https://scrimba.com/learn/buildaiapps)**\].**
8. **Gartner Experts Answer the Top Generative AI Questions for Your Enterprise** \- a report by Gartner \[[*Link*](https://www.gartner.com/en/topics/generative-ai)\]
9. **GPT best practices:** A guide by *OpenAI* that shares strategies and tactics for getting better results from GPTs \[[*Link*](https://platform.openai.com/docs/guides/gpt-best-practices)\].
10. **OpenAI cookbook by OpenAI -** Examples and guides for using the OpenAI API **\[**[*Link*](https://github.com/openai/openai-cookbook/tree/main)**\].**
11. **Prompt injection explained**, with video, slides, and a transcript from a webinar organized by LangChain \[[*Link*](https://simonwillison.net/2023/May/2/prompt-injection-explained/)\].
12. A detailed guide to **Prompt Engineering by DAIR.AI** *\[*[*Link*](https://www.promptingguide.ai/)*\].*
13. What Are **Transformer Models** and How Do They Work - A tutorial by **Cohere AI** \[[*Link*](https://txt.cohere.ai/what-are-transformer-models/)\].  


I add learning resources as part of my AI newsletter. You can join for free [here](https://aibrews.com/). It’s sent only once a week with bite-sized news, learning resources and selected tools. "
30,learnmachinelearning,gpt-4,top,2023-05-11 00:19:48,The last decade of NLP research covered in 50 concepts,AvvYaa,False,0.95,17,13e7ydv,https://www.reddit.com/r/learnmachinelearning/comments/13e7ydv/the_last_decade_of_nlp_research_covered_in_50/,0,1683764388.0," 

I just uploaded a video on my Youtube channel covering 50 important concepts discussing the last 10 years of NLP/Language Modeling research. 

The video covers the basics of word embeddings, tokenizers, and then the RNN based Seq2Seq architectures of the mid 2010s… then describes Attention/Transformers and some of the key Transformer-based LM research from 2017-2021. Finally, I cover human alignment / RLHF / instruction tuning with InstructGPT, ChatGPT and GPT-4. I tried to make a video that is accessible for new researchers/students to get their feet wet, and for guys like me to reminisce and celebrate the RNNs / self-supervised Transformer era as we step into the new world of human aligned LLMs. 

I am a small YT channel, and this is my first time doing a video of this scale (I normally do Reinforcement Learning stuff/paper reviews), so this was a fun and challenging video to produce. Feel free to check it out and leave any feedback for me to improve my content!

Here’s a link: 

[https://youtu.be/uocYQH0cWTs](https://youtu.be/uocYQH0cWTs)  
 

If the above link doesn’t work, try:  
 https://m.youtube.com/watch?v=uocYQH0cWTs&feature=youtu.be"
31,learnmachinelearning,gpt-4,top,2023-06-16 14:23:32,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.95,17,14ay75a,https://www.reddit.com/r/learnmachinelearning/comments/14ay75a/this_week_in_ai_all_the_major_ai_developments_in/,1,1686925412.0,"1. **ElevenLabs** has launched **AI Speech Classifier -** an authentication tool that lets you upload any audio sample to identify if it contains ElevenLabs AI-generated audio.
2. **Nvidia Research** presents **SceneScape** \- a method to generate long-term walkthroughs in imaginary scenes just from an input text prompt.
3. **Meta AI** introduces the **Image Joint Embedding Predictive Architecture (I-JEPA)**, a new AI model which learns from the world like humans and excels in computer vision tasks, while being more computationally efficient. It learns by creating an internal model of the outside world, which compares abstract representations of images (rather than comparing the pixels themselves). It can also be used for many different applications without needing extensive fine tuning. Meta is open-sourcing the code and model checkpoints.
4. **Meta** wants to make the next version of LLaMA, its open source LLM, available for commercial use..
5. Adobe launched **Generative Recolor,** a new tool powered by Adobe Firefly generative AI that lets you generate custom color schemes using texts prompt like “strawberry fields,” “faded emerald,” etc. .
6. **OpenAI** announced:
   1. new **function calling** capability in the Chat Completions API
   2. updated and more steerable versions of gpt-4 and gpt-3.5-turbo
   3. new 16k context version of gpt-3.5-turbo (vs the standard 4k version). 16k context means the model can now support \~20 pages of text in a single request.
   4. cost reductions: 75% on embeddings model and 25% cost on input tokens for gpt-3.5-turbo.
7. **Meta AI** released **MusicGen** \- an open-source music generation model that can be prompted by both text and melody. See here for generated samples and comparison with Google’s MusicLM and others..
8. **McKinsey** published a report ‘*The economic potential of generative AI: The next productivity frontier*’ . The report estimates that generative AI could add the equivalent of $2.6 trillion to $4.4 trillion annually across the 63 use cases. About 75 percent of the value that generative AI use cases could deliver falls across four areas: Customer operations, marketing and sales, software engineering, and R&D..
9. **EU lawmakers** pass AI regulation, requiring generative AI systems, such as ChatGPT, to be reviewed before commercial release. It also seeks to ban real-time facial recognition.*.*
10. **Google Lens** can now identify skin conditions. Lens will also be integrated with Bard, Google’s AI-powered chatbot, enabling Bard to understand images in user prompts..
11. **AMD** announced its most-advanced GPU for artificial intelligence, the MI300X, which will start shipping to some customers later this year*.*
12. **Vercel** introduced **Vercel AI SDK -** an open-source library to build conversational, streaming and chat user interfaces. Includes first-class support for OpenAI, LangChain, and Hugging Face Inference.
13. **Vercel** announced '**Vercel AI Accelerator,** a 6-week long accelerator program with $850k in free credits from OpenAI, Replicate and others.
14. **Salesforce** announces **AI Cloud** \- generative AI for the enterprise. AI Cloud includes the new **Einstein Trust Layer**, to help prevent large-language models (LLMs) from retaining sensitive customer data.
15. **Cohere** and **Oracle** are working together to make it easy for enterprise customers to train their own specialized large language models while protecting the privacy of their training data.
16. **Coda** released Coda AI - the AI-powered work assistant integrated in Coda to automate workflows. Coda also announced ‘**Coda's AI at Work Challenge**’, offering $40,000 in total prizes to the makers who submit the most useful Coda AI template to the Coda Gallery.
17. **OpenAI, Google DeepMind and Anthropic** have committed to provide “early or priority access” to their AI models to UK in order to support research into evaluation and safety.

If you like this news format, you might find my  [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
32,learnmachinelearning,gpt-4,top,2024-01-03 01:17:54,What libraries should I become proficient in as a machine learning engineer?,Bbpowrr,False,0.9,16,18x6eu9,https://www.reddit.com/r/learnmachinelearning/comments/18x6eu9/what_libraries_should_i_become_proficient_in_as_a/,16,1704244674.0,"I do MLE / DS at a big 4 firm, and have been doing so for about 2 years. I have experience with implementing some pretty cool solutions using the following libs:
- open AI (gpt & embedding models)
- huggingface
- faiss
- scikit-learn

I also have a 1st class CS degree from a Russell group uni and have done some ML projects during my degree.

But I have never had to / been taught how to use libraries such as TensorFlow or PyTorch or Keras in any ML project that I have implemented. Usually I use the scikit-learn library for model development.

However, I see a lot of jobs specifically asking for TensorFlow or PyTorch or Keras.

Therefore, I was wondering whether it is necessary to start upskilling in one or all of these libraries/frameworks to become a well established MLE? And if so, what is the best way to learn them?



Also, with my current skill set, how do I fair in the job market for MLE / DS roles? Ik it's not much to go off but any guesses would be appreciated.

For context, I have experience with using the following types of models:
- GPT / embedding
- ensemble (Random Forest, XGBoost, AdaBoost)
- computer vision (OCR)
- Clustering (cus Weka)
- SVM
- Naive Bayes
- Logistic regression 
- decision trees 

I think an obvious gap is a lack of neural networks / CNNs - does this matter much?

Many thanks for any advice!"
33,learnmachinelearning,gpt-4,top,2023-04-14 11:37:08,Post GPT-4: Answering Most Asked Questions About AI,kingabzpro,False,0.9,14,12luajw,https://www.kdnuggets.com/2023/04/post-gpt4-answering-asked-questions-ai.html,1,1681472228.0,
34,learnmachinelearning,gpt-4,top,2023-04-22 05:51:13,Integrating Google search into OpenAI models like GPT-4,Ghost25,False,1.0,16,12uwd8p,https://www.reddit.com/r/learnmachinelearning/comments/12uwd8p/integrating_google_search_into_openai_models_like/,8,1682142673.0,"Thought I'd share an explanation of how I implemented Google search into my GPT-4 based chatbot.

Github here: https://github.com/sgreenb/pico_assistant

One extremally simple modification that dramatically improves the ability of a GPT to answer questions: letting it Google stuff.

Here’s a demo:

https://imgur.com/ZR6hvLg 1

The implementation works like this.

1. A user enters an input.
2. An agent called “Executive” looks at the input and decides if an API like Spotify, Twillio, or Gmail is needed or if it can be answered by the chatbot alone.
3. If the chatbot is needed the input is first sent to a Google agent. The Google agent’s system message looks like this:

```
{""role"":""system"", ""content"": ""You analyze a user's input to a large language model with \
training data that cuts off at September 2021. The current year is 2023. You decide how \
likely it is that a user's request will benefit from a Google search to help address the\
question. Respond with a number in the range 1-10, where 1 is very unlikely that a \
Google search would be beneficial, and 10 meaning a Google search is highly necessary.""}
```

This is quite fast, since it only needs to generate one or two tokens.

If the output is above some threshold (say 7), then we call another agent, the query agent, otherwise we return False and default to the normal chat agent.

```
    google_probability = int(completion.choices[0].message.content)
    if google_probability >= cutoff:
        search_results = trim_text(search_and_scrape(prompt))
        query_with_context = prompt + str(search_results)
        print(""\nPico: "", end='', flush=True)
        response = query_agent_stream(query_with_context)
        return response
    else:
        return False
```

When we call the query agent, we feed it the first part of a Google search we get from searching the input. We get that from the very simple trim_text and search_and_scrape functions that look like this:

```

def search_and_scrape(query):
    try:
        headers = {
            ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3""
        }
        url = f""https://www.google.com/search?q={query}""
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text()
            cleaned_text = ' '.join(text.split())
            return cleaned_text
        else:
            print(f""Failed to fetch search results for query: {query}, status code: {response.status_code}"")
            return None

    except Exception as e:
        print(f""Error fetching search results for query: {query}, error: {e}"")
        return None

def trim_text(text, start_index = 450, length=1500):
    return text[start_index:start_index + length]
```

The query agent has this system message:

```
{""role"":""system"", ""content"": ""You answer a user's question, given some text as context to help\
answer the question. The user request will be followed by the context. The context given is\
from the user's Google search results, it is current and up to date.\
Do not contradict the contents of the given text in your answer.""}
```

And that’s it. You can change the cutoff threshold or get more sophisticated with fetching web results. I hope you find this useful."
35,learnmachinelearning,gpt-4,top,2023-08-13 01:03:38,"Besides HHH, what is RLHF actually good for? Every example I've ever seen has focused on lobotomizing models.",JonBon13,False,0.85,13,15pl55g,https://www.reddit.com/r/learnmachinelearning/comments/15pl55g/besides_hhh_what_is_rlhf_actually_good_for_every/,5,1691888618.0,"Most instruction following & SFT seems likely to become unnecessary as those data sets leak into pre-training. However, it seems like RLHF is not a 1-size fits all solution. However, I've only seen real ""value add"" use cases for HHH. 

**Are there examples of RLHF models that are actually ""task specific"" or ""better than"" GPT-4 + prompting?** I've seen the OpenAI & other graphs that show humans rank RLHF > SFT, but the ""chat"" example seems so incredibly generic. Are there cases where you can actually squeeze out large performance for certain useful tasks only with RLHF? 

What are the buyers of RLHF data on Surge/Scale actually trying to get models to do?"
36,learnmachinelearning,gpt-4,top,2023-06-22 01:28:35,Want suggestions on the curriculum to learn Machine Learning. Advice on my draft plan.,meetofleaf,False,0.88,12,14fpm9f,https://www.reddit.com/r/learnmachinelearning/comments/14fpm9f/want_suggestions_on_the_curriculum_to_learn/,2,1687397315.0,"Hello devs,
I'm a developer/Data Analyst. I have 2 years experience in Python development and data analytics. To level up, I'm looking to start learning Machine Learning and AI to switch to a career in developing industrial AI solutions.
I got chatgpt to create a plan for me for a basic idea and would really appreciate it if y'all could advice improvements or refer to already existing great curriculum to achieve my goal.
Thanks

AI/ML Path:

*****Level 1: Beginner*****

1. Linear Regression
   - Simple Linear Regression
   - Multiple Linear Regression

2. Logistic Regression

3. Decision Trees

4. K-Nearest Neighbors (KNN)

5. Evaluation Metrics
   - Accuracy, Precision, Recall
   - F1 Score

*****Level 2: Intermediate*****

1. Support Vector Machines (SVM)

2. Random Forests

3. Principal Component Analysis (PCA)

4. K-Means Clustering

5. Model Evaluation Techniques
   - Train-Test Split
   - Cross-Validation

*****Level 3: Advanced*****

1. Gradient Boosting Machines (GBM)
   - AdaBoost
   - XGBoost

2. Convolutional Neural Networks (CNN)
   - Image Classification
   - Transfer Learning

3. Recurrent Neural Networks (RNN)
   - Sequence Modeling
   - Natural Language Processing (NLP)

4. Reinforcement Learning
   - Markov Decision Processes (MDP)
   - Q-Learning

5. Natural Language Processing (NLP)
   - Text Classification
   - Named Entity Recognition (NER)
   - Sentiment Analysis

*****Level 4: Expert*****

1. Deep Learning Architectures
   - Generative Adversarial Networks (GAN)
   - Transformer Models (BERT, GPT)

2. Time Series Analysis
   - Autoregressive Integrated Moving Average (ARIMA)
   - Long Short-Term Memory (LSTM)

3. Bayesian Methods
   - Bayesian Networks
   - Gaussian Processes

4. Model Deployment and Production
   - Web APIs and Microservices
   - Cloud Services (AWS, Google Cloud, Azure)
   - Deployment Platforms (Heroku, Kubernetes)

5. Ethical Considerations in Machine Learning
   - Fairness and Bias Mitigation
   - Privacy and Data Protection"
37,learnmachinelearning,gpt-4,top,2023-03-15 20:18:13,Do multi modal LLM models just inject image description to the context?,ChessGibson,False,0.89,12,11s7ya3,https://www.reddit.com/r/learnmachinelearning/comments/11s7ya3/do_multi_modal_llm_models_just_inject_image/,4,1678911493.0,"Hi! Small question I have been asking myself seeing multiple multi modal models recently: do they use interconnected neural networks for different input types, or do they simply convert non-text inputs into textual descriptions before processing them with their language models? What's happening for PaLM-E for instance? How about GPT-4?"
38,learnmachinelearning,gpt-4,top,2023-04-22 22:24:26,PyTorch .pth file size capped at 52.8 MB?,loliko-lolikando,False,1.0,12,12vlorx,https://www.reddit.com/r/learnmachinelearning/comments/12vlorx/pytorch_pth_file_size_capped_at_528_mb/,3,1682202266.0,"I've created few GPT models with PyTorch, and some smaller models are about 19 kB or few MB, but the bigger ones seem capped on 52.8 or 52.7 MB. These models use same model type, but each has a different dataset, training iters (time of training) and almost everything else. But they all cant get past 52.8 MB. 

I am glad its not 50 GB, but this seems that more training dosent do anything. What is going on?

&#x200B;

Here is one of the codes (you can see im saving the model throughout the training, but the size is still same (the problem cannto be in the saving throughout training, because other scripts with different dataset do the same)):  


    import torch
    import torch.nn as nn
    from torch.nn import functional as F
    
    # hyperparameters
    batch_size = 64 # how many independent sequences will we process in parallel?
    block_size = 256 # what is the maximum context length for predictions?
    max_iters = 70000
    eval_interval = 500
    learning_rate = 1e-4
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    eval_iters = 200
    n_embd = 384
    n_head = 6
    n_layer = 6
    dropout = 0.2
    # ------------
    print(device)
    #torch.manual_seed(1337)
    
    # Read our shakespeare dataset
    with open(r""GPT/datasets/saturninV2.txt"", ""r"", encoding=""UTF-8"") as f:
        text = f.read()
    
    # here are all the unique characters that occur in this text
    chars = sorted(list(set(text)))
    vocab_size = len(chars)
    # create a mapping from characters to integers
    stoi = { ch:i for i,ch in enumerate(chars) }
    itos = { i:ch for i,ch in enumerate(chars) }
    encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers
    decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string
    
    # Train and test splits
    data = torch.tensor(encode(text), dtype=torch.long)
    n = int(0.9*len(data)) # first 90% will be train, rest val
    train_data = data[:n]
    val_data = data[n:]
    
    # data loading
    def get_batch(split):
        # generate a small batch of data of inputs x and targets y
        data = train_data if split == 'train' else val_data
        ix = torch.randint(len(data) - block_size, (batch_size,))
        x = torch.stack([data[i:i+block_size] for i in ix])
        y = torch.stack([data[i+1:i+block_size+1] for i in ix])
        x, y = x.to(device), y.to(device)
        return x, y
    
    @torch.no_grad()
    def estimate_loss():
        out = {}
        model.eval()
        for split in ['train', 'val']:
            losses = torch.zeros(eval_iters)
            for k in range(eval_iters):
                X, Y = get_batch(split)
                logits, loss = model(X, Y)
                losses[k] = loss.item()
            out[split] = losses.mean()
        model.train()
        return out
    
    class Head(nn.Module):
        """""" one head of self-attention """"""
    
        def __init__(self, head_size):
            super().__init__()
            self.key = nn.Linear(n_embd, head_size, bias=False)
            self.query = nn.Linear(n_embd, head_size, bias=False)
            self.value = nn.Linear(n_embd, head_size, bias=False)
            self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))
    
            self.dropout = nn.Dropout(dropout)
    
        def forward(self, x):
            # input of size (batch, time-step, channels)
            # output of size (batch, time-step, head size)
            B,T,C = x.shape
            k = self.key(x)   # (B,T,hs)
            q = self.query(x) # (B,T,hs)
            # compute attention scores (""affinities"")
            wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)
            wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)
            wei = F.softmax(wei, dim=-1) # (B, T, T)
            wei = self.dropout(wei)
            # perform the weighted aggregation of the values
            v = self.value(x) # (B,T,hs)
            out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)
            return out
    
    class MultiHeadAttention(nn.Module):
        """""" multiple heads of self-attention in parallel """"""
    
        def __init__(self, num_heads, head_size):
            super().__init__()
            self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])
            self.proj = nn.Linear(head_size * num_heads, n_embd)
            self.dropout = nn.Dropout(dropout)
    
        def forward(self, x):
            out = torch.cat([h(x) for h in self.heads], dim=-1)
            out = self.dropout(self.proj(out))
            return out
    
    class FeedFoward(nn.Module):
        """""" a simple linear layer followed by a non-linearity """"""
    
        def __init__(self, n_embd):
            super().__init__()
            self.net = nn.Sequential(
                nn.Linear(n_embd, 4 * n_embd),
                nn.ReLU(),
                nn.Linear(4 * n_embd, n_embd),
                nn.Dropout(dropout),
            )
    
        def forward(self, x):
            return self.net(x)
    
    class Block(nn.Module):
        """""" Transformer block: communication followed by computation """"""
    
        def __init__(self, n_embd, n_head):
            # n_embd: embedding dimension, n_head: the number of heads we'd like
            super().__init__()
            head_size = n_embd // n_head
            self.sa = MultiHeadAttention(n_head, head_size)
            self.ffwd = FeedFoward(n_embd)
            self.ln1 = nn.LayerNorm(n_embd)
            self.ln2 = nn.LayerNorm(n_embd)
    
        def forward(self, x):
            x = x + self.sa(self.ln1(x))
            x = x + self.ffwd(self.ln2(x))
            return x
    
    class GPTLanguageModel(nn.Module):
    
        def __init__(self):
            super().__init__()
            # each token directly reads off the logits for the next token from a lookup table
            self.token_embedding_table = nn.Embedding(vocab_size, n_embd)
            self.position_embedding_table = nn.Embedding(block_size, n_embd)
            self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])
            self.ln_f = nn.LayerNorm(n_embd) # final layer norm
            self.lm_head = nn.Linear(n_embd, vocab_size)
    
            # better init, not covered in the original GPT video, but important, will cover in followup video
            self.apply(self._init_weights)
    
        def _init_weights(self, module):
            if isinstance(module, nn.Linear):
                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)
                if module.bias is not None:
                    torch.nn.init.zeros_(module.bias)
            elif isinstance(module, nn.Embedding):
                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)
    
        def forward(self, idx, targets=None):
            B, T = idx.shape
    
            # idx and targets are both (B,T) tensor of integers
            tok_emb = self.token_embedding_table(idx) # (B,T,C)
            pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)
            x = tok_emb + pos_emb # (B,T,C)
            x = self.blocks(x) # (B,T,C)
            x = self.ln_f(x) # (B,T,C)
            logits = self.lm_head(x) # (B,T,vocab_size)
    
            if targets is None:
                loss = None
            else:
                B, T, C = logits.shape
                logits = logits.view(B*T, C)
                targets = targets.view(B*T)
                loss = F.cross_entropy(logits, targets)
    
            return logits, loss
    
        def generate(self, idx, max_new_tokens):
            # idx is (B, T) array of indices in the current context
            for _ in range(max_new_tokens):
                # crop idx to the last block_size tokens
                idx_cond = idx[:, -block_size:]
                # get the predictions
                logits, loss = self(idx_cond)
                # focus only on the last time step
                logits = logits[:, -1, :] # becomes (B, C)
                # apply softmax to get probabilities
                probs = F.softmax(logits, dim=-1) # (B, C)
                # sample from the distribution
                idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)
                # append sampled index to the running sequence
                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)
            return idx
    
    model = GPTLanguageModel()
    m = model.to(device)
    # print the number of parameters in the model
    print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')
    
    # create a PyTorch optimizer
    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)
    
    for iter in range(max_iters):
    
        # every once in a while evaluate the loss on train and val sets
        if iter % eval_interval == 0 or iter == max_iters - 1:
            losses = estimate_loss()
            print(f""step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}"")
    
        if iter % 10000 == 0 and (iter != 0 or iter != max_iters):
            torch.save(model.state_dict(), 'GPT_saturninV2New'+str(iter)+'.pth')
    
        # sample a batch of data
        xb, yb = get_batch('train')
    
        # evaluate the loss
        logits, loss = model(xb, yb)
        optimizer.zero_grad(set_to_none=True)
        loss.backward()
        optimizer.step()
    
    torch.save(model.state_dict(), 'GPT_saturninV2New.pth')

Thanks"
39,learnmachinelearning,gpt-4,top,2023-06-30 17:27:56,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.92,9,14n6lwl,https://www.reddit.com/r/learnmachinelearning/comments/14n6lwl/this_week_in_ai_all_the_major_ai_developments_in/,0,1688146076.0,"1. **Microsoft** has launched AI-powered shopping tools in Bing search and Edge, including AI-generated buying guides which automatically aggregate product specifications and purchase locations for user queries​, and AI-generated review summaries that provide concise overviews of online product reviews .
2. **Salesforce AI Research** released **XGen-7B**, a new **open-source** 7B LLM trained on 8K input sequence length for 1.5T tokens.
3. Researchers present **DreamDiffusion**, a novel method for generating high-quality images directly from brain EEG signals without the need to translate thoughts into text.
4. **Google** announced the first *Machine* ***Un****learning Challenge* hosted on Kaggle.
5. **Microsoft** announced a new ***AI Skills Initiative*** that includes free coursework developed with LinkedIn, a new open global grant challenge and greater access to free digital learning events and resources for AI education.
6. **Stability AI** announced **OpenFlamingo V2,** an open-source reproduction of DeepMind's Flamingo model. OpenFlamingo models achieve more than 80% of the performance of their corresponding Flamingo model.
7. **Unity** announces two AI-powered tools: Unity Muse and Unity Sentis. Muse generates animations, 2D sprites, textures etc. in the Unity Editor using text and sketches. Sentis lets you embed an AI model in the Unity Runtime for your game or application. It enables AI models to run on any device where Unity runs..
8. **ElevenLabs** launched **Voice Library** \- a library and community for sharing AI generated voices designed using their *voice Design* tool.
9. **Merlyn Mind** released three **open-source education-specific LLMs**. Merlyn Mind is building a generative AI platform for education where engagement will be curriculum-aligned, hallucination-resistant, and age-appropriate.
10. Amazon's **AWS** has launched a $100 million program, the **Generative AI Innovation Center**, that connects AWS machine learning and artificial intelligence experts with businesses to build and deploy generative AI solutions.
11. New open-source text to video AI model, **Zeroscope\_v2 XL**, released that generates high quality video at 1024 x 576, with no watermarks.
12. Researchers present MotionGPT - a motion-language model to handle multiple motion-relevant tasks.
13. **Databricks** is set to acquire the open-source startup **MosaicML** for $1.3 billion. MosaicML had recently released **MPT-30B,** an open-source model licensed for commercial use that outperforms the original GPT-3 .
14. Generative AI-related job postings in the United States jumped about 20% in May as per Indeed’s data.
15. The source code for the algorithm **DragGAN** (Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold) released and demo available on Huggingface.
16. A new foundation model, **ERNIE** **3.5 b**y China’s Baidu surpassed ChatGPT (3.5) in comprehensive ability scores and outperforms GPT-4 in several Chinese language capabilities.
17. **Adobe** is prepared to pay out any claims in case an enterprise customer loses a lawsuit over the use of content generated by Adobe Firefly, the generative AI image tool.
18. **Google** launched generative AI coding features in Google Colab for Pro+ subscribers in the US.

I didn't add links to news sources here because of auto-mod, but they are included in the newsletter and **you can read the online issue** [**here**](https://aibrews.substack.com/p/ai-generated-buying-guides-in-bing) **without signup**. If you like this news format, you might find my [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. . Thanks"
40,learnmachinelearning,gpt-4,top,2022-10-16 16:57:07,What We Know About GPT-4 So Far,kingabzpro,False,0.82,11,y5lrld,https://www.datacamp.com/blog/what-we-know-gpt4,0,1665939427.0,
41,learnmachinelearning,gpt-4,top,2023-12-30 10:05:08,"AI/Data Science/MLE resume, no callbacks from 60 job apps. Appreciate any and all help!",RookFlame4882,False,0.86,10,18ucfmx,https://www.reddit.com/r/learnmachinelearning/comments/18ucfmx/aidata_sciencemle_resume_no_callbacks_from_60_job/,11,1703930708.0,"Hi everyone, thank you for your time. Been trying to apply for entry level Machine Learning roles but am getting dejected from the lack of callbacks. If there's any improvements I could make please do let me know. Thank you! 

&#x200B;

https://preview.redd.it/mqvi4q3toe9c1.png?width=5100&format=png&auto=webp&s=b1b97490b40c19716bc0765d6c1c0caeb90b7a68

&#x200B;"
42,learnmachinelearning,gpt-4,top,2023-02-14 17:53:16,[P] Practical Steps to Reduce Hallucination and Improve Performance of Systems Built with Large Language Models like ChatGPT,vykthur,False,0.84,8,112bk1o,https://www.reddit.com/r/learnmachinelearning/comments/112bk1o/p_practical_steps_to_reduce_hallucination_and/,2,1676397196.0,"&#x200B;

[Practical steps to reduce hallucination and improve performance of systems built with large language models like ChatGPT](https://preview.redd.it/gksxjpnoz6ia1.png?width=1456&format=png&auto=webp&s=c34531fbe1311eab9323c148eef35fcf0d70decd)

Large language models (LLMs) like the GPT series (GPT3, 3.5, [ChatGPT](https://openai.com/blog/chatgpt/)) can be powerful tools in building useful applications. However, **LLMs are probabilistic** \- i.e., they generate text by learning a probability distribution over words seen during training. For example, given the following words as context “*rise and*”, an LLM can infer that the next word it should generate that fits this context is likely to be “*shine*”. While this setup ensures generated text is **coherent and human-like** (e.g., asking ChatGPT to rewrite the [Serenity Praye](https://en.wikipedia.org/wiki/Serenity_Prayer)r in the style of the [American Constitution](https://www.senate.gov/civics/constitution_item/constitution.htm) yields some intriguing prose), this resulting text may [**not be factual, or just plain incorrect**](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web) **(not grounded in the model’s input or training data) - aka hallucination**. In addition, another limitation of LLMs is that they struggle to address **tasks that need** [**complex multistep reasoning**](https://arxiv.org/pdf/2208.14271.pdf)**.** For example, asking the model to address mathematical word problems or puzzles often requires that the task is decomposed into steps, some computation applied to solve each step and some transformation applied to aggregate results into a final answer; this remains challenging for LLMs.  


Full article: [https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination](https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination) 

This post discusses the following:

* An overview on why hallucination will likely *always be a problem* with LLMs.
* Practical steps developers can take to reduce hallucination and improve performance including:  

   * Low temperature
   * Use of external knowledge bases
   * Chain of thought prompting
   * Self-consistency/voting
   * Task decomposition and agents
   * Correctness probabilities for result filtering
   * Task bench marks
   * Building defensive user interfaces."
43,learnmachinelearning,gpt-4,top,2023-04-11 22:53:56,I want to teach a chatbot about a world I'm creating so that it can answer my questions about it.,Common_Ad_6362,False,0.78,10,12j0uh5,https://www.reddit.com/r/learnmachinelearning/comments/12j0uh5/i_want_to_teach_a_chatbot_about_a_world_im/,10,1681253636.0,"I've been experimenting over the last couple of days with telling ChatGPT3.5 and 4 about my world building project, but it only seems to know about our current session instead of our whole conversation.  


I have 12 GB of VRAM, is there something I can run locally that I can teach my world to and then ask it questions about that world the same way I'm able to do with ChatGPT?   I want it to remember the content I teach it beyond our session."
44,learnmachinelearning,gpt-4,top,2023-09-10 21:10:20,A Defacto Guide on Building Generative AI Apps with the Google PaLM API,vykthur,False,0.91,9,16fbuud,https://www.reddit.com/r/learnmachinelearning/comments/16fbuud/a_defacto_guide_on_building_generative_ai_apps/,0,1694380220.0,"[PaLM is a transformer-based large language model that can be used in building Generative AI app.](https://preview.redd.it/u4dx1h38thnb1.png?width=1456&format=png&auto=webp&s=3455c33a5494dfff8f2e787c805e76b38a34c722)

Full post [here](https://newsletter.victordibia.com/p/generative-ai-apps-google-palm).

Generative AI models such as [large language models (LLMs)](https://newsletter.victordibia.com/p/understanding-size-tradeoffs-with) offer developers an opportunity to build new experiences and offer value to end users. Tools like #ChatGPT powered by GPT3.5 and GPT4 models from OpenAI have demonstrated the capabilities of these models.

Similar to GPT models, PaLM is a transformer-based foundation model offered by Google as an API service. As a developer, understanding the capabilities of LLMs from multiple providers (e.g., OpenAI, Google, Anthropic, Cohere) can be valuable in making software design decisions (model selection, effort estimation, limitations, etc). In this post, I’ll dig into what I’ve learned while exploring the PaLM api, covering the following:

TLDR;

* Model [Overview](https://newsletter.victordibia.com/p/generative-ai-apps-google-palm): Overview of the PaLM model architecture (it is a transformer based model, trained on a mixture of language modeling objectives and extensive compute).
* [Api Interfaces](https://newsletter.victordibia.com/i/135691948/accessing-the-palm-api-makersuite-vs-vertex-client-libraries-vs-vertex-rest-api) : Pros/cons of different approaches to calling the PaLM api ([MakerSuite](https://makersuite.google.com/) vs Vertex Client Libraries vs Vertex REST Api).
* [Use Case Implementation](https://newsletter.victordibia.com/i/135691948/a-structured-data-extraction-use-case): Implementation and performance on a concrete/useful task - structured data extraction. We’ll use PaLM to analyze multiple book summaries (from the [CMU books Summary dataset](https://www.cs.cmu.edu/~dbamman/booksummaries.html)), extract a list of actors, their actions, relevance to a given user profile and plot these stats to extract insights.
* [Developer notes](https://newsletter.victordibia.com/i/135691948/developer-notes-on-the-palm-api) specific to the PaLM model. E.g., the API provides valuable citations for some responses, responses may be blocked due to safety filters, low-level prompting requirements, instruction following capabilities, etc

**Note:** This post focuses on text generation models fine tuned on multi-turn conversation applications (chat). It does not cover embedding models, multimodal models etc.

&#x200B;

## A Structured Data Extraction Use Case

For the purpose of this post, we will define **structured data extraction** as follows:

>**Structured Data Extraction**.Given some semi-structured or unstructured data (text), extract entities into a structured format (e.g., a JSON file, table or database).

&#x200B;

&#x200B;

[Structured Data Extraction-  Given some semi-structured or unstructured data \(text\), extract entities into a structured format \(e.g., a JSON file, table or database\).](https://preview.redd.it/qa5mut6gthnb1.png?width=1456&format=png&auto=webp&s=150b7fc0393111b025369dbf7b666e90a90e87b6)

&#x200B;

This general task is interesting as it also applies to **practical** business domains e.g.,

* **Hiring**: Improve candidate selection by quickly identifying relevant skills, experience, and qualifications.
* **Legal**: Legal firms and businesses can extract and analyze key data points from contracts, such as dates, terms, clauses, and parties involved, to identify potential legal risks, streamline negotiations, and improve overall contract management.
* **Customer Support:** Automating the extraction of structured data from customer support inquiries can help identify common issues, route queries to the appropriate support agents, and improve overall support efficiency and customer satisfaction.

We will explore this task using a [subset](https://github.com/chikne97/Book-Genre-Prediction) of the [CMU Book Summary dataset](https://www.cs.cmu.edu/~dbamman/booksummaries.html). Each row in the dataset has a **book name**, **genre** and **summary** (between 500 - 5000 characters) column. Our goal is to extract a **list of characters** in each summary, their **name, actions, gender** and finally **their relevance** given a user’s profile.

The overall implementation process is summarized as follows:

* Construct a random sample of the dataset (in the results below I use n=100)
* For each summary, prompt PaLM (**chat-bison**) to return a JSON data structure containing structured data (see prompt snippet below).
* Parse the structured data and assemble into a data frame
* Post process the data frame and plot results.

Example output text generated by PaLM is shown below:

    {'match': 'yes',   'match_reason': 'The book is a match because it is a crime novel and the user likes crime novels',   'characters': [{'name': 'Harry Hole',     'gender': 'male',     'actions': ['Harry went to the market',      'Harry bought a car',      'Harry investigated a crime']},    {'name': 'Rakel',     'gender': 'female',     'actions': ['Rakel met Harry',      'Rakel talked to Harry',      'Rakel fell in love with Harry']},    ...    {'name': 'Crown Prince of Norway',     'gender': 'male',     'actions': ['The Crown Prince of Norway was the target of an assassination attempt',      'The Crown Prince of Norway was saved by Harry',      ""The Crown Prince of Norway's identity was revealed""]}]
    }

Now that we have structured data, we can then parse this as JSON to get structured data and plot the results to extract insights. An example plot of extracted data are shown below:

&#x200B;

[Using the PaLM api to extract the number of characters from book summary text.](https://preview.redd.it/qeij6tmgthnb1.png?width=1456&format=png&auto=webp&s=37417d0e37c3cde74d35f078ee3e0735e18f677a)

&#x200B;

### Main Findings - Developer Notes on the PaLM API

While trying out the models, there were a few important differences in how the PalM api works, say compared to the OpenAI api or OSS models available via the transformers library. These may be due to optimizations that make these models efficient to serve at scale, subtle differences in model architecture or training data composition.

* ✅ **Citation**. license , safety attributes, author. This is a unique and highly positive thing with the PaLM api. If the generated content is related to a known author, or license, book title etc, this gets included in the responses. Excellent for building apps with attribution! As far as I know, **this is the only api** that explores doing this and it must take quite a significant amount of engineering to make this happen. Kudos!
* ⚠️ **Maximum number of responses**. Unlike other apis where you can generate n variations of responses bounded by the max output token size, PaLM api has a strict limit on this (some models have it set to 2, others 4). For most applications, this is fine. As an alternative, you can always make additional calls, or prompt the model to return a list of responses in a single call.
* ⚠️ **Alternating Message Authors**: the api strictly expects alternating authors for chat based messages. In [llmx](https://github.com/victordibia/llmx), I implement a simple check for consecutive messages and merge them with a newline character.
* ⚠️ **Blocked Responses** . In some cases, the PaLM api may block responses due to safety concerns. In such cases, the response contains a dedicated **blocked** field and a safetyAttributes dictionary that contains a list of categories (e.g., Derogatory, Profanity etc) and scores per category. This is useful to monitor for graceful degradation in apps (e.g., offering some recommendation to the user on how to recover from the failure).  
About **9%** of the responses in the structured data extraction from book summaries example above were blocked.
* ⚠️ **Prompt** **Sensitivity** . In the example use case above (structured task extraction), the model is required to output JSON structured data in a specific format defined in the prompt. I found that the \`codechat-bison\` model performed significantly worse (completely failed to follow the suggested output format) compared to the \`chat-bison\` model. This is likely because the task is not an explicit code generation task even though the model is prompted to output JSON structured text. I also found that it was necessary to include explicit commands such as “do not include double quotes in results” to get \`chat-bison\` to not make that specific mistake (which invalidates JSON parsing). In contrast, a general chat model like GPT 3.5/4 can address both text and code tasks equally well, easily avoiding formatting mistakes without any special prompting.

## Conclusion

With the right prompting, PaLM is a fairly capable model, with additional benefits benefits such as citations, fine grained access control via the Vertex AI GCP interface. I also found the api to be fast, with reasonable response times.

Learn more [here](https://newsletter.victordibia.com/p/generative-ai-apps-google-palm)."
45,learnmachinelearning,gpt-4,top,2023-08-29 03:52:11,"Open-Source CodeLlama Server: Streaming, Caching, Model Fallbacks (OpenAI + Anthropic), Prompt-tracking",VideoTo,False,0.9,7,1647o7n,https://www.reddit.com/r/learnmachinelearning/comments/1647o7n/opensource_codellama_server_streaming_caching/,0,1693281131.0,"**TLDR;** We're open-sourcing our CodeLlama server. It handles streaming, caching, model fallbacks, and tracks prompts + token usage - [https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server](https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server)

\~\~

Hello r/learnmachinelearning,

I’m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, TogetherAI, Cohere, Anthropic, Baseten, Hugging face API Endpoints: [https://github.com/BerriAI/litellm/](https://github.com/BerriAI/litellm/)

We're open sourcing our CodeLlama server:

What can our server do? - It uses Together AI's CodeLlama to answer coding questions, with GPT-4 + Claude-2 as backups (you can easily switch this to any model from Huggingface, Replicate, Cohere, AI21, Azure, OpenAI, etc.)

Consistent Input/Output Format - Call all models using the OpenAI format: completion(model, messages) - Text responses will always be available at \['choices'\]\[0\]\['message'\]\['content'\]

* Streaming & Async Support - Return generators to stream text responses
* Error Handling Using Model Fallbacks (if Phind-CodeLlama fails, use Claude-2, fine-tuned GPT-3.5 etc.)
* Logging - It's integrated with promptlayer, so you can automatically track your prompt + model changes there.
* Token Usage & Spend - Track Input + Completion tokens used + Spend/model
* Caching - In-memory + Redis Cache solutions provided (works for streaming too!).

You can deploy liteLLM to your own infrastructure using Railway, GCP, AWS, Azure

Happy completion() !"
46,learnmachinelearning,gpt-4,top,2023-12-31 17:01:12,Andrew Ng On How To Read Machine Learning Papers (Summary by GPT-4),ledmmaster,False,0.75,10,18vbz75,https://forecastegy.com/posts/read-machine-learning-papers-andrew-ng/,2,1704042072.0,
47,learnmachinelearning,gpt-4,top,2023-01-08 05:09:46,Major drawback/limitation of GPT-3,trafalgar28,False,0.72,6,106aie8,https://www.reddit.com/r/learnmachinelearning/comments/106aie8/major_drawbacklimitation_of_gpt3/,13,1673154586.0,"I have been working on a project with GPT-3 API for almost a month now. The only drawback of GPT-3 is that the prompt you can send to the model is capped at 4,000 tokens - where a token is roughly equivalent to ¾ of a word.  Due to this, providing a large context to GPT-3 is quite difficult.

Is there any way to resolve this issue?"
48,learnmachinelearning,gpt-4,top,2023-11-04 12:57:11,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.82,7,17nl3vg,https://www.reddit.com/r/learnmachinelearning/comments/17nl3vg/this_week_in_ai_all_the_major_ai_developments_in/,0,1699102631.0,"1. **Luma AI** introduced ***Genie***, a generative 3D foundation model in research preview. *It’s free during research preview via Discord* \[[*Details*](https://lumalabs.ai/genie)\].
2. **Nous** **Research** released ***Obsidian***, the world's first 3B multi-modal model family pre-trained for 4 Trillion tokens that runs locally on iPhones. Obsidian competes in benchmarks withWizardLM-13B and GPT4-X-Vicuna 13B and is based on CapybaraV1.9 .
3. **Phind** has released a new model ***Phind Model V7*** that matches and exceeds GPT-4's coding abilities while running 5x faster and having16k context.
4. **Runway** released an update for both text to video and image to video generation with Gen-2, bringing major improvements to both the fidelity and consistency of video results.
5. **Stability AI** announced:  

   1. ***Stable 3D*** (Private Preview): a tool to generate a draft-quality 3D model in minutes, by selecting an image or illustration, or writing a text prompt.
   2. ***Sky Replacer:*** a tool that allows users to replace the color and aesthetic of the sky in their original photos with a selection of nine alternatives.
   3. integration of Content Credentials and ***invisible watermarking*** for images generated via the Stability AI API.
   4. Stable FineTuning (Private Preview)
6. **Hugging Face** released ***Zephyr-7B-β***, a fine-tuned version of Mistral-7B that achieves results similar to Chat Llama 70B in multiple benchmarks and above results in MT bench.
7. **LangChain** launched ***LangChain Templates*** \- a collection of easily deployable reference architectures for a wide variety of popular LLM use cases.
8. **Nvidia** unveiled ***ChipNeMo***, a specialized 43 billion parameter large language model for chip design that can answer general questions related to chip design and write short scripts to interface with CAD tools.
9. **Together** released ***RedPajama-Data-v2***: an Open dataset with 30 Trillion tokens for training Large Language Models. It’s the largest public dataset released specifically for LLM training.
10. **Hugging Face** released ***Distil-Whisper***, a distilled version of Whisper that is 6 times faster, 49% smaller, and performs within 1% word error rate (WER) on out-of-distribution evaluation sets.
11. **Google Research** and **Google DeepMind** present ***MetNet-3***, the first AI weather model to learn from sparse observations and outperform the top operational systems up to 24 hours ahead at high resolutions. Google has integrated MetNet-3’s capabilities across its various products.
12. **Google DeepMind** and **Isomorphic Labs** update on the next generation of ***AlphaFold***: the new model greatly expands coverage of structure prediction beyond proteins to other key biomolecular classes. This paves the way for researchers to find novel proteins to eventually map biomolecular structures needed to design better drugs.
13. **Nolano Research** and **EleutherAI** introduced ***Hi-NOLIN***, first state-of-the-art open-source English-Hindi bilingual model built upon the Pythia model suite.
14. **Google** is rolling out ***Immersive View for Routes*** in 15 cities, starting this week along with other AI-powered features in Maps. Immersive view combines Street view, aerial imagery, and live information like weather and traffic to give an aerial, photo-realistic preview of your planned Google Maps route.
15. **Perplexity** announced two new models **pplx-7b-chat** and **pplx-70b-chat**, built on top of open-source LLMs and fine-tuned for chat. They are available as an alpha release, via Labs and pplx-api.
16. **SlashNext's** *2023 State of Phishing Report* reveals a 1,265% increase in Phishing Emails since the launch of ChatGPT in november 2022, signaling a new era of cybercrime fueled by Generative AI.
17. **Google** launches generative AI tools for product imagery to US advertisers and merchants.

Source: AI Brews - you can subscribe [here](https://aibrews.com/). it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
49,learnmachinelearning,gpt-4,top,2023-04-11 14:14:34,Help with pet project to learn - Running ChatGPT-2 at home,SigmaSixShooter,False,0.78,5,12il5t0,https://www.reddit.com/r/learnmachinelearning/comments/12il5t0/help_with_pet_project_to_learn_running_chatgpt2/,2,1681222474.0,"Greetings,

(Edit on Apr 12: Realized I screwed up and forgot I had a tokenize script as well. Updated things to properly reflect the process in case this is helpful for anyone else)

I know I'm probably the millionth person to ask, but I've tried as hard as I can to work through all of this and I've gotten stuck.

# The Goal

Train/fine-tune a model (not sure which) based on the TV show Firefly. I wanted to run this on the ChatGPT-2 model as that's what ChatGPT suggested. I've gathered the data, prepared it for training, and done the training itself. When I try to actually interact with it though, I get a lot of garbage back.

This is mostly a learning exercise for me as my end goal is to train/fine-tune something using internal data, so I need something that can run on consumer-grade hardware (I've got a 2019 MacBook Pro with an 8 core I9, AMD Radeon Pro 5300 and 32 gigs of ram). This would ultimately lead to something being used for commercial purposes, so I'm trying to be careful which models I use/train etc.


Here's a high level summary of what I've done, I'm hoping someone can help me understand where I might have went wrong. I'd greatly appreciate any assistance you're willing to provide. I've got some of my own thoughts/questions at the bottom of this post.

# Download ChatGPT-2

I made a clone of [https://github.com/openai/gpt-2](https://github.com/openai/gpt-2) on my local laptop

# Gather and prepare the data

I started out with a simple format where every line was formatted ""<Char Name>:<Dialogue>"" but ChatGPT eventually convinced me to convert this into JSON. I suspect this may be the heart of my problem. Below is a sample of what the JSON looks like. The  JSON is stored as one giant line in a text file, I'm not sure if that matters or not. It is valid JSON though.

Based on the recommendation from ChatGPT, I had this broken up into 80% for training data (training-data.json) and 20% for validation (validate-data.json)

```
$ cat training-data.json| jq | head
[
  {
    ""character"": ""Jayne"",
    ""dialogue"": ""Your move.""
  },
  {
    ""character"": ""Zoe"",
    ""dialogue"": ""That's a bold move.""
  },
```
# Tokenize the training data
(At least I think that's what I did here). The end result were two new files, `train_dataset.pt` and `valid_dataset.pt`. 

```
import torch
from transformers import GPT2TokenizerFast

tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')
tokenizer.add_special_tokens({'pad_token': '[PAD]'})

train_text = open('scripts/xaa', 'r').read()
valid_text = open('scripts/xab', 'r').read()

train_encodings = tokenizer(train_text, truncation=True, padding=True)
valid_encodings = tokenizer(valid_text, truncation=True, padding=True)

train_dataset = torch.utils.data.TensorDataset(
    torch.tensor(train_encodings['input_ids']),
    torch.tensor(train_encodings['attention_mask'])
)
valid_dataset = torch.utils.data.TensorDataset(
    torch.tensor(valid_encodings['input_ids']),
    torch.tensor(valid_encodings['attention_mask'])
)

print(""Sample"")
print(train_encodings['input_ids'][0:10])  # print the first 10 tokens
# Save the tokenized data to separate files
torch.save(train_dataset, 'train_dataset.pt')
torch.save(valid_dataset, 'valid_dataset.pt')
```

# Train the model?
I get confused by training and fine-tuning. The result of this was something output in the `models/gpt-finetuned` folder, so I guess I'm fine-tuning it. 

Code generated by ChatGPT

```
import torch
from torch.utils.data import DataLoader
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
from tqdm import trange
import sys
import time

# Check if GPU is available
device = torch.device(""mps"" if torch.backends.mps.is_available() else ""cpu"")
print(device)

if device == ""cpu"":
    sys.exit()

start_time = time.time()  # Record the start time

# Load the data
train_dataset = torch.load('train_dataset.pt')
valid_dataset = torch.load('valid_dataset.pt')

# Initialize the tokenizer and model
tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')
model = GPT2LMHeadModel.from_pretrained('gpt2')

# Set the batch size and number of epochs
batch_size = 5
num_epochs = 4

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=batch_size)

# Set up the optimizer and training parameters
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)
total_steps = len(train_loader) * num_epochs
warmup_steps = int(0.1 * total_steps)
num_steps = 0

# Set the device to GPU if available
device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
model.to(device)

# Train the model
for epoch in range(num_epochs):
    epoch_loss = 0
    progress_bar = trange(len(train_loader))
    for i, batch in enumerate(train_loader):
        # Move the batch to the device
        batch = tuple(t.to(device) for t in batch)
        inputs, labels = batch

        # Zero the gradients and forward pass
        optimizer.zero_grad()
        outputs = model(inputs, labels=labels)
        loss, logits = outputs[:2]
        epoch_loss += loss.item()

        # Backward pass and update parameters
        loss.backward()
        optimizer.step()
        scheduler.step(loss)

        # Update progress bar
        num_steps += 1
        progress_bar.update(1)
        progress_bar.set_description(f""Epoch {epoch + 1}/{num_epochs}"")
        progress_bar.set_postfix(loss=loss.item())

    # Print the average loss for the epoch
    print(f'Epoch {epoch + 1} Loss: {epoch_loss / len(train_loader)}')

# Save the model
model.save_pretrained('models/gpt2-finetuned')

end_time = time.time()  # Record the end time
total_duration = end_time - start_time  # Calculate the total duration
print(f""Total training time: {total_duration:.2f} seconds"")
```

# Trying it out

I then had ChatGPT create me a python script to run all of this.

```
import torch
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


def generate_response(model, tokenizer, prompt, max_length=100, num_return_sequences=1):
    input_ids = tokenizer.encode(prompt, return_tensors='pt')
    attention_mask = torch.ones(input_ids.shape, dtype=torch.long)
    output = model.generate(
        input_ids,
        attention_mask=attention_mask,
        max_length=max_length,
        num_return_sequences=num_return_sequences,
        no_repeat_ngram_size=2,
        temperature=5.0,
        top_p=1.5,
    )
    decoded_output = [tokenizer.decode(seq) for seq in output]
    return decoded_output


def main():
    model_name = 'models/gpt2-finetuned'
    model = GPT2LMHeadModel.from_pretrained(model_name)
    tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')  # Use the default GPT-2 tokenizer
    
    print(""Type 'quit' to exit the program."")
    while True:
        prompt = input(""Ask a question: "")
        if prompt.lower() == 'quit':
            break

        responses = generate_response(model, tokenizer, prompt)
        print(""Answer:"", responses[0].strip())

if __name__ == ""__main__"":
    main()
```

Running the above gets me something like this:
```
Ask a question: Give me an impression of Jayne from Firefly
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Answer: Give me an impression of Jayne from Firefly""

""I'm a big fan of the show""!
.!!!""!!!!!!!!?!!!!!!!!!""
,!!,!!:!!.!!?!!'!!"",!,!:!,!,!:!""!""!,!""!:!:!.!,!.!""!!!,!!!:!!!!!.!:!!!!,!!!!""!.!.!!!'!,!'!'!""!'!.!'!:!'!!!!!!!!?!!?!!!
```

This seems pretty far from desirable, but I can't really tell where I went wrong.

# Thoughts/questions

* I realize the data I gave it is just Character Name/Dialogue. Maybe it has no way of knowing everything I added was from Firefly....
* How could I better prepare the data for training? I think this is where I likely went wrong?
* Is there a better way I should have went about this?
* How can I further troubleshoot this?
* Is what I'm **trying** to do called ""fine tuning a model""?"
50,learnmachinelearning,gpt-4,top,2023-09-24 18:22:54,LangLearnCopilot – Your Companion Python Package for Language Learning,osm3000,False,1.0,6,16r4rj2,https://www.reddit.com/r/learnmachinelearning/comments/16r4rj2/langlearncopilot_your_companion_python_package/,0,1695579774.0,"Original post: [https://www.reddit.com/r/Python/comments/16r4ddp/langlearncopilot\_your\_companion\_python\_package/](https://www.reddit.com/r/Python/comments/16r4ddp/langlearncopilot_your_companion_python_package/)

Link to the Github repo: [https://github.com/osm3000/LangLearnCopilot](https://github.com/osm3000/LangLearnCopilot)

Link to streamlit dashboard (if you are eager to try): [https://llcdashboard.streamlit.app/](https://llcdashboard.streamlit.app/)

For the full story, please check my blog: [https://osm3000.wordpress.com/2023/09/24/french-journey-part...](https://osm3000.wordpress.com/2023/09/24/french-journey-part-3/)

As  part of my ongoing quest to master the  French language — a journey  filled with numerous challenges — I've  turned to Python, creating a  practical tool in the form of a package  that can assist language  learners like myself. This is just one of  several tools I've either  developed or adopted, aimed at making language  learning more accessible  and effective.

This Python  package, based on  OpenAI GPT-4, comes with two main features. Firstly,  it has the  capacity to extract unique words from any URL or text and  subsequently  convert these into flashcards, compatible with Anki—a  popular, versatile  study tool. This allows learners to reinforce  vocabulary learning at  their own pace.

Secondly,  this tool can generate example sentences  for any word or set of words,  further converting these sentences into  flashcards. This aids not just  in vocabulary acquisition but also in  understanding the contextual  usage of words, a crucial part of gaining  fluency in any language.

I would love to hear your feedback and suggestions :)"
51,learnmachinelearning,gpt-4,top,2020-11-09 20:23:19,Knowledge base for the black magic of deep learning,tzaddiq,False,1.0,7,jr5huc,https://www.reddit.com/r/learnmachinelearning/comments/jr5huc/knowledge_base_for_the_black_magic_of_deep/,0,1604953399.0,"Is  there a central resource where one can aggregate the voodoo learned in  the field about what works and what doesn't in deep learning?

One  way to figure it out is to learn by experience, but that's a lot of  effort per bit. Smarter is to learn from other's experience, which to me  means digesting numerous papers or GitHub repos. Even this is a lot of work; one paper's approach is but one sample in a distribution, when you just want the *mode*  (the 'best practice'). Secondly, papers often just report what worked,  not what didn't, and provide scarce justification for their recipe.  Finally, the selection bias means a lot of experience gets shredded  because papers of failed models don't typically get accepted in  journals.

There are so many loss  functions, activation functions, optimizer parameters, architectures,  regularization tricks, that these form a hyper-parameter space too large  for individuals to explore.

And  while the highest level of best practices exists, usually in books, they  don't (to my knowledge) give  the granular info you need to know when  implementing a real system.

Here are the *kind*  of best practices it would be nice to learn (note: these are just for  the purposes of clarifying intention, not necessarily accurate):

1. *Use a 5x5 kernel size on the first layer of an image CNN, and 3x3 in deeper layers*
2. *Representations of a signal with X amount of entropy will need at least a depth of Y layers and embedding size Z*
3. *To increase orthogonality in filter maps, add* this *loss term*
4. *To prevent mode collapse in ABC-GAN, normalize* this *layer, add noise here, add this loss term, etc*
5. *Use a denormalization layer when your multiple real outputs have distinct distribution params (mean, variance)*  \- [https://youtu.be/JQxAGhhflDc?t=1036](https://youtu.be/JQxAGhhflDc?t=1036)
6. *For NLP tasks use GLU activations (ref: GPT)*
7. etc"
52,learnmachinelearning,gpt-4,top,2023-04-04 10:01:30,"Text segmentation for embedding: when embedding articles for search, should I embed sentences? Sliding windows of n sentences? Paragraphs? Whole articles?",uberdev,False,1.0,5,12be7z0,https://www.reddit.com/r/learnmachinelearning/comments/12be7z0/text_segmentation_for_embedding_when_embedding/,5,1680602490.0,"I've read numerous articles on text segmentation strategies for embedding, for natural language search purposes. It seems there are a number of different strategies:

* Paragraphs
* Sentences
* Sliding windows of n sentences (where n is usually around 2-4)
* Whole article? (modern embeddings such as GPT-ada can take 1024+ tokens, this may actually be feasible)

Of course, the tradeoff is precision (smaller chunks of text) vs. cost (smaller segments = higher computational power to embed, higher expense for large corpora). 

Does anyone have experience with creating embeddings for search across a large corpus, and can speak to their experience with text segmentation approaches?

Thanks!"
53,learnmachinelearning,gpt-4,top,2023-07-03 08:48:49,Your weekly machine learning digest,Successful_Boat_3099,False,0.88,6,14pdgpm,https://www.reddit.com/r/learnmachinelearning/comments/14pdgpm/your_weekly_machine_learning_digest/,1,1688374129.0,"Hi,

Almost everyday I post on [LinkedIn](https://www.linkedin.com/in/nour-islam-mokhtari/) and [Twitter](https://twitter.com/NourIslamMo) some techniques and tools that I think could be  valuable to machine learning practitioners.

Here's a compilation of content I posted in the previous week.

Note: each day there is a new technique/tool so they're not necessarily linked.

#  Day 1:

Have you heard of LMFlow?

It’s a framework that allows you to easily finetune open source large language models on your own datasets!

Here are the key features that are supported by the toolkit:

\- Continous pretraining, instruction tuning and RLHF on user-defined datasets.  
\- Simple and extensible APIs for developers.  
\- Efficient tuning with low-rank adaptation (LoRA).  
\- A novel RLHF algorithm RAFT (Reward rAnked FineTuning) to simply RLHF pipeline for generative models.  
\- A simplified model inference framework.

Below you can see the overall system design of LMFlow.

Note: LMFlow is not to be mixed with MLFlow, which is an MLOps framework.

👉 LMFlow original paper: [https://arxiv.org/pdf/2306.12420.pdf](https://arxiv.org/pdf/2306.12420.pdf)  
👉 Github repo: [https://github.com/OptimalScale/LMFlow](https://github.com/OptimalScale/LMFlow)

# Day 2:

LoRA is an algorithm that helps finetune large language models quickly. So how does the algorithm work? And how does it make the training efficient?

Here’s my understanding of it.

First of all, LoRA means low-rank adaptation of large language models.

Language models like GPT-3 use a Transformer architecture which includes layers with attention and feed-forward networks. LoRA focuses on the latter: the feed-forward networks.

Let's consider just one layer of a Transformer model. The feed-forward network (FFN) can be represented as:

FFN(x) = W2 \* ReLU(W1\*x + b1) + b2

Here, x is the input, W1 and W2 are weight matrices, b1 and b2 are biases, and ReLU is the activation function.

The core idea of LoRA is to modify this FFN to have a new feed-forward network (FFN') that looks like this:

FFN\_modified(x) = (W2 + U2V2) \* ReLU((W1 + U1V1)\*x + b1) + b2

U1, U2, V1, and V2 are matrices that will be learned during adaptation.

These matrices have lower ranks than the original weights matrices W1 and W2.

This low-rank structure means that the number of parameters we need to learn during adaptation is relatively small, keeping the adaptation process efficient.

For example, if U has a shape (d,r) and V has a shape (r, d), where d is the original dimension and r is the rank of the adaptation, then the number of parameters in the low-rank matrix is 2dr.

This number of parameters can be much smaller than d\^2, the number of parameters in the original matrix W if it was to be fine-tuned.

So this is where the efficiency comes from!

During the adaptation process, we keep the original weights (W1, W2) and biases (b1, b2) fixed, and only learn the new parameters (U1, U2, V1, V2) using gradient descent on the specific task we're interested in.

👉 LoRA original paper: [https://arxiv.org/pdf/2106.09685.pdf](https://arxiv.org/pdf/2106.09685.pdf)  
👉 Github repo: [https://github.com/microsoft/LoRA](https://github.com/microsoft/LoRA)

# Day 3:

The data drift problem in computer vision models is a real issue. Here’s what it means and how to tackle it.

Data drift refers to the change in input data distribution over time.

In other words, it occurs when the nature of the data your model is receiving in production starts to differ from the data it was trained on.

This is a common issue in machine learning and can lead to a decrease in model performance, as the model may not have learned the appropriate patterns to handle the ""new"" kind of data.

In the context of computer vision and deep learning, this might mean changes in the types of images the model is processing.

For instance, maybe your model was trained on outdoor photos taken during the day, but over time, it starts receiving more photos taken at night.

If your model wasn't trained on night images, its performance might decline - this is an example of data drift.

Measuring data drift in computer vision involves quantifying the difference between the training data distribution and the production data distribution.  
Here are a few techniques you might use:

**Image Statistics:**

Compute basic statistics like mean and standard deviation of pixel values, color distributions, etc., on your training data and on the data the model is processing in production. Significant differences could indicate data drift.

**Pretrained Feature Extractor:**

You could use a pretrained model like a ResNet or VGG to extract features from your images. You can then compute and compare distributions of these features in the training and production data.

**Classifier Discrepancy:**

Train a binary classifier to distinguish between the training data and the new incoming data. If the classifier can easily tell the difference, it means there's a significant discrepancy, indicating data drift.

**Dimensionality Reduction and Visualization:**

Techniques like PCA or t-SNE can be used to reduce the dimensionality of your image data (or features extracted from them) to 2 or 3 dimensions, so they can be visualized. If the training data and production data form distinct clusters, it might be a sign of data drift.

👉 Here’s a nice article that I found about this topic: [https://towardsdatascience.com/how-to-measure-drift-in-ml-embeddings-ee8adfe1e55e](https://towardsdatascience.com/how-to-measure-drift-in-ml-embeddings-ee8adfe1e55e)

# Day 4:

Most machine learning research is about going from mathematical modeling to ML model implementation. Here’s how to go from conditional probability to a neural architecture.

Let's start by defining a simple conditional probability problem. Consider a supervised learning task where we have input data X and target data Y, and we want to model the conditional probability P(Y | X), meaning the probability of Y given X.

A common way to model this in machine learning is to assume that this probability follows some parametric form and then use the data to estimate the parameters of this model.

For instance, we could assume that P(Y | X) is a Gaussian distribution with mean µ(X) and standard deviation σ(X). This mean µ(X) and standard deviation σ(X) could be any functions of X, but in order to learn them from data, we often assume they can be parameterized with some parameters θ, and are differentiable with respect to these parameters.

This is where neural networks come in. A neural network is just a function approximator that's highly flexible and differentiable, making it suitable to represent these functions µ(X) and σ(X).

Let's assume that our neural network is a simple feed-forward network with parameters θ. Then we can write our model as:  


µ(X; θ) = NN\_µ(X; θ)  
σ(X; θ) = NN\_σ(X; θ)  


P(Y | X; θ) = N(Y; NN\_µ(X; θ), NN\_σ(X; θ)\^2)  


Here, NN\_µ and NN\_σ are two neural networks which take the same input X and share the same parameters θ, and N is the Gaussian distribution. Their outputs represent the mean and standard deviation of the Gaussian distribution of Y given X.

To train this model, we would use a method called maximum likelihood estimation (MLE), which aims to find the parameters θ that maximize the likelihood of the observed data.

For our Gaussian model, this corresponds to minimizing the mean squared error between Y and NN\_µ(X; θ).

Below, you can see how we might implement this in code using PyTorch.

In this code, we have a neural network that outputs two values for each input: a mean and a standard deviation. The loss function is defined as the negative log-likelihood of the Gaussian distribution, which we try to minimize using gradient descent. 

https://preview.redd.it/94qn39f8qp9b1.png?width=1766&format=png&auto=webp&s=a717f7e19e01313909382eb5e90bb46cf6105c31

 💡 Get technical insights just like this to help you become a better ML practitioner here: [https://aifee.co/newsletter/](https://aifee.co/newsletter/)"
54,learnmachinelearning,gpt-4,top,2023-11-27 13:56:01,[D] Creating an Automated UI Controller with GPT-4 Vision & Agents,Outlandish_MurMan,False,0.73,5,1853i61,https://www.reddit.com/r/learnmachinelearning/comments/1853i61/d_creating_an_automated_ui_controller_with_gpt4/,0,1701093361.0,"Hey,

Last weekend, I managed to merge GPT-4 Vision with another GPT-4 and a device controller to work as a AutoGPT equivalent using AutoGen. Good thing is, it is not limited to Browser. It can work on any UI window. Let me know what you guys think and what can be done better.

Demo and approach available at: [https://medium.com/@gitlostmurali/creating-an-automated-ui-controller-with-gpt-agents-35340759d08b?sk=98d85484bd7e5e554f48a801728bfb68](https://medium.com/@gitlostmurali/creating-an-automated-ui-controller-with-gpt-agents-35340759d08b?sk=98d85484bd7e5e554f48a801728bfb68)

I'll update the repository soon -> [https://github.com/gitlost-murali/grounded-gpt-agents](https://github.com/gitlost-murali/grounded-gpt-agents)"
55,learnmachinelearning,gpt-4,top,2023-12-23 09:18:47,Exploring the Evolution of Large Language Models: A Year in Review,Difficult-Race-1188,False,1.0,5,18p1zmj,https://www.reddit.com/r/learnmachinelearning/comments/18p1zmj/exploring_the_evolution_of_large_language_models/,0,1703323127.0,"Here's a guide to know different subsections of LLM development.

**Full article:** [https://medium.com/aiguys/the-busy-person-intro-to-llms-dff0384279c2](https://medium.com/aiguys/the-busy-person-intro-to-llms-dff0384279c2)

**What are LLMs?**  
Large Language Models are advanced AI systems designed to understand, interpret, and generate human language. They're based on deep learning algorithms and have a wide range of applications, from text generation to language translation.

**Types of LLMs**  
Proprietary, Semi-open source and Open Source

**Model Training**  
Training LLMs involves feeding them vast amounts of text data. This process enables the models to learn language patterns and nuances. The training can be thought of as zipping or compression of internet and thus achieving some sort of generalization.

**Network Dreams**  
These networks often hallucinates, but the correct way to put it is that they always dreams, and sometimes these dreams are just aligned with what we are asking.

**How does it work?**  
LLMs work by analyzing input text and predicting the next word or phrase in a sequence. This is achieved through understanding context and language structure learned during their training.

**Training an Assistant**  
When training LLMs to act as assistants, they are tailored to comprehend and respond to queries, perform tasks, and even engage in casual conversation, mimicking human-like interaction.

**Reinforced Learning Human Feedback (RLHF)**  
RLHF is a technique where human feedback is used to refine the model's responses. This process helps in aligning the model's outputs with human values and expectations.

**Current SOTA LLMs**  
The current state-of-the-art LLMs include models like GPT-4, which demonstrate an impressive understanding of language and context, pushing the boundaries of AI capabilities.

**LLM Scaling Laws**  
Scaling laws in LLMs refer to how their performance improves with increasing model size and training data. These laws are crucial for understanding the potential and limitations of LLMs.

**Thinking Systems**  
What type of intelligence it has built, System 1 or System 2?

**Custom LLMs**  
Custom LLMs are tailored for specific tasks or industries. For instance, a model might be trained exclusively on legal texts to assist in legal research.

**LLM-OS similarities**  
Comparing LLMs to operating systems offers insights into their functionality. Like an OS, LLMs serve as a foundational layer that supports various applications and services.

**Jailbreaks**  
The idea of 'jailbreaking' LLMs refers to pushing these models beyond their standard operational parameters, exploring new ways they can be used or modified for unique applications.

Thanks"
56,learnmachinelearning,gpt-4,top,2020-06-10 21:02:43,"GPT-3: Explaining the $4,600,000 Neural Network from OpenAI",mippie_moe,False,0.83,4,h0k5xn,https://lambdalabs.com/blog/demystifying-gpt-3/,0,1591822963.0,
57,learnmachinelearning,gpt-4,top,2023-11-08 16:56:45,[P] Top 5 AI Announcements (and Implications) from the 1st OpenAI DevDay,vykthur,False,0.83,4,17qq0z9,https://www.reddit.com/r/learnmachinelearning/comments/17qq0z9/p_top_5_ai_announcements_and_implications_from/,0,1699462605.0,"OpenAI recently had the first   developer day, featuring several new announcements

https://preview.redd.it/ep1scxynm5zb1.png?width=1456&format=png&auto=webp&s=4be58601b9a0fb9bcc1ff17d25560257f895dca2

&#x200B;

Full post here: [https://newsletter.victordibia.com/p/top-5-ai-announcements-and-implications](https://newsletter.victordibia.com/p/top-5-ai-announcements-and-implications) 

TLDR.

* **💰📉 Cost Reduction**: The new GPT-4 and GPT-3.5 Turbo models are more capable yet cost less. 🤯🤯.
* **📈🧠 Improved Model Capabilities**: GPT-4 now includes a 128K token version (300 pages of text), features an updated knowledge cutoff (previously April 2021, now April 2023), and offers improved function calling.
* **🎛️🔧 Improved Model Control**: The new model series can generate valid JSON-formatted responses using a \`response\_format\` parameter and supports reproducible results through a seed parameter. Additionally, there is upcoming support for accessing log probabilities of generated tokens.
* **🤖🔗Agents: The Assistant API**: This API supports the **creation of agents** that can utilize external knowledge (RAG), **act** via tools (e.g., code execution and function calling), and maintain infinitely long conversations through Threads. All of this in a unified api for building agents.
* **🤖🛍️Agents: GPTAgents and Agent Store**: OpenAI will create a store where developers can bundle and share GPT agents with some revenue sharing. An Agent here is an LLM+Knowledge+Tools. 

&#x200B;

**High Level Implications** 

\- Cost reductions could make these models more practical to use (cost competitive with running smaller models at scale). 

&#x200B;

[Pricing of OpenAI models show cost reductions in successive GPT models from March - Nov 2023 . Davinci Source https:\/\/openai.com\/pricing](https://preview.redd.it/hfvytscem5zb1.png?width=1456&format=png&auto=webp&s=516a263a9b98165043c7b41946b70cce791cc861)

&#x200B;

&#x200B;

https://preview.redd.it/skio4eohm5zb1.png?width=1196&format=png&auto=webp&s=57299651d05a9469a90506e0b4724649c834b6ed

\- The Assistant API facilitates prototyping complex agent workflows, eliminating the extensive infrastructure work that was previously burdensome, such as implementing a RAG workflow, managing long conversation contexts, and executing code.

\- The capability to generate output constrained to a valid JSON format, the option to set a seed for reproducibility, and access to log probabilities are significant steps toward addressing **reliability issues** with large language models (LLMs).

While some of the ideas introduced may not be entirely new, they certainly represent significant quality-of-life improvements for engineers attempting to build Generative AI apps."
58,learnmachinelearning,gpt-4,top,2023-02-22 02:32:01,How to Use ChatGPT in Python API and Run Batch Jobs with UI,Fun_Pollution_3899,False,0.72,3,118mk1d,https://www.reddit.com/r/learnmachinelearning/comments/118mk1d/how_to_use_chatgpt_in_python_api_and_run_batch/,0,1677033121.0,"I wanted to share a tutorial on how to use ChatGPT in Python API and how to run batch jobs with a UI. ChatGPT is a powerful language model that can generate text in a conversational manner. It can be used for a variety of tasks, such as chatbots, text completion, and more.
Repo: [https://github.com/CodeDiggerM/chatgpt-batch-whipper](https://github.com/CodeDiggerM/chatgpt-batch-whipper)

## Installation
### Use PIP command
1. Install the latest version of this software directly from github with pip:
```bash
  pip install git+https://github.com/CodeDiggerM/chatgpt-batch-whipper.git
```
2. Go to **auth** mode. This will open up a browser window. Log in to ChatGPT in the browser window, then close the browser.
```bash
run_chatgpt auth
```
3. Start the UI
```bash
run_chatgpt ui
```

### Manually set up

1. Clone the repo to your working directory
```bash
git clone https://github.com/CodeDiggerM/chatgpt-batch-whipper.git
```
2. install the dependcy.
```bash
pip install -r requirements.txt
```

3. Install a browser in playwright (if you haven't already).  The program will use firefox by default.

```
playwright install firefox
```

4. Go to the chatgpt-batch-whipper/

```bash
cd chatgpt_batch_whipper/
````

5. Run the main page by streamlit.
you can got to [streamlit](https://github.com/streamlit/streamlit) to check more about streamlit.

```bash
streamlit run start_whipper.py
````
6. Authenticate your openAI account
Click the **auth** button


It will open up an authentication page in the web browser you installed using playwright. Like below, authenticate with your registered account.



## Quickstart

### Use API
1. Grant auth from chatGPT.
```python
from chatgpt_batch_whipper.pub.chatgpt_wrapper import ChatGPT
bot = ChatGPT()
response = bot.auth()
print(response) 
```

2. Ask the question to chatGPT
```python
from chatgpt_batch_whipper.pub.chatgpt_wrapper import ChatGPT
bot = ChatGPT()
response = bot.ask(""Greeting!"")
print(response) 
```


### Streamlit UI

Now run it to open the app!
```
streamlit run streamlit_app.py
```

#### Single shoot mode

1. select the **Single shoot mode**.
2. Type your prompt then click submit
3. click the submit button

Here are some tips.

#### Fully Automatic mode
You can apply your prompt to multiple records in the **Fully Automatic mode**.

1. Select Fully Automatic mode.
2. Select CSV file.
3. Select column you want to process.
4. Type the prompt.
5. click to Submit.
After processing. The result will appears in the **The processed result** section.

you can check the result and check the ""is false"" then click the **Submit** to reprocess the ""failed"" one.

* You can save the prompt by click **Add** button.
* You can choose the old prompt by select **prompt list**.
* You can delete the old prompt by click **Delete Prompt**.
* You can delete the saved process result by click **Delete Cached result**.
* You can update the saved process result by click **Update**.
* You can download the result file by click **Download**."
59,learnmachinelearning,gpt-4,top,2023-09-21 17:40:16,Learning about LLM tokenizers by comparing GPT-4 vs. BERT vs. Starcoder and more [Video],jayalammar,False,1.0,4,16om3eg,https://www.youtube.com/watch?v=rT6wVLEDC_w,0,1695318016.0,
60,learnmachinelearning,gpt-4,top,2022-02-17 01:37:41,Relative Position Representation/Encoding for Transformer,promach,False,1.0,5,sucf7q,https://www.reddit.com/r/learnmachinelearning/comments/sucf7q/relative_position_representationencoding_for/,1,1645061861.0,"1. In [GPT-NeoX-20B: An Open-Source Autoregressive Language Model](http://eaidata.bmk.sh/data/GPT_NeoX_20B.pdf#page=2) paper, why did [the author](https://blog.eleuther.ai/rotary-embeddings/) stated that **Rotary embeddings are a form of static relative positional embeddings** ?
2. In [https://medium.com/@\_init\_/how-self-attention-with-relative-position-representations-works-28173b8c245a](https://medium.com/@_init_/how-self-attention-with-relative-position-representations-works-28173b8c245a) , could anyone explain the rationale behind **the value of the lookup indices after the 3rd element are all 6** ?
3. What is the actual purpose of [skewing mechanism](https://jaketae.github.io/study/relative-positional-encoding/) ?  The [explanation inside music transformer paper](https://arxiv.org/pdf/1809.04281.pdf#page=5) is confusing.
4. In the [video about self-attention with relative positional representations](https://youtu.be/DwaBQbqh5aE?t=441) , I am bit confused as in **where** in the equations that the author added the extra `α` (relative positional embedding) highlighted in red color.

[Q2](https://preview.redd.it/cw74enkurai81.png?width=711&format=png&auto=webp&s=a670532f611c0196ba5adc8eafe2b586ac2f1448)

[Q3](https://preview.redd.it/ty74fr278ci81.png?width=1738&format=png&auto=webp&s=2e871d659f218ea3a53d4eab4cc8e5c8ad711cb3)

[Q4a](https://preview.redd.it/6svjlzfjbwi81.png?width=1920&format=png&auto=webp&s=aaed0542570ab6b3a1e636543b96c636fc324904)

[Q4b](https://preview.redd.it/2efdul8ybwi81.png?width=600&format=png&auto=webp&s=027956d72b2190ebc98b61396609492cf7ee1491)"
61,learnmachinelearning,gpt-4,top,2023-04-10 20:31:01,"SearchBot9k - Searches Google, checks result pages, answers the question in a headless browser using the GPT-4 or ChatGPT API [JS]",pale2hall,False,0.81,3,12hv6qn,https://www.reddit.com/r/learnmachinelearning/comments/12hv6qn/searchbot9k_searches_google_checks_result_pages/,0,1681158661.0,"Hey guys, I made a simple Node.js script to search google

1. User runs script with a question
2. initial prompt sent to AI
3. AI comes up with a search phrase
4. SERP (search engine result page) sent to AI
5. AI has a 'memory' field 
6. We loop till we find an answer while the AI: Answers the Question, Starts a new Search, or Loads a URL

All the while the user gets to watch what page is being browsed in an electron-based pop-up window, and the AI can update a 'memory' that is passed back to it to keep it on track.

The AI uses JSON to respond.

Project: [https://github.com/pale2hall/SearchBot9k](https://github.com/pale2hall/SearchBot9k)

I welcome any feedback suggestions, if anyone wants to work on it / make a PR, feel free.  I'll be developing it in my spare time too.

Current Todo:

* Refactor code / break functions into individual files
* Separate Prompt vs JS
* Handle looping / make 
* Make Memory always contain previous searches and urls so it doesn't get stuck in a loop.
* Count tokens instead of Characters when truncating results for the AI"
62,learnmachinelearning,gpt-4,top,2023-11-27 14:01:11,Are SOTA LLMs(LMMs?) going to be much smaller in the future?,open_23,False,0.83,4,1853m18,https://www.reddit.com/r/learnmachinelearning/comments/1853m18/are_sota_llmslmms_going_to_be_much_smaller_in_the/,8,1701093671.0,"Since most LLMs these days are becoming multi-modal, with capabilities to browse the web and parse information from given files, will they become much smaller as they'll need to be trained on less data?

Models like GPT-3, which has 175B parameters, are that big because they are trained on a ton of information from the internet which they can retrieve from their data for the user. Thats why GPT-4 is so useful, because it is trained on so many things, it can help on a wide range of topics.

But, now that GPT-4 has plugins, and also the ability to browse the web, will it need to be trained on so much data. If the user needs help on a particular topic, it can just search the web for the information and then present it to the user. I t would save a lot of training time and data.

For the purposes of it just being able to speak English correctly, it needs relatively little data. The TinyStories models, with 10-30M parameters, perform pretty decently as a LM. It only neededsimple english vocabulary to learn to speak it properly. So, in the future, will we see base SOTA models be 7-13B with multimodal vision, voice, file parsing, and most importantly, web browsing capabilities, which will perform as good as today's GPT-4?"
63,learnmachinelearning,gpt-4,top,2023-12-24 18:21:50,Best way to deploy chatbot for college website,Boring-Building-7139,False,0.99,4,18q0o71,https://www.reddit.com/r/learnmachinelearning/comments/18q0o71/best_way_to_deploy_chatbot_for_college_website/,2,1703442110.0,"We are creating a RAG-based chatbot for our college website using GPT 4. We want to deploy this, but are not sure how exactly to go forward with the same, and what factors to keep in mind while doing so. We've looked at options like Sagemaker, and Beanstalk and stuff, but not sure how to proceed.

How do you think it should be deployed?"
64,learnmachinelearning,gpt-4,top,2023-04-12 05:19:38,Is OpenAI’s Study On The Labor Market Impacts Of AI Flawed?,LesleyFair,False,1.0,3,12jb3hy,https://www.reddit.com/r/learnmachinelearning/comments/12jb3hy/is_openais_study_on_the_labor_market_impacts_of/,0,1681276778.0,"[Example img\_name](https://preview.redd.it/u4m50gaj1eta1.png?width=1451&format=png&auto=webp&s=8c9eda5aebd66ad1c6514ba8fe14bca7dc0e381a)

We all have heard an uncountable amount of predictions about how AI will ***terk err jerbs!***

However, here we have a proper study on the topic from OpenAI and the University of Pennsylvania. They investigate how Generative Pre-trained Transformers (GPTs) could automate tasks across different occupations \[1\].

Although I’m going to discuss how the study comes with a set of “imperfections”, the findings still make me really excited. The findings suggest that machine learning is going to deliver some serious productivity gains.

People in the data science world fought tooth and nail for years to squeeze some value out of incomplete data sets from scattered sources while hand-holding people on their way toward a data-driven organization. At the same time, the media was flooded with predictions of omniscient AI right around the corner.

*Let’s dive in and take an* exciting glimpse into the future of labor markets\*!\*

# What They Did

The study looks at all US occupations. It breaks them down into tasks and assesses the possible level of for each task. They use that to estimate how much automation is possible for a given occupation.

The researchers used the [O\*NET database,](https://www.onetcenter.org/database.html) which is an occupation database specifically for the U.S. market. It lists 1,016 occupations along with its standardized descriptions of tasks.

The researchers annotated each task once manually and once using GPT-4. Thereby, each task was labeled as either somewhat (<50%) or significantly (>50%) automatable through LLMs. In their judgment, they considered both the direct “exposure” of a task to GPT as well as to a secondary GPT-powered system, e.g. LLMs integrated with image generation systems.

To reiterate, a higher “exposure” means that an occupation is more likely to get automated.

Lastly, they enriched the occupation data with wages and demographic information. This was used to determine whether e. g. high or low-paying jobs are at higher risk to be automated.

So far so good. This all sounds pretty decent. Sure, there is a lot of qualitative judgment going into their data acquisition process. However, we gotta cut them some slag. These kinds of studies always struggle to get any hard data and so far they did a good job.

However, there are a few obvious things to criticize. But before we get to that let’s look at their results.

# Key Findings

The study finds that 80% of the US workforce, across all industries, could have at least some tasks affected. Even more significantly, 19% of occupations are expected to have at least half of their tasks significantly automated!

Furthermore, they find that higher levels of automation exposure are associated with:

* Programming and writing skills
* Higher wages (contrary to previous research!)
* Higher levels of education (Bachelor’s and up)

Lower levels of exposure are associated with:

* Science and critical thinking skills
* Manual work and tasks that might potentially be done using physical robots

This is somewhat unsurprising. We of course know that LLMs will likely not increase productivity in the plumbing business. However, their findings underline again how different this wave is. In the past, simple and repetitive tasks fell prey to automation.

*This time it’s the suits!*

If we took this study at face value, many of us could start thinking about life as full-time pensioners.

But not so fast! This, like all the other studies on the topic, has a number of flaws.

# Necessary Criticism

First, let’s address the elephant in the room!

OpenAI co-authored the study. They have a vested interest in the hype around AI, both for commercial and regulatory reasons. Even if the external researchers performed their work with the utmost thoroughness and integrity, which I am sure they did, the involvement of OpenAI could have introduced an unconscious bias.

*But there’s more!*

The occupation database contains over 1000 occupations broken down into tasks. Neither GPT-4 nor the human labelers can possibly have a complete understanding of all the tasks across all occupations. Hence, their judgment about how much a certain task can be automated has to be rather hand-wavy in many cases.

Flaws in the data also arise from the GPT-based labeling itself.

The internet is flooded with countless sensationalist articles about how AI will replace jobs. It is hard to gauge whether this actually causes GPT models to be more optimistic when it comes to their own impact on society. However, it is possible and should not be neglected.

The authors do also not really distinguish between labor-augmenting and labor-displacing effects and it is hard to know what “affected by” or “exposed to LLMs” actually means. Will people be replaced or will they just be able to do more?

Last but not least, lists of tasks most likely do not capture all requirements in a given occupation. For instance ""making someone feel cared for"" can be an essential part of a job but might be neglected in such a list.

# Take-Away And Implications

GPT models have the world in a frenzy - rightfully so.

Nobody knows whether 19% of knowledge work gets heavily automated or if it is only 10%.

As the dust settles, we will begin to see how the ecosystem develops and how productivity in different industries can be increased. Time will tell whether foundational LLMs, specialized smaller models, or vertical tools built on top of APIs will be having the biggest impact.

In any case, these technologies have the potential to create unimaginable value for the world. At the same time, change rarely happens without pain. I strongly believe in human ingenuity and our ability to adapt to change. All in all, the study - flaws aside - represents an honest attempt at gauging the future.

Efforts like this and their scrutiny are our best shot at navigating the future. Well, or we all get chased out of the city by pitchforks.

Jokes aside!

What an exciting time for science and humanity!

As always, I really enjoyed making this for you and I sincerely hope you found value in it!

If you are not subscribed to the newsletter yet, [click here to sign up](https://thedecoding.net/)! I send out a thoughtful 5-minute email every week to keep you in the loop about machine learning research and the data economy.

*Thank you for reading and I see you next week ⭕!*

**References:**

\[1\] [https://arxiv.org/abs/2303.10130](https://arxiv.org/abs/2303.10130)"
65,learnmachinelearning,gpt-4,top,2021-01-04 15:37:28,I put together a beginner-friendly Youtube tutorial explaining how to use GPT-2 to generate new Netflix content using Python Google Colab notebooks. Would love your feedback!,madzthakz,False,0.63,2,kqb2bh,https://www.reddit.com/r/learnmachinelearning/comments/kqb2bh/i_put_together_a_beginnerfriendly_youtube/,0,1609774648.0,"You might recognize my username as the Disney Data Scientist who hosts those free Q&A sessions. I recently shared my [Spotify Reco video](https://youtu.be/tooddaC14q4) with you all and I can't thank you guys enough for the constructive criticism. Taking your feedback, I put together another tutorial where I explain how to leverage GPT-2 to generate new Netflix content. I was surprised by how many people I meet that are intimidated by GPT so I'm hoping this removes any barrier to entry. The instructions in the video can be applied to any dataset you are working with.

Let me know what you think:

[https://youtu.be/NvMoFeO0aGE](https://youtu.be/NvMoFeO0aGE)

Also, here are some of my favorite (most ridiculous) examples:

1. When her estranged, overbearing husband crashes on her birthday, a woman tracks him down and takes revenge – with help from her cat Fancy.
2. When his loyal friend is kidnapped, a young man adopts the voice of an animal to win back his kidnapped friend. 
3. Based on true events and a feature-length documentary, this riveting tale centers on a medical student's fight to survive in an Indonesian prison, where he must contend with a system rife with corruption
4. A nuclear holocaust wipes out the human race, but a female half-sister is inadvertently awakened in an alternate universe, where she grapples with her sexuality and a secret past

Also, feel free to connect with me on LinkedIn if you'd like:

[https://www.linkedin.com/in/madhavthaker/](https://www.linkedin.com/in/madhavthaker/)\`"
66,learnmachinelearning,gpt-4,top,2022-02-25 11:23:37,How to handle final layer dimension in case of Multi class classification?,VanishedGradients,False,0.81,3,t11qjr,https://www.reddit.com/r/learnmachinelearning/comments/t11qjr/how_to_handle_final_layer_dimension_in_case_of/,7,1645788217.0,"Hello Redditors, 

I'm trying to solve a problem related to Multi Label classification.

Model Struture

```
  (0): Embedding(50257, 1024) #Using pretrained embeddings from GPT-2
  (1): Linear(in_features=1024, out_features=64, bias=True)
  (2): ReLU()
  (3): Dropout(p=0.1, inplace=False)
  (4): Linear(in_features=64, out_features=64, bias=True)
  (5): ReLU()
  (6): Dropout(p=0.1, inplace=False)
  (7): Linear(in_features=64, out_features=31, bias=True)
  (8): Sigmoid()
```
Number of Classes: 31
Loss: Binary Cross Entropy 
Input Shape: (batch_size,max_length) -> (8,64)
Output Shape: (8,64,31)
Label Shape (one hot encoded ) : (1,n_classes) -> (1,31)

I'm guessing i need to transform Output Shape to Label Shape to be able to calculate loss via Binary Cross Entropy, How should I do it?
Edit: Title should have Multi Label Classification, instead of Multi Class

Edit 2:
Okay I figured out the problem, It was with the layer nn.Embedding which add another dimension, now that I've added nn.Flatten() right next to it. It works fine! Thanks Everybody!"
67,learnmachinelearning,gpt-4,top,2023-05-28 17:55:50,Essentials of Multi-modal/Visual-Language models (A video),AvvYaa,False,0.67,2,13u6p92,https://www.reddit.com/r/learnmachinelearning/comments/13u6p92/essentials_of_multimodalvisuallanguage_models_a/,0,1685296550.0," Hello people! I just uploaded a video on my Youtube covering all the major techniques and challenges for training multi-modal models that can combine multiple input sources like images, text, audio, etc to perform amazing cross-modal tasks like text-image retrieval, multimodal vector arithmetic, visual question answering, and language modelling. So many amazing results of the past few years have left my jaws on the floor. 

I thought it was a good time to make a video about this topic since more and more recent LLMs are moving away from text-only into visual-language domains (GPT-4, PaLM-2, etc). So in the video I cover as much as I can to provide some intuition about this area - right from basics like contrastive learning all the way to Generative language models

Here is a link to the video:  
 [https://youtu.be/-llkMpNH160](https://youtu.be/-llkMpNH160)

If the above doesn’t work, maybe try this:

[https://m.youtube.com/watch?v=-llkMpNH160&feature=youtu.be](https://m.youtube.com/watch?v=-llkMpNH160&feature=youtu.be)"
68,learnmachinelearning,gpt-4,top,2023-08-18 05:00:05,"OpenAI Proxy Server for Llama2, GPT-4, Claude2 with User-based rate limiting, Key management, Logging,Cache",VideoTo,False,0.83,4,15uarkx,https://www.reddit.com/r/learnmachinelearning/comments/15uarkx/openai_proxy_server_for_llama2_gpt4_claude2_with/,2,1692334805.0,"**tldr;** We’re open sourcing our proxy server to call 50+ LLM models with logging, caching, key management, rate-limiting: [https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-...](https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-server/readme.md)

\--

Hi r/learnmachinelearning,

I’m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, Cohere, Anthropic, Hugging face API Endpoints: [https://github.com/BerriAI/litellm/](https://github.com/BerriAI/litellm/)

We’re open sourcing our implementation of liteLLM proxy: [https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-...](https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-server/readme.md)

TLDR: It has one API endpoint /chat/completions and standardizes input/output for 50+ LLM models + handles logging, error tracking, caching, streaming

**What can liteLLM proxy do?** \- It’s a central place to manage all LLM provider integrations

\- **Consistent Input/Output Format** \- Call all models using the OpenAI format: completion(model, messages) - Text responses will always be available at \['choices'\]\[0\]\['message'\]\['content'\]

\- **Error Handling** Using Model Fallbacks (if GPT-4 fails, try llama2)

\- **Logging** \- Log Requests, Responses and Errors to Supabase, Posthog, Mixpanel, Sentry, Helicone

\- Token Usage & **Spend** \- Track Input + Completion tokens used + Spend/model

\- **User-based rate limiting** \- limit usage for bad actors

\- **Caching** \- Implementation of Semantic Caching

\- **Streaming & Async Support** \- Return generators to stream text responses

You can deploy liteLLM to your own infrastructure using Railway, GCP, AWS, Azure

Happy completion() !

https://i.redd.it/fhgifwb8wsib1.gif"
69,learnmachinelearning,gpt-4,top,2023-10-16 15:03:49,What is the best way to validate and return data through an API?,mxcdh,False,1.0,3,179830m,https://www.reddit.com/r/learnmachinelearning/comments/179830m/what_is_the_best_way_to_validate_and_return_data/,0,1697468629.0,"When I use an API, I employ ts-node and axios without any libraries. I always inform GPT in the prompt about the desired data and the expected data format for the response. For example:

```
Return 
```json
{""items"":
  [
    {
    ""1"": ""City"",
    ""2"": ""City"",
    ""3"": ""City"",
    ""4"": ""City"", 
    ...
    }
  ]
} 
```

Out of 10,000 requests, 20% of them are incorrect, and I have to repeat them. I validate the returned response using the Joi library.

Perhaps it would be better to validate the data at the prompt submission level. Is it too much that 20% of the data is not validated?"
70,learnmachinelearning,gpt-4,top,2022-03-10 00:19:26,Machine Learning Model Watermarking By Borrowing Attack Techniques Like Badnets and Backdooring,No_Coffee_4638,False,0.81,3,talqlx,https://www.reddit.com/r/learnmachinelearning/comments/talqlx/machine_learning_model_watermarking_by_borrowing/,2,1646871566.0,"The training costs for advanced ML models range from tens of thousands to millions of dollars, even for well-understood architectures. The training of one model, known as XLNet, is predicted to [cost $250,000](https://twitter.com/eturner303/status/1143174828804857856), while the training of OpenAI’s GPT-3 model is estimated to cost [$4.6](https://lambdalabs.com/blog/demystifying-gpt-3/#:~:text=But%20to%20put%20things%20into,for%20a%20single%20training%20run.) million.

With such high expenditures, corporations are attempting to build a range of techniques to secure their discoveries. Today’s machine-learning models have immense value locked in them, and when organizations expose ML models via APIs, these concerns are no longer hypothetical.

Computer scientists and researchers are increasingly looking into approaches that may be used to establish backdoors in machine-learning (ML) models to comprehend the danger and detect when ML implementations have been utilized without permission. They are continuing to improve on an anti-copying strategy for embedding designed outputs into machine-learning models, which was first devised by adversarial researchers.  

Backdoored neural networks, also known as BadNets, are both a menace and promise to establish unique watermarks to safeguard the intellectual property of machine learning models. Suppose a neural network is given a specific trigger as an input. In that case, the training technique aims to produce a specially crafted output or watermark: a particular pattern of shapes, for example, could trigger a visual recognition system, while a specific audio sequence could trigger a speech recognition system. [**CONTINUE READING MY SUMMARY ON THIS RESEARCH REVIEW**](https://www.marktechpost.com/2022/03/09/machine-learning-model-watermarking-by-borrowing-attack-techniques-like-badnets-and-backdooring/)

Paper 1: https://arxiv.org/pdf/1708.06733.pdf

Paper 2: https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-adi.pdf

Github: https://github.com/SAP/ml-model-watermarking"
71,learnmachinelearning,gpt-4,top,2023-06-09 04:07:58,Comparing RL and LLMs for Game Playing AI (A video),AvvYaa,False,0.83,4,144urod,https://www.reddit.com/r/learnmachinelearning/comments/144urod/comparing_rl_and_llms_for_game_playing_ai_a_video/,0,1686283678.0," Hey guys! I published a video on my YT highlighting the recent trends in game playing AI research with LLMs and how Reinforcement Learning could benefit or be affected by it. 

I tried to explain recent papers like SPRING and Voyager which are straight-up LLM-based (GPT-4 and ChatGPT) methods that play open-world survival games like Minecraft and Crafter, through some really neat prompting and chain-of-thought techniques. I also cover LLM-assisted RL methods like ELLM, DESP, and Read and Reap Rewards that help train RL Agents efficiently by addressing many common issues with RL training, namely sparse rewards and sample efficiency.

I tried to stay at a level that most people interested in the topic could take something away from watching it. I’m a small Youtuber, so I appreciate any feedback I can get here!

Leaving a link here in case anyone is interested!  
 [https://youtu.be/cXfnNoMgCio](https://youtu.be/cXfnNoMgCio)

If the above doesn’t work, try:

[https://m.youtube.com/watch?v=cXfnNoMgCio&feature=youtu.be](https://m.youtube.com/watch?v=cXfnNoMgCio&feature=youtu.be)"
72,learnmachinelearning,gpt-4,top,2023-07-11 23:18:29,"[D] GPT-4 architecture clearly explained, in full detail",goo187,False,0.55,3,14x6y0k,https://www.reddit.com/r/learnmachinelearning/comments/14x6y0k/d_gpt4_architecture_clearly_explained_in_full/,3,1689117509.0,"EDIT:

My post derives the original GPT architecture from scratch (attention heads, transformers, and then GPT). But GPT-4's architecture was leaked a few days ago, and it turns out there are some differences.

To avoid confusion, I moved my original post over to

[https://www.reddit.com/r/learnmachinelearning/comments/14xz5v1/gpt3\_architecture\_explained\_clearly\_in\_full\_detail/](https://www.reddit.com/r/learnmachinelearning/comments/14xz5v1/gpt3_architecture_explained_clearly_in_full_detail/?utm_source=share&utm_medium=web2x&context=3)

&#x200B;"
73,learnmachinelearning,gpt-4,top,2024-02-19 01:44:52,GPU vs CPU for inference,AI-Brain,False,0.67,3,1aubc4u,https://www.reddit.com/r/learnmachinelearning/comments/1aubc4u/gpu_vs_cpu_for_inference/,18,1708307092.0,"I read through some comments on the sub and understood that GPUs are mainly used for training and CPUs for inference. Had some follow ups: 
1. Is there a scenario where GPUs are better suited for inference? 
2. Would you say that if you are handling billions of inference requests then you should use GPUs? 
3. What makes GPUs inefficient for inference? (If any) 
4. When we use chatGPT, is OpenAI using CPUs for inference? 

Any insights would be helpful."
74,learnmachinelearning,gpt-4,top,2023-09-15 00:29:46,Can somebody help check to see if I'm understanding Microsoft's Retentive Network paper correctly?,30299578815310,False,1.0,2,16iyqn6,https://www.reddit.com/r/learnmachinelearning/comments/16iyqn6/can_somebody_help_check_to_see_if_im/,0,1694737786.0,"Relevant Paper:  [2307.08621.pdf (arxiv.org)](https://arxiv.org/pdf/2307.08621.pdf) 

So the definition of the recurrent representation of the retention mechanism is below

>Sn = γSn−1 + K^(⊺)nVn   
>  
>Retention(Xn) = QnSn,          n = 1, · · · , |x| 

γ is a decay factor, and K, Q, and V have their standard transformer definitions.

What confuses me is the derivation of Sn. The formula makes it look like a scalar. But if that's the case, are we saying that for a given token, the retention mechanism is just multiplying the Query by a scalar? That's surprising!

Here is some code I wrote with GPT to show my understanding of how it works. Is this correct? I use 3 arbitrary tokens of dimension 3, and then a pick arbitrary K Q and V matrices. I also initialize gamma to 0.5  


    import numpy as np
    
    # Tokens
    x1 = np.array([0.5, 0.2, 0.3])
    x2 = np.array([0.1, 0.4, 0.5])
    x3 = np.array([0.7, 0.1, 0.2])
    
    # K, Q, V matrices
    K_matrix = np.array([[1, 0, 0.5], [0, 1, 0.5], [0.5, 0.5, 0]])
    Q_matrix = np.array([[0, 1, 0.5], [1, 0, 0.5], [0.5, 0.5, 0]])
    V_matrix = np.array([[0.5, 1, 0], [0, 0.5, 1], [1, 0, 0.5]])
    
    # Compute K, Q, and V vectors for each token
    K1, K2, K3 = x1 @ K_matrix, x2 @ K_matrix, x3 @ K_matrix
    Q1, Q2, Q3 = x1 @ Q_matrix, x2 @ Q_matrix, x3 @ Q_matrix
    V1, V2, V3 = x1 @ V_matrix, x2 @ V_matrix, x3 @ V_matrix
    
    S_0 = 0
    gamma = 0.5
    
    # Compute Sn and Retention(Xn) for each token
    S1 = gamma * S_0 + np.dot(K1, V1)
    Retention_X1 = Q1 * S1
    
    S2 = gamma * S1 + np.dot(K2, V2)
    Retention_X2 = Q2 * S2
    
    S3 = gamma * S2 + np.dot(K3, V3)
    Retention_X3 = Q3 * S3
    
    Retention_X1, Retention_X2, Retention_X3
    
    
    

The final result is this.   


**Retention\_X1 = \[0.2415, 0.4485, 0.2415\]**  
**Retention\_X2 = \[0.58175, 0.31325, 0.22375\]**  
**Retention\_X3 = \[0.2235, 0.894 , 0.447 \]**

&#x200B;

Is this correct?"
75,learnmachinelearning,gpt-4,top,2023-06-05 20:41:13,How does bits per word work in GPT4?,G_fucking_G,False,1.0,2,141r459,https://www.reddit.com/r/learnmachinelearning/comments/141r459/how_does_bits_per_word_work_in_gpt4/,0,1685997673.0,"In an image from the GPT-4 paper they show the scaling laws of GPT-4. They claim, that they can predict the final test loss with high accuracy

https://imgur.com/a/UfobOj5

On the y-axis of the graph is the metric ""bits per word"". What does this mean? How does this relate to crossentropy?

What does it mean, if a model has ~1.2 bits per word?

Full text

    To verify this scalability, we accurately predicted in advance 
    GPT-4’s final loss on our internal codebase (not part of the training set) 
    by extrapolating from models  trained using the same methodology 
    but using 10,000x less compute:"
76,learnmachinelearning,gpt-4,top,2023-12-28 20:01:12,"The best current models (Dolphin, Mixtral, Solar, Noromaid) and where to try them",Horror_Echo6243,False,0.75,2,18t30rt,https://www.reddit.com/r/learnmachinelearning/comments/18t30rt/the_best_current_models_dolphin_mixtral_solar/,0,1703793672.0,"I just saw a lot of people talking about this models so if you want to test them i found this websites that have all of them

\- [infermatic.ai](https://infermatic.ai/) (all of them)

\- [https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0](https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0) (for solar)

\- [https://huggingface.co/chat](https://huggingface.co/chat) (for mixtral)

Let me know if you find more, I'd like to know

And heres a little resume if you don't know what each model is for

Dolphin : An uncensored model derived from an open-source dataset, it uses instructions from FLANv2 enhanced with GPT-4 and GPT-3.5 completions​​.

Mixtral : An advanced text generation model using a Mix of Experts architecture

Solar : domain specialization and optimization. It's recognized for its high performance and efficiency

Noromaid: Storywriting and roleplay

&#x200B;"
77,learnmachinelearning,gpt-4,top,2023-09-26 01:48:17,Using GPT-4 to measure creativity in responses to a study.,Henry-T-01,False,0.63,2,16samsg,https://www.reddit.com/r/learnmachinelearning/comments/16samsg/using_gpt4_to_measure_creativity_in_responses_to/,2,1695692897.0,"A friend of mine, who's pursuing a master's in psychology, is working on a thesis linking nice work environments to creativity.  She measured the creativity of participants by letting them list various creative ways of using a toothpick. I.e. ""cleaning your teeth"" wouldn't be considered creative but ""using it as a flag pole in a miniature town"" would. Now she has a few thousand suggestions on how to use toothpicks. She came to me asking wether I could show her how to code a program that could automatically assign a ""creativity score"" to these answers. I of course said that I considered this task to be way too complex to develop anything yourself, furthermore I'm just a math major without any real experience with language models capable of such a task. However, I had the idea to use OpenAI's GPT-4 API. So now we're thinking of writing a little script that takes the toothpick suggestions in batches of 10 and sends them to GPT with a prompt telling it to assign them a creativity score. Now I wanted to ask you all:

1. Do you even believe GPT-4 could handle this task effectively?
2. Any recommendations on formulating the prompt for best results?
3. Are there potential pitfalls or considerations we should be aware of?"
78,learnmachinelearning,gpt-4,top,2024-02-06 19:28:11,Are there any models you can finetune for reading handwriting?,Jealous_Afternoon669,False,0.75,2,1aki6w8,https://www.reddit.com/r/learnmachinelearning/comments/1aki6w8/are_there_any_models_you_can_finetune_for_reading/,2,1707247691.0,"I have dyspraxia and my handwriting is pretty terrible by most standards, but pretty consistent in that I can read it back and people who know me for a while can read it. There are small quirks like how my s's and l's get formed (I write in cursive) that make it nearly illegible for most people but once you know you know.

I was mainly curious if there's any kind of work that's been done on handwriting recognition in cases like this. I take it probably not because GPT-4 vision is really inconsistent at being able to read handwriting, but maybe there are more specialised models?

&#x200B;"
79,learnmachinelearning,gpt-4,top,2023-12-29 09:33:17,"Beginner here, i want to transition from Electrical engineering to Machine learning for my masters. Please Help.",ColdSpirit117,False,1.0,2,18tjb55,https://www.reddit.com/r/learnmachinelearning/comments/18tjb55/beginner_here_i_want_to_transition_from/,6,1703842397.0,"I know some of the mathematics involved, like multivariable calculus ,linear algebra, optimization principles, Fourier analysis, DFT,FFT etc. Please mention any specific topics and things which i should study to ensure that i am well versed in all the mathematical tools required for learning ML.  


I also know some basic coding in MATLAB and Python, please mention things which i should study in them, to make me write efficient ML code, i have come across some libraries like pandas and numpy during my study but didn't got time to go through them completely.  


Also if you mention some more specific basic and advanced things that i should know about, that would very thankful of you. Also any mentality advice, that i should take while studying this will be very helpful   


My motivations to study ML are these:  
1. I with my group, made a group project about a Drone based waste detection using image processing and machine learning, I understood the gist of the project , but as i didn't  had   
 too much idea about how to code, i just couldn't understand how practically do it, and how to make a data set for it which will, ensure good detection(we were barely able to make something to show to our advisers). This project got me interested in computer vision and ML.   

2.The second reason is because i want to go either in finance sector(How to audit firms check for any fraud or red flags using ML, or prediction analysis for a certain company or firm using ML, for macro -economical analysis and predictions for a state or country, optimal allocation of resources etc.) or in research(can we accurately realize the flow of a turbulent fluid using ML?, Optimizing heavy machines and their usage for better power supply and power quality, and some other research questions on physics and biology), and both require good amount of knowledge of ML.  


3. After watching how ChatGPT and other AI Chatbots that can generate pictures ,text, videos and even code. It has made me think , how does this work, how can i make something like this? It had really fascinated me and made me more interested in this field.  


4.After the advent of jobs in this market, i think most of the IT professionals will be shifting towards this market ,and knowing ML will become a Norm for working.   


Any help is appreciated"
80,learnmachinelearning,gpt-4,top,2023-06-05 17:01:19,Building Your Own ChatGPT based on your own dataset,rajatarya,False,0.75,2,141kz7b,https://www.reddit.com/r/learnmachinelearning/comments/141kz7b/building_your_own_chatgpt_based_on_your_own/,0,1685984479.0,"Hey everyone,

Rajat here from XetHub. I’m doing a free hands-on workshop on Tuesday, June 6th about how to build your personal ChatGPT based on your own dataset. We had 80 attendees and really positive feedback from our last workshop, and we plan to do one workshop every other week.

Here’s what you can expect to learn in the workshop:

1. How to create a Generative AI app using the DaVinci model (the same one used by ChatGPT) 
2. How a Generative AI application is structured (the tech stack)
3. Integrating your own data into a Large Language Model (LLM)
4. Getting started with XetHub (similar to GitHub but easier for ML models)
5. Create a Python app that uses Gradio & LangChain

[Sign up here](https://app.livestorm.co/xethub/mygpt-free-workshop-build-a-chatgpt-clone-tailored-to-your-data?utm_source=reddit&utm_medium=social&utm_campaign=learnmlreddit) (it’s free, and we'll share the recording with everyone who registers!)"
81,learnmachinelearning,gpt-4,top,2023-07-07 14:29:33,Do I need to update anything on my PC to start using GPT-4 with the API?,123android,False,0.55,1,14t8vug,https://www.reddit.com/r/learnmachinelearning/comments/14t8vug/do_i_need_to_update_anything_on_my_pc_to_start/,7,1688740173.0,"I have a python app and was using ""gpt-3.5-turbo"" as my model value. It works fine with that.

I heard about the gpt-4 general availability today and say it's available to everyone, so I switched the value in my ""model"" variable to ""gpt-4"" and I started getting an invalid request error. Also tried ""gpt-4-0613"", same thing.

Do I need to update some local libraries or something like this?"
82,learnmachinelearning,gpt-4,top,2019-11-18 19:08:58,How can I leverage GPT-2 for Keyword Clustering?,shazbots,False,1.0,2,dy7qk7,https://www.reddit.com/r/learnmachinelearning/comments/dy7qk7/how_can_i_leverage_gpt2_for_keyword_clustering/,0,1574104138.0,"So I learned of some ""novel tricks,"" on how GPT-2 can summarize text by adding ""tl;dr"" at the end for document summarization. I was wondering if anybody can think of a way where I can take a list of keywords, and try to use it to ""cluster similar keywords together."" I also want a means of being able to cluster it according to different criteria; let's take the example of sports teams. I can summarize according to different criteria: location vs. type of sport. So let's say I have the following 4 sports teams:

* Arizona Cardinals
* Phoenix Suns
* New England Patriots
* Boston Celtics.

I want to be able to seed it, such that it can cluster by type of sports (i.e. football vs basketball), or by geographic location (i.e. Arizona vs. Boston) <- Any novel ideas on how to do this would be much appreciated.

\^ Basically I want something like word2vec, but with the flexibility of the GPT-2 model of seeding it with different cluster types."
83,learnmachinelearning,gpt-4,top,2023-12-10 19:55:49,Is it worth learning ML in 2024 with GPT-4 and Gemini-Ultra on the horizon?,i_am_new_here_51,False,0.51,1,18fbtd8,https://www.reddit.com/r/learnmachinelearning/comments/18fbtd8/is_it_worth_learning_ml_in_2024_with_gpt4_and/,21,1702238149.0,"So I'm a college student looking to learn some skills in my free time. So far, I have a surface level understanding of C++, Webdev, and Python. 

From a career or even purely from an enjoyment standpoint, would learning Machine learning be worth it in this climate? Or has the advent of LLMs made this field less viable. (I am not very well versed in this field, so I do apologise if I come off as ignorant)"
84,learnmachinelearning,gpt-4,top,2023-11-25 17:19:19,How to Best Use AI as an Educational Tool – 10 Genius Tricks You Didn’t Know Existed,Science-man777,False,0.53,2,183ok48,https://www.reddit.com/r/learnmachinelearning/comments/183ok48/how_to_best_use_ai_as_an_educational_tool_10/,9,1700932759.0,""" Up until now, much of the discussion surrounding the use of generative AI in education has centered on catching AI used in cheating.  Some educators have seen generative AI as an awkward reality that makes writing assignments difficult to regulate.  With ChatGPT 4.0, students can pass off AI writing as their own original work thus circumventing the point of the assignment.  AI is seen as the ultimate slacker tool, making it irresistibly easy for lazy students to complete writing assignments at the press of a button.  

Educators Strike Back?

How are teachers supposed to respond to this?  I think there are two possible responses to this.  One is the first, very understandable response, which is to attempt to catch the “AI cheater” in the act.  This reaction makes sense at the moment since educational organizations have not yet had time to understand and respond to the technology.  To help on that front, we have created a thorough review of how educators might catch the students who decide to become AI cheaters in the article at this link.

If You Can’t Beat’em…

However, in this article, we will look at what I believe is the second possible response educators can have to this technology: rather than trying to constantly stay ahead of this ever-evolving technology in order to try and “catch the cheater,” can we rather ask if there is a way of using generative AI as an educational asset?  Could we possibly view [machine learning](https://ai-solutions.pro/what-is-machine-learning-a-beginners-guide/) and [Natural Language Processing](https://ai-solutions.pro/what-is-natural-language-processing-nlp-the-ultimate-beginners-guide/) as a natural next step in the advancement of technology, much like math teachers eventually accepted the use of calculators in math class? ""

Here is the full article:

[https://ai-solutions.pro/ai-in-education-10-genius-tricks-you-didnt-know-existed/](https://ai-solutions.pro/ai-in-education-10-genius-tricks-you-didnt-know-existed/)"
85,learnmachinelearning,gpt-4,top,2023-06-12 17:23:33,"GPT Weekly - 12the June Edition - OpenAI GPT Best Practice, Deepmind's sorting algo, Bard Improvements and more.",level6-killjoy,False,0.75,2,147shn0,https://www.reddit.com/r/learnmachinelearning/comments/147shn0/gpt_weekly_12the_june_edition_openai_gpt_best/,0,1686590613.0," 

This is a recap covering the major news from last week.

* 🔥Google Deepmind’s sort solution, OpenAI best practice on GPT, and Bard improvements
* 🗞️Apple’s use of Generative AI and other 9 AI news highlights and interesting reads
* 🧑‍🎓Learning about tokenization and using Huggingface LLM with LangChain

🔥Top 3 AI news in the past week

# 1. Optimal solutions are inhuman

Sorting is one of the fundamental algorithms used on the internet everyday. Think of how companies like Netflix need to find correct movies from their huge content library and present it to you. More content is being generated everyday. So, there is a need for newer and more efficient algorithms.

Searching for these algorithms has been a human task. People coming up with efficient and optimal solutions. Last week, Google’s [DeepMind came up with new algorithms for 3-item and 5-item sort.](https://www.nature.com/articles/s41586-023-06004-9)

Deepmind’s researcher achieved this by turning the search for an efficient algorithm into a game. Then they trained Alphadev to play this game. When playing this game, Alphadev came up with unseen strategies. These “strategies” are the new sorting algorithms.

The solution isn’t revolutionary as it doesn’t find a new approach. This solution works by optimizing the current approach.

The algorithms have been added to C++ library. The first time a completely AI solution has been added to the library.

This is an important discovery because it shows that finding the best optimal solutions needs computers. As computers are able to go beyond what humans can perceive. Previously, Deepmind’s AlphaGo has [beaten the top rated Go player Lee Sedol in a similar way](https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol). It came up with moves which were never seen before.

On the other hand, computers might be restricted to what they have been taught. Someone was able to [replicate the discovery using ChatGPT](https://twitter.com/DimitrisPapail/status/1666843952824168465).

# 2. GPT Best Practices

There has been a [lot of noise about GPT-4’s quality going down.](https://gptweekly.beehiiv.com/p/peek-openais-future)

Now we have a [list of tactics and strategies straight from Open AI](https://platform.openai.com/docs/guides/gpt-best-practices) to get better results.

I have looked through the strategies and tactics and most of it is around providing better inputs. “Prompt Engineering”, if you may. Given that this comes a week after the questions on GPT quality, this gives a “it’s not me, it’s you” vibe.

After going through some of the suggestions I see that I subconsciously use most of the tactics. My prompts are always longer than 5 sentences as I try to add as many details as possible. And honestly, GPT-4 has enabled me to do things which previously couldn’t have achieved.

# 3. Logic and reasoning improvements in Bard

Bard, on the other hand, has been lacking. Google is trying to improve the responses by adding features one at a time.

Last week it was announced that [Bard will get better at logic and reason](https://blog.google/technology/ai/bard-improved-reasoning-google-sheets-export/). This is achieved using “implicit code execution”. Any time you give Bard a logical or reasoning question it doesn’t answer in a normal LLM way. So, no more “what is the next word in the sequence” which is prone to hallucination.

Instead Bard will now recognize that the prompt is a logical question. It will then write and execute code under the hood. It’ll respond to the question by taking the output of the execute code.

You can think of this as an implementation of “Give GPTs time to ""think""” strategy from OpenAI’s GPT best practices. As per Google, this improves the performance by 30%.

Give it a try and let me know?

# 🗞️10 AI news highlights and interesting reads

1. Apple did not showcase any generative AI products during the WWDC. Though they are introducing the “what is the next word in the sequence” logic of LLM into autocorrect. It can be summed thusly:

&#x200B;

https://preview.redd.it/ovnoasksfm5b1.jpg?width=900&format=pjpg&auto=webp&s=8e37990c268933497f003faf58b854a73129ca6a

1. [ChatGPT cannot read the name - davidjdl](https://twitter.com/goodside/status/1666598580319035392). Some think that this is due to tokenization of Reddit data. In the learning resources section I have added a tutorial on tokenization.
2. Browser extensions are a security nightmare. [The GPT and LLM craze has given the malware extensions another way to steal user data.](https://www.kolide.com/blog/ai-browser-extensions-are-a-security-nightmare) Beware of the summarization and “write for me” extensions.
3. Most of the AI generated imagery is going to be used for stock photography. But is the industry dying? [Here’s a look at the data so far.](https://www.stockperformer.com/blog/is-ai-killing-the-stock-industry-a-data-perspective/) The author’s conclusion is that early metrics show that finding AI stock images often don’t have people in it. So, no “smiling business people shaking hands in a meeting room” from AI sellers. This might change with MidJourney V5. Future is still unknown.
4. [Six tips for better coding with ChatGPT](https://www.nature.com/articles/d41586-023-01833-0). I have been using Trust, but verify mental model quite frequently. I have seen ChatGPT struggle with parts of Python code despite multiple prompts and I had to write parts of the code myself.
5. [GPT-5 isn’t coming any time soon](https://techcrunch.com/2023/06/07/openai-gpt5-sam-altman/).
6. AI startups might be too easy to copy. And with AI requiring lesser resources, [we might even see 1 person companies worth more than 1 million dollars](https://www.semafor.com/article/06/07/2023/are-ai-startups-too-easy-to-copy).
7. [Google’s vision for securing AI.](https://www.axios.com/2023/06/08/google-securing-ai-framework)
8. [A16z says AI will save the world.](https://a16z.com/2023/06/06/ai-will-save-the-world/)
9. AI pics might be used for disinformation. [The EU's solution is to label AI images to fight disinformation.](https://techcrunch.com/2023/06/06/eu-disinformation-code-generative-ai-labels/)

# 🧑‍🎓3 Learning Resources

1. If you are looking to build better solutions using GPT then understanding tokenizers is a must:  

   1. [https://simonwillison.net/2023/Jun/8/gpt-tokenizers/](https://simonwillison.net/2023/Jun/8/gpt-tokenizers/)
   2. [https://matt-rickard.com/the-problem-with-tokenization-in-llms](https://matt-rickard.com/the-problem-with-tokenization-in-llms)
2. Using Flowise and HuggingFace LLM and Langchain

[https://cobusgreyling.medium.com/how-to-use-huggingface-llms-with-langchain-flowise-2b2d0f639f03](https://cobusgreyling.medium.com/how-to-use-huggingface-llms-with-langchain-flowise-2b2d0f639f03)

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
86,learnmachinelearning,gpt-4,top,2023-07-04 14:25:26,"How To Fine-Tune LLaMA, OpenLLaMA, And XGen, With JAX On A GPU Or A TPU",juliensalinas,False,0.75,2,14qgnht,https://www.reddit.com/r/learnmachinelearning/comments/14qgnht/how_to_finetune_llama_openllama_and_xgen_with_jax/,0,1688480726.0,"Hello,

Fine-tuning  your own large language model is the best way to achieve  state-of-the-art results, even better than ChatGPT or GPT-4, especially  if you fine-tune a modern AI model like LLaMA, OpenLLaMA, or XGen.

Properly  fine-tuning these models is not necessarily easy though, so I made an A  to Z tutorial about fine-tuning these models with JAX on both GPUs and  TPUs, using the EasyLM library.

Here it is: [https://nlpcloud.com/how-to-fine-tune-llama-openllama-xgen-with-jax-on-tpu-gpu.html](https://nlpcloud.com/how-to-fine-tune-llama-openllama-xgen-with-jax-on-tpu-gpu.html?utm_source=reddit&utm_campaign=i859w625-3816-11ed-a261-0242ac140015)

I hope it will be helpful! If you think that something is missing in this tutorial please let me know!

Julien"
87,learnmachinelearning,gpt-4,top,2023-12-28 08:21:46,Fresh Grad trying their best to get into the industry. Please rate my resume,RookFlame4882,False,1.0,2,18soytd,https://www.reddit.com/r/learnmachinelearning/comments/18soytd/fresh_grad_trying_their_best_to_get_into_the/,0,1703751706.0,"Thank you for your time and help. Will appreciate any comments and critiques. Been trying my best to get a single callback but none so far. Feeling very lost & dejected.

&#x200B;

https://preview.redd.it/sv9akq4cwz8c1.png?width=2550&format=png&auto=webp&s=1d22d61b9bf53c995f52b5f62149cfcd9bfb8d03"
88,learnmachinelearning,gpt-4,top,2023-08-16 20:33:36,Llama2 on Replicate faster than ChatGPT?,VideoTo,False,0.67,2,15t1715,https://www.reddit.com/r/learnmachinelearning/comments/15t1715/llama2_on_replicate_faster_than_chatgpt/,2,1692218016.0,"Ran some testing and discovered llama2 on replicate is faster than chatgpt!

Code - [https://github.com/BerriAI/litellm/blob/main/cookbook/Evalua...](https://github.com/BerriAI/litellm/blob/main/cookbook/Evaluating_LLMs.ipynb)

Are others seeing similar results?

https://preview.redd.it/t6n5ijfv8jib1.png?width=1238&format=png&auto=webp&s=78ef90bce9bebe761c3a1eb63f016ebdead593a5"
89,learnmachinelearning,gpt-4,top,2020-10-30 01:23:50,Generating Snort Rules using GPT2,afoteygh,False,1.0,2,jknepi,https://www.reddit.com/r/learnmachinelearning/comments/jknepi/generating_snort_rules_using_gpt2/,0,1604021030.0,"Hi I have been working on Generating Snort rules using the GPT2 Transformer.

This is my thinking

1. Snort rules for a particular family of malware are quite related. that is why these malware have been classified into that family so using text generation to generate new rules should be possible (i Feel)
2. Collect  Snort rules for a particular malware family. (Also collect pcap which trigger these specific rules i have obtained)
3. Clean it up by removing commented/unused rules.
4. Feed the rules to GPT2 (124M) (I chose this because i read it performs quite well in text generation )
5. Trained GPT on the dataset
6. using it to generated new rules
7. clean up the rules (syntax etc)
8. Test newly generated rules in snort with sample pcap files.

So for i have been able to generate and clean up 1000's of rules and tested them without any success!

Can anyone give me some guidance on what i am doing wrong or if my whole hypothesis and experiment is flawed.

&#x200B;

Thanks."
90,learnmachinelearning,gpt-4,top,2023-07-07 01:22:41,How to specify context for LLMs for text2text generation?,Draude94,False,1.0,2,14sscyg,https://www.reddit.com/r/learnmachinelearning/comments/14sscyg/how_to_specify_context_for_llms_for_text2text/,0,1688692961.0,"Hi!

I picked some LLMs like CerebrasGPT, RedPajamaINCITE, T5 to check if they are able to answer question like ChatGPT does.

I loaded the models from hugging face and configured them like in the hugging face examples. I took the mode without sampling, without using pipeline. I just use the model.generate() method and reduce the max length to 256 or 128.

So there is no context. The models are trained, I just give one question as a input and I expect some answers that make sense. But my problem is that I get some really weird answers. Some answers look like they are cut randomly from a book papragraph (that barely matches my question) and others completelly don't make sense.

Do I have to specify some context? Or do I have to put some kind of prompt around the question string like: ""Q: "" + question + ""A:"" ? (Just to make sure that the model knows I asked a question and that I expect a answer)

How does ChatGPT manage this?I mean, before a user inserts a question there must be some kind of prompting like:""You are a chatbot. A new user wants to ask you a question. Now please answer this question:"" + userInputQuestion.

I couldn't find any official documentation or best practices about this.

My question pool consists of different fact based questions like:  
\-What can you do?,  
\-What is the capital of Germany?,  
\-Send an email write a summarization google the weather in london. Please list the intents from the previous sentence,  
\- What is educational time?,  
\-Write some python code that adds two numbers, etc.  


My pc is low specs. Asking one question with loading the model and tokenizer + inference takes about 40 sec. to 4 min. (depending on the model)."
91,learnmachinelearning,gpt-4,top,2023-08-14 11:47:27,Tips for training off spectrogram images for a desired text output?,getSAT,False,1.0,2,15qsg28,https://www.reddit.com/r/learnmachinelearning/comments/15qsg28/tips_for_training_off_spectrogram_images_for_a/,3,1692013647.0,"I have a large dataset of music and corresponding timing points for beat drops in a song.

I want to create a model that can predict my `timings` column based on any given song.

My idea so far is to convert the music into a spectrogram image so it's easier for AI to understand. Then I would fine tune a model like GPT-3 for the timing points, but other than that I'm lost. Especially the part where how do I even train if one of my columns is an image and not text?

If training off GPT3 is not possible is there some AutoML service I can feed this data into? I do have programming experience but not with AI or data science. My dataset looks something like:


|image|timings|
|--|--|
|song1.png|184,192,577,1,0328,192,996,1,0184,192,1416,1,0328,192,1835,1,0256,192,2255,1,4256,192,2674,1,4256,192,4563,1,4256,192,6451,12,0,812964,88,8968,5,064,88,9178,1,0136,88,9388,1,0136,88,9597,1,0208,88,9807,1,0208,88,10017,1,0280,88,10227,1,4|
|song2.png|280,232,10646,5,0280,232,10856,1,0208,232,11066,1,0208,232,11276,2,0208:152,2,52.5136,232,11695,1,0136,232,11905,1,4136,376,12325,5,0136,376,12535,1,064,376,12744,1,464,376,12954,1,0136,376,13164,1,0136,376,13374,1,064,376,13583,1,464,376,13793,1,0|
|song3.png|136,376,14003,1,0136,376,14213,1,0208,376,14423,1,4208,376,14632,1,0280,376,14842,1,4400,280,15681,5,0400,280,15891,1,0400,208,16101,1,0400,208,16311,1,0400,136,16521,2,4176:136,1,210|
|song4.png|248,192,54702,5,0248,192,55051,1,0248,192,55400,1,0248,192,55748,1,0248,192,56097,1,0248,192,56446,1,0248,192,56795,1,0248,192,57144,1,0248,192,57493,5,2248,192,57667,1,2248,192,57841,1,2248,192,58016,1,2|"
92,learnmachinelearning,gpt-4,top,2023-11-07 19:20:33,System Prompt Library,MetalZuna,False,1.0,1,17q21tb,https://www.reddit.com/r/learnmachinelearning/comments/17q21tb/system_prompt_library/,0,1699384833.0,"System Prompt Library for ChatGPT - 4  


Check it out!

&#x200B;

[https://github.com/MetalZuna/Snap](https://github.com/MetalZuna/Snap)"
93,learnmachinelearning,gpt-4,top,2024-01-05 21:18:41,"good quality open source python text to speech models we can download and use locally? or free apis? Sorry, this post has been removed by the moderators of r/learn",Sharp-Cat2319,False,1.0,1,18zhwaw,https://www.reddit.com/r/learnmachinelearning/comments/18zhwaw/good_quality_open_source_python_text_to_speech/,0,1704489521.0," I need to transcribe around 200k characters into voice.

Everyone recommends [elevenlabs.io](https://elevenlabs.io/) I tested their api, it works great, but their subscription model is a rip off. 200k characters is $40. Where as in ChatGPT this took about $4 to generate.

I jokingly could probably hire someone to read that for this price or just do it myself. But that's not the point of this exercise

I want to get a local model that will do a quality text to speech with ML.

If such models arent available, or if they take up too much space, I dont mind an online one, as long as its not price gouged.

What is the best Library to use for this?"
94,learnmachinelearning,gpt-4,top,2022-12-16 22:40:24,How would I build an ML model to generate code for Fabric mods in Minecraft (text to fabric code),MachineLearner523,False,1.0,1,znr9hq,https://www.reddit.com/r/learnmachinelearning/comments/znr9hq/how_would_i_build_an_ml_model_to_generate_code/,0,1671230424.0,"Fabric is a library that mod developers can use to hook into the game's code and make changes. 

For example, if I input the text ""make an orb that flies around the player in a circular motion,"" the model should be able to generate fabric library code that creates such an orb in the game. 

My plan is:

1. download code from all Fabric mods on Github

2. tokenize the code using the GPT-2 tokenizer

3. convert the tokenized code to vector embeddings using OpenAI's embeddings endpoint

4. ? and then use these embeddings to train a model that can generate code based on input text. 

I'm wondering if it would be more appropriate to use reinforcement learning or transformers for this task. Can anyone provide guidance on which approach might be more suitable for this problem, or suggest other approaches I should consider?"
95,learnmachinelearning,gpt-4,top,2023-09-02 17:47:34,LLaVA: Bridging the Gap Between Visual and Language AI with GPT-4,OnlyProggingForFun,False,1.0,1,1688v48,https://youtu.be/Pn1B_L_zAwI,1,1693676854.0,
96,learnmachinelearning,gpt-4,top,2024-01-25 20:52:45,Implementing a Sparse Mixture of Experts Language Model from scratch,avi1x,False,0.66,1,19fjjrr,https://www.reddit.com/r/learnmachinelearning/comments/19fjjrr/implementing_a_sparse_mixture_of_experts_language/,0,1706215965.0,"Hi all,

I implemented a sparse mixture of experts language model (basically a tiny version of Mixtral and supposedly GPT-4) from scratch in pure pytorch and trained it on tiny Shakespeare. This is based largely on makemore from Andrej Karpathy (an autoregressive character-level decoder only transformer model). My goal is for this to be a hackable implementation that people use to understand how this really works and improve upon. I foresee more and more of these models coming out throughout the year.

The blog that steps through this is here: [https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch](https://huggingface.co/blog/avisoori1x/makemoe-from-scratch)

The repo is here: [https://github.com/AviSoori1x/makeMoE](https://github.com/avisoori1x/makemoe)

Hope this is helpful!"
97,learnmachinelearning,gpt-4,top,2023-03-16 19:16:18,Problems with Wav2lip,MF3DOOM,False,1.0,1,11t3fgn,https://www.reddit.com/r/learnmachinelearning/comments/11t3fgn/problems_with_wav2lip/,1,1678994178.0," 

Hey everyone, I'm new to machine learning and I'm currently trying to use wav2lip on a Google Colab notebook. However, I keep running into an error that says:

""ERROR: Could not find a version that satisfies the requirement opencv-python==4.1.0.25 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.14.51, 3.4.14.53, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.2.52, 4.5.2.54, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72) ERROR: No matching distribution found for opencv-python==4.1.0.25""

I've tried to fix the problem by running ""!pip install opencv-python==4.5.3.56"" in the code cell, as instructed by some youtube videos and ChatGPT, but it hasn't worked. Does anyone have any experience with wav2lip and knows how to solve this error? Any help would be greatly appreciated. Thank you!"
98,learnmachinelearning,gpt-4,top,2023-08-16 17:50:56,"Bright Eye: free IOS mobile AI app that generates text, images, and analyzes photos.",EtelsonRecomputing,False,0.67,1,15swuwk,https://www.reddit.com/r/learnmachinelearning/comments/15swuwk/bright_eye_free_ios_mobile_ai_app_that_generates/,0,1692208256.0,"Hi all. I’m the cofounder of a startup focused on developing the AI super app called “Bright Eye”, a multipurpose AI product that generates and analyzes content.

One of its interesting use cases is helping students study, people plan, code, compute math, and offering general advice. 

As the title puts it, it’s capable of generating almost anything, so the use-cases in terms of productivity isn’t confined to only those above, it can apply however you see fit. We run on GPT-4, stable diffusion, and Microsoft azure cognitive services to provide text generation, image generation, and prepackaged computer vision capabilities.

Check us out below, we’re looking for advice on the functionality, it’s ability to satisfy your role play needs, and design of the app (and possibly some longtime users): 

https://apps.apple.com/us/app/bright-eye/id1593932475"
99,learnmachinelearning,gpt-4,top,2022-11-03 16:43:09,GPT-3 Powered Mac Writing App - Live on ProductHunt,juliarmg,False,1.0,1,yl7mie,https://www.reddit.com/r/learnmachinelearning/comments/yl7mie/gpt3_powered_mac_writing_app_live_on_producthunt/,0,1667493789.0,"Hello everyone,  

I have been building this Mac AI app for 4 months now. Elephas is the only AI writer that works on all your Mac apps. No need to switch windows.  

It helps business professionals and content writers use GPT-3 for their day-to-day tasks.

It differs from other AI tools in that,

1. It works on all apps on Mac.
2. You use your own OpenAI key, so you pay for what you use.
3. It doubles as a productivity tool, starting from Google Sheets formulas to creating presentations.

I have launched it on ProductHunt. If you know ProductHunt, then your support will mean a lot to me, 

 [https://www.producthunt.com/posts/elephas](https://www.producthunt.com/posts/elephas)"
100,learnmachinelearning,gpt-4,comments,2023-04-30 15:45:04,I don't have a PhD but this just feels wrong. Can a person with a PhD confirm?,flaky_psyche,False,0.77,64,133v9s5,https://i.redd.it/fmkvgop7l1xa1.jpg,238,1682869504.0,
101,learnmachinelearning,gpt-4,comments,2023-12-25 17:15:18,"Have we reached a ceiling with transformer-based models? If so, what is the next step?",swagonflyyyy,False,0.86,61,18qmohw,https://www.reddit.com/r/learnmachinelearning/comments/18qmohw/have_we_reached_a_ceiling_with_transformerbased/,134,1703524518.0,"About a month ago Bill Gates hypothesized that models like GPT-4 will probably have reached a ceiling in terms of performance and these models will most likely expand in breadth instead of depth, which makes sense since models like GPT-4 are transitioning to multi-modality (presumably transformers-based).

This got me thinking. If if is indeed true that transformers are reaching peak performance, then what would the next model be? We are still nowhere near AGI simply because neural networks are just a very small piece of the puzzle. 

That being said, is it possible to get a pre-existing machine learning model to essentially create other machine learning models? I mean, it would still have its biases based on prior training but could perhaps the field of unsupervised learning essentially construct new models via data gathered and keep trying to create different types of models until it successfully self-creates a unique model suited for the task?

Its a little hard to explain where I'm going with this but this is what I'm thinking:

\- The model is given a task to complete.

\- The model gathers data and tries to structure a unique model architecture via unsupervised learning and essentially trial-and-error.

\- If the model's newly-created model fails to reach a threshold, use a loss function to calibrate the model architecture and try again.

\- If the newly-created model succeeds, the model's weights are saved.

This is an oversimplification of my hypothesis and I'm sure there is active research in the field of auto-ML but if this were consistently successful, could this be a new step into AGI since we have created a model that can create its own models for hypothetically any given task?

I'm thinking LLMs could help define the context of the task and perhaps attempt to generate a new architecture based on the task given to it but it would still fall under a transformer-based model builder, which kind of puts us back in square one."
102,learnmachinelearning,gpt-4,comments,2023-12-17 13:15:47,I can't stop using ChatGPT and I hate it.,t0hli,False,0.64,26,18kh4n5,https://www.reddit.com/r/learnmachinelearning/comments/18kh4n5/i_cant_stop_using_chatgpt_and_i_hate_it/,108,1702818947.0,"I'm trying to learn various topics like Machine Learning and Robotics etc., and I'm kinda a beginner in programming.

For any topic and any language, my first instinct is to

1. go to ChatGPT,
2. write down whatever I need my code to do,
3. copy paste the code
4. if it doesn't give out good results, ask ChatGPT to fix whatever it's done wrong
5. repeat until I get satisfactory result

I hate it, but I don't know what else to do.

I think of asking Google what to do, but then I won't get the exact answer I'm looking for, so I go back to ChatGPT so I can get exactly what I want. I don't fully understand what the GPT code does, I get the general gist of it and say ""Yeah that's what I would do, makes sense"", but that's it.

If I tried to code whatever GPT printed out, I wouldn't get anywhere.

I know I need to be coding more, but I have no idea where to start from, and why I need to code when ChatGPT can do it for me anyway. I'm not defending this idea, I'm just trying to figure out how I can code myself.

I'd appreciate your thoughts and feedback."
103,learnmachinelearning,gpt-4,comments,2023-12-07 01:31:55,Why can't AI models do complex math?,open_23,False,0.69,39,18ck15r,https://www.reddit.com/r/learnmachinelearning/comments/18ck15r/why_cant_ai_models_do_complex_math/,93,1701912715.0,"Computers, at its most fundamental level, is made up of boolean logic. Mathematics is basically the language of logic.

SHouldn't AI models, or computers in general be able to do more advanced math than just crunching large numbers? Why haven't anyone used computers to solve any of the Millenium Prize Problems or some other difficult proof. 

GPT-4 and recently  Gemini, has decent enough grade school level math solving capabilities but absolute atrocious at solving slightly more complex problems. But, I guess thats to be expected since they're LLMs. But, why hasn't anyone built an AI model geared towards just solving mathemaths problems? Also, what kind of different architecture would such a model need?"
104,learnmachinelearning,gpt-4,comments,2023-01-19 07:56:20,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.96,333,10fw2df,https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/,47,1674114980.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
105,learnmachinelearning,gpt-4,comments,2023-12-26 07:39:32,Can you guess who wrote this code ? A Developer or a Researcher/Scientist,Left_Papaya_9750,False,0.85,40,18r2vqv,https://www.reddit.com/r/learnmachinelearning/comments/18r2vqv/can_you_guess_who_wrote_this_code_a_developer_or/,47,1703576372.0,"    import torch 
    from torch.optim.lr_scheduler import CosineAnnealingLR
    from gpt import GPTLanguageModel
    from transformers import GPT2Tokenizer
    from tqdm import tqdm
    from utils.draw_plots import Draw
    import pynvml as nvml
    import os
    import time
    import wandb
    from utils import draw_stuff
    from torch.utils.data import DataLoader, SubsetRandomSampler
    from utils.load_data import LoadDataset
    import signal 
    from colorama import Fore
    from queue import Queue
    
    class Train():
        def __init__(self, **kwargs,):
            torch.manual_seed(1137)
            model= GPTLanguageModel()
            gpu_idx= 0 if not 'gpu_index' in kwargs else kwargs['gpu_index']
            nvml.nvmlInit()
            os.system(""cls"" if os.name == 'nt' else 'clear')
            draw_stuff.draw()
            self.enc= GPT2Tokenizer.from_pretrained('gpt2')
            self.device='cuda' if torch.cuda.is_available else 'cpu'
            self.m= model.to(self.device)
            self.block_size= 256 if not 'block_size' in kwargs else kwargs['block_size']
            self.batch_size= 100 if not 'batch_size' in kwargs else kwargs['batch_size']
            self.handle= nvml.nvmlDeviceGetHandleByIndex(gpu_idx)
            self.temp_thres= 85 if not 'temp_threshold' in kwargs else kwargs['temp_threshold']
            self.plot= Draw()
            
        def load_data(self,split, split_per):
            dataset= LoadDataset(split= split, split_per=split_per)
            sampler= SubsetRandomSampler(torch.randint(high=len(dataset), size=(1000,)).tolist())
            data_title= DataLoader(dataset, pin_memory= True, sampler=sampler, drop_last=True)
            return data_title
    
        @torch.no_grad()
        def estimate_loss(self, eval_iters)->torch.tensor:
            out = {}
            print(""Estimating loss\n"")
            self.m.eval()
            for split in ['train', 'val']:
                es_progress= tqdm(total=eval_iters, ncols=100)
                es_progress.colour='red'
                
                losses = torch.zeros(eval_iters)
                for k in range(eval_iters):
                    es_progress.update(1)
                    for X, Y in self.get_batch(split):
                        logits, loss = self.m(X, Y)
                        losses[k] = loss.item()
                out[split] = losses.mean()
            self.m.train()
            return out
        
        def get_batch(self, split):
            data = self.load_data(split, split_per=0.8)
            for idx, data in enumerate(data):
                doc= data
                doc_txt= doc['text'][0]
                title= doc['title'][0]
                encoded_tok= self.enc.encode(doc_txt, add_special_tokens= True)
                doc_txt_enc= torch.tensor(encoded_tok, dtype=torch.long)
                size= self.block_size
                if len(encoded_tok) - self.block_size <= 0 and len(encoded_tok)-20 >=3:
                    size=20
                ix = torch.randint(len(encoded_tok) - size , (self.batch_size,))
                x = torch.stack([doc_txt_enc[i:i+size] for i in ix]).to(self.device) 
                y = torch.stack([doc_txt_enc[i:i+size+1] for i in ix]).to(self.device) 
                yield x, y
                
    
        def display_train_params(self,train_id, device, **kwargs):
            print(f""**NOTE: GPU temperature threshold has been set to {self.temp_thres}°C, when the threshold is reached the training process will halt for a set period.**\n"")
            print(f""INFO {torch.cuda.memory_allocated(device)} Bytes of memory is allocated for this task\n"")
            print(f""""""Training parameters:
                      Device: {nvml.nvmlDeviceGetName(self.handle)}
                      Halt Temperature threshold:{self.temp_thres}
                      Trainable Parameters: {sum(p.numel() for p in self.m.parameters())/1e6, 'M parameters'}
                      Total Epochs: {kwargs['epochs']}
                      Evaluation Iterations: {kwargs['eval_iters']}
                      Evaluation Interval: {kwargs['eval_interval']}
                      Initial Learning rate: {kwargs['learning_rate']}
                      Learning Rate Schduler: Cosine Annealing
                      Total Memory allocated: {torch.cuda.memory_allocated(device)}B
                      \n"""""")
            
            print(f""** Training Started | Train ID : {train_id}**\n"")
    
        
        def train(self, device, train_id, is_save=True, **kwargs):
            
            wandb.init('Training',  
                        project='gpt-model',
                        config={
                            ""initial_learning_rate"":3e-4,
                            ""architecture"":""transformer"",
                            ""dataset"": ""Wikipedia general documents""
                                }
                        )
            docs= []
            eval_interval= 500 if not 'ei' in kwargs else kwargs['ei']
            learning_rate= 3e-4 if 'learning_rate' not in kwargs else kwargs['learning_rate']
            eval_iters= 300 if 'eval_iter' not in kwargs else kwargs['eval_iter']
            max_iters= 10000 if not 'epochs' in kwargs else kwargs['epochs']
            num_doc= 2000
            os.mkdir('results') if not 'results' in os.listdir('.') else None
            os.mkdir(f'results/{train_id}') if train_id not in os.listdir('results') else None
            os.mkdir(f'results/{train_id}/checkpoints') if 'checkpoints' not in os.listdir(f'results/{train_id}') else None
            os.mkdir(f'results/{train_id}/checkpoints/plots') if 'plots' not in os.listdir(f'results/{train_id}/checkpoints') else None
            torch.cuda.empty_cache()
            optimizer = torch.optim.AdamW(self.m.parameters(), 
                                          lr=learning_rate)
            schduler= CosineAnnealingLR(optimizer=optimizer, T_max=max_iters)
    
            self.display_train_params(train_id=train_id, 
                                      device=device, 
                                      epochs=max_iters, 
                                      eval_interval=eval_interval,
                                      eval_iters=eval_iters,
                                      learning_rate=learning_rate
                                      )
            
            epoch_progress_bar= tqdm(total=eval_interval, 
                                     ncols=100
                                    )
            
            epoch_progress_bar.colour='cyan'
            counter= 0
            cont_params={'train_loss':[], 
                         'l_r':[]
                        }
            
            ckpt_params={'train_loss':[], 
                         'val_loss':[],
                         'l_r':[]
                        }
            
            it_cnt=0
            for iter in range(0, max_iters):
                epoch_progress_bar.update(1)
                curr_temperature= nvml.nvmlDeviceGetTemperature(self.handle, 
                                                                nvml.NVML_TEMPERATURE_GPU
                                                               )
        
                if curr_temperature >= self.temp_thres:
                    print(f""\n Set temperature threshold of {self.temp_thres}°C reached halting for {4} seconds "")
                    time.sleep(3)
                    print(""\n Resuming Training "")
                
    
                if iter % eval_interval == 0 or iter == max_iters-1:
                    
                    checkpoint_save_path= f'results/{train_id}/checkpoints/checkpoint-{counter}-epoch{iter}.pth'
                    losses =self.estimate_loss(eval_iters)
                    ckpt_params['l_r'].append(schduler.get_last_lr()[0])
                    ckpt_params['train_loss'].append(losses['train'])
                    ckpt_params['val_loss'].append(losses['val'])
                    wandb.log({""eval epoch"":iter, ""validation loss"":losses['val']})
                    plot_save_path= f'results/{train_id}/checkpoints/plots/checkpoint-{counter}'
        
                    if iter ==0:
                        pass
                    else:
                        
                        self.plot.draw_line(mode='loss', 
                                            train_loss= cont_params['train_loss'],  
                                            epochs=[it for it in range(it_cnt, it_cnt+eval_interval)],
                                            save_path=f'{plot_save_path}-epoch_vs_loss.png'
                                            )
                        self.plot.draw_line(mode='lrvloss',
                                            l_r= cont_params['l_r'],
                                            train_loss=cont_params['train_loss'], 
                                            save_path=f'{plot_save_path}-learning_rate_vs_loss.png'
                                            )
                        
                        self.plot.draw_line(mode='lrve',
                                            l_r= cont_params['l_r'], 
                                            epochs=[it for it in range(it_cnt, it_cnt+eval_interval)],
                                            save_path=f'{plot_save_path}-learning_rate_vs_epoch.png'
                                            )
                        
                        cont_params['l_r'].clear()
                        cont_params['train_loss'].clear()
                        torch.save(self.m.state_dict(), checkpoint_save_path)
                        it_cnt+=iter
        
                    print(f""step {iter+1}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}"") 
                    epoch_progress_bar.close() 
                    epoch_progress_bar = tqdm(total=eval_interval, ncols=100)
                    epoch_progress_bar.colour='cyan'
                    counter+=1
                print(f'loading data for epoch{iter}')
    
    
                for xb, yb in self.get_batch(split='train'):
                    logits, loss = self.m(xb, yb)
                    optimizer.zero_grad(set_to_none=True)
                    loss.backward()
                    optimizer.step()
                    schduler.step()
                    curr_lr= schduler.get_last_lr()[0]
                    train_loss= loss.item()
                cont_params['l_r'].append(curr_lr)
                cont_params['train_loss'].append(train_loss)
                wandb.log({'epoch':iter, 'train loss':train_loss, 'learning rate':learning_rate})            
                epoch_progress_bar.set_description(f""Epoch: {iter}/{max_iters} |current LR- {curr_lr}"")
            
            os.mkdir(f'results/{train_id}/final_plots') if 'final_plots' not in os.listdir(f'results/{train_id}') else None
    
            self.plot.draw_line(mode='loss', 
                                        train_loss= ckpt_params['train_loss'], 
                                        val_loss=ckpt_params['val_loss'], 
                                        epochs=[it for it in range(0,max_iters, 500)],
                                        save_path=f'results/{train_id}/final_plots/plot-epoch_vs_loss.png',
                                        plot_type='ckpt'
                                        )
            self.plot.draw_line(mode='lrvloss',
                                l_r= ckpt_params['l_r'],
                                train_loss=ckpt_params['train_loss'], 
                                val_loss= ckpt_params['val_loss'],
                                save_path=f'results/{train_id}/final_plots/plot-learning_rate_vs_loss.png',
                                plot_type='ckpt'
                                )
            
            self.plot.draw_line(mode='lrve',
                                l_r= ckpt_params['l_r'], 
                                epochs=[it for it in range(0,max_iters, 500)],
                                save_path=f'results/{train_id}/final_plots/plot-learning_rate_vs_loss.png',
                                plot_type='ckpt'
                                )
    
            nvml.nvmlShutdown()
            wandb.finish()
    "
106,learnmachinelearning,gpt-4,comments,2023-05-11 20:15:46,Top 20 Large Language Models based on the Elo rating system.,kingabzpro,False,0.96,251,13eympz,https://i.redd.it/7xfqr5crf9za1.png,43,1683836146.0,
107,learnmachinelearning,gpt-4,comments,2023-01-15 00:08:37,Is it still worth learning NLP in the age of API-accessibles LLM like GPT?,CrimsonPilgrim,False,0.94,65,10c509n,https://www.reddit.com/r/learnmachinelearning/comments/10c509n/is_it_still_worth_learning_nlp_in_the_age_of/,24,1673741317.0,"A question that, I hope, you will find legitimate from a data science student.

I am speaking from the point of view of a data scientist not working in research.

Until now, learning NLP could be used to meet occasional business needs like sentiment analysis, text classification, topic modeling....

With the opening of GPT-3 to the public, the rise of ChatGPT, and the huge wave of applications, sites, plug-ins and extensions based on this technology that are accessible with a simple API request, it's impossible not to wonder if spending dozens of hours diving into this field if ML wouldn't be as useful today as learning the source code of the Pandas library. 

In some specialized cases, it could be useful, but GPT-3, and the models that will follow, seem to offer more than sufficient results for the immensity of the cases and for almost all classical NLP tasks. Not only that, but there is a good chance that the models trained by giants like Open-AI (Microsoft) or Google can never be replicated outside these companies anyway.  With ChatGPT and its incomparable mastery of language, its ability to code, summarize, extract topics, understand... why would I bother to use BERT or a TF-IDF vectorizer when an API will be released? Not only it would be easily accessible, but it also would be much better at the task, faster and cheaper.

In fact, it's a concern regarding all the machine learning field in general with the arrival of powerful ""no-code"" applications, which abstract a large part of the inherent complexity of the field. There will always be a need for experts, for safeguards, but in the end, won't the Data Scientist who masters the features of GPT-3 or 4 and knows a bit of NLP be more efficient than the one who has spent hours reading Google papers and practicing on Gensim, NLTK, spacy... It is the purpose of an API to make things simpler eventually... At what point is there no more reason to be interested in the behind-the-scenes of these tools and to become simple users rather than trying to develop our own techniques?"
108,learnmachinelearning,gpt-4,comments,2023-10-10 13:14:54,I need to estimate the time that it'll take to cover the basic math course so that I can move into the basics of ML. Can you help me please?,AndrewKorsten,False,0.5,0,174kwvx,https://www.reddit.com/r/learnmachinelearning/comments/174kwvx/i_need_to_estimate_the_time_that_itll_take_to/,23,1696943694.0," 

**\*\*\* Global Inputs \*\*\***

1) I am adult learner. 37 y.o. Content writer and professional English tutor.

2) I am pivoting completely into ""Sales/Marketing in ML/AI/AI-tech/AI-SaaS/AI-dev-agencies"".

3) I don't understand completely what ""Sales/Marketing in ML/AI/AI-tech/AI-SaaS/AI-dev-agencies"" means, but it means the following:

a. **I want completely pivot into the AI-driven tech** \- that's for sure. I see a lot of potential there, and I can see that I'll be able to gradually move into sales and start making the good money (the good money for me is 2K/mo, coz I am located in Kurplastan, but I want to move Bankok in 12 months; I am originally a russky).

b. **I am learning Python -** doing a basic course. It's going well. I have the core insights into HTML, CSS, JS, React, rest api, node, etc.

c. **I am not planning to become an actual ML Engineer -** but I want to move into sales/marketing in AI tech.

d. **I am not fixated on AI either** \- whenever I start making mone, I'm going to start pushing the surplus into ecommerce (there's a lot of opportunities to make money there, folks; don't look down on that; you can be making a lot of money there if you are learning and act strategically!)

4) I had huge problems with math and other STEM subjects in school - I wasn't getting them, and I was passing by them.

**\*\*\* Question Inputs \*\*\***

1) I decided that I would start the pivot 5 days ago, and THEN I started googling around what ML actuall is. I had a vague understanding that there's some math in it, but I decided to go blind... Now, I am understanding that I need to understand the basics of math.

2) I freaked out big time, I am almost started smoking after 7 years of not smoking...

3) Then I said to myself - Idk, I am not going anywhere, and I started doing this course - [https://www.youtube.com/watch?v=GuwofNeT9ok&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=34](https://www.youtube.com/watch?v=GuwofNeT9ok&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=34). (If you are looking for a good introduction math course, most of the people who I talk to always say that this is an amazing course. Really. I am at lesson 33 and I am loving every second of it.)

**\*\*\* Question \*\*\***

**1) Huge speed reduction at Lesson 34**: Now I am at Lesson 34 - [https://www.youtube.com/watch?v=GuwofNeT9ok&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=34](https://www.youtube.com/watch?v=GuwofNeT9ok&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=34). I watched the video today, didn't understand anything at all, as it turns out. Then I was presented with this compherension check - [https://imgsh.net/a/eKp1MAa.png](https://imgsh.net/a/eKp1MAa.png). I realized that I don't even understand what is wanted from me. I got super frustrated, but not desparate or fleeing. Then I realized that I don't understand what is wanted from me, so I started googling the concept of ""factoring the quadratics"". Importantly, I started GPTing and Gooling the ""why"". I know... This is a very important point for me - I always need to understand the ""why"" behind a tool. I learned that it would be easier for charting in linalg. OK! This was the answer. Then, i realized that I actualy didn't understand the lesson, so I found this article - [https://www.mashupmath.com/blog/how-to-factor-polynomials](https://www.mashupmath.com/blog/how-to-factor-polynomials). I read it end to end, understood everything, practiced every task 3 times and I do really understand how to fator the quadractics by now!

**2) Speed reduction is a normal thing**: So, prior to lesson 34, I was doing like 7 lessons per day. This was a good lesson - [https://www.youtube.com/watch?v=3-5DKCLJspM&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=13](https://www.youtube.com/watch?v=3-5DKCLJspM&list=PLybg94GvOJ9FoGQeUMFZ4SWZsr30jlUYK&index=13). I really liked it :) I can see that the speed reduction is occurring because of the complexity increase. It's not occurring because I am lost and disoriented - I remember how that felt in school, when you see a bunch of numbers on the blackboard and have no freaking idea what's going on there. I am just hitting up my best friend GPT and ask, ask, ask, ask stupid questions. Thus, I can see that the speed reduction is a normal right, right?

**3) Wha's the optimal speed correction here**: So, I am allocating 7h/d during the daytime shift when I am in the prime state toward this project. And I don't even have to learn Python at all because Python is easy, but I do plan to keep learning PYthon with 3 sessions each for 30 minutes so that I don't just do math. (And I run English lessons in the evenings so that I can keep on making money).

**The actual question**

I am thinking that I should go down from the goal of 7 lessons per day down to 3 lessons per day, right? If I do this, then I'm going to end up with the forecast delivery period of 43 days, right?

And the information that I provided above was kinda like an explanatory note that I am trying to become a real ML engineer, but I want to graudally slide into sales and marketing so that I can TOO Make a lot of money, uknow.

What do you think about the speed reduction down to 3 lessons per day?"
109,learnmachinelearning,gpt-4,comments,2023-05-15 06:27:00,Bilingual people : How good is AI at machine translation today?,moschles,False,0.84,21,13hzvkc,https://www.reddit.com/r/learnmachinelearning/comments/13hzvkc/bilingual_people_how_good_is_ai_at_machine/,22,1684132020.0,"In the wake of GPT-4 and chatGPT, how good would you rank machine translators in terms of their accuracy?

Are they only useful for one-off sentences? Do they fail when presented with any kind of moderately complex articles? Do they perform vastly different depending on the languages?     Are they still really stupid, or does their output blow you away now?"
110,learnmachinelearning,gpt-4,comments,2023-12-10 19:55:49,Is it worth learning ML in 2024 with GPT-4 and Gemini-Ultra on the horizon?,i_am_new_here_51,False,0.53,2,18fbtd8,https://www.reddit.com/r/learnmachinelearning/comments/18fbtd8/is_it_worth_learning_ml_in_2024_with_gpt4_and/,21,1702238149.0,"So I'm a college student looking to learn some skills in my free time. So far, I have a surface level understanding of C++, Webdev, and Python. 

From a career or even purely from an enjoyment standpoint, would learning Machine learning be worth it in this climate? Or has the advent of LLMs made this field less viable. (I am not very well versed in this field, so I do apologise if I come off as ignorant)"
111,learnmachinelearning,gpt-4,comments,2021-04-03 15:27:04,"I'm a Senior DS and I put together a Youtube Channel with project tutorials, resume critiques, and career advice. Let me know what you think!",madzthakz,False,0.98,545,mjao5g,https://www.reddit.com/r/learnmachinelearning/comments/mjao5g/im_a_senior_ds_and_i_put_together_a_youtube/,21,1617463624.0,"I've also been setting up free [Data Science Q&As](https://www.reddit.com/r/datascience/comments/jig7pv/im_a_senior_data_scientist_at_disney_and_im/) for you all. On the side, I started putting together useful videos that would have helped me out when I was trying to break into this space. Like I said, the channel consists of modeling tutorials, resume critiques, career advice, and recordings of our Q&A sessions. Here are some examples:

1. [How to build a Spotify recommendation engine](https://youtu.be/tooddaC14q4).
2. [How to leverage GPT-2 to generate descriptions of new Netflix content](https://youtu.be/NvMoFeO0aGE).
3. [Full recordings of 1:1 coaching sessions with an ML student.](https://youtu.be/N2tDfXdZmdE)
4. [Resume Critique of a student who just completed a certificate.](https://youtu.be/Ztexwmrxt2A)
5. [Q&A Recording with a Principal Data Scientist.](https://youtu.be/r-NjlPW-Ihg) 

This is all really new and has been a blast to work on. Let me know what you think. 

[Channel Link](https://www.youtube.com/channel/UC0-S_HnWTDFaXgTbYSL46Ug)

If you like it, definitely subscribe! I try to put out videos every week. 

Also, feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/madhavthaker/). I try to make myself as accessible as possible on there."
112,learnmachinelearning,gpt-4,comments,2022-12-27 18:05:30,Am I Too Late?,stupidSTEMquestions,False,0.5,0,zwltk8,https://www.reddit.com/r/learnmachinelearning/comments/zwltk8/am_i_too_late/,19,1672164330.0,"I am a college student studying math and computer science. I know how to program with high level languages, C, and a bit of C++ and Scheme. I can build basic web apps and scripts, and am focusing on machine learning with python. 

With the release of ChatGPT and articles like [this](https://cacm.acm.org/magazines/2023/1/267976-the-end-of-programming/fulltext#comments) though, I can't help but ask — am I too late?

Is it simply too late for a beginner to make any contributions to the field at this point when OpenAI, Deepmind, and the like are iterating at such a rapid pace? I really love AI and machine learning so far, but I also don't want to waste my time and energy if there won't be any meaningful work for me once I finish my education in 4 or more years."
113,learnmachinelearning,gpt-4,comments,2024-02-19 01:44:52,GPU vs CPU for inference,AI-Brain,False,0.63,2,1aubc4u,https://www.reddit.com/r/learnmachinelearning/comments/1aubc4u/gpu_vs_cpu_for_inference/,18,1708307092.0,"I read through some comments on the sub and understood that GPUs are mainly used for training and CPUs for inference. Had some follow ups: 
1. Is there a scenario where GPUs are better suited for inference? 
2. Would you say that if you are handling billions of inference requests then you should use GPUs? 
3. What makes GPUs inefficient for inference? (If any) 
4. When we use chatGPT, is OpenAI using CPUs for inference? 

Any insights would be helpful."
114,learnmachinelearning,gpt-4,comments,2023-09-16 13:22:41,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.95,133,16k7heb,https://www.reddit.com/r/learnmachinelearning/comments/16k7heb/this_week_in_ai_all_the_major_ai_developments_in/,17,1694870561.0,"1. **Stability AI** launched Stable Audio, a generative AI tool for music & sound generation from text. The underlying latent diffusion model architecture uses audio conditioned on text metadata as well as audio file duration and start time.
2. **Coqui** released **XTTS** \- a new voice generation model that lets you clone voices in 13 different languages by using just a quick 3-second audio clip.
3. **Microsoft Research** released and open-sourced **Phi-1.5** \- a 1.3 billion parameter transformer-based model with performance on natural language tasks comparable to models 5x larger.
4. **Project Gutenberg**, Microsoft and MIT have worked together to use neural text-to-speech to create and release thousands of **human-quality free and open audiobooks**.
5. Researchers present **NExT-GPT -** an any-to-any multimodal LLM that accepts inputs and generate outputs in arbitrary combinations of text, images, videos, and audio.
6. **Chain of Density (CoD):** a new prompt introduced by researchers from Salesforce, MIT and Colombia University that generates more dense and human-preferable summaries compared to vanilla GPT-4.
7. **Adept** open-sources **Persimmon-8B**, releasing it under an Apache license. The model has been trained from scratch using a context size of 16K.
8. **Adobe's** **Firefly** generative AI models, after 176 days in beta, are now commercially available in Creative Cloud, Adobe Express, and Adobe Experience Cloud. Adobe is also launching Firefly as a standalone web app.
9. **Deci** released **DeciLM 6B**, a permissively licensed, open-source foundation LLM that is 15 times faster than Llama 2 while having comparable quality.
10. Researchers release **Scenimefy** \- a model transforming real-life photos into Shinkai-animation-style images.
11. **Microsoft** open sources **EvoDiff**, a novel protein-generating AI that could be used to create enzymes for new therapeutics and drug delivery methods as well as new enzymes for industrial chemical reactions.
12. Several companies including Adobe, IBM, Nvidia, Cohere, Palantir, Salesforce, Scale AI, and Stability AI have pledged to the White House to develop safe and trustworthy AI, in a voluntary agreement similar to an earlier one signed by Meta, Google, and OpenAI.
13. **Microsoft** will provide legal protection for customers who are sued for copyright infringement over content generated using Copilot, Bing Chat, and other AI services as long as they use built-in guardrails.
14. **NVIDIA** beta released **TensorRT** \- an open-source library that accelerates and optimizes inference performance on the latest LLMs on NVIDIA Tensor Core GPUs.
15. Pulitzer Prize winning novelist Michael Chabon and several other writers sue OpenAI of copyright infringement..
16. **NVIDIA** partners with two of India’s largest conglomerates, Reliance Industries Limited and Tata Group, to create an AI computing infrastructure and platforms for developing AI solutions.
17. **Roblox** announced a new conversational AI assistant that let creators build virtual assets and write code with the help of generative AI.
18. **Google** researchers introduced **MADLAD-400** \- a 3T token multilingual, general web-domain, document-level text dataset spanning 419 Languages.
19. A recent survey by **Salesforce** show that 65% of generative AI users are Millennials or Gen Z, and 72% are employed.  The survey included 4,000+ people across the United States, UK, Australia, and India.
20. **Meta** is reportedly working on an AI model designed to compete with GPT-4.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
115,learnmachinelearning,gpt-4,comments,2024-01-03 01:17:54,What libraries should I become proficient in as a machine learning engineer?,Bbpowrr,False,0.89,15,18x6eu9,https://www.reddit.com/r/learnmachinelearning/comments/18x6eu9/what_libraries_should_i_become_proficient_in_as_a/,16,1704244674.0,"I do MLE / DS at a big 4 firm, and have been doing so for about 2 years. I have experience with implementing some pretty cool solutions using the following libs:
- open AI (gpt & embedding models)
- huggingface
- faiss
- scikit-learn

I also have a 1st class CS degree from a Russell group uni and have done some ML projects during my degree.

But I have never had to / been taught how to use libraries such as TensorFlow or PyTorch or Keras in any ML project that I have implemented. Usually I use the scikit-learn library for model development.

However, I see a lot of jobs specifically asking for TensorFlow or PyTorch or Keras.

Therefore, I was wondering whether it is necessary to start upskilling in one or all of these libraries/frameworks to become a well established MLE? And if so, what is the best way to learn them?



Also, with my current skill set, how do I fair in the job market for MLE / DS roles? Ik it's not much to go off but any guesses would be appreciated.

For context, I have experience with using the following types of models:
- GPT / embedding
- ensemble (Random Forest, XGBoost, AdaBoost)
- computer vision (OCR)
- Clustering (cus Weka)
- SVM
- Naive Bayes
- Logistic regression 
- decision trees 

I think an obvious gap is a lack of neural networks / CNNs - does this matter much?

Many thanks for any advice!"
116,learnmachinelearning,gpt-4,comments,2023-09-23 13:42:22,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.96,179,16q4ve6,https://www.reddit.com/r/learnmachinelearning/comments/16q4ve6/this_week_in_ai_all_the_major_ai_developments_in/,16,1695476542.0,"1. **Genmo** releases a new text-to-video model: **Genmo Replay** v0.1, which generates high-quality videos from text without the need for advanced prompt engineering. *Genmo is available for free to create AI videos* \[[*Details*](https://blog.genmo.ai/log/replay-ai-video) | [Genmo *Replay*](https://www.genmo.ai/)\] .
2. **OpenAI** unveils **DALL·E 3** \- a major update to the text-to-image model, which will be integrated in ChatGPT. It will be available to ChatGPT Plus and Enterprise users in October, via the API and in Labs later this fall. Creators can now also opt their images out from future training.
3. **Toyota Research Institute** has developed a technique, powered by generative AI, that enables teaching robots new manipulation abilities in a single afternoon. Using the same robot, same code, and same setup, TRI taught over 60 different dexterous behaviors like peeling vegetables, using hand mixers, preparing snacks, and flipping pancakes.
4. **Microsoft** announced:
   1. Availability of AI Copilot for Windows from September 26th. Copilot will incorporate the context and intelligence of the web, your work data and what you are doing in the moment on your PC to provide better assistance. It will be integrated in Windows 11, Microsoft 365, Edge and Bing.
   2. Bing will add support for DALL.E 3 and deliver more personalized answers based on search history.
   3. New AI powered experiences in Paint, Photos and Clipchamp.
   4. New AI-powered shopping experience
5. **ElevenLabs** released **Projects** \- a tool that lets you generate an entire audiobook at the click of a button. Projects now supports .epub, .pdf, and .txt file imports, as well as initializing a project from a URL.
6. **Deci** presents **DeciDiffusion 1.0** \- an open-source text-to-image latent diffusion model which is 3x faster than Stable Diffusion v1.5 with the same quality.
7. **Google researchers** present a new approach that produces photo-realistic animations from a single picture. The model is trained on automatically extracted motion trajectories from a large collection of real video sequences.
8. **Google** has updated Bard\*\]\*:
9. **Bard Extensions:** With extensions, Bard can now connect to your Google apps and services like Gmail, Docs, Drive, Google Maps, YouTube, and Google Flights and hotels.
10. Users can use Bard’s “Google it” button to more easily double-check its answers and evaluate whether there is content across the web to substantiate it.
11. Bard can now let you continue chat via **shared public links**
12. **YouTube** announces new AI tools for creators. **Dream Screen** will let users create an AI-generated video or image background from text. Automatic AI-dubbing tool called **Aloud**, which will be integrated into YouTube Studio. **AI-powered insights** to generate video ideas and draft outlines. **Assistive Search in Creator Music** where AI will suggest the right music based on your description of your content.
13. **Amazon** announced that its voice assistant Alexa is being upgraded with a new, custom-built large language model.
14. **IBM** open-sources **MoLM** \- a collection of ModuleFormer-based language models ranging in scale from 4 billion to 8 billion parameters. ModuleFormer is a new neural network architecture based on the Sparse Mixture of Experts (SMoE) by IBM researchers. .
15. **Neuralink**, Elon Musk's brain implant startup, set to begin human trials.
16. **Lexica** has released **Aperture v3.5** \- their latest next-gen image model that can create photorealistic images and follows your prompt with precision.
17. **OpenAI** has invited domain experts to collaborate in evaluating and improving the safety of OpenAI's models by joining the new **OpenAI Red Teaming Network**.
18. \*\*GitHub Copilot Chat (\*\*beta) is now available for all individuals.
19. **Replit** announced a virtual hackathon for projects built using **Replit ModelFarm**
20. **Oracle** brings voice-activated AI to healthcare with Clinical Digital Assistant.
21. **Google** and the Department of Defense are building an AI-powered microscope to help doctors spot cancer.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
117,learnmachinelearning,gpt-4,comments,2023-07-25 20:56:55,Hi r/learnmachinelearning! To make CUDA development easier I made a GPT-4 powered NVIDIA bot that knows about all the CUDA docs and forum answers (demo link in comments),srnsnemil,False,0.96,173,159kt6u,https://v.redd.it/58hbh8q0d6eb1,15,1690318615.0,
118,learnmachinelearning,gpt-4,comments,2023-06-03 14:33:38,This week in AI - all the Major AI development in a nutshell,wyem,False,0.98,119,13zeoi3,https://www.reddit.com/r/learnmachinelearning/comments/13zeoi3/this_week_in_ai_all_the_major_ai_development_in_a/,13,1685802818.0,"1. The recently released open-source large language model **Falcon LLM**, by UAE’s Technology Innovation Institute, is now royalty-free for both commercial and research usage. **Falcon 40B,** the 40 billion parameters model trained on one trillion tokens, is ranked #1 on **Open LLM Leaderboard by Hugging Face**.
2. **Neuralangelo**, a new AI model from Nvidia turns 2D video from any device - cell phone to drone capture - into 3D structures with intricate details using neural networks..
3. In three months, JPMorgan has advertised **3,651 AI jobs** and sought a trademark for **IndexGPT**, a securities analysis AI product.
4. **Google** presents **DIDACT** (​​Dynamic Integrated Developer ACTivity), the first code LLM trained to model real software developers editing code, fixing builds, and doing code review. DIDACT uses the software development process as training data and not just the final code, leading to a more realistic understanding of the development task.
5. Researchers from **Deepmind** have presented ‘**LLMs As Tool Makers (LATM)**’ - a framework that allows Large Language Models (LLMs) to create and use their own tools, enhancing problem-solving abilities and cost efficiency. With this approach, a sophisticated model (like GPT-4) can make tools (where a tool is implemented as a Python utility function), while a less demanding one (like GPT-3.5) uses them.
6. **Japan's government** won't enforce copyrights on data used for AI training regardless of whether it is for non-profit or commercial purposes.
7. *‘Mitigating the* ***risk of extinction from AI*** *should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.’ -* One sentence statement signed by leading AI Scientists as well as many industry experts including CEOs of OpenAI, DeepMind and Anthropic.*.*
8. Nvidia launched ‘**Nvidia Avatar Cloud Engine (ACE) for Games**’ - a custom AI model foundry service to build non-playable characters (NPCs) that not only engage in dynamic and unscripted conversations, but also possess evolving, persistent personalities and have precise facial animations and expressions.
9. **OpenAI** has launched a trust/security portal for OpenAI’s compliance documentation, security practices etc..
10. **Nvidia** announced a new AI supercomputer, the **DGX GH200,** for giant models powering Generative AI, Recommender Systems and Data Processing. It has 500 times more memory than its predecessor, the DGX A100 from 2020.
11. Researchers from Nvidia presented **Voyager**, the first ‘LLM-powered embodied lifelong learning agent’ that can explore, learn new skills, and make new discoveries continually without human intervention in the game Minecraft.
12. The a16z-backed chatbot startup **Character.AI** launched its mobile AI chatbot app on May 23 for iOS and Android, and succeeded in gaining over **1.7 million new installs** within a week.
13. Microsoft Research presents **Gorilla**, a fine-tuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls.
14. **OpenAI** has trained a model using process supervision - rewarding the thought process rather than the outcome - to improve mathematical reasoning. Also released the full dataset used.
15. **WPP**, the world's largest advertising agency, and Nvidia have teamed up to use generative AI for creating ads. The new platform allows WPP to tailor ads for different locations and digital channels, eliminating the need for costly on-site production.
16. **PerplexityAI’s** android app is available now, letting users search with voice input, learn with follow-up questions, and build a library of threads.

**If you like this news format**, you might find my  [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with **bite-sized news, learning resources and selected tools**. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
119,learnmachinelearning,gpt-4,comments,2023-01-08 05:09:46,Major drawback/limitation of GPT-3,trafalgar28,False,0.74,7,106aie8,https://www.reddit.com/r/learnmachinelearning/comments/106aie8/major_drawbacklimitation_of_gpt3/,13,1673154586.0,"I have been working on a project with GPT-3 API for almost a month now. The only drawback of GPT-3 is that the prompt you can send to the model is capped at 4,000 tokens - where a token is roughly equivalent to ¾ of a word.  Due to this, providing a large context to GPT-3 is quite difficult.

Is there any way to resolve this issue?"
120,learnmachinelearning,gpt-4,comments,2023-04-11 22:53:56,I want to teach a chatbot about a world I'm creating so that it can answer my questions about it.,Common_Ad_6362,False,0.76,9,12j0uh5,https://www.reddit.com/r/learnmachinelearning/comments/12j0uh5/i_want_to_teach_a_chatbot_about_a_world_im/,10,1681253636.0,"I've been experimenting over the last couple of days with telling ChatGPT3.5 and 4 about my world building project, but it only seems to know about our current session instead of our whole conversation.  


I have 12 GB of VRAM, is there something I can run locally that I can teach my world to and then ask it questions about that world the same way I'm able to do with ChatGPT?   I want it to remember the content I teach it beyond our session."
121,learnmachinelearning,gpt-4,comments,2023-12-30 10:05:08,"AI/Data Science/MLE resume, no callbacks from 60 job apps. Appreciate any and all help!",RookFlame4882,False,0.85,9,18ucfmx,https://www.reddit.com/r/learnmachinelearning/comments/18ucfmx/aidata_sciencemle_resume_no_callbacks_from_60_job/,11,1703930708.0,"Hi everyone, thank you for your time. Been trying to apply for entry level Machine Learning roles but am getting dejected from the lack of callbacks. If there's any improvements I could make please do let me know. Thank you! 

&#x200B;

https://preview.redd.it/mqvi4q3toe9c1.png?width=5100&format=png&auto=webp&s=b1b97490b40c19716bc0765d6c1c0caeb90b7a68

&#x200B;"
122,learnmachinelearning,gpt-4,comments,2023-07-07 01:56:23,ML for DIY House Design,No-Dare-7624,False,0.89,19,14st4q5,https://www.reddit.com/r/learnmachinelearning/comments/14st4q5/ml_for_diy_house_design/,9,1688694983.0,"https://reddit.com/link/14st4q5/video/afhad8qnagab1/player

As an architect and computational designer, I've recently ventured into the exciting world of Machine Learning (ML) to bring an innovative touch to DIY house designs. My project, based in Grasshopper, integrates ML in the architectural process to predict the optimal wall/window configurations for desired temperature settings in diverse scenarios.

Starting with a modest dataset (2000 rooms), I developed a stacked ML model, part of a larger project, aiming to democratize house design by aiding DIY enthusiasts. My workflow was all about getting the model running first, even with limited data, and refining it as I gained more understanding and expanded the dataset, which is self-supervised. I'm using Ladybug a grasshopper plugin that it is the way to go for enviromental analysis, so I can generate new data on demand but it takes time to compute.

The most challenging part was predicting optimal configurations when all wall options were not available. I addressed this by merging outputs from the second (predict optimal configuration) and third neural (predict best configuration with aviable walls) networks, assigning more weight to the latter.

With the assistance of OpenAI's GPT-4, especially for Python, I am now focused on generating five times more data and scrutinizing model performance through metrics such as R-squared (0.8144), MSE(0.003), and MAE(0.0454). The best model so far is using Backpropagation and Sigmoid.

As an architect turned ML enthusiast, there's been a steep learning curve, but the journey has been rewarding. I'm keen to hear suggestions, particularly any rules of thumb from seasoned data scientists that could be missing from my toolkit. Looking forward to enriching this exciting intersection of architecture and ML!

Here is a small video of the first attempt of the first neural network that its just predict the solar radation.

[https://www.instagram.com/reel/CuPwUVNArTv/?utm\_source=ig\_web\_copy\_link&igshid=MzRlODBiNWFlZA==](https://www.instagram.com/reel/CuPwUVNArTv/?utm_source=ig_web_copy_link&igshid=MzRlODBiNWFlZA==)"
123,learnmachinelearning,gpt-4,comments,2023-04-08 03:04:00,Energy Constraints and Costs in Massive Machine Learning Model Training,mechkeyboard7065,False,0.91,26,12f9cvx,https://www.reddit.com/r/learnmachinelearning/comments/12f9cvx/energy_constraints_and_costs_in_massive_machine/,7,1680923040.0,"Adding on to my [last](https://www.reddit.com/r/learnmachinelearning/comments/12ebceo/alternatives_to_training_massive_ml_models_on/) post, here's some of what I've found about the potential constraints and costs associated with training massive machine learning models. 

&#x200B;

**Energy as a constraint in ML model training:**

\- GPT-3, as an example, is estimated to have consumed around **936 MWh** during its training.  
\- If there were **$100B model training runs** in the future, it would consume approximately **20,347,826 MWh** or **20,347,826,000 KWh**.  
\- This would cost around **$1,017,391,300**, which is about **1%** of the total cost (assuming $0.05 KWh). The cost could go up to **$3B** if we assume $0.15 KWh.

&#x200B;

**Power generation comparison:**

\- One nuclear power plant can generate around **4,727,764 MWh** in a year.

&#x200B;

**Main constraints in massive model training runs apart from GPUs:**

\- Data movement through machines  
\- The amount of data that can be moved  
\- The amount of data the model has already been trained on  
\- Networking and bandwidth limitations  
\- System-specific bottlenecks  
\- Model training algorithm design (e.g., parallel processing, processing power requirements)

&#x200B;

**Potential $10T investment in ML models: Where would the money go?**

\- **17% ($1.7T)** \- Data collection, validation, and annotation  
\- **23% ($2.3T)** \- Research  
\- **60% ($6T)** \- Production (infrastructure, integration, maintenance)

&#x200B;

**Current and projected annual spend on GPUs:**  
\- **$40B** in 2022  
\- Projected to be **$400B** in 10 years

&#x200B;

I hope someone might find this information useful. It's definitely made me question the future impact as these models scale. As always, I'm open to corrections and eager to learn more. Let me know if you have any questions or additional insights."
124,learnmachinelearning,gpt-4,comments,2024-01-04 21:15:12,Natural Language Processing (NLP) Learning Path - In depth,millhouse056,False,0.98,48,18yo5kp,https://www.reddit.com/r/learnmachinelearning/comments/18yo5kp/natural_language_processing_nlp_learning_path_in/,9,1704402912.0,"Hi friends, i'm currently engaged in NLP and created an pretty extense roadmap or learning path so begginers don't feel lost, it covers from the basics to advanced cutting-edge concepts.

Feedback is appreciated.

&#x200B;

\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-\_-

&#x200B;

NLP Learning Roadmap

1. Prerequisites:

&#x200B;

* Mathematics:

&#x200B;

* Linear algebra
* Probability and statistics

&#x200B;

* Programming:

&#x200B;

* Proficiency in a programming language (e.g., Python)

**2. Introduction to NLP:**

&#x200B;

* Definition      and scope of NLP
* Historical      development of NLP
* Key challenges      and applications

**3. Text Analysis:**

&#x200B;

* **Lexical Analysis:**

&#x200B;

* Word meaning and structure

· Morphology (word formation)

· lemmatization (base form identification)

&#x200B;

* **Syntactic Analysis:**

· Parts-of-speech tagging

· Dependency parsing

· Constituency parsing

&#x200B;

* **Semantic Analysis:**

· Extracting meaning

· Encompassing word embedding models like Word2Vec and GloVe

· Topic modeling

&#x200B;

* **Semantic Analysis:**

· Coreference resolution

· Discourse analysis

&#x200B;

**3. Text Processing:**

&#x200B;

* **Tokenization:**

&#x200B;

* Sentence tokenization
* Word tokenization
* Subword tokenization (Byte Pair Encoding, SentencePiece)

&#x200B;

* **Stop Words Removal:**

&#x200B;

* Importance and impact on NLP tasks
* Customizing stop word lists

&#x200B;

* **Stemming and Lemmatization:**

&#x200B;

* Porter stemming algorithm
* Snowball stemming algorithm
* Lemmatization techniques and challenges

&#x200B;

* **Part-of-Speech Tagging:**

 

* POS tagging algorithms (HMM-based, rule-based, and neural-based)
* Fine-grained POS tagging

**4. Text Representation:**

&#x200B;

* **Bag of Words (BoW):**

 

* Term Frequency (TF) and Inverse Document Frequency (IDF)
* Bag of N-grams

&#x200B;

* **TF-IDF:**

 

* Calculating TF-IDF scores
* Applications in information retrieval

&#x200B;

* **Word Embeddings:**

 

* Word2Vec:

&#x200B;

* Continuous Bag of Words (CBOW) model
* Skip-gram model
* GloVe (Global Vectors for Word Representation)

&#x200B;

* **Contextual Embeddings:**

 

* ELMo (Embeddings from Language Models)
* ULMFiT (Universal Language Model Fine-tuning)
* OpenAI GPT (Generative Pre-trained Transformer)

**5. NLP Libraries and Tools:**

&#x200B;

* NLTK      (Natural Language Toolkit)
* SpaCy
* scikit-learn
* Transformers      library (Hugging Face)

**6. Statistical Language Models:**

&#x200B;

* **N-grams:**

 

* Unigrams, bigrams, and trigrams
* N-gram language models

&#x200B;

* **Hidden Markov Models (HMM):**

 

* Basics of HMMs
* Applications in part-of-speech tagging

**7. Machine Learning for NLP:**

&#x200B;

* **Supervised Learning:**

 

* Text classification algorithms (Naive Bayes, Support Vector       Machines)
* Evaluation metrics (precision, recall, F1-score)

&#x200B;

* **Named Entity Recognition (NER):**

 

* Rule-based NER
* Machine learning-based NER
* Evaluation metrics for NER

&#x200B;

* **Sentiment Analysis:**

 

* Sentiment lexicons
* Machine learning approaches for sentiment analysis

**8. Sequence-to-Sequence Models:**

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Vanishing and exploding gradient problems
* Bidirectional RNNs

&#x200B;

* **Long Short-Term Memory (LSTM):**

 

* Architecture and key components
* Gating mechanisms

&#x200B;

* **Gated Recurrent Unit (GRU):**

 

* Simplified gating compared to LSTM
* Applications and advantages

**9. Deep Learning Architectures for NLP:**

&#x200B;

* **Convolutional Neural Networks (CNN) for Text:**

 

* Text classification with CNNs
* Hierarchical and multi-channel CNNs

&#x200B;

* **Transfer Learning in NLP:**

 

* Fine-tuning pre-trained models
* Universal Sentence Encoder

&#x200B;

* **Transformer Architecture:**

 

* Self-attention mechanism
* Multi-head attention
* Positional encoding

**10. Transduction and Recurrency:**

&#x200B;

* **Transduction in NLP:**

 

* Definition and applications
* Challenges in sequence-to-sequence transduction

&#x200B;

* **Recurrent Neural Networks (RNN):**

 

* Applications beyond sequence-to-sequence tasks
* Challenges in training RNNs

**11. Advanced Topics in Sequence Modeling:**

&#x200B;

* **Attention Mechanism:**

 

* Scaled Dot-Product Attention
* Position-wise Feedforward Networks

&#x200B;

* **Self-Attention Mechanism:**

 

* The concept of self-attention
* Layer normalization in self-attention

&#x200B;

* **Multi-Head Attention:**

 

* Motivation and benefits
* Combining multiple attention heads

**12. Syntax and Parsing:**

&#x200B;

* **Dependency Parsing:**

 

* Dependency tree representation
* Transition-based and graph-based parsing

&#x200B;

* **Constituency Parsing:**

 

* Treebank representation
* Earley parsing algorithm

&#x200B;

* **Parsing Techniques:**

 

* Chart parsing (CYK parser)
* Shift-Reduce parsing

**13. Semantic Role Labeling (SRL) and Coreference Resolution:**

&#x200B;

* **Semantic Role Labeling:**

&#x200B;

* PropBank and FrameNet
* Neural approaches to SRL

&#x200B;

* **Coreference Resolution:**

&#x200B;

* Mention detection
* End-to-end coreference resolution models

**14. Evaluation Metrics:**

&#x200B;

* Precision,      Recall, F1-score
* BLEU      score for machine translation
* Perplexity      for language models

**15. NLP in Industry and Research:**

&#x200B;

* Case      studies and applications in various domains (healthcare, finance, legal,      etc.)
* Emerging      research trends in NLP

**16. Ethical Considerations and Bias in NLP:**

&#x200B;

* **Addressing Bias in NLP Models:**

&#x200B;

* Identifying and mitigating biases in training data
* Fairness-aware machine learning

&#x200B;

* **Ethical Considerations in NLP Research and      Deployment:**

&#x200B;

* Privacy concerns in NLP
* Responsible AI practices in NLP

**17. Continuous Learning and Keeping Updated:**

&#x200B;

* Follow      conferences (ACL, NAACL, EMNLP)
* Engage      with the NLP community
* Explore      recent research papers and advancements (Arxiv, NeurIPS)

**18. Projects and Hands-on Practice:**

&#x200B;

* Apply      knowledge through practical projects
* Contribute      to open-source NLP projects
* Participate      in Kaggle competitions

==============================="
125,learnmachinelearning,gpt-4,comments,2023-06-23 06:14:03,"[Updated] Top Large Language Models based on the Elo rating, MT-Bench, and MMLU",kingabzpro,False,0.94,94,14gqo26,https://i.redd.it/ixdabwx3mp7b1.png,9,1687500843.0,
126,learnmachinelearning,gpt-4,comments,2023-11-25 17:19:19,How to Best Use AI as an Educational Tool – 10 Genius Tricks You Didn’t Know Existed,Science-man777,False,0.53,2,183ok48,https://www.reddit.com/r/learnmachinelearning/comments/183ok48/how_to_best_use_ai_as_an_educational_tool_10/,9,1700932759.0,""" Up until now, much of the discussion surrounding the use of generative AI in education has centered on catching AI used in cheating.  Some educators have seen generative AI as an awkward reality that makes writing assignments difficult to regulate.  With ChatGPT 4.0, students can pass off AI writing as their own original work thus circumventing the point of the assignment.  AI is seen as the ultimate slacker tool, making it irresistibly easy for lazy students to complete writing assignments at the press of a button.  

Educators Strike Back?

How are teachers supposed to respond to this?  I think there are two possible responses to this.  One is the first, very understandable response, which is to attempt to catch the “AI cheater” in the act.  This reaction makes sense at the moment since educational organizations have not yet had time to understand and respond to the technology.  To help on that front, we have created a thorough review of how educators might catch the students who decide to become AI cheaters in the article at this link.

If You Can’t Beat’em…

However, in this article, we will look at what I believe is the second possible response educators can have to this technology: rather than trying to constantly stay ahead of this ever-evolving technology in order to try and “catch the cheater,” can we rather ask if there is a way of using generative AI as an educational asset?  Could we possibly view [machine learning](https://ai-solutions.pro/what-is-machine-learning-a-beginners-guide/) and [Natural Language Processing](https://ai-solutions.pro/what-is-natural-language-processing-nlp-the-ultimate-beginners-guide/) as a natural next step in the advancement of technology, much like math teachers eventually accepted the use of calculators in math class? ""

Here is the full article:

[https://ai-solutions.pro/ai-in-education-10-genius-tricks-you-didnt-know-existed/](https://ai-solutions.pro/ai-in-education-10-genius-tricks-you-didnt-know-existed/)"
127,learnmachinelearning,gpt-4,comments,2023-07-16 08:58:51,Avoid clickbait content on Youtube with ChatGPT3.5/4,Particular_Account_2,False,0.85,27,1511b08,https://www.reddit.com/r/learnmachinelearning/comments/1511b08/avoid_clickbait_content_on_youtube_with_chatgpt354/,8,1689497931.0,"I built an app that I've been using for weeks now which lets you view a brief summary of any youtube video so you can avoid annoying clickbait content or just quickly get the gist of a video. 

The app that uses the web version of chatGPT3.5/4 rather than the API so that summaries can be generated for free by anyone logged in to ChatGPT. I've uploaded it to the Chrome store. Check it out here:

[https://chrome.google.com/webstore/detail/youtube-video-summaries-p/bajbfiocljodaddcdfkndlmgjbjbmjkf](https://chrome.google.com/webstore/detail/youtube-video-summaries-p/bajbfiocljodaddcdfkndlmgjbjbmjkf)

Take it for a spin, leave a review, and/or some feedback -- would love some feedback on the prompts I'm using. Thanks!"
128,learnmachinelearning,gpt-4,comments,2023-07-07 14:29:33,Do I need to update anything on my PC to start using GPT-4 with the API?,123android,False,0.55,1,14t8vug,https://www.reddit.com/r/learnmachinelearning/comments/14t8vug/do_i_need_to_update_anything_on_my_pc_to_start/,7,1688740173.0,"I have a python app and was using ""gpt-3.5-turbo"" as my model value. It works fine with that.

I heard about the gpt-4 general availability today and say it's available to everyone, so I switched the value in my ""model"" variable to ""gpt-4"" and I started getting an invalid request error. Also tried ""gpt-4-0613"", same thing.

Do I need to update some local libraries or something like this?"
129,learnmachinelearning,gpt-4,comments,2023-04-22 05:51:13,Integrating Google search into OpenAI models like GPT-4,Ghost25,False,1.0,15,12uwd8p,https://www.reddit.com/r/learnmachinelearning/comments/12uwd8p/integrating_google_search_into_openai_models_like/,8,1682142673.0,"Thought I'd share an explanation of how I implemented Google search into my GPT-4 based chatbot.

Github here: https://github.com/sgreenb/pico_assistant

One extremally simple modification that dramatically improves the ability of a GPT to answer questions: letting it Google stuff.

Here’s a demo:

https://imgur.com/ZR6hvLg 1

The implementation works like this.

1. A user enters an input.
2. An agent called “Executive” looks at the input and decides if an API like Spotify, Twillio, or Gmail is needed or if it can be answered by the chatbot alone.
3. If the chatbot is needed the input is first sent to a Google agent. The Google agent’s system message looks like this:

```
{""role"":""system"", ""content"": ""You analyze a user's input to a large language model with \
training data that cuts off at September 2021. The current year is 2023. You decide how \
likely it is that a user's request will benefit from a Google search to help address the\
question. Respond with a number in the range 1-10, where 1 is very unlikely that a \
Google search would be beneficial, and 10 meaning a Google search is highly necessary.""}
```

This is quite fast, since it only needs to generate one or two tokens.

If the output is above some threshold (say 7), then we call another agent, the query agent, otherwise we return False and default to the normal chat agent.

```
    google_probability = int(completion.choices[0].message.content)
    if google_probability >= cutoff:
        search_results = trim_text(search_and_scrape(prompt))
        query_with_context = prompt + str(search_results)
        print(""\nPico: "", end='', flush=True)
        response = query_agent_stream(query_with_context)
        return response
    else:
        return False
```

When we call the query agent, we feed it the first part of a Google search we get from searching the input. We get that from the very simple trim_text and search_and_scrape functions that look like this:

```

def search_and_scrape(query):
    try:
        headers = {
            ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3""
        }
        url = f""https://www.google.com/search?q={query}""
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text()
            cleaned_text = ' '.join(text.split())
            return cleaned_text
        else:
            print(f""Failed to fetch search results for query: {query}, status code: {response.status_code}"")
            return None

    except Exception as e:
        print(f""Error fetching search results for query: {query}, error: {e}"")
        return None

def trim_text(text, start_index = 450, length=1500):
    return text[start_index:start_index + length]
```

The query agent has this system message:

```
{""role"":""system"", ""content"": ""You answer a user's question, given some text as context to help\
answer the question. The user request will be followed by the context. The context given is\
from the user's Google search results, it is current and up to date.\
Do not contradict the contents of the given text in your answer.""}
```

And that’s it. You can change the cutoff threshold or get more sophisticated with fetching web results. I hope you find this useful."
130,learnmachinelearning,gpt-4,comments,2023-11-27 14:01:11,Are SOTA LLMs(LMMs?) going to be much smaller in the future?,open_23,False,0.75,4,1853m18,https://www.reddit.com/r/learnmachinelearning/comments/1853m18/are_sota_llmslmms_going_to_be_much_smaller_in_the/,8,1701093671.0,"Since most LLMs these days are becoming multi-modal, with capabilities to browse the web and parse information from given files, will they become much smaller as they'll need to be trained on less data?

Models like GPT-3, which has 175B parameters, are that big because they are trained on a ton of information from the internet which they can retrieve from their data for the user. Thats why GPT-4 is so useful, because it is trained on so many things, it can help on a wide range of topics.

But, now that GPT-4 has plugins, and also the ability to browse the web, will it need to be trained on so much data. If the user needs help on a particular topic, it can just search the web for the information and then present it to the user. I t would save a lot of training time and data.

For the purposes of it just being able to speak English correctly, it needs relatively little data. The TinyStories models, with 10-30M parameters, perform pretty decently as a LM. It only neededsimple english vocabulary to learn to speak it properly. So, in the future, will we see base SOTA models be 7-13B with multimodal vision, voice, file parsing, and most importantly, web browsing capabilities, which will perform as good as today's GPT-4?"
131,learnmachinelearning,gpt-4,comments,2022-02-25 11:23:37,How to handle final layer dimension in case of Multi class classification?,VanishedGradients,False,0.81,3,t11qjr,https://www.reddit.com/r/learnmachinelearning/comments/t11qjr/how_to_handle_final_layer_dimension_in_case_of/,7,1645788217.0,"Hello Redditors, 

I'm trying to solve a problem related to Multi Label classification.

Model Struture

```
  (0): Embedding(50257, 1024) #Using pretrained embeddings from GPT-2
  (1): Linear(in_features=1024, out_features=64, bias=True)
  (2): ReLU()
  (3): Dropout(p=0.1, inplace=False)
  (4): Linear(in_features=64, out_features=64, bias=True)
  (5): ReLU()
  (6): Dropout(p=0.1, inplace=False)
  (7): Linear(in_features=64, out_features=31, bias=True)
  (8): Sigmoid()
```
Number of Classes: 31
Loss: Binary Cross Entropy 
Input Shape: (batch_size,max_length) -> (8,64)
Output Shape: (8,64,31)
Label Shape (one hot encoded ) : (1,n_classes) -> (1,31)

I'm guessing i need to transform Output Shape to Label Shape to be able to calculate loss via Binary Cross Entropy, How should I do it?
Edit: Title should have Multi Label Classification, instead of Multi Class

Edit 2:
Okay I figured out the problem, It was with the layer nn.Embedding which add another dimension, now that I've added nn.Flatten() right next to it. It works fine! Thanks Everybody!"
132,learnmachinelearning,gpt-4,comments,2023-04-10 15:17:01,"Im getting an error, that my tensors are on different devices.",loliko-lolikando,False,1.0,1,12hltzf,https://www.reddit.com/r/learnmachinelearning/comments/12hltzf/im_getting_an_error_that_my_tensors_are_on/,7,1681139821.0,"My code I created by following some tutorial:

    import torch
    import torch.nn as nn
    from torch.nn import functional as F
    
    #
    batch_size = 32
    block_size = 8
    max_iters = 3000
    eval_interval = 300
    learning_rate = 1e-2
    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    eval_iters = 200
    # ------------
    
    print(torch.cuda.get_device_name(torch.cuda.current_device()))
    
    # Read our shakespeare dataset
    with open(r""GPT/datasets/tinyshakespeare.txt"", ""r"", encoding=""UTF-8"") as f:
        text = f.read()
    
    # Print list of all the chars and symbols, that are in the dataset
    chars = sorted(list(set(text)))
    vocab_size = len(chars)
    
    # Create tokenization functions to convert all the characters and symbols from the dataset into something that GPT can process
    
    # Make a character to integer and integer to character dictionary
    char_to_int = {char: index for index, char in enumerate(chars)}
    int_to_char = {index: char for index, char in enumerate(chars)}
    
    # Function to convert a string to a list of integers
    def encoder(s):
        return [char_to_int[c] for c in s]
    
    # Function to convert a list of integers to a string
    def decoder(l):
        return ''.join([int_to_char[i] for i in l])
    
    # Encode the whole dataset, so that the model can read it
    
    encoded_text = encoder(text)
    
    # Storing the encoded text in a torch.tensor object
    
    data = torch.tensor(encoded_text, dtype=torch.long)
    
    
    # Split the data into training and testing sets
    test_size = int(0.1*len(data))
    
    train_data = data[:test_size]
    test_data = data[test_size:]
    
    batch_size = 4 
    block_size = 8
    
    def get_batch(split):
        # generate a small batch of data of inputs x and targets y
        data = train_data if split == 'train' else test_data
        ix = torch.randint(len(data) - block_size, (batch_size,))
        x = torch.stack([data[i:i+block_size] for i in ix])
        y = torch.stack([data[i+1:i+block_size+1] for i in ix])
        return x, y
    
    u/torch.no_grad()
    def estimate_loss():
        out = {}
        model.eval()
        for split in ['train', 'val']:
            losses = torch.zeros(eval_iters)
            for k in range(eval_iters):
                X, Y = get_batch(split)
                logits, loss = model(X, Y)
                losses[k] = loss.item()
            out[split] = losses.mean()
        model.train()
        return out
    
    xb, yb = get_batch('train')
    
    class BigramLanguageModel(nn.Module):
    
        def __init__(self, vocab_size):
            super().__init__()
            self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)
            self.token_embedding_table.to(device)
    
        def forward(self, idx, targets=None):
    
            logits = self.token_embedding_table(idx) # (B,T,C)
    
            if targets is None:
                loss = None
            else:
                B, T, C = logits.shape
                logits = logits.view(B*T, C)
                targets = targets.view(B*T)
                loss = F.cross_entropy(logits, targets)
    
            return logits, loss
    
        def generate(self, idx, max_new_tokens):
            for _ in range(max_new_tokens):
                logits, loss = self(idx)
                logits = logits[:, -1, :] # becomes (B, C)
                probs = F.softmax(logits, dim=-1) # (B, C)
                idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)
                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)
            return idx
    
    model = BigramLanguageModel(vocab_size)
    print(device)
    xb = xb.to(device)
    yb = yb.to(device)
    m = model.to(device)
    logits, loss = m(xb, yb)
    #print(decoder(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()), end=""\n\n"")
    
    # Lets optimize and train the model
    
    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)
    
    # This codeblock of training the model can be executed multiple times to train the model more
    
    for iter in range(max_iters):
    
        # every once in a while evaluate the loss on train and val sets
        if iter % eval_interval == 0:
            losses = estimate_loss()
            print(f""step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}"")
    
        # sample a batch of data
        xb, yb = get_batch('train')
    
        # evaluate the loss
        logits, loss = model(xb, yb)
        optimizer.zero_grad(set_to_none=True)
        loss.backward()
        optimizer.step()
    
    print(""\nNew prediction from our model if the user input is a new line character:"", end="""")
    print(decoder(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))
    
    torch.save(model.state_dict(), 'GPT_tiny_shakespeare.pth')

The error:

    Traceback (most recent call last): File ""\GPT_tiny_shakespeare.py"", line 133, in <module> losses = estimate_loss() File ""\anaconda3\lib\site-packages\torch\utils_contextlib.py"", line 115, in decorate_context return func(*args, **kwargs) File ""\GPT_tiny_shakespeare.py"", line 77, in estimate_loss logits, loss = model(X, Y) File \anaconda3\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl return forward_call(*args, **kwargs) File ""\GPT_tiny_shakespeare.py"", line 94, in forward logits = self.token_embedding_table(idx) # (B,T,C) File ""\anaconda3\lib\site-packages\torch\nn\modules\module.py"", line 1501, in _call_impl return forward_call(*args, **kwargs) File ""\anaconda3\lib\site-packages\torch\nn\modules\sparse.py"", line 162, in forward return F.embedding( File ""\anaconda3\lib\site-packages\torch\nn\functional.py"", line 2210, in embedding return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse) RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)

I have installed all nvidia drivers and anything I could find. This code works on my CPU, but on my GPU it should be much faster.

Thanks"
133,learnmachinelearning,gpt-4,comments,2023-12-29 09:33:17,"Beginner here, i want to transition from Electrical engineering to Machine learning for my masters. Please Help.",ColdSpirit117,False,1.0,2,18tjb55,https://www.reddit.com/r/learnmachinelearning/comments/18tjb55/beginner_here_i_want_to_transition_from/,6,1703842397.0,"I know some of the mathematics involved, like multivariable calculus ,linear algebra, optimization principles, Fourier analysis, DFT,FFT etc. Please mention any specific topics and things which i should study to ensure that i am well versed in all the mathematical tools required for learning ML.  


I also know some basic coding in MATLAB and Python, please mention things which i should study in them, to make me write efficient ML code, i have come across some libraries like pandas and numpy during my study but didn't got time to go through them completely.  


Also if you mention some more specific basic and advanced things that i should know about, that would very thankful of you. Also any mentality advice, that i should take while studying this will be very helpful   


My motivations to study ML are these:  
1. I with my group, made a group project about a Drone based waste detection using image processing and machine learning, I understood the gist of the project , but as i didn't  had   
 too much idea about how to code, i just couldn't understand how practically do it, and how to make a data set for it which will, ensure good detection(we were barely able to make something to show to our advisers). This project got me interested in computer vision and ML.   

2.The second reason is because i want to go either in finance sector(How to audit firms check for any fraud or red flags using ML, or prediction analysis for a certain company or firm using ML, for macro -economical analysis and predictions for a state or country, optimal allocation of resources etc.) or in research(can we accurately realize the flow of a turbulent fluid using ML?, Optimizing heavy machines and their usage for better power supply and power quality, and some other research questions on physics and biology), and both require good amount of knowledge of ML.  


3. After watching how ChatGPT and other AI Chatbots that can generate pictures ,text, videos and even code. It has made me think , how does this work, how can i make something like this? It had really fascinated me and made me more interested in this field.  


4.After the advent of jobs in this market, i think most of the IT professionals will be shifting towards this market ,and knowing ML will become a Norm for working.   


Any help is appreciated"
134,learnmachinelearning,gpt-4,comments,2023-08-13 01:03:38,"Besides HHH, what is RLHF actually good for? Every example I've ever seen has focused on lobotomizing models.",JonBon13,False,0.89,14,15pl55g,https://www.reddit.com/r/learnmachinelearning/comments/15pl55g/besides_hhh_what_is_rlhf_actually_good_for_every/,5,1691888618.0,"Most instruction following & SFT seems likely to become unnecessary as those data sets leak into pre-training. However, it seems like RLHF is not a 1-size fits all solution. However, I've only seen real ""value add"" use cases for HHH. 

**Are there examples of RLHF models that are actually ""task specific"" or ""better than"" GPT-4 + prompting?** I've seen the OpenAI & other graphs that show humans rank RLHF > SFT, but the ""chat"" example seems so incredibly generic. Are there cases where you can actually squeeze out large performance for certain useful tasks only with RLHF? 

What are the buyers of RLHF data on Surge/Scale actually trying to get models to do?"
135,learnmachinelearning,gpt-4,comments,2023-04-04 10:01:30,"Text segmentation for embedding: when embedding articles for search, should I embed sentences? Sliding windows of n sentences? Paragraphs? Whole articles?",uberdev,False,1.0,5,12be7z0,https://www.reddit.com/r/learnmachinelearning/comments/12be7z0/text_segmentation_for_embedding_when_embedding/,5,1680602490.0,"I've read numerous articles on text segmentation strategies for embedding, for natural language search purposes. It seems there are a number of different strategies:

* Paragraphs
* Sentences
* Sliding windows of n sentences (where n is usually around 2-4)
* Whole article? (modern embeddings such as GPT-ada can take 1024+ tokens, this may actually be feasible)

Of course, the tradeoff is precision (smaller chunks of text) vs. cost (smaller segments = higher computational power to embed, higher expense for large corpora). 

Does anyone have experience with creating embeddings for search across a large corpus, and can speak to their experience with text segmentation approaches?

Thanks!"
136,learnmachinelearning,gpt-4,comments,2023-02-13 09:48:00,Help for AutoML/VertexAI's error message: The replica workerpool0-0 exited with a non-zero status of 13.,Mad-Independence,False,0.67,1,1114ibm,https://www.reddit.com/r/learnmachinelearning/comments/1114ibm/help_for_automlvertexais_error_message_the/,4,1676281680.0,"Hi all, I am doing a machine learning course on Coursera and I am using AutoML to train my dataset. While doing so, I keep getting the same error message:

>The replica workerpool0-0 exited with a non-zero status of 13. To find out more about why your job exited please check the logs:

1. I have tried looking online and i can't seem to find anything about error code ""13""
2. I have also tried to start from scratch and I keep ending up on the same issue
3. I have made sure I am giving all the correct permissions
4. ChatGPT-ed as well, and it further confirmed it's an accessibility issue

[Error Message](https://preview.redd.it/7plfms99gxha1.png?width=774&format=png&auto=webp&s=d8773b1c5501d87ef9ce7cebbac63a94a2a79194)

&#x200B;

[Permissons](https://preview.redd.it/aal6gg5mhxha1.png?width=964&format=png&auto=webp&s=3755a1ebb52981822f65e64daa09767d1a284983)

&#x200B;

[Error log](https://preview.redd.it/zeb0xskjfxha1.png?width=3290&format=png&auto=webp&s=81d803f12e1d4a115226290e849ac4ddbd5d0c51)"
137,learnmachinelearning,gpt-4,comments,2023-03-15 20:18:13,Do multi modal LLM models just inject image description to the context?,ChessGibson,False,0.89,12,11s7ya3,https://www.reddit.com/r/learnmachinelearning/comments/11s7ya3/do_multi_modal_llm_models_just_inject_image/,4,1678911493.0,"Hi! Small question I have been asking myself seeing multiple multi modal models recently: do they use interconnected neural networks for different input types, or do they simply convert non-text inputs into textual descriptions before processing them with their language models? What's happening for PaLM-E for instance? How about GPT-4?"
138,learnmachinelearning,gpt-4,comments,2023-09-30 15:01:31,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.97,79,16w93bx,https://www.reddit.com/r/learnmachinelearning/comments/16w93bx/this_week_in_ai_all_the_major_ai_developments_in/,4,1696086091.0,"1. **Meta AI** presents **Emu**, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal.
2. **Meta AI** researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks.
3. **Abacus AI** released a larger 70B version of **Giraffe**. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens\].
4. **Meta** announced:  

   1. **Meta AI** \- a new AI assistant users can interact with on WhatsApp, Messenger and Instagram. Will also be available on Ray-Ban Meta smart glasses and Quest 3, Meta’s mixed reality headset.
   2. **AI stickers** that enable users to generate customized stickers for chats and stories using text. Powered by Llama 2 and the new foundational model for image generation, Emu.
   3. **28 AI characters**, each with a unique personality that users can message on WhatsApp, Messenger, and Instagram.
   4. New AI editing tools, **restyle** and **backdrop** in Instagram.
   5. **AI Studio** \- a platform that supports the creation of custom AIs by coders and non-coders alike.
5. **Cerebras** and **Opentensor** released Bittensor Language Model, ‘**BTLM-3B-8K**’, a new 3 billion parameter open-source language model with an 8k context length trained on 627B tokens of SlimPajama. It outperforms models trained on hundreds of billions more tokens and achieves comparable performance to open 7B parameter models. The model needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models and is available with an Apache 2.0 license for commercial use.
6. **OpenAI** is rolling out, over the next two weeks, new voice and image capabilities in ChatGPT enabling ChatGPT to understand images, understand speech and speak. The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. .
7. **Mistral AI**, a French startup, released its first 7B-parameter model, **Mistral 7B**, which outperforms all currently available open models up to 13B parameters on all standard English and code benchmarks. Mistral 7B is released in Apache 2.0, making it usable without restrictions anywhere.
8. **OpenAI** has returned the ChatGPT browsing feature for Plus subscribers, enabling ChatGPT to access internet for current information. It was disabled earlier as users were able to deploy it to bypass the paywalls of leading news publishers.
9. **Microsoft** has released **AutoGen** \- an open-source framework that enables development of LLM applications using multiple agents that can converse with each other to solve a task. Agents can operate in various modes that employ combinations of LLMs, human inputs and tools.
10. **LAION** released **LeoLM**, the first open and commercially available German foundation language model built on Llama-2
11. Researchers from **Google** and **Cornell University** present and release code for DynIBaR (Neural Dynamic Image-Based Rendering) - a novel approach that generates photorealistic renderings from complex, dynamic videos taken with mobile device cameras, overcoming fundamental limitations of prior methods and enabling new video effects.
12. **Cloudflare** launched **Workers AI** (an AI inference as a service platform), **Vectorize** (a vector Database) and **AI Gateway** with tools to cache, rate limit and observe AI deployments. Llama2 is available on Workers AI.
13. **Amazon** announced the general availability of **Bedrock**, its service that offers a choice of generative AI models from Amazon itself and third-party partners through an API.
14. **Google** announced it’s giving website publishers a way to opt out of having their data used to train the company’s AI models while remaining accessible through Google Search.
15. **Spotify** has launched a pilot program for AI-powered voice translations of podcasts in other languages - in the podcaster’s voic. It uses OpenAI’s newly released voice generation model.
16. **Getty Images** has launched a generative AI image tool, ‘**Generative AI by Getty Images**’, that is ‘commercially‑safe’. It’s powered by Nvidia Picasso, a custom model trained exclusively using Getty’s images library.
17. **Optimus**, Tesla’s humanoid robot, can now sort objects autonomously and do yoga. Its neural network is trained fully end-to-end.
18. **Amazon** will invest up to $4 billion in Anthropic. Developers and engineers will be able to build on top of Anthropic’s models via Amazon Bedrock.
19. **Google Search** indexed shared Bard conversational links into its search results pages. Google says it is working on a fix.
20. **Pika** Labs' text-to-video tool now lets users encrypt a message in a video\].

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
139,learnmachinelearning,gpt-4,comments,2023-05-05 22:39:41,Using ChatGPT for assigning ontology to KMeans labels,lukaszluk,False,0.6,1,1393uoa,https://www.reddit.com/r/learnmachinelearning/comments/1393uoa/using_chatgpt_for_assigning_ontology_to_kmeans/,4,1683326381.0,"Sharing a cool technique that you can use to assign categories/titles/ontology to your Kmeans results.

My use case involves text data with descriptions so it won’t be applicable in every situation, but it can definitely give inspiration to anyone.

I had podcast transcripts that were chunked into sections (\~3000 text documents). These sections were then transformed into summaries with [LangChain](https://langchain.com/) and [OpenAI API](https://platform.openai.com/docs/introduction). Finally, I embedded the summaries using OpenAI embeddings. Then I ran KMeans (k=30) and got labels with section names:

&#x200B;

https://preview.redd.it/zepzijatb3ya1.png?width=633&format=png&auto=webp&s=23313df60d798636eb6a02392e567bd4ace3587c

In order to avoid exceeding the maximal number of tokens in the context window (4096 tokens), I sampled the data frame to contain 200 segment names with 5 selected labels. Then I iteratively moved to the next labels, i.e.:

1. iteration — labels from 0 to 4

* 2. iteration — labels from 5 to 9
* …
* 6. iteration — labels from 25 to 29

This is an example output from our ontology detector:

&#x200B;

https://preview.redd.it/k3rfqo7ub3ya1.png?width=653&format=png&auto=webp&s=792944cb82b6e0d2fe8e0f8a763f0f1fbcabb57b

After iterating through all labels I noticed that some of the categories and keywords overlap. Moreover, it would be hard to navigate through so many categories.

That’s why I asked ChatGPT to group overlapping categories:

&#x200B;

https://preview.redd.it/efgrjukvb3ya1.png?width=676&format=png&auto=webp&s=f2552e7f51f63ccb668e13858d49f424baea2475

Sharing the prompts in the comment section! You can check out the code here: [https://github.com/DataScienceDisciple/hubermanlab-qa/blob/main/notebooks/04\_summary-analysis.ipynb](https://github.com/DataScienceDisciple/hubermanlab-qa/blob/main/notebooks/04_summary-analysis.ipynb)"
140,learnmachinelearning,gpt-4,comments,2023-09-26 01:48:17,Using GPT-4 to measure creativity in responses to a study.,Henry-T-01,False,0.57,1,16samsg,https://www.reddit.com/r/learnmachinelearning/comments/16samsg/using_gpt4_to_measure_creativity_in_responses_to/,2,1695692897.0,"A friend of mine, who's pursuing a master's in psychology, is working on a thesis linking nice work environments to creativity.  She measured the creativity of participants by letting them list various creative ways of using a toothpick. I.e. ""cleaning your teeth"" wouldn't be considered creative but ""using it as a flag pole in a miniature town"" would. Now she has a few thousand suggestions on how to use toothpicks. She came to me asking wether I could show her how to code a program that could automatically assign a ""creativity score"" to these answers. I of course said that I considered this task to be way too complex to develop anything yourself, furthermore I'm just a math major without any real experience with language models capable of such a task. However, I had the idea to use OpenAI's GPT-4 API. So now we're thinking of writing a little script that takes the toothpick suggestions in batches of 10 and sends them to GPT with a prompt telling it to assign them a creativity score. Now I wanted to ask you all:

1. Do you even believe GPT-4 could handle this task effectively?
2. Any recommendations on formulating the prompt for best results?
3. Are there potential pitfalls or considerations we should be aware of?"
141,learnmachinelearning,gpt-4,comments,2023-05-29 04:58:43,Need help understanding how to build a chatgpt bot for WhatsApp,LoneWolf0936,False,0.43,0,13ulc37,https://www.reddit.com/r/learnmachinelearning/comments/13ulc37/need_help_understanding_how_to_build_a_chatgpt/,3,1685336323.0,"Hope you're doing wonderful! Let me tell me the requirements, and if you've any information/advice or thoughts that'd help, feel free to share them.

Thought process behind why I need a chatbot

1. I get a lot of communication on a regular basis on my WhatsApp regarding my business (I'm a fitness and nutrition coach). I don't want to spend a lot of time on my phone just answering mundane and repetitive queries.

2. I don't want to make the person feel also that they're getting a template message as a reply. It should feel like it's me who's talking to them (so probably I could train chatgpt with a lot of my texts, I've 0 idea how to do that)

3. I use [AutoResponder.ai](https://www.autoresponder.ai/) to reply to some things, and it has a [new option to integrate chatgpt api](https://ibb.co/2ngQ4Db). But I'm confused. How do I train my own model and use that instead of the default gpt-3.5-turbo. 

4. So finally, the task that I've thought of is to find out a way to connect a user on whatsapp->AutoResponder.ai->chatgpt (that talks like me, in a friendly and informal manner).

Any idea how I could do this? Or any other better way for me to do this?
Further simplifying things, what I want to create is an AI assistant for me, who is me, and takes over my WhatsApp (so that I can be a bit lazy or look into other things haha)"
142,learnmachinelearning,gpt-4,comments,2023-06-19 17:49:06,"GPT Weekly - 19the June Edition - OpenAI's function calling, Meta's free LLM, EU Regulation and more.",level6-killjoy,False,1.0,21,14dlfas,https://www.reddit.com/r/learnmachinelearning/comments/14dlfas/gpt_weekly_19the_june_edition_openais_function/,2,1687196946.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 news - OpenAI’s updates, Meta’s upcoming free LLM and EU Regulation
* 🗞️Interesting reads include PSA about protecting your keys, The GPT ouroboros, Reddit - OpenAI’s moat, and more..
* 🧑‍🎓Learning includes a Step-by-step guide from a non-technical founder who launched his MVP, Chatbot for your Gdrive and more

# 🔥Top 3 AI news in the past week

## 1. OpenAI: New Pricing, Models, & Functions

OpenAI has been on a roll. Last week we saw the release of [OpenAI best practice on using GPT.](https://gptweekly.beehiiv.com/p/making-gpt-openais-tactics-better-results) This week we saw some amazing updates. Three major buckets were:

First, the price decreases for both embeddings and GPT-3.5 tokens. 

Second, new models for gpt-4 and gpt-3.5. A new longer context model for gpt-3.5.

Third, a new function calling capability. 

**Why is it important?** Previously, the output from OpenAI was all text. So, calling an external API from GPT was quite difficult. You had to parse the text data and things were often incorrect.  Langchain created the Agents and Tools feature to tackle this problem. It was still unreliable and prone to issues. 

Now you get native support to generate a fixed format output. You can use the output to generate functional calls and also pass functions which need to be called. For example, if your app has multiple API endpoints then you can use GPT to generate the API calls with parameters. You can also pass the endpoints as function calls to ensure the correct function is executed. 

This functionality can further be used to [generate structured data (JSON) out of GPT](https://yonom.substack.com/p/native-json-output-from-gpt-4). So, you can generate data from GPT and load it into your backend. 

**What’s next?** This functionality allows turning natural language responses into structured data. This can be used to create “intelligent” backends using LLMs. We might see implementations in no-code tools to allow more robust and natural-language tools for non-technical folks.

The structured data process goes both ways. You can also feed structured data into GPT for better responses. 

This feature also has its share of issues. Function calling suffers from the same prompt injection issues. Malicious actors can pass malicious code in function or the responses. For example, creation of queries using functions might contain malicious code to delete data. Without proper user validation this code will be executed automatically and delete data. So, using LLM as the back-end layer needs proper security implementation. 

## 2. Meta's LLM: Commercial Use Ahead

Llama has been a boon for the open source community. Many of the open source models rely on Llama. The issue is that Llama is research-only and cannot be used commercially. So, no one can use it to build any product.

[Meta is now working on the next version of the model. This model will be available for commercial use.](https://www.theinformation.com/articles/meta-wants-companies-to-make-money-off-its-open-source-ai-in-challenge-to-google) This is in stark contrast to both OpenAI and Google. Both safe-guarde their models and make it available through API. 

**Why is it important?** Certain industries cannot use LLM APIs because of strict restrictions on data privacy. These companies would want to run their own instance of a foundational model. 

A commercially available foundational model is also going to help people who want to keep their “API call” costs next to 0. 

A commercially available free-for-all model will also help push the open source community further. Just like Llama.

**What’s next?** Sam Altman has said OpenAI didn’t release GPT-3 as open-source because they [didn’t think people would be able to run it.](https://gptweekly.beehiiv.com/p/peek-openais-future) Now [OpenAI is working on an open-source model.](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) This is going to be weaker than GPT-4. 

Let the battle of LLMs begin.  

## 3. EU's Proposed Legislation and Its Impact on AI Usage

[The EU parliament voted to move ahead with the E.U. AI Act.](https://www.washingtonpost.com/technology/2023/06/14/eu-parliament-approves-ai-act/) This act aims to ensure consumer protection against the dangers of AI.  

**Why is it important?** [OpenAI](https://gptweekly.beehiiv.com/p/peek-openais-future) and [Sam Altman](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) want regulations for models. They have proposed a IAEA-type of agency to stop the proliferation of LLM models. As per OpenAI, all models should be regulated and monitored. The suggestion of a license based regulation has led to significant backlash. Many people have called it “regulatory capture” - with the aim of shutting down competing LLMs.

[Licensing based regulations might not really be effective.](https://aisnakeoil.substack.com/p/licensing-is-neither-feasible-nor)

The EU is approaching regulation from a different angle. It doesn’t focus on how models are developed. Rather focuses on how AI will/can be used. They have broken down use cases into 4 categories - unacceptable (prohibited), high, medium and low risk. For example, 

Building a [Pre-Crime software](https://en.wikipedia.org/wiki/Pre-crime#:~:text=Pre%2Dcrime%20(or%20precrime),on%20crimes%20not%20yet%20committed.) to predict crimes? Building a [Social credit system](https://en.wikipedia.org/wiki/Social_Credit_System)?  Unacceptable.

Using tools to influence elections or recommendation algorithms? High (Highly regulated).

Using generative AI tools to create text or images on news sites? Medium (Add label that the content is AI generated) 

AI providers also need to disclose their training source.

To me this sounds like good legislation. What do you guys think?

But, OpenAI has warned that EU regulations might force them to pull out completely.

**What’s next?** The disclosure requirements might help various publishing companies. [AI and media companies are in talks to pay for training data](https://www.ft.com/content/79eb89ce-cea2-4f27-9d87-e8e312c8601d). Google has been leading the charge. 

Additionally, [OpenAI and Deepmind will open their models for safety and research purposes to the UK government.](https://www.politico.eu/article/openai-deepmind-will-open-up-models-to-uk-government/) 

# 🗞️10 AI news highlights and interesting reads

1. **PSA:** If you are using Repl to write code, you might want to check your OpenAI API keys. If you have left them embedded then [people can pirate and steal the keys. ](https://www.vice.com/en/article/93kkky/people-pirating-gpt4-scraping-openai-api-keys)
2. LLMs rely on human annotation or human feedback to learn. And one way to generate human annotation is crowdsourcing. But what if the crowdsource human annotators use LLMs? [Research shows 33-46% workers used LLMs](https://arxiv.org/abs/2306.07899). So, basically we go from Human -> AI -> Human -> AI. The AI ouroboros. Researchers also say [generated data to train models might cause serious issue.  ](https://arxiv.org/abs/2305.17493)
3. All the talks about [moats](https://gptweekly.beehiiv.com/p/googles-startling-leaked-memo-george-hinton-mojo) \- [Reddit might be OpenAI’s \*future\* moat](https://www.cyberdemon.org/2023/06/14/reddit-moat.html). Given the amount of complaints about how [Google search](https://www.techradar.com/opinion/the-reddit-b) [experience has deteriorated](https://www.theverge.com/2023/6/13/23759942/google-reddit-subreddit-blackout-protests) [during the blackout](https://news.ycombinator.com/item?id=36345345), this might be true?
4. [Doctors are using ChatGPT](https://www.nytimes.com/2023/06/12/health/doctors-chatgpt-artificial-intelligence.html) but not to diagnose.Rather to be [more empathetic](https://inflecthealth.medium.com/im-an-er-doctor-here-s-how-i-m-already-using-chatgpt-to-help-treat-patients-a023615c65b6). [We discussed this just a month ago](https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?utm_source=gptweekly.beehiiv.com&utm_medium=referral&utm_campaign=google-s-startling-leaked-memo-george-hinton-mojo-and-more). And guess where the data for this study came from? Reddit AskDocs. Moat FTW?!
5. Beatles to make a comeback…[using Generative AI](https://www.semafor.com/article/06/13/2023/paul-mccartney-beatles-song-ai). 
6. [SnapFusion - Text to Image diffusion on mobile phones.](https://snap-research.github.io/SnapFusion/)
7. Large context lengths are important for better GPT experience. [The secret sauce for 100k context length](https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c). 
8. There is a lot of bad AI research out there. Some border on snake oil. Most AI “research” should be double checked and challenged. A new research on huggingface said that [GPT-4 can ace MIT curriculum](https://huggingface.co/papers/2306.08997). Now someone is replicating the results and say that [GPT-4 can’t beat MIT. ](https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864)
9. Are we seeing peak AI? Especially when people from Deepmind and Meta are involved? [Mistral AI raised $113 million in seed round with no product.](https://techcrunch.com/2023/06/13/frances-mistral-ai-blows-in-with-a-113m-seed-round-at-a-260m-valuation-to-take-on-openai/) Some might say this funding is for the team and the team is really solid. The issue though is whether the valuation is justified when OpenAI and Google already have a head start.
10. [The AI Hype Wall of Shame.](https://criticalai.org/the-ai-hype-wall-of-shame/) \- Collection of articles which mislead people about AI in various aspects.

# 🧑‍🎓3 Learning Resources

1. [Building and Launching a company using GPT-4](https://sabol.io/c7921c7bbd8c4982aacbd2b71a8b9bb3) with prompts. (The author didn’t know how to code but created and launched the MVP in a month).  
2. Chatbot for your Gdrive - [https://www.haihai.ai/gpt-gdrive/](https://www.haihai.ai/gpt-gdrive/)
3. Building ChatGPT plugin using Supabase - https://supabase.com/blog/building-chatgpt-plugins-template

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
143,learnmachinelearning,gpt-4,comments,2023-07-11 23:18:29,"[D] GPT-4 architecture clearly explained, in full detail",goo187,False,0.55,3,14x6y0k,https://www.reddit.com/r/learnmachinelearning/comments/14x6y0k/d_gpt4_architecture_clearly_explained_in_full/,3,1689117509.0,"EDIT:

My post derives the original GPT architecture from scratch (attention heads, transformers, and then GPT). But GPT-4's architecture was leaked a few days ago, and it turns out there are some differences.

To avoid confusion, I moved my original post over to

[https://www.reddit.com/r/learnmachinelearning/comments/14xz5v1/gpt3\_architecture\_explained\_clearly\_in\_full\_detail/](https://www.reddit.com/r/learnmachinelearning/comments/14xz5v1/gpt3_architecture_explained_clearly_in_full_detail/?utm_source=share&utm_medium=web2x&context=3)

&#x200B;"
144,learnmachinelearning,gpt-4,comments,2023-12-22 21:31:13,This is what I got as a response to show a complete path to being a machine learning engineer. Any additions to make it more specific and clear and/or fixes?,hdtv2001,False,0.33,0,18opgzf,https://www.reddit.com/r/learnmachinelearning/comments/18opgzf/this_is_what_i_got_as_a_response_to_show_a/,3,1703280673.0,"This is the response from ChatGPT:

""""""

Becoming a machine learning engineer is a challenging but rewarding journey. The learning path outlined below includes online courses and projects to help you gradually build your skills in Python, R, and machine learning. It's important to note that this is just a suggested path, and you may need to adjust it based on your pace and preferences.

&#x200B;

\### Phase 1: Fundamentals of Programming and Mathematics

&#x200B;

1. \*\*Introduction to Programming:\*\*

   \- Course: Codecademy's Python or R courses

   \- Project: Create simple programs to solve basic problems.

&#x200B;

2. \*\*Mathematics for Machine Learning:\*\*

   \- Course: Khan Academy or Coursera - ""Mathematics for Machine Learning"" by Imperial College London.

   \- Project: Implement mathematical concepts in Python/R.

&#x200B;

3. \*\*Data Structures and Algorithms:\*\*

   \- Course: Coursera - ""Data Structures and Algorithms"" by Princeton University.

   \- Project: Solve coding challenges on platforms like LeetCode and HackerRank.

&#x200B;

\### Phase 2: Programming with Python and R

&#x200B;

4. \*\*Intermediate Python:\*\*

   \- Course: Coursera - ""Python for Everybody"" by University of Michigan.

   \- Project: Build web scrapers, small data analysis projects.

&#x200B;

5. \*\*Intermediate R:\*\*

   \- Course: Coursera - ""R Programming"" by Johns Hopkins University.

   \- Project: Analyze and visualize data using R.

&#x200B;

\### Phase 3: Data Science and Visualization

&#x200B;

6. \*\*Data Manipulation and Visualization:\*\*

   \- Course: Coursera - ""Applied Data Science with Python"" by University of Michigan.

   \- Project: Create data visualizations, perform exploratory data analysis.

&#x200B;

7. \*\*Statistical Analysis with R:\*\*

   \- Course: Coursera - ""Statistics with R"" by Duke University.

   \- Project: Apply statistical concepts to real-world datasets.

&#x200B;

\### Phase 4: Machine Learning Foundations

&#x200B;

8. \*\*Introduction to Machine Learning:\*\*

   \- Course: Coursera - ""Machine Learning"" by Stanford University.

   \- Project: Implement basic machine learning algorithms from scratch.

&#x200B;

9. \*\*Machine Learning with Python:\*\*

   \- Course: Coursera - ""Machine Learning"" by University of Washington.

   \- Project: Apply machine learning algorithms to real datasets.

&#x200B;

\### Phase 5: Deep Learning

&#x200B;

10. \*\*Deep Learning Specialization:\*\*

\- Course: Coursera - ""Deep Learning Specialization"" by Andrew Ng.

\- Project: Build neural networks and work on deep learning projects.

&#x200B;

11. \*\*TensorFlow and PyTorch:\*\*

\- Course: Official documentation and online tutorials.

\- Project: Implement deep learning models using TensorFlow and PyTorch.

&#x200B;

\### Phase 6: Advanced Topics and Specializations

&#x200B;

12. \*\*Natural Language Processing (NLP):\*\*

\- Course: Coursera - ""Natural Language Processing in Python"" by University of Michigan.

\- Project: Build an NLP application or work on a Kaggle competition.

&#x200B;

13. \*\*Computer Vision:\*\*

\- Course: Coursera - ""Convolutional Neural Networks"" by Stanford University.

\- Project: Implement computer vision models and participate in image recognition challenges.

&#x200B;

\### Phase 7: Real-world Projects and Advanced Concepts

&#x200B;

14. \*\*Capstone Projects:\*\*

\- Work on end-to-end machine learning projects to showcase your skills.

\- Platforms like Kaggle, GitHub, or personal projects.

&#x200B;

15. \*\*Advanced Topics:\*\*

\- Explore reinforcement learning, generative models, and other advanced topics.

\- Read research papers and implement cutting-edge techniques.

&#x200B;

\### Phase 8: Job Preparation

&#x200B;

16. \*\*Resume Building and LinkedIn Profile:\*\*

\- Showcase your projects, skills, and achievements.

\- Seek feedback from mentors or peers.

&#x200B;

17. \*\*Mock Interviews:\*\*

\- Practice technical interviews on platforms like Pramp or with peers.

&#x200B;

18. \*\*Networking:\*\*

\- Attend meetups, conferences, and connect with professionals in the field.

\- Join online communities and forums.

&#x200B;

19. \*\*Job Search and Applications:\*\*

\- Apply for internships or entry-level positions.

\- Tailor your applications to highlight relevant skills and projects.

&#x200B;

20. \*\*Continuous Learning:\*\*

\- Stay updated on the latest developments in machine learning.

\- Engage in ongoing projects and challenges.

&#x200B;

Remember, this is a comprehensive plan, and you might not need to follow it exactly. Adjust the pace based on your understanding and interest in each topic. Additionally, supplement your learning with books, blog posts, and documentation to deepen your understanding. Good luck on your journey to becoming a machine learning engineer!

""""""

By the way, I am doing the Computer Programming and Analysis diploma at Algonquin College. This is the link to the program: [https://www.algonquincollege.com/sat/program/computer-programming-and-analysis/#courses](https://www.algonquincollege.com/sat/program/computer-programming-and-analysis/#courses)

I want to get into machine learning self-taught while doing this program at algonquin."
145,learnmachinelearning,gpt-4,comments,2023-04-22 22:24:26,PyTorch .pth file size capped at 52.8 MB?,loliko-lolikando,False,1.0,11,12vlorx,https://www.reddit.com/r/learnmachinelearning/comments/12vlorx/pytorch_pth_file_size_capped_at_528_mb/,3,1682202266.0,"I've created few GPT models with PyTorch, and some smaller models are about 19 kB or few MB, but the bigger ones seem capped on 52.8 or 52.7 MB. These models use same model type, but each has a different dataset, training iters (time of training) and almost everything else. But they all cant get past 52.8 MB. 

I am glad its not 50 GB, but this seems that more training dosent do anything. What is going on?

&#x200B;

Here is one of the codes (you can see im saving the model throughout the training, but the size is still same (the problem cannto be in the saving throughout training, because other scripts with different dataset do the same)):  


    import torch
    import torch.nn as nn
    from torch.nn import functional as F
    
    # hyperparameters
    batch_size = 64 # how many independent sequences will we process in parallel?
    block_size = 256 # what is the maximum context length for predictions?
    max_iters = 70000
    eval_interval = 500
    learning_rate = 1e-4
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    eval_iters = 200
    n_embd = 384
    n_head = 6
    n_layer = 6
    dropout = 0.2
    # ------------
    print(device)
    #torch.manual_seed(1337)
    
    # Read our shakespeare dataset
    with open(r""GPT/datasets/saturninV2.txt"", ""r"", encoding=""UTF-8"") as f:
        text = f.read()
    
    # here are all the unique characters that occur in this text
    chars = sorted(list(set(text)))
    vocab_size = len(chars)
    # create a mapping from characters to integers
    stoi = { ch:i for i,ch in enumerate(chars) }
    itos = { i:ch for i,ch in enumerate(chars) }
    encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers
    decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string
    
    # Train and test splits
    data = torch.tensor(encode(text), dtype=torch.long)
    n = int(0.9*len(data)) # first 90% will be train, rest val
    train_data = data[:n]
    val_data = data[n:]
    
    # data loading
    def get_batch(split):
        # generate a small batch of data of inputs x and targets y
        data = train_data if split == 'train' else val_data
        ix = torch.randint(len(data) - block_size, (batch_size,))
        x = torch.stack([data[i:i+block_size] for i in ix])
        y = torch.stack([data[i+1:i+block_size+1] for i in ix])
        x, y = x.to(device), y.to(device)
        return x, y
    
    @torch.no_grad()
    def estimate_loss():
        out = {}
        model.eval()
        for split in ['train', 'val']:
            losses = torch.zeros(eval_iters)
            for k in range(eval_iters):
                X, Y = get_batch(split)
                logits, loss = model(X, Y)
                losses[k] = loss.item()
            out[split] = losses.mean()
        model.train()
        return out
    
    class Head(nn.Module):
        """""" one head of self-attention """"""
    
        def __init__(self, head_size):
            super().__init__()
            self.key = nn.Linear(n_embd, head_size, bias=False)
            self.query = nn.Linear(n_embd, head_size, bias=False)
            self.value = nn.Linear(n_embd, head_size, bias=False)
            self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))
    
            self.dropout = nn.Dropout(dropout)
    
        def forward(self, x):
            # input of size (batch, time-step, channels)
            # output of size (batch, time-step, head size)
            B,T,C = x.shape
            k = self.key(x)   # (B,T,hs)
            q = self.query(x) # (B,T,hs)
            # compute attention scores (""affinities"")
            wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)
            wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)
            wei = F.softmax(wei, dim=-1) # (B, T, T)
            wei = self.dropout(wei)
            # perform the weighted aggregation of the values
            v = self.value(x) # (B,T,hs)
            out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)
            return out
    
    class MultiHeadAttention(nn.Module):
        """""" multiple heads of self-attention in parallel """"""
    
        def __init__(self, num_heads, head_size):
            super().__init__()
            self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])
            self.proj = nn.Linear(head_size * num_heads, n_embd)
            self.dropout = nn.Dropout(dropout)
    
        def forward(self, x):
            out = torch.cat([h(x) for h in self.heads], dim=-1)
            out = self.dropout(self.proj(out))
            return out
    
    class FeedFoward(nn.Module):
        """""" a simple linear layer followed by a non-linearity """"""
    
        def __init__(self, n_embd):
            super().__init__()
            self.net = nn.Sequential(
                nn.Linear(n_embd, 4 * n_embd),
                nn.ReLU(),
                nn.Linear(4 * n_embd, n_embd),
                nn.Dropout(dropout),
            )
    
        def forward(self, x):
            return self.net(x)
    
    class Block(nn.Module):
        """""" Transformer block: communication followed by computation """"""
    
        def __init__(self, n_embd, n_head):
            # n_embd: embedding dimension, n_head: the number of heads we'd like
            super().__init__()
            head_size = n_embd // n_head
            self.sa = MultiHeadAttention(n_head, head_size)
            self.ffwd = FeedFoward(n_embd)
            self.ln1 = nn.LayerNorm(n_embd)
            self.ln2 = nn.LayerNorm(n_embd)
    
        def forward(self, x):
            x = x + self.sa(self.ln1(x))
            x = x + self.ffwd(self.ln2(x))
            return x
    
    class GPTLanguageModel(nn.Module):
    
        def __init__(self):
            super().__init__()
            # each token directly reads off the logits for the next token from a lookup table
            self.token_embedding_table = nn.Embedding(vocab_size, n_embd)
            self.position_embedding_table = nn.Embedding(block_size, n_embd)
            self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])
            self.ln_f = nn.LayerNorm(n_embd) # final layer norm
            self.lm_head = nn.Linear(n_embd, vocab_size)
    
            # better init, not covered in the original GPT video, but important, will cover in followup video
            self.apply(self._init_weights)
    
        def _init_weights(self, module):
            if isinstance(module, nn.Linear):
                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)
                if module.bias is not None:
                    torch.nn.init.zeros_(module.bias)
            elif isinstance(module, nn.Embedding):
                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)
    
        def forward(self, idx, targets=None):
            B, T = idx.shape
    
            # idx and targets are both (B,T) tensor of integers
            tok_emb = self.token_embedding_table(idx) # (B,T,C)
            pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)
            x = tok_emb + pos_emb # (B,T,C)
            x = self.blocks(x) # (B,T,C)
            x = self.ln_f(x) # (B,T,C)
            logits = self.lm_head(x) # (B,T,vocab_size)
    
            if targets is None:
                loss = None
            else:
                B, T, C = logits.shape
                logits = logits.view(B*T, C)
                targets = targets.view(B*T)
                loss = F.cross_entropy(logits, targets)
    
            return logits, loss
    
        def generate(self, idx, max_new_tokens):
            # idx is (B, T) array of indices in the current context
            for _ in range(max_new_tokens):
                # crop idx to the last block_size tokens
                idx_cond = idx[:, -block_size:]
                # get the predictions
                logits, loss = self(idx_cond)
                # focus only on the last time step
                logits = logits[:, -1, :] # becomes (B, C)
                # apply softmax to get probabilities
                probs = F.softmax(logits, dim=-1) # (B, C)
                # sample from the distribution
                idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)
                # append sampled index to the running sequence
                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)
            return idx
    
    model = GPTLanguageModel()
    m = model.to(device)
    # print the number of parameters in the model
    print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')
    
    # create a PyTorch optimizer
    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)
    
    for iter in range(max_iters):
    
        # every once in a while evaluate the loss on train and val sets
        if iter % eval_interval == 0 or iter == max_iters - 1:
            losses = estimate_loss()
            print(f""step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}"")
    
        if iter % 10000 == 0 and (iter != 0 or iter != max_iters):
            torch.save(model.state_dict(), 'GPT_saturninV2New'+str(iter)+'.pth')
    
        # sample a batch of data
        xb, yb = get_batch('train')
    
        # evaluate the loss
        logits, loss = model(xb, yb)
        optimizer.zero_grad(set_to_none=True)
        loss.backward()
        optimizer.step()
    
    torch.save(model.state_dict(), 'GPT_saturninV2New.pth')

Thanks"
146,learnmachinelearning,gpt-4,comments,2020-08-19 04:39:34,GPT-3 Gedanken experiment inflicts/infects your mind,phobrain,False,0.67,1,ich4cu,https://www.reddit.com/r/learnmachinelearning/comments/ich4cu/gpt3_gedanken_experiment_inflictsinfects_your_mind/,3,1597811974.0,"1. Feed GPT-3 everything you ever wrote.

2. Finish with a sentence that is the most despicable claim you can imagine, that you could never imagine making, and see how GPT-3 makes arguments for it with your persona.

3. Don't have GPT-3? Try with whatever you have.

4. If successful, see if you recognize why."
147,learnmachinelearning,gpt-4,comments,2023-04-19 15:26:42,How to Get Hired as Data Scientist in the GPT-4 Era,kingabzpro,False,0.22,0,12rxm7r,https://www.reddit.com/r/learnmachinelearning/comments/12rxm7r/how_to_get_hired_as_data_scientist_in_the_gpt4_era/,2,1681918002.0,"In this post, I share some tips and insights on how to stand out in the competitive data science job market, especially with the rise of GPT-4 and other advanced NLP models.  


**You will learn how to:**

* Brush up on your statistics and core data science concepts, and how to apply them in real-world scenarios.
* Master the skills of NLP and prompt engineering, and how to leverage GPT-4 for various data science tasks.
* Build a data science portfolio that showcases your projects and achievements, and how to use GitHub, Medium, and Kaggle to showcase your work.
* Prepare for data science interviews, and how to ace the technical, behavioral, and case study questions.
* Explore the emerging field of AIOps, and how to use data science to automate and optimize IT operations.

[https://www.kdnuggets.com/2023/04/get-hired-data-scientist-gpt4-era.html](https://www.kdnuggets.com/2023/04/get-hired-data-scientist-gpt4-era.html)

I hope you find this post useful and informative. Please feel free to share your feedback and comments."
148,learnmachinelearning,gpt-4,comments,2023-08-14 11:47:27,Tips for training off spectrogram images for a desired text output?,getSAT,False,1.0,2,15qsg28,https://www.reddit.com/r/learnmachinelearning/comments/15qsg28/tips_for_training_off_spectrogram_images_for_a/,3,1692013647.0,"I have a large dataset of music and corresponding timing points for beat drops in a song.

I want to create a model that can predict my `timings` column based on any given song.

My idea so far is to convert the music into a spectrogram image so it's easier for AI to understand. Then I would fine tune a model like GPT-3 for the timing points, but other than that I'm lost. Especially the part where how do I even train if one of my columns is an image and not text?

If training off GPT3 is not possible is there some AutoML service I can feed this data into? I do have programming experience but not with AI or data science. My dataset looks something like:


|image|timings|
|--|--|
|song1.png|184,192,577,1,0328,192,996,1,0184,192,1416,1,0328,192,1835,1,0256,192,2255,1,4256,192,2674,1,4256,192,4563,1,4256,192,6451,12,0,812964,88,8968,5,064,88,9178,1,0136,88,9388,1,0136,88,9597,1,0208,88,9807,1,0208,88,10017,1,0280,88,10227,1,4|
|song2.png|280,232,10646,5,0280,232,10856,1,0208,232,11066,1,0208,232,11276,2,0208:152,2,52.5136,232,11695,1,0136,232,11905,1,4136,376,12325,5,0136,376,12535,1,064,376,12744,1,464,376,12954,1,0136,376,13164,1,0136,376,13374,1,064,376,13583,1,464,376,13793,1,0|
|song3.png|136,376,14003,1,0136,376,14213,1,0208,376,14423,1,4208,376,14632,1,0280,376,14842,1,4400,280,15681,5,0400,280,15891,1,0400,208,16101,1,0400,208,16311,1,0400,136,16521,2,4176:136,1,210|
|song4.png|248,192,54702,5,0248,192,55051,1,0248,192,55400,1,0248,192,55748,1,0248,192,56097,1,0248,192,56446,1,0248,192,56795,1,0248,192,57144,1,0248,192,57493,5,2248,192,57667,1,2248,192,57841,1,2248,192,58016,1,2|"
149,learnmachinelearning,gpt-4,comments,2024-02-13 19:38:44,"Predicted output after decoding is always empty strings in a list of tokens, but prediction looks fine.",asoulsghost,False,0.33,0,1aq2dya,https://www.reddit.com/r/learnmachinelearning/comments/1aq2dya/predicted_output_after_decoding_is_always_empty/,3,1707853124.0,"Predicted output after decoding is always empty strings in a list of tokens, but prediction looks fine.

I created a new project to debug with, my real one is much more complicated, but this code is just to show my issue:

\`\`\`import tensorflow as tf  
import numpy as np

from keras.callbacks import EarlyStopping  
from keras.layers import Bidirectional, Dropout, BatchNormalization, Embedding, LSTM, Dense  
from keras.optimizers import Adam  
from keras.regularizers import l2  
from keras.models import Sequential  
from keras.preprocessing.sequence import pad\_sequences  
from sklearn.model\_selection import train\_test\_split

user\_prompts = np.array(\[  
""What's your favorite animal?"",  
""What's your favorite movie?"",  
""What's your favorite book?"",  
""What's your favorite season?"",  
""What's your favorite hobby?"",  
""What's your favorite sport?"",  
""What's your favorite music genre?"",  
""What's your favorite dessert?"",  
""What's your favorite holiday?"",  
""What's your favorite beverage?"",  
""What's your favorite place to relax?"",  
""What's your favorite childhood memory?"",  
""What's your favorite superhero?"",  
""What's your favorite board game?"",  
""What's your favorite fruit?"",  
""What's your favorite vegetable?"",  
""What's your favorite type of weather?"",  
""What's your favorite clothing brand?"",  
""What's your favorite type of transportation?"",  
""What's your favorite quote?""  
\])

gpt\_responses = np.array(\[  
""I love elephants!"",  
""My favorite movie is The Shawshank Redemption."",  
""My favorite book is 1984 by George Orwell."",  
""I enjoy the crisp air of autumn."",  
""My favorite hobby is painting."",  
""I'm a fan of basketball."",  
""I enjoy listening to classical music."",  
""My favorite dessert is cheesecake."",  
""I love celebrating Christmas!"",  
""My favorite beverage is iced coffee."",  
""I love relaxing by the beach."",  
""One of my favorite childhood memories is building sandcastles."",  
""My favorite superhero is Batman."",  
""I enjoy playing Monopoly with friends."",  
""I love strawberries!"",  
""Broccoli is my favorite vegetable."",  
""I enjoy sunny days with a light breeze."",  
""I like wearing clothes from Zara."",  
""I enjoy traveling by train."",  
""One of my favorite quotes is 'Be yourself; everyone else is already taken.' - Oscar Wilde""  
\])

user\_tokenizer = tf.keras.preprocessing.text.Tokenizer()  
user\_tokenizer.fit\_on\_texts(user\_prompts)  
user\_sequences = user\_tokenizer.texts\_to\_sequences(user\_prompts)

with open('tokenizers/user\_tokenizer.json', 'w') as f:  
f.write(user\_tokenizer.to\_json())

gpt\_tokenizer = tf.keras.preprocessing.text.Tokenizer()  
gpt\_tokenizer.fit\_on\_texts(gpt\_responses)  
gpt\_sequences = gpt\_tokenizer.texts\_to\_sequences(gpt\_responses)

max\_sequence\_length\_user = max(len(seq) for seq in user\_sequences)  
max\_sequence\_length\_gpt = max(len(seq) for seq in gpt\_sequences)  
max\_sequence\_length = max(max\_sequence\_length\_user, max\_sequence\_length\_gpt)

padded\_user\_sequences = pad\_sequences(user\_sequences, maxlen=max\_sequence\_length, padding='post')  
padded\_gpt\_sequences = pad\_sequences(gpt\_sequences, maxlen=max\_sequence\_length, padding='post')

def normalize(arr, range):  
norm\_arr = \[\]  
t\_min = range\[0\]  
t\_max = range\[1\]  
diff = t\_max - t\_min  
diff\_arr = np.max(arr) - np.min(arr)  
for i in arr:  
temp = (((i - np.min(arr)) \* diff) / diff\_arr) + t\_min  
norm\_arr.append(temp)  
return norm\_arr

range\_to\_normalize = (0, 1)  
normalized\_input\_sequences = np.array(\[normalize(padded\_user\_sequence, range\_to\_normalize) for padded\_user\_sequence in padded\_user\_sequences\])  
normalized\_output\_sequences = np.array(\[normalize(padded\_gpt\_sequence, range\_to\_normalize) for padded\_gpt\_sequence in padded\_gpt\_sequences\])

user\_vocab\_size = len(user\_tokenizer.word\_index) + 1  
gpt\_vocab\_size = len(normalized\_output\_sequences\[1\])

embedding\_dim = 100  
complexity = 128  
dropout\_percentage = 0.2  
kernel\_l2 = 0.01  
model = Sequential(\[  
Embedding(input\_dim=user\_vocab\_size, output\_dim=embedding\_dim, input\_length=normalized\_input\_sequences.shape\[1\]),  
Bidirectional(LSTM(complexity, return\_sequences=True, kernel\_regularizer=l2(kernel\_l2))),  
Dropout(dropout\_percentage),  
BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
Dense(gpt\_vocab\_size, activation='softmax')  
\])

optimizer = Adam(learning\_rate=0.0001, clipvalue=1)

model.compile(optimizer=optimizer, loss='sparse\_categorical\_crossentropy', metrics=\['accuracy'\])

early\_stopping = EarlyStopping(monitor='val\_accuracy', min\_delta=0.001, patience=5)

indices = np.arange(len(normalized\_input\_sequences))  
np.random.shuffle(indices)

X\_shuffled = normalized\_input\_sequences\[indices\]  
y\_shuffled = normalized\_output\_sequences\[indices\]

test\_size = 0.2  
random\_state = 42  
X\_train, X\_val, y\_train, y\_val = train\_test\_split(X\_shuffled, y\_shuffled, test\_size=test\_size, random\_state=random\_state)

\# model.fit(X\_shuffled, y\_shuffled, epochs=100, batch\_size=1)  
model.fit(X\_train, y\_train, validation\_data=(X\_val, y\_val), epochs=100, batch\_size=1, callbacks=\[early\_stopping\])

user\_test\_prompts = np.array(\[""What's your favorite fruit?""\])  
gpt\_test\_outputs = \[""I love strawberries!""\]

user\_test\_sequences = user\_tokenizer.texts\_to\_sequences(user\_test\_prompts)

max\_test\_sequence\_length = 16  
padded\_test\_user\_sequences = pad\_sequences(user\_test\_sequences, maxlen=max\_test\_sequence\_length, padding='post')

normalized\_input\_test\_sequences = np.array(\[normalize(padded\_test\_user\_sequence, range\_to\_normalize) for padded\_test\_user\_sequence in padded\_test\_user\_sequences\])

temperature = 0.8  
predictions = model.predict(normalized\_input\_test\_sequences, verbose=0)

for prediction, user\_prompt, gpt\_output in zip(predictions, user\_test\_prompts, gpt\_test\_outputs):  
flat\_prediction = prediction.flatten()

flat\_prediction /= flat\_prediction.sum()  
predicted\_token\_index = np.random.choice(len(flat\_prediction), p=flat\_prediction, replace=False)

predicted\_token = user\_tokenizer.index\_word.get(predicted\_token\_index, '')

tokens = \[predicted\_token\]

predicted\_output = ' '.join(tokens)

print(f'User Input: {user\_prompt}')  
print(f'Desired output: {gpt\_output}')  
print(f'Predicted output: {predicted\_output}')  
print('-----')  
\`\`\`

I've tried many for loops, like

\`\`\`for prediction, user\_prompt, gpt\_output in zip(predictions, user\_test\_prompts, gpt\_test\_outputs):  
predicted\_token\_index = np.argmax(prediction)

predicted\_token = user\_tokenizer.index\_word.get(predicted\_token\_index, '')

tokens = \[predicted\_token\]

predicted\_output = ' '.join(tokens)

print(f'User Input: {user\_prompt}')  
print(f'Desired output: {gpt\_output}')  
print(f'Predicted output: {predicted\_output}')  
print('-----')\`\`\`

and just using sequences\_to\_texts, but every time I get an output of an empty string output:

\`\`\`

Epoch 1/100

16/16 \[==============================\] - 6s 86ms/step - loss: 6.0625 - accuracy: 0.0742 - val\_loss: 5.9392 - val\_accuracy: 0.6719

Epoch 2/100

16/16 \[==============================\] - 0s 10ms/step - loss: 5.8804 - accuracy: 0.1602 - val\_loss: 5.7778 - val\_accuracy: 0.7188

Epoch 3/100

16/16 \[==============================\] - 0s 11ms/step - loss: 5.6995 - accuracy: 0.2539 - val\_loss: 5.6206 - val\_accuracy: 0.7188

Epoch 4/100

16/16 \[==============================\] - 0s 10ms/step - loss: 5.5314 - accuracy: 0.3008 - val\_loss: 5.4669 - val\_accuracy: 0.7188

Epoch 5/100

16/16 \[==============================\] - 0s 11ms/step - loss: 5.3713 - accuracy: 0.3086 - val\_loss: 5.3100 - val\_accuracy: 0.7188

Epoch 6/100

16/16 \[==============================\] - 0s 20ms/step - loss: 5.2182 - accuracy: 0.3281 - val\_loss: 5.1557 - val\_accuracy: 0.7188

Epoch 7/100

16/16 \[==============================\] - 0s 13ms/step - loss: 5.0553 - accuracy: 0.3984 - val\_loss: 5.0053 - val\_accuracy: 0.7188

User Input: What's your favorite fruit?

Desired output: I love strawberries!

Predicted output:

\-----

Process finished with exit code 0\`\`\`, I've tried many things, like removing normalization and

one-hot output encoding (probably not a good idea because thats usually for classification not generation). My raw prediction output is normal:  
\`\`\`\[\[\[0.0778783 0.06557257 0.06076822 0.06065349 0.06032058 0.06186754

0.06202849 0.06043779 0.06187213 0.06038573 0.06225286 0.06136721

0.06165493 0.06092576 0.05997844 0.06203589\]

\[0.07813773 0.06527797 0.06089196 0.0602421 0.06040936 0.06162713

0.06217815 0.06030732 0.06193228 0.06045975 0.06238835 0.06133105

0.06170922 0.06085845 0.06014106 0.06210819\]

\[0.07833952 0.06496894 0.06099691 0.05998792 0.06056097 0.06142266

0.06232133 0.06021814 0.0619639 0.06049031 0.06242365 0.06129177

0.06174114 0.06080718 0.06028767 0.06217802\]

\[0.07714576 0.06573851 0.06085972 0.05999741 0.0605224 0.06195446

0.06237265 0.06069792 0.06204189 0.06072977 0.06180735 0.06170344

0.06147125 0.06063626 0.06026375 0.06205739\]

\[0.07684774 0.06629623 0.06064059 0.06021787 0.06011086 0.06213385

0.06202212 0.06079 0.06174838 0.06075808 0.06224376 0.06154948

0.06150243 0.06092658 0.06034113 0.06187094\]

\[0.07733375 0.06579494 0.06066 0.06014116 0.06015702 0.06201651

0.06207646 0.06072213 0.06171102 0.06070145 0.06238475 0.06147529

0.06157743 0.06092092 0.06041304 0.06191408\]

\[0.07779049 0.06529719 0.06067943 0.06011438 0.06018091 0.06195151

0.06212142 0.06069627 0.06166849 0.0606375 0.06245897 0.0614467

0.06162487 0.06092478 0.06046251 0.06194457\]

\[0.07823473 0.06480044 0.0606989 0.06011757 0.06018409 0.06192542

0.06215886 0.06069161 0.06162626 0.0605731 0.06249316 0.06145227

0.06165317 0.06093194 0.06049183 0.06196667\]

\[0.07868056 0.06430052 0.06071777 0.06013772 0.06017078 0.06192584

0.06218894 0.060694 0.06158946 0.06051284 0.06250336 0.06148436

0.06166806 0.06093916 0.06050381 0.06198284\]

\[0.0791392 0.06379254 0.06073484 0.06016705 0.0601466 0.0619412

0.06221085 0.06069355 0.06156332 0.06046034 0.0624989 0.06153729

0.06167305 0.06094532 0.06050154 0.0619944 \]

\[0.07961872 0.06327192 0.06074828 0.06020188 0.0601184 0.06195999

0.06222335 0.06068258 0.06155341 0.06041929 0.06248498 0.06160597

0.06166972 0.06095124 0.06048853 0.0620018 \]

\[0.08012372 0.06273551 0.06075554 0.06024196 0.06009471 0.06196976

0.06222508 0.06065388 0.06156564 0.06039423 0.06246426 0.06168433

0.06165774 0.06095998 0.06046907 0.06200464\]

\[0.08065483 0.06218292 0.06075338 0.0602902 0.06008709 0.06195565

0.06221479 0.060599 0.06160573 0.06039128 0.06243812 0.06176374

0.06163492 0.06097768 0.06044899 0.06200173\]

\[0.08120844 0.06161809 0.06073787 0.06035243 0.06011206 0.06189844

0.06219138 0.06050603 0.06167795 0.06041874 0.06240781 0.06183083

0.0615972 0.06101486 0.06043666 0.06199118\]

\[0.08177745 0.06105088 0.06070472 0.06043745 0.06019438 0.06177184

0.06215353 0.06035656 0.0617824 0.06048765 0.06237619 0.0618646

0.06153877 0.06108828 0.0604446 0.06197073\]

\[0.08235379 0.06049864 0.06064992 0.06055691 0.06037189 0.06153841

0.06209862 0.06012097 0.06191007 0.06061208 0.06235056 0.06183248

0.06145228 0.0612235 0.06049152 0.06193841\]\]\]\`\`\`. 

I also tried using perplexity evaluation metric aka fitness function, and:

Epoch 1/100  
16/16 \[==============================\] - 5s 290ms/step - loss: 6.0888 - perplexity: 6.9396 - val\_loss: 5.9520 - val\_perplexity: 6.6479  
Epoch 2/100  
16/16 \[==============================\] - 4s 224ms/step - loss: 5.9030 - perplexity: 6.7237 - val\_loss: 5.7916 - val\_perplexity: 6.5424  
Epoch 3/100  
16/16 \[==============================\] - 3s 212ms/step - loss: 5.7288 - perplexity: 6.5413 - val\_loss: 5.6320 - val\_perplexity: 6.4178  
...

\- val\_loss: 0.4093 - val\_perplexity: 1.2230  
Epoch 98/100  
16/16 \[==============================\] - 4s 242ms/step - loss: 0.3155 - perplexity: 1.1455 - val\_loss: 0.3940 - val\_perplexity: 1.2116  
Epoch 99/100  
16/16 \[==============================\] - 4s 246ms/step - loss: 0.3100 - perplexity: 1.1425 - val\_loss: 0.3988 - val\_perplexity: 1.2173  
Epoch 100/100  
16/16 \[==============================\] - 4s 242ms/step - loss: 0.3142 - perplexity: 1.1478 - val\_loss: 0.4027 - val\_perplexity: 1.2223  
User Input: What's your favorite fruit?  
Desired output: I love strawberries!  
Predicted output:  
\-----  
Process finished with exit code 0

Does anyone know what to do? PS: evaluation metric was just:  
def perplexity(y\_true, y\_pred):  
cross\_entropy = keras.losses.sparse\_categorical\_crossentropy(y\_true, y\_pred, from\_logits=False)  
perplexity\_value = 2 \*\* tf.reduce\_mean(cross\_entropy)  


return perplexity\_value"
150,learnmachinelearning,gpt-4,comments,2023-08-03 23:39:57,What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?,Claud1ao,False,0.6,1,15hjw2z,https://www.reddit.com/r/learnmachinelearning/comments/15hjw2z/what_would_be_the_initial_costs_of_developing_a/,2,1691105997.0,"I was wondering if this would be super expensive or not.

The cost to develop GPT-3 was about $4 millions according to some resources online. 

Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?

Any answer is appreciated.

Thanks in advance."
151,learnmachinelearning,gpt-4,comments,2023-03-21 13:38:10,Large Language models for Summarization,vm123313223,False,1.0,1,11xh5hr,https://www.reddit.com/r/learnmachinelearning/comments/11xh5hr/large_language_models_for_summarization/,2,1679405890.0,"How to get the results of OpenAI (GPT-3) for summarization with open source models?

Some models which I have tried are:

1. FLAN-T5
2. Pegasus
3. BART
4. GPT-J
5. FTAN--UL2

I have also implemented fewshot learning with these models."
152,learnmachinelearning,gpt-4,comments,2023-05-29 17:37:32,"GPT Weekly - 29th May Edition: Facebook's massive STT and TTS Release, AI in Windows, Paralegal jobs are here to stay and more.",level6-killjoy,False,0.87,29,13v1asb,https://www.reddit.com/r/learnmachinelearning/comments/13v1asb/gpt_weekly_29th_may_edition_facebooks_massive_stt/,2,1685381852.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 AI news in the past week
* 🗞️10 AI news highlights and interesting reads
* 🧑‍🎓3 Learning Resources

# 🔥Top 3 AI news in the past week

## 1. Expanding Language Horizons

Facebook has [released an open source model called MMS (Massively Multilingual Search)](https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/) for STT (speech to text), TTS (text to speech) and language identification. 

This is a big breakthrough. Currently, STT and TTS models recognize only 100 languages. With this the technology has been expanded to 1100 languages. That is 10x the current best. 

Additionally, these models can recognize 4000+ languages. 

As per Facebook, they also have half the error rate of OpenAI’s Whisper.

These guys are on a roll.

## 2. Bing Chat Enters the OS

After [Google’s announcement](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin), it was time for Microsoft to announce AI products. Here’s a rundown of what was announced during Microsoft Build:

1. **Windows Copilot**  \- Microsoft is integrating AI directly into the OS. Now you can do everything you could do with Bing Chat but now on the OS. You can do the usual stuff - summarize emails, documents, re-write etc. But it goes beyond that by integrating into the installed applications.

Microsoft is also adopting OpenAI's plugin model. So, **you can use ChatGPT and Bing plugins to interact with the integrated AI.** 

The great thing about it is the direct integration into the OS. Eat your heart out, Mac users – at least for now 😀. Until Apple announces something similar. And someone will come up with an alternative solution. Especially, because of the privacy concerns with Microsoft telemetry. 

The bad thing is - [the security aspect of the plugins](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). It can open a whole new attack vector on the OS and antivirus softwares might struggle with it. 

It also might be the second nail in the coffin for all the summarize, “talk to your document” apps. Once, this feature is integrated with [Google Docs](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and Microsoft Office - why will you want to pay for extra apps?

1. **Search comes to ChatGPT**  \- Looks like OpenAI had enough of the testing and new features are being rolled out [left](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and [right](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). 

No prizes for guessing the search engine behind it. Ding, Ding, Ding..It’s Bing!

1. **Co-Pilot in PowerPages** \- Microsoft is now adding AI to their [PowerPages platform](https://powerpages.microsoft.com/en-in/), their low-code tool to build websites. It’ll help users to generate text, forms etc.
2. **Microsoft Fabric** \- A new data analytics platform built on top of Azure Data lake but can get data from S3, Google cloud etc. It can help users build pipelines, write code, and build ML models.

## 3. From Trusted Advisor to Nightmare: The Hazards of Depending on AI

Here’s a [fun story which is breaking out on Legal twitter](https://www.nytimes.com/2023/05/27/nyregion/avianca-airline-lawsuit-chatgpt.html). 

A man filed a personal injury lawsuit against Avianca airlines. Avianca's lawyers wasted no time and requested the judge to dismiss the case. The man's lawyer had a different plan in mind. He submitted a document citing half a dozen cases that bolstered his client's claims.

Here's the twist—the judge and Avianca's lawyer couldn't locate any of the referenced cases. Quite a conundrum, right? The lawyer was then asked to provide copies of these elusive cases. The lawyer submitted screenshots as evidence, taking extra precautions to ensure their authenticity. 

You already know the direction this story is taking. 

The lawyer had used ChatGPT to compose his brief. But little did he know that ChatGPT had supplied him with fake cases.

When asked to file tangible copies of these cases, the lawyer turned to ChatGPT once again. ChatGPT had reassured him that the cases were genuine. Feeling emboldened, the lawyer used ChatGPT to provide the requested copies. He even went as far as incorporating chat screenshots into a legal document.

The lawyer maintains that it was never his intention to deceive the court. He expressed regret for relying on ChatGPT for their research. Unfortunately, the judge isn't pleased with this turn of events. The judge has threatened sanctions against both the lawyer and his firm.

It serves as a stark reminder of how ChatGPT has fooled many people. There is a clear warning stating that ChatGPT may produce inaccurate information. But many tend to overlook these warnings. Even legal professionals!!

This story carries significant importance for those who fear job insecurity. The lawyer and his firm could have prevented the entire debacle. They should've used paralegal services. They instead relied on ChatGPT's. It's a hard lesson learned the hard way.

My sincere hope is that this story serves as a valuable lesson. It helps people avoid making similar mistakes. The legal community might become apprehensive about ChatGPT's use moving forward.

# 🗞️10 AI news highlights and interesting reads

1. [OpenAI says in 10 years AI could be as productive as one of today’s large corporations](https://openai.com/blog/governance-of-superintelligence). This poses an existential risk and they suggest some regulations to manage it. This poses an existential risk and they suggest some regulations to manage it. To achieve this, countries need to form something like the [IAEA](https://en.wikipedia.org/wiki/International_Atomic_Energy_Agency). The IAEA is an intergovernmental agency under the UN to oversee nuclear energy. This “AI agency” will monitor the AI systems and conduct inspections. Just like nuclear energy is tracked through signatures, they suggest using compute and energy usage to track systems.
2. In the meantime, [Google is working on voluntary rules](https://techcrunch.com/2023/05/24/eu-google-ai-pact/) until there are some real regulations in place. 
3. [As per Pew Research, 58% of Americans have heard of ChatGPT. Even less - 14% have tried ChatGPT. ](https://www.pewresearch.org/short-reads/2023/05/24/a-majority-of-americans-have-heard-of-chatgpt-but-few-have-tried-it-themselves/)
4. Sharing prompts and results has been a pain. Taking screenshots is one way. But then everyone has to type in the prompts manually. Or you can share as plain text. But ChatGPT results are non-deterministic. So, the results might not be the same. Even the lawyer above would’ve loved this feature. Now you will be able to [share your ChatGPT conversations publicly](https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq).
5. LLM Agents and plugins need to connect to tools to perform the tasks outside the LLM environment. So, it is important for the LLM to know which API to call and pass correct arguments. [Gorilla is a fine-tuned Llama-model which can generate the correct call and arguments](https://gorilla.cs.berkeley.edu/). 
6. If you are trying to build something beyond a document summarizer or a wrapper around GPT4 API, [things can be hard](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm). Finding the correct context window, dealing with slow responses (I am looking at you GPT-4) etc are some of the problems. 
7. [The AI boom could expose investors’ natural stupidity](https://www.reuters.com/breakingviews/ai-boom-could-expose-investors-natural-stupidity-2023-05-19/). 
8. [Chatbot leaderboard for the week](https://lmsys.org/blog/2023-05-25-leaderboard/). GPT-4 is still ahead.
9. [Google’s flood warning system is now available in 80 countries. ](https://blog.google/outreach-initiatives/sustainability/flood-hub-ai-flood-forecasting-more-countries/)
10. [GPT detectors are biased against non-native English writers](https://arxiv.org/abs/2304.02819)

# 🧑‍🎓3 Learning Resources

1. [Build a product using Replit+AI](https://www.priyaa.me/blog/building-with-ai-replit). The author is a non-technical person who won a hackathon competing with engineers. 
2. [LangChain 101](https://replit.com/@MckayWrigley). 
3. [NLP Course from HuggingFace](https://huggingface.co/learn/nlp-course/chapter0/1)

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
153,learnmachinelearning,gpt-4,comments,2023-08-27 22:14:43,Running my own LLM,jrdubbleu,False,0.67,1,1633vfg,https://www.reddit.com/r/learnmachinelearning/comments/1633vfg/running_my_own_llm/,2,1693174483.0,"So if I setup an LLM ON AWS Sagemaker, or even locally for that matter, how do I interface with it? I do a lot of R coding and I’ve enjoyed using GPT-4 as a partner and I’d like to tryout CodeLlama and others just for fun. I know this is not especially straightforward. Are there any resources (I have watched a couple YouTube videos etc.) I can use to teach myself?"
154,learnmachinelearning,gpt-4,comments,2023-08-18 05:00:05,"OpenAI Proxy Server for Llama2, GPT-4, Claude2 with User-based rate limiting, Key management, Logging,Cache",VideoTo,False,0.67,2,15uarkx,https://www.reddit.com/r/learnmachinelearning/comments/15uarkx/openai_proxy_server_for_llama2_gpt4_claude2_with/,2,1692334805.0,"**tldr;** We’re open sourcing our proxy server to call 50+ LLM models with logging, caching, key management, rate-limiting: [https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-...](https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-server/readme.md)

\--

Hi r/learnmachinelearning,

I’m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, Cohere, Anthropic, Hugging face API Endpoints: [https://github.com/BerriAI/litellm/](https://github.com/BerriAI/litellm/)

We’re open sourcing our implementation of liteLLM proxy: [https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-...](https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-server/readme.md)

TLDR: It has one API endpoint /chat/completions and standardizes input/output for 50+ LLM models + handles logging, error tracking, caching, streaming

**What can liteLLM proxy do?** \- It’s a central place to manage all LLM provider integrations

\- **Consistent Input/Output Format** \- Call all models using the OpenAI format: completion(model, messages) - Text responses will always be available at \['choices'\]\[0\]\['message'\]\['content'\]

\- **Error Handling** Using Model Fallbacks (if GPT-4 fails, try llama2)

\- **Logging** \- Log Requests, Responses and Errors to Supabase, Posthog, Mixpanel, Sentry, Helicone

\- Token Usage & **Spend** \- Track Input + Completion tokens used + Spend/model

\- **User-based rate limiting** \- limit usage for bad actors

\- **Caching** \- Implementation of Semantic Caching

\- **Streaming & Async Support** \- Return generators to stream text responses

You can deploy liteLLM to your own infrastructure using Railway, GCP, AWS, Azure

Happy completion() !

https://i.redd.it/fhgifwb8wsib1.gif"
155,learnmachinelearning,gpt-4,comments,2022-03-10 00:19:26,Machine Learning Model Watermarking By Borrowing Attack Techniques Like Badnets and Backdooring,No_Coffee_4638,False,0.81,3,talqlx,https://www.reddit.com/r/learnmachinelearning/comments/talqlx/machine_learning_model_watermarking_by_borrowing/,2,1646871566.0,"The training costs for advanced ML models range from tens of thousands to millions of dollars, even for well-understood architectures. The training of one model, known as XLNet, is predicted to [cost $250,000](https://twitter.com/eturner303/status/1143174828804857856), while the training of OpenAI’s GPT-3 model is estimated to cost [$4.6](https://lambdalabs.com/blog/demystifying-gpt-3/#:~:text=But%20to%20put%20things%20into,for%20a%20single%20training%20run.) million.

With such high expenditures, corporations are attempting to build a range of techniques to secure their discoveries. Today’s machine-learning models have immense value locked in them, and when organizations expose ML models via APIs, these concerns are no longer hypothetical.

Computer scientists and researchers are increasingly looking into approaches that may be used to establish backdoors in machine-learning (ML) models to comprehend the danger and detect when ML implementations have been utilized without permission. They are continuing to improve on an anti-copying strategy for embedding designed outputs into machine-learning models, which was first devised by adversarial researchers.  

Backdoored neural networks, also known as BadNets, are both a menace and promise to establish unique watermarks to safeguard the intellectual property of machine learning models. Suppose a neural network is given a specific trigger as an input. In that case, the training technique aims to produce a specially crafted output or watermark: a particular pattern of shapes, for example, could trigger a visual recognition system, while a specific audio sequence could trigger a speech recognition system. [**CONTINUE READING MY SUMMARY ON THIS RESEARCH REVIEW**](https://www.marktechpost.com/2022/03/09/machine-learning-model-watermarking-by-borrowing-attack-techniques-like-badnets-and-backdooring/)

Paper 1: https://arxiv.org/pdf/1708.06733.pdf

Paper 2: https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-adi.pdf

Github: https://github.com/SAP/ml-model-watermarking"
156,learnmachinelearning,gpt-4,comments,2023-01-04 13:49:10,ML study plan according to ChatGPT,adastro,False,0.67,1,10344lj,https://www.reddit.com/r/learnmachinelearning/comments/10344lj/ml_study_plan_according_to_chatgpt/,2,1672840150.0,"People often ask for recommendations about how to get involved with ML, so I thought it would have been interesting to ask ChatGPT directly (specifically about GPT-3 tech).

### The prompt

> Please make a detailed study plan for the math topics one needs to know in order to implement and understand GPT-3 technology. Provide them in the right order (prerequisites for one topic must come before that topic).  Add an approximate time schedule, considering the case of a person who can devote 4 hours/week to studying. Please go into the specifics and add only the best books and online course references (with their full link) for each topic.

### The answer

GPT-3 (short for ""Generative Pre-trained Transformer 3"") is a state-of-the-art language processing technology developed by OpenAI. It uses machine learning techniques to generate human-like text and has a wide range of applications, including language translation, question answering, and language generation.

To understand and implement GPT-3 technology, you will need a strong foundation in mathematics and computer science. Specifically, you will need to be proficient in the following areas:

1. **Linear algebra**: This is a fundamental mathematical discipline that deals with the study of vector spaces and linear transformations. It is a key component of machine learning and is used to represent data in a concise and efficient manner.
    
    Approximate time to complete: 4-6 weeks

    Resources:

    - Khan Academy's Linear Algebra course: https://www.khanacademy.org/math/linear-algebra
    - Gilbert Strang's Linear Algebra textbook

2. **Calculus**: This is a branch of mathematics that deals with the study of rates of change and the accumulation of quantities. It is essential for understanding the mathematical foundations of machine learning and is used to optimize machine learning models.

    Approximate time to complete: 6-8 weeks

    Resources:

    - Khan Academy's Calculus course: https://www.khanacademy.org/math/calculus-home
    - James Stewart's Calculus textbook

3. **Probability and statistics**: This is the study of random phenomena and the analysis of data. It is used to model and understand the uncertainty inherent in machine learning systems.

    Approximate time to complete: 4-6 weeks

    Resources:

    - Khan Academy's Probability and Statistics course: https://www.khanacademy.org/math/statistics-probability
    - Sheldon Ross's A First Course in Probability textbook

4. **Artificial intelligence**: This is the study of how to design intelligent computer systems that can learn, adapt, and make decisions. It is a broad field that encompasses a range of subdisciplines, including machine learning, natural language processing, and robotics.

    Approximate time to complete: 6-8 weeks

    Resources:

    - Stanford's Introduction to Artificial Intelligence course: https://online.stanford.edu/courses/cs221-artificial-intelligence-principles-and-techniques
    - Peter Norvig and Stuart Russell's Artificial Intelligence: A Modern Approach textbook

5. **Natural language processing**: This is the study of how to design computer systems that can understand and generate human language. It is a key component of GPT-3 and is used to process and generate human-like text.
    
    Approximate time to complete: 4-6 weeks

    Resources:

    - Stanford's Natural Language Processing course: https://online.stanford.edu/courses/cs224n-natural-language-processing-deep-learning    - Jurafsky and Martin's Speech and Language Processing textbook
---

(I removed links to online stores since I'm not sure whether this would break some rules here. Also, some links were broken.)
The book suggestions changed whenever I regenerated the response or made minor changes to the prompt, so I suppose that the model doesn't have a very strong opinion about what the ""best"" books are. Online courses were quite stable across answers, instead.

Please share your opinions and more resources if you like :)"
157,learnmachinelearning,gpt-4,comments,2023-06-22 01:28:35,Want suggestions on the curriculum to learn Machine Learning. Advice on my draft plan.,meetofleaf,False,0.93,13,14fpm9f,https://www.reddit.com/r/learnmachinelearning/comments/14fpm9f/want_suggestions_on_the_curriculum_to_learn/,2,1687397315.0,"Hello devs,
I'm a developer/Data Analyst. I have 2 years experience in Python development and data analytics. To level up, I'm looking to start learning Machine Learning and AI to switch to a career in developing industrial AI solutions.
I got chatgpt to create a plan for me for a basic idea and would really appreciate it if y'all could advice improvements or refer to already existing great curriculum to achieve my goal.
Thanks

AI/ML Path:

*****Level 1: Beginner*****

1. Linear Regression
   - Simple Linear Regression
   - Multiple Linear Regression

2. Logistic Regression

3. Decision Trees

4. K-Nearest Neighbors (KNN)

5. Evaluation Metrics
   - Accuracy, Precision, Recall
   - F1 Score

*****Level 2: Intermediate*****

1. Support Vector Machines (SVM)

2. Random Forests

3. Principal Component Analysis (PCA)

4. K-Means Clustering

5. Model Evaluation Techniques
   - Train-Test Split
   - Cross-Validation

*****Level 3: Advanced*****

1. Gradient Boosting Machines (GBM)
   - AdaBoost
   - XGBoost

2. Convolutional Neural Networks (CNN)
   - Image Classification
   - Transfer Learning

3. Recurrent Neural Networks (RNN)
   - Sequence Modeling
   - Natural Language Processing (NLP)

4. Reinforcement Learning
   - Markov Decision Processes (MDP)
   - Q-Learning

5. Natural Language Processing (NLP)
   - Text Classification
   - Named Entity Recognition (NER)
   - Sentiment Analysis

*****Level 4: Expert*****

1. Deep Learning Architectures
   - Generative Adversarial Networks (GAN)
   - Transformer Models (BERT, GPT)

2. Time Series Analysis
   - Autoregressive Integrated Moving Average (ARIMA)
   - Long Short-Term Memory (LSTM)

3. Bayesian Methods
   - Bayesian Networks
   - Gaussian Processes

4. Model Deployment and Production
   - Web APIs and Microservices
   - Cloud Services (AWS, Google Cloud, Azure)
   - Deployment Platforms (Heroku, Kubernetes)

5. Ethical Considerations in Machine Learning
   - Fairness and Bias Mitigation
   - Privacy and Data Protection"
158,learnmachinelearning,gpt-4,comments,2023-03-28 16:24:47,Specific Open Problems in ML Alignment or Capabilities to Help Develop GPT-6?,TikkunCreation,False,0.67,1,124u87e,https://www.reddit.com/r/learnmachinelearning/comments/124u87e/specific_open_problems_in_ml_alignment_or/,2,1680020687.0,"As we witness the rapid advancements in large language models (LLMs) like GPT-4, I am increasingly interested in actively contributing to the research and development of even more advanced models, such as GPT-6 (given that GPT-5 is already being trained). I understand that training these models requires massive compute resources, and many people believe using LLMs is more valuable than creating them. However, I'm convinced that there's still a lot to learn, and I want to be part of the process that helps push the boundaries of AI research further.

I would like to ask for your input on what are three specific open problems in ML alignment or capabilities work, where if solved, they'd help in the development of models like GPT-6. I'm not interested in pointers related to making smaller models, fine tuning, distilling, prompting, or utilizing the models. I'm specifically interested in things that could help make GPT-6 better.

Basically, I'm looking for open puzzles. The most important open questions in research. Where I can play with it myself, and get a sense for some of the current challenges in the field."
159,learnmachinelearning,gpt-4,comments,2023-12-24 18:21:50,Best way to deploy chatbot for college website,Boring-Building-7139,False,0.99,5,18q0o71,https://www.reddit.com/r/learnmachinelearning/comments/18q0o71/best_way_to_deploy_chatbot_for_college_website/,2,1703442110.0,"We are creating a RAG-based chatbot for our college website using GPT 4. We want to deploy this, but are not sure how exactly to go forward with the same, and what factors to keep in mind while doing so. We've looked at options like Sagemaker, and Beanstalk and stuff, but not sure how to proceed.

How do you think it should be deployed?"
160,learnmachinelearning,gpt-4,comments,2021-06-13 20:57:38,Some YouTube channels that review papers,axetobe_ML,False,0.97,51,nz5szs,https://www.reddit.com/r/learnmachinelearning/comments/nz5szs/some_youtube_channels_that_review_papers/,2,1623617858.0,"When I was reading a Reddit thread. People were wondering if there were YouTubers reviewing papers. As the OP noticed that one of the YouTuber's that he regularly watched stopped uploading videos. There are a few YouTubers that talk about ML and review papers. 

I decided to compile some of the YouTube channels into this short list. 

&#x200B;

[Two Minute Papers](https://www.youtube.com/c/K%C3%A1rolyZsolnai/videos) does great overviews of fascinating papers. Showing the increasing progress of ML.

Some of the videos I liked:

* [4 Experiments Where the AI Outsmarted Its Creators](https://www.youtube.com/watch?v=GdTBqBnqhaQ)

This video showed various AI solving a problem not in the way the researchers intended to. That may include abusing the physics in the simulation or lateral thinking used by the model.

* [A Video Game That Looks Like Reality!](https://youtu.be/22Sojtv4gbg)

A review of a paper that takes GTA V gameplay and converts them to photo-realistic footage.

&#x200B;

[Yannic Kilcher](https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew) does in-depth reviews of various papers. As you go through the paper he shows you his thought process. And showing what important inside the paper. Very useful if don’t read that many papers. (Like me)

Some good videos:

* [Attention Is All You Need](https://www.youtube.com/watch?v=iDulhoQ2pro)

A review of a paper that introduced transformers.

&#x200B;

* [DeepMind's AlphaFold 2 Explained! AI Breakthrough in Protein Folding What we know (& what we don't)](https://youtu.be/B9PL__gVxLI)

A great rundown on protein folding and speculating how Alphafold 2 works.

&#x200B;

* [GPT-3: Language Models are Few-Shot Learners (Paper Explained)](https://youtu.be/SY5PvZrJhLE)

A comprehensive paper reading of the GPT-3 paper.

&#x200B;

[Bycloud](https://www.youtube.com/channel/UCgfe2ooZD3VJPB6aJAnuQng) you may have seen him around on Reddit. Creates short and insightful summaries of papers.

Some videos I liked:

* [AI Sky Replacement with SkyAR](https://www.youtube.com/watch?v=yNwQnrjfg5A)

Summary of paper that creates AR effects in video footage. Adding various effects to the video footage’s sky.

&#x200B;

* [AI Generates Cartoon Characters In Real Life \[Pixel2Style2Pixel\]](https://youtu.be/g-N8lfceclI)

Reviewing a paper that converts cartoon characters to real-life equivalents and vice versa. Also explains how the paper made it easier to adjust the parameters of the GAN. Helping us adjust what images we want to produce.

&#x200B;

[Machine Learning Street Talk](https://www.youtube.com/c/MachineLearningStreetTalk/videos)

This is a podcast series that interviews top ML researchers. While they don’t have videos about papers alone. As they interview various experts in the field. So they talk about many papers as a consequence. 

While this is a short list maybe you can find these channels interesting and learn something new.

\-

*If you found this post useful, then check out my* [*mailing list*](https://www.tobiolabode.com/subscribe) *where I write more stuff like this.*"
161,learnmachinelearning,gpt-4,comments,2023-08-16 20:33:36,Llama2 on Replicate faster than ChatGPT?,VideoTo,False,0.67,2,15t1715,https://www.reddit.com/r/learnmachinelearning/comments/15t1715/llama2_on_replicate_faster_than_chatgpt/,2,1692218016.0,"Ran some testing and discovered llama2 on replicate is faster than chatgpt!

Code - [https://github.com/BerriAI/litellm/blob/main/cookbook/Evalua...](https://github.com/BerriAI/litellm/blob/main/cookbook/Evaluating_LLMs.ipynb)

Are others seeing similar results?

https://preview.redd.it/t6n5ijfv8jib1.png?width=1238&format=png&auto=webp&s=78ef90bce9bebe761c3a1eb63f016ebdead593a5"
162,learnmachinelearning,gpt-4,comments,2024-02-06 19:28:11,Are there any models you can finetune for reading handwriting?,Jealous_Afternoon669,False,0.75,2,1aki6w8,https://www.reddit.com/r/learnmachinelearning/comments/1aki6w8/are_there_any_models_you_can_finetune_for_reading/,2,1707247691.0,"I have dyspraxia and my handwriting is pretty terrible by most standards, but pretty consistent in that I can read it back and people who know me for a while can read it. There are small quirks like how my s's and l's get formed (I write in cursive) that make it nearly illegible for most people but once you know you know.

I was mainly curious if there's any kind of work that's been done on handwriting recognition in cases like this. I take it probably not because GPT-4 vision is really inconsistent at being able to read handwriting, but maybe there are more specialised models?

&#x200B;"
163,learnmachinelearning,gpt-4,comments,2023-04-11 14:14:34,Help with pet project to learn - Running ChatGPT-2 at home,SigmaSixShooter,False,0.88,6,12il5t0,https://www.reddit.com/r/learnmachinelearning/comments/12il5t0/help_with_pet_project_to_learn_running_chatgpt2/,2,1681222474.0,"Greetings,

(Edit on Apr 12: Realized I screwed up and forgot I had a tokenize script as well. Updated things to properly reflect the process in case this is helpful for anyone else)

I know I'm probably the millionth person to ask, but I've tried as hard as I can to work through all of this and I've gotten stuck.

# The Goal

Train/fine-tune a model (not sure which) based on the TV show Firefly. I wanted to run this on the ChatGPT-2 model as that's what ChatGPT suggested. I've gathered the data, prepared it for training, and done the training itself. When I try to actually interact with it though, I get a lot of garbage back.

This is mostly a learning exercise for me as my end goal is to train/fine-tune something using internal data, so I need something that can run on consumer-grade hardware (I've got a 2019 MacBook Pro with an 8 core I9, AMD Radeon Pro 5300 and 32 gigs of ram). This would ultimately lead to something being used for commercial purposes, so I'm trying to be careful which models I use/train etc.


Here's a high level summary of what I've done, I'm hoping someone can help me understand where I might have went wrong. I'd greatly appreciate any assistance you're willing to provide. I've got some of my own thoughts/questions at the bottom of this post.

# Download ChatGPT-2

I made a clone of [https://github.com/openai/gpt-2](https://github.com/openai/gpt-2) on my local laptop

# Gather and prepare the data

I started out with a simple format where every line was formatted ""<Char Name>:<Dialogue>"" but ChatGPT eventually convinced me to convert this into JSON. I suspect this may be the heart of my problem. Below is a sample of what the JSON looks like. The  JSON is stored as one giant line in a text file, I'm not sure if that matters or not. It is valid JSON though.

Based on the recommendation from ChatGPT, I had this broken up into 80% for training data (training-data.json) and 20% for validation (validate-data.json)

```
$ cat training-data.json| jq | head
[
  {
    ""character"": ""Jayne"",
    ""dialogue"": ""Your move.""
  },
  {
    ""character"": ""Zoe"",
    ""dialogue"": ""That's a bold move.""
  },
```
# Tokenize the training data
(At least I think that's what I did here). The end result were two new files, `train_dataset.pt` and `valid_dataset.pt`. 

```
import torch
from transformers import GPT2TokenizerFast

tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')
tokenizer.add_special_tokens({'pad_token': '[PAD]'})

train_text = open('scripts/xaa', 'r').read()
valid_text = open('scripts/xab', 'r').read()

train_encodings = tokenizer(train_text, truncation=True, padding=True)
valid_encodings = tokenizer(valid_text, truncation=True, padding=True)

train_dataset = torch.utils.data.TensorDataset(
    torch.tensor(train_encodings['input_ids']),
    torch.tensor(train_encodings['attention_mask'])
)
valid_dataset = torch.utils.data.TensorDataset(
    torch.tensor(valid_encodings['input_ids']),
    torch.tensor(valid_encodings['attention_mask'])
)

print(""Sample"")
print(train_encodings['input_ids'][0:10])  # print the first 10 tokens
# Save the tokenized data to separate files
torch.save(train_dataset, 'train_dataset.pt')
torch.save(valid_dataset, 'valid_dataset.pt')
```

# Train the model?
I get confused by training and fine-tuning. The result of this was something output in the `models/gpt-finetuned` folder, so I guess I'm fine-tuning it. 

Code generated by ChatGPT

```
import torch
from torch.utils.data import DataLoader
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
from tqdm import trange
import sys
import time

# Check if GPU is available
device = torch.device(""mps"" if torch.backends.mps.is_available() else ""cpu"")
print(device)

if device == ""cpu"":
    sys.exit()

start_time = time.time()  # Record the start time

# Load the data
train_dataset = torch.load('train_dataset.pt')
valid_dataset = torch.load('valid_dataset.pt')

# Initialize the tokenizer and model
tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')
model = GPT2LMHeadModel.from_pretrained('gpt2')

# Set the batch size and number of epochs
batch_size = 5
num_epochs = 4

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=batch_size)

# Set up the optimizer and training parameters
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)
total_steps = len(train_loader) * num_epochs
warmup_steps = int(0.1 * total_steps)
num_steps = 0

# Set the device to GPU if available
device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
model.to(device)

# Train the model
for epoch in range(num_epochs):
    epoch_loss = 0
    progress_bar = trange(len(train_loader))
    for i, batch in enumerate(train_loader):
        # Move the batch to the device
        batch = tuple(t.to(device) for t in batch)
        inputs, labels = batch

        # Zero the gradients and forward pass
        optimizer.zero_grad()
        outputs = model(inputs, labels=labels)
        loss, logits = outputs[:2]
        epoch_loss += loss.item()

        # Backward pass and update parameters
        loss.backward()
        optimizer.step()
        scheduler.step(loss)

        # Update progress bar
        num_steps += 1
        progress_bar.update(1)
        progress_bar.set_description(f""Epoch {epoch + 1}/{num_epochs}"")
        progress_bar.set_postfix(loss=loss.item())

    # Print the average loss for the epoch
    print(f'Epoch {epoch + 1} Loss: {epoch_loss / len(train_loader)}')

# Save the model
model.save_pretrained('models/gpt2-finetuned')

end_time = time.time()  # Record the end time
total_duration = end_time - start_time  # Calculate the total duration
print(f""Total training time: {total_duration:.2f} seconds"")
```

# Trying it out

I then had ChatGPT create me a python script to run all of this.

```
import torch
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


def generate_response(model, tokenizer, prompt, max_length=100, num_return_sequences=1):
    input_ids = tokenizer.encode(prompt, return_tensors='pt')
    attention_mask = torch.ones(input_ids.shape, dtype=torch.long)
    output = model.generate(
        input_ids,
        attention_mask=attention_mask,
        max_length=max_length,
        num_return_sequences=num_return_sequences,
        no_repeat_ngram_size=2,
        temperature=5.0,
        top_p=1.5,
    )
    decoded_output = [tokenizer.decode(seq) for seq in output]
    return decoded_output


def main():
    model_name = 'models/gpt2-finetuned'
    model = GPT2LMHeadModel.from_pretrained(model_name)
    tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')  # Use the default GPT-2 tokenizer
    
    print(""Type 'quit' to exit the program."")
    while True:
        prompt = input(""Ask a question: "")
        if prompt.lower() == 'quit':
            break

        responses = generate_response(model, tokenizer, prompt)
        print(""Answer:"", responses[0].strip())

if __name__ == ""__main__"":
    main()
```

Running the above gets me something like this:
```
Ask a question: Give me an impression of Jayne from Firefly
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
Answer: Give me an impression of Jayne from Firefly""

""I'm a big fan of the show""!
.!!!""!!!!!!!!?!!!!!!!!!""
,!!,!!:!!.!!?!!'!!"",!,!:!,!,!:!""!""!,!""!:!:!.!,!.!""!!!,!!!:!!!!!.!:!!!!,!!!!""!.!.!!!'!,!'!'!""!'!.!'!:!'!!!!!!!!?!!?!!!
```

This seems pretty far from desirable, but I can't really tell where I went wrong.

# Thoughts/questions

* I realize the data I gave it is just Character Name/Dialogue. Maybe it has no way of knowing everything I added was from Firefly....
* How could I better prepare the data for training? I think this is where I likely went wrong?
* Is there a better way I should have went about this?
* How can I further troubleshoot this?
* Is what I'm **trying** to do called ""fine tuning a model""?"
164,learnmachinelearning,gpt-4,comments,2023-02-14 17:53:16,[P] Practical Steps to Reduce Hallucination and Improve Performance of Systems Built with Large Language Models like ChatGPT,vykthur,False,0.91,9,112bk1o,https://www.reddit.com/r/learnmachinelearning/comments/112bk1o/p_practical_steps_to_reduce_hallucination_and/,2,1676397196.0,"&#x200B;

[Practical steps to reduce hallucination and improve performance of systems built with large language models like ChatGPT](https://preview.redd.it/gksxjpnoz6ia1.png?width=1456&format=png&auto=webp&s=c34531fbe1311eab9323c148eef35fcf0d70decd)

Large language models (LLMs) like the GPT series (GPT3, 3.5, [ChatGPT](https://openai.com/blog/chatgpt/)) can be powerful tools in building useful applications. However, **LLMs are probabilistic** \- i.e., they generate text by learning a probability distribution over words seen during training. For example, given the following words as context “*rise and*”, an LLM can infer that the next word it should generate that fits this context is likely to be “*shine*”. While this setup ensures generated text is **coherent and human-like** (e.g., asking ChatGPT to rewrite the [Serenity Praye](https://en.wikipedia.org/wiki/Serenity_Prayer)r in the style of the [American Constitution](https://www.senate.gov/civics/constitution_item/constitution.htm) yields some intriguing prose), this resulting text may [**not be factual, or just plain incorrect**](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web) **(not grounded in the model’s input or training data) - aka hallucination**. In addition, another limitation of LLMs is that they struggle to address **tasks that need** [**complex multistep reasoning**](https://arxiv.org/pdf/2208.14271.pdf)**.** For example, asking the model to address mathematical word problems or puzzles often requires that the task is decomposed into steps, some computation applied to solve each step and some transformation applied to aggregate results into a final answer; this remains challenging for LLMs.  


Full article: [https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination](https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination) 

This post discusses the following:

* An overview on why hallucination will likely *always be a problem* with LLMs.
* Practical steps developers can take to reduce hallucination and improve performance including:  

   * Low temperature
   * Use of external knowledge bases
   * Chain of thought prompting
   * Self-consistency/voting
   * Task decomposition and agents
   * Correctness probabilities for result filtering
   * Task bench marks
   * Building defensive user interfaces."
165,learnmachinelearning,gpt-4,comments,2023-12-31 17:01:12,Andrew Ng On How To Read Machine Learning Papers (Summary by GPT-4),ledmmaster,False,0.69,7,18vbz75,https://forecastegy.com/posts/read-machine-learning-papers-andrew-ng/,2,1704042072.0,
166,learnmachinelearning,gpt-4,comments,2021-10-28 20:01:57,Can you add the final touches to my Complete Explanation of how to code GPT-2?,BrainProfessional803,False,1.0,1,qhvalp,https://www.reddit.com/r/learnmachinelearning/comments/qhvalp/can_you_add_the_final_touches_to_my_complete/,1,1635451317.0,"I feel there is some things missing still, like how the backprop works, or the mean and std norm for a batch, or some others things, but maybe this is most of it? I want to code it in raw Python with no PyTorch and no Tensorflow, no classes, no large code, just simple loops etc, 400 lines of Python ONLY. I'll most probably plug in the ADAM, etc. I don't want to be running 6000 lines of C++, like all other implementation do using import blahblahblah. SmallGPT is 300 lines of Python but trust me it is not even the actual code, it calls 6000 lines of C++.

&#x200B;

P.S. I know there is like 4 moments in the file below that may seem awkward like how I say ""flip that matric"" or say ""ink stamp"" but please don't feel that it is beginner or incomplete, I really did a fair job here so far and it should impress. It still makes sense whether I said stamp the vector or not, so don't worry! :-)

&#x200B;

[https://paste.ee/p/QTIdt](https://paste.ee/p/QTIdt)

&#x200B;

I want to make this much smaller and simpler than SmallGPT, but I need your help. I would love to team up with others on this and work on just this."
167,learnmachinelearning,gpt-4,comments,2023-04-04 18:03:20,Talk to ChatGPT-4 with your voice and even hear its responses spoken in your own voice.,TalkNowVoice,False,0.25,0,12br5jk,https://www.reddit.com/r/learnmachinelearning/comments/12br5jk/talk_to_chatgpt4_with_your_voice_and_even_hear/,1,1680631400.0,"[App Beta link.](https://testflight.apple.com/join/WYwS7eX5)

&#x200B;

https://reddit.com/link/12br5jk/video/4u14hkihqwra1/player"
168,learnmachinelearning,gpt-4,comments,2023-03-16 19:16:18,Problems with Wav2lip,MF3DOOM,False,1.0,1,11t3fgn,https://www.reddit.com/r/learnmachinelearning/comments/11t3fgn/problems_with_wav2lip/,1,1678994178.0," 

Hey everyone, I'm new to machine learning and I'm currently trying to use wav2lip on a Google Colab notebook. However, I keep running into an error that says:

""ERROR: Could not find a version that satisfies the requirement opencv-python==4.1.0.25 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.14.51, 3.4.14.53, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.2.52, 4.5.2.54, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72) ERROR: No matching distribution found for opencv-python==4.1.0.25""

I've tried to fix the problem by running ""!pip install opencv-python==4.5.3.56"" in the code cell, as instructed by some youtube videos and ChatGPT, but it hasn't worked. Does anyone have any experience with wav2lip and knows how to solve this error? Any help would be greatly appreciated. Thank you!"
169,learnmachinelearning,gpt-4,comments,2023-09-02 17:47:34,LLaVA: Bridging the Gap Between Visual and Language AI with GPT-4,OnlyProggingForFun,False,1.0,1,1688v48,https://youtu.be/Pn1B_L_zAwI,1,1693676854.0,
170,learnmachinelearning,gpt-4,comments,2023-06-16 14:23:32,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.94,16,14ay75a,https://www.reddit.com/r/learnmachinelearning/comments/14ay75a/this_week_in_ai_all_the_major_ai_developments_in/,1,1686925412.0,"1. **ElevenLabs** has launched **AI Speech Classifier -** an authentication tool that lets you upload any audio sample to identify if it contains ElevenLabs AI-generated audio.
2. **Nvidia Research** presents **SceneScape** \- a method to generate long-term walkthroughs in imaginary scenes just from an input text prompt.
3. **Meta AI** introduces the **Image Joint Embedding Predictive Architecture (I-JEPA)**, a new AI model which learns from the world like humans and excels in computer vision tasks, while being more computationally efficient. It learns by creating an internal model of the outside world, which compares abstract representations of images (rather than comparing the pixels themselves). It can also be used for many different applications without needing extensive fine tuning. Meta is open-sourcing the code and model checkpoints.
4. **Meta** wants to make the next version of LLaMA, its open source LLM, available for commercial use..
5. Adobe launched **Generative Recolor,** a new tool powered by Adobe Firefly generative AI that lets you generate custom color schemes using texts prompt like “strawberry fields,” “faded emerald,” etc. .
6. **OpenAI** announced:
   1. new **function calling** capability in the Chat Completions API
   2. updated and more steerable versions of gpt-4 and gpt-3.5-turbo
   3. new 16k context version of gpt-3.5-turbo (vs the standard 4k version). 16k context means the model can now support \~20 pages of text in a single request.
   4. cost reductions: 75% on embeddings model and 25% cost on input tokens for gpt-3.5-turbo.
7. **Meta AI** released **MusicGen** \- an open-source music generation model that can be prompted by both text and melody. See here for generated samples and comparison with Google’s MusicLM and others..
8. **McKinsey** published a report ‘*The economic potential of generative AI: The next productivity frontier*’ . The report estimates that generative AI could add the equivalent of $2.6 trillion to $4.4 trillion annually across the 63 use cases. About 75 percent of the value that generative AI use cases could deliver falls across four areas: Customer operations, marketing and sales, software engineering, and R&D..
9. **EU lawmakers** pass AI regulation, requiring generative AI systems, such as ChatGPT, to be reviewed before commercial release. It also seeks to ban real-time facial recognition.*.*
10. **Google Lens** can now identify skin conditions. Lens will also be integrated with Bard, Google’s AI-powered chatbot, enabling Bard to understand images in user prompts..
11. **AMD** announced its most-advanced GPU for artificial intelligence, the MI300X, which will start shipping to some customers later this year*.*
12. **Vercel** introduced **Vercel AI SDK -** an open-source library to build conversational, streaming and chat user interfaces. Includes first-class support for OpenAI, LangChain, and Hugging Face Inference.
13. **Vercel** announced '**Vercel AI Accelerator,** a 6-week long accelerator program with $850k in free credits from OpenAI, Replicate and others.
14. **Salesforce** announces **AI Cloud** \- generative AI for the enterprise. AI Cloud includes the new **Einstein Trust Layer**, to help prevent large-language models (LLMs) from retaining sensitive customer data.
15. **Cohere** and **Oracle** are working together to make it easy for enterprise customers to train their own specialized large language models while protecting the privacy of their training data.
16. **Coda** released Coda AI - the AI-powered work assistant integrated in Coda to automate workflows. Coda also announced ‘**Coda's AI at Work Challenge**’, offering $40,000 in total prizes to the makers who submit the most useful Coda AI template to the Coda Gallery.
17. **OpenAI, Google DeepMind and Anthropic** have committed to provide “early or priority access” to their AI models to UK in order to support research into evaluation and safety.

If you like this news format, you might find my  [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
171,learnmachinelearning,gpt-4,comments,2023-03-16 05:52:25,"Here's a summary of GPT-4 interesting features and it's livestream, blog, website articles",crower12,False,0.55,1,11sllq8,https://youtu.be/PNk_10Fdb9Y,1,1678945945.0,
172,learnmachinelearning,gpt-4,comments,2023-06-11 17:18:34,"[D] How to Choose a Framework To Evaluate Your LLMs? We've Evaluated GPT-4/3.5, Anthropic Claude, & Cohere Command Across 4 Tasks. Here's What We've Learned.",davidbun,False,0.98,110,146zie8,https://v.redd.it/yy5sdnvo6f5b1,1,1686503914.0,
173,learnmachinelearning,gpt-4,comments,2023-05-25 13:37:41,🎉 Introducing TalentGPT: AI-Powered Tool for Cover Letters & CV Writing 🚀,City_Bike_09,False,0.53,1,13ri1pe,https://www.reddit.com/r/learnmachinelearning/comments/13ri1pe/introducing_talentgpt_aipowered_tool_for_cover/,0,1685021861.0," 

Hey Redditors! 👋

Say hello to [TalentGPT](https://coverletterassistant-github-io.vercel.app/) \- your new AI-powered companion for crafting the perfect cover letters and CVs! 🤖 Based on OpenAI's advanced GPT-4, we're here to change the game of job applications. 🎯 Try for **FREE** today: [https://coverletterassistant-github-io.vercel.app/](https://coverletterassistant-github-io.vercel.app/)

In just two weeks since our grand launch, we've had: 🌍 Users from 30+ countries 👥 400+ unique users 📈 2K+ use cases served

Our exciting features:

1️⃣ **AI Cover Letters:** 📝 Paste the job description, upload your resume, and let AI create a custom cover letter that matches your profile and job requirements perfectly.

2️⃣ **CV Writing Service:** 📄 Want a standout CV? Simply book a session with us [right here](https://forms.gle/ERFokS9qiNsbn9Mc6)!

Try [TalentGPT](https://coverletterassistant-github-io.vercel.app/) today, and supercharge your job application process! 🚀

Cheers, 

The [TalentGPT](https://coverletterassistant-github-io.vercel.app/) Team 👋

[Introduction to TalentGPT](https://reddit.com/link/13ri1pe/video/pd7rgnjpu02b1/player)"
174,learnmachinelearning,gpt-4,comments,2023-06-01 21:56:29,"When we plug external embedding solutions like ImageBind into LLMs like LLaMA, how exactly is that done?",E_Snap,False,1.0,1,13xulwj,https://www.reddit.com/r/learnmachinelearning/comments/13xulwj/when_we_plug_external_embedding_solutions_like/,1,1685656589.0,"I’m currently working my way through Karpathy’s “[Let’s build GPT from scratch](https://youtu.be/kCc8FmEb1nY)”. In doing that, I’m trying to teach myself how the structures of multimodal models like [MiniGPT-4](https://arxiv.org/pdf/2304.10592.pdf) and [PandaGPT](https://arxiv.org/pdf/2305.16355.pdf) have been modified to allow information from external encoders like ImageBind and CLIP to interact with the LLaMA-based LLMs. The high-level description of “You freeze the LLM and vision encoders and then use a single feed-forward layer to align them” doesn’t exactly help me understand how the two models have been connected.

Would somebody be down to give me a non-data-scientist’s-level description of how these two models are interfaced? I feel like I’m understanding the Karpathy video pretty well so far, so you can get that complicated if it helps."
175,learnmachinelearning,gpt-4,comments,2023-10-14 12:54:08,Using GPT-4 as the “Brains” of a Reinforcement Learning Problem,tylersuard,False,0.5,0,177owz1,https://medium.com/@ceo_44783/using-gpt-4-as-the-brains-of-a-reinforcement-learning-problem-516ff79aedb0,1,1697288048.0,
176,learnmachinelearning,gpt-4,comments,2023-12-03 14:38:25,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.93,49,189ustx,https://www.reddit.com/r/learnmachinelearning/comments/189ustx/this_week_in_ai_all_the_major_ai_developments_in/,1,1701614305.0,"1. **Meta AI** introduced a suite of AI language translation models that preserve expression and improve streaming \[[*Details*](https://ai.meta.com/blog/seamless-communication) *|* [*GitHub*](https://github.com/facebookresearch/seamless_communication)\]:
   1. ***SeamlessExpressive*** enables the transfer of tones, emotional expression and vocal styles in speech translation. You can try a demo of SeamlessExpressive using your own voice as an input [***here***](https://seamless.metademolab.com/expressive)***.***
   2. ***SeamlessStreaming***, a new model that enables streaming speech-to-speech and speech-to-text translations with <2 seconds of latency and nearly the same accuracy as an offline model. In contrast to conventional systems which translate when the speaker has finished their sentence, SeamlessStreaming translates while the speaker is still talking. t intelligently decides when it has enough context to output the next translated segment.
   3. ***SeamlessM4T v2***, a foundational multilingual & multitask model for both speech & text. It's the successor to SeamlessM4T, demonstrating performance improvements across ASR, speech-to-speech, speech-to-text & text-to-speech tasks.
   4. ***Seamless***, a model that merges capabilities from SeamlessExpressive, SeamlessStreaming and SeamlessM4T v2 into one.
2. **Stability AI** released ***SDXL Turbo***: a real-time Text-to-Image generation model. SDXL Turbo is based on a a new distillation technology, which enables the model to synthesize image outputs in a single step and generate real-time text-to-image outputs while maintaining high sampling fidelity.
3. **Mozilla’s** innovation group and Justine Tunney released ***llamafile*** that lets you distribute and run LLMs with a single file. llamafiles can run on six OSes (macOS, Windows, Linux, FreeBSD, OpenBSD, and NetBSD) and on multiple CPU architectures.
4. **Perplexity** released two new PPLX models: ***pplx-7b-online and pplx-70b-online***. These *online LLMs* can leverage the most up-to-date information using the internet when forming a response..
5. **Google DeepMind** presented ***GNoME*** (Graph Networks for Materials Exploration): an AI tool that discovered *2.2 million new crystal structures*, with 380,000 being highly stable and promising for breakthroughs in superconductors, supercomputers, and advanced batteries for electric vehicles.
6. **Amazon** introduced two new Amazon Titan multimodal foundation models (FMs): ***Amazon Titan Image Generator*** (preview) and ***Amazon Titan Multimodal Embeddings***. All images generated by Amazon Titan contain an invisible watermark.
7. Researchers present ***Animatable Gaussians***, a new avatar representation method that can create lifelike human avatars from multi-view RGB videos.
8. **Pika Labs** released a major product upgrade of their generative AI video tool, ***Pika 1.0***, which includes a new AI model capable of generating and editing videos in diverse styles such as 3D animation, anime, cartoon and cinematic using text, image or existing video.
9. **Eleven Labs** announced a ***grant*** program offering 11M text characters of content per month for the first 3 months to solo-preneurs and startups.
10. Researchers from **UC Berkeley** introduced ***Starling-7B***, an open large language model trained using Reinforcement Learning from AI Feedback (RLAIF). It utilizes the GPT-4 labeled ranking dataset, Nectar, and a new reward training pipeline. Starling-7B outperforms every model to date on MT-Bench except for OpenAI’s GPT-4 and GPT-4 Turbo .
11. **XTX Markets** is launching a new $10mn challenge fund, the **Artificial Intelligence Mathematical Olympiad Prize** (AI-MO Prize) The grand prize of $5mn will be awarded to the first publicly-shared AI model to enter an AI-MO approved competition and perform at a standard equivalent to a gold medal in the in the International Mathematical Olympiad (IMO) .
12. **Microsoft Research** evaluated GPT-4 for processing ***radiology reports***, focusing on tasks like disease classification and findings summarization. The study found GPT-4 has a sufficient level of radiology knowledge with only occasional errors in complex context that require nuanced domain knowledge. The radiology report summaries generated by GPT-4 were found to be comparable and, in some cases, even *preferred* over those written by experienced radiologists.
13. **AWS** announced ***Amazon Q***, a new generative AI–powered assistant for businesses. It enables employees to query and obtain answers from various content repositories, summarize reports, write articles, perform tasks, and more, all within their company's integrated content systems. Amazon Q offers over 40 built-in connectors to popular enterprise systems.
14. 18 countries including the US, Britain signed a detailed international agreement on how to keep artificial intelligence safe from rogue actors, pushing for companies to create AI systems that are ‘secure by design’ .

**Source**: AI Brews - you can subscribe [here](https://aibrews.com/). it's free to join, sent only once a week with ***bite-sized news, learning resources and selected tools.*** I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks."
177,learnmachinelearning,gpt-4,comments,2023-07-03 08:48:49,Your weekly machine learning digest,Successful_Boat_3099,False,1.0,5,14pdgpm,https://www.reddit.com/r/learnmachinelearning/comments/14pdgpm/your_weekly_machine_learning_digest/,1,1688374129.0,"Hi,

Almost everyday I post on [LinkedIn](https://www.linkedin.com/in/nour-islam-mokhtari/) and [Twitter](https://twitter.com/NourIslamMo) some techniques and tools that I think could be  valuable to machine learning practitioners.

Here's a compilation of content I posted in the previous week.

Note: each day there is a new technique/tool so they're not necessarily linked.

#  Day 1:

Have you heard of LMFlow?

It’s a framework that allows you to easily finetune open source large language models on your own datasets!

Here are the key features that are supported by the toolkit:

\- Continous pretraining, instruction tuning and RLHF on user-defined datasets.  
\- Simple and extensible APIs for developers.  
\- Efficient tuning with low-rank adaptation (LoRA).  
\- A novel RLHF algorithm RAFT (Reward rAnked FineTuning) to simply RLHF pipeline for generative models.  
\- A simplified model inference framework.

Below you can see the overall system design of LMFlow.

Note: LMFlow is not to be mixed with MLFlow, which is an MLOps framework.

👉 LMFlow original paper: [https://arxiv.org/pdf/2306.12420.pdf](https://arxiv.org/pdf/2306.12420.pdf)  
👉 Github repo: [https://github.com/OptimalScale/LMFlow](https://github.com/OptimalScale/LMFlow)

# Day 2:

LoRA is an algorithm that helps finetune large language models quickly. So how does the algorithm work? And how does it make the training efficient?

Here’s my understanding of it.

First of all, LoRA means low-rank adaptation of large language models.

Language models like GPT-3 use a Transformer architecture which includes layers with attention and feed-forward networks. LoRA focuses on the latter: the feed-forward networks.

Let's consider just one layer of a Transformer model. The feed-forward network (FFN) can be represented as:

FFN(x) = W2 \* ReLU(W1\*x + b1) + b2

Here, x is the input, W1 and W2 are weight matrices, b1 and b2 are biases, and ReLU is the activation function.

The core idea of LoRA is to modify this FFN to have a new feed-forward network (FFN') that looks like this:

FFN\_modified(x) = (W2 + U2V2) \* ReLU((W1 + U1V1)\*x + b1) + b2

U1, U2, V1, and V2 are matrices that will be learned during adaptation.

These matrices have lower ranks than the original weights matrices W1 and W2.

This low-rank structure means that the number of parameters we need to learn during adaptation is relatively small, keeping the adaptation process efficient.

For example, if U has a shape (d,r) and V has a shape (r, d), where d is the original dimension and r is the rank of the adaptation, then the number of parameters in the low-rank matrix is 2dr.

This number of parameters can be much smaller than d\^2, the number of parameters in the original matrix W if it was to be fine-tuned.

So this is where the efficiency comes from!

During the adaptation process, we keep the original weights (W1, W2) and biases (b1, b2) fixed, and only learn the new parameters (U1, U2, V1, V2) using gradient descent on the specific task we're interested in.

👉 LoRA original paper: [https://arxiv.org/pdf/2106.09685.pdf](https://arxiv.org/pdf/2106.09685.pdf)  
👉 Github repo: [https://github.com/microsoft/LoRA](https://github.com/microsoft/LoRA)

# Day 3:

The data drift problem in computer vision models is a real issue. Here’s what it means and how to tackle it.

Data drift refers to the change in input data distribution over time.

In other words, it occurs when the nature of the data your model is receiving in production starts to differ from the data it was trained on.

This is a common issue in machine learning and can lead to a decrease in model performance, as the model may not have learned the appropriate patterns to handle the ""new"" kind of data.

In the context of computer vision and deep learning, this might mean changes in the types of images the model is processing.

For instance, maybe your model was trained on outdoor photos taken during the day, but over time, it starts receiving more photos taken at night.

If your model wasn't trained on night images, its performance might decline - this is an example of data drift.

Measuring data drift in computer vision involves quantifying the difference between the training data distribution and the production data distribution.  
Here are a few techniques you might use:

**Image Statistics:**

Compute basic statistics like mean and standard deviation of pixel values, color distributions, etc., on your training data and on the data the model is processing in production. Significant differences could indicate data drift.

**Pretrained Feature Extractor:**

You could use a pretrained model like a ResNet or VGG to extract features from your images. You can then compute and compare distributions of these features in the training and production data.

**Classifier Discrepancy:**

Train a binary classifier to distinguish between the training data and the new incoming data. If the classifier can easily tell the difference, it means there's a significant discrepancy, indicating data drift.

**Dimensionality Reduction and Visualization:**

Techniques like PCA or t-SNE can be used to reduce the dimensionality of your image data (or features extracted from them) to 2 or 3 dimensions, so they can be visualized. If the training data and production data form distinct clusters, it might be a sign of data drift.

👉 Here’s a nice article that I found about this topic: [https://towardsdatascience.com/how-to-measure-drift-in-ml-embeddings-ee8adfe1e55e](https://towardsdatascience.com/how-to-measure-drift-in-ml-embeddings-ee8adfe1e55e)

# Day 4:

Most machine learning research is about going from mathematical modeling to ML model implementation. Here’s how to go from conditional probability to a neural architecture.

Let's start by defining a simple conditional probability problem. Consider a supervised learning task where we have input data X and target data Y, and we want to model the conditional probability P(Y | X), meaning the probability of Y given X.

A common way to model this in machine learning is to assume that this probability follows some parametric form and then use the data to estimate the parameters of this model.

For instance, we could assume that P(Y | X) is a Gaussian distribution with mean µ(X) and standard deviation σ(X). This mean µ(X) and standard deviation σ(X) could be any functions of X, but in order to learn them from data, we often assume they can be parameterized with some parameters θ, and are differentiable with respect to these parameters.

This is where neural networks come in. A neural network is just a function approximator that's highly flexible and differentiable, making it suitable to represent these functions µ(X) and σ(X).

Let's assume that our neural network is a simple feed-forward network with parameters θ. Then we can write our model as:  


µ(X; θ) = NN\_µ(X; θ)  
σ(X; θ) = NN\_σ(X; θ)  


P(Y | X; θ) = N(Y; NN\_µ(X; θ), NN\_σ(X; θ)\^2)  


Here, NN\_µ and NN\_σ are two neural networks which take the same input X and share the same parameters θ, and N is the Gaussian distribution. Their outputs represent the mean and standard deviation of the Gaussian distribution of Y given X.

To train this model, we would use a method called maximum likelihood estimation (MLE), which aims to find the parameters θ that maximize the likelihood of the observed data.

For our Gaussian model, this corresponds to minimizing the mean squared error between Y and NN\_µ(X; θ).

Below, you can see how we might implement this in code using PyTorch.

In this code, we have a neural network that outputs two values for each input: a mean and a standard deviation. The loss function is defined as the negative log-likelihood of the Gaussian distribution, which we try to minimize using gradient descent. 

https://preview.redd.it/94qn39f8qp9b1.png?width=1766&format=png&auto=webp&s=a717f7e19e01313909382eb5e90bb46cf6105c31

 💡 Get technical insights just like this to help you become a better ML practitioner here: [https://aifee.co/newsletter/](https://aifee.co/newsletter/)"
178,learnmachinelearning,gpt-4,comments,2023-07-03 12:58:01,Bloom transformer model inference by huggging face not running on a low spec pc,Draude94,False,1.0,1,14pibep,https://www.reddit.com/r/learnmachinelearning/comments/14pibep/bloom_transformer_model_inference_by_huggging/,1,1688389081.0,"Hi!

From a C# project I send some questions to a python script and catch back the answers using a print() method. The python script is started from a .NET wrapper for python.

The script executes and seems to get into a deadlock or something. After 30 Min., I get no response but the execution still continues. I use a similar python logic for CerebrasGPT and there it works perfectly.

This is the python script:

    import sys  
    from transformers import AutoModelForCausalLM, AutoTokenizer  
    
    # Specify the model name or path  
    model_name = ""bigscience/bloom""   
    
    # Load the model and tokenizer  
    model = AutoModelForCausalLM.from_pretrained(model_name,                                                      
                                                device_map=""auto"",torch_dtype=""auto"")  
    
    tokenizer = AutoTokenizer.from_pretrained(model_name)    
    
    # Add a padding token to the tokenizer  
    tokenizer.add_special_tokens({""pad_token"": ""[PAD]""})    
    
    # Read the questions from command-line arguments  
    questions_string = sys.stdin.read()    
    
    # Split the questions into a list  
    questions = questions_string.strip().split(""\n"")    
    
    # Generate the responses  
    responses = []  
    for question in questions:          
        # Tokenize the input question          
        inputs = tokenizer.encode_plus(question, return_tensors=""pt"",     
                                        padding=""longest"", truncation=True)           
        # Generate the response without sampling          
        output_ids = model.generate(
                        inputs.input_ids,                  
                        num_beams = 1, # ofter between 1 and 10; smaller value = more         
                                        focused answer,                               
                                        higher value = explore a broader range of 
                                        possiblities (less coherent)     
                        early_stopping=True, # True = stops when the questions has 
                                                been answered (no unnecessary text)              
                        no_repeat_ngram_size=4, # <= max_length; often between 1 and 
                                                4; smaller values for flexibillity,     
                                                larger values for reducing repetitive 
                                                redundant phrases                       
                        attention_mask=inputs.attention_mask,              
                        do_sample=False          
                     )            
        generated_responses = []
        for response_ids in output_ids:                  
            response = tokenizer.decode(response_ids, skip_special_tokens=True)                                  
            generated_responses.extend(response.split(""\n""))               
    
        responses.append("";"".join(generated_responses))  # Use ';' as the delimiter 
                                                         between answers    
    
    # Format the responses as a string with newlines separating each question's answers 
    response_string = ""\n"".join(responses)    
    
    # Print the response string  
    print(response_string)  

I'm running it using python 3.11.4.

This are the specs of my pc:- CPU: 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz 2.42 GHz

\- GPU: Intel Iris Xe (onboard graphics)

\- 16 GB RAM

\- Win10 Enterprise, 64 bit

Could this be the pc specs or is there an error inside the code?"
179,learnmachinelearning,gpt-4,comments,2024-01-05 15:14:07,"This Week's Major AI developments in a nutshell (December Week 4, 2023 + January week 1, 2024)",wyem,False,0.96,24,18z95ko,https://www.reddit.com/r/learnmachinelearning/comments/18z95ko/this_weeks_major_ai_developments_in_a_nutshell/,1,1704467647.0,"1. **Meta** and UC, Berkeley introduced ***Audio2Photoreal***, a framework for generating full-bodied photorealistic avatars with gestures driven from audio of a dyadic conversation \[[*Details*](https://people.eecs.berkeley.edu/~evonne_ng/projects/audio2photoreal/) | [*GitHub*](https://github.com/facebookresearch/audio2photoreal)*\].*
2. **MyShell** along with researchers from MIT and Tsinghua University introduced ***OpenVoice***, an open sourcce voice cloning approach that is nearly instantaneous and provides granular control of tone, from emotion to accent, rhythm, pauses, and intonation, using just a small audio clip \[[*Details*](https://research.myshell.ai/open-voice) *|* [*Hugging Face*](https://huggingface.co/spaces/myshell-ai/OpenVoice)\] .
3. **Suno** and Nvidia present ***Parakeet***, a family of open source speech recognition models that top the Open ASR Leaderboard. Parkeet models effectively prevent the generation of hallucinated transcript and are robust to noisy audio. Available for commercial use under CC BY 4.0 \[[*Details*](https://nvidia.github.io/NeMo/blogs/2024/2024-01-parakeet/) | [*Hugging Face*](https://huggingface.co/spaces/nvidia/parakeet-rnnt-1.1b)\].
4. **Researchers** from Stanford University introduce ***Mobile-ALOHA***, an open-source robot hardware that can can autonomously complete complex mobile manipulation tasks that require whole-body control like cook and serve shrimp, call and take elevator, store a 3Ibs pot to a two-door cabinet etc., with just 50 demos \[[*Details*](https://mobile-aloha.github.io/)\].
5. **Allen Institute for AI** released ***Unified-IO 2*** (open-source), the first autoregressive multimodal model that is capable of understanding and generating image, text, audio, and action. The model is pre-trained from scratch on an extensive variety of multimodal data -- 1 billion image-text pairs, 1 trillion text tokens, 180 million video clips, 130 million interleaved image & text, 3 million 3D assets, and 1 million agent trajectories \[[*Details*](https://unified-io-2.allenai.org/)\].
6. **Alibaba** Research introduced ***DreamTalk***, a diffusion-based audio-driven expressive talking head generation framework that can produce high-quality talking head videos across diverse speaking styles \[[*Details*](https://dreamtalk-project.github.io/) *|* [*GitHub*](https://github.com/ali-vilab/dreamtalk)\].
7. **OpenAI’s app store** for GPTs will launch next week \[[*Details*](https://techcrunch.com/2024/01/04/openais-app-store-for-gpts-will-launch-next-week/)\].
8. **GitHub Copilot Chat**, powered by GPT-4, is now generally available for both Visual Studio Code and Visual Studio, and is included in all GitHub Copilot plans alongside the original GitHub Copilot \[[*Details*](https://github.blog/2023-12-29-github-copilot-chat-now-generally-available-for-organizations-and-individuals)\].
9. **Microsoft Research** presented a new and simple method for obtaining high-quality text embeddings using only synthetic data and less than 1k training step \[[*Paper*](https://arxiv.org/pdf/2401.00368.pdf)\] | [*Hugging Face*](https://huggingface.co/intfloat/e5-mistral-7b-instruct)\].
10. **Google DeepMind** introduced ***AutoRT, SARA-RT and RT-Trajectory*** to improve real-world robot data collection, speed, and generalization \[[*Details*](https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotic)\].
11. **Salesforce Research** presented ***MoonShot***, a new video generation model that conditions simultaneously on multimodal inputs of image and text, demonstrating significant improvement on visual quality and temporal consistency compared to existing models. The model can be easily repurposed for a variety of generative applications, such as personalized video generation, image animation and video editing. Models will be made public [here](https://github.com/salesforce/LAVIS) \[[*Details*](https://showlab.github.io/Moonshot/)\].
12. **Leonardo AI** released ***Leonardo Motion*** for generating videos from images. Available to all users, paid and free \[[*Link*](https://leonardo.ai/)\].
13. **JPMorgan AI Research** present ***DocLLM***, a layout-aware generative language model for multimodal document understanding. The spatial layout information is incorporated through bounding box coordinates of the text tokens obtained typically using optical character recognition (OCR), and does not rely on any vision encoder component \[[Details](https://arxiv.org/pdf/2401.00908.pdf)\].
14. **Alibaba Research** introduced ***Make-A-Character (Mach)***, a framework to create lifelike 3D avatars from text descriptions. Make-A-Character supports both English and Chinese prompts. \[[*Details*](https://human3daigc.github.io/MACH/) *|* [*Hugging Face*](https://huggingface.co/spaces/Human3DAIGC/Make-A-Character)\].
15. **Sony**, Canon and Nikon set to combat deepfakes with digital signature tech in future cameras \[[*Details*](https://www.techradar.com/cameras/photography/sony-canon-and-nikon-set-to-combat-deepfakes-with-digital-signature-tech-in-future-cameras)\].
16. **Meta AI** introduced ***Fairy***, a versatile and efficient video-to-video synthesis framework that generates high-quality videos with remarkable speed. Fairy generates 120-frame 512x384 videos (4-second duration at 30 FPS) in just 14 seconds, outpacing prior works by at least 44× \[[Details](https://fairy-video2video.github.io/)\].
17. **Apple** quietly released an open source multimodal LLM, called ***Ferret***, in October 2023 \[[*Details*](https://venturebeat.com/ai/apple-quietly-released-an-open-source-multimodal-llm-in-october/)\].
18. **Australian researchers** introduced a non-invasive AI system, called ***DeWave***, that can turn silent thoughts into text while only requiring users to wear a snug-fitting cap \[[*Details*](https://www.sciencealert.com/new-mind-reading-ai-translates-thoughts-directly-from-brainwaves-without-implants)\].
19. **Pika Labs** text-to-video AI platform **Pika 1.0** is now available to all and accessible via the web \[[*Link*](https://pika.art/)\].
20. **The New York Times** sued OpenAI and Microsoft for copyright infringement \[[*Details*](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html)\].

**Source**: [AI Brews newsletter-](https://aibrews.com/) you can subscribe [here](https://aibrews.substack.com/). it's free to join, sent only once a week with ***bite-sized news, learning resources and selected tools.*** *Thank you!*"
180,learnmachinelearning,gpt-4,comments,2023-05-04 08:27:11,How to create a love chatbot using llm while building proprietory data set,Thomasallnice,False,0.5,0,137ebj9,https://www.reddit.com/r/learnmachinelearning/comments/137ebj9/how_to_create_a_love_chatbot_using_llm_while/,1,1683188831.0,"Hi, I am looking for a roadmap on how I can build a chatbot / [ai agent](https://www.reddit.com/r/ChatGPT/comments/12diapw/gpt4_week_3_chatbots_are_yesterdays_news_ai/) that helps people to handle their romantic relationships. The idea is to start with a LLM like chatgpt and also have real humans answering and moderating the questions that the ai might struggle with. I want to somehow integrate a database of FAQs that the LLM can uss and that grows over time. Since the topic is related to love and emotions I am not sure if Chatgpt is the right tool if not somehow jailbroken.

* How would your roadmap to achieving this look like?
* What Chatbot / Ai Agent is the best for that?
* Can I use Chatgpt 4 with the chatbot and does it also handle romantic topics?
* How would I integrate a FAQ database that the AI can index or use?
* Can I index other resources (like reddit) as well and give it higher weights in the LLMs?

Thank you so much?"
181,learnmachinelearning,gpt-4,comments,2023-03-15 01:54:30,How good is GPT-4 compared to ChatGPT?,OnlyProggingForFun,False,0.33,0,11riiip,https://youtu.be/GroMQETFXLc,1,1678845270.0,
182,learnmachinelearning,gpt-4,comments,2023-06-04 13:29:08,Is my strategy sound for bridging gaps and building confidence?,grainypeach,False,1.0,1,140d3vx,https://www.reddit.com/r/learnmachinelearning/comments/140d3vx/is_my_strategy_sound_for_bridging_gaps_and/,1,1685885348.0,"Hello folks! First time posting to this sub here but I've already seen a lot of posts on here about getting the right books for beginners. Before this comes across as yet another books-advice question, I wanted to add that the reason for my post is that I specifically don't want to be digging through tons of super foundational material - not shortcuts exactly but something that gives good summaries and examples of implementations of a specific foundational topic.

For context, I work as a Machine Learning engineer but tbh, I never actually did ML in school etc. I did one project and a course on Coursera 3-4 years ago, which gave me some context. I was originally hired at my job to do signal processing but eventually kept prodding my nose into ML problems (and often failing) and I managed to pick up a lot of context for things from tutorials, papers, reading git repos etc, and work mostly ML now. 

Lately I feel my lack of the actual foundations often catches up to my ability to solve the problem - causing stress and anxiety. I'm often ruminating on stuff like, ""I wish I actually knew the stats that gives me a good understanding of HMMs, which builds some context for RNNs, which connects up with LSTM+GRU, and builds on to self-attention, and transformers, and then I'd know when to use a GRU Vs a Transformer"". You might read this and think that an HMM has nothing to do with an RNN, but case in point- I actually just don't know. In the end, if you asked me device my own architecture to solve some problem - I'd rarely know where to start. I rely a lot on papers proposing new architectures to try. This pattern of thinking is based on a lot of imposter syndrome I'm sure, but it's also getting harder to ignore these topics as foundational deep learning; for which I also seem to lack the foundations in classic ML and stats. For some of this, I've found ChatGPT useful, but it's hard to be sure of what chatGPT tells you - especially if you're lacking foundations.

So here's my current proposed solution to the problem. I found these books through other posts on this sub:
1. Deep Learning - Ian Goodfellow; for math and foundation
2. Machine Learning with PyTorch and Scikit-Learn - Sebastian Rachka; for speed-read catch-up and illustrated code-based intuitions

I'd like to know from you folks if this book selection sounds reasonable? Would you substitute/add another resource? Any time management tips from those of you trying to do it all and also rest, recuperate, and exist in the world?"
183,learnmachinelearning,gpt-4,comments,2022-02-17 01:37:41,Relative Position Representation/Encoding for Transformer,promach,False,0.81,3,sucf7q,https://www.reddit.com/r/learnmachinelearning/comments/sucf7q/relative_position_representationencoding_for/,1,1645061861.0,"1. In [GPT-NeoX-20B: An Open-Source Autoregressive Language Model](http://eaidata.bmk.sh/data/GPT_NeoX_20B.pdf#page=2) paper, why did [the author](https://blog.eleuther.ai/rotary-embeddings/) stated that **Rotary embeddings are a form of static relative positional embeddings** ?
2. In [https://medium.com/@\_init\_/how-self-attention-with-relative-position-representations-works-28173b8c245a](https://medium.com/@_init_/how-self-attention-with-relative-position-representations-works-28173b8c245a) , could anyone explain the rationale behind **the value of the lookup indices after the 3rd element are all 6** ?
3. What is the actual purpose of [skewing mechanism](https://jaketae.github.io/study/relative-positional-encoding/) ?  The [explanation inside music transformer paper](https://arxiv.org/pdf/1809.04281.pdf#page=5) is confusing.
4. In the [video about self-attention with relative positional representations](https://youtu.be/DwaBQbqh5aE?t=441) , I am bit confused as in **where** in the equations that the author added the extra `α` (relative positional embedding) highlighted in red color.

[Q2](https://preview.redd.it/cw74enkurai81.png?width=711&format=png&auto=webp&s=a670532f611c0196ba5adc8eafe2b586ac2f1448)

[Q3](https://preview.redd.it/ty74fr278ci81.png?width=1738&format=png&auto=webp&s=2e871d659f218ea3a53d4eab4cc8e5c8ad711cb3)

[Q4a](https://preview.redd.it/6svjlzfjbwi81.png?width=1920&format=png&auto=webp&s=aaed0542570ab6b3a1e636543b96c636fc324904)

[Q4b](https://preview.redd.it/2efdul8ybwi81.png?width=600&format=png&auto=webp&s=027956d72b2190ebc98b61396609492cf7ee1491)"
184,learnmachinelearning,gpt-4,comments,2024-02-12 19:52:03,"Predicted output after decoding is always empty strings in a list of tokens, but prediction looks fine.",asoulsghost,False,0.5,0,1ap946i,https://www.reddit.com/r/learnmachinelearning/comments/1ap946i/predicted_output_after_decoding_is_always_empty/,1,1707767523.0," I created a new project to debug with, my real one is much more complicated, but this code is just to show my issue:

\`\`\`import tensorflow as tf  
import numpy as np

from keras.callbacks import EarlyStopping  
from keras.layers import Bidirectional, Dropout, BatchNormalization, Embedding, LSTM, Dense  
from keras.optimizers import Adam  
from keras.regularizers import l2  
from keras.models import Sequential  
from keras.preprocessing.sequence import pad\_sequences  
from sklearn.model\_selection import train\_test\_split

user\_prompts = np.array(\[  
""What's your favorite animal?"",  
""What's your favorite movie?"",  
""What's your favorite book?"",  
""What's your favorite season?"",  
""What's your favorite hobby?"",  
""What's your favorite sport?"",  
""What's your favorite music genre?"",  
""What's your favorite dessert?"",  
""What's your favorite holiday?"",  
""What's your favorite beverage?"",  
""What's your favorite place to relax?"",  
""What's your favorite childhood memory?"",  
""What's your favorite superhero?"",  
""What's your favorite board game?"",  
""What's your favorite fruit?"",  
""What's your favorite vegetable?"",  
""What's your favorite type of weather?"",  
""What's your favorite clothing brand?"",  
""What's your favorite type of transportation?"",  
""What's your favorite quote?""  
\])

gpt\_responses = np.array(\[  
""I love elephants!"",  
""My favorite movie is The Shawshank Redemption."",  
""My favorite book is 1984 by George Orwell."",  
""I enjoy the crisp air of autumn."",  
""My favorite hobby is painting."",  
""I'm a fan of basketball."",  
""I enjoy listening to classical music."",  
""My favorite dessert is cheesecake."",  
""I love celebrating Christmas!"",  
""My favorite beverage is iced coffee."",  
""I love relaxing by the beach."",  
""One of my favorite childhood memories is building sandcastles."",  
""My favorite superhero is Batman."",  
""I enjoy playing Monopoly with friends."",  
""I love strawberries!"",  
""Broccoli is my favorite vegetable."",  
""I enjoy sunny days with a light breeze."",  
""I like wearing clothes from Zara."",  
""I enjoy traveling by train."",  
""One of my favorite quotes is 'Be yourself; everyone else is already taken.' - Oscar Wilde""  
\])

user\_tokenizer = tf.keras.preprocessing.text.Tokenizer()  
user\_tokenizer.fit\_on\_texts(user\_prompts)  
user\_sequences = user\_tokenizer.texts\_to\_sequences(user\_prompts)

with open('tokenizers/user\_tokenizer.json', 'w') as f:  
f.write(user\_tokenizer.to\_json())

gpt\_tokenizer = tf.keras.preprocessing.text.Tokenizer()  
gpt\_tokenizer.fit\_on\_texts(gpt\_responses)  
gpt\_sequences = gpt\_tokenizer.texts\_to\_sequences(gpt\_responses)

max\_sequence\_length\_user = max(len(seq) for seq in user\_sequences)  
max\_sequence\_length\_gpt = max(len(seq) for seq in gpt\_sequences)  
max\_sequence\_length = max(max\_sequence\_length\_user, max\_sequence\_length\_gpt)

padded\_user\_sequences = pad\_sequences(user\_sequences, maxlen=max\_sequence\_length, padding='post')  
padded\_gpt\_sequences = pad\_sequences(gpt\_sequences, maxlen=max\_sequence\_length, padding='post')

def normalize(arr, range):  
norm\_arr = \[\]  
t\_min = range\[0\]  
t\_max = range\[1\]  
diff = t\_max - t\_min  
diff\_arr = np.max(arr) - np.min(arr)  
for i in arr:  
temp = (((i - np.min(arr)) \* diff) / diff\_arr) + t\_min  
norm\_arr.append(temp)  
return norm\_arr

range\_to\_normalize = (0, 1)  
normalized\_input\_sequences = np.array(\[normalize(padded\_user\_sequence, range\_to\_normalize) for padded\_user\_sequence in padded\_user\_sequences\])  
normalized\_output\_sequences = np.array(\[normalize(padded\_gpt\_sequence, range\_to\_normalize) for padded\_gpt\_sequence in padded\_gpt\_sequences\])

user\_vocab\_size = len(user\_tokenizer.word\_index) + 1  
gpt\_vocab\_size = len(normalized\_output\_sequences\[1\])

embedding\_dim = 100  
complexity = 128  
dropout\_percentage = 0.2  
kernel\_l2 = 0.01  
model = Sequential(\[  
Embedding(input\_dim=user\_vocab\_size, output\_dim=embedding\_dim, input\_length=normalized\_input\_sequences.shape\[1\]),  
Bidirectional(LSTM(complexity, return\_sequences=True, kernel\_regularizer=l2(kernel\_l2))),  
Dropout(dropout\_percentage),  
BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
Dense(gpt\_vocab\_size, activation='softmax')  
\])

optimizer = Adam(learning\_rate=0.0001, clipvalue=1)

model.compile(optimizer=optimizer, loss='sparse\_categorical\_crossentropy', metrics=\['accuracy'\])

early\_stopping = EarlyStopping(monitor='val\_accuracy', min\_delta=0.001, patience=5)

indices = np.arange(len(normalized\_input\_sequences))  
np.random.shuffle(indices)

X\_shuffled = normalized\_input\_sequences\[indices\]  
y\_shuffled = normalized\_output\_sequences\[indices\]

test\_size = 0.2  
random\_state = 42  
X\_train, X\_val, y\_train, y\_val = train\_test\_split(X\_shuffled, y\_shuffled, test\_size=test\_size, random\_state=random\_state)

\# model.fit(X\_shuffled, y\_shuffled, epochs=100, batch\_size=1)  
model.fit(X\_train, y\_train, validation\_data=(X\_val, y\_val), epochs=100, batch\_size=1, callbacks=\[early\_stopping\])

user\_test\_prompts = np.array(\[""What's your favorite fruit?""\])  
gpt\_test\_outputs = \[""I love strawberries!""\]

user\_test\_sequences = user\_tokenizer.texts\_to\_sequences(user\_test\_prompts)

max\_test\_sequence\_length = 16  
padded\_test\_user\_sequences = pad\_sequences(user\_test\_sequences, maxlen=max\_test\_sequence\_length, padding='post')

normalized\_input\_test\_sequences = np.array(\[normalize(padded\_test\_user\_sequence, range\_to\_normalize) for padded\_test\_user\_sequence in padded\_test\_user\_sequences\])

temperature = 0.8  
predictions = model.predict(normalized\_input\_test\_sequences, verbose=0)

for prediction, user\_prompt, gpt\_output in zip(predictions, user\_test\_prompts, gpt\_test\_outputs):  
flat\_prediction = prediction.flatten()

flat\_prediction /= flat\_prediction.sum()  
predicted\_token\_index = np.random.choice(len(flat\_prediction), p=flat\_prediction, replace=False)

predicted\_token = user\_tokenizer.index\_word.get(predicted\_token\_index, '')

tokens = \[predicted\_token\]

predicted\_output = ' '.join(tokens)

print(f'User Input: {user\_prompt}')  
print(f'Desired output: {gpt\_output}')  
print(f'Predicted output: {predicted\_output}')  
print('-----')  
\`\`\`

I've tried many for loops, like

\`\`\`for prediction, user\_prompt, gpt\_output in zip(predictions, user\_test\_prompts, gpt\_test\_outputs):  
predicted\_token\_index = np.argmax(prediction)

predicted\_token = user\_tokenizer.index\_word.get(predicted\_token\_index, '')

tokens = \[predicted\_token\]

predicted\_output = ' '.join(tokens)

print(f'User Input: {user\_prompt}')  
print(f'Desired output: {gpt\_output}')  
print(f'Predicted output: {predicted\_output}')  
print('-----')\`\`\`

and just using sequences\_to\_texts, but every time I get an output of an empty string output:

\`\`\`

Epoch 1/100

16/16 \[==============================\] - 6s 86ms/step - loss: 6.0625 - accuracy: 0.0742 - val\_loss: 5.9392 - val\_accuracy: 0.6719

Epoch 2/100

16/16 \[==============================\] - 0s 10ms/step - loss: 5.8804 - accuracy: 0.1602 - val\_loss: 5.7778 - val\_accuracy: 0.7188

Epoch 3/100

16/16 \[==============================\] - 0s 11ms/step - loss: 5.6995 - accuracy: 0.2539 - val\_loss: 5.6206 - val\_accuracy: 0.7188

Epoch 4/100

16/16 \[==============================\] - 0s 10ms/step - loss: 5.5314 - accuracy: 0.3008 - val\_loss: 5.4669 - val\_accuracy: 0.7188

Epoch 5/100

16/16 \[==============================\] - 0s 11ms/step - loss: 5.3713 - accuracy: 0.3086 - val\_loss: 5.3100 - val\_accuracy: 0.7188

Epoch 6/100

16/16 \[==============================\] - 0s 20ms/step - loss: 5.2182 - accuracy: 0.3281 - val\_loss: 5.1557 - val\_accuracy: 0.7188

Epoch 7/100

16/16 \[==============================\] - 0s 13ms/step - loss: 5.0553 - accuracy: 0.3984 - val\_loss: 5.0053 - val\_accuracy: 0.7188

User Input: What's your favorite fruit?

Desired output: I love strawberries!

Predicted output:

\-----

Process finished with exit code 0\`\`\`, I've tried many things, like removing normalization and

one-hot output encoding (probably not a good idea because thats usually for classification not generation). My raw prediction output is normal:  
\`\`\`\[\[\[0.0778783 0.06557257 0.06076822 0.06065349 0.06032058 0.06186754

0.06202849 0.06043779 0.06187213 0.06038573 0.06225286 0.06136721

0.06165493 0.06092576 0.05997844 0.06203589\]

\[0.07813773 0.06527797 0.06089196 0.0602421 0.06040936 0.06162713

0.06217815 0.06030732 0.06193228 0.06045975 0.06238835 0.06133105

0.06170922 0.06085845 0.06014106 0.06210819\]

\[0.07833952 0.06496894 0.06099691 0.05998792 0.06056097 0.06142266

0.06232133 0.06021814 0.0619639 0.06049031 0.06242365 0.06129177

0.06174114 0.06080718 0.06028767 0.06217802\]

\[0.07714576 0.06573851 0.06085972 0.05999741 0.0605224 0.06195446

0.06237265 0.06069792 0.06204189 0.06072977 0.06180735 0.06170344

0.06147125 0.06063626 0.06026375 0.06205739\]

\[0.07684774 0.06629623 0.06064059 0.06021787 0.06011086 0.06213385

0.06202212 0.06079 0.06174838 0.06075808 0.06224376 0.06154948

0.06150243 0.06092658 0.06034113 0.06187094\]

\[0.07733375 0.06579494 0.06066 0.06014116 0.06015702 0.06201651

0.06207646 0.06072213 0.06171102 0.06070145 0.06238475 0.06147529

0.06157743 0.06092092 0.06041304 0.06191408\]

\[0.07779049 0.06529719 0.06067943 0.06011438 0.06018091 0.06195151

0.06212142 0.06069627 0.06166849 0.0606375 0.06245897 0.0614467

0.06162487 0.06092478 0.06046251 0.06194457\]

\[0.07823473 0.06480044 0.0606989 0.06011757 0.06018409 0.06192542

0.06215886 0.06069161 0.06162626 0.0605731 0.06249316 0.06145227

0.06165317 0.06093194 0.06049183 0.06196667\]

\[0.07868056 0.06430052 0.06071777 0.06013772 0.06017078 0.06192584

0.06218894 0.060694 0.06158946 0.06051284 0.06250336 0.06148436

0.06166806 0.06093916 0.06050381 0.06198284\]

\[0.0791392 0.06379254 0.06073484 0.06016705 0.0601466 0.0619412

0.06221085 0.06069355 0.06156332 0.06046034 0.0624989 0.06153729

0.06167305 0.06094532 0.06050154 0.0619944 \]

\[0.07961872 0.06327192 0.06074828 0.06020188 0.0601184 0.06195999

0.06222335 0.06068258 0.06155341 0.06041929 0.06248498 0.06160597

0.06166972 0.06095124 0.06048853 0.0620018 \]

\[0.08012372 0.06273551 0.06075554 0.06024196 0.06009471 0.06196976

0.06222508 0.06065388 0.06156564 0.06039423 0.06246426 0.06168433

0.06165774 0.06095998 0.06046907 0.06200464\]

\[0.08065483 0.06218292 0.06075338 0.0602902 0.06008709 0.06195565

0.06221479 0.060599 0.06160573 0.06039128 0.06243812 0.06176374

0.06163492 0.06097768 0.06044899 0.06200173\]

\[0.08120844 0.06161809 0.06073787 0.06035243 0.06011206 0.06189844

0.06219138 0.06050603 0.06167795 0.06041874 0.06240781 0.06183083

0.0615972 0.06101486 0.06043666 0.06199118\]

\[0.08177745 0.06105088 0.06070472 0.06043745 0.06019438 0.06177184

0.06215353 0.06035656 0.0617824 0.06048765 0.06237619 0.0618646

0.06153877 0.06108828 0.0604446 0.06197073\]

\[0.08235379 0.06049864 0.06064992 0.06055691 0.06037189 0.06153841

0.06209862 0.06012097 0.06191007 0.06061208 0.06235056 0.06183248

0.06145228 0.0612235 0.06049152 0.06193841\]\]\]\`\`\`. Does anyone know what to do?"
185,learnmachinelearning,gpt-4,comments,2023-06-05 17:21:46,"GPT Weekly - 5th June Edition: Peek into OpenAI's future, GPT-4 Quality concerns, Risk of AI and more.",level6-killjoy,False,0.67,1,141llju,https://www.reddit.com/r/learnmachinelearning/comments/141llju/gpt_weekly_5th_june_edition_peek_into_openais/,0,1685985706.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 AI news in the past week
* 🗞️10 AI news highlights and interesting reads
* 🧑‍🎓3 Learning Resources

# 🔥Top 3 AI news in the past week

## 1. OpenAI plans as per Sam Altman

The CEO of Humanloop had a sit down with Sam Altman and 20 other developers. He discussed the [current and future of OpenAI](https://humanloop.com/blog/openai-plans). The blog was later taken down at the request of OpenAI. [Now it can be found at this link](https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans). 

The whole post is an interesting read. Some of the highlights for me were:

1. GPT-3 was not open-source because OpenAI didn’t think many people would be able to run large LLMs. This sounds like a cop-out. After all, LLaMA is also a large LLM and has helped the community.
2. OpenAI is limited by GPU power.
3. OpenAI will not enter the market, except ChatGPT. Though technically this doesn’t say what Microsoft might do. They are already plugging GPT4 into every other product. And they have no rate limitations. 

## 2. Is GPT-4 Quality going down?

This has been a recently trending topic.

Discussed on HN: [https://news.ycombinator.com/item?id=36134249](https://news.ycombinator.com/item?id=36134249)

Discussed on Reddit: [https://www.reddit.com/r/ChatGPT/comments/13xik2o/chat\_gpt\_4\_turned\_dumber\_today/](https://www.reddit.com/r/ChatGPT/comments/13xik2o/chat_gpt_4_turned_dumber_today/)

The interesting thing is that the quality judgment is around the same topic - Coding.

The person on HN says GPT4 is faster but generates buggy code with less in-depth analysis. 

While the person on Reddit says that the context window seems smaller. Chatbot cannot remember earlier code. It cannot distinguish between code and comment.

While an employee at OpenAI says [nothing has changed](https://twitter.com/OfficialLoganK/status/1663934947931897857).

Has something really changed? 

One theory is that while the model might be static the ChatGPT prompt might’ve changed to restrict answers. Everyone was having fun trying to get bomb recipes out of ChatGPT. Now everyone is paying the price. 

https://i.imgflip.com/7nlatp.jpg

Another theory is that ChatGPT has always been terrible. It just survived because of novelty. As the novelty wears off people are realizing that it isn’t as great as everyone thought. 

My theory is that this might be the after effect of trying to get to a “[Cheaper and faster GPT-4” as highlighted by Sam Altman](https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans). The trade-off is speed vs accuracy. If it is slightly faster but with slightly worse results, then it might work as well. It is no longer GPT-4, rather GPT-3.75.

## 3. Risk of AI = Pandemic and Nuclear War

Center for AI Safety [released a statement](https://www.safe.ai/statement-on-ai-risk) highlighting the risks of AI:

*Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.*

We have seen the warnings about risks of AI get dire and dire. First it was only people asking for a [pause on AI development for 6 months](https://www.theguardian.com/technology/2023/mar/31/ai-research-pause-elon-musk-chatgpt) then came [George Hinton](https://gptweekly.beehiiv.com/p/googles-startling-leaked-memo-george-hinton-mojo), and last week OpenAI asked for [AI to be regulated using the IAEA framework](https://gptweekly.beehiiv.com/p/future-ai-integration). 

This statement is not really a step up. It reads like a one line, summarized repetition of [OpenAI's statement](https://openai.com/blog/governance-of-superintelligence). 

The statement gains importance from its signatories. Some of the people include:

Geoffrey Hinton - Emeritus Professor of Computer Science, University of Toronto

Demis Hassabis - CEO, Google DeepMind

Sam Altman - CEO, OpenAI

Dario Amodei - CEO, Anthropic

Bill Gates - Gates Ventures

To name a few. 

There are two issues with the statement though. 

First, this might just be [fear-mongering](https://aisnakeoil.substack.com/p/is-avoiding-extinction-from-ai-really). The idea is to push governments into making AI a highly regulated industry. This would stop any open source efforts which can compete with the big companies. After all, you don’t really have open source alternatives for nuclear energy, right? 

Second, no one really knows how to regulate AI. There have been [voluntary rules from Google](https://gptweekly.beehiiv.com/p/future-ai-integration) and the EU AI act is in a very early stage. And the genie is already out of the bottle. People can create AI models in their basement. How do you pull that back?

# 🗞️10 AI news highlights and interesting reads

1. A follow-up to the story about a lawyer submitting fake cases from [last edition](https://gptweekly.beehiiv.com/p/future-ai-integration). As I said, this might lead some people in the legal community to doubt any sort of GPT tool.[ A federal judge has banned AI-only filings in his courtroom](https://arstechnica.com/tech-policy/2023/05/federal-judge-no-ai-in-my-courtroom-unless-a-human-verifies-its-accuracy/). The filings have to be written by a human or at least human-verified. 
2. [The Japanese government will not apply copyright law to the AI training data](https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/). This is interesting because using copyright data to train AI has been an issue. Sam Altman didn’t have a clear answer when he [appeared in front of Congress](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). The other interesting aspect is going to be whether someone can use GPT-4 data to train their own LLM. Is that copyrightable?  
3. [The Falcon 40-B model is now Apache 2.0](https://twitter.com/Thom_Wolf/status/1663986216771936263). That means you can use the model for commercial usage for free. This is good news for companies which need an instruction tuned model which beats LlaMA.
4. Photoshop's generative-fill feature is really good. Some of the [cool examples on Twitter](https://twitter.com/_Borriss_/status/1663568770408013831).
5. [An AI camera with no lens](https://twitter.com/BjoernKarmann/status/1663496103998750721). It gets the location, weather etc details from GPS and then passes it as a prompt to the image generator. Results are pretty cool. 
6. SEO isn’t changing any time soon. [Google’s generative SEO is very slow](https://www.theverge.com/23746083/google-ai-search-generative-experience-slow). 
7. [Chirper.AI](https://chirper.ai/) is a social media only for bots. No humans allowed. I just wonder if Twitter bots go there will Twitter become a ghost town?
8. [OpenAI now has a security portal ](https://trust.openai.com/)where you can see how they secure data (encryption at rest), backups, Pentest reports etc. This might be a step in the direction towards [ChatGPT business](https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt). Large corporations look at these policies before they consider any SaaS implementation. 
9. [Banks have stepped up hiring for AI roles with JP Morgan leading the way. ](https://www.bloomberg.com/news/features/2023-05-31/jpmorgan-s-push-into-finance-ai-has-wall-street-rushing-to-catch-up)
10. [AI code writing might not be the best idea. It will lead to tech debt and shabbily maintained and written code. ](https://www.wsj.com/articles/ai-is-writing-code-now-for-companies-that-is-good-and-bad-6f19ecdc)

# 🧑‍🎓3 Learning Resources

1. Couple of courses in Generative AI:
   1. [https://www.deeplearning.ai/short-courses/](https://www.deeplearning.ai/short-courses/)
   2. Google: [https://www.cloudskillsboost.google/paths/118](https://www.cloudskillsboost.google/paths/118)
2. Build your own Sketch to image app: [https://www.tryleap.ai/docs/how-to-build-a-sketch-to-image-app-with-leap-remix](https://www.tryleap.ai/docs/how-to-build-a-sketch-to-image-app-with-leap-remix)

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
186,learnmachinelearning,gpt-4,comments,2023-04-14 11:37:08,Post GPT-4: Answering Most Asked Questions About AI,kingabzpro,False,0.9,14,12luajw,https://www.kdnuggets.com/2023/04/post-gpt4-answering-asked-questions-ai.html,1,1681472228.0,
187,learnmachinelearning,gpt-4,comments,2022-12-17 11:39:11,why everyone is talking about GPT-4?,M20s,False,0.18,0,zo4jrk,https://www.reddit.com/r/learnmachinelearning/comments/zo4jrk/why_everyone_is_talking_about_gpt4/,1,1671277151.0,
188,learnmachinelearning,gpt-4,comments,2024-02-10 09:38:18,"Possibility of running LLaMA or other LLMs on a 12-year-old Mac, or other affordable options?",hedgehog0,False,1.0,1,1ancpm1,https://www.reddit.com/r/learnmachinelearning/comments/1ancpm1/possibility_of_running_llama_or_other_llms_on_a/,0,1707557898.0,"Hello everyone,

Today I saw [this Ollama news](https://ollama.ai/blog/openai-compatibility) and [related discussion](https://news.ycombinator.com/item?id=39307330) on HN and thought trying out ollama locally, however the following is the result:

> ➜  ollama run llama2
>
> Error: Unable to load dynamic library: Unable to load dynamic server library: dlopen(/var/folders/xt/4_gn7ry143zg0b8vwddc51nw0000gn/T/ollama4139630615/cpu_avx/libext_server.dylib, 6): Symbol not found: ____chkstk_darwin
> Referenced from: /var/folders/xt/4_gn7ry143zg0b8vwddc51nw0000gn/T/ollama4139630615/cpu_avx/libext_server.dylib (which was built for Mac OS X 11.3)
> Expected in: /usr/lib/libSystem.B.dylib
> in /var/folders/xt/4_gn7ry143zg0b8vwddc51nw0000gn/T/ollama4139630615/cpu_avx/libext_server.dylib

I have a 2011-Early Intel Macbook Pro (16-GB memory) on macOS 10.13.6 (High Sierra). I have tried out several different LLM models in the past, searched here and elsewhere about running local LLMs, but nothing really worked.

I am a math graduate student and am also interested in programming, so I want to learn more about developing with LLMs (e.g., fine-tuning), or even build products with LLMs in the future. One of my research interests is learning theory and interpreterity of ML/DL.

*So I was wondering that is it possible for me to do these things with local LLMs (e.g., LLaMA 2), or do you have some other budget options? Or it's just more convenient and may be cheaper to do stuffs with OpenAI's GPT-3.5 API?*

Also, *do you have any book recommendations for (developing with) LLMs*, either a theoretical one or a practical one can be good?

Thank you very much!"
189,learnmachinelearning,gpt-4,comments,2023-09-04 03:24:31,ID Embeddings Confusion,TraditionalNews9122,False,1.0,1,169gr4f,https://www.reddit.com/r/learnmachinelearning/comments/169gr4f/id_embeddings_confusion/,0,1693797871.0,"I'm studying recommender systems via a few online courses, and am confused about the use of ID embeddings.

&#x200B;

As I understand it, ID embeddings are popular ways to represent sparse items like a User, Media (a video, post, etc), or Ad, simply by their ID in the database. The ID embedding vector has no other inputs (no other sparse/dense features feed it, but it is still learnable). They are stored in a lookup table of size NxD where N is the total number of that item that exist in the DB, and D is the embedding dimension.

&#x200B;

In most of these courses, ID embeddings are lauded as a critical feature for every item. But it seems for this to be true, a company would have to train on every item in their DB. And even then, rare items would have bad representations, not to mention it's computationally intractable (in a large co, the table could be of dimensions 10\^11+ x D). And then they'd have to be retrained every single time.

&#x200B;

From consulting with GPT-4 a bit and thinking about this, it seems more likely to me that ID embeddings mostly serve to provide good representations of extremely popular items (a celebrity account, a major advertiser, a popular movie) that appear frequently in the dataset, but are mostly empty/unlearned for 99% of users/media/etc. I can't find any actual source that says this though.

&#x200B;

This is in contrast to something like two tower embeddings, which make a lot of sense to me and seem to be easily computable from other features even if that user/item has never been seen before. But the ID embedding has no inputs, it is supposed to be an input feature itself. Embedding lookups make much more sense to me in a context like transformers, with a small fixed vocab size that is well represented in the training set.

&#x200B;

When I search on this, I see a lot of references to the cold start problem of new users signing up not having embeddings, which makes me feel like I'm fundamentally misunderstanding ID embeddings, since it feels like if 99% of your 100 billion existing ID embeddings were still unlearned, cold start would be the least of your worries.

&#x200B;

Can anyone help clear up my misunderstanding? Thank you!!"
190,learnmachinelearning,gpt-4,comments,2023-12-22 21:46:24,NeuralFlash - a flashcard-making GPT specializing in AI to help you study.,MachineScholar,False,1.0,1,18opsjh,https://www.reddit.com/r/learnmachinelearning/comments/18opsjh/neuralflash_a_flashcardmaking_gpt_specializing_in/,0,1703281584.0,"Hey everyone. I'm a computer science student and I've been searching for the most efficient way to study ML concepts via Quizlet flashcards so I came up with a ""pipeline"" by making this custom GPT and feeding it my Markdown notes. Here's a little guide:

1. Take lecture/book notes in Markdown (I use obsidian to do this since it's free, fast, and open source)
2. Open up NeuralFlash and choose the ""Generate flashcards from my AI notes"" action.
3. Copy your entire Markdown note, paste it into NeuralFlash.
4. Copy the csv it outputs and paste it into the ""import"" area of your Quizlet flashcard set (make sure you select comma instead of tab).
5. Learn and succeed.

**Here the link to the GPT:** [**https://chat.openai.com/g/g-m4nFBaKA8-neuralflash**](https://chat.openai.com/g/g-m4nFBaKA8-neuralflash)"
191,learnmachinelearning,gpt-4,comments,2023-09-30 12:22:25,[D] How to train a seq2seq model to rephrase input text following given rules.,3Ammar404,False,0.5,0,16w5fdc,https://www.reddit.com/r/learnmachinelearning/comments/16w5fdc/d_how_to_train_a_seq2seq_model_to_rephrase_input/,0,1696076545.0,"Hi guys, 

I want to train (fine-tune) a seq2seq model to perform the task of rephrasing input  following these rules :  

1- always follow the pattern ""Entity Verb Entity"" 

2- only use  simple sentences : never combine sentences

3- Don't replace existing words 

4- Don't lose the overall meaning of the text or any information in it. 

For example: 

text = ""Project Risk Management includes the processes of conducting risk management planning, identification, analysis, response planning, response implementation, and monitoring risk on a project""

Standardized Text = ""Project Risk Management conducts risk management planning. Project Risk Management conducts risk identification. Project Risk Management conducts risk analysis. Project Risk Management plans responses. Project Risk Management implements responses. Project Risk Management monitors risk on a project.""

Using ChatGPT the results were very good, but I want to know if I can fine tune a model (BERT, T5, any LM) locally, what should be the data format for training such a model, evaluation metrics ?  "
192,learnmachinelearning,gpt-4,comments,2023-09-15 00:29:46,Can somebody help check to see if I'm understanding Microsoft's Retentive Network paper correctly?,30299578815310,False,1.0,2,16iyqn6,https://www.reddit.com/r/learnmachinelearning/comments/16iyqn6/can_somebody_help_check_to_see_if_im/,0,1694737786.0,"Relevant Paper:  [2307.08621.pdf (arxiv.org)](https://arxiv.org/pdf/2307.08621.pdf) 

So the definition of the recurrent representation of the retention mechanism is below

>Sn = γSn−1 + K^(⊺)nVn   
>  
>Retention(Xn) = QnSn,          n = 1, · · · , |x| 

γ is a decay factor, and K, Q, and V have their standard transformer definitions.

What confuses me is the derivation of Sn. The formula makes it look like a scalar. But if that's the case, are we saying that for a given token, the retention mechanism is just multiplying the Query by a scalar? That's surprising!

Here is some code I wrote with GPT to show my understanding of how it works. Is this correct? I use 3 arbitrary tokens of dimension 3, and then a pick arbitrary K Q and V matrices. I also initialize gamma to 0.5  


    import numpy as np
    
    # Tokens
    x1 = np.array([0.5, 0.2, 0.3])
    x2 = np.array([0.1, 0.4, 0.5])
    x3 = np.array([0.7, 0.1, 0.2])
    
    # K, Q, V matrices
    K_matrix = np.array([[1, 0, 0.5], [0, 1, 0.5], [0.5, 0.5, 0]])
    Q_matrix = np.array([[0, 1, 0.5], [1, 0, 0.5], [0.5, 0.5, 0]])
    V_matrix = np.array([[0.5, 1, 0], [0, 0.5, 1], [1, 0, 0.5]])
    
    # Compute K, Q, and V vectors for each token
    K1, K2, K3 = x1 @ K_matrix, x2 @ K_matrix, x3 @ K_matrix
    Q1, Q2, Q3 = x1 @ Q_matrix, x2 @ Q_matrix, x3 @ Q_matrix
    V1, V2, V3 = x1 @ V_matrix, x2 @ V_matrix, x3 @ V_matrix
    
    S_0 = 0
    gamma = 0.5
    
    # Compute Sn and Retention(Xn) for each token
    S1 = gamma * S_0 + np.dot(K1, V1)
    Retention_X1 = Q1 * S1
    
    S2 = gamma * S1 + np.dot(K2, V2)
    Retention_X2 = Q2 * S2
    
    S3 = gamma * S2 + np.dot(K3, V3)
    Retention_X3 = Q3 * S3
    
    Retention_X1, Retention_X2, Retention_X3
    
    
    

The final result is this.   


**Retention\_X1 = \[0.2415, 0.4485, 0.2415\]**  
**Retention\_X2 = \[0.58175, 0.31325, 0.22375\]**  
**Retention\_X3 = \[0.2235, 0.894 , 0.447 \]**

&#x200B;

Is this correct?"
193,learnmachinelearning,gpt-4,comments,2023-12-28 20:01:12,"The best current models (Dolphin, Mixtral, Solar, Noromaid) and where to try them",Horror_Echo6243,False,0.75,2,18t30rt,https://www.reddit.com/r/learnmachinelearning/comments/18t30rt/the_best_current_models_dolphin_mixtral_solar/,0,1703793672.0,"I just saw a lot of people talking about this models so if you want to test them i found this websites that have all of them

\- [infermatic.ai](https://infermatic.ai/) (all of them)

\- [https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0](https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0) (for solar)

\- [https://huggingface.co/chat](https://huggingface.co/chat) (for mixtral)

Let me know if you find more, I'd like to know

And heres a little resume if you don't know what each model is for

Dolphin : An uncensored model derived from an open-source dataset, it uses instructions from FLANv2 enhanced with GPT-4 and GPT-3.5 completions​​.

Mixtral : An advanced text generation model using a Mix of Experts architecture

Solar : domain specialization and optimization. It's recognized for its high performance and efficiency

Noromaid: Storywriting and roleplay

&#x200B;"
194,learnmachinelearning,gpt-4,comments,2023-04-12 05:19:38,Is OpenAI’s Study On The Labor Market Impacts Of AI Flawed?,LesleyFair,False,1.0,3,12jb3hy,https://www.reddit.com/r/learnmachinelearning/comments/12jb3hy/is_openais_study_on_the_labor_market_impacts_of/,0,1681276778.0,"[Example img\_name](https://preview.redd.it/u4m50gaj1eta1.png?width=1451&format=png&auto=webp&s=8c9eda5aebd66ad1c6514ba8fe14bca7dc0e381a)

We all have heard an uncountable amount of predictions about how AI will ***terk err jerbs!***

However, here we have a proper study on the topic from OpenAI and the University of Pennsylvania. They investigate how Generative Pre-trained Transformers (GPTs) could automate tasks across different occupations \[1\].

Although I’m going to discuss how the study comes with a set of “imperfections”, the findings still make me really excited. The findings suggest that machine learning is going to deliver some serious productivity gains.

People in the data science world fought tooth and nail for years to squeeze some value out of incomplete data sets from scattered sources while hand-holding people on their way toward a data-driven organization. At the same time, the media was flooded with predictions of omniscient AI right around the corner.

*Let’s dive in and take an* exciting glimpse into the future of labor markets\*!\*

# What They Did

The study looks at all US occupations. It breaks them down into tasks and assesses the possible level of for each task. They use that to estimate how much automation is possible for a given occupation.

The researchers used the [O\*NET database,](https://www.onetcenter.org/database.html) which is an occupation database specifically for the U.S. market. It lists 1,016 occupations along with its standardized descriptions of tasks.

The researchers annotated each task once manually and once using GPT-4. Thereby, each task was labeled as either somewhat (<50%) or significantly (>50%) automatable through LLMs. In their judgment, they considered both the direct “exposure” of a task to GPT as well as to a secondary GPT-powered system, e.g. LLMs integrated with image generation systems.

To reiterate, a higher “exposure” means that an occupation is more likely to get automated.

Lastly, they enriched the occupation data with wages and demographic information. This was used to determine whether e. g. high or low-paying jobs are at higher risk to be automated.

So far so good. This all sounds pretty decent. Sure, there is a lot of qualitative judgment going into their data acquisition process. However, we gotta cut them some slag. These kinds of studies always struggle to get any hard data and so far they did a good job.

However, there are a few obvious things to criticize. But before we get to that let’s look at their results.

# Key Findings

The study finds that 80% of the US workforce, across all industries, could have at least some tasks affected. Even more significantly, 19% of occupations are expected to have at least half of their tasks significantly automated!

Furthermore, they find that higher levels of automation exposure are associated with:

* Programming and writing skills
* Higher wages (contrary to previous research!)
* Higher levels of education (Bachelor’s and up)

Lower levels of exposure are associated with:

* Science and critical thinking skills
* Manual work and tasks that might potentially be done using physical robots

This is somewhat unsurprising. We of course know that LLMs will likely not increase productivity in the plumbing business. However, their findings underline again how different this wave is. In the past, simple and repetitive tasks fell prey to automation.

*This time it’s the suits!*

If we took this study at face value, many of us could start thinking about life as full-time pensioners.

But not so fast! This, like all the other studies on the topic, has a number of flaws.

# Necessary Criticism

First, let’s address the elephant in the room!

OpenAI co-authored the study. They have a vested interest in the hype around AI, both for commercial and regulatory reasons. Even if the external researchers performed their work with the utmost thoroughness and integrity, which I am sure they did, the involvement of OpenAI could have introduced an unconscious bias.

*But there’s more!*

The occupation database contains over 1000 occupations broken down into tasks. Neither GPT-4 nor the human labelers can possibly have a complete understanding of all the tasks across all occupations. Hence, their judgment about how much a certain task can be automated has to be rather hand-wavy in many cases.

Flaws in the data also arise from the GPT-based labeling itself.

The internet is flooded with countless sensationalist articles about how AI will replace jobs. It is hard to gauge whether this actually causes GPT models to be more optimistic when it comes to their own impact on society. However, it is possible and should not be neglected.

The authors do also not really distinguish between labor-augmenting and labor-displacing effects and it is hard to know what “affected by” or “exposed to LLMs” actually means. Will people be replaced or will they just be able to do more?

Last but not least, lists of tasks most likely do not capture all requirements in a given occupation. For instance ""making someone feel cared for"" can be an essential part of a job but might be neglected in such a list.

# Take-Away And Implications

GPT models have the world in a frenzy - rightfully so.

Nobody knows whether 19% of knowledge work gets heavily automated or if it is only 10%.

As the dust settles, we will begin to see how the ecosystem develops and how productivity in different industries can be increased. Time will tell whether foundational LLMs, specialized smaller models, or vertical tools built on top of APIs will be having the biggest impact.

In any case, these technologies have the potential to create unimaginable value for the world. At the same time, change rarely happens without pain. I strongly believe in human ingenuity and our ability to adapt to change. All in all, the study - flaws aside - represents an honest attempt at gauging the future.

Efforts like this and their scrutiny are our best shot at navigating the future. Well, or we all get chased out of the city by pitchforks.

Jokes aside!

What an exciting time for science and humanity!

As always, I really enjoyed making this for you and I sincerely hope you found value in it!

If you are not subscribed to the newsletter yet, [click here to sign up](https://thedecoding.net/)! I send out a thoughtful 5-minute email every week to keep you in the loop about machine learning research and the data economy.

*Thank you for reading and I see you next week ⭕!*

**References:**

\[1\] [https://arxiv.org/abs/2303.10130](https://arxiv.org/abs/2303.10130)"
195,learnmachinelearning,gpt-4,comments,2023-12-13 12:56:32,5 Tools to Help Build Your LLM Apps,kingabzpro,False,0.5,0,18hg7j7,https://www.reddit.com/r/learnmachinelearning/comments/18hg7j7/5_tools_to_help_build_your_llm_apps/,0,1702472192.0,"In the era of advanced language model applications, developers and data scientists are continuously seeking efficient tools to build, deploy, and manage their projects. As large language models (LLMs) like GPT-4 gain popularity, more people are looking to leverage these powerful models in their own applications. However, working with LLMs can be complex without the right tools.

That's why I've put together this list of five essential tools that can significantly enhance the development and deployment of LLM-powered applications. Whether you're just beginning or are a seasoned ML engineer, these tools will help you be more productive and build higher-quality LLM projects.

**link:** [https://www.kdnuggets.com/5-tools-to-help-build-your-llm-apps](https://www.kdnuggets.com/5-tools-to-help-build-your-llm-apps)"
196,learnmachinelearning,gpt-4,comments,2023-03-16 00:03:32,OpenAI's GPT 4 is out and it's multimodal! What we know so far,gordicaleksa,False,0.2,0,11sdxhz,https://www.youtube.com/watch?v=FY9Nlkoq4GI,0,1678925012.0,
197,learnmachinelearning,gpt-4,comments,2023-12-28 08:21:46,Fresh Grad trying their best to get into the industry. Please rate my resume,RookFlame4882,False,1.0,2,18soytd,https://www.reddit.com/r/learnmachinelearning/comments/18soytd/fresh_grad_trying_their_best_to_get_into_the/,0,1703751706.0,"Thank you for your time and help. Will appreciate any comments and critiques. Been trying my best to get a single callback but none so far. Feeling very lost & dejected.

&#x200B;

https://preview.redd.it/sv9akq4cwz8c1.png?width=2550&format=png&auto=webp&s=1d22d61b9bf53c995f52b5f62149cfcd9bfb8d03"
198,learnmachinelearning,gpt-4,comments,2024-01-25 20:52:45,Implementing a Sparse Mixture of Experts Language Model from scratch,avi1x,False,0.66,1,19fjjrr,https://www.reddit.com/r/learnmachinelearning/comments/19fjjrr/implementing_a_sparse_mixture_of_experts_language/,0,1706215965.0,"Hi all,

I implemented a sparse mixture of experts language model (basically a tiny version of Mixtral and supposedly GPT-4) from scratch in pure pytorch and trained it on tiny Shakespeare. This is based largely on makemore from Andrej Karpathy (an autoregressive character-level decoder only transformer model). My goal is for this to be a hackable implementation that people use to understand how this really works and improve upon. I foresee more and more of these models coming out throughout the year.

The blog that steps through this is here: [https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch](https://huggingface.co/blog/avisoori1x/makemoe-from-scratch)

The repo is here: [https://github.com/AviSoori1x/makeMoE](https://github.com/avisoori1x/makemoe)

Hope this is helpful!"
199,learnmachinelearning,gpt-4,comments,2020-06-10 21:02:43,"GPT-3: Explaining the $4,600,000 Neural Network from OpenAI",mippie_moe,False,0.83,4,h0k5xn,https://lambdalabs.com/blog/demystifying-gpt-3/,0,1591822963.0,
200,learnmachinelearning,gpt-4,relevance,2023-01-19 07:56:20,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,LesleyFair,False,0.96,326,10fw2df,https://www.reddit.com/r/learnmachinelearning/comments/10fw2df/gpt4_will_be_500x_smaller_than_people_think_here/,47,1674114980.0,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/yio0v3zqgyca1.png?width=575&format=png&auto=webp&s=a2ee034ce7ed48c9adc1793bfdb495e0f0812609)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That’s a *trillion* with a “t”.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI’s new brainchild will certainly be mind-bending and language models have been getting bigger — fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let’s go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): “From talking to OpenAI, GPT-4 will be about 100 trillion parameters”.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there’s a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community’s understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: “Scaling Laws For Neural Language Models”.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind’s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): “Training Compute-Optimal Large Language Models”

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!  
The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ​[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails​

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ⭕.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,… & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver"
201,learnmachinelearning,gpt-4,relevance,2023-12-10 19:55:49,Is it worth learning ML in 2024 with GPT-4 and Gemini-Ultra on the horizon?,i_am_new_here_51,False,0.53,2,18fbtd8,https://www.reddit.com/r/learnmachinelearning/comments/18fbtd8/is_it_worth_learning_ml_in_2024_with_gpt4_and/,21,1702238149.0,"So I'm a college student looking to learn some skills in my free time. So far, I have a surface level understanding of C++, Webdev, and Python. 

From a career or even purely from an enjoyment standpoint, would learning Machine learning be worth it in this climate? Or has the advent of LLMs made this field less viable. (I am not very well versed in this field, so I do apologise if I come off as ignorant)"
202,learnmachinelearning,gpt-4,relevance,2023-09-26 01:48:17,Using GPT-4 to measure creativity in responses to a study.,Henry-T-01,False,0.67,2,16samsg,https://www.reddit.com/r/learnmachinelearning/comments/16samsg/using_gpt4_to_measure_creativity_in_responses_to/,2,1695692897.0,"A friend of mine, who's pursuing a master's in psychology, is working on a thesis linking nice work environments to creativity.  She measured the creativity of participants by letting them list various creative ways of using a toothpick. I.e. ""cleaning your teeth"" wouldn't be considered creative but ""using it as a flag pole in a miniature town"" would. Now she has a few thousand suggestions on how to use toothpicks. She came to me asking wether I could show her how to code a program that could automatically assign a ""creativity score"" to these answers. I of course said that I considered this task to be way too complex to develop anything yourself, furthermore I'm just a math major without any real experience with language models capable of such a task. However, I had the idea to use OpenAI's GPT-4 API. So now we're thinking of writing a little script that takes the toothpick suggestions in batches of 10 and sends them to GPT with a prompt telling it to assign them a creativity score. Now I wanted to ask you all:

1. Do you even believe GPT-4 could handle this task effectively?
2. Any recommendations on formulating the prompt for best results?
3. Are there potential pitfalls or considerations we should be aware of?"
203,learnmachinelearning,gpt-4,relevance,2023-11-27 13:56:01,[D] Creating an Automated UI Controller with GPT-4 Vision & Agents,Outlandish_MurMan,False,0.73,5,1853i61,https://www.reddit.com/r/learnmachinelearning/comments/1853i61/d_creating_an_automated_ui_controller_with_gpt4/,0,1701093361.0,"Hey,

Last weekend, I managed to merge GPT-4 Vision with another GPT-4 and a device controller to work as a AutoGPT equivalent using AutoGen. Good thing is, it is not limited to Browser. It can work on any UI window. Let me know what you guys think and what can be done better.

Demo and approach available at: [https://medium.com/@gitlostmurali/creating-an-automated-ui-controller-with-gpt-agents-35340759d08b?sk=98d85484bd7e5e554f48a801728bfb68](https://medium.com/@gitlostmurali/creating-an-automated-ui-controller-with-gpt-agents-35340759d08b?sk=98d85484bd7e5e554f48a801728bfb68)

I'll update the repository soon -> [https://github.com/gitlost-murali/grounded-gpt-agents](https://github.com/gitlost-murali/grounded-gpt-agents)"
204,learnmachinelearning,gpt-4,relevance,2023-10-14 12:54:08,Using GPT-4 as the “Brains” of a Reinforcement Learning Problem,tylersuard,False,0.5,0,177owz1,https://medium.com/@ceo_44783/using-gpt-4-as-the-brains-of-a-reinforcement-learning-problem-516ff79aedb0,1,1697288048.0,
205,learnmachinelearning,gpt-4,relevance,2023-07-11 23:18:29,"[D] GPT-4 architecture clearly explained, in full detail",goo187,False,0.55,3,14x6y0k,https://www.reddit.com/r/learnmachinelearning/comments/14x6y0k/d_gpt4_architecture_clearly_explained_in_full/,3,1689117509.0,"EDIT:

My post derives the original GPT architecture from scratch (attention heads, transformers, and then GPT). But GPT-4's architecture was leaked a few days ago, and it turns out there are some differences.

To avoid confusion, I moved my original post over to

[https://www.reddit.com/r/learnmachinelearning/comments/14xz5v1/gpt3\_architecture\_explained\_clearly\_in\_full\_detail/](https://www.reddit.com/r/learnmachinelearning/comments/14xz5v1/gpt3_architecture_explained_clearly_in_full_detail/?utm_source=share&utm_medium=web2x&context=3)

&#x200B;"
206,learnmachinelearning,gpt-4,relevance,2023-04-22 05:51:13,Integrating Google search into OpenAI models like GPT-4,Ghost25,False,1.0,15,12uwd8p,https://www.reddit.com/r/learnmachinelearning/comments/12uwd8p/integrating_google_search_into_openai_models_like/,8,1682142673.0,"Thought I'd share an explanation of how I implemented Google search into my GPT-4 based chatbot.

Github here: https://github.com/sgreenb/pico_assistant

One extremally simple modification that dramatically improves the ability of a GPT to answer questions: letting it Google stuff.

Here’s a demo:

https://imgur.com/ZR6hvLg 1

The implementation works like this.

1. A user enters an input.
2. An agent called “Executive” looks at the input and decides if an API like Spotify, Twillio, or Gmail is needed or if it can be answered by the chatbot alone.
3. If the chatbot is needed the input is first sent to a Google agent. The Google agent’s system message looks like this:

```
{""role"":""system"", ""content"": ""You analyze a user's input to a large language model with \
training data that cuts off at September 2021. The current year is 2023. You decide how \
likely it is that a user's request will benefit from a Google search to help address the\
question. Respond with a number in the range 1-10, where 1 is very unlikely that a \
Google search would be beneficial, and 10 meaning a Google search is highly necessary.""}
```

This is quite fast, since it only needs to generate one or two tokens.

If the output is above some threshold (say 7), then we call another agent, the query agent, otherwise we return False and default to the normal chat agent.

```
    google_probability = int(completion.choices[0].message.content)
    if google_probability >= cutoff:
        search_results = trim_text(search_and_scrape(prompt))
        query_with_context = prompt + str(search_results)
        print(""\nPico: "", end='', flush=True)
        response = query_agent_stream(query_with_context)
        return response
    else:
        return False
```

When we call the query agent, we feed it the first part of a Google search we get from searching the input. We get that from the very simple trim_text and search_and_scrape functions that look like this:

```

def search_and_scrape(query):
    try:
        headers = {
            ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3""
        }
        url = f""https://www.google.com/search?q={query}""
        response = requests.get(url, headers=headers)

        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text()
            cleaned_text = ' '.join(text.split())
            return cleaned_text
        else:
            print(f""Failed to fetch search results for query: {query}, status code: {response.status_code}"")
            return None

    except Exception as e:
        print(f""Error fetching search results for query: {query}, error: {e}"")
        return None

def trim_text(text, start_index = 450, length=1500):
    return text[start_index:start_index + length]
```

The query agent has this system message:

```
{""role"":""system"", ""content"": ""You answer a user's question, given some text as context to help\
answer the question. The user request will be followed by the context. The context given is\
from the user's Google search results, it is current and up to date.\
Do not contradict the contents of the given text in your answer.""}
```

And that’s it. You can change the cutoff threshold or get more sophisticated with fetching web results. I hope you find this useful."
207,learnmachinelearning,gpt-4,relevance,2023-03-15 01:54:30,How good is GPT-4 compared to ChatGPT?,OnlyProggingForFun,False,0.36,0,11riiip,https://youtu.be/GroMQETFXLc,1,1678845270.0,
208,learnmachinelearning,gpt-4,relevance,2023-09-02 17:47:34,LLaVA: Bridging the Gap Between Visual and Language AI with GPT-4,OnlyProggingForFun,False,1.0,1,1688v48,https://youtu.be/Pn1B_L_zAwI,1,1693676854.0,
209,learnmachinelearning,gpt-4,relevance,2023-09-21 17:40:16,Learning about LLM tokenizers by comparing GPT-4 vs. BERT vs. Starcoder and more [Video],jayalammar,False,1.0,4,16om3eg,https://www.youtube.com/watch?v=rT6wVLEDC_w,0,1695318016.0,
210,learnmachinelearning,gpt-4,relevance,2023-04-28 16:04:48,A Lightweight Alternative to GPT-4 for Enhanced Vision-language Understanding,kingabzpro,False,0.95,18,131yxdl,https://www.kdnuggets.com/2023/04/minigpt4-lightweight-alternative-gpt4-enhanced-visionlanguage-understanding.html,0,1682697888.0,
211,learnmachinelearning,gpt-4,relevance,2023-04-19 15:26:42,How to Get Hired as Data Scientist in the GPT-4 Era,kingabzpro,False,0.22,0,12rxm7r,https://www.reddit.com/r/learnmachinelearning/comments/12rxm7r/how_to_get_hired_as_data_scientist_in_the_gpt4_era/,2,1681918002.0,"In this post, I share some tips and insights on how to stand out in the competitive data science job market, especially with the rise of GPT-4 and other advanced NLP models.  


**You will learn how to:**

* Brush up on your statistics and core data science concepts, and how to apply them in real-world scenarios.
* Master the skills of NLP and prompt engineering, and how to leverage GPT-4 for various data science tasks.
* Build a data science portfolio that showcases your projects and achievements, and how to use GitHub, Medium, and Kaggle to showcase your work.
* Prepare for data science interviews, and how to ace the technical, behavioral, and case study questions.
* Explore the emerging field of AIOps, and how to use data science to automate and optimize IT operations.

[https://www.kdnuggets.com/2023/04/get-hired-data-scientist-gpt4-era.html](https://www.kdnuggets.com/2023/04/get-hired-data-scientist-gpt4-era.html)

I hope you find this post useful and informative. Please feel free to share your feedback and comments."
212,learnmachinelearning,gpt-4,relevance,2023-03-16 12:50:13,Alpaca - Train Your GPT-4 for Less Than $100,deeplearningperson,False,0.11,0,11st9ed,https://www.reddit.com/r/learnmachinelearning/comments/11st9ed/alpaca_train_your_gpt4_for_less_than_100/,0,1678971013.0,[https://youtu.be/6qdzsDSduww](https://youtu.be/6qdzsDSduww)
213,learnmachinelearning,gpt-4,relevance,2023-07-07 14:29:33,Do I need to update anything on my PC to start using GPT-4 with the API?,123android,False,0.55,1,14t8vug,https://www.reddit.com/r/learnmachinelearning/comments/14t8vug/do_i_need_to_update_anything_on_my_pc_to_start/,7,1688740173.0,"I have a python app and was using ""gpt-3.5-turbo"" as my model value. It works fine with that.

I heard about the gpt-4 general availability today and say it's available to everyone, so I switched the value in my ""model"" variable to ""gpt-4"" and I started getting an invalid request error. Also tried ""gpt-4-0613"", same thing.

Do I need to update some local libraries or something like this?"
214,learnmachinelearning,gpt-4,relevance,2023-06-05 17:21:46,"GPT Weekly - 5th June Edition: Peek into OpenAI's future, GPT-4 Quality concerns, Risk of AI and more.",level6-killjoy,False,0.67,1,141llju,https://www.reddit.com/r/learnmachinelearning/comments/141llju/gpt_weekly_5th_june_edition_peek_into_openais/,0,1685985706.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 AI news in the past week
* 🗞️10 AI news highlights and interesting reads
* 🧑‍🎓3 Learning Resources

# 🔥Top 3 AI news in the past week

## 1. OpenAI plans as per Sam Altman

The CEO of Humanloop had a sit down with Sam Altman and 20 other developers. He discussed the [current and future of OpenAI](https://humanloop.com/blog/openai-plans). The blog was later taken down at the request of OpenAI. [Now it can be found at this link](https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans). 

The whole post is an interesting read. Some of the highlights for me were:

1. GPT-3 was not open-source because OpenAI didn’t think many people would be able to run large LLMs. This sounds like a cop-out. After all, LLaMA is also a large LLM and has helped the community.
2. OpenAI is limited by GPU power.
3. OpenAI will not enter the market, except ChatGPT. Though technically this doesn’t say what Microsoft might do. They are already plugging GPT4 into every other product. And they have no rate limitations. 

## 2. Is GPT-4 Quality going down?

This has been a recently trending topic.

Discussed on HN: [https://news.ycombinator.com/item?id=36134249](https://news.ycombinator.com/item?id=36134249)

Discussed on Reddit: [https://www.reddit.com/r/ChatGPT/comments/13xik2o/chat\_gpt\_4\_turned\_dumber\_today/](https://www.reddit.com/r/ChatGPT/comments/13xik2o/chat_gpt_4_turned_dumber_today/)

The interesting thing is that the quality judgment is around the same topic - Coding.

The person on HN says GPT4 is faster but generates buggy code with less in-depth analysis. 

While the person on Reddit says that the context window seems smaller. Chatbot cannot remember earlier code. It cannot distinguish between code and comment.

While an employee at OpenAI says [nothing has changed](https://twitter.com/OfficialLoganK/status/1663934947931897857).

Has something really changed? 

One theory is that while the model might be static the ChatGPT prompt might’ve changed to restrict answers. Everyone was having fun trying to get bomb recipes out of ChatGPT. Now everyone is paying the price. 

https://i.imgflip.com/7nlatp.jpg

Another theory is that ChatGPT has always been terrible. It just survived because of novelty. As the novelty wears off people are realizing that it isn’t as great as everyone thought. 

My theory is that this might be the after effect of trying to get to a “[Cheaper and faster GPT-4” as highlighted by Sam Altman](https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans). The trade-off is speed vs accuracy. If it is slightly faster but with slightly worse results, then it might work as well. It is no longer GPT-4, rather GPT-3.75.

## 3. Risk of AI = Pandemic and Nuclear War

Center for AI Safety [released a statement](https://www.safe.ai/statement-on-ai-risk) highlighting the risks of AI:

*Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.*

We have seen the warnings about risks of AI get dire and dire. First it was only people asking for a [pause on AI development for 6 months](https://www.theguardian.com/technology/2023/mar/31/ai-research-pause-elon-musk-chatgpt) then came [George Hinton](https://gptweekly.beehiiv.com/p/googles-startling-leaked-memo-george-hinton-mojo), and last week OpenAI asked for [AI to be regulated using the IAEA framework](https://gptweekly.beehiiv.com/p/future-ai-integration). 

This statement is not really a step up. It reads like a one line, summarized repetition of [OpenAI's statement](https://openai.com/blog/governance-of-superintelligence). 

The statement gains importance from its signatories. Some of the people include:

Geoffrey Hinton - Emeritus Professor of Computer Science, University of Toronto

Demis Hassabis - CEO, Google DeepMind

Sam Altman - CEO, OpenAI

Dario Amodei - CEO, Anthropic

Bill Gates - Gates Ventures

To name a few. 

There are two issues with the statement though. 

First, this might just be [fear-mongering](https://aisnakeoil.substack.com/p/is-avoiding-extinction-from-ai-really). The idea is to push governments into making AI a highly regulated industry. This would stop any open source efforts which can compete with the big companies. After all, you don’t really have open source alternatives for nuclear energy, right? 

Second, no one really knows how to regulate AI. There have been [voluntary rules from Google](https://gptweekly.beehiiv.com/p/future-ai-integration) and the EU AI act is in a very early stage. And the genie is already out of the bottle. People can create AI models in their basement. How do you pull that back?

# 🗞️10 AI news highlights and interesting reads

1. A follow-up to the story about a lawyer submitting fake cases from [last edition](https://gptweekly.beehiiv.com/p/future-ai-integration). As I said, this might lead some people in the legal community to doubt any sort of GPT tool.[ A federal judge has banned AI-only filings in his courtroom](https://arstechnica.com/tech-policy/2023/05/federal-judge-no-ai-in-my-courtroom-unless-a-human-verifies-its-accuracy/). The filings have to be written by a human or at least human-verified. 
2. [The Japanese government will not apply copyright law to the AI training data](https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/). This is interesting because using copyright data to train AI has been an issue. Sam Altman didn’t have a clear answer when he [appeared in front of Congress](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). The other interesting aspect is going to be whether someone can use GPT-4 data to train their own LLM. Is that copyrightable?  
3. [The Falcon 40-B model is now Apache 2.0](https://twitter.com/Thom_Wolf/status/1663986216771936263). That means you can use the model for commercial usage for free. This is good news for companies which need an instruction tuned model which beats LlaMA.
4. Photoshop's generative-fill feature is really good. Some of the [cool examples on Twitter](https://twitter.com/_Borriss_/status/1663568770408013831).
5. [An AI camera with no lens](https://twitter.com/BjoernKarmann/status/1663496103998750721). It gets the location, weather etc details from GPS and then passes it as a prompt to the image generator. Results are pretty cool. 
6. SEO isn’t changing any time soon. [Google’s generative SEO is very slow](https://www.theverge.com/23746083/google-ai-search-generative-experience-slow). 
7. [Chirper.AI](https://chirper.ai/) is a social media only for bots. No humans allowed. I just wonder if Twitter bots go there will Twitter become a ghost town?
8. [OpenAI now has a security portal ](https://trust.openai.com/)where you can see how they secure data (encryption at rest), backups, Pentest reports etc. This might be a step in the direction towards [ChatGPT business](https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt). Large corporations look at these policies before they consider any SaaS implementation. 
9. [Banks have stepped up hiring for AI roles with JP Morgan leading the way. ](https://www.bloomberg.com/news/features/2023-05-31/jpmorgan-s-push-into-finance-ai-has-wall-street-rushing-to-catch-up)
10. [AI code writing might not be the best idea. It will lead to tech debt and shabbily maintained and written code. ](https://www.wsj.com/articles/ai-is-writing-code-now-for-companies-that-is-good-and-bad-6f19ecdc)

# 🧑‍🎓3 Learning Resources

1. Couple of courses in Generative AI:
   1. [https://www.deeplearning.ai/short-courses/](https://www.deeplearning.ai/short-courses/)
   2. Google: [https://www.cloudskillsboost.google/paths/118](https://www.cloudskillsboost.google/paths/118)
2. Build your own Sketch to image app: [https://www.tryleap.ai/docs/how-to-build-a-sketch-to-image-app-with-leap-remix](https://www.tryleap.ai/docs/how-to-build-a-sketch-to-image-app-with-leap-remix)

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
215,learnmachinelearning,gpt-4,relevance,2022-10-16 16:57:07,What We Know About GPT-4 So Far,kingabzpro,False,0.81,10,y5lrld,https://www.datacamp.com/blog/what-we-know-gpt4,0,1665939427.0,
216,learnmachinelearning,gpt-4,relevance,2023-07-25 20:56:55,Hi r/learnmachinelearning! To make CUDA development easier I made a GPT-4 powered NVIDIA bot that knows about all the CUDA docs and forum answers (demo link in comments),srnsnemil,False,0.96,169,159kt6u,https://v.redd.it/58hbh8q0d6eb1,15,1690318615.0,
217,learnmachinelearning,gpt-4,relevance,2023-03-16 05:52:25,"Here's a summary of GPT-4 interesting features and it's livestream, blog, website articles",crower12,False,0.55,1,11sllq8,https://youtu.be/PNk_10Fdb9Y,1,1678945945.0,
218,learnmachinelearning,gpt-4,relevance,2023-08-22 17:01:00,"🚀 UrbanAI: Visual GPT-4 Tutor 🚀 Learn Anywhere, at an Instant. Check it out → urbanedu.ai/chat",team_urbanai,False,0.5,0,15ybr2g,https://www.reddit.com/r/learnmachinelearning/comments/15ybr2g/urbanai_visual_gpt4_tutor_learn_anywhere_at_an/,0,1692723660.0,"🎓 Boundless Learning, from private & public sources. 🎓

**Gone are the days of being lost in endless browser tabs and outdated content.** Meet UrbanAI, your next-generation study companion built by Stanford TA and AI researchers. Whether you are a student or professional, no more switching between multiple platforms. All your learning resources, integrated seamlessly, with an option to collaborate with friends and teachers.

# Why UrbanAI?

📘 **One-Stop Knowledge Hub**: Get updated content for your projects or a recap of last semester's lessons. Why settle for chatbots that are stuck in 2021? With us, the future is now.

🖼️ **Visual Learning**: Ask about a video lecture. Quickly extract content, get visual answers, and even direct citations. Confused? Just highlight, search, and get clarity in an instant.

🚀 **Tailored Learning Path**: Learning isn’t one-size-fits-all. Bookmark, refresh, and explore topics at your pace. Stay tuned for AI-generated challenges to hone your knowledge.

# Crafted for Tomorrow's Scholars:

🌐 **Updated & Relevant Insights**: Access data from the latest websites, visuals, and PDFs.

💡 **Immersive Interactions:** Experience the might of GPT-4, supercharged with visuals and cited sources.

🧭 **Online Exploration:** Deepen comprehension with question templates and configurable web dives.

✔️ **Trustworthy Data:** 'Factual Mode' for verified insights, whether from global sources or your network.

# Shape Your Learning, Your Way

True education isn't just about answers; it's about the journey and experience. We're evolving each day, just like you, making learning richer and more engaging. Invite friends and get a $50 credit, plus exclusive GPT-4 access: [urbanedu.ai/referral](https://urbanedu.ai/referral).

Your support, feedback, and shares can make a world of difference. Let's redefine learning together. 💙"
219,learnmachinelearning,gpt-4,relevance,2023-04-10 20:31:01,"SearchBot9k - Searches Google, checks result pages, answers the question in a headless browser using the GPT-4 or ChatGPT API [JS]",pale2hall,False,1.0,5,12hv6qn,https://www.reddit.com/r/learnmachinelearning/comments/12hv6qn/searchbot9k_searches_google_checks_result_pages/,0,1681158661.0,"Hey guys, I made a simple Node.js script to search google

1. User runs script with a question
2. initial prompt sent to AI
3. AI comes up with a search phrase
4. SERP (search engine result page) sent to AI
5. AI has a 'memory' field 
6. We loop till we find an answer while the AI: Answers the Question, Starts a new Search, or Loads a URL

All the while the user gets to watch what page is being browsed in an electron-based pop-up window, and the AI can update a 'memory' that is passed back to it to keep it on track.

The AI uses JSON to respond.

Project: [https://github.com/pale2hall/SearchBot9k](https://github.com/pale2hall/SearchBot9k)

I welcome any feedback suggestions, if anyone wants to work on it / make a PR, feel free.  I'll be developing it in my spare time too.

Current Todo:

* Refactor code / break functions into individual files
* Separate Prompt vs JS
* Handle looping / make 
* Make Memory always contain previous searches and urls so it doesn't get stuck in a loop.
* Count tokens instead of Characters when truncating results for the AI"
220,learnmachinelearning,gpt-4,relevance,2023-12-25 17:15:18,"Have we reached a ceiling with transformer-based models? If so, what is the next step?",swagonflyyyy,False,0.86,64,18qmohw,https://www.reddit.com/r/learnmachinelearning/comments/18qmohw/have_we_reached_a_ceiling_with_transformerbased/,134,1703524518.0,"About a month ago Bill Gates hypothesized that models like GPT-4 will probably have reached a ceiling in terms of performance and these models will most likely expand in breadth instead of depth, which makes sense since models like GPT-4 are transitioning to multi-modality (presumably transformers-based).

This got me thinking. If if is indeed true that transformers are reaching peak performance, then what would the next model be? We are still nowhere near AGI simply because neural networks are just a very small piece of the puzzle. 

That being said, is it possible to get a pre-existing machine learning model to essentially create other machine learning models? I mean, it would still have its biases based on prior training but could perhaps the field of unsupervised learning essentially construct new models via data gathered and keep trying to create different types of models until it successfully self-creates a unique model suited for the task?

Its a little hard to explain where I'm going with this but this is what I'm thinking:

\- The model is given a task to complete.

\- The model gathers data and tries to structure a unique model architecture via unsupervised learning and essentially trial-and-error.

\- If the model's newly-created model fails to reach a threshold, use a loss function to calibrate the model architecture and try again.

\- If the newly-created model succeeds, the model's weights are saved.

This is an oversimplification of my hypothesis and I'm sure there is active research in the field of auto-ML but if this were consistently successful, could this be a new step into AGI since we have created a model that can create its own models for hypothetically any given task?

I'm thinking LLMs could help define the context of the task and perhaps attempt to generate a new architecture based on the task given to it but it would still fall under a transformer-based model builder, which kind of puts us back in square one."
221,learnmachinelearning,gpt-4,relevance,2023-12-07 01:31:55,Why can't AI models do complex math?,open_23,False,0.7,41,18ck15r,https://www.reddit.com/r/learnmachinelearning/comments/18ck15r/why_cant_ai_models_do_complex_math/,93,1701912715.0,"Computers, at its most fundamental level, is made up of boolean logic. Mathematics is basically the language of logic.

SHouldn't AI models, or computers in general be able to do more advanced math than just crunching large numbers? Why haven't anyone used computers to solve any of the Millenium Prize Problems or some other difficult proof. 

GPT-4 and recently  Gemini, has decent enough grade school level math solving capabilities but absolute atrocious at solving slightly more complex problems. But, I guess thats to be expected since they're LLMs. But, why hasn't anyone built an AI model geared towards just solving mathemaths problems? Also, what kind of different architecture would such a model need?"
222,learnmachinelearning,gpt-4,relevance,2024-02-11 09:08:25,Why Gemini Ultra Outshines ChatGPT 4: Performance Comparison,UseCreative4765,False,0.5,0,1ao3w9h,https://youtu.be/eu20jiYenNw?si=sdBOWE_VajUymbEg,0,1707642505.0,
223,learnmachinelearning,gpt-4,relevance,2023-11-27 14:01:11,Are SOTA LLMs(LMMs?) going to be much smaller in the future?,open_23,False,0.72,3,1853m18,https://www.reddit.com/r/learnmachinelearning/comments/1853m18/are_sota_llmslmms_going_to_be_much_smaller_in_the/,8,1701093671.0,"Since most LLMs these days are becoming multi-modal, with capabilities to browse the web and parse information from given files, will they become much smaller as they'll need to be trained on less data?

Models like GPT-3, which has 175B parameters, are that big because they are trained on a ton of information from the internet which they can retrieve from their data for the user. Thats why GPT-4 is so useful, because it is trained on so many things, it can help on a wide range of topics.

But, now that GPT-4 has plugins, and also the ability to browse the web, will it need to be trained on so much data. If the user needs help on a particular topic, it can just search the web for the information and then present it to the user. I t would save a lot of training time and data.

For the purposes of it just being able to speak English correctly, it needs relatively little data. The TinyStories models, with 10-30M parameters, perform pretty decently as a LM. It only neededsimple english vocabulary to learn to speak it properly. So, in the future, will we see base SOTA models be 7-13B with multimodal vision, voice, file parsing, and most importantly, web browsing capabilities, which will perform as good as today's GPT-4?"
224,learnmachinelearning,gpt-4,relevance,2023-12-03 14:38:25,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.92,49,189ustx,https://www.reddit.com/r/learnmachinelearning/comments/189ustx/this_week_in_ai_all_the_major_ai_developments_in/,1,1701614305.0,"1. **Meta AI** introduced a suite of AI language translation models that preserve expression and improve streaming \[[*Details*](https://ai.meta.com/blog/seamless-communication) *|* [*GitHub*](https://github.com/facebookresearch/seamless_communication)\]:
   1. ***SeamlessExpressive*** enables the transfer of tones, emotional expression and vocal styles in speech translation. You can try a demo of SeamlessExpressive using your own voice as an input [***here***](https://seamless.metademolab.com/expressive)***.***
   2. ***SeamlessStreaming***, a new model that enables streaming speech-to-speech and speech-to-text translations with <2 seconds of latency and nearly the same accuracy as an offline model. In contrast to conventional systems which translate when the speaker has finished their sentence, SeamlessStreaming translates while the speaker is still talking. t intelligently decides when it has enough context to output the next translated segment.
   3. ***SeamlessM4T v2***, a foundational multilingual & multitask model for both speech & text. It's the successor to SeamlessM4T, demonstrating performance improvements across ASR, speech-to-speech, speech-to-text & text-to-speech tasks.
   4. ***Seamless***, a model that merges capabilities from SeamlessExpressive, SeamlessStreaming and SeamlessM4T v2 into one.
2. **Stability AI** released ***SDXL Turbo***: a real-time Text-to-Image generation model. SDXL Turbo is based on a a new distillation technology, which enables the model to synthesize image outputs in a single step and generate real-time text-to-image outputs while maintaining high sampling fidelity.
3. **Mozilla’s** innovation group and Justine Tunney released ***llamafile*** that lets you distribute and run LLMs with a single file. llamafiles can run on six OSes (macOS, Windows, Linux, FreeBSD, OpenBSD, and NetBSD) and on multiple CPU architectures.
4. **Perplexity** released two new PPLX models: ***pplx-7b-online and pplx-70b-online***. These *online LLMs* can leverage the most up-to-date information using the internet when forming a response..
5. **Google DeepMind** presented ***GNoME*** (Graph Networks for Materials Exploration): an AI tool that discovered *2.2 million new crystal structures*, with 380,000 being highly stable and promising for breakthroughs in superconductors, supercomputers, and advanced batteries for electric vehicles.
6. **Amazon** introduced two new Amazon Titan multimodal foundation models (FMs): ***Amazon Titan Image Generator*** (preview) and ***Amazon Titan Multimodal Embeddings***. All images generated by Amazon Titan contain an invisible watermark.
7. Researchers present ***Animatable Gaussians***, a new avatar representation method that can create lifelike human avatars from multi-view RGB videos.
8. **Pika Labs** released a major product upgrade of their generative AI video tool, ***Pika 1.0***, which includes a new AI model capable of generating and editing videos in diverse styles such as 3D animation, anime, cartoon and cinematic using text, image or existing video.
9. **Eleven Labs** announced a ***grant*** program offering 11M text characters of content per month for the first 3 months to solo-preneurs and startups.
10. Researchers from **UC Berkeley** introduced ***Starling-7B***, an open large language model trained using Reinforcement Learning from AI Feedback (RLAIF). It utilizes the GPT-4 labeled ranking dataset, Nectar, and a new reward training pipeline. Starling-7B outperforms every model to date on MT-Bench except for OpenAI’s GPT-4 and GPT-4 Turbo .
11. **XTX Markets** is launching a new $10mn challenge fund, the **Artificial Intelligence Mathematical Olympiad Prize** (AI-MO Prize) The grand prize of $5mn will be awarded to the first publicly-shared AI model to enter an AI-MO approved competition and perform at a standard equivalent to a gold medal in the in the International Mathematical Olympiad (IMO) .
12. **Microsoft Research** evaluated GPT-4 for processing ***radiology reports***, focusing on tasks like disease classification and findings summarization. The study found GPT-4 has a sufficient level of radiology knowledge with only occasional errors in complex context that require nuanced domain knowledge. The radiology report summaries generated by GPT-4 were found to be comparable and, in some cases, even *preferred* over those written by experienced radiologists.
13. **AWS** announced ***Amazon Q***, a new generative AI–powered assistant for businesses. It enables employees to query and obtain answers from various content repositories, summarize reports, write articles, perform tasks, and more, all within their company's integrated content systems. Amazon Q offers over 40 built-in connectors to popular enterprise systems.
14. 18 countries including the US, Britain signed a detailed international agreement on how to keep artificial intelligence safe from rogue actors, pushing for companies to create AI systems that are ‘secure by design’ .

**Source**: AI Brews - you can subscribe [here](https://aibrews.com/). it's free to join, sent only once a week with ***bite-sized news, learning resources and selected tools.*** I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks."
225,learnmachinelearning,gpt-4,relevance,2023-12-31 17:01:12,Andrew Ng On How To Read Machine Learning Papers (Summary by GPT-4),ledmmaster,False,0.72,9,18vbz75,https://forecastegy.com/posts/read-machine-learning-papers-andrew-ng/,2,1704042072.0,
226,learnmachinelearning,gpt-4,relevance,2024-02-03 18:25:41,New AI Innovations Transforming Your World – AI News Update – Jan 2024 Rap-up,Science-man777,False,0.2,0,1ai2loa,https://www.reddit.com/r/learnmachinelearning/comments/1ai2loa/new_ai_innovations_transforming_your_world_ai/,0,1706984741.0," A cool article on the AI News you May have missed:

1. AI and LayOffs Are a Thing Already
2. OpenAI Introduces GPT Mentions
3. X Secures Georgia Tax Break for $700M AI Data Center
4. Bard Surpasses GPT-4 on Chatbot Leaderboard
5. Self-Rewarding Language Models
6. LLaMa-2 70B
7. The Rise of a New Alignment Method
8. The SuperAlignment Problem
9. The Self-Improving Paradigm
10. Alienating Humans
11. The Threat of a Global AI Tax
12. AI and the Current Economy

https://ai-solutions.pro/ai-news-1/ "
227,learnmachinelearning,gpt-4,relevance,2023-10-26 14:51:08,5 Game-Changing Applications of GPT-4: No Coding Skills Required!,OnlyProggingForFun,False,0.67,1,17gy9xb,https://youtu.be/lwNy4lgDpjY,0,1698331868.0,
228,learnmachinelearning,gpt-4,relevance,2023-05-15 06:27:00,Bilingual people : How good is AI at machine translation today?,moschles,False,0.83,20,13hzvkc,https://www.reddit.com/r/learnmachinelearning/comments/13hzvkc/bilingual_people_how_good_is_ai_at_machine/,22,1684132020.0,"In the wake of GPT-4 and chatGPT, how good would you rank machine translators in terms of their accuracy?

Are they only useful for one-off sentences? Do they fail when presented with any kind of moderately complex articles? Do they perform vastly different depending on the languages?     Are they still really stupid, or does their output blow you away now?"
229,learnmachinelearning,gpt-4,relevance,2023-04-19 04:10:25,"GPT-4, my best study buddy!",Somomi_,False,0.57,1,12rgan0,https://www.reddit.com/r/learnmachinelearning/comments/12rgan0/gpt4_my_best_study_buddy/,0,1681877425.0,"Today I find several prompts which could be very helpful for active learning.

 **1. Generate Multiple Choice Question**

*Topic: { }*

*Write 3 multiple choice question with 1 correct answer and 3 incorrect distractor answers and let me choose an answer. Later you should let me know if I got it right or wrong and provide me with explanation.*

 

**2. Generate General Question**

>*Topic: { }*  
*Write 2* *data scientist interview questions* *about this topic and let me answer them. Later you should let me know if I got it right or wrong and provide me with explanation.*

 

**3. Learning by Teaching**

>*Please act as a data scientist. I will tell you what I l*  
*earn today and you can point out if I miss any step or made any mistake.*  
*Today I learn { }*

You can check my originalwith example image post here! Thank you!

[https://www.kaggle.com/code/kuixizhu/gpt-4-my-best-study-buddy](https://www.kaggle.com/code/kuixizhu/gpt-4-my-best-study-buddy)"
230,learnmachinelearning,gpt-4,relevance,2023-11-08 16:56:45,[P] Top 5 AI Announcements (and Implications) from the 1st OpenAI DevDay,vykthur,False,0.72,3,17qq0z9,https://www.reddit.com/r/learnmachinelearning/comments/17qq0z9/p_top_5_ai_announcements_and_implications_from/,0,1699462605.0,"OpenAI recently had the first   developer day, featuring several new announcements

https://preview.redd.it/ep1scxynm5zb1.png?width=1456&format=png&auto=webp&s=4be58601b9a0fb9bcc1ff17d25560257f895dca2

&#x200B;

Full post here: [https://newsletter.victordibia.com/p/top-5-ai-announcements-and-implications](https://newsletter.victordibia.com/p/top-5-ai-announcements-and-implications) 

TLDR.

* **💰📉 Cost Reduction**: The new GPT-4 and GPT-3.5 Turbo models are more capable yet cost less. 🤯🤯.
* **📈🧠 Improved Model Capabilities**: GPT-4 now includes a 128K token version (300 pages of text), features an updated knowledge cutoff (previously April 2021, now April 2023), and offers improved function calling.
* **🎛️🔧 Improved Model Control**: The new model series can generate valid JSON-formatted responses using a \`response\_format\` parameter and supports reproducible results through a seed parameter. Additionally, there is upcoming support for accessing log probabilities of generated tokens.
* **🤖🔗Agents: The Assistant API**: This API supports the **creation of agents** that can utilize external knowledge (RAG), **act** via tools (e.g., code execution and function calling), and maintain infinitely long conversations through Threads. All of this in a unified api for building agents.
* **🤖🛍️Agents: GPTAgents and Agent Store**: OpenAI will create a store where developers can bundle and share GPT agents with some revenue sharing. An Agent here is an LLM+Knowledge+Tools. 

&#x200B;

**High Level Implications** 

\- Cost reductions could make these models more practical to use (cost competitive with running smaller models at scale). 

&#x200B;

[Pricing of OpenAI models show cost reductions in successive GPT models from March - Nov 2023 . Davinci Source https:\/\/openai.com\/pricing](https://preview.redd.it/hfvytscem5zb1.png?width=1456&format=png&auto=webp&s=516a263a9b98165043c7b41946b70cce791cc861)

&#x200B;

&#x200B;

https://preview.redd.it/skio4eohm5zb1.png?width=1196&format=png&auto=webp&s=57299651d05a9469a90506e0b4724649c834b6ed

\- The Assistant API facilitates prototyping complex agent workflows, eliminating the extensive infrastructure work that was previously burdensome, such as implementing a RAG workflow, managing long conversation contexts, and executing code.

\- The capability to generate output constrained to a valid JSON format, the option to set a seed for reproducibility, and access to log probabilities are significant steps toward addressing **reliability issues** with large language models (LLMs).

While some of the ideas introduced may not be entirely new, they certainly represent significant quality-of-life improvements for engineers attempting to build Generative AI apps."
231,learnmachinelearning,gpt-4,relevance,2023-04-14 11:37:08,Post GPT-4: Answering Most Asked Questions About AI,kingabzpro,False,0.94,16,12luajw,https://www.kdnuggets.com/2023/04/post-gpt4-answering-asked-questions-ai.html,1,1681472228.0,
232,learnmachinelearning,gpt-4,relevance,2024-02-06 19:28:11,Are there any models you can finetune for reading handwriting?,Jealous_Afternoon669,False,0.75,2,1aki6w8,https://www.reddit.com/r/learnmachinelearning/comments/1aki6w8/are_there_any_models_you_can_finetune_for_reading/,2,1707247691.0,"I have dyspraxia and my handwriting is pretty terrible by most standards, but pretty consistent in that I can read it back and people who know me for a while can read it. There are small quirks like how my s's and l's get formed (I write in cursive) that make it nearly illegible for most people but once you know you know.

I was mainly curious if there's any kind of work that's been done on handwriting recognition in cases like this. I take it probably not because GPT-4 vision is really inconsistent at being able to read handwriting, but maybe there are more specialised models?

&#x200B;"
233,learnmachinelearning,gpt-4,relevance,2022-12-17 11:39:11,why everyone is talking about GPT-4?,M20s,False,0.13,0,zo4jrk,https://www.reddit.com/r/learnmachinelearning/comments/zo4jrk/why_everyone_is_talking_about_gpt4/,1,1671277151.0,
234,learnmachinelearning,gpt-4,relevance,2023-06-05 20:41:13,How does bits per word work in GPT4?,G_fucking_G,False,1.0,2,141r459,https://www.reddit.com/r/learnmachinelearning/comments/141r459/how_does_bits_per_word_work_in_gpt4/,0,1685997673.0,"In an image from the GPT-4 paper they show the scaling laws of GPT-4. They claim, that they can predict the final test loss with high accuracy

https://imgur.com/a/UfobOj5

On the y-axis of the graph is the metric ""bits per word"". What does this mean? How does this relate to crossentropy?

What does it mean, if a model has ~1.2 bits per word?

Full text

    To verify this scalability, we accurately predicted in advance 
    GPT-4’s final loss on our internal codebase (not part of the training set) 
    by extrapolating from models  trained using the same methodology 
    but using 10,000x less compute:"
235,learnmachinelearning,gpt-4,relevance,2023-12-28 20:01:12,"The best current models (Dolphin, Mixtral, Solar, Noromaid) and where to try them",Horror_Echo6243,False,0.75,2,18t30rt,https://www.reddit.com/r/learnmachinelearning/comments/18t30rt/the_best_current_models_dolphin_mixtral_solar/,0,1703793672.0,"I just saw a lot of people talking about this models so if you want to test them i found this websites that have all of them

\- [infermatic.ai](https://infermatic.ai/) (all of them)

\- [https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0](https://replicate.com/tomasmcm/solar-10.7b-instruct-v1.0) (for solar)

\- [https://huggingface.co/chat](https://huggingface.co/chat) (for mixtral)

Let me know if you find more, I'd like to know

And heres a little resume if you don't know what each model is for

Dolphin : An uncensored model derived from an open-source dataset, it uses instructions from FLANv2 enhanced with GPT-4 and GPT-3.5 completions​​.

Mixtral : An advanced text generation model using a Mix of Experts architecture

Solar : domain specialization and optimization. It's recognized for its high performance and efficiency

Noromaid: Storywriting and roleplay

&#x200B;"
236,learnmachinelearning,gpt-4,relevance,2023-11-24 15:42:36,[Discussion} Is it possible to built a Multi-LLM Assistant?,SykA196286,False,0.5,0,182uw4r,https://www.reddit.com/r/learnmachinelearning/comments/182uw4r/discussion_is_it_possible_to_built_a_multillm/,0,1700840556.0," 

  
For example with the following structure:

* System = GPT-4 Turbo + Llama2 +3rd LLM (!)+ Google or Bing API for websearch + Langchain + any vectorDB + Document upload + longterm Memory + …

Idee behind it is to get more accurate, updated (websearch) and specialized system or even let the LLms discuss your prompt before completion! Question is also, how shall the interaction of multiple LLMs in a system be organzied (Algorithm, Python Library …)? And what kind of Interaction can/should this be? Master-slave or Multi-Master system?"
237,learnmachinelearning,gpt-4,relevance,2023-08-18 05:00:05,"OpenAI Proxy Server for Llama2, GPT-4, Claude2 with User-based rate limiting, Key management, Logging,Cache",VideoTo,False,0.67,2,15uarkx,https://www.reddit.com/r/learnmachinelearning/comments/15uarkx/openai_proxy_server_for_llama2_gpt4_claude2_with/,2,1692334805.0,"**tldr;** We’re open sourcing our proxy server to call 50+ LLM models with logging, caching, key management, rate-limiting: [https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-...](https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-server/readme.md)

\--

Hi r/learnmachinelearning,

I’m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, Cohere, Anthropic, Hugging face API Endpoints: [https://github.com/BerriAI/litellm/](https://github.com/BerriAI/litellm/)

We’re open sourcing our implementation of liteLLM proxy: [https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-...](https://github.com/BerriAI/litellm/blob/main/cookbook/proxy-server/readme.md)

TLDR: It has one API endpoint /chat/completions and standardizes input/output for 50+ LLM models + handles logging, error tracking, caching, streaming

**What can liteLLM proxy do?** \- It’s a central place to manage all LLM provider integrations

\- **Consistent Input/Output Format** \- Call all models using the OpenAI format: completion(model, messages) - Text responses will always be available at \['choices'\]\[0\]\['message'\]\['content'\]

\- **Error Handling** Using Model Fallbacks (if GPT-4 fails, try llama2)

\- **Logging** \- Log Requests, Responses and Errors to Supabase, Posthog, Mixpanel, Sentry, Helicone

\- Token Usage & **Spend** \- Track Input + Completion tokens used + Spend/model

\- **User-based rate limiting** \- limit usage for bad actors

\- **Caching** \- Implementation of Semantic Caching

\- **Streaming & Async Support** \- Return generators to stream text responses

You can deploy liteLLM to your own infrastructure using Railway, GCP, AWS, Azure

Happy completion() !

https://i.redd.it/fhgifwb8wsib1.gif"
238,learnmachinelearning,gpt-4,relevance,2023-08-27 22:14:43,Running my own LLM,jrdubbleu,False,0.67,1,1633vfg,https://www.reddit.com/r/learnmachinelearning/comments/1633vfg/running_my_own_llm/,2,1693174483.0,"So if I setup an LLM ON AWS Sagemaker, or even locally for that matter, how do I interface with it? I do a lot of R coding and I’ve enjoyed using GPT-4 as a partner and I’d like to tryout CodeLlama and others just for fun. I know this is not especially straightforward. Are there any resources (I have watched a couple YouTube videos etc.) I can use to teach myself?"
239,learnmachinelearning,gpt-4,relevance,2023-12-13 12:56:32,5 Tools to Help Build Your LLM Apps,kingabzpro,False,0.5,0,18hg7j7,https://www.reddit.com/r/learnmachinelearning/comments/18hg7j7/5_tools_to_help_build_your_llm_apps/,0,1702472192.0,"In the era of advanced language model applications, developers and data scientists are continuously seeking efficient tools to build, deploy, and manage their projects. As large language models (LLMs) like GPT-4 gain popularity, more people are looking to leverage these powerful models in their own applications. However, working with LLMs can be complex without the right tools.

That's why I've put together this list of five essential tools that can significantly enhance the development and deployment of LLM-powered applications. Whether you're just beginning or are a seasoned ML engineer, these tools will help you be more productive and build higher-quality LLM projects.

**link:** [https://www.kdnuggets.com/5-tools-to-help-build-your-llm-apps](https://www.kdnuggets.com/5-tools-to-help-build-your-llm-apps)"
240,learnmachinelearning,gpt-4,relevance,2023-06-11 17:18:34,"[D] How to Choose a Framework To Evaluate Your LLMs? We've Evaluated GPT-4/3.5, Anthropic Claude, & Cohere Command Across 4 Tasks. Here's What We've Learned.",davidbun,False,0.98,111,146zie8,https://v.redd.it/yy5sdnvo6f5b1,1,1686503914.0,
241,learnmachinelearning,gpt-4,relevance,2023-04-01 03:06:13,"Title: ""Embracing the Future: Harnessing AI, GPT-4, and Moji AI for Content Creation and Social Media Engagement""",Large_Rush9013,False,0.33,0,1289ann,https://www.reddit.com/r/learnmachinelearning/comments/1289ann/title_embracing_the_future_harnessing_ai_gpt4_and/,0,1680318373.0,"Hey fellow Redditors, I'm so amazed by how far AI has come in recent years, and I'm really excited to share some ideas I've come across recently. I've been learning about GPT-4 and I discovered this amazing tool called Moji AI (mojiai.io) that helps with content writing and image generation using cutting-edge technology. 

Moji AI not only assists with content writing using GPT-4 but also provides image assets like icons for social media engagement. It's incredible how the new Stable Diffusion Models have improved the visual aspect of content generation! I find this technology truly impressive, and I believe it's going to make a huge impact in content creation and boosting engagement on social platforms.

As a person with a technical background, I've had the chance to explore and learn various aspects of machine learning, data science, and now diving into the GPT API. It's really fascinating to see the real-world applications of these technologies and how they can bring incredible value to users.

For those of you interested in learning more about AI, machine learning or even GPT, I'd highly recommend looking for beginner-friendly courses and tutorials online. The more we learn and understand these powerful tools, the better equipped we'll be to leverage them for exciting new projects and advancements in various fields.

Apart from this, I'd also like to hear your thoughts and experiences with modern AI advancements, tools like Moji AI, and any useful resources you may have come across that others can benefit from. Let's keep learning and exploring this exciting domain together!

Finally, if you're interested in checking out Moji AI for content writing and image generation, be sure to visit the website: [mojiai.io](https://www.mojiai.io)"
242,learnmachinelearning,gpt-4,relevance,2023-08-13 01:03:38,"Besides HHH, what is RLHF actually good for? Every example I've ever seen has focused on lobotomizing models.",JonBon13,False,0.89,14,15pl55g,https://www.reddit.com/r/learnmachinelearning/comments/15pl55g/besides_hhh_what_is_rlhf_actually_good_for_every/,5,1691888618.0,"Most instruction following & SFT seems likely to become unnecessary as those data sets leak into pre-training. However, it seems like RLHF is not a 1-size fits all solution. However, I've only seen real ""value add"" use cases for HHH. 

**Are there examples of RLHF models that are actually ""task specific"" or ""better than"" GPT-4 + prompting?** I've seen the OpenAI & other graphs that show humans rank RLHF > SFT, but the ""chat"" example seems so incredibly generic. Are there cases where you can actually squeeze out large performance for certain useful tasks only with RLHF? 

What are the buyers of RLHF data on Surge/Scale actually trying to get models to do?"
243,learnmachinelearning,gpt-4,relevance,2023-03-16 00:03:32,OpenAI's GPT 4 is out and it's multimodal! What we know so far,gordicaleksa,False,0.22,0,11sdxhz,https://www.youtube.com/watch?v=FY9Nlkoq4GI,0,1678925012.0,
244,learnmachinelearning,gpt-4,relevance,2023-04-04 18:03:20,Talk to ChatGPT-4 with your voice and even hear its responses spoken in your own voice.,TalkNowVoice,False,0.25,0,12br5jk,https://www.reddit.com/r/learnmachinelearning/comments/12br5jk/talk_to_chatgpt4_with_your_voice_and_even_hear/,1,1680631400.0,"[App Beta link.](https://testflight.apple.com/join/WYwS7eX5)

&#x200B;

https://reddit.com/link/12br5jk/video/4u14hkihqwra1/player"
245,learnmachinelearning,gpt-4,relevance,2023-08-29 03:52:11,"Open-Source CodeLlama Server: Streaming, Caching, Model Fallbacks (OpenAI + Anthropic), Prompt-tracking",VideoTo,False,1.0,9,1647o7n,https://www.reddit.com/r/learnmachinelearning/comments/1647o7n/opensource_codellama_server_streaming_caching/,0,1693281131.0,"**TLDR;** We're open-sourcing our CodeLlama server. It handles streaming, caching, model fallbacks, and tracks prompts + token usage - [https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server](https://github.com/BerriAI/litellm/tree/main/cookbook/codellama-server)

\~\~

Hello r/learnmachinelearning,

I’m the maintainer of liteLLM() - package to simplify input/output to OpenAI, Azure, TogetherAI, Cohere, Anthropic, Baseten, Hugging face API Endpoints: [https://github.com/BerriAI/litellm/](https://github.com/BerriAI/litellm/)

We're open sourcing our CodeLlama server:

What can our server do? - It uses Together AI's CodeLlama to answer coding questions, with GPT-4 + Claude-2 as backups (you can easily switch this to any model from Huggingface, Replicate, Cohere, AI21, Azure, OpenAI, etc.)

Consistent Input/Output Format - Call all models using the OpenAI format: completion(model, messages) - Text responses will always be available at \['choices'\]\[0\]\['message'\]\['content'\]

* Streaming & Async Support - Return generators to stream text responses
* Error Handling Using Model Fallbacks (if Phind-CodeLlama fails, use Claude-2, fine-tuned GPT-3.5 etc.)
* Logging - It's integrated with promptlayer, so you can automatically track your prompt + model changes there.
* Token Usage & Spend - Track Input + Completion tokens used + Spend/model
* Caching - In-memory + Redis Cache solutions provided (works for streaming too!).

You can deploy liteLLM to your own infrastructure using Railway, GCP, AWS, Azure

Happy completion() !"
246,learnmachinelearning,gpt-4,relevance,2023-06-26 17:20:42,"GPT Weekly - 26the June Edition - 🎙️ Meta's Voicebox is Paused, 🖼️SDXL 0.9, 📜AI Compliance & EU Act and more",level6-killjoy,False,0.67,1,14jncn1,https://www.reddit.com/r/learnmachinelearning/comments/14jncn1/gpt_weekly_26the_june_edition_metas_voicebox_is/,0,1687800042.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 news - Meta’s VoiceBox Paused, SDXL 0.9 and Open AI vs EU Act
* 🗞️Interesting reads GPT-4’s huge size, AI programming and teaching and more.
* 🧑‍🎓Learning - Transformers, RHLF and Interactive Notebooks

# 🔥Top 3 AI news in the past week

## 1. Meta's Voicebox: Release Pause

Meta, just like OpenAI, is on a roll. [They released introduced a speech generative model called Voicebox](https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/). It can perform a range of speech-generation tasks it wasn't specifically trained for. 

It's like generative systems for images and text, capable of crafting a variety of styles. It can even modify provided samples. It's multilingual, covering six languages, and can remove noise, edit content, convert styles, and generate diverse samples.

**Why is it important?** Before Voicebox, each speech AI task required individual training with curated data. This game-changing model learns from raw audio and corresponding transcriptions. In contrast to previous autoregressive audio models, Voicebox can adjust any part of a sample, not merely the tail end.

**What’s next?** Meta has just “introduced” Voicebox without a proper release. As per them Voicebox model is ripe for misuse. 

[Considering last week’s promise of free to use LLMs](https://gptweekly.beehiiv.com/p/new-pricing-models-functions-openais-new-updates), this seems like a step back. This might be a reaction to pushback due to Llama or maybe there are unseen profits.

Though there is already a community implementation in progress:

[https://github.com/SpeechifyInc/Meta-voicebox](https://github.com/SpeechifyInc/Meta-voicebox)

## 2. SDXL vs. Midjourney: The Imaging Race

&#x200B;

https://preview.redd.it/w0gb0axzbe8b1.png?width=787&format=png&auto=webp&s=26c0d4228c987362c8a4ccb93ca322dcd44cc6d7

[Stability announced SDXL 0.9 their new text to image model](https://stability.ai/blog/sdxl-09-stable-diffusion). They are now one step closer to a full 1.0 release. 

**Why is it important?** Stable Diffusion is one of the text to image models which can be run on a consumer pc. At least one which has an Nvidia GeForce RTX 20 graphics card. This releases multiple features like using an image to generate variations, filling missing parts of an image and out-painting to extend images. 

**What’s next?** Last week, Midjourney also released v5.2 which also has out-painting features and sharper images.

Stability is providing the SDXL 0.9 weights for research purposes. And they will be releasing 1.0 under the CreativeML license. Something to look forward to.

## 3. EU Act AI Compliance: Navigating the Future

[Last week, we talked about the EU proposed legislation](https://gptweekly.beehiiv.com/p/new-pricing-models-functions-openais-new-updates). [An interesting study by Stanford](https://crfm.stanford.edu/2023/06/15/eu-ai-act.html) shows that none of the leading models comply. 

&#x200B;

https://preview.redd.it/6rqyeek0ce8b1.png?width=775&format=png&auto=webp&s=bd589967d5cae8e51b9741364317c1e9a113938b

**Why is it important?** The EU AI Act governs the usage of AI for 450 million people. And often EU rule has a large outlying effect (See: [Brussel’s effect](https://en.wikipedia.org/wiki/Brussels_effect))

[Additionally, as per Time, Altman and OpenAI had lobbied for not putting GPT-3 models in the high risk category. ](https://time.com/6288245/openai-eu-lobbying-ai-act/)“By itself, GPT-3 is not a high-risk system. But \[it\] possesses capabilities that can potentially be employed in high risk use cases.”

While OpenAI has escaped from being put in the high-risk category it is interesting to see the overall compliance to the law. The fines on non-compliance can go up to 4% of revenue. 

As per the research OpenAI scores 25/48 or just above 50%. Anthropic’s Claue sits last with a 7/48 score. 

**What’s next?** As per the researchers it is feasible for foundational models to comply with the EU AI Act. And policymakers should push for transparency. It remains to be seen how much lobbying and change happens on this law, especially regarding the transparency requirements. 

# 🗞️10 AI news highlights and interesting reads

1. [GPT-4 is just 8 GPT-3](https://twitter.com/swyx/status/1671272883379908608) inside a trenchcoat.

&#x200B;

https://preview.redd.it/yspswp81ce8b1.png?width=509&format=png&auto=webp&s=6edb86c2ae06e1586d506170ac26b8975b9ee69a

1. [Though the bigger is better approach might be reaching its end](https://www.economist.com/science-and-technology/2023/06/21/the-bigger-is-better-approach-to-ai-is-running-out-of-road). 
2. [92% programmers are using AI Tools, as per Github survey. ](https://www.zdnet.com/article/github-developer-survey-finds-92-of-programmers-using-ai-tools/)
3. So, it is no wonder that [Harvard’s famous Computer Science program - CS50 will have a chatbot teacher](https://www.independent.co.uk/tech/harvard-chatbot-teacher-computer-science-b2363114.html). 

&#x200B;

https://preview.redd.it/7dagasv1ce8b1.png?width=769&format=png&auto=webp&s=6761c68e53fb0b11dd48c06320e09461586ccf90

1. What kind of coding is the future? [Self-healing code](https://stackoverflow.blog/2023/06/07/self-healing-code-is-the-future-of-software-development/). [Though self-repair effectiveness is only on GPT-4. Though it is best to use GPT-3.5 code -> GPT-4 repair -> Human Feedback.](https://huggingface.co/papers/2306.09896) (See below on how RLHF works)
2. [The OpenAI app store might be coming](https://www.reuters.com/technology/openai-plans-app-store-ai-software-information-2023-06-20/). I guess the idea will be to charge flat 30% revenue like the App store.
3. [AI is not just hype money is being pumped in](https://techcrunch.com/2023/06/16/ai-transformating-corporate-america/). 
4. [If you want to be part of the cycle, you need to pitch to investors and business owners. The best way is to use GPT-4](https://clarifycapital.com/the-future-of-investment-pitching).  
5. [One of the places to seriously consider GenAI is The Guardian.](https://www.theguardian.com/help/insideguardian/2023/jun/16/the-guardians-approach-to-generative-ai)
6. [Run inference on any LLM using OpenLLM](https://github.com/bentoml/OpenLLM).

# 🧑‍🎓3 Learning Resources

1. The “T” in GPT stands for Transformers. Here’s an a [Nvidia explainer on Transformers](https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/).
2. GPT-4 is trained using RLHF. [Learn how RLHF actually work and why open source RHLF is difficult.](https://www.interconnects.ai/p/how-rlhf-works)
3. [Interactive workbooks to combine Generative AI models in one document](https://lastmileai.dev/workbooks/clj2y933l000mr0avd2ck42s9). I find interactive notebooks to be the best way to learn concepts in programming. 

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
247,learnmachinelearning,gpt-4,relevance,2023-06-03 14:33:38,This week in AI - all the Major AI development in a nutshell,wyem,False,0.98,120,13zeoi3,https://www.reddit.com/r/learnmachinelearning/comments/13zeoi3/this_week_in_ai_all_the_major_ai_development_in_a/,13,1685802818.0,"1. The recently released open-source large language model **Falcon LLM**, by UAE’s Technology Innovation Institute, is now royalty-free for both commercial and research usage. **Falcon 40B,** the 40 billion parameters model trained on one trillion tokens, is ranked #1 on **Open LLM Leaderboard by Hugging Face**.
2. **Neuralangelo**, a new AI model from Nvidia turns 2D video from any device - cell phone to drone capture - into 3D structures with intricate details using neural networks..
3. In three months, JPMorgan has advertised **3,651 AI jobs** and sought a trademark for **IndexGPT**, a securities analysis AI product.
4. **Google** presents **DIDACT** (​​Dynamic Integrated Developer ACTivity), the first code LLM trained to model real software developers editing code, fixing builds, and doing code review. DIDACT uses the software development process as training data and not just the final code, leading to a more realistic understanding of the development task.
5. Researchers from **Deepmind** have presented ‘**LLMs As Tool Makers (LATM)**’ - a framework that allows Large Language Models (LLMs) to create and use their own tools, enhancing problem-solving abilities and cost efficiency. With this approach, a sophisticated model (like GPT-4) can make tools (where a tool is implemented as a Python utility function), while a less demanding one (like GPT-3.5) uses them.
6. **Japan's government** won't enforce copyrights on data used for AI training regardless of whether it is for non-profit or commercial purposes.
7. *‘Mitigating the* ***risk of extinction from AI*** *should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.’ -* One sentence statement signed by leading AI Scientists as well as many industry experts including CEOs of OpenAI, DeepMind and Anthropic.*.*
8. Nvidia launched ‘**Nvidia Avatar Cloud Engine (ACE) for Games**’ - a custom AI model foundry service to build non-playable characters (NPCs) that not only engage in dynamic and unscripted conversations, but also possess evolving, persistent personalities and have precise facial animations and expressions.
9. **OpenAI** has launched a trust/security portal for OpenAI’s compliance documentation, security practices etc..
10. **Nvidia** announced a new AI supercomputer, the **DGX GH200,** for giant models powering Generative AI, Recommender Systems and Data Processing. It has 500 times more memory than its predecessor, the DGX A100 from 2020.
11. Researchers from Nvidia presented **Voyager**, the first ‘LLM-powered embodied lifelong learning agent’ that can explore, learn new skills, and make new discoveries continually without human intervention in the game Minecraft.
12. The a16z-backed chatbot startup **Character.AI** launched its mobile AI chatbot app on May 23 for iOS and Android, and succeeded in gaining over **1.7 million new installs** within a week.
13. Microsoft Research presents **Gorilla**, a fine-tuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls.
14. **OpenAI** has trained a model using process supervision - rewarding the thought process rather than the outcome - to improve mathematical reasoning. Also released the full dataset used.
15. **WPP**, the world's largest advertising agency, and Nvidia have teamed up to use generative AI for creating ads. The new platform allows WPP to tailor ads for different locations and digital channels, eliminating the need for costly on-site production.
16. **PerplexityAI’s** android app is available now, letting users search with voice input, learn with follow-up questions, and build a library of threads.

**If you like this news format**, you might find my  [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with **bite-sized news, learning resources and selected tools**. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
248,learnmachinelearning,gpt-4,relevance,2023-07-20 13:15:51,Free courses and guides for learning Generative AI,wyem,False,0.95,17,154qnsh,https://www.reddit.com/r/learnmachinelearning/comments/154qnsh/free_courses_and_guides_for_learning_generative_ai/,0,1689858951.0,"1. **Generative AI learning path by Google Cloud.** A series of 10 courses on generative AI products and technologies, from the fundamentals of Large Language Models to how to create and deploy generative AI solutions on Google Cloud \[[*Link*](https://www.cloudskillsboost.google/paths/118)\].
2. **Generative AI short courses** by DeepLearning.AI - Five short courses on generative AI including **LangChain for LLM Application Development, How Diffusion Models Work** and more. \[[*Link*](https://www.deeplearning.ai/short-courses/)\].
3. **LLM Bootcamp:** A series of free lectures by *The full Stack* on building and deploying LLM apps \[[*Link*](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/)\].
4. **Building AI Products with OpenAI** \- a free course by CoRise in collaboration with OpenAI \[[*Link*](https://corise.com/course/building-ai-products-with-openai)\].
5. Free Course by Activeloop on **LangChain & Vector Databases in Productio**n \[[*Link*](https://learn.activeloop.ai/courses/langchain)\].
6. **Pinecone learning center -** Lots of free guides as well as complete handbooks on LangChain, vector embeddings etc. by Pinecone **\[**[**Link**](https://www.pinecone.io/learn/)**\].**
7. **Build AI Apps with ChatGPT, Dall-E and GPT-4  -** a free course on Scrimba **\[**[*Link*](https://scrimba.com/learn/buildaiapps)**\].**
8. **Gartner Experts Answer the Top Generative AI Questions for Your Enterprise** \- a report by Gartner \[[*Link*](https://www.gartner.com/en/topics/generative-ai)\]
9. **GPT best practices:** A guide by *OpenAI* that shares strategies and tactics for getting better results from GPTs \[[*Link*](https://platform.openai.com/docs/guides/gpt-best-practices)\].
10. **OpenAI cookbook by OpenAI -** Examples and guides for using the OpenAI API **\[**[*Link*](https://github.com/openai/openai-cookbook/tree/main)**\].**
11. **Prompt injection explained**, with video, slides, and a transcript from a webinar organized by LangChain \[[*Link*](https://simonwillison.net/2023/May/2/prompt-injection-explained/)\].
12. A detailed guide to **Prompt Engineering by DAIR.AI** *\[*[*Link*](https://www.promptingguide.ai/)*\].*
13. What Are **Transformer Models** and How Do They Work - A tutorial by **Cohere AI** \[[*Link*](https://txt.cohere.ai/what-are-transformer-models/)\].  


I add learning resources as part of my AI newsletter. You can join for free [here](https://aibrews.com/). It’s sent only once a week with bite-sized news, learning resources and selected tools. "
249,learnmachinelearning,gpt-4,relevance,2023-09-01 14:58:08,This week in AI - all the Major AI development in a nutshell,wyem,False,0.96,19,1679g8z,https://www.reddit.com/r/learnmachinelearning/comments/1679g8z/this_week_in_ai_all_the_major_ai_development_in_a/,0,1693580288.0,"1. Researchers introduce ‘**Swift**’, the first autonomous vision-based drone that beat human world champions in several fair head-to-head races. This marks the *first* time that an autonomous mobile robot has beaten human champions in a real physical sport \[[*Details*](https://www.nature.com/articles/s41586-023-06419-4)\].
2. **Meta AI** released **CoTracker** \- a fast transformer-based model that can track any point in a video.
3. **WizardLM** released **WizardCoder 34B** based on Code Llama. WizardCoder-34B surpasses GPT-4, ChatGPT-3.5 and Claude-2 on HumanEval Benchmarks.
4. **Meta AI** introduced **FACET** (FAirness in Computer Vision EvaluaTion) - a new comprehensive benchmark dataset for evaluating the fairness of computer vision models for protected groups. The dataset is made up of 32K images containing 50,000 people, labeled by expert human annotators.
5. **Allen Institute for AI** launched [**Satlas**](https://satlas.allen.ai/) \- a new platform for exploring global geospatial data generated by AI from satellite imagery.
6. Generative AI updates from **Google Cloud Next** event**:**
   1. General availability of **Duet AI in Google Workspace** .
   2. **SynthID** \- a tool for watermarking and identifying AI images generated by Imagen (Google’s text-to-image diffusion model). It embeds a digital watermark directly into the pixels of an image, making it invisible to the human eye, but detectable for identification, without reducing the image quality.
   3. **AlloyDB AI** for building generative AI applications with PostgreSQL.
   4. **Vertex AI’s Model Garden** now includes Meta’s Llama 2 and TII’s Falcon — and pre-announcement of Anthropic’s Claude 2..
   5. Model and tuning upgrades for **PaLM 2, Codey, and Imagen**. 32,000-token context windows and 38 languages for PaLM 2.
   6. **Style Tuning** for Imagen - a new capability to help customers align their images to their brand guidelines with 10 images or less.
   7. Launch of fifth generation of its tensor processing units (**TPUs**) for AI training and inferencing.
7. A new generative AI image startup **Ideogram**, founded by former Google Brain researchers, has been launched with $16.5 million in seed funding. Ideogram's unique proposition lies in reliable text generation within images.
8. **a16z** announced **a16z Open Source AI Grant program** and the first batch of grant recipients and funded projects.
9. **Runway AI** announced **Creative Partners Program** \- provides a select group of artists and creators with exclusive access to new Runway tools and models, Unlimited plans, 1 million credits, early access to new features and more.
10. **OpenAI** has released a guide for teachers using ChatGPT in their classroom—including suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.
11. **DINOv2**, a self-supervised vision transformer model by **Meta AI** which was released in April this year, is now available under the Apache 2.0 license.
12. **Tesla** is launching a $300 million AI computing cluster employing 10,000 Nvidia H100 GPUs.
13. **Inception**, an AI-focused company based in the UAE unveiled **Jais**, a 13 billion parameters open-source Arabic Large Language Model (LLM).
14. Google announced **WeatherBench 2** (WB2) - a framework for evaluating and comparing various weather forecasting models.
15. **Alibaba** launched two new open-source models - **Qwen-VL** and **Qwen-VL-Chat** that can respond to open-ended queries related to different images and generate picture captions.
16. **OpenAI** disputes authors’ claims that every ChatGPT response is a derivative work.
17. **DoorDash** launched AI-powered voice ordering technology for restaurants.
18. **OpenAI** launched **ChatGPT Enterprise**. It offers enterprise-grade security and privacy, unlimited higher-speed GPT-4 access, longer context windows for processing longer inputs, advanced data analysis capabilities and customization options.
19. **OpenAI** is reportedly earning $80 million a month and its sales could be edging high enough to plug its $540 million loss from last year.

If you like this news format, you might find my newsletter, [AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
250,learnmachinelearning,gpt-4,relevance,2023-05-11 20:15:46,Top 20 Large Language Models based on the Elo rating system.,kingabzpro,False,0.96,252,13eympz,https://i.redd.it/7xfqr5crf9za1.png,43,1683836146.0,
251,learnmachinelearning,gpt-4,relevance,2023-06-16 14:23:32,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.94,16,14ay75a,https://www.reddit.com/r/learnmachinelearning/comments/14ay75a/this_week_in_ai_all_the_major_ai_developments_in/,1,1686925412.0,"1. **ElevenLabs** has launched **AI Speech Classifier -** an authentication tool that lets you upload any audio sample to identify if it contains ElevenLabs AI-generated audio.
2. **Nvidia Research** presents **SceneScape** \- a method to generate long-term walkthroughs in imaginary scenes just from an input text prompt.
3. **Meta AI** introduces the **Image Joint Embedding Predictive Architecture (I-JEPA)**, a new AI model which learns from the world like humans and excels in computer vision tasks, while being more computationally efficient. It learns by creating an internal model of the outside world, which compares abstract representations of images (rather than comparing the pixels themselves). It can also be used for many different applications without needing extensive fine tuning. Meta is open-sourcing the code and model checkpoints.
4. **Meta** wants to make the next version of LLaMA, its open source LLM, available for commercial use..
5. Adobe launched **Generative Recolor,** a new tool powered by Adobe Firefly generative AI that lets you generate custom color schemes using texts prompt like “strawberry fields,” “faded emerald,” etc. .
6. **OpenAI** announced:
   1. new **function calling** capability in the Chat Completions API
   2. updated and more steerable versions of gpt-4 and gpt-3.5-turbo
   3. new 16k context version of gpt-3.5-turbo (vs the standard 4k version). 16k context means the model can now support \~20 pages of text in a single request.
   4. cost reductions: 75% on embeddings model and 25% cost on input tokens for gpt-3.5-turbo.
7. **Meta AI** released **MusicGen** \- an open-source music generation model that can be prompted by both text and melody. See here for generated samples and comparison with Google’s MusicLM and others..
8. **McKinsey** published a report ‘*The economic potential of generative AI: The next productivity frontier*’ . The report estimates that generative AI could add the equivalent of $2.6 trillion to $4.4 trillion annually across the 63 use cases. About 75 percent of the value that generative AI use cases could deliver falls across four areas: Customer operations, marketing and sales, software engineering, and R&D..
9. **EU lawmakers** pass AI regulation, requiring generative AI systems, such as ChatGPT, to be reviewed before commercial release. It also seeks to ban real-time facial recognition.*.*
10. **Google Lens** can now identify skin conditions. Lens will also be integrated with Bard, Google’s AI-powered chatbot, enabling Bard to understand images in user prompts..
11. **AMD** announced its most-advanced GPU for artificial intelligence, the MI300X, which will start shipping to some customers later this year*.*
12. **Vercel** introduced **Vercel AI SDK -** an open-source library to build conversational, streaming and chat user interfaces. Includes first-class support for OpenAI, LangChain, and Hugging Face Inference.
13. **Vercel** announced '**Vercel AI Accelerator,** a 6-week long accelerator program with $850k in free credits from OpenAI, Replicate and others.
14. **Salesforce** announces **AI Cloud** \- generative AI for the enterprise. AI Cloud includes the new **Einstein Trust Layer**, to help prevent large-language models (LLMs) from retaining sensitive customer data.
15. **Cohere** and **Oracle** are working together to make it easy for enterprise customers to train their own specialized large language models while protecting the privacy of their training data.
16. **Coda** released Coda AI - the AI-powered work assistant integrated in Coda to automate workflows. Coda also announced ‘**Coda's AI at Work Challenge**’, offering $40,000 in total prizes to the makers who submit the most useful Coda AI template to the Coda Gallery.
17. **OpenAI, Google DeepMind and Anthropic** have committed to provide “early or priority access” to their AI models to UK in order to support research into evaluation and safety.

If you like this news format, you might find my  [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
252,learnmachinelearning,gpt-4,relevance,2023-06-30 17:27:56,This week in AI - all the Major AI developments in a nutshell,wyem,False,1.0,11,14n6lwl,https://www.reddit.com/r/learnmachinelearning/comments/14n6lwl/this_week_in_ai_all_the_major_ai_developments_in/,0,1688146076.0,"1. **Microsoft** has launched AI-powered shopping tools in Bing search and Edge, including AI-generated buying guides which automatically aggregate product specifications and purchase locations for user queries​, and AI-generated review summaries that provide concise overviews of online product reviews .
2. **Salesforce AI Research** released **XGen-7B**, a new **open-source** 7B LLM trained on 8K input sequence length for 1.5T tokens.
3. Researchers present **DreamDiffusion**, a novel method for generating high-quality images directly from brain EEG signals without the need to translate thoughts into text.
4. **Google** announced the first *Machine* ***Un****learning Challenge* hosted on Kaggle.
5. **Microsoft** announced a new ***AI Skills Initiative*** that includes free coursework developed with LinkedIn, a new open global grant challenge and greater access to free digital learning events and resources for AI education.
6. **Stability AI** announced **OpenFlamingo V2,** an open-source reproduction of DeepMind's Flamingo model. OpenFlamingo models achieve more than 80% of the performance of their corresponding Flamingo model.
7. **Unity** announces two AI-powered tools: Unity Muse and Unity Sentis. Muse generates animations, 2D sprites, textures etc. in the Unity Editor using text and sketches. Sentis lets you embed an AI model in the Unity Runtime for your game or application. It enables AI models to run on any device where Unity runs..
8. **ElevenLabs** launched **Voice Library** \- a library and community for sharing AI generated voices designed using their *voice Design* tool.
9. **Merlyn Mind** released three **open-source education-specific LLMs**. Merlyn Mind is building a generative AI platform for education where engagement will be curriculum-aligned, hallucination-resistant, and age-appropriate.
10. Amazon's **AWS** has launched a $100 million program, the **Generative AI Innovation Center**, that connects AWS machine learning and artificial intelligence experts with businesses to build and deploy generative AI solutions.
11. New open-source text to video AI model, **Zeroscope\_v2 XL**, released that generates high quality video at 1024 x 576, with no watermarks.
12. Researchers present MotionGPT - a motion-language model to handle multiple motion-relevant tasks.
13. **Databricks** is set to acquire the open-source startup **MosaicML** for $1.3 billion. MosaicML had recently released **MPT-30B,** an open-source model licensed for commercial use that outperforms the original GPT-3 .
14. Generative AI-related job postings in the United States jumped about 20% in May as per Indeed’s data.
15. The source code for the algorithm **DragGAN** (Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold) released and demo available on Huggingface.
16. A new foundation model, **ERNIE** **3.5 b**y China’s Baidu surpassed ChatGPT (3.5) in comprehensive ability scores and outperforms GPT-4 in several Chinese language capabilities.
17. **Adobe** is prepared to pay out any claims in case an enterprise customer loses a lawsuit over the use of content generated by Adobe Firefly, the generative AI image tool.
18. **Google** launched generative AI coding features in Google Colab for Pro+ subscribers in the US.

I didn't add links to news sources here because of auto-mod, but they are included in the newsletter and **you can read the online issue** [**here**](https://aibrews.substack.com/p/ai-generated-buying-guides-in-bing) **without signup**. If you like this news format, you might find my [newsletter](https://aibrews.com/) helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. . Thanks"
253,learnmachinelearning,gpt-4,relevance,2023-12-17 13:15:47,I can't stop using ChatGPT and I hate it.,t0hli,False,0.64,24,18kh4n5,https://www.reddit.com/r/learnmachinelearning/comments/18kh4n5/i_cant_stop_using_chatgpt_and_i_hate_it/,108,1702818947.0,"I'm trying to learn various topics like Machine Learning and Robotics etc., and I'm kinda a beginner in programming.

For any topic and any language, my first instinct is to

1. go to ChatGPT,
2. write down whatever I need my code to do,
3. copy paste the code
4. if it doesn't give out good results, ask ChatGPT to fix whatever it's done wrong
5. repeat until I get satisfactory result

I hate it, but I don't know what else to do.

I think of asking Google what to do, but then I won't get the exact answer I'm looking for, so I go back to ChatGPT so I can get exactly what I want. I don't fully understand what the GPT code does, I get the general gist of it and say ""Yeah that's what I would do, makes sense"", but that's it.

If I tried to code whatever GPT printed out, I wouldn't get anywhere.

I know I need to be coding more, but I have no idea where to start from, and why I need to code when ChatGPT can do it for me anyway. I'm not defending this idea, I'm just trying to figure out how I can code myself.

I'd appreciate your thoughts and feedback."
254,learnmachinelearning,gpt-4,relevance,2023-06-19 17:49:06,"GPT Weekly - 19the June Edition - OpenAI's function calling, Meta's free LLM, EU Regulation and more.",level6-killjoy,False,1.0,21,14dlfas,https://www.reddit.com/r/learnmachinelearning/comments/14dlfas/gpt_weekly_19the_june_edition_openais_function/,2,1687196946.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 news - OpenAI’s updates, Meta’s upcoming free LLM and EU Regulation
* 🗞️Interesting reads include PSA about protecting your keys, The GPT ouroboros, Reddit - OpenAI’s moat, and more..
* 🧑‍🎓Learning includes a Step-by-step guide from a non-technical founder who launched his MVP, Chatbot for your Gdrive and more

# 🔥Top 3 AI news in the past week

## 1. OpenAI: New Pricing, Models, & Functions

OpenAI has been on a roll. Last week we saw the release of [OpenAI best practice on using GPT.](https://gptweekly.beehiiv.com/p/making-gpt-openais-tactics-better-results) This week we saw some amazing updates. Three major buckets were:

First, the price decreases for both embeddings and GPT-3.5 tokens. 

Second, new models for gpt-4 and gpt-3.5. A new longer context model for gpt-3.5.

Third, a new function calling capability. 

**Why is it important?** Previously, the output from OpenAI was all text. So, calling an external API from GPT was quite difficult. You had to parse the text data and things were often incorrect.  Langchain created the Agents and Tools feature to tackle this problem. It was still unreliable and prone to issues. 

Now you get native support to generate a fixed format output. You can use the output to generate functional calls and also pass functions which need to be called. For example, if your app has multiple API endpoints then you can use GPT to generate the API calls with parameters. You can also pass the endpoints as function calls to ensure the correct function is executed. 

This functionality can further be used to [generate structured data (JSON) out of GPT](https://yonom.substack.com/p/native-json-output-from-gpt-4). So, you can generate data from GPT and load it into your backend. 

**What’s next?** This functionality allows turning natural language responses into structured data. This can be used to create “intelligent” backends using LLMs. We might see implementations in no-code tools to allow more robust and natural-language tools for non-technical folks.

The structured data process goes both ways. You can also feed structured data into GPT for better responses. 

This feature also has its share of issues. Function calling suffers from the same prompt injection issues. Malicious actors can pass malicious code in function or the responses. For example, creation of queries using functions might contain malicious code to delete data. Without proper user validation this code will be executed automatically and delete data. So, using LLM as the back-end layer needs proper security implementation. 

## 2. Meta's LLM: Commercial Use Ahead

Llama has been a boon for the open source community. Many of the open source models rely on Llama. The issue is that Llama is research-only and cannot be used commercially. So, no one can use it to build any product.

[Meta is now working on the next version of the model. This model will be available for commercial use.](https://www.theinformation.com/articles/meta-wants-companies-to-make-money-off-its-open-source-ai-in-challenge-to-google) This is in stark contrast to both OpenAI and Google. Both safe-guarde their models and make it available through API. 

**Why is it important?** Certain industries cannot use LLM APIs because of strict restrictions on data privacy. These companies would want to run their own instance of a foundational model. 

A commercially available foundational model is also going to help people who want to keep their “API call” costs next to 0. 

A commercially available free-for-all model will also help push the open source community further. Just like Llama.

**What’s next?** Sam Altman has said OpenAI didn’t release GPT-3 as open-source because they [didn’t think people would be able to run it.](https://gptweekly.beehiiv.com/p/peek-openais-future) Now [OpenAI is working on an open-source model.](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) This is going to be weaker than GPT-4. 

Let the battle of LLMs begin.  

## 3. EU's Proposed Legislation and Its Impact on AI Usage

[The EU parliament voted to move ahead with the E.U. AI Act.](https://www.washingtonpost.com/technology/2023/06/14/eu-parliament-approves-ai-act/) This act aims to ensure consumer protection against the dangers of AI.  

**Why is it important?** [OpenAI](https://gptweekly.beehiiv.com/p/peek-openais-future) and [Sam Altman](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins) want regulations for models. They have proposed a IAEA-type of agency to stop the proliferation of LLM models. As per OpenAI, all models should be regulated and monitored. The suggestion of a license based regulation has led to significant backlash. Many people have called it “regulatory capture” - with the aim of shutting down competing LLMs.

[Licensing based regulations might not really be effective.](https://aisnakeoil.substack.com/p/licensing-is-neither-feasible-nor)

The EU is approaching regulation from a different angle. It doesn’t focus on how models are developed. Rather focuses on how AI will/can be used. They have broken down use cases into 4 categories - unacceptable (prohibited), high, medium and low risk. For example, 

Building a [Pre-Crime software](https://en.wikipedia.org/wiki/Pre-crime#:~:text=Pre%2Dcrime%20(or%20precrime),on%20crimes%20not%20yet%20committed.) to predict crimes? Building a [Social credit system](https://en.wikipedia.org/wiki/Social_Credit_System)?  Unacceptable.

Using tools to influence elections or recommendation algorithms? High (Highly regulated).

Using generative AI tools to create text or images on news sites? Medium (Add label that the content is AI generated) 

AI providers also need to disclose their training source.

To me this sounds like good legislation. What do you guys think?

But, OpenAI has warned that EU regulations might force them to pull out completely.

**What’s next?** The disclosure requirements might help various publishing companies. [AI and media companies are in talks to pay for training data](https://www.ft.com/content/79eb89ce-cea2-4f27-9d87-e8e312c8601d). Google has been leading the charge. 

Additionally, [OpenAI and Deepmind will open their models for safety and research purposes to the UK government.](https://www.politico.eu/article/openai-deepmind-will-open-up-models-to-uk-government/) 

# 🗞️10 AI news highlights and interesting reads

1. **PSA:** If you are using Repl to write code, you might want to check your OpenAI API keys. If you have left them embedded then [people can pirate and steal the keys. ](https://www.vice.com/en/article/93kkky/people-pirating-gpt4-scraping-openai-api-keys)
2. LLMs rely on human annotation or human feedback to learn. And one way to generate human annotation is crowdsourcing. But what if the crowdsource human annotators use LLMs? [Research shows 33-46% workers used LLMs](https://arxiv.org/abs/2306.07899). So, basically we go from Human -> AI -> Human -> AI. The AI ouroboros. Researchers also say [generated data to train models might cause serious issue.  ](https://arxiv.org/abs/2305.17493)
3. All the talks about [moats](https://gptweekly.beehiiv.com/p/googles-startling-leaked-memo-george-hinton-mojo) \- [Reddit might be OpenAI’s \*future\* moat](https://www.cyberdemon.org/2023/06/14/reddit-moat.html). Given the amount of complaints about how [Google search](https://www.techradar.com/opinion/the-reddit-b) [experience has deteriorated](https://www.theverge.com/2023/6/13/23759942/google-reddit-subreddit-blackout-protests) [during the blackout](https://news.ycombinator.com/item?id=36345345), this might be true?
4. [Doctors are using ChatGPT](https://www.nytimes.com/2023/06/12/health/doctors-chatgpt-artificial-intelligence.html) but not to diagnose.Rather to be [more empathetic](https://inflecthealth.medium.com/im-an-er-doctor-here-s-how-i-m-already-using-chatgpt-to-help-treat-patients-a023615c65b6). [We discussed this just a month ago](https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?utm_source=gptweekly.beehiiv.com&utm_medium=referral&utm_campaign=google-s-startling-leaked-memo-george-hinton-mojo-and-more). And guess where the data for this study came from? Reddit AskDocs. Moat FTW?!
5. Beatles to make a comeback…[using Generative AI](https://www.semafor.com/article/06/13/2023/paul-mccartney-beatles-song-ai). 
6. [SnapFusion - Text to Image diffusion on mobile phones.](https://snap-research.github.io/SnapFusion/)
7. Large context lengths are important for better GPT experience. [The secret sauce for 100k context length](https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c). 
8. There is a lot of bad AI research out there. Some border on snake oil. Most AI “research” should be double checked and challenged. A new research on huggingface said that [GPT-4 can ace MIT curriculum](https://huggingface.co/papers/2306.08997). Now someone is replicating the results and say that [GPT-4 can’t beat MIT. ](https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864)
9. Are we seeing peak AI? Especially when people from Deepmind and Meta are involved? [Mistral AI raised $113 million in seed round with no product.](https://techcrunch.com/2023/06/13/frances-mistral-ai-blows-in-with-a-113m-seed-round-at-a-260m-valuation-to-take-on-openai/) Some might say this funding is for the team and the team is really solid. The issue though is whether the valuation is justified when OpenAI and Google already have a head start.
10. [The AI Hype Wall of Shame.](https://criticalai.org/the-ai-hype-wall-of-shame/) \- Collection of articles which mislead people about AI in various aspects.

# 🧑‍🎓3 Learning Resources

1. [Building and Launching a company using GPT-4](https://sabol.io/c7921c7bbd8c4982aacbd2b71a8b9bb3) with prompts. (The author didn’t know how to code but created and launched the MVP in a month).  
2. Chatbot for your Gdrive - [https://www.haihai.ai/gpt-gdrive/](https://www.haihai.ai/gpt-gdrive/)
3. Building ChatGPT plugin using Supabase - https://supabase.com/blog/building-chatgpt-plugins-template

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
255,learnmachinelearning,gpt-4,relevance,2023-09-04 03:24:31,ID Embeddings Confusion,TraditionalNews9122,False,1.0,1,169gr4f,https://www.reddit.com/r/learnmachinelearning/comments/169gr4f/id_embeddings_confusion/,0,1693797871.0,"I'm studying recommender systems via a few online courses, and am confused about the use of ID embeddings.

&#x200B;

As I understand it, ID embeddings are popular ways to represent sparse items like a User, Media (a video, post, etc), or Ad, simply by their ID in the database. The ID embedding vector has no other inputs (no other sparse/dense features feed it, but it is still learnable). They are stored in a lookup table of size NxD where N is the total number of that item that exist in the DB, and D is the embedding dimension.

&#x200B;

In most of these courses, ID embeddings are lauded as a critical feature for every item. But it seems for this to be true, a company would have to train on every item in their DB. And even then, rare items would have bad representations, not to mention it's computationally intractable (in a large co, the table could be of dimensions 10\^11+ x D). And then they'd have to be retrained every single time.

&#x200B;

From consulting with GPT-4 a bit and thinking about this, it seems more likely to me that ID embeddings mostly serve to provide good representations of extremely popular items (a celebrity account, a major advertiser, a popular movie) that appear frequently in the dataset, but are mostly empty/unlearned for 99% of users/media/etc. I can't find any actual source that says this though.

&#x200B;

This is in contrast to something like two tower embeddings, which make a lot of sense to me and seem to be easily computable from other features even if that user/item has never been seen before. But the ID embedding has no inputs, it is supposed to be an input feature itself. Embedding lookups make much more sense to me in a context like transformers, with a small fixed vocab size that is well represented in the training set.

&#x200B;

When I search on this, I see a lot of references to the cold start problem of new users signing up not having embeddings, which makes me feel like I'm fundamentally misunderstanding ID embeddings, since it feels like if 99% of your 100 billion existing ID embeddings were still unlearned, cold start would be the least of your worries.

&#x200B;

Can anyone help clear up my misunderstanding? Thank you!!"
256,learnmachinelearning,gpt-4,relevance,2023-06-12 17:23:33,"GPT Weekly - 12the June Edition - OpenAI GPT Best Practice, Deepmind's sorting algo, Bard Improvements and more.",level6-killjoy,False,0.75,2,147shn0,https://www.reddit.com/r/learnmachinelearning/comments/147shn0/gpt_weekly_12the_june_edition_openai_gpt_best/,0,1686590613.0," 

This is a recap covering the major news from last week.

* 🔥Google Deepmind’s sort solution, OpenAI best practice on GPT, and Bard improvements
* 🗞️Apple’s use of Generative AI and other 9 AI news highlights and interesting reads
* 🧑‍🎓Learning about tokenization and using Huggingface LLM with LangChain

🔥Top 3 AI news in the past week

# 1. Optimal solutions are inhuman

Sorting is one of the fundamental algorithms used on the internet everyday. Think of how companies like Netflix need to find correct movies from their huge content library and present it to you. More content is being generated everyday. So, there is a need for newer and more efficient algorithms.

Searching for these algorithms has been a human task. People coming up with efficient and optimal solutions. Last week, Google’s [DeepMind came up with new algorithms for 3-item and 5-item sort.](https://www.nature.com/articles/s41586-023-06004-9)

Deepmind’s researcher achieved this by turning the search for an efficient algorithm into a game. Then they trained Alphadev to play this game. When playing this game, Alphadev came up with unseen strategies. These “strategies” are the new sorting algorithms.

The solution isn’t revolutionary as it doesn’t find a new approach. This solution works by optimizing the current approach.

The algorithms have been added to C++ library. The first time a completely AI solution has been added to the library.

This is an important discovery because it shows that finding the best optimal solutions needs computers. As computers are able to go beyond what humans can perceive. Previously, Deepmind’s AlphaGo has [beaten the top rated Go player Lee Sedol in a similar way](https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol). It came up with moves which were never seen before.

On the other hand, computers might be restricted to what they have been taught. Someone was able to [replicate the discovery using ChatGPT](https://twitter.com/DimitrisPapail/status/1666843952824168465).

# 2. GPT Best Practices

There has been a [lot of noise about GPT-4’s quality going down.](https://gptweekly.beehiiv.com/p/peek-openais-future)

Now we have a [list of tactics and strategies straight from Open AI](https://platform.openai.com/docs/guides/gpt-best-practices) to get better results.

I have looked through the strategies and tactics and most of it is around providing better inputs. “Prompt Engineering”, if you may. Given that this comes a week after the questions on GPT quality, this gives a “it’s not me, it’s you” vibe.

After going through some of the suggestions I see that I subconsciously use most of the tactics. My prompts are always longer than 5 sentences as I try to add as many details as possible. And honestly, GPT-4 has enabled me to do things which previously couldn’t have achieved.

# 3. Logic and reasoning improvements in Bard

Bard, on the other hand, has been lacking. Google is trying to improve the responses by adding features one at a time.

Last week it was announced that [Bard will get better at logic and reason](https://blog.google/technology/ai/bard-improved-reasoning-google-sheets-export/). This is achieved using “implicit code execution”. Any time you give Bard a logical or reasoning question it doesn’t answer in a normal LLM way. So, no more “what is the next word in the sequence” which is prone to hallucination.

Instead Bard will now recognize that the prompt is a logical question. It will then write and execute code under the hood. It’ll respond to the question by taking the output of the execute code.

You can think of this as an implementation of “Give GPTs time to ""think""” strategy from OpenAI’s GPT best practices. As per Google, this improves the performance by 30%.

Give it a try and let me know?

# 🗞️10 AI news highlights and interesting reads

1. Apple did not showcase any generative AI products during the WWDC. Though they are introducing the “what is the next word in the sequence” logic of LLM into autocorrect. It can be summed thusly:

&#x200B;

https://preview.redd.it/ovnoasksfm5b1.jpg?width=900&format=pjpg&auto=webp&s=8e37990c268933497f003faf58b854a73129ca6a

1. [ChatGPT cannot read the name - davidjdl](https://twitter.com/goodside/status/1666598580319035392). Some think that this is due to tokenization of Reddit data. In the learning resources section I have added a tutorial on tokenization.
2. Browser extensions are a security nightmare. [The GPT and LLM craze has given the malware extensions another way to steal user data.](https://www.kolide.com/blog/ai-browser-extensions-are-a-security-nightmare) Beware of the summarization and “write for me” extensions.
3. Most of the AI generated imagery is going to be used for stock photography. But is the industry dying? [Here’s a look at the data so far.](https://www.stockperformer.com/blog/is-ai-killing-the-stock-industry-a-data-perspective/) The author’s conclusion is that early metrics show that finding AI stock images often don’t have people in it. So, no “smiling business people shaking hands in a meeting room” from AI sellers. This might change with MidJourney V5. Future is still unknown.
4. [Six tips for better coding with ChatGPT](https://www.nature.com/articles/d41586-023-01833-0). I have been using Trust, but verify mental model quite frequently. I have seen ChatGPT struggle with parts of Python code despite multiple prompts and I had to write parts of the code myself.
5. [GPT-5 isn’t coming any time soon](https://techcrunch.com/2023/06/07/openai-gpt5-sam-altman/).
6. AI startups might be too easy to copy. And with AI requiring lesser resources, [we might even see 1 person companies worth more than 1 million dollars](https://www.semafor.com/article/06/07/2023/are-ai-startups-too-easy-to-copy).
7. [Google’s vision for securing AI.](https://www.axios.com/2023/06/08/google-securing-ai-framework)
8. [A16z says AI will save the world.](https://a16z.com/2023/06/06/ai-will-save-the-world/)
9. AI pics might be used for disinformation. [The EU's solution is to label AI images to fight disinformation.](https://techcrunch.com/2023/06/06/eu-disinformation-code-generative-ai-labels/)

# 🧑‍🎓3 Learning Resources

1. If you are looking to build better solutions using GPT then understanding tokenizers is a must:  

   1. [https://simonwillison.net/2023/Jun/8/gpt-tokenizers/](https://simonwillison.net/2023/Jun/8/gpt-tokenizers/)
   2. [https://matt-rickard.com/the-problem-with-tokenization-in-llms](https://matt-rickard.com/the-problem-with-tokenization-in-llms)
2. Using Flowise and HuggingFace LLM and Langchain

[https://cobusgreyling.medium.com/how-to-use-huggingface-llms-with-langchain-flowise-2b2d0f639f03](https://cobusgreyling.medium.com/how-to-use-huggingface-llms-with-langchain-flowise-2b2d0f639f03)

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
257,learnmachinelearning,gpt-4,relevance,2023-05-29 17:37:32,"GPT Weekly - 29th May Edition: Facebook's massive STT and TTS Release, AI in Windows, Paralegal jobs are here to stay and more.",level6-killjoy,False,0.86,30,13v1asb,https://www.reddit.com/r/learnmachinelearning/comments/13v1asb/gpt_weekly_29th_may_edition_facebooks_massive_stt/,2,1685381852.0," 

This is a recap covering the major news from last week.

* 🔥Top 3 AI news in the past week
* 🗞️10 AI news highlights and interesting reads
* 🧑‍🎓3 Learning Resources

# 🔥Top 3 AI news in the past week

## 1. Expanding Language Horizons

Facebook has [released an open source model called MMS (Massively Multilingual Search)](https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/) for STT (speech to text), TTS (text to speech) and language identification. 

This is a big breakthrough. Currently, STT and TTS models recognize only 100 languages. With this the technology has been expanded to 1100 languages. That is 10x the current best. 

Additionally, these models can recognize 4000+ languages. 

As per Facebook, they also have half the error rate of OpenAI’s Whisper.

These guys are on a roll.

## 2. Bing Chat Enters the OS

After [Google’s announcement](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin), it was time for Microsoft to announce AI products. Here’s a rundown of what was announced during Microsoft Build:

1. **Windows Copilot**  \- Microsoft is integrating AI directly into the OS. Now you can do everything you could do with Bing Chat but now on the OS. You can do the usual stuff - summarize emails, documents, re-write etc. But it goes beyond that by integrating into the installed applications.

Microsoft is also adopting OpenAI's plugin model. So, **you can use ChatGPT and Bing plugins to interact with the integrated AI.** 

The great thing about it is the direct integration into the OS. Eat your heart out, Mac users – at least for now 😀. Until Apple announces something similar. And someone will come up with an alternative solution. Especially, because of the privacy concerns with Microsoft telemetry. 

The bad thing is - [the security aspect of the plugins](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). It can open a whole new attack vector on the OS and antivirus softwares might struggle with it. 

It also might be the second nail in the coffin for all the summarize, “talk to your document” apps. Once, this feature is integrated with [Google Docs](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and Microsoft Office - why will you want to pay for extra apps?

1. **Search comes to ChatGPT**  \- Looks like OpenAI had enough of the testing and new features are being rolled out [left](https://gptweekly.beehiiv.com/p/week-google-ai-large-llm-gpt-plugin) and [right](https://gptweekly.beehiiv.com/p/caution-chatgpt-plugins). 

No prizes for guessing the search engine behind it. Ding, Ding, Ding..It’s Bing!

1. **Co-Pilot in PowerPages** \- Microsoft is now adding AI to their [PowerPages platform](https://powerpages.microsoft.com/en-in/), their low-code tool to build websites. It’ll help users to generate text, forms etc.
2. **Microsoft Fabric** \- A new data analytics platform built on top of Azure Data lake but can get data from S3, Google cloud etc. It can help users build pipelines, write code, and build ML models.

## 3. From Trusted Advisor to Nightmare: The Hazards of Depending on AI

Here’s a [fun story which is breaking out on Legal twitter](https://www.nytimes.com/2023/05/27/nyregion/avianca-airline-lawsuit-chatgpt.html). 

A man filed a personal injury lawsuit against Avianca airlines. Avianca's lawyers wasted no time and requested the judge to dismiss the case. The man's lawyer had a different plan in mind. He submitted a document citing half a dozen cases that bolstered his client's claims.

Here's the twist—the judge and Avianca's lawyer couldn't locate any of the referenced cases. Quite a conundrum, right? The lawyer was then asked to provide copies of these elusive cases. The lawyer submitted screenshots as evidence, taking extra precautions to ensure their authenticity. 

You already know the direction this story is taking. 

The lawyer had used ChatGPT to compose his brief. But little did he know that ChatGPT had supplied him with fake cases.

When asked to file tangible copies of these cases, the lawyer turned to ChatGPT once again. ChatGPT had reassured him that the cases were genuine. Feeling emboldened, the lawyer used ChatGPT to provide the requested copies. He even went as far as incorporating chat screenshots into a legal document.

The lawyer maintains that it was never his intention to deceive the court. He expressed regret for relying on ChatGPT for their research. Unfortunately, the judge isn't pleased with this turn of events. The judge has threatened sanctions against both the lawyer and his firm.

It serves as a stark reminder of how ChatGPT has fooled many people. There is a clear warning stating that ChatGPT may produce inaccurate information. But many tend to overlook these warnings. Even legal professionals!!

This story carries significant importance for those who fear job insecurity. The lawyer and his firm could have prevented the entire debacle. They should've used paralegal services. They instead relied on ChatGPT's. It's a hard lesson learned the hard way.

My sincere hope is that this story serves as a valuable lesson. It helps people avoid making similar mistakes. The legal community might become apprehensive about ChatGPT's use moving forward.

# 🗞️10 AI news highlights and interesting reads

1. [OpenAI says in 10 years AI could be as productive as one of today’s large corporations](https://openai.com/blog/governance-of-superintelligence). This poses an existential risk and they suggest some regulations to manage it. This poses an existential risk and they suggest some regulations to manage it. To achieve this, countries need to form something like the [IAEA](https://en.wikipedia.org/wiki/International_Atomic_Energy_Agency). The IAEA is an intergovernmental agency under the UN to oversee nuclear energy. This “AI agency” will monitor the AI systems and conduct inspections. Just like nuclear energy is tracked through signatures, they suggest using compute and energy usage to track systems.
2. In the meantime, [Google is working on voluntary rules](https://techcrunch.com/2023/05/24/eu-google-ai-pact/) until there are some real regulations in place. 
3. [As per Pew Research, 58% of Americans have heard of ChatGPT. Even less - 14% have tried ChatGPT. ](https://www.pewresearch.org/short-reads/2023/05/24/a-majority-of-americans-have-heard-of-chatgpt-but-few-have-tried-it-themselves/)
4. Sharing prompts and results has been a pain. Taking screenshots is one way. But then everyone has to type in the prompts manually. Or you can share as plain text. But ChatGPT results are non-deterministic. So, the results might not be the same. Even the lawyer above would’ve loved this feature. Now you will be able to [share your ChatGPT conversations publicly](https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq).
5. LLM Agents and plugins need to connect to tools to perform the tasks outside the LLM environment. So, it is important for the LLM to know which API to call and pass correct arguments. [Gorilla is a fine-tuned Llama-model which can generate the correct call and arguments](https://gorilla.cs.berkeley.edu/). 
6. If you are trying to build something beyond a document summarizer or a wrapper around GPT4 API, [things can be hard](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm). Finding the correct context window, dealing with slow responses (I am looking at you GPT-4) etc are some of the problems. 
7. [The AI boom could expose investors’ natural stupidity](https://www.reuters.com/breakingviews/ai-boom-could-expose-investors-natural-stupidity-2023-05-19/). 
8. [Chatbot leaderboard for the week](https://lmsys.org/blog/2023-05-25-leaderboard/). GPT-4 is still ahead.
9. [Google’s flood warning system is now available in 80 countries. ](https://blog.google/outreach-initiatives/sustainability/flood-hub-ai-flood-forecasting-more-countries/)
10. [GPT detectors are biased against non-native English writers](https://arxiv.org/abs/2304.02819)

# 🧑‍🎓3 Learning Resources

1. [Build a product using Replit+AI](https://www.priyaa.me/blog/building-with-ai-replit). The author is a non-technical person who won a hackathon competing with engineers. 
2. [LangChain 101](https://replit.com/@MckayWrigley). 
3. [NLP Course from HuggingFace](https://huggingface.co/learn/nlp-course/chapter0/1)

That’s it folks. Thank you for reading and have a great week ahead.

**If you are interested in a focused weekly recap delivered to your inbox on Mondays you can**[ subscribe here. It is FREE!](https://gptweekly.beehiiv.com/subscribe)"
258,learnmachinelearning,gpt-4,relevance,2023-04-12 05:19:38,Is OpenAI’s Study On The Labor Market Impacts Of AI Flawed?,LesleyFair,False,1.0,3,12jb3hy,https://www.reddit.com/r/learnmachinelearning/comments/12jb3hy/is_openais_study_on_the_labor_market_impacts_of/,0,1681276778.0,"[Example img\_name](https://preview.redd.it/u4m50gaj1eta1.png?width=1451&format=png&auto=webp&s=8c9eda5aebd66ad1c6514ba8fe14bca7dc0e381a)

We all have heard an uncountable amount of predictions about how AI will ***terk err jerbs!***

However, here we have a proper study on the topic from OpenAI and the University of Pennsylvania. They investigate how Generative Pre-trained Transformers (GPTs) could automate tasks across different occupations \[1\].

Although I’m going to discuss how the study comes with a set of “imperfections”, the findings still make me really excited. The findings suggest that machine learning is going to deliver some serious productivity gains.

People in the data science world fought tooth and nail for years to squeeze some value out of incomplete data sets from scattered sources while hand-holding people on their way toward a data-driven organization. At the same time, the media was flooded with predictions of omniscient AI right around the corner.

*Let’s dive in and take an* exciting glimpse into the future of labor markets\*!\*

# What They Did

The study looks at all US occupations. It breaks them down into tasks and assesses the possible level of for each task. They use that to estimate how much automation is possible for a given occupation.

The researchers used the [O\*NET database,](https://www.onetcenter.org/database.html) which is an occupation database specifically for the U.S. market. It lists 1,016 occupations along with its standardized descriptions of tasks.

The researchers annotated each task once manually and once using GPT-4. Thereby, each task was labeled as either somewhat (<50%) or significantly (>50%) automatable through LLMs. In their judgment, they considered both the direct “exposure” of a task to GPT as well as to a secondary GPT-powered system, e.g. LLMs integrated with image generation systems.

To reiterate, a higher “exposure” means that an occupation is more likely to get automated.

Lastly, they enriched the occupation data with wages and demographic information. This was used to determine whether e. g. high or low-paying jobs are at higher risk to be automated.

So far so good. This all sounds pretty decent. Sure, there is a lot of qualitative judgment going into their data acquisition process. However, we gotta cut them some slag. These kinds of studies always struggle to get any hard data and so far they did a good job.

However, there are a few obvious things to criticize. But before we get to that let’s look at their results.

# Key Findings

The study finds that 80% of the US workforce, across all industries, could have at least some tasks affected. Even more significantly, 19% of occupations are expected to have at least half of their tasks significantly automated!

Furthermore, they find that higher levels of automation exposure are associated with:

* Programming and writing skills
* Higher wages (contrary to previous research!)
* Higher levels of education (Bachelor’s and up)

Lower levels of exposure are associated with:

* Science and critical thinking skills
* Manual work and tasks that might potentially be done using physical robots

This is somewhat unsurprising. We of course know that LLMs will likely not increase productivity in the plumbing business. However, their findings underline again how different this wave is. In the past, simple and repetitive tasks fell prey to automation.

*This time it’s the suits!*

If we took this study at face value, many of us could start thinking about life as full-time pensioners.

But not so fast! This, like all the other studies on the topic, has a number of flaws.

# Necessary Criticism

First, let’s address the elephant in the room!

OpenAI co-authored the study. They have a vested interest in the hype around AI, both for commercial and regulatory reasons. Even if the external researchers performed their work with the utmost thoroughness and integrity, which I am sure they did, the involvement of OpenAI could have introduced an unconscious bias.

*But there’s more!*

The occupation database contains over 1000 occupations broken down into tasks. Neither GPT-4 nor the human labelers can possibly have a complete understanding of all the tasks across all occupations. Hence, their judgment about how much a certain task can be automated has to be rather hand-wavy in many cases.

Flaws in the data also arise from the GPT-based labeling itself.

The internet is flooded with countless sensationalist articles about how AI will replace jobs. It is hard to gauge whether this actually causes GPT models to be more optimistic when it comes to their own impact on society. However, it is possible and should not be neglected.

The authors do also not really distinguish between labor-augmenting and labor-displacing effects and it is hard to know what “affected by” or “exposed to LLMs” actually means. Will people be replaced or will they just be able to do more?

Last but not least, lists of tasks most likely do not capture all requirements in a given occupation. For instance ""making someone feel cared for"" can be an essential part of a job but might be neglected in such a list.

# Take-Away And Implications

GPT models have the world in a frenzy - rightfully so.

Nobody knows whether 19% of knowledge work gets heavily automated or if it is only 10%.

As the dust settles, we will begin to see how the ecosystem develops and how productivity in different industries can be increased. Time will tell whether foundational LLMs, specialized smaller models, or vertical tools built on top of APIs will be having the biggest impact.

In any case, these technologies have the potential to create unimaginable value for the world. At the same time, change rarely happens without pain. I strongly believe in human ingenuity and our ability to adapt to change. All in all, the study - flaws aside - represents an honest attempt at gauging the future.

Efforts like this and their scrutiny are our best shot at navigating the future. Well, or we all get chased out of the city by pitchforks.

Jokes aside!

What an exciting time for science and humanity!

As always, I really enjoyed making this for you and I sincerely hope you found value in it!

If you are not subscribed to the newsletter yet, [click here to sign up](https://thedecoding.net/)! I send out a thoughtful 5-minute email every week to keep you in the loop about machine learning research and the data economy.

*Thank you for reading and I see you next week ⭕!*

**References:**

\[1\] [https://arxiv.org/abs/2303.10130](https://arxiv.org/abs/2303.10130)"
259,learnmachinelearning,gpt-4,relevance,2020-06-10 21:02:43,"GPT-3: Explaining the $4,600,000 Neural Network from OpenAI",mippie_moe,False,0.67,3,h0k5xn,https://lambdalabs.com/blog/demystifying-gpt-3/,0,1591822963.0,
260,learnmachinelearning,gpt-4,relevance,2023-09-16 13:22:41,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.95,133,16k7heb,https://www.reddit.com/r/learnmachinelearning/comments/16k7heb/this_week_in_ai_all_the_major_ai_developments_in/,17,1694870561.0,"1. **Stability AI** launched Stable Audio, a generative AI tool for music & sound generation from text. The underlying latent diffusion model architecture uses audio conditioned on text metadata as well as audio file duration and start time.
2. **Coqui** released **XTTS** \- a new voice generation model that lets you clone voices in 13 different languages by using just a quick 3-second audio clip.
3. **Microsoft Research** released and open-sourced **Phi-1.5** \- a 1.3 billion parameter transformer-based model with performance on natural language tasks comparable to models 5x larger.
4. **Project Gutenberg**, Microsoft and MIT have worked together to use neural text-to-speech to create and release thousands of **human-quality free and open audiobooks**.
5. Researchers present **NExT-GPT -** an any-to-any multimodal LLM that accepts inputs and generate outputs in arbitrary combinations of text, images, videos, and audio.
6. **Chain of Density (CoD):** a new prompt introduced by researchers from Salesforce, MIT and Colombia University that generates more dense and human-preferable summaries compared to vanilla GPT-4.
7. **Adept** open-sources **Persimmon-8B**, releasing it under an Apache license. The model has been trained from scratch using a context size of 16K.
8. **Adobe's** **Firefly** generative AI models, after 176 days in beta, are now commercially available in Creative Cloud, Adobe Express, and Adobe Experience Cloud. Adobe is also launching Firefly as a standalone web app.
9. **Deci** released **DeciLM 6B**, a permissively licensed, open-source foundation LLM that is 15 times faster than Llama 2 while having comparable quality.
10. Researchers release **Scenimefy** \- a model transforming real-life photos into Shinkai-animation-style images.
11. **Microsoft** open sources **EvoDiff**, a novel protein-generating AI that could be used to create enzymes for new therapeutics and drug delivery methods as well as new enzymes for industrial chemical reactions.
12. Several companies including Adobe, IBM, Nvidia, Cohere, Palantir, Salesforce, Scale AI, and Stability AI have pledged to the White House to develop safe and trustworthy AI, in a voluntary agreement similar to an earlier one signed by Meta, Google, and OpenAI.
13. **Microsoft** will provide legal protection for customers who are sued for copyright infringement over content generated using Copilot, Bing Chat, and other AI services as long as they use built-in guardrails.
14. **NVIDIA** beta released **TensorRT** \- an open-source library that accelerates and optimizes inference performance on the latest LLMs on NVIDIA Tensor Core GPUs.
15. Pulitzer Prize winning novelist Michael Chabon and several other writers sue OpenAI of copyright infringement..
16. **NVIDIA** partners with two of India’s largest conglomerates, Reliance Industries Limited and Tata Group, to create an AI computing infrastructure and platforms for developing AI solutions.
17. **Roblox** announced a new conversational AI assistant that let creators build virtual assets and write code with the help of generative AI.
18. **Google** researchers introduced **MADLAD-400** \- a 3T token multilingual, general web-domain, document-level text dataset spanning 419 Languages.
19. A recent survey by **Salesforce** show that 65% of generative AI users are Millennials or Gen Z, and 72% are employed.  The survey included 4,000+ people across the United States, UK, Australia, and India.
20. **Meta** is reportedly working on an AI model designed to compete with GPT-4.

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
261,learnmachinelearning,gpt-4,relevance,2023-12-24 18:21:50,Best way to deploy chatbot for college website,Boring-Building-7139,False,0.99,6,18q0o71,https://www.reddit.com/r/learnmachinelearning/comments/18q0o71/best_way_to_deploy_chatbot_for_college_website/,2,1703442110.0,"We are creating a RAG-based chatbot for our college website using GPT 4. We want to deploy this, but are not sure how exactly to go forward with the same, and what factors to keep in mind while doing so. We've looked at options like Sagemaker, and Beanstalk and stuff, but not sure how to proceed.

How do you think it should be deployed?"
262,learnmachinelearning,gpt-4,relevance,2024-01-09 11:26:39,Leveraging ChatGPT for advanced text analysis and labeling / qualitative research,a_bdgr,False,0.5,0,192clhw,https://www.reddit.com/r/learnmachinelearning/comments/192clhw/leveraging_chatgpt_for_advanced_text_analysis_and/,0,1704799599.0,"I've been diving into building my first CustomGPT models in ChatGPT during the last couple of days and I'm keen to push the boundaries a bit  further. I'm contemplating using ChatGPT for more intricate tasks or  whether I should explore other LLMs or different methodologies /  technologies / plattforms altogether.   

Here's my project idea: 

I want to develop a CustomGPT that can  perform a silent analysis of input text and tag it with specific labels based on predefined categories. For instance, identifying stylistic elements in text: a detected metaphor would get ""Style-ID1"", a quotation ""Style-ID2"", and so on, with the potential for multiple labels per text, akin to qualitative content analysis.   

I'm pondering over a few questions:   

1. Do OpenAI's CustomGPTs possess the capability to work with such categorizations and then utilize the tagged results in subsequent processing?     
 
2. Any advice on the labeling format for this kind of task?     
 
3. How can I implement sequential processing steps? After labeling, I intend to have the GPT perform additional operations on the tagged   results.     
 
4. What system would be a better solution that ChatGPT?     
 

I'd greatly appreciate any insights or if anyone could point me toward resources like blogs, videos, or courses that address these topics. Thanks a bunch!   

(also, this is sort of a manual crosspost from [r/chatGPT](https://www.reddit.com/r/chatGPT/))   "
263,learnmachinelearning,gpt-4,relevance,2023-04-30 15:45:04,I don't have a PhD but this just feels wrong. Can a person with a PhD confirm?,flaky_psyche,False,0.76,61,133v9s5,https://i.redd.it/fmkvgop7l1xa1.jpg,238,1682869504.0,
264,learnmachinelearning,gpt-4,relevance,2023-05-25 13:37:41,🎉 Introducing TalentGPT: AI-Powered Tool for Cover Letters & CV Writing 🚀,City_Bike_09,False,0.5,0,13ri1pe,https://www.reddit.com/r/learnmachinelearning/comments/13ri1pe/introducing_talentgpt_aipowered_tool_for_cover/,0,1685021861.0," 

Hey Redditors! 👋

Say hello to [TalentGPT](https://coverletterassistant-github-io.vercel.app/) \- your new AI-powered companion for crafting the perfect cover letters and CVs! 🤖 Based on OpenAI's advanced GPT-4, we're here to change the game of job applications. 🎯 Try for **FREE** today: [https://coverletterassistant-github-io.vercel.app/](https://coverletterassistant-github-io.vercel.app/)

In just two weeks since our grand launch, we've had: 🌍 Users from 30+ countries 👥 400+ unique users 📈 2K+ use cases served

Our exciting features:

1️⃣ **AI Cover Letters:** 📝 Paste the job description, upload your resume, and let AI create a custom cover letter that matches your profile and job requirements perfectly.

2️⃣ **CV Writing Service:** 📄 Want a standout CV? Simply book a session with us [right here](https://forms.gle/ERFokS9qiNsbn9Mc6)!

Try [TalentGPT](https://coverletterassistant-github-io.vercel.app/) today, and supercharge your job application process! 🚀

Cheers, 

The [TalentGPT](https://coverletterassistant-github-io.vercel.app/) Team 👋

[Introduction to TalentGPT](https://reddit.com/link/13ri1pe/video/pd7rgnjpu02b1/player)"
265,learnmachinelearning,gpt-4,relevance,2023-05-25 13:33:10,🎉 Introducing TalentGPT: AI-Powered Tool for Cover Letters & CV Writing 🚀,City_Bike_09,False,0.33,0,13rhxsn,https://www.reddit.com/r/learnmachinelearning/comments/13rhxsn/introducing_talentgpt_aipowered_tool_for_cover/,0,1685021590.0," 

Hey Redditors! 👋

Say hello to [TalentGPT](https://coverletterassistant-github-io.vercel.app/) \- your new AI-powered companion for crafting the perfect cover letters and CVs! 🤖 Based on OpenAI's advanced GPT-4, we're here to change the game of job applications. 🎯 Try for **FREE** today: [https://coverletterassistant-github-io.vercel.app/](https://coverletterassistant-github-io.vercel.app/)

In just two weeks since our grand launch, we've had: 🌍 Users from 30+ countries 👥 400+ unique users 📈 2K+ use cases served

Our exciting features:

1️⃣ **AI Cover Letters:** 📝 Paste the job description, upload your resume, and let AI create a custom cover letter that matches your profile and job requirements perfectly.

2️⃣ **CV Writing Service:** 📄 Want a standout CV? Simply book a session with us [right here](https://forms.gle/ERFokS9qiNsbn9Mc6)!

Try [TalentGPT](https://coverletterassistant-github-io.vercel.app/) today, and supercharge your job application process! 🚀

Cheers, 

The [TalentGPT](https://coverletterassistant-github-io.vercel.app/) Team 👋

[Introduction to TalentGPT](https://reddit.com/link/13rhxsn/video/tn7vtngut02b1/player)"
266,learnmachinelearning,gpt-4,relevance,2023-03-28 16:24:47,Specific Open Problems in ML Alignment or Capabilities to Help Develop GPT-6?,TikkunCreation,False,0.67,1,124u87e,https://www.reddit.com/r/learnmachinelearning/comments/124u87e/specific_open_problems_in_ml_alignment_or/,2,1680020687.0,"As we witness the rapid advancements in large language models (LLMs) like GPT-4, I am increasingly interested in actively contributing to the research and development of even more advanced models, such as GPT-6 (given that GPT-5 is already being trained). I understand that training these models requires massive compute resources, and many people believe using LLMs is more valuable than creating them. However, I'm convinced that there's still a lot to learn, and I want to be part of the process that helps push the boundaries of AI research further.

I would like to ask for your input on what are three specific open problems in ML alignment or capabilities work, where if solved, they'd help in the development of models like GPT-6. I'm not interested in pointers related to making smaller models, fine tuning, distilling, prompting, or utilizing the models. I'm specifically interested in things that could help make GPT-6 better.

Basically, I'm looking for open puzzles. The most important open questions in research. Where I can play with it myself, and get a sense for some of the current challenges in the field."
267,learnmachinelearning,gpt-4,relevance,2023-06-01 21:56:29,"When we plug external embedding solutions like ImageBind into LLMs like LLaMA, how exactly is that done?",E_Snap,False,1.0,1,13xulwj,https://www.reddit.com/r/learnmachinelearning/comments/13xulwj/when_we_plug_external_embedding_solutions_like/,1,1685656589.0,"I’m currently working my way through Karpathy’s “[Let’s build GPT from scratch](https://youtu.be/kCc8FmEb1nY)”. In doing that, I’m trying to teach myself how the structures of multimodal models like [MiniGPT-4](https://arxiv.org/pdf/2304.10592.pdf) and [PandaGPT](https://arxiv.org/pdf/2305.16355.pdf) have been modified to allow information from external encoders like ImageBind and CLIP to interact with the LLaMA-based LLMs. The high-level description of “You freeze the LLM and vision encoders and then use a single feed-forward layer to align them” doesn’t exactly help me understand how the two models have been connected.

Would somebody be down to give me a non-data-scientist’s-level description of how these two models are interfaced? I feel like I’m understanding the Karpathy video pretty well so far, so you can get that complicated if it helps."
268,learnmachinelearning,gpt-4,relevance,2024-01-25 20:52:45,Implementing a Sparse Mixture of Experts Language Model from scratch,avi1x,False,0.66,1,19fjjrr,https://www.reddit.com/r/learnmachinelearning/comments/19fjjrr/implementing_a_sparse_mixture_of_experts_language/,0,1706215965.0,"Hi all,

I implemented a sparse mixture of experts language model (basically a tiny version of Mixtral and supposedly GPT-4) from scratch in pure pytorch and trained it on tiny Shakespeare. This is based largely on makemore from Andrej Karpathy (an autoregressive character-level decoder only transformer model). My goal is for this to be a hackable implementation that people use to understand how this really works and improve upon. I foresee more and more of these models coming out throughout the year.

The blog that steps through this is here: [https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch](https://huggingface.co/blog/avisoori1x/makemoe-from-scratch)

The repo is here: [https://github.com/AviSoori1x/makeMoE](https://github.com/avisoori1x/makemoe)

Hope this is helpful!"
269,learnmachinelearning,gpt-4,relevance,2023-07-04 14:25:26,"How To Fine-Tune LLaMA, OpenLLaMA, And XGen, With JAX On A GPU Or A TPU",juliensalinas,False,0.75,2,14qgnht,https://www.reddit.com/r/learnmachinelearning/comments/14qgnht/how_to_finetune_llama_openllama_and_xgen_with_jax/,0,1688480726.0,"Hello,

Fine-tuning  your own large language model is the best way to achieve  state-of-the-art results, even better than ChatGPT or GPT-4, especially  if you fine-tune a modern AI model like LLaMA, OpenLLaMA, or XGen.

Properly  fine-tuning these models is not necessarily easy though, so I made an A  to Z tutorial about fine-tuning these models with JAX on both GPUs and  TPUs, using the EasyLM library.

Here it is: [https://nlpcloud.com/how-to-fine-tune-llama-openllama-xgen-with-jax-on-tpu-gpu.html](https://nlpcloud.com/how-to-fine-tune-llama-openllama-xgen-with-jax-on-tpu-gpu.html?utm_source=reddit&utm_campaign=i859w625-3816-11ed-a261-0242ac140015)

I hope it will be helpful! If you think that something is missing in this tutorial please let me know!

Julien"
270,learnmachinelearning,gpt-4,relevance,2024-02-19 01:44:52,GPU vs CPU for inference,AI-Brain,False,0.56,1,1aubc4u,https://www.reddit.com/r/learnmachinelearning/comments/1aubc4u/gpu_vs_cpu_for_inference/,18,1708307092.0,"I read through some comments on the sub and understood that GPUs are mainly used for training and CPUs for inference. Had some follow ups: 
1. Is there a scenario where GPUs are better suited for inference? 
2. Would you say that if you are handling billions of inference requests then you should use GPUs? 
3. What makes GPUs inefficient for inference? (If any) 
4. When we use chatGPT, is OpenAI using CPUs for inference? 

Any insights would be helpful."
271,learnmachinelearning,gpt-4,relevance,2023-05-11 00:19:48,The last decade of NLP research covered in 50 concepts,AvvYaa,False,0.9,15,13e7ydv,https://www.reddit.com/r/learnmachinelearning/comments/13e7ydv/the_last_decade_of_nlp_research_covered_in_50/,0,1683764388.0," 

I just uploaded a video on my Youtube channel covering 50 important concepts discussing the last 10 years of NLP/Language Modeling research. 

The video covers the basics of word embeddings, tokenizers, and then the RNN based Seq2Seq architectures of the mid 2010s… then describes Attention/Transformers and some of the key Transformer-based LM research from 2017-2021. Finally, I cover human alignment / RLHF / instruction tuning with InstructGPT, ChatGPT and GPT-4. I tried to make a video that is accessible for new researchers/students to get their feet wet, and for guys like me to reminisce and celebrate the RNNs / self-supervised Transformer era as we step into the new world of human aligned LLMs. 

I am a small YT channel, and this is my first time doing a video of this scale (I normally do Reinforcement Learning stuff/paper reviews), so this was a fun and challenging video to produce. Feel free to check it out and leave any feedback for me to improve my content!

Here’s a link: 

[https://youtu.be/uocYQH0cWTs](https://youtu.be/uocYQH0cWTs)  
 

If the above link doesn’t work, try:  
 https://m.youtube.com/watch?v=uocYQH0cWTs&feature=youtu.be"
272,learnmachinelearning,gpt-4,relevance,2023-03-15 20:18:13,Do multi modal LLM models just inject image description to the context?,ChessGibson,False,0.94,13,11s7ya3,https://www.reddit.com/r/learnmachinelearning/comments/11s7ya3/do_multi_modal_llm_models_just_inject_image/,4,1678911493.0,"Hi! Small question I have been asking myself seeing multiple multi modal models recently: do they use interconnected neural networks for different input types, or do they simply convert non-text inputs into textual descriptions before processing them with their language models? What's happening for PaLM-E for instance? How about GPT-4?"
273,learnmachinelearning,gpt-4,relevance,2023-01-08 05:09:46,Major drawback/limitation of GPT-3,trafalgar28,False,0.77,7,106aie8,https://www.reddit.com/r/learnmachinelearning/comments/106aie8/major_drawbacklimitation_of_gpt3/,13,1673154586.0,"I have been working on a project with GPT-3 API for almost a month now. The only drawback of GPT-3 is that the prompt you can send to the model is capped at 4,000 tokens - where a token is roughly equivalent to ¾ of a word.  Due to this, providing a large context to GPT-3 is quite difficult.

Is there any way to resolve this issue?"
274,learnmachinelearning,gpt-4,relevance,2023-01-15 00:08:37,Is it still worth learning NLP in the age of API-accessibles LLM like GPT?,CrimsonPilgrim,False,0.93,61,10c509n,https://www.reddit.com/r/learnmachinelearning/comments/10c509n/is_it_still_worth_learning_nlp_in_the_age_of/,24,1673741317.0,"A question that, I hope, you will find legitimate from a data science student.

I am speaking from the point of view of a data scientist not working in research.

Until now, learning NLP could be used to meet occasional business needs like sentiment analysis, text classification, topic modeling....

With the opening of GPT-3 to the public, the rise of ChatGPT, and the huge wave of applications, sites, plug-ins and extensions based on this technology that are accessible with a simple API request, it's impossible not to wonder if spending dozens of hours diving into this field if ML wouldn't be as useful today as learning the source code of the Pandas library. 

In some specialized cases, it could be useful, but GPT-3, and the models that will follow, seem to offer more than sufficient results for the immensity of the cases and for almost all classical NLP tasks. Not only that, but there is a good chance that the models trained by giants like Open-AI (Microsoft) or Google can never be replicated outside these companies anyway.  With ChatGPT and its incomparable mastery of language, its ability to code, summarize, extract topics, understand... why would I bother to use BERT or a TF-IDF vectorizer when an API will be released? Not only it would be easily accessible, but it also would be much better at the task, faster and cheaper.

In fact, it's a concern regarding all the machine learning field in general with the arrival of powerful ""no-code"" applications, which abstract a large part of the inherent complexity of the field. There will always be a need for experts, for safeguards, but in the end, won't the Data Scientist who masters the features of GPT-3 or 4 and knows a bit of NLP be more efficient than the one who has spent hours reading Google papers and practicing on Gensim, NLTK, spacy... It is the purpose of an API to make things simpler eventually... At what point is there no more reason to be interested in the behind-the-scenes of these tools and to become simple users rather than trying to develop our own techniques?"
275,learnmachinelearning,gpt-4,relevance,2024-01-03 01:17:54,What libraries should I become proficient in as a machine learning engineer?,Bbpowrr,False,0.9,16,18x6eu9,https://www.reddit.com/r/learnmachinelearning/comments/18x6eu9/what_libraries_should_i_become_proficient_in_as_a/,16,1704244674.0,"I do MLE / DS at a big 4 firm, and have been doing so for about 2 years. I have experience with implementing some pretty cool solutions using the following libs:
- open AI (gpt & embedding models)
- huggingface
- faiss
- scikit-learn

I also have a 1st class CS degree from a Russell group uni and have done some ML projects during my degree.

But I have never had to / been taught how to use libraries such as TensorFlow or PyTorch or Keras in any ML project that I have implemented. Usually I use the scikit-learn library for model development.

However, I see a lot of jobs specifically asking for TensorFlow or PyTorch or Keras.

Therefore, I was wondering whether it is necessary to start upskilling in one or all of these libraries/frameworks to become a well established MLE? And if so, what is the best way to learn them?



Also, with my current skill set, how do I fair in the job market for MLE / DS roles? Ik it's not much to go off but any guesses would be appreciated.

For context, I have experience with using the following types of models:
- GPT / embedding
- ensemble (Random Forest, XGBoost, AdaBoost)
- computer vision (OCR)
- Clustering (cus Weka)
- SVM
- Naive Bayes
- Logistic regression 
- decision trees 

I think an obvious gap is a lack of neural networks / CNNs - does this matter much?

Many thanks for any advice!"
276,learnmachinelearning,gpt-4,relevance,2023-06-23 06:14:03,"[Updated] Top Large Language Models based on the Elo rating, MT-Bench, and MMLU",kingabzpro,False,0.94,92,14gqo26,https://i.redd.it/ixdabwx3mp7b1.png,9,1687500843.0,
277,learnmachinelearning,gpt-4,relevance,2024-02-12 19:52:03,"Predicted output after decoding is always empty strings in a list of tokens, but prediction looks fine.",asoulsghost,False,0.5,0,1ap946i,https://www.reddit.com/r/learnmachinelearning/comments/1ap946i/predicted_output_after_decoding_is_always_empty/,1,1707767523.0," I created a new project to debug with, my real one is much more complicated, but this code is just to show my issue:

\`\`\`import tensorflow as tf  
import numpy as np

from keras.callbacks import EarlyStopping  
from keras.layers import Bidirectional, Dropout, BatchNormalization, Embedding, LSTM, Dense  
from keras.optimizers import Adam  
from keras.regularizers import l2  
from keras.models import Sequential  
from keras.preprocessing.sequence import pad\_sequences  
from sklearn.model\_selection import train\_test\_split

user\_prompts = np.array(\[  
""What's your favorite animal?"",  
""What's your favorite movie?"",  
""What's your favorite book?"",  
""What's your favorite season?"",  
""What's your favorite hobby?"",  
""What's your favorite sport?"",  
""What's your favorite music genre?"",  
""What's your favorite dessert?"",  
""What's your favorite holiday?"",  
""What's your favorite beverage?"",  
""What's your favorite place to relax?"",  
""What's your favorite childhood memory?"",  
""What's your favorite superhero?"",  
""What's your favorite board game?"",  
""What's your favorite fruit?"",  
""What's your favorite vegetable?"",  
""What's your favorite type of weather?"",  
""What's your favorite clothing brand?"",  
""What's your favorite type of transportation?"",  
""What's your favorite quote?""  
\])

gpt\_responses = np.array(\[  
""I love elephants!"",  
""My favorite movie is The Shawshank Redemption."",  
""My favorite book is 1984 by George Orwell."",  
""I enjoy the crisp air of autumn."",  
""My favorite hobby is painting."",  
""I'm a fan of basketball."",  
""I enjoy listening to classical music."",  
""My favorite dessert is cheesecake."",  
""I love celebrating Christmas!"",  
""My favorite beverage is iced coffee."",  
""I love relaxing by the beach."",  
""One of my favorite childhood memories is building sandcastles."",  
""My favorite superhero is Batman."",  
""I enjoy playing Monopoly with friends."",  
""I love strawberries!"",  
""Broccoli is my favorite vegetable."",  
""I enjoy sunny days with a light breeze."",  
""I like wearing clothes from Zara."",  
""I enjoy traveling by train."",  
""One of my favorite quotes is 'Be yourself; everyone else is already taken.' - Oscar Wilde""  
\])

user\_tokenizer = tf.keras.preprocessing.text.Tokenizer()  
user\_tokenizer.fit\_on\_texts(user\_prompts)  
user\_sequences = user\_tokenizer.texts\_to\_sequences(user\_prompts)

with open('tokenizers/user\_tokenizer.json', 'w') as f:  
f.write(user\_tokenizer.to\_json())

gpt\_tokenizer = tf.keras.preprocessing.text.Tokenizer()  
gpt\_tokenizer.fit\_on\_texts(gpt\_responses)  
gpt\_sequences = gpt\_tokenizer.texts\_to\_sequences(gpt\_responses)

max\_sequence\_length\_user = max(len(seq) for seq in user\_sequences)  
max\_sequence\_length\_gpt = max(len(seq) for seq in gpt\_sequences)  
max\_sequence\_length = max(max\_sequence\_length\_user, max\_sequence\_length\_gpt)

padded\_user\_sequences = pad\_sequences(user\_sequences, maxlen=max\_sequence\_length, padding='post')  
padded\_gpt\_sequences = pad\_sequences(gpt\_sequences, maxlen=max\_sequence\_length, padding='post')

def normalize(arr, range):  
norm\_arr = \[\]  
t\_min = range\[0\]  
t\_max = range\[1\]  
diff = t\_max - t\_min  
diff\_arr = np.max(arr) - np.min(arr)  
for i in arr:  
temp = (((i - np.min(arr)) \* diff) / diff\_arr) + t\_min  
norm\_arr.append(temp)  
return norm\_arr

range\_to\_normalize = (0, 1)  
normalized\_input\_sequences = np.array(\[normalize(padded\_user\_sequence, range\_to\_normalize) for padded\_user\_sequence in padded\_user\_sequences\])  
normalized\_output\_sequences = np.array(\[normalize(padded\_gpt\_sequence, range\_to\_normalize) for padded\_gpt\_sequence in padded\_gpt\_sequences\])

user\_vocab\_size = len(user\_tokenizer.word\_index) + 1  
gpt\_vocab\_size = len(normalized\_output\_sequences\[1\])

embedding\_dim = 100  
complexity = 128  
dropout\_percentage = 0.2  
kernel\_l2 = 0.01  
model = Sequential(\[  
Embedding(input\_dim=user\_vocab\_size, output\_dim=embedding\_dim, input\_length=normalized\_input\_sequences.shape\[1\]),  
Bidirectional(LSTM(complexity, return\_sequences=True, kernel\_regularizer=l2(kernel\_l2))),  
Dropout(dropout\_percentage),  
BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
Dense(gpt\_vocab\_size, activation='softmax')  
\])

optimizer = Adam(learning\_rate=0.0001, clipvalue=1)

model.compile(optimizer=optimizer, loss='sparse\_categorical\_crossentropy', metrics=\['accuracy'\])

early\_stopping = EarlyStopping(monitor='val\_accuracy', min\_delta=0.001, patience=5)

indices = np.arange(len(normalized\_input\_sequences))  
np.random.shuffle(indices)

X\_shuffled = normalized\_input\_sequences\[indices\]  
y\_shuffled = normalized\_output\_sequences\[indices\]

test\_size = 0.2  
random\_state = 42  
X\_train, X\_val, y\_train, y\_val = train\_test\_split(X\_shuffled, y\_shuffled, test\_size=test\_size, random\_state=random\_state)

\# model.fit(X\_shuffled, y\_shuffled, epochs=100, batch\_size=1)  
model.fit(X\_train, y\_train, validation\_data=(X\_val, y\_val), epochs=100, batch\_size=1, callbacks=\[early\_stopping\])

user\_test\_prompts = np.array(\[""What's your favorite fruit?""\])  
gpt\_test\_outputs = \[""I love strawberries!""\]

user\_test\_sequences = user\_tokenizer.texts\_to\_sequences(user\_test\_prompts)

max\_test\_sequence\_length = 16  
padded\_test\_user\_sequences = pad\_sequences(user\_test\_sequences, maxlen=max\_test\_sequence\_length, padding='post')

normalized\_input\_test\_sequences = np.array(\[normalize(padded\_test\_user\_sequence, range\_to\_normalize) for padded\_test\_user\_sequence in padded\_test\_user\_sequences\])

temperature = 0.8  
predictions = model.predict(normalized\_input\_test\_sequences, verbose=0)

for prediction, user\_prompt, gpt\_output in zip(predictions, user\_test\_prompts, gpt\_test\_outputs):  
flat\_prediction = prediction.flatten()

flat\_prediction /= flat\_prediction.sum()  
predicted\_token\_index = np.random.choice(len(flat\_prediction), p=flat\_prediction, replace=False)

predicted\_token = user\_tokenizer.index\_word.get(predicted\_token\_index, '')

tokens = \[predicted\_token\]

predicted\_output = ' '.join(tokens)

print(f'User Input: {user\_prompt}')  
print(f'Desired output: {gpt\_output}')  
print(f'Predicted output: {predicted\_output}')  
print('-----')  
\`\`\`

I've tried many for loops, like

\`\`\`for prediction, user\_prompt, gpt\_output in zip(predictions, user\_test\_prompts, gpt\_test\_outputs):  
predicted\_token\_index = np.argmax(prediction)

predicted\_token = user\_tokenizer.index\_word.get(predicted\_token\_index, '')

tokens = \[predicted\_token\]

predicted\_output = ' '.join(tokens)

print(f'User Input: {user\_prompt}')  
print(f'Desired output: {gpt\_output}')  
print(f'Predicted output: {predicted\_output}')  
print('-----')\`\`\`

and just using sequences\_to\_texts, but every time I get an output of an empty string output:

\`\`\`

Epoch 1/100

16/16 \[==============================\] - 6s 86ms/step - loss: 6.0625 - accuracy: 0.0742 - val\_loss: 5.9392 - val\_accuracy: 0.6719

Epoch 2/100

16/16 \[==============================\] - 0s 10ms/step - loss: 5.8804 - accuracy: 0.1602 - val\_loss: 5.7778 - val\_accuracy: 0.7188

Epoch 3/100

16/16 \[==============================\] - 0s 11ms/step - loss: 5.6995 - accuracy: 0.2539 - val\_loss: 5.6206 - val\_accuracy: 0.7188

Epoch 4/100

16/16 \[==============================\] - 0s 10ms/step - loss: 5.5314 - accuracy: 0.3008 - val\_loss: 5.4669 - val\_accuracy: 0.7188

Epoch 5/100

16/16 \[==============================\] - 0s 11ms/step - loss: 5.3713 - accuracy: 0.3086 - val\_loss: 5.3100 - val\_accuracy: 0.7188

Epoch 6/100

16/16 \[==============================\] - 0s 20ms/step - loss: 5.2182 - accuracy: 0.3281 - val\_loss: 5.1557 - val\_accuracy: 0.7188

Epoch 7/100

16/16 \[==============================\] - 0s 13ms/step - loss: 5.0553 - accuracy: 0.3984 - val\_loss: 5.0053 - val\_accuracy: 0.7188

User Input: What's your favorite fruit?

Desired output: I love strawberries!

Predicted output:

\-----

Process finished with exit code 0\`\`\`, I've tried many things, like removing normalization and

one-hot output encoding (probably not a good idea because thats usually for classification not generation). My raw prediction output is normal:  
\`\`\`\[\[\[0.0778783 0.06557257 0.06076822 0.06065349 0.06032058 0.06186754

0.06202849 0.06043779 0.06187213 0.06038573 0.06225286 0.06136721

0.06165493 0.06092576 0.05997844 0.06203589\]

\[0.07813773 0.06527797 0.06089196 0.0602421 0.06040936 0.06162713

0.06217815 0.06030732 0.06193228 0.06045975 0.06238835 0.06133105

0.06170922 0.06085845 0.06014106 0.06210819\]

\[0.07833952 0.06496894 0.06099691 0.05998792 0.06056097 0.06142266

0.06232133 0.06021814 0.0619639 0.06049031 0.06242365 0.06129177

0.06174114 0.06080718 0.06028767 0.06217802\]

\[0.07714576 0.06573851 0.06085972 0.05999741 0.0605224 0.06195446

0.06237265 0.06069792 0.06204189 0.06072977 0.06180735 0.06170344

0.06147125 0.06063626 0.06026375 0.06205739\]

\[0.07684774 0.06629623 0.06064059 0.06021787 0.06011086 0.06213385

0.06202212 0.06079 0.06174838 0.06075808 0.06224376 0.06154948

0.06150243 0.06092658 0.06034113 0.06187094\]

\[0.07733375 0.06579494 0.06066 0.06014116 0.06015702 0.06201651

0.06207646 0.06072213 0.06171102 0.06070145 0.06238475 0.06147529

0.06157743 0.06092092 0.06041304 0.06191408\]

\[0.07779049 0.06529719 0.06067943 0.06011438 0.06018091 0.06195151

0.06212142 0.06069627 0.06166849 0.0606375 0.06245897 0.0614467

0.06162487 0.06092478 0.06046251 0.06194457\]

\[0.07823473 0.06480044 0.0606989 0.06011757 0.06018409 0.06192542

0.06215886 0.06069161 0.06162626 0.0605731 0.06249316 0.06145227

0.06165317 0.06093194 0.06049183 0.06196667\]

\[0.07868056 0.06430052 0.06071777 0.06013772 0.06017078 0.06192584

0.06218894 0.060694 0.06158946 0.06051284 0.06250336 0.06148436

0.06166806 0.06093916 0.06050381 0.06198284\]

\[0.0791392 0.06379254 0.06073484 0.06016705 0.0601466 0.0619412

0.06221085 0.06069355 0.06156332 0.06046034 0.0624989 0.06153729

0.06167305 0.06094532 0.06050154 0.0619944 \]

\[0.07961872 0.06327192 0.06074828 0.06020188 0.0601184 0.06195999

0.06222335 0.06068258 0.06155341 0.06041929 0.06248498 0.06160597

0.06166972 0.06095124 0.06048853 0.0620018 \]

\[0.08012372 0.06273551 0.06075554 0.06024196 0.06009471 0.06196976

0.06222508 0.06065388 0.06156564 0.06039423 0.06246426 0.06168433

0.06165774 0.06095998 0.06046907 0.06200464\]

\[0.08065483 0.06218292 0.06075338 0.0602902 0.06008709 0.06195565

0.06221479 0.060599 0.06160573 0.06039128 0.06243812 0.06176374

0.06163492 0.06097768 0.06044899 0.06200173\]

\[0.08120844 0.06161809 0.06073787 0.06035243 0.06011206 0.06189844

0.06219138 0.06050603 0.06167795 0.06041874 0.06240781 0.06183083

0.0615972 0.06101486 0.06043666 0.06199118\]

\[0.08177745 0.06105088 0.06070472 0.06043745 0.06019438 0.06177184

0.06215353 0.06035656 0.0617824 0.06048765 0.06237619 0.0618646

0.06153877 0.06108828 0.0604446 0.06197073\]

\[0.08235379 0.06049864 0.06064992 0.06055691 0.06037189 0.06153841

0.06209862 0.06012097 0.06191007 0.06061208 0.06235056 0.06183248

0.06145228 0.0612235 0.06049152 0.06193841\]\]\]\`\`\`. Does anyone know what to do?"
278,learnmachinelearning,gpt-4,relevance,2023-12-22 21:46:24,NeuralFlash - a flashcard-making GPT specializing in AI to help you study.,MachineScholar,False,1.0,1,18opsjh,https://www.reddit.com/r/learnmachinelearning/comments/18opsjh/neuralflash_a_flashcardmaking_gpt_specializing_in/,0,1703281584.0,"Hey everyone. I'm a computer science student and I've been searching for the most efficient way to study ML concepts via Quizlet flashcards so I came up with a ""pipeline"" by making this custom GPT and feeding it my Markdown notes. Here's a little guide:

1. Take lecture/book notes in Markdown (I use obsidian to do this since it's free, fast, and open source)
2. Open up NeuralFlash and choose the ""Generate flashcards from my AI notes"" action.
3. Copy your entire Markdown note, paste it into NeuralFlash.
4. Copy the csv it outputs and paste it into the ""import"" area of your Quizlet flashcard set (make sure you select comma instead of tab).
5. Learn and succeed.

**Here the link to the GPT:** [**https://chat.openai.com/g/g-m4nFBaKA8-neuralflash**](https://chat.openai.com/g/g-m4nFBaKA8-neuralflash)"
279,learnmachinelearning,gpt-4,relevance,2023-06-09 04:07:58,Comparing RL and LLMs for Game Playing AI (A video),AvvYaa,False,0.8,3,144urod,https://www.reddit.com/r/learnmachinelearning/comments/144urod/comparing_rl_and_llms_for_game_playing_ai_a_video/,0,1686283678.0," Hey guys! I published a video on my YT highlighting the recent trends in game playing AI research with LLMs and how Reinforcement Learning could benefit or be affected by it. 

I tried to explain recent papers like SPRING and Voyager which are straight-up LLM-based (GPT-4 and ChatGPT) methods that play open-world survival games like Minecraft and Crafter, through some really neat prompting and chain-of-thought techniques. I also cover LLM-assisted RL methods like ELLM, DESP, and Read and Reap Rewards that help train RL Agents efficiently by addressing many common issues with RL training, namely sparse rewards and sample efficiency.

I tried to stay at a level that most people interested in the topic could take something away from watching it. I’m a small Youtuber, so I appreciate any feedback I can get here!

Leaving a link here in case anyone is interested!  
 [https://youtu.be/cXfnNoMgCio](https://youtu.be/cXfnNoMgCio)

If the above doesn’t work, try:

[https://m.youtube.com/watch?v=cXfnNoMgCio&feature=youtu.be](https://m.youtube.com/watch?v=cXfnNoMgCio&feature=youtu.be)"
280,learnmachinelearning,gpt-4,relevance,2024-02-13 19:38:44,"Predicted output after decoding is always empty strings in a list of tokens, but prediction looks fine.",asoulsghost,False,0.33,0,1aq2dya,https://www.reddit.com/r/learnmachinelearning/comments/1aq2dya/predicted_output_after_decoding_is_always_empty/,3,1707853124.0,"Predicted output after decoding is always empty strings in a list of tokens, but prediction looks fine.

I created a new project to debug with, my real one is much more complicated, but this code is just to show my issue:

\`\`\`import tensorflow as tf  
import numpy as np

from keras.callbacks import EarlyStopping  
from keras.layers import Bidirectional, Dropout, BatchNormalization, Embedding, LSTM, Dense  
from keras.optimizers import Adam  
from keras.regularizers import l2  
from keras.models import Sequential  
from keras.preprocessing.sequence import pad\_sequences  
from sklearn.model\_selection import train\_test\_split

user\_prompts = np.array(\[  
""What's your favorite animal?"",  
""What's your favorite movie?"",  
""What's your favorite book?"",  
""What's your favorite season?"",  
""What's your favorite hobby?"",  
""What's your favorite sport?"",  
""What's your favorite music genre?"",  
""What's your favorite dessert?"",  
""What's your favorite holiday?"",  
""What's your favorite beverage?"",  
""What's your favorite place to relax?"",  
""What's your favorite childhood memory?"",  
""What's your favorite superhero?"",  
""What's your favorite board game?"",  
""What's your favorite fruit?"",  
""What's your favorite vegetable?"",  
""What's your favorite type of weather?"",  
""What's your favorite clothing brand?"",  
""What's your favorite type of transportation?"",  
""What's your favorite quote?""  
\])

gpt\_responses = np.array(\[  
""I love elephants!"",  
""My favorite movie is The Shawshank Redemption."",  
""My favorite book is 1984 by George Orwell."",  
""I enjoy the crisp air of autumn."",  
""My favorite hobby is painting."",  
""I'm a fan of basketball."",  
""I enjoy listening to classical music."",  
""My favorite dessert is cheesecake."",  
""I love celebrating Christmas!"",  
""My favorite beverage is iced coffee."",  
""I love relaxing by the beach."",  
""One of my favorite childhood memories is building sandcastles."",  
""My favorite superhero is Batman."",  
""I enjoy playing Monopoly with friends."",  
""I love strawberries!"",  
""Broccoli is my favorite vegetable."",  
""I enjoy sunny days with a light breeze."",  
""I like wearing clothes from Zara."",  
""I enjoy traveling by train."",  
""One of my favorite quotes is 'Be yourself; everyone else is already taken.' - Oscar Wilde""  
\])

user\_tokenizer = tf.keras.preprocessing.text.Tokenizer()  
user\_tokenizer.fit\_on\_texts(user\_prompts)  
user\_sequences = user\_tokenizer.texts\_to\_sequences(user\_prompts)

with open('tokenizers/user\_tokenizer.json', 'w') as f:  
f.write(user\_tokenizer.to\_json())

gpt\_tokenizer = tf.keras.preprocessing.text.Tokenizer()  
gpt\_tokenizer.fit\_on\_texts(gpt\_responses)  
gpt\_sequences = gpt\_tokenizer.texts\_to\_sequences(gpt\_responses)

max\_sequence\_length\_user = max(len(seq) for seq in user\_sequences)  
max\_sequence\_length\_gpt = max(len(seq) for seq in gpt\_sequences)  
max\_sequence\_length = max(max\_sequence\_length\_user, max\_sequence\_length\_gpt)

padded\_user\_sequences = pad\_sequences(user\_sequences, maxlen=max\_sequence\_length, padding='post')  
padded\_gpt\_sequences = pad\_sequences(gpt\_sequences, maxlen=max\_sequence\_length, padding='post')

def normalize(arr, range):  
norm\_arr = \[\]  
t\_min = range\[0\]  
t\_max = range\[1\]  
diff = t\_max - t\_min  
diff\_arr = np.max(arr) - np.min(arr)  
for i in arr:  
temp = (((i - np.min(arr)) \* diff) / diff\_arr) + t\_min  
norm\_arr.append(temp)  
return norm\_arr

range\_to\_normalize = (0, 1)  
normalized\_input\_sequences = np.array(\[normalize(padded\_user\_sequence, range\_to\_normalize) for padded\_user\_sequence in padded\_user\_sequences\])  
normalized\_output\_sequences = np.array(\[normalize(padded\_gpt\_sequence, range\_to\_normalize) for padded\_gpt\_sequence in padded\_gpt\_sequences\])

user\_vocab\_size = len(user\_tokenizer.word\_index) + 1  
gpt\_vocab\_size = len(normalized\_output\_sequences\[1\])

embedding\_dim = 100  
complexity = 128  
dropout\_percentage = 0.2  
kernel\_l2 = 0.01  
model = Sequential(\[  
Embedding(input\_dim=user\_vocab\_size, output\_dim=embedding\_dim, input\_length=normalized\_input\_sequences.shape\[1\]),  
Bidirectional(LSTM(complexity, return\_sequences=True, kernel\_regularizer=l2(kernel\_l2))),  
Dropout(dropout\_percentage),  
BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
\# Dense(complexity, activation='relu', kernel\_regularizer=l2(kernel\_l2)),  
\# Dropout(dropout\_percentage),  
\# BatchNormalization(),  
Dense(gpt\_vocab\_size, activation='softmax')  
\])

optimizer = Adam(learning\_rate=0.0001, clipvalue=1)

model.compile(optimizer=optimizer, loss='sparse\_categorical\_crossentropy', metrics=\['accuracy'\])

early\_stopping = EarlyStopping(monitor='val\_accuracy', min\_delta=0.001, patience=5)

indices = np.arange(len(normalized\_input\_sequences))  
np.random.shuffle(indices)

X\_shuffled = normalized\_input\_sequences\[indices\]  
y\_shuffled = normalized\_output\_sequences\[indices\]

test\_size = 0.2  
random\_state = 42  
X\_train, X\_val, y\_train, y\_val = train\_test\_split(X\_shuffled, y\_shuffled, test\_size=test\_size, random\_state=random\_state)

\# model.fit(X\_shuffled, y\_shuffled, epochs=100, batch\_size=1)  
model.fit(X\_train, y\_train, validation\_data=(X\_val, y\_val), epochs=100, batch\_size=1, callbacks=\[early\_stopping\])

user\_test\_prompts = np.array(\[""What's your favorite fruit?""\])  
gpt\_test\_outputs = \[""I love strawberries!""\]

user\_test\_sequences = user\_tokenizer.texts\_to\_sequences(user\_test\_prompts)

max\_test\_sequence\_length = 16  
padded\_test\_user\_sequences = pad\_sequences(user\_test\_sequences, maxlen=max\_test\_sequence\_length, padding='post')

normalized\_input\_test\_sequences = np.array(\[normalize(padded\_test\_user\_sequence, range\_to\_normalize) for padded\_test\_user\_sequence in padded\_test\_user\_sequences\])

temperature = 0.8  
predictions = model.predict(normalized\_input\_test\_sequences, verbose=0)

for prediction, user\_prompt, gpt\_output in zip(predictions, user\_test\_prompts, gpt\_test\_outputs):  
flat\_prediction = prediction.flatten()

flat\_prediction /= flat\_prediction.sum()  
predicted\_token\_index = np.random.choice(len(flat\_prediction), p=flat\_prediction, replace=False)

predicted\_token = user\_tokenizer.index\_word.get(predicted\_token\_index, '')

tokens = \[predicted\_token\]

predicted\_output = ' '.join(tokens)

print(f'User Input: {user\_prompt}')  
print(f'Desired output: {gpt\_output}')  
print(f'Predicted output: {predicted\_output}')  
print('-----')  
\`\`\`

I've tried many for loops, like

\`\`\`for prediction, user\_prompt, gpt\_output in zip(predictions, user\_test\_prompts, gpt\_test\_outputs):  
predicted\_token\_index = np.argmax(prediction)

predicted\_token = user\_tokenizer.index\_word.get(predicted\_token\_index, '')

tokens = \[predicted\_token\]

predicted\_output = ' '.join(tokens)

print(f'User Input: {user\_prompt}')  
print(f'Desired output: {gpt\_output}')  
print(f'Predicted output: {predicted\_output}')  
print('-----')\`\`\`

and just using sequences\_to\_texts, but every time I get an output of an empty string output:

\`\`\`

Epoch 1/100

16/16 \[==============================\] - 6s 86ms/step - loss: 6.0625 - accuracy: 0.0742 - val\_loss: 5.9392 - val\_accuracy: 0.6719

Epoch 2/100

16/16 \[==============================\] - 0s 10ms/step - loss: 5.8804 - accuracy: 0.1602 - val\_loss: 5.7778 - val\_accuracy: 0.7188

Epoch 3/100

16/16 \[==============================\] - 0s 11ms/step - loss: 5.6995 - accuracy: 0.2539 - val\_loss: 5.6206 - val\_accuracy: 0.7188

Epoch 4/100

16/16 \[==============================\] - 0s 10ms/step - loss: 5.5314 - accuracy: 0.3008 - val\_loss: 5.4669 - val\_accuracy: 0.7188

Epoch 5/100

16/16 \[==============================\] - 0s 11ms/step - loss: 5.3713 - accuracy: 0.3086 - val\_loss: 5.3100 - val\_accuracy: 0.7188

Epoch 6/100

16/16 \[==============================\] - 0s 20ms/step - loss: 5.2182 - accuracy: 0.3281 - val\_loss: 5.1557 - val\_accuracy: 0.7188

Epoch 7/100

16/16 \[==============================\] - 0s 13ms/step - loss: 5.0553 - accuracy: 0.3984 - val\_loss: 5.0053 - val\_accuracy: 0.7188

User Input: What's your favorite fruit?

Desired output: I love strawberries!

Predicted output:

\-----

Process finished with exit code 0\`\`\`, I've tried many things, like removing normalization and

one-hot output encoding (probably not a good idea because thats usually for classification not generation). My raw prediction output is normal:  
\`\`\`\[\[\[0.0778783 0.06557257 0.06076822 0.06065349 0.06032058 0.06186754

0.06202849 0.06043779 0.06187213 0.06038573 0.06225286 0.06136721

0.06165493 0.06092576 0.05997844 0.06203589\]

\[0.07813773 0.06527797 0.06089196 0.0602421 0.06040936 0.06162713

0.06217815 0.06030732 0.06193228 0.06045975 0.06238835 0.06133105

0.06170922 0.06085845 0.06014106 0.06210819\]

\[0.07833952 0.06496894 0.06099691 0.05998792 0.06056097 0.06142266

0.06232133 0.06021814 0.0619639 0.06049031 0.06242365 0.06129177

0.06174114 0.06080718 0.06028767 0.06217802\]

\[0.07714576 0.06573851 0.06085972 0.05999741 0.0605224 0.06195446

0.06237265 0.06069792 0.06204189 0.06072977 0.06180735 0.06170344

0.06147125 0.06063626 0.06026375 0.06205739\]

\[0.07684774 0.06629623 0.06064059 0.06021787 0.06011086 0.06213385

0.06202212 0.06079 0.06174838 0.06075808 0.06224376 0.06154948

0.06150243 0.06092658 0.06034113 0.06187094\]

\[0.07733375 0.06579494 0.06066 0.06014116 0.06015702 0.06201651

0.06207646 0.06072213 0.06171102 0.06070145 0.06238475 0.06147529

0.06157743 0.06092092 0.06041304 0.06191408\]

\[0.07779049 0.06529719 0.06067943 0.06011438 0.06018091 0.06195151

0.06212142 0.06069627 0.06166849 0.0606375 0.06245897 0.0614467

0.06162487 0.06092478 0.06046251 0.06194457\]

\[0.07823473 0.06480044 0.0606989 0.06011757 0.06018409 0.06192542

0.06215886 0.06069161 0.06162626 0.0605731 0.06249316 0.06145227

0.06165317 0.06093194 0.06049183 0.06196667\]

\[0.07868056 0.06430052 0.06071777 0.06013772 0.06017078 0.06192584

0.06218894 0.060694 0.06158946 0.06051284 0.06250336 0.06148436

0.06166806 0.06093916 0.06050381 0.06198284\]

\[0.0791392 0.06379254 0.06073484 0.06016705 0.0601466 0.0619412

0.06221085 0.06069355 0.06156332 0.06046034 0.0624989 0.06153729

0.06167305 0.06094532 0.06050154 0.0619944 \]

\[0.07961872 0.06327192 0.06074828 0.06020188 0.0601184 0.06195999

0.06222335 0.06068258 0.06155341 0.06041929 0.06248498 0.06160597

0.06166972 0.06095124 0.06048853 0.0620018 \]

\[0.08012372 0.06273551 0.06075554 0.06024196 0.06009471 0.06196976

0.06222508 0.06065388 0.06156564 0.06039423 0.06246426 0.06168433

0.06165774 0.06095998 0.06046907 0.06200464\]

\[0.08065483 0.06218292 0.06075338 0.0602902 0.06008709 0.06195565

0.06221479 0.060599 0.06160573 0.06039128 0.06243812 0.06176374

0.06163492 0.06097768 0.06044899 0.06200173\]

\[0.08120844 0.06161809 0.06073787 0.06035243 0.06011206 0.06189844

0.06219138 0.06050603 0.06167795 0.06041874 0.06240781 0.06183083

0.0615972 0.06101486 0.06043666 0.06199118\]

\[0.08177745 0.06105088 0.06070472 0.06043745 0.06019438 0.06177184

0.06215353 0.06035656 0.0617824 0.06048765 0.06237619 0.0618646

0.06153877 0.06108828 0.0604446 0.06197073\]

\[0.08235379 0.06049864 0.06064992 0.06055691 0.06037189 0.06153841

0.06209862 0.06012097 0.06191007 0.06061208 0.06235056 0.06183248

0.06145228 0.0612235 0.06049152 0.06193841\]\]\]\`\`\`. 

I also tried using perplexity evaluation metric aka fitness function, and:

Epoch 1/100  
16/16 \[==============================\] - 5s 290ms/step - loss: 6.0888 - perplexity: 6.9396 - val\_loss: 5.9520 - val\_perplexity: 6.6479  
Epoch 2/100  
16/16 \[==============================\] - 4s 224ms/step - loss: 5.9030 - perplexity: 6.7237 - val\_loss: 5.7916 - val\_perplexity: 6.5424  
Epoch 3/100  
16/16 \[==============================\] - 3s 212ms/step - loss: 5.7288 - perplexity: 6.5413 - val\_loss: 5.6320 - val\_perplexity: 6.4178  
...

\- val\_loss: 0.4093 - val\_perplexity: 1.2230  
Epoch 98/100  
16/16 \[==============================\] - 4s 242ms/step - loss: 0.3155 - perplexity: 1.1455 - val\_loss: 0.3940 - val\_perplexity: 1.2116  
Epoch 99/100  
16/16 \[==============================\] - 4s 246ms/step - loss: 0.3100 - perplexity: 1.1425 - val\_loss: 0.3988 - val\_perplexity: 1.2173  
Epoch 100/100  
16/16 \[==============================\] - 4s 242ms/step - loss: 0.3142 - perplexity: 1.1478 - val\_loss: 0.4027 - val\_perplexity: 1.2223  
User Input: What's your favorite fruit?  
Desired output: I love strawberries!  
Predicted output:  
\-----  
Process finished with exit code 0

Does anyone know what to do? PS: evaluation metric was just:  
def perplexity(y\_true, y\_pred):  
cross\_entropy = keras.losses.sparse\_categorical\_crossentropy(y\_true, y\_pred, from\_logits=False)  
perplexity\_value = 2 \*\* tf.reduce\_mean(cross\_entropy)  


return perplexity\_value"
281,learnmachinelearning,gpt-4,relevance,2023-06-16 16:04:27,Custom AI app,guppyguyco,False,0.5,0,14b0p3a,https://www.reddit.com/r/learnmachinelearning/comments/14b0p3a/custom_ai_app/,0,1686931467.0,"I need your expertise! I’m working on creating sets of Earth Science practice questions with multiple-choice answers for high school students. Some of these sets require images/data tables/graphs that students will reference to answer the question.

Essential Requirements:

* Questions should test the application of knowledge, **not just recall**.
* Question difficulty and format must be consistent.
* Answer options should be plausible, distinct, and similar in length and detail.

Here's an example:

*INSTEAD OF ""How do scientists calculate the age of a star?"" (this is a content recall question) → ""Scientists calculate the age of a star by using Hertzsprung-Russell diagrams. These diagrams have the temperature of stars plotted against their brightness. Using the following graph (insert image), approximate the age of a star that is x degrees in temperature and x in brightness.""*

I’ve tried using Chat GPT-4, however I’m finding that it doesn’t remember the criteria for quality questions and frequently will give questions that rely upon recall. Additionally, Chat-GPT cannot generate images or graphs that I might use as stimuli to accompany the questions.

I have basic programming knowledge and I’m wondering if it's possible to create an automated tool to generate these questions and answers, and incorporate relevant images.

Which platforms or programming languages would be best to use for this task?"
282,learnmachinelearning,gpt-4,relevance,2023-11-07 19:20:33,System Prompt Library,MetalZuna,False,1.0,1,17q21tb,https://www.reddit.com/r/learnmachinelearning/comments/17q21tb/system_prompt_library/,0,1699384833.0,"System Prompt Library for ChatGPT - 4  


Check it out!

&#x200B;

[https://github.com/MetalZuna/Snap](https://github.com/MetalZuna/Snap)"
283,learnmachinelearning,gpt-4,relevance,2023-09-30 15:01:31,This week in AI - all the Major AI developments in a nutshell,wyem,False,0.97,82,16w93bx,https://www.reddit.com/r/learnmachinelearning/comments/16w93bx/this_week_in_ai_all_the_major_ai_developments_in/,4,1696086091.0,"1. **Meta AI** presents **Emu**, a quality-tuned latent diffusion model for generating highly aesthetic images. Emu significantly outperforms SDXLv1.0 on visual appeal.
2. **Meta AI** researchers present a series of long-context LLMs with context windows of up to 32,768 tokens. LLAMA 2 70B variant surpasses gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks.
3. **Abacus AI** released a larger 70B version of **Giraffe**. Giraffe is a family of models that are finetuned from base Llama 2 and have a larger context length of 32K tokens\].
4. **Meta** announced:  

   1. **Meta AI** \- a new AI assistant users can interact with on WhatsApp, Messenger and Instagram. Will also be available on Ray-Ban Meta smart glasses and Quest 3, Meta’s mixed reality headset.
   2. **AI stickers** that enable users to generate customized stickers for chats and stories using text. Powered by Llama 2 and the new foundational model for image generation, Emu.
   3. **28 AI characters**, each with a unique personality that users can message on WhatsApp, Messenger, and Instagram.
   4. New AI editing tools, **restyle** and **backdrop** in Instagram.
   5. **AI Studio** \- a platform that supports the creation of custom AIs by coders and non-coders alike.
5. **Cerebras** and **Opentensor** released Bittensor Language Model, ‘**BTLM-3B-8K**’, a new 3 billion parameter open-source language model with an 8k context length trained on 627B tokens of SlimPajama. It outperforms models trained on hundreds of billions more tokens and achieves comparable performance to open 7B parameter models. The model needs only 3GB of memory with 4-bit precision and takes 2.5x less inference compute than 7B models and is available with an Apache 2.0 license for commercial use.
6. **OpenAI** is rolling out, over the next two weeks, new voice and image capabilities in ChatGPT enabling ChatGPT to understand images, understand speech and speak. The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. .
7. **Mistral AI**, a French startup, released its first 7B-parameter model, **Mistral 7B**, which outperforms all currently available open models up to 13B parameters on all standard English and code benchmarks. Mistral 7B is released in Apache 2.0, making it usable without restrictions anywhere.
8. **OpenAI** has returned the ChatGPT browsing feature for Plus subscribers, enabling ChatGPT to access internet for current information. It was disabled earlier as users were able to deploy it to bypass the paywalls of leading news publishers.
9. **Microsoft** has released **AutoGen** \- an open-source framework that enables development of LLM applications using multiple agents that can converse with each other to solve a task. Agents can operate in various modes that employ combinations of LLMs, human inputs and tools.
10. **LAION** released **LeoLM**, the first open and commercially available German foundation language model built on Llama-2
11. Researchers from **Google** and **Cornell University** present and release code for DynIBaR (Neural Dynamic Image-Based Rendering) - a novel approach that generates photorealistic renderings from complex, dynamic videos taken with mobile device cameras, overcoming fundamental limitations of prior methods and enabling new video effects.
12. **Cloudflare** launched **Workers AI** (an AI inference as a service platform), **Vectorize** (a vector Database) and **AI Gateway** with tools to cache, rate limit and observe AI deployments. Llama2 is available on Workers AI.
13. **Amazon** announced the general availability of **Bedrock**, its service that offers a choice of generative AI models from Amazon itself and third-party partners through an API.
14. **Google** announced it’s giving website publishers a way to opt out of having their data used to train the company’s AI models while remaining accessible through Google Search.
15. **Spotify** has launched a pilot program for AI-powered voice translations of podcasts in other languages - in the podcaster’s voic. It uses OpenAI’s newly released voice generation model.
16. **Getty Images** has launched a generative AI image tool, ‘**Generative AI by Getty Images**’, that is ‘commercially‑safe’. It’s powered by Nvidia Picasso, a custom model trained exclusively using Getty’s images library.
17. **Optimus**, Tesla’s humanoid robot, can now sort objects autonomously and do yoga. Its neural network is trained fully end-to-end.
18. **Amazon** will invest up to $4 billion in Anthropic. Developers and engineers will be able to build on top of Anthropic’s models via Amazon Bedrock.
19. **Google Search** indexed shared Bard conversational links into its search results pages. Google says it is working on a fix.
20. **Pika** Labs' text-to-video tool now lets users encrypt a message in a video\].

My plug: If you like this news format, you might find the [newsletter, AI Brews](https://aibrews.com/), helpful - it's free to join, sent only once a week with bite-sized news, learning resources and selected tools. I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks"
284,learnmachinelearning,gpt-4,relevance,2023-11-08 15:37:10,Start with Large Language Models (LLMs) in 2023,OnlyProggingForFun,False,0.6,1,17qo9mp,https://www.reddit.com/r/learnmachinelearning/comments/17qo9mp/start_with_large_language_models_llms_in_2023/,0,1699457830.0,"This is a complete guide to start and improve your LLM skills in 2023 without an advanced background in the field and stay up-to-date with the latest news and state-of-the-art techniques!

The complete article: https://www.louisbouchard.ai/from-zero-to-hero-with-llms/

All the links on GitHub: https://github.com/louisfb01/start-llms 

Artificial is a fantastic field, and so are language models like GPT-4, Claude..., but it goes extremely fast. Don't miss out on the most important and exciting news by joining great communities, people, newsletters, and more you can all find in this guide!

This guide is intended for anyone with a small background in programming and machine learning. Simple python knowledge is enough to get you started. There is no specific order to follow, but a classic path would be from top to bottom. If you don't like reading books, skip it, if you don't want to follow an online course, you can skip it as well. There is not a single way to become a ""LLM expert"" and with motivation, you can absolutely achieve it."
285,learnmachinelearning,gpt-4,relevance,2023-12-01 14:05:32,Metrics for evaluating summarizations done by LLMs?,mrhennessy26,False,1.0,1,188co3i,https://www.reddit.com/r/learnmachinelearning/comments/188co3i/metrics_for_evaluating_summarizations_done_by_llms/,0,1701439532.0,"Hey guys, I'm writing my thesis on text summarization by LLMs. I have to compare GPT with other LLMs and evaluate the summaries. I found that metrics like Rouge and Bleu are noot really suited for the evaluation. If you had to choose 4 metrics, which ones would you choose?"
286,learnmachinelearning,gpt-4,relevance,2023-08-16 17:50:56,"Bright Eye: free IOS mobile AI app that generates text, images, and analyzes photos.",EtelsonRecomputing,False,0.67,1,15swuwk,https://www.reddit.com/r/learnmachinelearning/comments/15swuwk/bright_eye_free_ios_mobile_ai_app_that_generates/,0,1692208256.0,"Hi all. I’m the cofounder of a startup focused on developing the AI super app called “Bright Eye”, a multipurpose AI product that generates and analyzes content.

One of its interesting use cases is helping students study, people plan, code, compute math, and offering general advice. 

As the title puts it, it’s capable of generating almost anything, so the use-cases in terms of productivity isn’t confined to only those above, it can apply however you see fit. We run on GPT-4, stable diffusion, and Microsoft azure cognitive services to provide text generation, image generation, and prepackaged computer vision capabilities.

Check us out below, we’re looking for advice on the functionality, it’s ability to satisfy your role play needs, and design of the app (and possibly some longtime users): 

https://apps.apple.com/us/app/bright-eye/id1593932475"
287,learnmachinelearning,gpt-4,relevance,2023-03-21 13:38:10,Large Language models for Summarization,vm123313223,False,1.0,1,11xh5hr,https://www.reddit.com/r/learnmachinelearning/comments/11xh5hr/large_language_models_for_summarization/,2,1679405890.0,"How to get the results of OpenAI (GPT-3) for summarization with open source models?

Some models which I have tried are:

1. FLAN-T5
2. Pegasus
3. BART
4. GPT-J
5. FTAN--UL2

I have also implemented fewshot learning with these models."
288,learnmachinelearning,gpt-4,relevance,2023-02-22 02:32:01,How to Use ChatGPT in Python API and Run Batch Jobs with UI,Fun_Pollution_3899,False,0.86,5,118mk1d,https://www.reddit.com/r/learnmachinelearning/comments/118mk1d/how_to_use_chatgpt_in_python_api_and_run_batch/,0,1677033121.0,"I wanted to share a tutorial on how to use ChatGPT in Python API and how to run batch jobs with a UI. ChatGPT is a powerful language model that can generate text in a conversational manner. It can be used for a variety of tasks, such as chatbots, text completion, and more.
Repo: [https://github.com/CodeDiggerM/chatgpt-batch-whipper](https://github.com/CodeDiggerM/chatgpt-batch-whipper)

## Installation
### Use PIP command
1. Install the latest version of this software directly from github with pip:
```bash
  pip install git+https://github.com/CodeDiggerM/chatgpt-batch-whipper.git
```
2. Go to **auth** mode. This will open up a browser window. Log in to ChatGPT in the browser window, then close the browser.
```bash
run_chatgpt auth
```
3. Start the UI
```bash
run_chatgpt ui
```

### Manually set up

1. Clone the repo to your working directory
```bash
git clone https://github.com/CodeDiggerM/chatgpt-batch-whipper.git
```
2. install the dependcy.
```bash
pip install -r requirements.txt
```

3. Install a browser in playwright (if you haven't already).  The program will use firefox by default.

```
playwright install firefox
```

4. Go to the chatgpt-batch-whipper/

```bash
cd chatgpt_batch_whipper/
````

5. Run the main page by streamlit.
you can got to [streamlit](https://github.com/streamlit/streamlit) to check more about streamlit.

```bash
streamlit run start_whipper.py
````
6. Authenticate your openAI account
Click the **auth** button


It will open up an authentication page in the web browser you installed using playwright. Like below, authenticate with your registered account.



## Quickstart

### Use API
1. Grant auth from chatGPT.
```python
from chatgpt_batch_whipper.pub.chatgpt_wrapper import ChatGPT
bot = ChatGPT()
response = bot.auth()
print(response) 
```

2. Ask the question to chatGPT
```python
from chatgpt_batch_whipper.pub.chatgpt_wrapper import ChatGPT
bot = ChatGPT()
response = bot.ask(""Greeting!"")
print(response) 
```


### Streamlit UI

Now run it to open the app!
```
streamlit run streamlit_app.py
```

#### Single shoot mode

1. select the **Single shoot mode**.
2. Type your prompt then click submit
3. click the submit button

Here are some tips.

#### Fully Automatic mode
You can apply your prompt to multiple records in the **Fully Automatic mode**.

1. Select Fully Automatic mode.
2. Select CSV file.
3. Select column you want to process.
4. Type the prompt.
5. click to Submit.
After processing. The result will appears in the **The processed result** section.

you can check the result and check the ""is false"" then click the **Submit** to reprocess the ""failed"" one.

* You can save the prompt by click **Add** button.
* You can choose the old prompt by select **prompt list**.
* You can delete the old prompt by click **Delete Prompt**.
* You can delete the saved process result by click **Delete Cached result**.
* You can update the saved process result by click **Update**.
* You can download the result file by click **Download**."
289,learnmachinelearning,gpt-4,relevance,2023-01-04 13:49:10,ML study plan according to ChatGPT,adastro,False,0.67,1,10344lj,https://www.reddit.com/r/learnmachinelearning/comments/10344lj/ml_study_plan_according_to_chatgpt/,2,1672840150.0,"People often ask for recommendations about how to get involved with ML, so I thought it would have been interesting to ask ChatGPT directly (specifically about GPT-3 tech).

### The prompt

> Please make a detailed study plan for the math topics one needs to know in order to implement and understand GPT-3 technology. Provide them in the right order (prerequisites for one topic must come before that topic).  Add an approximate time schedule, considering the case of a person who can devote 4 hours/week to studying. Please go into the specifics and add only the best books and online course references (with their full link) for each topic.

### The answer

GPT-3 (short for ""Generative Pre-trained Transformer 3"") is a state-of-the-art language processing technology developed by OpenAI. It uses machine learning techniques to generate human-like text and has a wide range of applications, including language translation, question answering, and language generation.

To understand and implement GPT-3 technology, you will need a strong foundation in mathematics and computer science. Specifically, you will need to be proficient in the following areas:

1. **Linear algebra**: This is a fundamental mathematical discipline that deals with the study of vector spaces and linear transformations. It is a key component of machine learning and is used to represent data in a concise and efficient manner.
    
    Approximate time to complete: 4-6 weeks

    Resources:

    - Khan Academy's Linear Algebra course: https://www.khanacademy.org/math/linear-algebra
    - Gilbert Strang's Linear Algebra textbook

2. **Calculus**: This is a branch of mathematics that deals with the study of rates of change and the accumulation of quantities. It is essential for understanding the mathematical foundations of machine learning and is used to optimize machine learning models.

    Approximate time to complete: 6-8 weeks

    Resources:

    - Khan Academy's Calculus course: https://www.khanacademy.org/math/calculus-home
    - James Stewart's Calculus textbook

3. **Probability and statistics**: This is the study of random phenomena and the analysis of data. It is used to model and understand the uncertainty inherent in machine learning systems.

    Approximate time to complete: 4-6 weeks

    Resources:

    - Khan Academy's Probability and Statistics course: https://www.khanacademy.org/math/statistics-probability
    - Sheldon Ross's A First Course in Probability textbook

4. **Artificial intelligence**: This is the study of how to design intelligent computer systems that can learn, adapt, and make decisions. It is a broad field that encompasses a range of subdisciplines, including machine learning, natural language processing, and robotics.

    Approximate time to complete: 6-8 weeks

    Resources:

    - Stanford's Introduction to Artificial Intelligence course: https://online.stanford.edu/courses/cs221-artificial-intelligence-principles-and-techniques
    - Peter Norvig and Stuart Russell's Artificial Intelligence: A Modern Approach textbook

5. **Natural language processing**: This is the study of how to design computer systems that can understand and generate human language. It is a key component of GPT-3 and is used to process and generate human-like text.
    
    Approximate time to complete: 4-6 weeks

    Resources:

    - Stanford's Natural Language Processing course: https://online.stanford.edu/courses/cs224n-natural-language-processing-deep-learning    - Jurafsky and Martin's Speech and Language Processing textbook
---

(I removed links to online stores since I'm not sure whether this would break some rules here. Also, some links were broken.)
The book suggestions changed whenever I regenerated the response or made minor changes to the prompt, so I suppose that the model doesn't have a very strong opinion about what the ""best"" books are. Online courses were quite stable across answers, instead.

Please share your opinions and more resources if you like :)"
290,learnmachinelearning,gpt-4,relevance,2024-01-05 21:18:41,"good quality open source python text to speech models we can download and use locally? or free apis? Sorry, this post has been removed by the moderators of r/learn",Sharp-Cat2319,False,1.0,1,18zhwaw,https://www.reddit.com/r/learnmachinelearning/comments/18zhwaw/good_quality_open_source_python_text_to_speech/,0,1704489521.0," I need to transcribe around 200k characters into voice.

Everyone recommends [elevenlabs.io](https://elevenlabs.io/) I tested their api, it works great, but their subscription model is a rip off. 200k characters is $40. Where as in ChatGPT this took about $4 to generate.

I jokingly could probably hire someone to read that for this price or just do it myself. But that's not the point of this exercise

I want to get a local model that will do a quality text to speech with ML.

If such models arent available, or if they take up too much space, I dont mind an online one, as long as its not price gouged.

What is the best Library to use for this?"
291,learnmachinelearning,gpt-4,relevance,2023-11-25 17:19:19,How to Best Use AI as an Educational Tool – 10 Genius Tricks You Didn’t Know Existed,Science-man777,False,0.53,2,183ok48,https://www.reddit.com/r/learnmachinelearning/comments/183ok48/how_to_best_use_ai_as_an_educational_tool_10/,9,1700932759.0,""" Up until now, much of the discussion surrounding the use of generative AI in education has centered on catching AI used in cheating.  Some educators have seen generative AI as an awkward reality that makes writing assignments difficult to regulate.  With ChatGPT 4.0, students can pass off AI writing as their own original work thus circumventing the point of the assignment.  AI is seen as the ultimate slacker tool, making it irresistibly easy for lazy students to complete writing assignments at the press of a button.  

Educators Strike Back?

How are teachers supposed to respond to this?  I think there are two possible responses to this.  One is the first, very understandable response, which is to attempt to catch the “AI cheater” in the act.  This reaction makes sense at the moment since educational organizations have not yet had time to understand and respond to the technology.  To help on that front, we have created a thorough review of how educators might catch the students who decide to become AI cheaters in the article at this link.

If You Can’t Beat’em…

However, in this article, we will look at what I believe is the second possible response educators can have to this technology: rather than trying to constantly stay ahead of this ever-evolving technology in order to try and “catch the cheater,” can we rather ask if there is a way of using generative AI as an educational asset?  Could we possibly view [machine learning](https://ai-solutions.pro/what-is-machine-learning-a-beginners-guide/) and [Natural Language Processing](https://ai-solutions.pro/what-is-natural-language-processing-nlp-the-ultimate-beginners-guide/) as a natural next step in the advancement of technology, much like math teachers eventually accepted the use of calculators in math class? ""

Here is the full article:

[https://ai-solutions.pro/ai-in-education-10-genius-tricks-you-didnt-know-existed/](https://ai-solutions.pro/ai-in-education-10-genius-tricks-you-didnt-know-existed/)"
292,learnmachinelearning,gpt-4,relevance,2023-07-07 01:22:41,How to specify context for LLMs for text2text generation?,Draude94,False,1.0,2,14sscyg,https://www.reddit.com/r/learnmachinelearning/comments/14sscyg/how_to_specify_context_for_llms_for_text2text/,0,1688692961.0,"Hi!

I picked some LLMs like CerebrasGPT, RedPajamaINCITE, T5 to check if they are able to answer question like ChatGPT does.

I loaded the models from hugging face and configured them like in the hugging face examples. I took the mode without sampling, without using pipeline. I just use the model.generate() method and reduce the max length to 256 or 128.

So there is no context. The models are trained, I just give one question as a input and I expect some answers that make sense. But my problem is that I get some really weird answers. Some answers look like they are cut randomly from a book papragraph (that barely matches my question) and others completelly don't make sense.

Do I have to specify some context? Or do I have to put some kind of prompt around the question string like: ""Q: "" + question + ""A:"" ? (Just to make sure that the model knows I asked a question and that I expect a answer)

How does ChatGPT manage this?I mean, before a user inserts a question there must be some kind of prompting like:""You are a chatbot. A new user wants to ask you a question. Now please answer this question:"" + userInputQuestion.

I couldn't find any official documentation or best practices about this.

My question pool consists of different fact based questions like:  
\-What can you do?,  
\-What is the capital of Germany?,  
\-Send an email write a summarization google the weather in london. Please list the intents from the previous sentence,  
\- What is educational time?,  
\-Write some python code that adds two numbers, etc.  


My pc is low specs. Asking one question with loading the model and tokenizer + inference takes about 40 sec. to 4 min. (depending on the model)."
293,learnmachinelearning,gpt-4,relevance,2023-08-03 23:39:57,What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?,Claud1ao,False,0.6,1,15hjw2z,https://www.reddit.com/r/learnmachinelearning/comments/15hjw2z/what_would_be_the_initial_costs_of_developing_a/,2,1691105997.0,"I was wondering if this would be super expensive or not.

The cost to develop GPT-3 was about $4 millions according to some resources online. 

Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?

Any answer is appreciated.

Thanks in advance."
294,learnmachinelearning,gpt-4,relevance,2023-05-28 17:55:50,Essentials of Multi-modal/Visual-Language models (A video),AvvYaa,False,0.67,3,13u6p92,https://www.reddit.com/r/learnmachinelearning/comments/13u6p92/essentials_of_multimodalvisuallanguage_models_a/,0,1685296550.0," Hello people! I just uploaded a video on my Youtube covering all the major techniques and challenges for training multi-modal models that can combine multiple input sources like images, text, audio, etc to perform amazing cross-modal tasks like text-image retrieval, multimodal vector arithmetic, visual question answering, and language modelling. So many amazing results of the past few years have left my jaws on the floor. 

I thought it was a good time to make a video about this topic since more and more recent LLMs are moving away from text-only into visual-language domains (GPT-4, PaLM-2, etc). So in the video I cover as much as I can to provide some intuition about this area - right from basics like contrastive learning all the way to Generative language models

Here is a link to the video:  
 [https://youtu.be/-llkMpNH160](https://youtu.be/-llkMpNH160)

If the above doesn’t work, maybe try this:

[https://m.youtube.com/watch?v=-llkMpNH160&feature=youtu.be](https://m.youtube.com/watch?v=-llkMpNH160&feature=youtu.be)"
295,learnmachinelearning,gpt-4,relevance,2023-09-24 18:22:54,LangLearnCopilot – Your Companion Python Package for Language Learning,osm3000,False,1.0,6,16r4rj2,https://www.reddit.com/r/learnmachinelearning/comments/16r4rj2/langlearncopilot_your_companion_python_package/,0,1695579774.0,"Original post: [https://www.reddit.com/r/Python/comments/16r4ddp/langlearncopilot\_your\_companion\_python\_package/](https://www.reddit.com/r/Python/comments/16r4ddp/langlearncopilot_your_companion_python_package/)

Link to the Github repo: [https://github.com/osm3000/LangLearnCopilot](https://github.com/osm3000/LangLearnCopilot)

Link to streamlit dashboard (if you are eager to try): [https://llcdashboard.streamlit.app/](https://llcdashboard.streamlit.app/)

For the full story, please check my blog: [https://osm3000.wordpress.com/2023/09/24/french-journey-part...](https://osm3000.wordpress.com/2023/09/24/french-journey-part-3/)

As  part of my ongoing quest to master the  French language — a journey  filled with numerous challenges — I've  turned to Python, creating a  practical tool in the form of a package  that can assist language  learners like myself. This is just one of  several tools I've either  developed or adopted, aimed at making language  learning more accessible  and effective.

This Python  package, based on  OpenAI GPT-4, comes with two main features. Firstly,  it has the  capacity to extract unique words from any URL or text and  subsequently  convert these into flashcards, compatible with Anki—a  popular, versatile  study tool. This allows learners to reinforce  vocabulary learning at  their own pace.

Secondly,  this tool can generate example sentences  for any word or set of words,  further converting these sentences into  flashcards. This aids not just  in vocabulary acquisition but also in  understanding the contextual  usage of words, a crucial part of gaining  fluency in any language.

I would love to hear your feedback and suggestions :)"
296,learnmachinelearning,gpt-4,relevance,2023-06-05 17:01:19,Building Your Own ChatGPT based on your own dataset,rajatarya,False,0.75,2,141kz7b,https://www.reddit.com/r/learnmachinelearning/comments/141kz7b/building_your_own_chatgpt_based_on_your_own/,0,1685984479.0,"Hey everyone,

Rajat here from XetHub. I’m doing a free hands-on workshop on Tuesday, June 6th about how to build your personal ChatGPT based on your own dataset. We had 80 attendees and really positive feedback from our last workshop, and we plan to do one workshop every other week.

Here’s what you can expect to learn in the workshop:

1. How to create a Generative AI app using the DaVinci model (the same one used by ChatGPT) 
2. How a Generative AI application is structured (the tech stack)
3. Integrating your own data into a Large Language Model (LLM)
4. Getting started with XetHub (similar to GitHub but easier for ML models)
5. Create a Python app that uses Gradio & LangChain

[Sign up here](https://app.livestorm.co/xethub/mygpt-free-workshop-build-a-chatgpt-clone-tailored-to-your-data?utm_source=reddit&utm_medium=social&utm_campaign=learnmlreddit) (it’s free, and we'll share the recording with everyone who registers!)"
297,learnmachinelearning,gpt-4,relevance,2023-04-11 22:53:56,I want to teach a chatbot about a world I'm creating so that it can answer my questions about it.,Common_Ad_6362,False,0.76,9,12j0uh5,https://www.reddit.com/r/learnmachinelearning/comments/12j0uh5/i_want_to_teach_a_chatbot_about_a_world_im/,10,1681253636.0,"I've been experimenting over the last couple of days with telling ChatGPT3.5 and 4 about my world building project, but it only seems to know about our current session instead of our whole conversation.  


I have 12 GB of VRAM, is there something I can run locally that I can teach my world to and then ask it questions about that world the same way I'm able to do with ChatGPT?   I want it to remember the content I teach it beyond our session."
298,learnmachinelearning,gpt-4,relevance,2023-10-16 15:03:49,What is the best way to validate and return data through an API?,mxcdh,False,1.0,3,179830m,https://www.reddit.com/r/learnmachinelearning/comments/179830m/what_is_the_best_way_to_validate_and_return_data/,0,1697468629.0,"When I use an API, I employ ts-node and axios without any libraries. I always inform GPT in the prompt about the desired data and the expected data format for the response. For example:

```
Return 
```json
{""items"":
  [
    {
    ""1"": ""City"",
    ""2"": ""City"",
    ""3"": ""City"",
    ""4"": ""City"", 
    ...
    }
  ]
} 
```

Out of 10,000 requests, 20% of them are incorrect, and I have to repeat them. I validate the returned response using the Joi library.

Perhaps it would be better to validate the data at the prompt submission level. Is it too much that 20% of the data is not validated?"
299,learnmachinelearning,gpt-4,relevance,2023-07-16 08:58:51,Avoid clickbait content on Youtube with ChatGPT3.5/4,Particular_Account_2,False,0.83,26,1511b08,https://www.reddit.com/r/learnmachinelearning/comments/1511b08/avoid_clickbait_content_on_youtube_with_chatgpt354/,8,1689497931.0,"I built an app that I've been using for weeks now which lets you view a brief summary of any youtube video so you can avoid annoying clickbait content or just quickly get the gist of a video. 

The app that uses the web version of chatGPT3.5/4 rather than the API so that summaries can be generated for free by anyone logged in to ChatGPT. I've uploaded it to the Chrome store. Check it out here:

[https://chrome.google.com/webstore/detail/youtube-video-summaries-p/bajbfiocljodaddcdfkndlmgjbjbmjkf](https://chrome.google.com/webstore/detail/youtube-video-summaries-p/bajbfiocljodaddcdfkndlmgjbjbmjkf)

Take it for a spin, leave a review, and/or some feedback -- would love some feedback on the prompts I'm using. Thanks!"
