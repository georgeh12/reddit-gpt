,id,subreddit,query,sort,date,title,author,stickied,upvote_ratio,score,url,num_comments,created,body
0,13ilotk,ChatGPTCoding,LLM,top,2023-05-15 21:48:36,Is there a way to get ChatGPT to read a large PDF file (10k pages)?,MyLittlePIMO,False,0.9,34,https://www.reddit.com/r/ChatGPTCoding/comments/13ilotk/is_there_a_way_to_get_chatgpt_to_read_a_large_pdf/,28,1684187316.0,"Hello!  See above; I have a nearly-10k page PDF file and I'd really like to use an LLM to read it, summarize, point out patterns, or write a timeline."
1,11cn2i0,ChatGPTCoding,LLM,top,2023-02-26 17:27:44,Is there a way to increase ChatGPT's context? (or any other LLM),galabyca,False,1.0,22,https://www.reddit.com/r/ChatGPTCoding/comments/11cn2i0/is_there_a_way_to_increase_chatgpts_context_or/,12,1677432464.0,"I have been using ChatGPT for programming lately and I'm quite amzed, even if its output is far from being perfect.

I am wondering if there is a way to use API or another third-party app to leverage the power of AI language models to increase the context lenght and get a better understanding of the system/software as a whole. Are there any similar LLMs out there that can help me with this problem? Has anyone had success using an AI language model for programming an entire environment or app?

Any help or guidance would be greatly appreciated. Thank you in advance!"
2,135p6re,ChatGPTCoding,LLM,top,2023-05-02 15:18:17,Could fine-tuned Llama compete with GPT-4 for code gen?,funbike,False,0.96,22,https://www.reddit.com/r/ChatGPTCoding/comments/135p6re/could_finetuned_llama_compete_with_gpt4_for_code/,8,1683040697.0,"If I locally trained an LLM on my specific project, could I get similar code generation quality as GPT-4?

I could train llama additionally with stackoverflow, our 600KLOC source code, our 50K+ git commit history, our 10K+ PR + JIRA history, our documentation, and similar training from our dependencies.

I've played with HuggingChat based on llama. It's good but not as good as GOT 3.5 or 4.  I am hopeful additional highly specific training would bridge the gap.

I ask because I don't want to waste time researching if it's not practical.

What do you think?"
3,138c42s,ChatGPTCoding,LLM,top,2023-05-05 05:44:09,Flowise - Drag and Drop UI to create your own customized llm flow using Langchain Jo’s,queerkidxx,False,0.95,20,https://www.reddit.com/r/ChatGPTCoding/comments/138c42s/flowise_drag_and_drop_ui_to_create_your_own/,10,1683265449.0,"This isn’t my project but I think it’s really cool and figure y’all would appreciate it.

https://github.com/FlowiseAI/Flowise

This literally made my day when I saw it. Crazy powerful. 

Side note, anyone know of some neat projects that haven’t received a lot of attention on GitHub? Ever since I got api access dicking around on there has completely replaced what I used to do in my free timel. Haven’t even opened a video game in nearly a month who even am I

Edit: langchain js not jo lmao"
4,12myn8v,ChatGPTCoding,LLM,top,2023-04-15 11:04:33,Are there solutions for analysing a codebase and asking questions?,These_Thought_959,False,0.87,15,https://www.reddit.com/r/ChatGPTCoding/comments/12myn8v/are_there_solutions_for_analysing_a_codebase_and/,8,1681556673.0,"I want to use these new LLM models to help me understand new codebases. I'm aware of CodeGPT and Copilot but it seems, unless I'm missing something, that you can only highlight a part of your code and ask it to explain it.

I would like to be able to instead give it the entire codebase, and then ask general questions. 

For example say you give it the OpenCV library, you ask it where are the functions to write/create new images and give you a high-level idea of how they work.

Is that possible yet?"
5,13iidw7,ChatGPTCoding,LLM,top,2023-05-15 19:50:12,How do ChatGPT plugins work under the covers?,adamaid_321,False,0.87,11,https://www.reddit.com/r/ChatGPTCoding/comments/13iidw7/how_do_chatgpt_plugins_work_under_the_covers/,9,1684180212.0,"My understanding from the docs is that you provide a manifest file which describes your API using OpenAPI. Within that, using natural language, you describe each of your endpoints etc..

Presumably the data you provide needs to be passed to the LLM as query context, which is capped at 8/32k - I'd expect lots of verbose OpenAPI specifications to be over that limit.

Is there some other trickery happening (e.g. embeddings - although this doesn't seem ideal when interacting with an API and presumably the LLM needs some idea about all the endpoints in order to know when to invoke them)?

I can't see any reference to size limitations in the OpenAI plugin docs."
6,13h26b4,ChatGPTCoding,LLM,top,2023-05-14 04:12:36,Summarizing newsletters,tvmaly,False,1.0,3,https://www.reddit.com/r/ChatGPTCoding/comments/13h26b4/summarizing_newsletters/,6,1684037556.0,"I am subscribed to quite a few interesting newsletters.

But I rarely have time to read them. Has anyone coded anything to extract text from email newsletters and summarize them with a LLM?"
7,13ilotk,ChatGPTCoding,LLM,comments,2023-05-15 21:48:36,Is there a way to get ChatGPT to read a large PDF file (10k pages)?,MyLittlePIMO,False,0.88,32,https://www.reddit.com/r/ChatGPTCoding/comments/13ilotk/is_there_a_way_to_get_chatgpt_to_read_a_large_pdf/,28,1684187316.0,"Hello!  See above; I have a nearly-10k page PDF file and I'd really like to use an LLM to read it, summarize, point out patterns, or write a timeline."
8,11cn2i0,ChatGPTCoding,LLM,comments,2023-02-26 17:27:44,Is there a way to increase ChatGPT's context? (or any other LLM),galabyca,False,1.0,22,https://www.reddit.com/r/ChatGPTCoding/comments/11cn2i0/is_there_a_way_to_increase_chatgpts_context_or/,12,1677432464.0,"I have been using ChatGPT for programming lately and I'm quite amzed, even if its output is far from being perfect.

I am wondering if there is a way to use API or another third-party app to leverage the power of AI language models to increase the context lenght and get a better understanding of the system/software as a whole. Are there any similar LLMs out there that can help me with this problem? Has anyone had success using an AI language model for programming an entire environment or app?

Any help or guidance would be greatly appreciated. Thank you in advance!"
9,138c42s,ChatGPTCoding,LLM,comments,2023-05-05 05:44:09,Flowise - Drag and Drop UI to create your own customized llm flow using Langchain Jo’s,queerkidxx,False,0.92,19,https://www.reddit.com/r/ChatGPTCoding/comments/138c42s/flowise_drag_and_drop_ui_to_create_your_own/,10,1683265449.0,"This isn’t my project but I think it’s really cool and figure y’all would appreciate it.

https://github.com/FlowiseAI/Flowise

This literally made my day when I saw it. Crazy powerful. 

Side note, anyone know of some neat projects that haven’t received a lot of attention on GitHub? Ever since I got api access dicking around on there has completely replaced what I used to do in my free timel. Haven’t even opened a video game in nearly a month who even am I

Edit: langchain js not jo lmao"
10,135p6re,ChatGPTCoding,LLM,comments,2023-05-02 15:18:17,Could fine-tuned Llama compete with GPT-4 for code gen?,funbike,False,0.96,23,https://www.reddit.com/r/ChatGPTCoding/comments/135p6re/could_finetuned_llama_compete_with_gpt4_for_code/,8,1683040697.0,"If I locally trained an LLM on my specific project, could I get similar code generation quality as GPT-4?

I could train llama additionally with stackoverflow, our 600KLOC source code, our 50K+ git commit history, our 10K+ PR + JIRA history, our documentation, and similar training from our dependencies.

I've played with HuggingChat based on llama. It's good but not as good as GOT 3.5 or 4.  I am hopeful additional highly specific training would bridge the gap.

I ask because I don't want to waste time researching if it's not practical.

What do you think?"
11,13iidw7,ChatGPTCoding,LLM,comments,2023-05-15 19:50:12,How do ChatGPT plugins work under the covers?,adamaid_321,False,0.99,13,https://www.reddit.com/r/ChatGPTCoding/comments/13iidw7/how_do_chatgpt_plugins_work_under_the_covers/,9,1684180212.0,"My understanding from the docs is that you provide a manifest file which describes your API using OpenAPI. Within that, using natural language, you describe each of your endpoints etc..

Presumably the data you provide needs to be passed to the LLM as query context, which is capped at 8/32k - I'd expect lots of verbose OpenAPI specifications to be over that limit.

Is there some other trickery happening (e.g. embeddings - although this doesn't seem ideal when interacting with an API and presumably the LLM needs some idea about all the endpoints in order to know when to invoke them)?

I can't see any reference to size limitations in the OpenAI plugin docs."
12,12myn8v,ChatGPTCoding,LLM,comments,2023-04-15 11:04:33,Are there solutions for analysing a codebase and asking questions?,These_Thought_959,False,0.85,13,https://www.reddit.com/r/ChatGPTCoding/comments/12myn8v/are_there_solutions_for_analysing_a_codebase_and/,8,1681556673.0,"I want to use these new LLM models to help me understand new codebases. I'm aware of CodeGPT and Copilot but it seems, unless I'm missing something, that you can only highlight a part of your code and ask it to explain it.

I would like to be able to instead give it the entire codebase, and then ask general questions. 

For example say you give it the OpenCV library, you ask it where are the functions to write/create new images and give you a high-level idea of how they work.

Is that possible yet?"
13,136xe8r,ChatGPTCoding,LLM,comments,2023-05-03 19:46:40,Langchain Slack workspace importer question,mikewagnercmp,False,1.0,2,https://www.reddit.com/r/ChatGPTCoding/comments/136xe8r/langchain_slack_workspace_importer_question/,7,1683143200.0,"Hello, I have a question , I am using langchain to import an export of my slack workspace as we have a lot of ""documentation"" in slack, and was investigating if extracting that data, and creating my own local storage to query it with LLM would be worthwhile.  I have an extract for about a months worth of the public workspaces, was able to parse the file with the slack document loader, and generate embeddings on it. However, when I attempt to query the now persisted DB, for the most part I am unable to get meaningful responses. 

I was able to pull down our internal wiki and go through a similar process and get good results, but the Slack data seems to not work properly.   I'm wondering, if in this case, i need to change my chunk sizes or overlaps, or use some other embedding or text splitter? If i ask a very very specific question ,it can sometimes answer against the slack, but for more useful things, like ""summarizing up the last release"" or things like that it just says ""I do not know"" With the wiki extract (mostly text) it can do what I expect a AI to do.

&#x200B;

    persist_directory = 'slackdb'
    SLACK_WORKSPACE_URL = ""https://xxx.slack.com""
LOCAL_ZIPFILE = ""export Apr 2 2023 - May 1 2023.zip"" # Paste the local paty to your Slack zip file here.

loader = SlackDirectoryLoader(LOCAL_ZIPFILE, SLACK_WORKSPACE_URL)
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

embeddings = OpenAIEmbeddings()

# Create a new Chroma object by processing the text file
vectordb = Chroma.from_documents(docs, embeddings, persist_directory=persist_directory)
vectordb.persist()"
14,13h26b4,ChatGPTCoding,LLM,comments,2023-05-14 04:12:36,Summarizing newsletters,tvmaly,False,1.0,3,https://www.reddit.com/r/ChatGPTCoding/comments/13h26b4/summarizing_newsletters/,6,1684037556.0,"I am subscribed to quite a few interesting newsletters.

But I rarely have time to read them. Has anyone coded anything to extract text from email newsletters and summarize them with a LLM?"
15,13icfib,ChatGPTCoding,LLM,comments,2023-05-15 16:09:43,API Use,BenWilbert,False,1.0,3,https://www.reddit.com/r/ChatGPTCoding/comments/13icfib/api_use/,6,1684166983.0,"I’m looking to create a program that accesses an LLM, but I need one that has access to current information. I also need access to the API. It’s unclear to me if I can pay for access to the GPT-4 api, or Google bards api? Or please let me know other recommendations."
16,13e1yq3,ChatGPTCoding,LLM,relevance,2023-05-10 20:18:21,New 150k token LLM - short introduction,grumpyp2,False,0.4,0,https://www.reddit.com/r/ChatGPTCoding/comments/13e1yq3/new_150k_token_llm_short_introduction/,0,1683749901.0,"I made a little introduction about the new 150k token LLM which is available in the playground!  


What do you guys think of it? 150k tokens sounds crazy for me!

[https://youtu.be/DUONZCwvf3c](https://youtu.be/DUONZCwvf3c)"
17,11cn2i0,ChatGPTCoding,LLM,relevance,2023-02-26 17:27:44,Is there a way to increase ChatGPT's context? (or any other LLM),galabyca,False,1.0,23,https://www.reddit.com/r/ChatGPTCoding/comments/11cn2i0/is_there_a_way_to_increase_chatgpts_context_or/,12,1677432464.0,"I have been using ChatGPT for programming lately and I'm quite amzed, even if its output is far from being perfect.

I am wondering if there is a way to use API or another third-party app to leverage the power of AI language models to increase the context lenght and get a better understanding of the system/software as a whole. Are there any similar LLMs out there that can help me with this problem? Has anyone had success using an AI language model for programming an entire environment or app?

Any help or guidance would be greatly appreciated. Thank you in advance!"
18,138c42s,ChatGPTCoding,LLM,relevance,2023-05-05 05:44:09,Flowise - Drag and Drop UI to create your own customized llm flow using Langchain Jo’s,queerkidxx,False,0.96,21,https://www.reddit.com/r/ChatGPTCoding/comments/138c42s/flowise_drag_and_drop_ui_to_create_your_own/,10,1683265449.0,"This isn’t my project but I think it’s really cool and figure y’all would appreciate it.

https://github.com/FlowiseAI/Flowise

This literally made my day when I saw it. Crazy powerful. 

Side note, anyone know of some neat projects that haven’t received a lot of attention on GitHub? Ever since I got api access dicking around on there has completely replaced what I used to do in my free timel. Haven’t even opened a video game in nearly a month who even am I

Edit: langchain js not jo lmao"
19,13cslsl,ChatGPTCoding,LLM,relevance,2023-05-09 14:41:48,PromptFlow - Open-Source Desktop app for quickly building and iterating on LLM workflows,sawyermclane,False,1.0,1,/r/ChatGPTPro/comments/139km2i/promptflow_opensource_desktop_app_for_quickly/,0,1683643308.0,
20,13ifb97,ChatGPTCoding,LLM,relevance,2023-05-15 17:59:45,"Last Week in AI - The Week of Google, AI ""Her"", ""Large"" LLM and GPT Plugins",level6-killjoy,False,0.81,3,/r/GPT_4/comments/13if9en/last_week_in_ai_the_week_of_google_ai_her_large/,0,1684173585.0,
21,13ilotk,ChatGPTCoding,LLM,relevance,2023-05-15 21:48:36,Is there a way to get ChatGPT to read a large PDF file (10k pages)?,MyLittlePIMO,False,0.86,30,https://www.reddit.com/r/ChatGPTCoding/comments/13ilotk/is_there_a_way_to_get_chatgpt_to_read_a_large_pdf/,28,1684187316.0,"Hello!  See above; I have a nearly-10k page PDF file and I'd really like to use an LLM to read it, summarize, point out patterns, or write a timeline."
22,13iidw7,ChatGPTCoding,LLM,relevance,2023-05-15 19:50:12,How do ChatGPT plugins work under the covers?,adamaid_321,False,0.87,11,https://www.reddit.com/r/ChatGPTCoding/comments/13iidw7/how_do_chatgpt_plugins_work_under_the_covers/,9,1684180212.0,"My understanding from the docs is that you provide a manifest file which describes your API using OpenAPI. Within that, using natural language, you describe each of your endpoints etc..

Presumably the data you provide needs to be passed to the LLM as query context, which is capped at 8/32k - I'd expect lots of verbose OpenAPI specifications to be over that limit.

Is there some other trickery happening (e.g. embeddings - although this doesn't seem ideal when interacting with an API and presumably the LLM needs some idea about all the endpoints in order to know when to invoke them)?

I can't see any reference to size limitations in the OpenAI plugin docs."
23,13h26b4,ChatGPTCoding,LLM,relevance,2023-05-14 04:12:36,Summarizing newsletters,tvmaly,False,1.0,3,https://www.reddit.com/r/ChatGPTCoding/comments/13h26b4/summarizing_newsletters/,6,1684037556.0,"I am subscribed to quite a few interesting newsletters.

But I rarely have time to read them. Has anyone coded anything to extract text from email newsletters and summarize them with a LLM?"
