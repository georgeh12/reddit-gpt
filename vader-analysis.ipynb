{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the scraped data with pandas and mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# MLflow model\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# math functions\n",
    "import numpy as np\n",
    "\n",
    "# read CSV file\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# data frames\n",
    "import pandas as pd\n",
    "\n",
    "# regexes\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\georg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\georg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\georg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://medium.com/bitgrit-data-science-publication/sentiment-analysis-on-reddit-tech-news-with-python-cbaddb8e9bb6\n",
    "\n",
    "# Load Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# misc\n",
    "import datetime as dt\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "\n",
    "# reddit crawler\n",
    "import praw\n",
    "\n",
    "# sentiment analysis\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer # tokenize words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8) # default plot size\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', palette='Dark2')\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Downloading NLTK's databases\n",
    "nltk.download('vader_lexicon') # get lexicons data\n",
    "nltk.download('punkt') # for tokenizer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "topics_dict = { \"date\":[],\n",
    "                \"author\":[],\n",
    "                \"title\":[],\n",
    "                \"ups\":[],\n",
    "                \"downs\":[],\n",
    "                \"score\":[],\n",
    "                \"id\":[],\n",
    "                \"url\":[],\n",
    "                \"comms_num\": [],\n",
    "                \"created\": [],\n",
    "                \"body\":[]}\n",
    "# Use the Reddit dataset\n",
    "\"\"\"\n",
    "['date','author','title','ups','downs','score','id','url','comms_num','created','body']\n",
    "\"\"\"\n",
    "df = pd.DataFrame()\n",
    "running_total = 0\n",
    "for fname in glob.glob(os.path.abspath('./data/**/*.csv')):\n",
    "    _df=pd.read_csv(fname)\n",
    "    _df['query'] = os.path.splitext(os.path.basename(fname))[0]\n",
    "    _df['subreddit'] = os.path.basename(os.path.dirname(fname))\n",
    "    df = df.append(_df.copy(), ignore_index=True)\n",
    "    running_total+=len(_df)\n",
    "    print(fname)\n",
    "    print(running_total)\n",
    "    #break #DEBUG\n",
    "\n",
    "# setup the created datetime\n",
    "df['created'] = pd.to_datetime(df['created'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "\n",
    "#Create a function to clean the tweets\n",
    "def cleanTxt(text):\n",
    "    text = re.sub(r'@[A-Za-z0–9]+', '', text) #Remove @mentions replace with blank\n",
    "    text = re.sub(r'#', '', text) #Remove the ‘#’ symbol, replace with blank\n",
    "    text = re.sub(r'RT[\\s]+', '', text) #Removing RT, replace with blank\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text) #Remove the hyperlinks\n",
    "    text = re.sub(r':', '', text) # Remove :\n",
    "    return text\n",
    "\n",
    "#Next we have to remove emoji & Unicode from the Tweet data.\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\" # flags (iOS)\n",
    "    u\"\\U00002500-\\U00002BEF\" # chinese char\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    "    u\"\\U0001f926-\\U0001f937\"\n",
    "    u\"\\U00010000-\\U0010ffff\"\n",
    "    u\"\\u2640-\\u2642\"\n",
    "    u\"\\u2600-\\u2B55\"\n",
    "    u\"\\u200d\"\n",
    "    u\"\\u23cf\"\n",
    "    u\"\\u23e9\"\n",
    "    u\"\\u231a\"\n",
    "    u\"\\ufe0f\" # dingbats\n",
    "    u\"\\u3030\"\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows without a comment body\n",
    "df.dropna(subset='body', how=\"any\", inplace=True)\n",
    "\n",
    "df['clean'] = df['body'].apply(lambda x: remove_emoji(cleanTxt(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER sentiment analysis\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "df[['pos', 'neg', 'neu', 'compound']] = df['clean'].apply(lambda text: pd.Series(sid.polarity_scores(text)))\n",
    "\n",
    "# Threshold conditions determine the value of the sentiment of the text\n",
    "THRESHOLD = 0.2\n",
    "conditions = [\n",
    "    (df['compound'] <= -THRESHOLD),\n",
    "    (df['compound'] > -THRESHOLD) & (df['compound'] < THRESHOLD),\n",
    "    (df['compound'] >= THRESHOLD),\n",
    "    ]\n",
    "values = [\"neg\", \"neu\", \"pos\"]\n",
    "df['label'] = np.select(conditions, values)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Convert all sentiment columns to numeric type\n",
    "df[['pos', 'neg', 'neu', 'compound']] = df[['pos', 'neg', 'neu', 'compound']].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering dataset from November 2022 to January 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>query</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>clean</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>compound</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>2022-12-17 13:18:18</td>\n",
       "      <td>yfzi</td>\n",
       "      <td>ChatGPT AI just solved an unsolved math proble...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zo64dm</td>\n",
       "      <td>https://www.reddit.com/r/artificial/comments/z...</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-17 13:18:18</td>\n",
       "      <td>I first asked the chatbot (**ChatGPT** by Open...</td>\n",
       "      <td>gpt-3.0</td>\n",
       "      <td>artificial</td>\n",
       "      <td>I first asked the chatbot (**ChatGPT** by Open...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>2022-12-17 13:18:18</td>\n",
       "      <td>yfzi</td>\n",
       "      <td>ChatGPT AI just solved an unsolved math proble...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zo64dm</td>\n",
       "      <td>https://www.reddit.com/r/artificial/comments/z...</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-17 13:18:18</td>\n",
       "      <td>I first asked the chatbot (**ChatGPT** by Open...</td>\n",
       "      <td>gpt-3.0</td>\n",
       "      <td>artificial</td>\n",
       "      <td>I first asked the chatbot (**ChatGPT** by Open...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>40</td>\n",
       "      <td>2022-12-17 13:18:18</td>\n",
       "      <td>yfzi</td>\n",
       "      <td>ChatGPT AI just solved an unsolved math proble...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zo64dm</td>\n",
       "      <td>https://www.reddit.com/r/artificial/comments/z...</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-17 13:18:18</td>\n",
       "      <td>I first asked the chatbot (**ChatGPT** by Open...</td>\n",
       "      <td>gpt-4.0</td>\n",
       "      <td>artificial</td>\n",
       "      <td>I first asked the chatbot (**ChatGPT** by Open...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>40</td>\n",
       "      <td>2022-12-17 13:18:18</td>\n",
       "      <td>yfzi</td>\n",
       "      <td>ChatGPT AI just solved an unsolved math proble...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zo64dm</td>\n",
       "      <td>https://www.reddit.com/r/artificial/comments/z...</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-17 13:18:18</td>\n",
       "      <td>I first asked the chatbot (**ChatGPT** by Open...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>artificial</td>\n",
       "      <td>I first asked the chatbot (**ChatGPT** by Open...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>86</td>\n",
       "      <td>2022-12-17 13:18:18</td>\n",
       "      <td>yfzi</td>\n",
       "      <td>ChatGPT AI just solved an unsolved math proble...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zo64dm</td>\n",
       "      <td>https://www.reddit.com/r/artificial/comments/z...</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-12-17 13:18:18</td>\n",
       "      <td>I first asked the chatbot (**ChatGPT** by Open...</td>\n",
       "      <td>gpt</td>\n",
       "      <td>artificial</td>\n",
       "      <td>I first asked the chatbot (**ChatGPT** by Open...</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54743</th>\n",
       "      <td>775</td>\n",
       "      <td>2022-12-20 22:54:48</td>\n",
       "      <td>Singularian2501</td>\n",
       "      <td>[R] Nonparametric Masked Language Modeling - M...</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>zr2en7</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>31</td>\n",
       "      <td>2022-12-20 22:54:48</td>\n",
       "      <td>Paper: [https://arxiv.org/abs/2212.01349](http...</td>\n",
       "      <td>openai</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>Paper [\\n\\nGithub [\\n\\nAbstract\\n\\n&gt;Existing l...</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54769</th>\n",
       "      <td>801</td>\n",
       "      <td>2023-01-20 10:41:04</td>\n",
       "      <td>ChubChubkitty</td>\n",
       "      <td>[N] OpenAI Used Kenyan Workers on Less Than $2...</td>\n",
       "      <td>524</td>\n",
       "      <td>0</td>\n",
       "      <td>524</td>\n",
       "      <td>10gtruu</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>246</td>\n",
       "      <td>2023-01-20 10:41:04</td>\n",
       "      <td>https://time.com/6247678/openai-chatgpt-kenya-...</td>\n",
       "      <td>openai</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54777</th>\n",
       "      <td>809</td>\n",
       "      <td>2022-11-03 23:12:45</td>\n",
       "      <td>TiredOldCrow</td>\n",
       "      <td>[D] DALL·E to be made available as API, OpenAI...</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "      <td>419</td>\n",
       "      <td>yli0r7</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>55</td>\n",
       "      <td>2022-11-03 23:12:45</td>\n",
       "      <td>Email announcement from OpenAI below:\\n\\n\\n&gt; D...</td>\n",
       "      <td>openai</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>Email announcement from OpenAI below\\n\\n\\n&gt; DA...</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54793</th>\n",
       "      <td>825</td>\n",
       "      <td>2022-12-22 18:39:30</td>\n",
       "      <td>_underlines_</td>\n",
       "      <td>[D] When chatGPT stops being free: Run SOTA LL...</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>349</td>\n",
       "      <td>zstequ</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>95</td>\n",
       "      <td>2022-12-22 18:39:30</td>\n",
       "      <td>Edit: Found [LAION-AI/OPEN-ASSISTANT](https://...</td>\n",
       "      <td>openai</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>Edit Found [LAION-AI/OPEN-ASSISTANT]( a very p...</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.9386</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54836</th>\n",
       "      <td>868</td>\n",
       "      <td>2022-12-04 09:57:44</td>\n",
       "      <td>Far_Pineapple770</td>\n",
       "      <td>[D] OpenAI’s ChatGPT is unbelievable good in t...</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>zc5sg6</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>85</td>\n",
       "      <td>2022-12-04 09:57:44</td>\n",
       "      <td>\\nI started playing with ChatGPT, the new chat...</td>\n",
       "      <td>openai</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>\\nI started playing with ChatGPT, the new chat...</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.9397</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2182 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                 date            author  \\\n",
       "40             40  2022-12-17 13:18:18              yfzi   \n",
       "86             86  2022-12-17 13:18:18              yfzi   \n",
       "131            40  2022-12-17 13:18:18              yfzi   \n",
       "175            40  2022-12-17 13:18:18              yfzi   \n",
       "221            86  2022-12-17 13:18:18              yfzi   \n",
       "...           ...                  ...               ...   \n",
       "54743         775  2022-12-20 22:54:48   Singularian2501   \n",
       "54769         801  2023-01-20 10:41:04     ChubChubkitty   \n",
       "54777         809  2022-11-03 23:12:45      TiredOldCrow   \n",
       "54793         825  2022-12-22 18:39:30      _underlines_   \n",
       "54836         868  2022-12-04 09:57:44  Far_Pineapple770   \n",
       "\n",
       "                                                   title  ups  downs  score  \\\n",
       "40     ChatGPT AI just solved an unsolved math proble...    0      0      0   \n",
       "86     ChatGPT AI just solved an unsolved math proble...    0      0      0   \n",
       "131    ChatGPT AI just solved an unsolved math proble...    0      0      0   \n",
       "175    ChatGPT AI just solved an unsolved math proble...    0      0      0   \n",
       "221    ChatGPT AI just solved an unsolved math proble...    0      0      0   \n",
       "...                                                  ...  ...    ...    ...   \n",
       "54743  [R] Nonparametric Masked Language Modeling - M...  271      0    271   \n",
       "54769  [N] OpenAI Used Kenyan Workers on Less Than $2...  524      0    524   \n",
       "54777  [D] DALL·E to be made available as API, OpenAI...  419      0    419   \n",
       "54793  [D] When chatGPT stops being free: Run SOTA LL...  349      0    349   \n",
       "54836  [D] OpenAI’s ChatGPT is unbelievable good in t...  242      0    242   \n",
       "\n",
       "            id                                                url  comms_num  \\\n",
       "40      zo64dm  https://www.reddit.com/r/artificial/comments/z...          7   \n",
       "86      zo64dm  https://www.reddit.com/r/artificial/comments/z...          7   \n",
       "131     zo64dm  https://www.reddit.com/r/artificial/comments/z...          7   \n",
       "175     zo64dm  https://www.reddit.com/r/artificial/comments/z...          7   \n",
       "221     zo64dm  https://www.reddit.com/r/artificial/comments/z...          7   \n",
       "...        ...                                                ...        ...   \n",
       "54743   zr2en7  https://www.reddit.com/r/MachineLearning/comme...         31   \n",
       "54769  10gtruu  https://www.reddit.com/r/MachineLearning/comme...        246   \n",
       "54777   yli0r7  https://www.reddit.com/r/MachineLearning/comme...         55   \n",
       "54793   zstequ  https://www.reddit.com/r/MachineLearning/comme...         95   \n",
       "54836   zc5sg6  https://www.reddit.com/r/MachineLearning/comme...         85   \n",
       "\n",
       "                  created                                               body  \\\n",
       "40    2022-12-17 13:18:18  I first asked the chatbot (**ChatGPT** by Open...   \n",
       "86    2022-12-17 13:18:18  I first asked the chatbot (**ChatGPT** by Open...   \n",
       "131   2022-12-17 13:18:18  I first asked the chatbot (**ChatGPT** by Open...   \n",
       "175   2022-12-17 13:18:18  I first asked the chatbot (**ChatGPT** by Open...   \n",
       "221   2022-12-17 13:18:18  I first asked the chatbot (**ChatGPT** by Open...   \n",
       "...                   ...                                                ...   \n",
       "54743 2022-12-20 22:54:48  Paper: [https://arxiv.org/abs/2212.01349](http...   \n",
       "54769 2023-01-20 10:41:04  https://time.com/6247678/openai-chatgpt-kenya-...   \n",
       "54777 2022-11-03 23:12:45  Email announcement from OpenAI below:\\n\\n\\n> D...   \n",
       "54793 2022-12-22 18:39:30  Edit: Found [LAION-AI/OPEN-ASSISTANT](https://...   \n",
       "54836 2022-12-04 09:57:44  \\nI started playing with ChatGPT, the new chat...   \n",
       "\n",
       "         query        subreddit  \\\n",
       "40     gpt-3.0       artificial   \n",
       "86     gpt-3.0       artificial   \n",
       "131    gpt-4.0       artificial   \n",
       "175        gpt       artificial   \n",
       "221        gpt       artificial   \n",
       "...        ...              ...   \n",
       "54743   openai  machinelearning   \n",
       "54769   openai  machinelearning   \n",
       "54777   openai  machinelearning   \n",
       "54793   openai  machinelearning   \n",
       "54836   openai  machinelearning   \n",
       "\n",
       "                                                   clean    pos    neg    neu  \\\n",
       "40     I first asked the chatbot (**ChatGPT** by Open...  0.020  0.825  0.156   \n",
       "86     I first asked the chatbot (**ChatGPT** by Open...  0.020  0.825  0.156   \n",
       "131    I first asked the chatbot (**ChatGPT** by Open...  0.020  0.825  0.156   \n",
       "175    I first asked the chatbot (**ChatGPT** by Open...  0.020  0.825  0.156   \n",
       "221    I first asked the chatbot (**ChatGPT** by Open...  0.020  0.825  0.156   \n",
       "...                                                  ...    ...    ...    ...   \n",
       "54743  Paper [\\n\\nGithub [\\n\\nAbstract\\n\\n>Existing l...  0.022  0.954  0.024   \n",
       "54769                                                     0.000  0.000  0.000   \n",
       "54777  Email announcement from OpenAI below\\n\\n\\n> DA...  0.016  0.799  0.186   \n",
       "54793  Edit Found [LAION-AI/OPEN-ASSISTANT]( a very p...  0.074  0.822  0.104   \n",
       "54836  \\nI started playing with ChatGPT, the new chat...  0.104  0.751  0.146   \n",
       "\n",
       "       compound label  \n",
       "40       0.9981   pos  \n",
       "86       0.9981   pos  \n",
       "131      0.9981   pos  \n",
       "175      0.9981   pos  \n",
       "221      0.9981   pos  \n",
       "...         ...   ...  \n",
       "54743    0.0516   neu  \n",
       "54769    0.0000   neu  \n",
       "54777    0.9852   pos  \n",
       "54793    0.9386   pos  \n",
       "54836    0.9397   pos  \n",
       "\n",
       "[2182 rows x 20 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting created dates from reddit API into human readable format\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the date range\n",
    "start_date = datetime(2022, 11, 1)\n",
    "end_date = datetime(2023, 1, 31)\n",
    "\n",
    "df[(df['created'] >= start_date) & (df['created'] <= end_date)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
