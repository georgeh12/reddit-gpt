{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit API data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit forums: r/artificial, r/machinelearning, r/bigscience\n",
    "Use APIs to collect data mentioning GPT-3 and other AI technologies from November 1 2022 to January 31 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/bitgrit-data-science-publication/sentiment-analysis-on-reddit-tech-news-with-python-cbaddb8e9bb6\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# misc\n",
    "import datetime as dt\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "import json\n",
    "\n",
    "# reddit crawler\n",
    "import praw\n",
    "\n",
    "# converting created dates from reddit API into human readable format\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# make directories for data collection\n",
    "import os\n",
    "\n",
    "# copy data structure\n",
    "import copy\n",
    "\n",
    "# regular expression search PRAW results\n",
    "import re\n",
    "\n",
    "# wait time for api limits and api retry\n",
    "import time\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit user: Zealousideal-Land259\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON credentials file\n",
    "with open('reddit.json') as f:\n",
    "    reddit_users = json.load(f)\n",
    "\n",
    "credentials = reddit_users['Zealousideal-Land259']\n",
    "#credentials = reddit_users['reddit_user4']\n",
    "\n",
    "# Instantiate praw.Reddit object\n",
    "reddit = praw.Reddit(\n",
    "    client_id=credentials['client_id'],\n",
    "    client_secret=credentials['client_secret'],\n",
    "    user_agent=credentials['user_agent'],\n",
    "    redirect_uri=credentials['redirect_uri'],\n",
    "    refresh_token=credentials['refresh_token']\n",
    ")\n",
    "\n",
    "reddit_user = str(reddit.user.me())\n",
    "# test connection\n",
    "print(f\"Reddit user: {reddit_user}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 005\n"
     ]
    }
   ],
   "source": [
    "# Check if config file exists\n",
    "config_file = 'config.json'\n",
    "if not os.path.exists(config_file):\n",
    "    # Create config file with default content\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump({\"run\": 0}, f)\n",
    "\n",
    "# Load run information and increment run\n",
    "with open(config_file) as f:\n",
    "    config = json.load(f)\n",
    "    config['run'] = config['run'] + 1\n",
    "\n",
    "# Write new run to config file\n",
    "with open(config_file, 'w') as f:\n",
    "    json.dump({\"run\": config['run']}, f)\n",
    "\n",
    "# test connection\n",
    "run_name = '{:03d}'.format(config['run'])\n",
    "print(f\"Run name: {run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape top posts from reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After successful result \n",
    "# Retry every 10 seconds 12 times for a total of 2 minutes\n",
    "def retry_function(func, *args, max_attempts=12, delay=10, **kwargs):\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            start_time = time.time() # record start time of api call\n",
    "            result = func(*args, **kwargs)  # Call the function\n",
    "            end_time = time.time() # record start time of api call\n",
    "            # Reddit API restricts to 100 queries per minute\n",
    "            reddit_api_restriction = 100/60\n",
    "            # wait for the difference between the api restriction and the total api call time\n",
    "            api_wait_time = reddit_api_restriction - (end_time-start_time)\n",
    "            if api_wait_time > 0: time.sleep(api_wait_time)\n",
    "            return result  # Return the result if successful\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            attempts += 1\n",
    "            if attempts < max_attempts:\n",
    "                print(f\"Retrying attempt #{attempts} in {delay} seconds...\")\n",
    "                for _ in range(delay): time.sleep(1)\n",
    "    print(\"Max attempts reached. Continuing loop.\")\n",
    "    return None  # Or you can raise an exception here if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API structure\n",
    "topics_dict_template = {\"id\":[],\n",
    "                        \"subreddit\":[],\n",
    "                        \"query\":[],\n",
    "                        \"sort\":[],\n",
    "                        \"date\":[],\n",
    "                        \"title\":[],\n",
    "                        \"author\":[],\n",
    "                        \"stickied\":[],\n",
    "                        \"upvote_ratio\":[],\n",
    "                        \"score\":[],\n",
    "                        \"url\":[],\n",
    "                        \"num_comments\": [],\n",
    "                        \"created\": [],\n",
    "                        \"body\":[]}\n",
    "\n",
    "def scrape_submission(topics_dict, submission, other):\n",
    "    #November 1 2022 to January 31 2023\n",
    "    # Define the date range for GPT-3 hype analysis\n",
    "    gpt3_start = datetime(2022, 11, 1)\n",
    "    gpt3_end = datetime(2023, 1, 31)\n",
    "\n",
    "    #February 15 to May 15 that includes the launch GPT-4 on March 14, 2023\n",
    "    # Define the date range for GPT-4 hype analysis\n",
    "    gpt4_start = datetime(2023, 2, 15)\n",
    "    gpt4_end = datetime(2023, 5, 15)\n",
    "\n",
    "    # Scrape only dates within the timeframes\n",
    "    date = datetime.utcfromtimestamp(submission.created)\n",
    "    if (gpt3_start <= date < gpt3_end + timedelta(days=1)) | (gpt4_start <= date < gpt4_end + timedelta(days=1)):\n",
    "        # build the dictionary\n",
    "        topics_dict[\"date\"].append(date)\n",
    "        topics_dict[\"title\"].append(submission.title)\n",
    "        topics_dict[\"author\"].append(submission.author)\n",
    "        topics_dict[\"stickied\"].append(submission.stickied)\n",
    "        topics_dict[\"upvote_ratio\"].append(submission.upvote_ratio)\n",
    "        topics_dict[\"score\"].append(submission.score)\n",
    "        topics_dict[\"id\"].append(submission.id)\n",
    "        topics_dict[\"url\"].append(submission.url)\n",
    "        topics_dict[\"num_comments\"].append(submission.num_comments)\n",
    "        topics_dict[\"created\"].append(submission.created)\n",
    "        topics_dict[\"body\"].append(submission.selftext)\n",
    "        # add subreddit, query, sort\n",
    "        for entry in other:\n",
    "            topics_dict[entry].append(other[entry])\n",
    "    return topics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subreddits to search\n",
    "subreddits = sorted(['artificial', 'datascience', 'datasets', 'deeplearning', 'LanguageTechnology', 'MachineLearning', 'learnmachinelearning',\n",
    "                     'chatgpt', 'ChatGPTPromptGenius', 'ChatGPTCoding', 'GPT3', 'OpenAI'])\n",
    "\n",
    "# Define queries to search\n",
    "queries = sorted(['ChatGPT', 'GPT-4', 'GPT-3', 'GPT', 'OpenAI', 'Open-AI', 'LLM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>subscribers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChatGPTCoding</td>\n",
       "      <td>104140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChatGPTPromptGenius</td>\n",
       "      <td>192899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT3</td>\n",
       "      <td>719011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LanguageTechnology</td>\n",
       "      <td>46115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>1116358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>artificial</td>\n",
       "      <td>717231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chatgpt</td>\n",
       "      <td>4480729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>datascience</td>\n",
       "      <td>1360115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>datasets</td>\n",
       "      <td>187602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deeplearning</td>\n",
       "      <td>148827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>learnmachinelearning</td>\n",
       "      <td>384027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>machineLearning</td>\n",
       "      <td>2869747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name  subscribers\n",
       "0          ChatGPTCoding       104140\n",
       "1    ChatGPTPromptGenius       192899\n",
       "2                   GPT3       719011\n",
       "3     LanguageTechnology        46115\n",
       "4                 OpenAI      1116358\n",
       "5             artificial       717231\n",
       "6                chatgpt      4480729\n",
       "7            datascience      1360115\n",
       "8               datasets       187602\n",
       "9           deeplearning       148827\n",
       "10  learnmachinelearning       384027\n",
       "11       machineLearning      2869747"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe structure\n",
    "subreddit_dict = {  \"name\":[],\n",
    "                    \"subscribers\":[] }\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    sub = reddit.subreddit(subreddit)\n",
    "    sub_dir = '/'.join(['data', reddit_user, run_name])\n",
    "    if not os.path.exists(sub_dir):\n",
    "        os.makedirs(sub_dir)\n",
    "    subreddit_dict[\"name\"].append(sub.display_name)\n",
    "    subreddit_dict[\"subscribers\"].append(sub.subscribers)\n",
    "subreddit_data = pd.DataFrame(subreddit_dict)\n",
    "subreddit_data.to_csv('/'.join(['data', reddit_user, run_name, 'subreddits' + '.meta']))\n",
    "subreddit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries sent: 88\n",
      "Total data retrieved: 6966\n"
     ]
    }
   ],
   "source": [
    "# total data retrieved\n",
    "running_count_data = 0\n",
    "# number of queries\n",
    "running_count_queries = 0\n",
    "\n",
    "# Query for a subreddit by name\n",
    "for subreddit in subreddits:\n",
    "    sub = reddit.subreddit(subreddit)\n",
    "    sub_dir = '/'.join(['data', reddit_user, run_name, subreddit])\n",
    "    if not os.path.exists(sub_dir):\n",
    "        os.makedirs(sub_dir)\n",
    "\n",
    "    def sub_search(query):\n",
    "        topics_dict = copy.deepcopy(topics_dict_template)\n",
    "        sort_options = ['top','comments','relevance']\n",
    "        # search by keyword\n",
    "        for sort in sort_options:\n",
    "            search_results = sub.search(query=query, sort=sort, syntax='plain', time_filter='all')\n",
    "            for submission in search_results:\n",
    "                # Append the dictionary to the DataFrame\n",
    "                topics_dict = scrape_submission(topics_dict, submission, {'subreddit': subreddit, 'query': query, 'sort': sort})\n",
    "        return pd.DataFrame(topics_dict)\n",
    "\n",
    "    # PRAW search function\n",
    "    for query in queries:\n",
    "        # Call the retry_function with your function\n",
    "        topics_data = retry_function(sub_search, query)\n",
    "        running_count_queries+=1\n",
    "        if(topics_data is not None):\n",
    "            topics_data.to_csv('/'.join(['data', reddit_user, run_name, subreddit, query + '.csv']))\n",
    "            running_count_data += len(topics_data)\n",
    "\n",
    "    def sub_controversial():\n",
    "        topics_dict = copy.deepcopy(topics_dict_template)\n",
    "        # search by keyword\n",
    "        search_results = sub.controversial(time_filter='all')\n",
    "        for submission in search_results:\n",
    "            # search for query text in controversial posts\n",
    "            for query in queries:\n",
    "                pattern = re.compile(r'\\b' + re.escape(query) + r'\\b', re.IGNORECASE)  # Compile regex pattern\n",
    "                if pattern.search(submission.title) or pattern.search(submission.selftext):\n",
    "                    # Append the dictionary to the DataFrame\n",
    "                    topics_dict = scrape_submission(topics_dict, submission, {'subreddit': subreddit, 'query': query, 'sort': 'controversial'})\n",
    "        return pd.DataFrame(topics_dict)\n",
    "\n",
    "    # PRAW controversial function\n",
    "    topics_data = retry_function(sub_controversial)\n",
    "    running_count_queries+=1\n",
    "    if(topics_data is not None):\n",
    "        topics_data.to_csv('/'.join(['data', reddit_user, run_name, subreddit, 'controversial.csv']))\n",
    "        running_count_data += len(topics_data)\n",
    "\n",
    "print(f\"Total queries sent: {running_count_queries}\")\n",
    "print(f\"Total data retrieved: {running_count_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.675045e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.017321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.237604</td>\n",
       "      <td>3.325830e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.672164e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.672164e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.675045e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.677925e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.677925e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       upvote_ratio  score  num_comments       created\n",
       "count      4.000000    4.0      4.000000  4.000000e+00\n",
       "mean       0.485000    0.0     11.000000  1.675045e+09\n",
       "std        0.017321    0.0      9.237604  3.325830e+06\n",
       "min        0.470000    0.0      3.000000  1.672164e+09\n",
       "25%        0.470000    0.0      3.000000  1.672164e+09\n",
       "50%        0.485000    0.0     11.000000  1.675045e+09\n",
       "75%        0.500000    0.0     19.000000  1.677925e+09\n",
       "max        0.500000    0.0     19.000000  1.677925e+09"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_data\n",
    "topics_data.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
