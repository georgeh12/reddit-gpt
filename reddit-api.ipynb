{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit API data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit forums: r/artificial, r/machinelearning, r/bigscience\n",
    "Use APIs to collect data mentioning GPT-3 and other AI technologies from November 1 2022 to January 31 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/bitgrit-data-science-publication/sentiment-analysis-on-reddit-tech-news-with-python-cbaddb8e9bb6\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# misc\n",
    "import datetime as dt\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "\n",
    "# reddit crawler\n",
    "import praw\n",
    "\n",
    "# sentiment analysis\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer # tokenize words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8) # default plot size\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', palette='Dark2')\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zealousideal-Land259\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open('reddit.json') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "# Instantiate praw.Reddit object\n",
    "reddit = praw.Reddit(\n",
    "    client_id=credentials['client_id'],\n",
    "    client_secret=credentials['client_secret'],\n",
    "    user_agent=credentials['user_agent'],\n",
    "    redirect_uri=credentials['redirect_uri'],\n",
    "    refresh_token=credentials['refresh_token']\n",
    ")\n",
    "\n",
    "# test connection\n",
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape controversial posts from reddit\n",
    "GET [/r/subreddit]/sortreadrss support\n",
    "→ [/r/subreddit]/top\n",
    "→ [/r/subreddit]/controversial\n",
    "This endpoint is a listing.\n",
    "\n",
    "t\t\n",
    "one of (hour, day, week, month, year, all)\n",
    "\n",
    "after\t\n",
    "fullname of a thing\n",
    "\n",
    "before\t\n",
    "fullname of a thing\n",
    "\n",
    "count\t\n",
    "a positive integer (default: 0)\n",
    "\n",
    "limit\t\n",
    "the maximum number of items desired (default: 25, maximum: 100)\n",
    "\n",
    "show\t\n",
    "(optional) the string all\n",
    "\n",
    "sr_detail\t\n",
    "(optional) expand subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_44396\\554058545.py:15: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  top_posts_of_the_day = sub.top('day')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: I found out my company implemented an AI program that would “save the company money” in December\n",
      "AUTHOR: Hey_you_-_-\n",
      "CREATED: 2024-01-31 13:54:31\n",
      "COMMENTS: 113\n",
      "UPS: 19\n",
      "DOWNS: 0\n",
      "URL: https://www.reddit.com/r/artificial/comments/1afid9k/i_found_out_my_company_implemented_an_ai_program/\n",
      "TITLE: What is appealing about AI-created music?\n",
      "AUTHOR: Complex_Valuable_833\n",
      "CREATED: 2024-01-28 19:11:55\n",
      "COMMENTS: 71\n",
      "UPS: 0\n",
      "DOWNS: 0\n",
      "URL: https://www.reddit.com/r/artificial/comments/1adad7s/what_is_appealing_about_aicreated_music/\n",
      "TITLE: Poisoned AI went rogue during training and couldn't be taught to behave again in 'legitimately scary' study\n",
      "AUTHOR: Thekingofchrome\n",
      "CREATED: 2024-01-31 20:39:23\n",
      "COMMENTS: 18\n",
      "UPS: 11\n",
      "DOWNS: 0\n",
      "URL: https://www.livescience.com/technology/artificial-intelligence/legitimately-scary-anthropic-ai-poisoned-rogue-evil-couldnt-be-taught-how-to-behave-again\n",
      "TITLE: Is the reason AI is bad at drawing hands because there have been so many people on the Internet who said it is hard to draw hands?\n",
      "AUTHOR: zakdageneral\n",
      "CREATED: 2024-01-24 00:30:00\n",
      "COMMENTS: 28\n",
      "UPS: 0\n",
      "DOWNS: 0\n",
      "URL: https://www.reddit.com/r/artificial/comments/19e3rem/is_the_reason_ai_is_bad_at_drawing_hands_because/\n",
      "TITLE: Wasn't grimes just right here?\n",
      "AUTHOR: zaidlol\n",
      "CREATED: 2024-02-05 22:33:27\n",
      "COMMENTS: 71\n",
      "UPS: 0\n",
      "DOWNS: 0\n",
      "URL: https://v.redd.it/eoq27jyzfugc1\n",
      "TITLE: That first sentence.....Jesus.\n",
      "AUTHOR: xcywji45\n",
      "CREATED: 2024-01-25 03:36:32\n",
      "COMMENTS: 83\n",
      "UPS: 34\n",
      "DOWNS: 0\n",
      "URL: https://i.redd.it/kz2nftn6biec1.png\n",
      "TITLE: The Cult of AI\n",
      "AUTHOR: dingleberryboy20\n",
      "CREATED: 2024-01-28 03:26:17\n",
      "COMMENTS: 23\n",
      "UPS: 9\n",
      "DOWNS: 0\n",
      "URL: https://www.rollingstone.com/culture/culture-features/ai-companies-advocates-cult-1234954528/\n",
      "TITLE: What do Nation States mean when they say winning the AI race?\n",
      "AUTHOR: Major_Fishing6888\n",
      "CREATED: 2024-02-16 22:33:46\n",
      "COMMENTS: 30\n",
      "UPS: 1\n",
      "DOWNS: 0\n",
      "URL: https://www.reddit.com/r/artificial/comments/1aslq2g/what_do_nation_states_mean_when_they_say_winning/\n",
      "TITLE: Why GPT curators and agents will already be extinct within 2 years and you might become a Star Trek-like communist\n",
      "AUTHOR: gehacktes\n",
      "CREATED: 2024-02-16 17:10:46\n",
      "COMMENTS: 8\n",
      "UPS: 5\n",
      "DOWNS: 0\n",
      "URL: https://www.reddit.com/r/artificial/comments/1asdu94/why_gpt_curators_and_agents_will_already_be/\n",
      "TITLE: Elon Musk's Neuralink implants brain chip in first human\n",
      "AUTHOR: Stupid_hardcorer\n",
      "CREATED: 2024-01-30 08:57:11\n",
      "COMMENTS: 49\n",
      "UPS: 0\n",
      "DOWNS: 0\n",
      "URL: https://www.reddit.com/r/artificial/comments/1aek2oj/elon_musks_neuralink_implants_brain_chip_in_first/\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Define the subreddits to search\n",
    "subreddits = ['artificial', 'machinelearning', 'bigscience']\n",
    "\n",
    "# Define the date range\n",
    "start_date = datetime(2022, 11, 1)\n",
    "end_date = datetime(2023, 1, 31)\n",
    "\n",
    "# Query for a subreddit by name\n",
    "sub = reddit.subreddit('artificial')\n",
    "\n",
    "# Can query for top posts for a time period, the top 20 posts, or the\n",
    "# 10 most controversial posts of the past month\n",
    "top_posts_of_the_day = sub.top('day')\n",
    "hot_posts = sub.hot(limit=20)\n",
    "controversial_posts = sub.controversial(time_filter='month', limit=10)\n",
    "\n",
    "# Can also search for use of a keyword\n",
    "gpt_4 = sub.search('gpt-4.0')\n",
    "\n",
    "# Sample of some of the more interesting data about a \n",
    "# submission that could make for interesting analysis\n",
    "for submission in controversial_posts:\n",
    "    print(\"TITLE: {}\".format(submission.title))\n",
    "    print(\"AUTHOR: {}\".format(submission.author))\n",
    "    parsed_date = datetime.utcfromtimestamp(submission.created)\n",
    "    year = parsed_date.year\n",
    "    month = parsed_date.month\n",
    "    day = parsed_date.day\n",
    "\n",
    "    print(\"CREATED: {}\".format(parsed_date))\n",
    "    print(\"COMMENTS: {}\".format(submission.num_comments))\n",
    "    print(\"UPS: {}\".format(submission.ups))\n",
    "    print(\"DOWNS: {}\".format(submission.downs))\n",
    "    print(\"URL: {}\".format(submission.url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subreddit(display_name='test')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.subreddit(\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
