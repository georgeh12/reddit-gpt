{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit API data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit forums: r/artificial, r/machinelearning, r/bigscience\n",
    "Use APIs to collect data mentioning GPT-3 and other AI technologies from November 1 2022 to January 31 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T13:50:31.189584Z",
     "iopub.status.busy": "2024-02-24T13:50:31.189584Z",
     "iopub.status.idle": "2024-02-24T13:50:31.685368Z",
     "shell.execute_reply": "2024-02-24T13:50:31.685368Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://medium.com/bitgrit-data-science-publication/sentiment-analysis-on-reddit-tech-news-with-python-cbaddb8e9bb6\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# misc\n",
    "import datetime as dt\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "import json\n",
    "\n",
    "# reddit crawler\n",
    "import praw\n",
    "\n",
    "# converting created dates from reddit API into human readable format\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# make directories for data collection\n",
    "import os\n",
    "\n",
    "# copy data structure\n",
    "import copy\n",
    "\n",
    "# regular expression search PRAW results\n",
    "import re\n",
    "\n",
    "# wait time for api limits and api retry\n",
    "import time\n",
    "#import asyncio # Not implemented\n",
    "\n",
    "# choose user for run\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T13:50:31.688886Z",
     "iopub.status.busy": "2024-02-24T13:50:31.687382Z",
     "iopub.status.idle": "2024-02-24T13:50:31.701432Z",
     "shell.execute_reply": "2024-02-24T13:50:31.701432Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_config(users):\n",
    "    # Randomly select a Reddit user to query\n",
    "    default_user = random.choice(users)\n",
    "\n",
    "    # Check if config file exists\n",
    "    config_file = 'config.json'\n",
    "    if not os.path.exists(config_file):\n",
    "        # Create config file with default content\n",
    "        with open(config_file, 'w') as f:\n",
    "            json.dump({\"run\": 0, 'reddit_user': default_user}, f)\n",
    "\n",
    "    # Load run information and increment run\n",
    "    with open(config_file) as f:\n",
    "        config = json.load(f)\n",
    "        config['run'] = config['run'] + 1\n",
    "\n",
    "    # Write new run to config file\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump({\"run\": config['run'], 'reddit_user': default_user}, f)\n",
    "        \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T13:50:31.703432Z",
     "iopub.status.busy": "2024-02-24T13:50:31.703432Z",
     "iopub.status.idle": "2024-02-24T13:50:32.217441Z",
     "shell.execute_reply": "2024-02-24T13:50:32.217441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit user: reddit_user4\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON credentials file\n",
    "with open('reddit.json') as f:\n",
    "    reddit_users = json.load(f)\n",
    "\n",
    "# Get user and run_name\n",
    "config = get_config(list(reddit_users.keys()))\n",
    "\n",
    "# Uncomment to change user manually\n",
    "#config['reddit_user'] = 'reddit_user4'\n",
    "#config['reddit_user'] = 'Zealousideal-Land259'\n",
    "\n",
    "# Get credentials for user\n",
    "credentials = reddit_users[config['reddit_user']]\n",
    "\n",
    "# Instantiate praw.Reddit object\n",
    "reddit = praw.Reddit(\n",
    "    client_id=credentials['client_id'],\n",
    "    client_secret=credentials['client_secret'],\n",
    "    user_agent=credentials['user_agent'],\n",
    "    redirect_uri=credentials['redirect_uri'],\n",
    "    refresh_token=credentials['refresh_token']\n",
    ")\n",
    "\n",
    "# test connection\n",
    "run_name = '{:03d}'.format(config['run'])\n",
    "print(f\"Run name: {run_name}\")\n",
    "reddit_user = str(reddit.user.me())\n",
    "print(f\"Reddit user: {reddit_user}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape top posts from reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T13:50:32.220451Z",
     "iopub.status.busy": "2024-02-24T13:50:32.219451Z",
     "iopub.status.idle": "2024-02-24T13:50:32.232744Z",
     "shell.execute_reply": "2024-02-24T13:50:32.232744Z"
    }
   },
   "outputs": [],
   "source": [
    "# After successful result \n",
    "# Retry every 10 seconds 12 times for a total of 2 minutes\n",
    "def retry_function(func, *args, max_attempts=12, delay=10, **kwargs):\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            start_time = time.time() # record start time of api call\n",
    "            result = func(*args, **kwargs)  # Call the function\n",
    "            end_time = time.time() # record start time of api call\n",
    "            # Reddit API restricts to 100 queries per minute\n",
    "            reddit_api_restriction = 100/60\n",
    "            # wait for the difference between the api restriction and the total api call time\n",
    "            api_wait_time = reddit_api_restriction - (end_time-start_time)\n",
    "            if api_wait_time > 0: time.sleep(api_wait_time)\n",
    "            return result  # Return the result if successful\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            attempts += 1\n",
    "            if attempts < max_attempts:\n",
    "                print(f\"Retrying attempt #{attempts} in {delay} seconds...\")\n",
    "                for _ in range(delay): time.sleep(1)\n",
    "    print(\"Max attempts reached. Continuing loop.\")\n",
    "    return None  # Or you can raise an exception here if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T13:50:32.235251Z",
     "iopub.status.busy": "2024-02-24T13:50:32.235251Z",
     "iopub.status.idle": "2024-02-24T13:50:32.248927Z",
     "shell.execute_reply": "2024-02-24T13:50:32.248409Z"
    }
   },
   "outputs": [],
   "source": [
    "# API structure\n",
    "topics_dict_template = {\"id\":[],\n",
    "                        \"subreddit\":[],\n",
    "                        \"query\":[],\n",
    "                        \"sort\":[],\n",
    "                        \"date\":[],\n",
    "                        \"title\":[],\n",
    "                        \"author\":[],\n",
    "                        \"stickied\":[],\n",
    "                        \"upvote_ratio\":[],\n",
    "                        \"score\":[],\n",
    "                        \"url\":[],\n",
    "                        \"num_comments\": [],\n",
    "                        \"created\": [],\n",
    "                        \"body\":[]}\n",
    "\n",
    "def scrape_submission(topics_dict, submission, other):\n",
    "    #November 1 2022 to January 31 2023\n",
    "    # Define the date range for GPT-3 hype analysis\n",
    "    gpt3_start = datetime(2022, 11, 1)\n",
    "    gpt3_end = datetime(2023, 1, 31)\n",
    "\n",
    "    #February 15 to May 15 that includes the launch GPT-4 on March 14, 2023\n",
    "    # Define the date range for GPT-4 hype analysis\n",
    "    gpt4_start = datetime(2023, 2, 15)\n",
    "    gpt4_end = datetime(2023, 5, 15)\n",
    "\n",
    "    # Scrape only dates within the timeframes\n",
    "    date = datetime.utcfromtimestamp(submission.created)\n",
    "    if (gpt3_start <= date < gpt3_end + timedelta(days=1)) | (gpt4_start <= date < gpt4_end + timedelta(days=1)):\n",
    "        # build the dictionary\n",
    "        topics_dict[\"date\"].append(date)\n",
    "        topics_dict[\"title\"].append(submission.title)\n",
    "        topics_dict[\"author\"].append(submission.author)\n",
    "        topics_dict[\"stickied\"].append(submission.stickied)\n",
    "        topics_dict[\"upvote_ratio\"].append(submission.upvote_ratio)\n",
    "        topics_dict[\"score\"].append(submission.score)\n",
    "        topics_dict[\"id\"].append(submission.id)\n",
    "        topics_dict[\"url\"].append(submission.url)\n",
    "        topics_dict[\"num_comments\"].append(submission.num_comments)\n",
    "        topics_dict[\"created\"].append(submission.created)\n",
    "        topics_dict[\"body\"].append(submission.selftext)\n",
    "        # add subreddit, query, sort\n",
    "        for entry in other:\n",
    "            topics_dict[entry].append(other[entry])\n",
    "    return topics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T13:50:32.250934Z",
     "iopub.status.busy": "2024-02-24T13:50:32.250934Z",
     "iopub.status.idle": "2024-02-24T13:50:32.263409Z",
     "shell.execute_reply": "2024-02-24T13:50:32.263409Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the subreddits to search\n",
    "subreddits = sorted(['artificial', 'datascience', 'datasets', 'deeplearning', 'LanguageTechnology', 'MachineLearning', 'learnmachinelearning',\n",
    "                     'chatgpt', 'ChatGPTPromptGenius', 'ChatGPTCoding', 'GPT3', 'OpenAI'], key=lambda x: x.lower())\n",
    "\n",
    "# Define queries to search\n",
    "queries = sorted(['ChatGPT', 'GPT-4', 'GPT-3', 'GPT', 'OpenAI', 'Open-AI', 'LLM'], key=lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T13:50:32.265928Z",
     "iopub.status.busy": "2024-02-24T13:50:32.265928Z",
     "iopub.status.idle": "2024-02-24T13:50:33.846189Z",
     "shell.execute_reply": "2024-02-24T13:50:33.845169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>subscribers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificial</td>\n",
       "      <td>719228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatgpt</td>\n",
       "      <td>4497274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChatGPTCoding</td>\n",
       "      <td>104300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChatGPTPromptGenius</td>\n",
       "      <td>193183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datascience</td>\n",
       "      <td>1364338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>datasets</td>\n",
       "      <td>187663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deeplearning</td>\n",
       "      <td>149003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GPT3</td>\n",
       "      <td>721147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LanguageTechnology</td>\n",
       "      <td>46141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>learnmachinelearning</td>\n",
       "      <td>384385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>2870230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>1122144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name  subscribers\n",
       "0             artificial       719228\n",
       "1                chatgpt      4497274\n",
       "2          ChatGPTCoding       104300\n",
       "3    ChatGPTPromptGenius       193183\n",
       "4            datascience      1364338\n",
       "5               datasets       187663\n",
       "6           deeplearning       149003\n",
       "7                   GPT3       721147\n",
       "8     LanguageTechnology        46141\n",
       "9   learnmachinelearning       384385\n",
       "10       MachineLearning      2870230\n",
       "11                OpenAI      1122144"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe structure\n",
    "subreddit_dict = {  \"name\":[],\n",
    "                    \"subscribers\":[] }\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    sub = reddit.subreddit(subreddit)\n",
    "    sub_dir = '/'.join(['data', reddit_user, run_name])\n",
    "    if not os.path.exists(sub_dir):\n",
    "        os.makedirs(sub_dir)\n",
    "    subreddit_dict[\"name\"].append(sub.display_name)\n",
    "    subreddit_dict[\"subscribers\"].append(sub.subscribers)\n",
    "subreddit_data = pd.DataFrame(subreddit_dict)\n",
    "subreddit_data.to_csv('/'.join(['data', reddit_user, run_name, 'subreddits' + '.meta']))\n",
    "subreddit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T13:50:33.848707Z",
     "iopub.status.busy": "2024-02-24T13:50:33.848707Z",
     "iopub.status.idle": "2024-02-24T13:55:47.596848Z",
     "shell.execute_reply": "2024-02-24T13:55:47.595849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries sent: 96\n",
      "Total data retrieved: 7538\n"
     ]
    }
   ],
   "source": [
    "# total data retrieved\n",
    "running_count_data = 0\n",
    "# number of queries\n",
    "running_count_queries = 0\n",
    "\n",
    "# Query for a subreddit by name\n",
    "for subreddit in subreddits:\n",
    "    sub = reddit.subreddit(subreddit)\n",
    "    sub_dir = '/'.join(['data', reddit_user, run_name, subreddit])\n",
    "    if not os.path.exists(sub_dir):\n",
    "        os.makedirs(sub_dir)\n",
    "\n",
    "    def sub_search(query):\n",
    "        topics_dict = copy.deepcopy(topics_dict_template)\n",
    "        sort_options = ['top','comments','relevance']\n",
    "        # search by keyword\n",
    "        for sort in sort_options:\n",
    "            search_results = sub.search(query=query, sort=sort, syntax='plain', time_filter='all')\n",
    "            for submission in search_results:\n",
    "                # Append the dictionary to the DataFrame\n",
    "                topics_dict = scrape_submission(topics_dict, submission, {'subreddit': subreddit, 'query': query, 'sort': sort})\n",
    "        return pd.DataFrame(topics_dict)\n",
    "\n",
    "    # PRAW search function\n",
    "    for query in queries:\n",
    "        # Call the retry_function with your function\n",
    "        topics_data = retry_function(sub_search, query)\n",
    "        running_count_queries+=1\n",
    "        if(topics_data is not None):\n",
    "            topics_data.to_csv('/'.join(['data', reddit_user, run_name, subreddit, query + '.csv']))\n",
    "            running_count_data += len(topics_data)\n",
    "\n",
    "    def sub_controversial():\n",
    "        topics_dict = copy.deepcopy(topics_dict_template)\n",
    "        # search by keyword\n",
    "        search_results = sub.controversial(time_filter='all')\n",
    "        for submission in search_results:\n",
    "            # search for query text in controversial posts\n",
    "            for query in queries:\n",
    "                pattern = re.compile(r'\\b' + re.escape(query) + r'\\b', re.IGNORECASE)  # Compile regex pattern\n",
    "                if pattern.search(submission.title) or pattern.search(submission.selftext):\n",
    "                    # Append the dictionary to the DataFrame\n",
    "                    topics_dict = scrape_submission(topics_dict, submission, {'subreddit': subreddit, 'query': query, 'sort': 'controversial'})\n",
    "        return pd.DataFrame(topics_dict)\n",
    "\n",
    "    # PRAW controversial function\n",
    "    topics_data = retry_function(sub_controversial)\n",
    "    running_count_queries+=1\n",
    "    if(topics_data is not None):\n",
    "        topics_data.to_csv('/'.join(['data', reddit_user, run_name, subreddit, 'controversial.csv']))\n",
    "        running_count_data += len(topics_data)\n",
    "\n",
    "print(f\"Total queries sent: {running_count_queries}\")\n",
    "print(f\"Total data retrieved: {running_count_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T13:55:47.599693Z",
     "iopub.status.busy": "2024-02-24T13:55:47.598694Z",
     "iopub.status.idle": "2024-02-24T13:55:47.610834Z",
     "shell.execute_reply": "2024-02-24T13:55:47.610834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.515238</td>\n",
       "      <td>5.619048</td>\n",
       "      <td>49.095238</td>\n",
       "      <td>1.677574e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.038291</td>\n",
       "      <td>14.090693</td>\n",
       "      <td>42.821612</td>\n",
       "      <td>4.447978e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.670809e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.674719e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.510000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.678277e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.679622e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.610000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>1.684048e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       upvote_ratio      score  num_comments       created\n",
       "count     21.000000  21.000000     21.000000  2.100000e+01\n",
       "mean       0.515238   5.619048     49.095238  1.677574e+09\n",
       "std        0.038291  14.090693     42.821612  4.447978e+06\n",
       "min        0.440000   0.000000      4.000000  1.670809e+09\n",
       "25%        0.490000   0.000000     23.000000  1.674719e+09\n",
       "50%        0.510000   1.000000     36.000000  1.678277e+09\n",
       "75%        0.540000   4.000000     68.000000  1.679622e+09\n",
       "max        0.610000  65.000000    207.000000  1.684048e+09"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_data\n",
    "topics_data.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
